commit 5802862c3854c5f2393743014889eced6cc4e2fd
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Nov 23 21:42:43 2009 +0000

    finished min_periods implementation, cleanup of shared code between MovingOLS and MovingPanelOLS
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@50 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index 26bc3efe0..f15b10e48 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -1157,16 +1157,19 @@ class DataMatrix(DataFrame):
                 else:
                     raise Exception('Begin date after last date in this index!')
 
-        if fromDate and toDate:
+        haveFrom = fromDate is not None
+        haveTo = toDate is not None
+
+        if haveFrom and haveTo:
             if nPeriods:
                 raise Exception('fromDate/toDate, toDate/nPeriods, ' +
                                 'fromDate/nPeriods are mutually exclusive')
             beg_slice = self.index.indexMap[fromDate]
             end_slice = self.index.indexMap[toDate] + 1
-        elif fromDate and nPeriods:
+        elif haveFrom and nPeriods:
             beg_slice = self.index.indexMap[fromDate]
             end_slice = self.index.indexMap[fromDate] + nPeriods
-        elif toDate and nPeriods:
+        elif haveTo and nPeriods:
             beg_slice = self.index.indexMap[toDate] - nPeriods + 1
             end_slice = self.index.indexMap[toDate] + 1
         else:
@@ -1469,9 +1472,10 @@ class DataMatrix(DataFrame):
         -------
         DataMatrix with filtered columns
         """
-        if len(self.columns) == 0:
+        if len(self.cols()) == 0:
             return self
-        intersection = self.columns.intersection(items)
+        intersection = Index(self.cols()).intersection(items)
+
         indexer = [self.columns.indexMap[col] for col in intersection]
         newValues = self.values[:, indexer].copy()
         return DataMatrix(newValues, index=self.index, columns=intersection)
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 7cb2c20d2..5d2b9f2b1 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -635,23 +635,23 @@ class LongPanelIndex(object):
 
         return True
 
-    def getSlice(self, begin=None, end=None):
+    def truncate(self, before=None, after=None):
         """
         Slice index between two major axis values, return complete LongPanel
 
         Parameters
         ----------
-        begin: type of major_axis values or None, default None
+        before: type of major_axis values or None, default None
             None defaults to start of panel
 
-        end: type of major_axis values or None, default None
-            None defaults to end of panel
+        after: type of major_axis values or None, default None
+            None defaults to after of panel
 
         Returns
         -------
         LongPanel
         """
-        i, j = self._getAxisBounds(begin, end)
+        i, j = self._getAxisBounds(before, after)
         left, right = self._getLabelBounds(i, j)
 
         return LongPanelIndex(self.major_axis[i : j],
@@ -808,6 +808,17 @@ class LongPanel(Panel):
 
         return LongPanel(values, items, index, factors=factors)
 
+    @property
+    def columns(self):
+        """
+        So LongPanel can be DataMatrix-like at times
+        """
+        return self.items
+
+    def cols(self):
+        "DataMatrix compatibility"
+        return self.columns
+
     def copy(self):
         values = self.values.copy()
         items = self.items
@@ -1059,57 +1070,27 @@ class LongPanel(Panel):
 
         return LongPanel(new_values, self.items, new_index)
 
-    def getSlice(self, begin=None, end=None):
+    def truncate(self, before=None, after=None):
         """
         Slice panel between two major axis values, return complete LongPanel
 
         Parameters
         ----------
-        begin: type of major_axis values or None, default None
+        before: type of major_axis values or None, default None
             None defaults to start of panel
 
-        end: type of major_axis values or None, default None
+        after: type of major_axis values or None, default None
             None defaults to end of panel
 
         Returns
         -------
         LongPanel
         """
-        left, right = self.index.getMajorBounds(begin, end)
-        new_index = self.index.getSlice(begin, end)
+        left, right = self.index.getMajorBounds(before, after)
+        new_index = self.index.truncate(before, after)
 
         return LongPanel(self.values[left : right],
-                         self.items,
-                         new_index)
-
-    def getSliceAtIndices(self, begin, end):
-        return self.getSlice(
-            self.index.major_axis[begin], self.index.major_axis[end])
-
-    def getValueSlice(self, begin=None, end=None):
-        """
-        Slice panel between two major axis values and return only
-        values array
-
-        Parameters
-        ----------
-        begin: type of major_axis values or None, default None
-            None defaults to start of panel
-
-        end: type of major_axis values or None, default None
-            None defaults to end of panel
-
-        Returns
-        -------
-        ndarray
-        """
-        left, right = self.index.getMajorBounds(begin, end)
-
-        return self.values[left : right]
-
-    def getValueSliceAtIndices(self, begin, end):
-        return self.getValueSlice(
-            self.index.major_axis[begin], self.index.major_axis[end])
+                         self.items, new_index)
 
     def filterItems(self, items):
         """
diff --git a/pandas/stats/interface.py b/pandas/stats/interface.py
index 07c89e3c3..05ea3f76e 100644
--- a/pandas/stats/interface.py
+++ b/pandas/stats/interface.py
@@ -81,10 +81,9 @@ def ols(**kwargs):
 
     y = kwargs.get('y')
     if window_type == common.FULL_SAMPLE:
-        if 'window_type' in kwargs:
-            del kwargs['window_type']
-        if 'window' in kwargs:
-            del kwargs['window']
+        for rolling_field in ('window_type', 'window', 'min_periods'):
+            if rolling_field in kwargs:
+                del kwargs[rolling_field]
 
         if isinstance(y, Series):
             klass = OLS
diff --git a/pandas/stats/math.py b/pandas/stats/math.py
index c844e6334..db4b61269 100644
--- a/pandas/stats/math.py
+++ b/pandas/stats/math.py
@@ -7,8 +7,6 @@ from scipy import stats
 import numpy as np
 import numpy.linalg as linalg
 
-from pandas.stats.common import FULL_SAMPLE, EXPANDING, ROLLING, TIME, ENTITY
-
 def rank(X, cond=1.0e-12):
     """
     Return the rank of a matrix X based on its generalized inverse,
@@ -37,34 +35,39 @@ def inv(a):
     except linalg.LinAlgError:
         return np.linalg.pinv(a)
 
-def calc_xx_with_time_effects(x, y):
-    """
-    Returns X'X - (X'T) (T'T)^-1 (T'X)
-    """
-    # X'X
-    xx = np.dot(x.values.T, x.values)
-    xt = x.sum().values
-
-    # X'X - (T'T)^-1 (T'X)
-    count = y.count()
-    selector = count > 0
-
-    xt = xt[selector]
-    count = count[selector]
-
-    return xx - np.dot(xt.T / count, xt)
-
 def is_psd(m):
     eigvals = linalg.eigvals(m)
-
     return np.isreal(eigvals).all() and (eigvals >= 0).all()
 
-def newey_west(m, nw_lags, nobs, df, nw_overlap=False):
-    """Returns the Newey West values."""
+def newey_west(m, max_lags, nobs, df, nw_overlap=False):
+    """
+    Compute Newey-West adjusted covariance matrix, taking into account
+    specified number of leads / lags
+
+    Parameters
+    ----------
+    m: (N x K)
+    max_lags: int
+    nobs: int
+        Number of observations in model
+    df: int
+        Degrees of freedom in explanatory variables
+    nw_overlap: boolean
+
+    Returns
+    -------
+    ndarray (K x K)
+
+    Reference
+    ---------
+    Newey, W. K. & West, K. D. (1987) A Simple, Positive
+    Semi-definite, Heteroskedasticity and Autocorrelation Consistent
+    Covariance Matrix, Econometrica, vol. 55(3), 703-708
+    """
     Xeps = np.dot(m.T, m)
-    for lag in xrange(1, nw_lags + 1):
+    for lag in xrange(1, max_lags + 1):
         auto_cov = np.dot(m[:-lag].T, m[lag:])
-        weight = lag / (nw_lags + 1)
+        weight = lag / (max_lags + 1)
         if nw_overlap:
             weight = 0
         bb = auto_cov + auto_cov.T
@@ -74,136 +77,39 @@ def newey_west(m, nw_lags, nobs, df, nw_overlap=False):
     Xeps *= nobs / (nobs - df)
 
     if nw_overlap and not is_psd(Xeps):
-        new_nw_lags = int(np.ceil(nw_lags * 1.5))
+        new_max_lags = int(np.ceil(max_lags * 1.5))
         print ('nw_overlap is True and newey_west generated a non positive '
-               'semidefinite matrix, so using newey_west with nw_lags of %d.'
-               % new_nw_lags)
-        return newey_west(m, new_nw_lags, nobs, df)
+               'semidefinite matrix, so using newey_west with max_lags of %d.'
+               % new_max_lags)
+        return newey_west(m, new_max_lags, nobs, df)
 
     return Xeps
 
-def var_beta_panel(y, x, beta, xx, rmse, cluster_axis,
-                   nw_lags, nobs, df, nw_overlap):
-
-    from pandas.core.panel import LongPanel, group_agg
-
-    xx_inv = inv(xx)
-
-    if cluster_axis is None:
-        if nw_lags is None:
-            return xx_inv * (rmse ** 2)
-        else:
-            resid = y.values.squeeze() - np.dot(x.values, beta)
-            m = (x.values.T * resid).T
-
-            xeps = newey_west(m, nw_lags, nobs, df, nw_overlap)
-
-            return np.dot(xx_inv, np.dot(xeps, xx_inv))
-    else:
-        Xb = np.dot(x.values, beta).reshape((len(x.values), 1))
-        resid = LongPanel(y.values - Xb, ['resid'], y.index)
-
-        if cluster_axis == 1:
-            x = x.swapaxes()
-            resid = resid.swapaxes()
-
-        m = group_agg(x.values * resid.values, x.index._bounds,
-                      lambda x: np.sum(x, axis=0))
-
-        if nw_lags is None:
-            nw_lags = 0
-
-        xox = 0
-        for i in range(len(x.major_axis)):
-            xox += newey_west(m[i : i + 1], nw_lags,
-                              nobs, df, nw_overlap)
-
-        return np.dot(xx_inv, np.dot(xox, xx_inv))
-
-
-def xx_time_effects(x, y):
+def calc_F(R, r, beta, var_beta, nobs, df):
     """
-    Returns X'X - (X'T) (T'T)^-1 (T'X)
+    Computes the standard F-test statistic for linear restriction
+    hypothesis testing
+
+    Parameters
+    ----------
+    R: ndarray (N x N)
+        Restriction matrix
+    r: ndarray (N x 1)
+        Restriction vector
+    beta: ndarray (N x 1)
+        Estimated model coefficients
+    var_beta: ndarray (N x N)
+        Variance covariance matrix of regressors
+    nobs: int
+        Number of observations in model
+    df: int
+        Model degrees of freedom
+
+    Returns
+    -------
+    F value, (q, df_resid), p value
     """
-    # X'X
-    xx = np.dot(x.values.T, x.values)
-    xt = x.sum().values
-
-    count = y.count()
-    selector = count > 0
-
-    # X'X - (T'T)^-1 (T'X)
-    xt = xt[selector]
-    count = count[selector]
-
-    return xx - np.dot(xt.T / count, xt)
 
-def calc_var_beta(x, y, nw_lags, rmse, beta, nobs, df, window_type=FULL_SAMPLE,
-                  window=None, nw_overlap=False):
-    """Returns the covariance of beta.
-
-    For a full-sample regression, this returns the covariance matrix of betas.
-    For rolling/expanding regressions, this returns the variances of betas.
-    """
-    if window_type == FULL_SAMPLE:
-        xx = np.dot(x.T, x)
-    else:
-        cum_xx = []
-        cum_xx.append(np.dot(x[0 : 1].T, x[0 : 1]))
-
-        for i in xrange(1, len(y)):
-            cum_xx.append(cum_xx[i - 1] + np.dot(x[i : i + 1].T,
-                      x[i : i + 1]))
-
-    if window_type == FULL_SAMPLE:
-        if nw_lags is None:
-            return inv(xx) * (rmse ** 2)
-        else:
-            resid = y - np.dot(x, beta)
-            m = (x.T * resid).T
-
-            xeps = newey_west(m, nw_lags, nobs, df, nw_overlap)
-
-            xx_inv = inv(xx)
-            return np.dot(xx_inv, np.dot(xeps, xx_inv))
-    else:
-        results = []
-        start = window - 1
-        for i in xrange(start, len(y)):
-            if nw_lags is None:
-                temp_xx = cum_xx[i]
-                if window_type == ROLLING and i >= window:
-                    temp_xx = temp_xx - cum_xx[i - window]
-                result = inv(temp_xx) * (rmse[i - start] ** 2)
-            else:
-                temp_xx = cum_xx[i]
-
-                if window_type == EXPANDING:
-                    begin = 0
-                else:
-                    begin = i - start
-                    if i >= window:
-                        temp_xx = temp_xx - cum_xx[i - window]
-
-                section = slice(begin, i + 1)
-
-                resid = y[section] - np.dot(x[section], beta[i - start])
-                m = (x[section].T * resid).T
-
-                window_nobs = i + 1 - begin
-                window_df = df[i - start]
-
-                xeps = newey_west(m, nw_lags, window_nobs,
-                                  window_df, nw_overlap)
-
-                xx_inv = inv(temp_xx)
-                result = np.dot(xx_inv, np.dot(xeps, xx_inv))
-
-            results.append(result)
-
-        return results
-
-def calc_F(R, r, beta, var_beta, nobs, df):
     hyp = np.dot(R, beta.reshape(len(beta), 1)) - r
     RSR = np.dot(R, np.dot(var_beta, R.T))
 
@@ -214,55 +120,3 @@ def calc_F(R, r, beta, var_beta, nobs, df):
     p_value = 1 - stats.f.cdf(F, q, nobs - df)
 
     return F, (q, nobs - df), p_value
-
-def calc_f_stat(nw_lags, r2, r2_adj, cols, beta, var_beta, nobs, df,
-                window=None, T=None):
-    if nw_lags is None:
-        F = r2 / (r2 - r2_adj)
-
-        q = len(cols)
-        if 'intercept' in cols:
-            q -= 1
-
-        if window is None:
-            shape = q, nobs - df
-            p_value = 1 - stats.f.cdf(F, shape[0], shape[1])
-            return F, shape, p_value
-
-        results = []
-
-        start = window - 1
-        for i in xrange(start, T):
-            shape = q, nobs[i - start] - df[i - start]
-            p_value = 1 - stats.f.cdf(F[i - start], shape[0], shape[1])
-            result = F[i - start], shape, p_value
-            results.append(result)
-
-        return results
-
-    k = len(cols)
-
-    R = np.eye(k)
-    r = np.zeros((k, 1))
-
-    intercept = cols.indexMap.get('intercept')
-
-    if intercept is not None:
-        R = np.concatenate((R[0 : intercept], R[intercept + 1:]))
-        r = np.concatenate((r[0 : intercept], r[intercept + 1:]))
-
-    if window is None:
-        return calc_F(R, r, beta, var_beta, nobs, df)
-
-    results = []
-
-    start = window - 1
-    for i in xrange(start, T):
-        b = beta[i - start]
-        vb = var_beta[i - start]
-        n = nobs[i - start]
-        d = df[i - start]
-        result = calc_F(R, r, b, vb, n, d)
-        results.append(result)
-
-    return results
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index bd99a9b1b..e7f490556 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -3,6 +3,7 @@ Simple OLS.
 """
 from __future__ import division
 
+from itertools import izip, starmap
 from StringIO import StringIO
 
 import numpy as np
@@ -41,7 +42,6 @@ class OLS(object):
 
         self._x_raw = self._x.values
         self._y_raw = self._y.view(np.ndarray)
-        self._nobs = len(self._y_raw)
 
         self.sm_ols = sm.OLS(self._y_raw, self._x_raw).fit()
 
@@ -65,6 +65,10 @@ class OLS(object):
     def nobs(self):
         return self._nobs
 
+    @property
+    def _nobs(self):
+        return len(self._y_raw)
+
     @property
     def nw_lags(self):
         return self._nw_lags
@@ -127,7 +131,37 @@ class OLS(object):
         """Returns the raw f-stat value."""
         return math.calc_f_stat(self._nw_lags, self._r2_raw, self._r2_adj_raw,
                                 self._x.columns, self._beta_raw,
-                                self._var_beta_raw,self._nobs, self.df)
+                                self._var_beta_raw, self._nobs, self.df)
+
+    @cache_readonly
+    def _f_stat_raw(self):
+        """Returns the raw f-stat value."""
+        cols = self._x.columns
+
+        if self._nw_lags is None:
+            F = self._r2_raw / (self._r2_raw - self._r2_adj_raw)
+
+            q = len(cols)
+            if 'intercept' in cols:
+                q -= 1
+
+            shape = q, self.df_resid
+            p_value = 1 - stats.f.cdf(F, shape[0], shape[1])
+            return F, shape, p_value
+
+        k = len(cols)
+        R = np.eye(k)
+        r = np.zeros((k, 1))
+
+        intercept = cols.indexMap.get('intercept')
+
+        if intercept is not None:
+            R = np.concatenate((R[0 : intercept], R[intercept + 1:]))
+            r = np.concatenate((r[0 : intercept], r[intercept + 1:]))
+
+        return math.calc_F(R, r, self._beta_raw, self._var_beta_raw,
+                           self._nobs, self.df)
+
     @cache_readonly
     def f_stat(self):
         """Returns the f-stat value."""
@@ -180,7 +214,7 @@ class OLS(object):
         r = np.array(r).reshape(q, 1)
 
         result = math.calc_F(R, r, self._beta_raw, self._var_beta_raw,
-                             self.nobs, self.df)
+                             self._nobs, self.df)
 
         return common.f_stat_to_dict(result)
 
@@ -195,7 +229,7 @@ class OLS(object):
     @cache_readonly
     def p_value(self):
         """Returns the p values."""
-        return Series(self._p_value_raw, index=self._result_index)
+        return Series(self._p_value_raw, index=self.beta.index)
 
     @cache_readonly
     def _r2_raw(self):
@@ -247,7 +281,7 @@ class OLS(object):
     @cache_readonly
     def std_err(self):
         """Returns the standard err values of the betas."""
-        return Series(self._std_err_raw, index=self._result_index)
+        return Series(self._std_err_raw, index=self.beta.index)
 
     @cache_readonly
     def _t_stat_raw(self):
@@ -257,17 +291,10 @@ class OLS(object):
     @cache_readonly
     def t_stat(self):
         """Returns the t-stat values of the betas."""
-        return Series(self._t_stat_raw, index=self._result_index)
+        return Series(self._t_stat_raw, index=self.beta.index)
 
+    @cache_readonly
     def _var_beta_raw(self):
-        """Returns the raw covariance of beta."""
-        result = math.calc_var_beta(x=self._x_raw, y=self._y_raw,
-                                    nw_lags=self._nw_lags, rmse=self._rmse_raw,
-                                    beta=self._beta_raw, nobs=self.nobs,
-                                    df=self._df_raw, nw_overlap=self._nw_overlap)
-        return np.array(result)
-
-    def _var_beta_raw2(self):
         """
         Returns the raw covariance of beta.
         """
@@ -279,10 +306,10 @@ class OLS(object):
         if self._nw_lags is None:
             return math.inv(xx) * (self._rmse_raw ** 2)
         else:
-            resid = y - np.dot(x, beta)
+            resid = y - np.dot(x, self._beta_raw)
             m = (x.T * resid).T
 
-            xeps = math.newey_west(m, self._nw_lags, self.nobs, self._df_raw,
+            xeps = math.newey_west(m, self._nw_lags, self._nobs, self._df_raw,
                                    self._nw_overlap)
 
             xx_inv = math.inv(xx)
@@ -291,8 +318,8 @@ class OLS(object):
     @cache_readonly
     def var_beta(self):
         """Returns the variance-covariance matrix of beta."""
-        return DataMatrix(self._var_beta_raw, index=self._result_index,
-                          columns=self._result_index)
+        return DataMatrix(self._var_beta_raw, index=self.beta.index,
+                          columns=self.beta.index)
 
     @cache_readonly
     def _y_fitted_raw(self):
@@ -318,7 +345,7 @@ class OLS(object):
         return self.y_fitted
 
     RESULT_FIELDS = ['r2', 'r2_adj', 'df', 'df_model', 'df_resid', 'rmse',
-                     'f_stat', 'beta', 'std_err', 't_stat', 'p_value']
+                     'f_stat', 'beta', 'std_err', 't_stat', 'p_value', 'nobs']
 
     @cache_readonly
     def _results(self):
@@ -430,7 +457,7 @@ Degrees of Freedom: model %(df_model)d, resid %(df_resid)d
             'formula' : formula.getvalue(),
             'r2' : results['r2'],
             'r2_adj' : results['r2_adj'],
-            'nobs' : self.nobs,
+            'nobs' : results['nobs'],
             'df'  : results['df'],
             'df_model'  : results['df_model'],
             'df_resid'  : results['df_resid'],
@@ -446,6 +473,12 @@ Degrees of Freedom: model %(df_model)d, resid %(df_resid)d
     def __repr__(self):
         return self.summary
 
+
+    @cache_readonly
+    def _time_obs_count(self):
+        # XXX
+        return self._time_has_obs.astype(int)
+
     @property
     def _total_times(self):
         return self._time_has_obs.sum()
@@ -481,9 +514,8 @@ class MovingOLS(OLS):
         self._window = window
         self._min_periods = window if min_periods is None else min_periods
 
-    @property
-    def _is_rolling(self):
-        return self._window_type == common.ROLLING
+#-------------------------------------------------------------------------------
+# "Public" results
 
     @cache_readonly
     def beta(self):
@@ -492,6 +524,109 @@ class MovingOLS(OLS):
                           index=self._result_index,
                           columns=self._x.cols())
 
+    @cache_readonly
+    def rank(self):
+        return Series(self._rank_raw, index=self._result_index)
+
+    @cache_readonly
+    def df(self):
+        """Returns the degrees of freedom."""
+        return Series(self._df_raw, index=self._result_index)
+
+    @cache_readonly
+    def df_model(self):
+        """Returns the model degrees of freedom."""
+        return Series(self._df_model_raw, index=self._result_index)
+
+    @cache_readonly
+    def df_resid(self):
+        """Returns the residual degrees of freedom."""
+        return Series(self._df_resid_raw, index=self._result_index)
+
+    @cache_readonly
+    def f_stat(self):
+        """Returns the f-stat value."""
+        f_stat_dicts = dict((date, common.f_stat_to_dict(f_stat))
+                            for date, f_stat in zip(self.beta.index,
+                                                    self._f_stat_raw))
+
+        return DataFrame.fromDict(f_stat_dicts).T
+
+    def f_test(self, hypothesis):
+        raise Exception('f_test not supported for rolling/expanding OLS')
+
+    @cache_readonly
+    def p_value(self):
+        """Returns the p values."""
+        cols = self.beta.cols()
+        return DataMatrix(self._p_value_raw, columns=cols,
+                          index=self._result_index)
+
+    @cache_readonly
+    def r2(self):
+        """Returns the r-squared values."""
+        return Series(self._r2_raw, index=self._result_index)
+
+    @cache_readonly
+    def resid(self):
+        """Returns the residuals."""
+        return Series(self._resid_raw[self._valid_obs_labels],
+                      index=self._result_index)
+
+    @cache_readonly
+    def r2_adj(self):
+        """Returns the r-squared adjusted values."""
+        index = self.r2.index
+
+        return Series(self._r2_adj_raw, index=index)
+
+    @cache_readonly
+    def rmse(self):
+        """Returns the rmse values."""
+        return Series(self._rmse_raw, index=self._result_index)
+
+    @cache_readonly
+    def std_err(self):
+        """Returns the standard err values."""
+        return DataMatrix(self._std_err_raw, columns=self.beta.cols(),
+                          index=self._result_index)
+
+    @cache_readonly
+    def t_stat(self):
+        """Returns the t-stat value."""
+        return DataMatrix(self._t_stat_raw, columns=self.beta.cols(),
+                          index=self._result_index)
+
+    @cache_readonly
+    def var_beta(self):
+        """Returns the covariance of beta."""
+        result = []
+        for i in xrange(len(self._var_beta_raw)):
+            dm = DataMatrix(self._var_beta_raw[i], columns=self.beta.cols(),
+                            index=self.beta.cols())
+            result.append(dm)
+
+        return Series(result, index=self._result_index)
+
+    @cache_readonly
+    def y_fitted(self):
+        """Returns the fitted y values."""
+        return Series(self._y_fitted_raw[self._valid_obs_labels],
+                      index=self._result_index)
+
+    @cache_readonly
+    def y_predict(self):
+        """Returns the predicted y values."""
+        return Series(self._y_predict_raw[self._valid_obs_labels],
+                      index=self._result_index)
+
+#-------------------------------------------------------------------------------
+# "raw" attributes, calculations
+
+    @property
+    def _is_rolling(self):
+        return self._window_type == common.ROLLING
+
     @cache_readonly
     def _beta_raw(self):
         """Runs the regression and returns the beta."""
@@ -509,9 +644,9 @@ class MovingOLS(OLS):
 
     @cache_readonly
     def _rolling_ols_call(self):
-        return self._calc_betas()
+        return self._calc_betas(self._x, self._y)
 
-    def _calc_betas(self):
+    def _calc_betas(self, x, y):
         N = len(self._index)
         K = len(self._x.cols())
 
@@ -523,11 +658,10 @@ class MovingOLS(OLS):
         window = self._window
 
         # Use transformed (demeaned) Y, X variables
-        cum_xx = self._cum_xx(self._x)
-        cum_xy = self._cum_xy(self._x, self._y)
+        cum_xx = self._cum_xx(x)
+        cum_xy = self._cum_xy(x, y)
 
         for i in xrange(N):
-            # XXX
             if not valid[i] or not enough[i]:
                 continue
 
@@ -543,70 +677,76 @@ class MovingOLS(OLS):
 
         return betas, have_betas
 
+    def _rolling_rank(self):
+        dates = self._index
+        window = self._window
+
+        ranks = np.empty(len(dates), dtype=float)
+        ranks[:] = np.NaN
+        for i, date in enumerate(dates):
+            if self._is_rolling and i >= window:
+                prior_date = dates[i - window + 1]
+            else:
+                prior_date = dates[0]
+
+            x_slice = self._x.truncate(before=prior_date, after=date)
+            ranks[i] = math.rank(x_slice.values)
+
+        return ranks
+
     def _cum_xx(self, x):
+        dates = self._index
         K = len(x.cols())
         valid = self._time_has_obs
         cum_xx = []
 
         last = np.zeros((K, K))
-        for i, date in enumerate(self._index):
+        for i, date in enumerate(dates):
             if not valid[i]:
                 cum_xx.append(last)
                 continue
 
-            xs = x.getXS(date)
-            xx = last = last + np.outer(xs, xs)
+            x_slice = x.truncate(date, date).values
+            xx = last = last + np.dot(x_slice.T, x_slice)
             cum_xx.append(xx)
 
         return cum_xx
 
     def _cum_xy(self, x, y):
+        dates = self._index
         valid = self._time_has_obs
         cum_xy = []
-        last = len(x.cols())
-        for i, date in enumerate(self._index):
+
+        # A little kludge so we can use this method for both
+        # MovingOLS and MovingPanelOLS
+        if isinstance(y, Series):
+            y_converter = lambda x: np.asarray(x)
+        else:
+            y_converter = lambda x: x.values.squeeze()
+
+        last = np.zeros(len(x.cols()))
+        for i, date in enumerate(dates):
             if not valid[i]:
                 cum_xy.append(last)
                 continue
 
-            xs = np.asarray(x.getXS(date))
-            xy = last = last + xs * y[date]
+            x_slice = x.truncate(date, date).values
+            y_slice = y_converter(y.truncate(date, date))
+
+            xy = last = last + np.dot(x_slice.T, y_slice)
             cum_xy.append(xy)
 
         return cum_xy
 
-    @cache_readonly
-    def rank(self):
-        return Series(self._rank_raw, index=self._result_index)
-
     @cache_readonly
     def _rank_raw(self):
-        rank = self._rolling_rank
-
+        rank = self._rolling_rank()
         return rank[self._valid_indices]
 
-    @cache_readonly
-    def _rolling_rank(self):
-        dates = self._index
-        enough = self._enough_obs
-        window = self._window
-
-        ranks = np.empty(len(dates), dtype=float)
-        ranks[:] = np.NaN
-        for i, date in enumerate(dates):
-            if self._is_rolling and i >= window:
-                prior_date = dates[i - window + 1]
-            else:
-                prior_date = dates[0]
-
-            x_slice = self._x.truncate(before=prior_date, after=date)
-            ranks[i] = math.rank(x_slice.values)
-
-        return ranks
-
     @cache_readonly
     def _df_raw(self):
         """Returns the degrees of freedom."""
+        return self._rank_raw
 
     @cache_readonly
     def _df_model_raw(self):
@@ -618,42 +758,47 @@ class MovingOLS(OLS):
         """Returns the raw residual degrees of freedom."""
         return self._nobs - self._df_raw
 
-        return self._rank_raw
-
     @cache_readonly
     def _f_stat_raw(self):
         """Returns the raw f-stat value."""
-        return math.calc_f_stat(self._nw_lags, self._r2_raw, self._r2_adj_raw,
-                                self._x.columns, self._beta_raw,
-                                self._var_beta_raw, self._nobs, self.df,
-                                self._window, self._nobs)
+        items = self.beta.columns
+        nobs = self._nobs
+        df = self._df_raw
+        df_resid = nobs - df
 
-    @cache_readonly
-    def df(self):
-        """Returns the degrees of freedom."""
-        return Series(self._df_raw, index=self._result_index)
+        # var_beta has not been newey-west adjusted
+        if self._nw_lags is None:
+            F = self._r2_raw / (self._r2_raw - self._r2_adj_raw)
 
-    @cache_readonly
-    def df_model(self):
-        """Returns the model degrees of freedom."""
-        return Series(self._df_model_raw, index=self._result_index)
+            q = len(items)
+            if 'intercept' in items:
+                q -= 1
 
-    @cache_readonly
-    def df_resid(self):
-        """Returns the residual degrees of freedom."""
-        return Series(self._df_resid_raw, index=self._result_index)
+            def get_result_simple(Fst, d):
+                return Fst, (q, d), 1 - stats.f.cdf(Fst, q, d)
 
-    @cache_readonly
-    def f_stat(self):
-        """Returns the f-stat value."""
-        f_stat_dicts = dict((date, common.f_stat_to_dict(f_stat))
-                            for date, f_stat in zip(self.beta.index,
-                                                    self._f_stat_raw))
+            # Compute the P-value for each pair
+            result = starmap(get_result_simple, izip(F, df_resid))
 
-        return DataFrame.fromDict(f_stat_dicts).T
+            return list(result)
 
-    def f_test(self, hypothesis):
-        raise Exception('f_test not supported for rolling/expanding OLS')
+        K = len(items)
+        R = np.eye(K)
+        r = np.zeros((K, 1))
+
+        intercept = items.indexMap.get('intercept')
+
+        if intercept is not None:
+            R = np.concatenate((R[0 : intercept], R[intercept + 1:]))
+            r = np.concatenate((r[0 : intercept], r[intercept + 1:]))
+
+        def get_result(beta, vcov, n, d):
+            return math.calc_F(R, r, beta, vcov, n, d)
+
+        results = starmap(get_result,
+                          izip(self._beta_raw, self._var_beta_raw, nobs, df))
+
+        return list(results)
 
     @cache_readonly
     def _p_value_raw(self):
@@ -667,25 +812,16 @@ class MovingOLS(OLS):
 
         return result
 
-    @cache_readonly
-    def p_value(self):
-        """Returns the p values."""
-        cols = self.beta.cols()
-        return DataMatrix(self._p_value_raw, columns=cols, index=self._result_index)
-
     @cache_readonly
     def _resid_stats(self):
+        sst = []
+        sse = []
+
         Y = self._y
         X = self._x
-
         dates = self._index
         window = self._window
-
-        sst = []
-        sse = []
-
         for n, index in enumerate(self._valid_indices):
-
             if self._is_rolling and index >= window:
                 prior_date = dates[index - window + 1]
             else:
@@ -730,33 +866,10 @@ class MovingOLS(OLS):
         factors = (nobs - 1) / (nobs - self._df_raw)
         return 1 - (1 - self._r2_raw) * factors
 
-    @cache_readonly
-    def r2(self):
-        """Returns the r-squared values."""
-        return Series(self._r2_raw, index=self._result_index)
-
     @cache_readonly
     def _resid_raw(self):
         """Returns the raw residuals."""
-        start = self._window - 1
-        return self._y_raw[start:] - self._y_fitted_raw
-
-    @cache_readonly
-    def resid(self):
-        """Returns the residuals."""
-        return Series(self._resid_raw, index=self._result_index)
-
-    @cache_readonly
-    def r2_adj(self):
-        """Returns the r-squared adjusted values."""
-        index = self.r2.index
-
-        return Series(self._r2_adj_raw, index=index)
-
-    @cache_readonly
-    def rmse(self):
-        """Returns the rmse values."""
-        return Series(self._rmse_raw, index=self._result_index)
+        return (self._y_raw - self._y_fitted_raw)
 
     @cache_readonly
     def _std_err_raw(self):
@@ -767,111 +880,74 @@ class MovingOLS(OLS):
 
         return np.nan_to_num(np.array(results))
 
-    @cache_readonly
-    def std_err(self):
-        """Returns the standard err values."""
-        return DataMatrix(self._std_err_raw, columns=self.beta.cols(),
-                          index=self._result_index)
-
     @cache_readonly
     def _t_stat_raw(self):
         """Returns the raw t-stat value."""
         return np.nan_to_num(self._beta_raw / self._std_err_raw)
 
     @cache_readonly
-    def t_stat(self):
-        """Returns the t-stat value."""
-        return DataMatrix(self._t_stat_raw, columns=self.beta.cols(),
-                          index=self._result_index)
-
     def _var_beta_raw(self):
         """Returns the raw covariance of beta."""
-        result = math.calc_var_beta(x=self._x_raw, y=self._y_raw,
-                                    window_type=self._window_type,
-                                    window=self._window, nw_lags=self._nw_lags,
-                                    rmse=self._rmse_raw, beta=self._beta_raw,
-                                    nobs=self.nobs, df=self._df_raw,
-                                    nw_overlap=self._nw_overlap)
-        return np.array(result)
-
-    def _var_beta_raw2(self):
-        """Returns the raw covariance of beta."""
-        results = []
-        start = window - 1
-        for i in xrange(start, len(y)):
-            if nw_lags is None:
-                temp_xx = cum_xx[i]
-                if window_type == ROLLING and i >= window:
-                    temp_xx = temp_xx - cum_xx[i - window]
-                result = inv(temp_xx) * (rmse[i - start] ** 2)
-            else:
-                temp_xx = cum_xx[i]
+        x = self._x
+        y = self._y
+        dates = self._index
+        nobs = self._nobs
+        rmse = self._rmse_raw
+        beta = self._beta_raw
+        df = self._df_raw
+        window = self._window
+        cum_xx = self._cum_xx(self._x)
 
-                if window_type == EXPANDING:
-                    begin = 0
-                else:
-                    begin = i - start
-                    if i >= window:
-                        temp_xx = temp_xx - cum_xx[i - window]
+        results = []
+        for n, i in enumerate(self._valid_indices):
+            xx = cum_xx[i]
+            date = dates[i]
 
-                section = slice(begin, i + 1)
+            if self._is_rolling and i >= window:
+                xx = xx - cum_xx[i - window]
+                prior_date = dates[i - window + 1]
+            else:
+                prior_date = dates[0]
 
-                resid = y[section] - np.dot(x[section], beta[i - start])
-                m = (x[section].T * resid).T
+            x_slice = x.truncate(before=prior_date, after=date)
+            y_slice = y.truncate(before=prior_date, after=date)
+            xv = x_slice.values
+            yv = np.asarray(y_slice)
 
-                window_nobs = i + 1 - begin
-                window_df = df[i - start]
+            if self._nw_lags is None:
+                result = math.inv(xx) * (rmse[n] ** 2)
+            else:
+                resid = yv - np.dot(xv, beta[n])
+                m = (xv.T * resid).T
 
-                xeps = newey_west(m, nw_lags, window_nobs,
-                                  window_df, nw_overlap)
+                xeps = math.newey_west(m, self._nw_lags, nobs[n], df[n],
+                                       self._nw_overlap)
 
-                xx_inv = inv(temp_xx)
+                xx_inv = math.inv(xx)
                 result = np.dot(xx_inv, np.dot(xeps, xx_inv))
 
             results.append(result)
 
-        return results
-
-    @cache_readonly
-    def var_beta(self):
-        """Returns the covariance of beta."""
-        result = []
-        for i in xrange(len(self._var_beta_raw)):
-            result.append(DataMatrix(
-                self._var_beta_raw[i], columns=self.beta.cols(),
-                index=self.beta.cols()))
-
-        return Series(result, index=self._result_index)
+        return np.array(results)
 
     @cache_readonly
     def _y_fitted_raw(self):
         """Returns the raw fitted y values."""
-        start = self._window - 1
-        return (self._x_raw[start:] * self._beta_raw).sum(1)
-
-    @cache_readonly
-    def y_fitted(self):
-        """Returns the fitted y values."""
-        return Series(self._y_fitted_raw, index=self._result_index)
+        return (self._x_raw * self._beta_matrix(lag=0)).sum(1)
 
     @cache_readonly
     def _y_predict_raw(self):
         """Returns the raw predicted y values."""
-        bx = self._beta_raw[: -1] * self._x_raw[self._window :]
-        return bx.sum(1)
-
-    @cache_readonly
-    def y_predict(self):
-        """Returns the predicted y values."""
-        index = self.beta.index[1 :]
-        return Series(self._y_predict_raw, index=index)
+        return (self._x_raw * self._beta_matrix(lag=1)).sum(1)
 
     @cache_readonly
     def _results(self):
         results = {}
         for result in self.RESULT_FIELDS:
             value = getattr(self, result)
-            if isinstance(value, Series):
+            if isinstance(value, np.ndarray):
+                value = value[-1]
+            elif isinstance(value, Series):
                 value = value[self.beta.index[-1]]
             elif isinstance(value, DataFrame):
                 value = value.getXS(self.beta.index[-1])
@@ -882,29 +958,12 @@ class MovingOLS(OLS):
         return results
 
     @cache_readonly
-    def _nobs(self):
-        results = []
-        start = self._window - 1
-        for i in xrange(start, self._nobs):
-            if self._window_type == common.EXPANDING:
-                result = i + 1
-            else:
-                result = self._window
-
-            results.append(result)
-
-        return results
-
-    def _beta_matrix(self, lag=0):
-        assert(lag >= 0)
-
-        labels = self._y_trans.index.major_labels - lag
-        indexer = self._valid_indices.searchsorted(labels, side='left')
+    def _window_time_obs(self):
+        window_obs = tseries.rolling_sum(self._time_obs_count > 0,
+                                         self._window, minp=1)
 
-        beta_matrix = self._beta_raw[indexer]
-        beta_matrix[labels < 0] = np.NaN
-
-        return beta_matrix
+        window_obs[np.isnan(window_obs)] = 0
+        return window_obs.astype(int)
 
     @cache_readonly
     def _nobs_raw(self):
@@ -914,15 +973,35 @@ class MovingOLS(OLS):
             # expanding case
             window = len(self._index)
 
-        result = tseries.rolling_sum(self._time_has_obs, window,
+        result = tseries.rolling_sum(self._time_obs_count, window,
                                      minp=1)
 
         return result.astype(int)
 
+    def _beta_matrix(self, lag=0):
+        assert(lag >= 0)
+
+        labels = np.arange(len(self._y)) - lag
+        indexer = self._valid_obs_labels.searchsorted(labels, side='left')
+
+        beta_matrix = self._beta_raw[indexer]
+        beta_matrix[labels < self._valid_obs_labels[0]] = np.NaN
+
+        return beta_matrix
+
+    @cache_readonly
+    def _valid_obs_labels(self):
+        dates = self._index[self._valid_indices]
+        return self._y.index.searchsorted(dates)
+
     @cache_readonly
     def _nobs(self):
         return self._nobs_raw[self._valid_indices]
 
+    @property
+    def nobs(self):
+        return Series(self._nobs, index=self._result_index)
+
     @cache_readonly
     def _enough_obs(self):
         # XXX: what's the best way to determine where to start?
@@ -999,3 +1078,4 @@ def _filter_data(lhs, rhs):
     filtered_lhs = filtered_rhs.pop('_y')
 
     return filtered_lhs, filtered_rhs, pre_filtered_rhs, index, valid
+
diff --git a/pandas/stats/plm.py b/pandas/stats/plm.py
index 1ab41d025..f493d9de5 100644
--- a/pandas/stats/plm.py
+++ b/pandas/stats/plm.py
@@ -6,20 +6,16 @@ Linear regression objects for panel data
 # pylint: disable-msg=E1103
 
 from __future__ import division
-from itertools import izip, starmap
 
 import numpy as np
-from scipy import stats
 
 from pandas.core.panel import WidePanel, LongPanel
 from pandas.core.matrix import DataMatrix
 from pandas.core.series import Series
 from pandas.stats.ols import OLS, MovingOLS
 from pandas.util.decorators import cache_readonly
-
 import pandas.stats.common as common
 import pandas.stats.math as math
-import pandas.lib.tseries as tseries
 
 class PanelOLS(OLS):
     """Implements panel OLS.
@@ -85,9 +81,8 @@ class PanelOLS(OLS):
         self._y_trans_raw = self._y_trans.values.squeeze()
 
         self._index = self._y.major_axis
-        self._T = len(self._index)
 
-        self._nobs = len(self._y_trans_raw)
+        self._T = len(self._index)
 
     def log(self, msg):
         if self._verbose:
@@ -306,7 +301,7 @@ class PanelOLS(OLS):
         X = self._x_trans_raw
         Y = self._y_trans_raw
 
-        beta, ssr, rank, sing = np.linalg.lstsq(X, Y)
+        beta, _, _, _ = np.linalg.lstsq(X, Y)
 
         return beta
 
@@ -333,13 +328,6 @@ class PanelOLS(OLS):
 
         return df
 
-    @cache_readonly
-    def _f_stat_raw(self):
-        """Returns the raw f-stat value."""
-        return math.calc_f_stat(self._nw_lags, self._r2_raw, self._r2_adj_raw,
-                                self._x.items, self._beta_raw,
-                                self._var_beta_raw, self._nobs, self.df)
-
     @cache_readonly
     def _r2_raw(self):
         Y = self._y_trans_raw
@@ -356,8 +344,9 @@ class PanelOLS(OLS):
     @cache_readonly
     def _r2_adj_raw(self):
         """Returns the raw r-squared adjusted values."""
-        factor = ((self._nobs - 1) / (self._nobs - self._df_raw))
-        return 1 - (1 - self._r2_raw) * factor
+        nobs = self._nobs
+        factors = (nobs - 1) / (nobs - self._df_raw)
+        return 1 - (1 - self._r2_raw) * factors
 
     @cache_readonly
     def _resid_raw(self):
@@ -387,13 +376,13 @@ class PanelOLS(OLS):
             cluster_axis = 1
 
         if self._time_effects:
-            xx = math.xx_time_effects(self._x, self._y)
+            xx = _xx_time_effects(self._x, self._y)
         else:
             xx = np.dot(self._x.values.T, self._x.values)
 
-        return math.var_beta_panel(self._y, self._x, self._beta_raw, xx,
-                                   self._rmse_raw, cluster_axis, self._nw_lags,
-                                   self.nobs, self._df_raw, self._nw_overlap)
+        return _var_beta_panel(self._y, self._x, self._beta_raw, xx,
+                              self._rmse_raw, cluster_axis, self._nw_lags,
+                              self._nobs, self._df_raw, self._nw_overlap)
 
     @cache_readonly
     def _y_fitted_raw(self):
@@ -452,7 +441,7 @@ class PanelOLS(OLS):
         r = np.array(r).reshape(q, 1)
 
         result = math.calc_F(R, r, self._beta_raw, self._var_beta_raw,
-                             self.nobs, self.df)
+                             self._nobs, self.df)
 
         return common.f_stat_to_dict(result)
 
@@ -477,6 +466,10 @@ class PanelOLS(OLS):
     def _time_has_obs(self):
         return self._time_obs_count > 0
 
+    @property
+    def _nobs(self):
+        return len(self._y_trans_raw)
+
 def _convertDummies(dummies, mapping):
     # cleans up the names of the generated dummies
     new_items = []
@@ -517,7 +510,7 @@ def add_intercept(panel, name='intercept'):
 
     return panel
 
-class MovingPanelOLS(PanelOLS, MovingOLS):
+class MovingPanelOLS(MovingOLS, PanelOLS):
     """Implements rolling/expanding panel OLS.
 
     Parameters
@@ -583,111 +576,26 @@ class MovingPanelOLS(PanelOLS, MovingOLS):
         self._min_periods = window if min_periods is None else min_periods
 
     @cache_readonly
-    def beta(self):
-        return DataMatrix(self._beta_raw,
-                          index=self._result_index,
-                          columns=self._x.items)
-
-    def _calc_betas(self):
-        N = len(self._index)
-        K = len(self._x.items)
-
-        betas = np.empty((N, K), dtype=float)
-        betas[:] = np.NaN
-
-        valid = self._time_has_obs
-        enough = self._enough_obs
-        window_obs = self._window_time_obs
-
-        # Use transformed (demeaned) Y, X variables
-        cum_xx = self._cum_xx(self._x_trans)
-        cum_xy = self._cum_xy(self._x_trans, self._y_trans)
-
-        for i in xrange(N):
-            # XXX
-            if not valid[i] or not enough[i]:
-                continue
-
-            xx = cum_xx[i]
-            xy = cum_xy[i]
-            obs = window_obs[i]
-            if self._is_rolling and i >= obs:
-                xx = xx - cum_xx[i - obs]
-                xy = xy - cum_xy[i - obs]
-
-            betas[i] = math.solve(xx, xy).squeeze()
-
-        have_betas = np.arange(N)[-np.isnan(betas).any(axis=1)]
-
-        return betas, have_betas
-
-    def _cum_xx(self, x):
-        dates = x.index.major_axis
-        K = len(x.items)
-        valid = self._time_has_obs
-        cum_xx = []
-
-        last = np.zeros((K, K))
-        for i, date in enumerate(dates):
-            if not valid[i]:
-                cum_xx.append(last)
-                continue
-
-            x_slice = x.getValueSlice(date, date)
-            xx = last = last + np.dot(x_slice.T, x_slice)
-            cum_xx.append(xx)
-
-        return cum_xx
-
-    def _cum_xy(self, x, y):
-        dates = x.index.major_axis
-        valid = self._time_has_obs
-        cum_xy = []
-
-        last = np.zeros((len(x.items), 1))
-        for i, date in enumerate(dates):
-            if not valid[i]:
-                cum_xy.append(last)
-                continue
-
-            x_slice = x.getValueSlice(date, date)
-            y_slice = y.getValueSlice(date, date)
-
-            xy = last = last + np.dot(x_slice.T, y_slice)
-            cum_xy.append(xy)
-
-        return cum_xy
+    def resid(self):
+        return self._unstack_y(self._resid_raw)
 
     @cache_readonly
-    def _rolling_rank(self):
-        dates = self._x.index.major_axis
-
-        N = len(dates)
-        ranks = np.empty(N, dtype=float)
-        ranks[:] = np.NaN
-
-        enough = self._enough_obs
-        time_periods = self._window_time_obs
-
-        for i in xrange(N):
-            if not enough[i]:
-                continue
-
-            if self._is_rolling:
-                prior_date = dates[i - time_periods[i] + 1]
-            else:
-                prior_date = dates[0]
+    def y_fitted(self):
+        return self._unstack_y(self._y_fitted_raw)
 
-            date = dates[i]
-            x_slice = self._x.getValueSlice(prior_date, date)
-            ranks[i] = math.rank(x_slice)
+    @cache_readonly
+    def y_predict(self):
+        """Returns the predicted y values."""
+        return self._unstack_y(self._y_predict_raw)
 
-        return ranks
+    @cache_readonly
+    def _rolling_ols_call(self):
+        return self._calc_betas(self._x_trans, self._y_trans)
 
     @cache_readonly
     def _df_raw(self):
         """Returns the degrees of freedom."""
-        df = self._rolling_rank
+        df = self._rolling_rank()
 
         if self._time_effects:
             df += self._window_time_obs
@@ -707,115 +615,65 @@ class MovingPanelOLS(PanelOLS, MovingOLS):
         elif self._cluster == common.ENTITY:
             cluster_axis = 1
 
-        time_periods = self._window_time_obs
         nobs = self._nobs
         rmse = self._rmse_raw
         beta = self._beta_raw
         df = self._df_raw
+        window = self._window
 
         if not self._time_effects:
             # Non-transformed X
-
             cum_xx = self._cum_xx(self._x)
 
         results = []
         for n, i in enumerate(self._valid_indices):
-            obs = time_periods[i]
-
-            if self._is_rolling:
-                prior_date = dates[i - obs + 1]
+            if self._is_rolling and i >= window:
+                prior_date = dates[i - window + 1]
             else:
                 prior_date = dates[0]
 
             date = dates[i]
 
-            x_slice = x.getSlice(prior_date, date)
-            y_slice = y.getSlice(prior_date, date)
+            x_slice = x.truncate(prior_date, date)
+            y_slice = y.truncate(prior_date, date)
 
             if self._time_effects:
-                xx = math.xx_time_effects(x_slice, y_slice)
+                xx = _xx_time_effects(x_slice, y_slice)
             else:
                 xx = cum_xx[i]
-                if self._is_rolling and i >= obs:
-                    xx = xx - cum_xx[i - time_periods[i]]
+                if self._is_rolling and i >= window:
+                    xx = xx - cum_xx[i - window]
 
-            result = math.var_beta_panel(y_slice, x_slice, beta[n], xx, rmse[n],
-                                         cluster_axis, self._nw_lags,
-                                         nobs[n], df[n],
-                                         self._nw_overlap)
+            result = _var_beta_panel(y_slice, x_slice, beta[n], xx, rmse[n],
+                                    cluster_axis, self._nw_lags,
+                                    nobs[n], df[n], self._nw_overlap)
 
             results.append(result)
 
         return np.array(results)
 
-    def f_test(self, hypothesis):
-        raise Exception('f_test not supported for rolling/expanding OLS')
-
-    @cache_readonly
-    def _f_stat_raw(self):
-        """Returns the raw f-stat value."""
-        items = self._x.items
-        nobs = self._nobs
-        df = self._df_raw
-        df_resid = nobs - df
-
-        # var_beta has not been newey-west adjusted
-        if self._nw_lags is None:
-            F = self._r2_raw / (self._r2_raw - self._r2_adj_raw)
-
-            q = len(items)
-            if 'intercept' in items:
-                q -= 1
-
-            def get_result_simple(Fst, d):
-                return Fst, (q, d), 1 - stats.f.cdf(Fst, q, d)
-
-            # Compute the P-value for each pair
-            result = starmap(get_result_simple, izip(F, df_resid))
-
-            return list(result)
-
-        K = len(items)
-        R = np.eye(K)
-        r = np.zeros((K, 1))
-
-        intercept = items.indexMap.get('intercept')
-
-        if intercept is not None:
-            R = np.concatenate((R[0 : intercept], R[intercept + 1:]))
-            r = np.concatenate((r[0 : intercept], r[intercept + 1:]))
-
-        def get_result(beta, vcov, n, d):
-            return math.calc_F(R, r, beta, vcov, n, d)
-
-        results = starmap(get_result,
-                          izip(self._beta_raw, self._var_beta_raw, nobs, df))
-
-        return list(results)
-
     @cache_readonly
     def _resid_stats(self):
         Y = self._y_trans
         Y_orig = self._y
         X = self._x_trans
         dates = self._index
-        time_periods = self._window_time_obs
+        window = self._window
 
         sst = []
         sse = []
 
-        for n, index in enumerate(self._valid_indices):
-
-            if self._is_rolling:
-                prior_date = dates[index - time_periods[index] + 1]
+        for n, i in enumerate(self._valid_indices):
+            if self._is_rolling and i >= window:
+                prior_date = dates[i - window + 1]
             else:
                 prior_date = dates[0]
 
-            date = dates[index]
+            date = dates[i]
 
-            X_slice = X.getValueSlice(prior_date, date)
-            Y_slice = Y.getValueSlice(prior_date, date).squeeze()
-            Y_orig_slice = Y_orig.getValueSlice(prior_date, date).squeeze()
+            X_slice = X.truncate(prior_date, date).values
+            Y_slice = Y.truncate(prior_date, date).values.squeeze()
+            Y_orig_slice = Y_orig.truncate(prior_date, date).values.squeeze()
 
             beta_slice = self._beta_raw[n]
 
@@ -835,24 +693,6 @@ class MovingPanelOLS(PanelOLS, MovingOLS):
             'sst' : sst,
         }
 
-    @cache_readonly
-    def _rmse_raw(self):
-        """Returns the raw rmse values."""
-        return np.sqrt(self._resid_stats['sse'] / self._df_resid_raw)
-
-    @cache_readonly
-    def _r2_raw(self):
-        rs = self._resid_stats
-        return 1 - rs['sse'] / rs['sst']
-
-    @cache_readonly
-    def _r2_adj_raw(self):
-        """Returns the raw r-squared adjusted values."""
-        nobs = self._nobs
-        factors = (nobs - 1) / (nobs - self._df_raw)
-        return 1 - (1 - self._r2_raw) * factors
-
-
     @cache_readonly
     def _resid_raw(self):
         beta_matrix = self._beta_matrix(lag=0)
@@ -876,19 +716,6 @@ class MovingPanelOLS(PanelOLS, MovingOLS):
         betas = self._beta_matrix(lag=1)
         return (betas * x).sum(1)
 
-    @cache_readonly
-    def resid(self):
-        return self._unstack_y(self._resid_raw)
-
-    @cache_readonly
-    def y_fitted(self):
-        return self._unstack_y(self._y_fitted_raw)
-
-    @cache_readonly
-    def y_predict(self):
-        """Returns the predicted y values."""
-        return self._unstack_y(self._y_predict_raw)
-
     def _beta_matrix(self, lag=0):
         assert(lag >= 0)
 
@@ -896,34 +723,10 @@ class MovingPanelOLS(PanelOLS, MovingOLS):
         indexer = self._valid_indices.searchsorted(labels, side='left')
 
         beta_matrix = self._beta_raw[indexer]
-        beta_matrix[labels < 0] = np.NaN
+        beta_matrix[labels < self._valid_indices[0]] = np.NaN
 
         return beta_matrix
 
-    @cache_readonly
-    def _nobs_raw(self):
-        if self._window_type == common.EXPANDING:
-            window = len(self._index)
-        else:
-            window = self._window
-
-        result = tseries.rolling_sum(self._time_obs_count, window,
-                                     minp=1)
-
-        return result.astype(int)
-
-    @cache_readonly
-    def _nobs(self):
-        return self._nobs_raw[self._valid_indices]
-
-    @cache_readonly
-    def _window_time_obs(self):
-        window_obs = tseries.rolling_sum(self._time_obs_count > 0,
-                                         self._window, minp=1)
-
-        window_obs[np.isnan(window_obs)] = 0
-        return window_obs.astype(int)
-
     @cache_readonly
     def _enough_obs(self):
         # XXX: what's the best way to determine where to start?
@@ -984,7 +787,8 @@ class NonPooledPanelOLS(object):
     ]
 
     def __init__(self, y, x, window_type=common.FULL_SAMPLE, window=None,
-                 intercept=True, nw_lags=None, nw_overlap=False):
+                 min_periods=None, intercept=True, nw_lags=None,
+                 nw_overlap=False):
 
         for attr in self.ATTRIBUTES:
             setattr(self.__class__, attr, create_ols_attr(attr))
@@ -1003,8 +807,67 @@ class NonPooledPanelOLS(object):
                                   x=entity_x,
                                   window_type=window_type,
                                   window=window,
+                                  min_periods=min_periods,
                                   intercept=intercept,
                                   nw_lags=nw_lags,
                                   nw_overlap=nw_overlap)
 
         self.results = results
+
+
+def _var_beta_panel(y, x, beta, xx, rmse, cluster_axis,
+                   nw_lags, nobs, df, nw_overlap):
+
+    from pandas.core.panel import LongPanel, group_agg
+
+    xx_inv = math.inv(xx)
+
+    if cluster_axis is None:
+        if nw_lags is None:
+            return xx_inv * (rmse ** 2)
+        else:
+            resid = y.values.squeeze() - np.dot(x.values, beta)
+            m = (x.values.T * resid).T
+
+            xeps = math.newey_west(m, nw_lags, nobs, df, nw_overlap)
+
+            return np.dot(xx_inv, np.dot(xeps, xx_inv))
+    else:
+        Xb = np.dot(x.values, beta).reshape((len(x.values), 1))
+        resid = LongPanel(y.values - Xb, ['resid'], y.index)
+
+        if cluster_axis == 1:
+            x = x.swapaxes()
+            resid = resid.swapaxes()
+
+        m = group_agg(x.values * resid.values, x.index._bounds,
+                      lambda x: np.sum(x, axis=0))
+
+        if nw_lags is None:
+            nw_lags = 0
+
+        xox = 0
+        for i in range(len(x.major_axis)):
+            xox += math.newey_west(m[i : i + 1], nw_lags,
+                                   nobs, df, nw_overlap)
+
+        return np.dot(xx_inv, np.dot(xox, xx_inv))
+
+def _xx_time_effects(x, y):
+    """
+    Returns X'X - (X'T) (T'T)^-1 (T'X)
+    """
+    # X'X
+    xx = np.dot(x.values.T, x.values)
+    xt = x.sum().values
+
+    count = y.count()
+    selector = count > 0
+
+    # X'X - (T'T)^-1 (T'X)
+    xt = xt[selector]
+    count = count[selector]
+
+    return xx - np.dot(xt.T / count, xt)
+
+
diff --git a/pandas/stats/tests/test_ols.py b/pandas/stats/tests/test_ols.py
index 5a8b8bdb6..aa2949c98 100644
--- a/pandas/stats/tests/test_ols.py
+++ b/pandas/stats/tests/test_ols.py
@@ -28,8 +28,8 @@ def _check_repr(obj):
 class TestOLS(BaseTest):
 
     FIELDS = ['beta', 'df', 'df_model', 'df_resid', 'f_stat', 'p_value',
-              'r2', 'r2_adj', 'resid', 'rmse', 'std_err', 't_stat',
-              'var_beta', 'y_fitted']
+              'r2', 'r2_adj', 'rmse', 'std_err', 't_stat',
+              'var_beta']
 
     # TODO: Add tests for OLS y predict
     # TODO: Right now we just check for consistency between full-sample and
@@ -84,54 +84,58 @@ class TestOLS(BaseTest):
         _check_non_raw_results(result)
 
     def checkMovingOLS(self, window_type, x, y, **kwds):
-        window = tools.rank(x.values) + 2
+        window = tools.rank(x.values) * 2
 
-        moving = ols(y=y, x=x, window_type=window_type, window=window,
-                     **kwds)
+        moving = ols(y=y, x=x, window_type=window_type,
+                     window=window, **kwds)
 
         if isinstance(moving.y, Series):
             index = moving.y.index
         elif isinstance(moving.y, LongPanel):
             index = moving.y.major_axis
 
-        time = len(index)
-
-        reference_last_only = ['resid', 'y_fitted']
-
-        for i in xrange(time - window + 1):
-            if window_type == ROLLING:
-                start = index[i]
+        for n, i in enumerate(moving._valid_indices):
+            if window_type == ROLLING and i >= window:
+                prior_date = index[i - window + 1]
             else:
-                start = index[0]
+                prior_date = index[0]
 
-            end = index[i + window - 1]
+            date = index[i]
 
-            x2 = {}
+            x_iter = {}
             for k, v in x.iteritems():
-                x2[k] = v.truncate(start, end)
-            y2 = y.truncate(start, end)
-
-            static = ols(y=y2, x=x2, **kwds)
+                x_iter[k] = v.truncate(before=prior_date, after=date)
+            y_iter = y.truncate(before=prior_date, after=date)
 
-            self.compare(static, moving, reference_last_only, i)
+            static = ols(y=y_iter, x=x_iter, **kwds)
 
-            # y-predict (just non-null check)
-            self.assertTrue(np.isfinite(moving._y_predict_raw).all())
+            self.compare(static, moving, event_index=i,
+                         result_index=n)
 
         _check_non_raw_results(moving)
 
-    def compare(self, reference, result, reference_last_only=None,
+    def compare(self, static, moving, event_index=None,
                 result_index=None):
-        for field in self.FIELDS:
-            attr = '_%s_raw' % field
 
-            ref = getattr(reference, attr)
+        # Check resid if we have a time index specified
+        if event_index is not None:
+            ref = static._resid_raw[-1]
+            res = moving._resid_raw[event_index]
+
+            assert_almost_equal(ref, res)
+
+            ref = static._y_fitted_raw[-1]
+            res = moving._y_fitted_raw[event_index]
 
-            if (reference_last_only is not None
-                and field in reference_last_only):
-                ref = ref[-1]
+            assert_almost_equal(ref, res)
 
-            res = getattr(result, attr)
+        # Check y_fitted
+
+        for field in self.FIELDS:
+            attr = '_%s_raw' % field
+
+            ref = getattr(static, attr)
+            res = getattr(moving, attr)
 
             if result_index is not None:
                 res = res[result_index]
@@ -314,51 +318,51 @@ class TestPanelOLS(BaseTest):
         weights = self.panel_y.copy()
 
         weights.values = np.random.standard_normal(weights.values.shape)
-        self.checkRollingOLS(self.panel_x,
+        self.checkMovingOLS(self.panel_x,
                             self.panel_y, weights=weights)
 
     def testRolling(self):
-        self.checkRollingOLS(self.panel_x, self.panel_y)
+        self.checkMovingOLS(self.panel_x, self.panel_y)
 
     def testRollingWithFixedEffects(self):
-        self.checkRollingOLS(self.panel_x, self.panel_y,
+        self.checkMovingOLS(self.panel_x, self.panel_y,
                             entity_effects=True)
 
     def testRollingWithTimeEffects(self):
-        self.checkRollingOLS(self.panel_x, self.panel_y,
+        self.checkMovingOLS(self.panel_x, self.panel_y,
                             time_effects=True)
 
     def testRollingWithNeweyWest(self):
-        self.checkRollingOLS(self.panel_x, self.panel_y,
+        self.checkMovingOLS(self.panel_x, self.panel_y,
                             nw_lags=1)
 
     def testRollingWithEntityCluster(self):
-        self.checkRollingOLS(self.panel_x, self.panel_y,
+        self.checkMovingOLS(self.panel_x, self.panel_y,
                             cluster=ENTITY)
 
     def testRollingWithTimeEffectsAndEntityCluster(self):
-        self.checkRollingOLS(self.panel_x, self.panel_y,
+        self.checkMovingOLS(self.panel_x, self.panel_y,
                             time_effects=True, cluster=ENTITY)
 
     def testRollingWithTimeCluster(self):
-        self.checkRollingOLS(self.panel_x, self.panel_y,
+        self.checkMovingOLS(self.panel_x, self.panel_y,
                             cluster=TIME)
 
     def testRollingWithNeweyWestAndEntityCluster(self):
-        self.checkRollingOLS(self.panel_x, self.panel_y,
+        self.checkMovingOLS(self.panel_x, self.panel_y,
                             nw_lags=1, cluster=ENTITY)
 
     def testRollingWithNeweyWestAndTimeEffectsAndEntityCluster(self):
-        self.checkRollingOLS(self.panel_x, self.panel_y,
+        self.checkMovingOLS(self.panel_x, self.panel_y,
                             nw_lags=1, cluster=ENTITY, time_effects=True)
 
     def testExpanding(self):
-        self.checkRollingOLS(self.panel_x, self.panel_y, window_type=EXPANDING)
+        self.checkMovingOLS(self.panel_x, self.panel_y, window_type=EXPANDING)
 
     def testNonPooled(self):
         self.checkNonPooled(y=self.panel_y, x=self.panel_x)
         self.checkNonPooled(y=self.panel_y, x=self.panel_x,
-                                    window_type=ROLLING, window=25)
+                            window_type=ROLLING, window=25, min_periods=10)
 
     def checkNonPooled(self, x, y, **kwds):
         # For now, just check that it doesn't crash
@@ -368,7 +372,7 @@ class TestPanelOLS(BaseTest):
         for attr in NonPooledPanelOLS.ATTRIBUTES:
             _check_repr(getattr(result, attr))
 
-    def checkRollingOLS(self, x, y, window_type=ROLLING, **kwds):
+    def checkMovingOLS(self, x, y, window_type=ROLLING, **kwds):
         window = 25  # must be larger than rank of x
 
         moving = ols(y=y, x=x, window_type=window_type,
@@ -379,11 +383,9 @@ class TestPanelOLS(BaseTest):
         elif isinstance(moving.y, LongPanel):
             index = moving.y.major_axis
 
-        time_periods = moving._window_time_obs
-
         for n, i in enumerate(moving._valid_indices):
-            if window_type == ROLLING:
-                prior_date = index[i - time_periods[i] + 1]
+            if window_type == ROLLING and i >= window:
+                prior_date = index[i - window + 1]
             else:
                 prior_date = index[0]
 
diff --git a/pandas/stats/tests/test_ols_filter.py b/pandas/stats/tests/test_ols_filter.py
index 80ef83bbf..737113dce 100644
--- a/pandas/stats/tests/test_ols_filter.py
+++ b/pandas/stats/tests/test_ols_filter.py
@@ -2,6 +2,7 @@ from datetime import datetime
 import unittest
 
 from numpy import NaN
+import numpy as np
 
 from pandas.core.datetools import bday
 from pandas.core.api import DateRange, Series, DataFrame
@@ -33,28 +34,32 @@ class TestOLSFilter(unittest.TestCase):
         self.DICT1 = data
 
     def testFilterWithSeriesRHS(self):
-        lhs, rhs, rhs_pre = _filter_data(self.TS1, {'x1' : self.TS2})
+        (lhs, rhs, rhs_pre,
+        index, valid) = _filter_data(self.TS1, {'x1' : self.TS2})
         self.tsAssertEqual(self.TS1, lhs)
         self.tsAssertEqual(self.TS2[:3], rhs['x1'])
         self.tsAssertEqual(self.TS2, rhs_pre['x1'])
 
     def testFilterWithSeriesRHS2(self):
-        lhs, rhs, rhs_pre = _filter_data(self.TS2, {'x1' : self.TS1})
+        (lhs, rhs, rhs_pre,
+        index, valid) = _filter_data(self.TS2, {'x1' : self.TS1})
         self.tsAssertEqual(self.TS2[:3], lhs)
         self.tsAssertEqual(self.TS1, rhs['x1'])
         self.tsAssertEqual(self.TS1, rhs_pre['x1'])
 
     def testFilterWithSeriesRHS3(self):
-        lhs, rhs, rhs_pre = _filter_data(self.TS3, {'x1' : self.TS4})
-        exp_lhs = self.TS3[2]
-        exp_rhs = self.TS4[2]
+        (lhs, rhs, rhs_pre,
+        index, valid) = _filter_data(self.TS3, {'x1' : self.TS4})
+        exp_lhs = self.TS3[2:3]
+        exp_rhs = self.TS4[2:3]
         exp_rhs_pre = self.TS4[1:]
         self.tsAssertEqual(exp_lhs, lhs)
         self.tsAssertEqual(exp_rhs, rhs['x1'])
         self.tsAssertEqual(exp_rhs_pre, rhs_pre['x1'])
 
     def testFilterWithDataFrameRHS(self):
-        lhs, rhs, _ = _filter_data(self.TS1, self.DF1)
+        (lhs, rhs, rhs_pre,
+        index, valid) = _filter_data(self.TS1, self.DF1)
         exp_lhs = self.TS1[1:]
         exp_rhs1 = self.TS2[1:3]
         exp_rhs2 = self.TS4[1:3]
@@ -63,7 +68,8 @@ class TestOLSFilter(unittest.TestCase):
         self.tsAssertEqual(exp_rhs2, rhs['x2'])
 
     def testFilterWithDictRHS(self):
-        lhs, rhs, _ = _filter_data(self.TS1, self.DICT1)
+        (lhs, rhs, rhs_pre,
+        index, valid) = _filter_data(self.TS1, self.DICT1)
         exp_lhs = self.TS1[1:]
         exp_rhs1 = self.TS2[1:3]
         exp_rhs2 = self.TS4[1:3]
