commit b63ac552bdb32c52b1a6ca3bb0aaff35be2b99c0
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Apr 22 18:54:46 2012 -0400

    REF: split time series resampling into resample.py, other miscellaneous refactoring

diff --git a/pandas/__init__.py b/pandas/__init__.py
index 44838894c..a4281a7d2 100644
--- a/pandas/__init__.py
+++ b/pandas/__init__.py
@@ -22,6 +22,7 @@ from pandas.info import __doc__
 from pandas.core.api import *
 from pandas.sparse.api import *
 from pandas.stats.api import *
+from pandas.tseries.api import *
 
 from pandas.core.format import (set_printoptions, reset_printoptions,
                                 set_eng_float_format)
diff --git a/pandas/core/api.py b/pandas/core/api.py
index 895a1a79a..41721c483 100644
--- a/pandas/core/api.py
+++ b/pandas/core/api.py
@@ -11,7 +11,7 @@ from pandas.core.index import Index, Int64Index, MultiIndex
 from pandas.core.series import Series, TimeSeries
 from pandas.core.frame import DataFrame
 from pandas.core.panel import Panel
-from pandas.core.groupby import groupby, TimeGrouper
+from pandas.core.groupby import groupby
 from pandas.core.reshape import pivot_simple as pivot
 
 WidePanel = Panel
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index d3e6bccff..1682a43f7 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -137,8 +137,8 @@ class PandasObject(Picklable):
         return groupby(self, by, axis=axis, level=level, as_index=as_index,
                        sort=sort, group_keys=group_keys)
 
-    def convert(self, rule, method='pad', how='last', axis=0, as_index=True,
-                closed='right', label='right', as_period=False):
+    def convert(self, rule, method='pad', how='mean', axis=0, as_index=True,
+                closed='right', label='right', kind=None):
         """
         Convenience method for frequency conversion and resampling of regular
         time-series data.
@@ -146,7 +146,7 @@ class PandasObject(Picklable):
         Parameters
         ----------
         rule : the offset string or object representing target conversion
-        how : string, method for down- or re-sampling, default 'last'
+        how : string, method for down- or re-sampling, default 'mean'
         method : string, method for upsampling, default 'pad'
         axis : int, optional, default 0
         closed : {'right', 'left'}, default 'right'
@@ -155,35 +155,23 @@ class PandasObject(Picklable):
             Which bin edge label to label bucket with
         as_index : see synonymous argument of groupby
         """
-        from pandas.core.groupby import TimeGrouper, translate_grouping
-
-        if isinstance(rule, basestring):
-            rule = datetools.to_offset(rule)
+        from pandas.tseries.resample import TimeGrouper
 
         idx = self._get_axis(axis)
         if not isinstance(idx, DatetimeIndex):
             raise ValueError("Cannot call convert with non-DatetimeIndex")
 
-        if not isinstance(rule, datetools.DateOffset):
-            raise ValueError("Rule not a recognized offset")
-
-        interval = TimeGrouper(rule, label=label,
-                               closed=closed, obj=self)
-
-        currfreq = len(idx)
-        targfreq = len(interval.binner) - 2 # since binner extends endpoints
+        grouper = TimeGrouper(rule, label=label, closed=closed,
+                              axis=self.index, kind=kind)
 
-        if targfreq <= currfreq:
+        # since binner extends endpoints
+        if len(grouper.binner) - 2 <= len(idx):
             # down- or re-sampling
-            grouped  = self.groupby(interval, axis=axis, as_index=as_index)
-
-            if isinstance(how, basestring):
-                how = translate_grouping(how)
-
+            grouped  = self.groupby(grouper, axis=axis, as_index=as_index)
             result = grouped.agg(how)
         else:
             # upsampling
-            result = self.reindex(interval.binner[1:-1].view('M8[us]'),
+            result = self.reindex(grouper.binner[1:-1].view('M8[us]'),
                                   method=method)
 
         result.index.offset = rule
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 916db55a0..e450c6d4e 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -8,11 +8,9 @@ from pandas.core.index import Index, MultiIndex
 from pandas.core.internals import BlockManager, make_block
 from pandas.core.series import Series
 from pandas.core.panel import Panel
-from pandas.tseries.index import DatetimeIndex
 from pandas.util.decorators import cache_readonly, Appender
 import pandas.core.algorithms as algos
 import pandas.core.common as com
-import pandas.core.datetools as dt
 import pandas._tseries as lib
 
 
@@ -351,6 +349,11 @@ class GroupBy(object):
         """
         return self._cython_agg_general('ohlc')
 
+    def last(self):
+        def picker(arr):
+            return arr[-1] if arr is not None and len(arr) else np.nan
+        return self.agg(picker)
+
     def _cython_agg_general(self, how):
         output = {}
         for name, obj in self._iterate_slices():
@@ -728,6 +731,7 @@ class Grouper(object):
         result = lib.maybe_convert_objects(result, try_float=0)
         return result, counts
 
+
 def generate_bins_generic(values, binner, closed, label):
     """
     Generate bin edge offsets and bin labels for one array using another array
@@ -804,28 +808,6 @@ def generate_bins_generic(values, binner, closed, label):
     return bins, labels
 
 
-def _generate_time_binner(dtindex, offset,
-                          begin=None, end=None, nperiods=None):
-
-    if isinstance(offset, basestring):
-        offset = dt.to_offset(offset)
-
-    if begin is None:
-        first = lib.Timestamp(dtindex[0] - offset)
-    else:
-        first = lib.Timestamp(offset.rollback(begin))
-
-    if end is None:
-        last = lib.Timestamp(dtindex[-1] + offset)
-    else:
-        last = lib.Timestamp(offset.rollforward(end))
-
-    if isinstance(offset, dt.Tick):
-        return np.arange(first.value, last.value+1, offset.us_stride(),
-                         dtype=np.int64)
-
-    return DatetimeIndex(freq=offset, start=first, end=last, periods=nperiods)
-
 
 class BinGrouper(Grouper):
 
@@ -912,95 +894,6 @@ class BinGrouper(Grouper):
 
         return result, names
 
-
-
-class TimeGrouper(BinGrouper):
-    """
-    Custom groupby class for time-interval grouping
-
-    Parameters
-    ----------
-    interval : pandas offset string or object for identifying bin edges
-    closed : closed end of interval; left (default) or right
-    label : interval boundary to use for labeling; left (default) or right
-    begin : optional, timestamp-like
-    end : optional, timestamp-like
-    nperiods : optional, integer
-
-    Notes
-    -----
-    Use begin, end, nperiods to generate intervals that cannot be derived
-    directly from the associated object
-    """
-
-    obj = None
-    bins = None
-    binlabels = None
-    begin = None
-    end = None
-    nperiods = None
-    binner = None
-
-    def __init__(self, interval='Min', closed='left', label='left',
-                 begin=None, end=None, nperiods=None, obj=None):
-        self.offset = interval
-        self.closed = closed
-        self.label = label
-        self.begin = begin
-        self.end = end
-        self.nperiods = None
-
-        if obj is not None:
-            self.set_obj(obj)
-
-    def set_obj(self, obj):
-        """
-        Injects the object we'll act on, which we use to initialize grouper
-        """
-        if id(self.obj) == id(obj):
-            return
-
-        self.obj = obj
-
-        if not isinstance(obj.index, DatetimeIndex):
-            raise ValueError("Cannot apply TimeGrouper to non-DatetimeIndex")
-
-        index = obj.index
-
-        if len(obj.index) < 1:
-            self.bins = []
-            self.binlabels = []
-            return
-
-        self.binner = _generate_time_binner(obj.index, self.offset, self.begin,
-                                            self.end, self.nperiods)
-
-        if isinstance(self.binner, DatetimeIndex):
-            self.binner = self.binner.asi8
-
-        # general version, knowing nothing about relative frequencies
-        bins, labels = lib.generate_bins_dt64(index.asi8, self.binner,
-                                              self.closed, self.label)
-
-        self.bins = bins
-        self.binlabels = labels.view('M8[us]')
-
-    @property
-    def names(self):
-        return [self.obj.index.name]
-
-    @property
-    def levels(self):
-        return [self.binlabels]
-
-    @cache_readonly
-    def ngroups(self):
-        return len(self.binlabels)
-
-    @cache_readonly
-    def result_index(self):
-        return self.binlabels
-
     def agg_series(self, obj, func):
         dummy = obj[:0]
         grouper = lib.SeriesBinGrouper(obj, func, self.bins, dummy)
@@ -1147,7 +1040,7 @@ def _get_grouper(obj, key=None, axis=0, level=None, sort=True):
                 key = group_axis
 
     if isinstance(key, Grouper):
-        key.set_obj(obj)
+        key.set_axis(group_axis)
         return key, []
 
     if not isinstance(key, (tuple, list)):
@@ -1970,8 +1863,7 @@ def _compress_group_index(group_index, sort=True):
     obs_group_ids = np.array(uniques, dtype='i8')
 
     if sort and len(obs_group_ids) > 0:
-        obs_group_ids, comp_ids = _reorder_by_uniques(obs_group_ids,
-                                                      comp_ids)
+        obs_group_ids, comp_ids = _reorder_by_uniques(obs_group_ids, comp_ids)
 
     return comp_ids, obs_group_ids
 
@@ -1997,15 +1889,16 @@ def _reorder_by_uniques(uniques, labels):
 import __builtin__
 
 _func_table = {
-    __builtin__.sum : np.sum
+    __builtin__.sum: np.sum
 }
 
 _cython_table = {
-    __builtin__.sum : 'sum',
-    np.sum : 'sum',
-    np.mean : 'mean',
-    np.std : 'std',
-    np.var : 'var'
+    __builtin__.sum: 'sum',
+    np.sum: 'sum',
+    np.mean: 'mean',
+    np.prod: 'prod',
+    np.std: 'std',
+    np.var: 'var'
 }
 
 def _intercept_function(func):
@@ -2032,14 +1925,6 @@ def numpy_groupby(data, labels, axis=0):
 #-----------------------------------------------------------------------
 # Helper functions
 
-def translate_grouping(how):
-    if how in 'last':
-        def picker(arr):
-            return arr[-1] if arr is not None and len(arr) else np.nan
-        return picker
-
-    return how
-
 
 from pandas.util import py3compat
 import sys
diff --git a/pandas/src/period.c b/pandas/src/period.c
index c4d1fbb90..c28e96d4d 100644
--- a/pandas/src/period.c
+++ b/pandas/src/period.c
@@ -966,9 +966,10 @@ long asfreq(long period_ordinal, int freq1, int freq2, char relation)
 
     long val = (*func)(period_ordinal, relation, &finfo);
 
-    if (val == INT_ERR_CODE)
+    if (val == INT_ERR_CODE) {
         Py_Error(PyExc_ValueError, "Unable to convert to desired frequency.");
-
+		goto onError;
+	}
     return val;
 onError:
     return INT_ERR_CODE;
diff --git a/pandas/tseries/api.py b/pandas/tseries/api.py
new file mode 100644
index 000000000..34b6ac688
--- /dev/null
+++ b/pandas/tseries/api.py
@@ -0,0 +1,8 @@
+"""
+
+"""
+
+
+from pandas.tseries.index import DatetimeIndex, date_range, bdate_range
+from pandas.tseries.period import PeriodIndex, period_range
+from pandas.tseries.resample import TimeGrouper
diff --git a/pandas/tseries/period.py b/pandas/tseries/period.py
index 05657b47c..39ae790f3 100644
--- a/pandas/tseries/period.py
+++ b/pandas/tseries/period.py
@@ -854,3 +854,22 @@ def _validate_end_alias(how):
         raise ValueError('How must be one of S or E')
     return how
 
+def period_range(start=None, end=None, periods=None, freq='D'):
+    """
+    Return a fixed frequency datetime index, with day (calendar) as the default
+    frequency
+
+
+    Parameters
+    ----------
+    start :
+    end :
+    normalize : bool, default False
+        Normalize start/end dates to midnight before generating date range
+
+    Returns
+    -------
+
+    """
+    return PeriodIndex(start=start, end=end, periods=periods,
+                       freq=freq)
diff --git a/pandas/tseries/resample.py b/pandas/tseries/resample.py
new file mode 100644
index 000000000..348be998d
--- /dev/null
+++ b/pandas/tseries/resample.py
@@ -0,0 +1,154 @@
+import numpy as np
+
+from pandas.core.groupby import BinGrouper
+from pandas.tseries.frequencies import to_offset
+from pandas.tseries.index import DatetimeIndex
+from pandas.tseries.offsets import DateOffset, Tick
+from pandas.tseries.period import PeriodIndex
+from pandas.util.decorators import cache_readonly
+import pandas.core.common as com
+
+from pandas._tseries import Timestamp
+import pandas._tseries as lib
+
+class TimeGrouper(BinGrouper):
+    """
+    Custom groupby class for time-interval grouping
+
+    Parameters
+    ----------
+    rule : pandas offset string or object for identifying bin edges
+    closed : closed end of interval; left (default) or right
+    label : interval boundary to use for labeling; left (default) or right
+    begin : optional, timestamp-like
+    end : optional, timestamp-like
+    nperiods : optional, integer
+
+    Notes
+    -----
+    Use begin, end, nperiods to generate intervals that cannot be derived
+    directly from the associated object
+    """
+
+    axis = None
+    bins = None
+    binlabels = None
+    begin = None
+    end = None
+    nperiods = None
+    binner = None
+
+    def __init__(self, offset='Min', closed='left', label='left',
+                 begin=None, end=None, nperiods=None, axis=None,
+                 kind=None):
+        if isinstance(offset, basestring):
+            offset = to_offset(offset)
+
+        if not isinstance(offset, DateOffset):
+            raise ValueError("Rule not a recognized offset")
+
+        self.offset = offset
+        self.closed = closed
+        self.label = label
+        self.begin = begin
+        self.end = end
+        self.nperiods = None
+
+        if axis is not None:
+            self.set_axis(axis)
+
+    def set_axis(self, axis):
+        """
+        Injects the axisect we'll act on, which we use to initialize grouper
+        """
+        if id(self.axis) == id(axis):
+            return
+
+        self.axis = axis
+
+        if len(self.axis) < 1:
+            self.bins = []
+            self.binlabels = []
+            return
+
+        if isinstance(self.axis, DatetimeIndex):
+            self.binner = _generate_time_binner(self.axis, self.offset,
+                                                self.begin, self.end,
+                                                self.nperiods)
+
+            int_axis = self.axis.asi8
+            int_binner = com._ensure_int64(self.binner)
+
+            # general version, knowing nothing about relative frequencies
+            bins, labels = lib.generate_bins_dt64(int_axis, int_binner,
+                                                  self.closed, self.label)
+
+            self.bins = bins
+            self.binlabels = labels.view('M8[us]')
+        elif isinstance(self.axis, PeriodIndex):
+            pass
+        else:
+            raise ValueError('Invalid index: %s' % type(self.axis))
+
+
+    @property
+    def names(self):
+        return [self.axis.name]
+
+    @property
+    def levels(self):
+        return [self.binlabels]
+
+    @cache_readonly
+    def ngroups(self):
+        return len(self.binlabels)
+
+    @cache_readonly
+    def result_index(self):
+        return self.binlabels
+
+
+def _generate_time_binner(dtindex, offset, begin=None, end=None, nperiods=None):
+    if isinstance(offset, basestring):
+        offset = to_offset(offset)
+
+    if begin is None:
+        first = Timestamp(dtindex[0] - offset)
+    else:
+        first = Timestamp(offset.rollback(begin))
+
+    if end is None:
+        last = Timestamp(dtindex[-1] + offset)
+    else:
+        last = Timestamp(offset.rollforward(end))
+
+    if isinstance(offset, Tick):
+        return np.arange(first.value, last.value+1, offset.us_stride(),
+                         dtype=np.int64)
+
+    result = DatetimeIndex(freq=offset, start=first, end=last,
+                           periods=nperiods)
+    return result.asi8
+
+
+def _generate_period_binner(dtindex, offset, begin=None, end=None,
+                            nperiods=None):
+    if isinstance(offset, basestring):
+        offset = to_offset(offset)
+
+    if begin is None:
+        first = Timestamp(dtindex[0] - offset)
+    else:
+        first = Timestamp(offset.rollback(begin))
+
+    if end is None:
+        last = Timestamp(dtindex[-1] + offset)
+    else:
+        last = Timestamp(offset.rollforward(end))
+
+    if isinstance(offset, Tick):
+        return np.arange(first.value, last.value+1, offset.us_stride(),
+                         dtype=np.int64)
+
+    return DatetimeIndex(freq=offset, start=first, end=last, periods=nperiods)
+
diff --git a/pandas/tseries/tests/test_resample.py b/pandas/tseries/tests/test_resample.py
new file mode 100644
index 000000000..85928c4e0
--- /dev/null
+++ b/pandas/tseries/tests/test_resample.py
@@ -0,0 +1,162 @@
+from datetime import datetime
+
+import numpy as np
+
+from pandas import Series, DataFrame
+
+from pandas.tseries.offsets import Minute
+from pandas.tseries.resample import DatetimeIndex, TimeGrouper
+
+import unittest
+import nose
+
+from pandas.util.testing import assert_series_equal, assert_almost_equal
+
+class TestResample(unittest.TestCase):
+
+    def setUp(self):
+        dti = DatetimeIndex(start=datetime(2005,1,1),
+                            end=datetime(2005,1,10), freq='Min')
+
+        self.series = Series(np.random.rand(len(dti)), dti)
+
+    def test_custom_grouper(self):
+
+        dti = DatetimeIndex(freq='Min', start=datetime(2005,1,1),
+                            end=datetime(2005,1,10))
+
+        data = np.array([1]*len(dti))
+        s = Series(data, index=dti)
+
+        b = TimeGrouper(Minute(5))
+        g = s.groupby(b)
+
+        self.assertEquals(g.ngroups, 2593)
+
+        # construct expected val
+        arr = [5] * 2592
+        arr.append(1)
+        idx = dti[0:-1:5]
+        idx = idx.append(DatetimeIndex([np.datetime64(dti[-1])]))
+        expect = Series(arr, index=idx)
+
+        # cython returns float for now
+        result = g.agg(np.sum)
+        assert_series_equal(result, expect.astype(float))
+
+        data = np.random.rand(len(dti), 10)
+        df = DataFrame(data, index=dti)
+        r = df.groupby(b).agg(np.sum)
+
+        self.assertEquals(len(r.columns), 10)
+        self.assertEquals(len(r.index), 2593)
+
+    def test_convert_basic(self):
+        s = self.series
+
+        result = s.convert('5Min', how='last')
+
+        grouper = TimeGrouper(Minute(5), closed='right', label='right')
+        expect = s.groupby(grouper).agg(lambda x: x[-1])
+
+        assert_series_equal(result, expect)
+
+        # from daily
+        dti = DatetimeIndex(start=datetime(2005,1,1), end=datetime(2005,1,10),
+                            freq='D')
+
+        s = Series(np.random.rand(len(dti)), dti)
+
+        # to weekly
+        result = s.convert('w-sun', how='last')
+
+        self.assertEquals(len(result), 3)
+        self.assert_((result.index.dayofweek == [6,6,6]).all())
+        self.assertEquals(result.irow(0), s['1/2/2005'])
+        self.assertEquals(result.irow(1), s['1/9/2005'])
+        self.assertEquals(result.irow(2), s.irow(-1))
+
+        result = s.convert('W-MON', how='last')
+        self.assertEquals(len(result), 2)
+        self.assert_((result.index.dayofweek == [0,0]).all())
+        self.assertEquals(result.irow(0), s['1/3/2005'])
+        self.assertEquals(result.irow(1), s['1/10/2005'])
+
+        result = s.convert('W-TUE', how='last')
+        self.assertEquals(len(result), 2)
+        self.assert_((result.index.dayofweek == [1,1]).all())
+        self.assertEquals(result.irow(0), s['1/4/2005'])
+        self.assertEquals(result.irow(1), s['1/10/2005'])
+
+        result = s.convert('W-WED', how='last')
+        self.assertEquals(len(result), 2)
+        self.assert_((result.index.dayofweek == [2,2]).all())
+        self.assertEquals(result.irow(0), s['1/5/2005'])
+        self.assertEquals(result.irow(1), s['1/10/2005'])
+
+        result = s.convert('W-THU', how='last')
+        self.assertEquals(len(result), 2)
+        self.assert_((result.index.dayofweek == [3,3]).all())
+        self.assertEquals(result.irow(0), s['1/6/2005'])
+        self.assertEquals(result.irow(1), s['1/10/2005'])
+
+        result = s.convert('W-FRI', how='last')
+        self.assertEquals(len(result), 2)
+        self.assert_((result.index.dayofweek == [4,4]).all())
+        self.assertEquals(result.irow(0), s['1/7/2005'])
+        self.assertEquals(result.irow(1), s['1/10/2005'])
+
+        # to biz day
+        result = s.convert('B', how='last')
+        self.assertEquals(len(result), 6)
+        self.assert_((result.index.dayofweek == [0,1,2,3,4,0]).all())
+        self.assertEquals(result.irow(0), s['1/3/2005'])
+        self.assertEquals(result.irow(1), s['1/4/2005'])
+        self.assertEquals(result.irow(5), s['1/10/2005'])
+
+    def test_convert_upsample(self):
+        # from daily
+        dti = DatetimeIndex(start=datetime(2005,1,1), end=datetime(2005,1,10),
+                            freq='D')
+
+        s = Series(np.random.rand(len(dti)), dti)
+
+        # to minutely, by padding
+        result = s.convert('Min', method='pad')
+        self.assertEquals(len(result), 12961)
+        self.assertEquals(result[0], s[0])
+        self.assertEquals(result[-1], s[-1])
+
+    def test_convert_ohlc(self):
+        s = self.series
+
+        grouper = TimeGrouper(Minute(5), closed='right', label='right')
+        expect = s.groupby(grouper).agg(lambda x: x[-1])
+        result = s.convert('5Min', how='ohlc')
+
+        self.assertEquals(len(result), len(expect))
+        self.assertEquals(len(result.columns), 4)
+
+        xs = result.irow(-1)
+        self.assertEquals(xs['open'], s[-5])
+        self.assertEquals(xs['high'], s[-5:].max())
+        self.assertEquals(xs['low'], s[-5:].min())
+        self.assertEquals(xs['close'], s[-1])
+
+        xs = result.irow(1)
+        self.assertEquals(xs['open'], s[1])
+        self.assertEquals(xs['high'], s[1:6].max())
+        self.assertEquals(xs['low'], s[1:6].min())
+        self.assertEquals(xs['close'], s[5])
+
+    def test_convert_reconvert(self):
+        dti = DatetimeIndex(start=datetime(2005,1,1), end=datetime(2005,1,10),
+                            freq='D')
+        s = Series(np.random.rand(len(dti)), dti)
+        s = s.convert('B').convert('8H')
+        self.assertEquals(len(s), 22)
+
+if __name__ == '__main__':
+    nose.runmodule(argv=[__file__,'-vvs','-x','--pdb', '--pdb-failure'],
+                   exit=False)
+
diff --git a/pandas/tseries/tests/test_timeseries.py b/pandas/tseries/tests/test_timeseries.py
index 6429459a3..12adcfb19 100644
--- a/pandas/tseries/tests/test_timeseries.py
+++ b/pandas/tseries/tests/test_timeseries.py
@@ -25,8 +25,8 @@ import cPickle as pickle
 import pandas.core.datetools as dt
 from numpy.random import rand
 from pandas.util.testing import assert_frame_equal
-from pandas.core.groupby import TimeGrouper
-from pandas.core.datetools import Minute, BDay
+from pandas.tseries.resample import TimeGrouper
+from pandas.core.datetools import BDay
 import pandas.core.common as com
 
 NaT = lib.NaT
@@ -773,142 +773,6 @@ class TestDatetime64(unittest.TestCase):
         s['1/2/2009':'2009-06-05'] = -3
         self.assert_((s[48:54] == -3).all())
 
-    def test_custom_grouper(self):
-
-        dti = DatetimeIndex(freq='Min', start=datetime(2005,1,1),
-                            end=datetime(2005,1,10))
-
-        data = np.array([1]*len(dti))
-        s = Series(data, index=dti)
-
-        b = TimeGrouper(Minute(5))
-        g = s.groupby(b)
-
-        self.assertEquals(g.ngroups, 2593)
-
-        # construct expected val
-        arr = [5] * 2592
-        arr.append(1)
-        idx = dti[0:-1:5]
-        idx = idx.append(DatetimeIndex([np.datetime64(dti[-1])]))
-        expect = Series(arr, index=idx)
-
-        # cython returns float for now
-        result = g.agg(np.sum)
-        assert_series_equal(result, expect.astype(float))
-
-        data = np.random.rand(len(dti), 10)
-        df = DataFrame(data, index=dti)
-        r = df.groupby(b).agg(np.sum)
-
-        self.assertEquals(len(r.columns), 10)
-        self.assertEquals(len(r.index), 2593)
-
-    def test_convert_basic(self):
-        s = self.series
-
-        result = s.convert('5Min')
-
-        grouper = TimeGrouper(Minute(5), closed='right', label='right')
-        expect = s.groupby(grouper).agg(lambda x: x[-1])
-
-        assert_series_equal(result, expect)
-
-        # from daily
-        dti = DatetimeIndex(start=datetime(2005,1,1), end=datetime(2005,1,10),
-                            freq='D')
-
-        s = Series(rand(len(dti)), dti)
-
-        # to weekly
-        result = s.convert('w-sun')
-
-        self.assertEquals(len(result), 3)
-        self.assert_((result.index.dayofweek == [6,6,6]).all())
-        self.assertEquals(result.irow(0), s['1/2/2005'])
-        self.assertEquals(result.irow(1), s['1/9/2005'])
-        self.assertEquals(result.irow(2), s.irow(-1))
-
-        result = s.convert('W-MON')
-        self.assertEquals(len(result), 2)
-        self.assert_((result.index.dayofweek == [0,0]).all())
-        self.assertEquals(result.irow(0), s['1/3/2005'])
-        self.assertEquals(result.irow(1), s['1/10/2005'])
-
-        result = s.convert('W-TUE')
-        self.assertEquals(len(result), 2)
-        self.assert_((result.index.dayofweek == [1,1]).all())
-        self.assertEquals(result.irow(0), s['1/4/2005'])
-        self.assertEquals(result.irow(1), s['1/10/2005'])
-
-        result = s.convert('W-WED')
-        self.assertEquals(len(result), 2)
-        self.assert_((result.index.dayofweek == [2,2]).all())
-        self.assertEquals(result.irow(0), s['1/5/2005'])
-        self.assertEquals(result.irow(1), s['1/10/2005'])
-
-        result = s.convert('W-THU')
-        self.assertEquals(len(result), 2)
-        self.assert_((result.index.dayofweek == [3,3]).all())
-        self.assertEquals(result.irow(0), s['1/6/2005'])
-        self.assertEquals(result.irow(1), s['1/10/2005'])
-
-        result = s.convert('W-FRI')
-        self.assertEquals(len(result), 2)
-        self.assert_((result.index.dayofweek == [4,4]).all())
-        self.assertEquals(result.irow(0), s['1/7/2005'])
-        self.assertEquals(result.irow(1), s['1/10/2005'])
-
-        # to biz day
-        result = s.convert('B')
-        self.assertEquals(len(result), 6)
-        self.assert_((result.index.dayofweek == [0,1,2,3,4,0]).all())
-        self.assertEquals(result.irow(0), s['1/3/2005'])
-        self.assertEquals(result.irow(1), s['1/4/2005'])
-        self.assertEquals(result.irow(5), s['1/10/2005'])
-
-    def test_convert_upsample(self):
-        # from daily
-        dti = DatetimeIndex(start=datetime(2005,1,1), end=datetime(2005,1,10),
-                            freq='D')
-
-        s = Series(rand(len(dti)), dti)
-
-        # to minutely, by padding
-        result = s.convert('Min', method='pad')
-        self.assertEquals(len(result), 12961)
-        self.assertEquals(result[0], s[0])
-        self.assertEquals(result[-1], s[-1])
-
-    def test_convert_ohlc(self):
-        s = self.series
-
-        grouper = TimeGrouper(Minute(5), closed='right', label='right')
-        expect = s.groupby(grouper).agg(lambda x: x[-1])
-        result = s.convert('5Min', how='ohlc')
-
-        self.assertEquals(len(result), len(expect))
-        self.assertEquals(len(result.columns), 4)
-
-        xs = result.irow(-1)
-        self.assertEquals(xs['open'], s[-5])
-        self.assertEquals(xs['high'], s[-5:].max())
-        self.assertEquals(xs['low'], s[-5:].min())
-        self.assertEquals(xs['close'], s[-1])
-
-        xs = result.irow(1)
-        self.assertEquals(xs['open'], s[1])
-        self.assertEquals(xs['high'], s[1:6].max())
-        self.assertEquals(xs['low'], s[1:6].min())
-        self.assertEquals(xs['close'], s[5])
-
-    def test_convert_reconvert(self):
-        dti = DatetimeIndex(start=datetime(2005,1,1), end=datetime(2005,1,10),
-                            freq='D')
-        s = Series(rand(len(dti)), dti)
-        s = s.convert('B').convert('8H')
-        self.assertEquals(len(s), 22)
-
     def test_tz_localize(self):
         _skip_if_no_pytz()
         from pandas.core.datetools import Hour
