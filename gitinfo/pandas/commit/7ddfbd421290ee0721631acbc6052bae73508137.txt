commit 7ddfbd421290ee0721631acbc6052bae73508137
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Fri Jul 22 12:01:51 2011 -0400

    ENH: got multi-groupby working in Cython. Lot more work needed

diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index bbb58e813..de350a88d 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -7,23 +7,6 @@ from pandas.core.series import Series
 from pandas.core.panel import WidePanel
 import pandas._tseries as _tseries
 
-class GroupDict(dict):
-    def __repr__(self):
-        stringDict = dict([(str(x), x) for x in self])
-        sortedKeys = sorted(stringDict)
-
-        maxLen = max([len(x) for x in stringDict])
-
-        output = StringIO()
-        output.write(str(self.__class__))
-
-        for k in sortedKeys:
-            key = stringDict[k]
-            size = len(self[key])
-            output.write('\n %s -> %d values' % (str(k).ljust(maxLen), size))
-
-        return output.getvalue()
-
 def groupby(obj, grouper, **kwds):
     """
     Intercepts creation and dispatches to the appropriate class based
@@ -51,8 +34,7 @@ class Grouping(object):
     @property
     def groups(self):
         if self._groups is None:
-            self._groups = _tseries.groupby(self.labels, self.grouper,
-                                            output=GroupDict())
+            self._groups = _tseries.groupby(self.labels, self.grouper)
         return self._groups
 
 class GroupBy(object):
@@ -71,9 +53,11 @@ class GroupBy(object):
         self._group_axis = np.asarray(obj._get_axis(axis))
         self._group_axis_name = obj._get_axis_name(axis)
         self.groupings = [Grouping(self._group_axis, grouper)]
+        self.primary = self.groupings[0]
 
-    def getGroup(self, indices):
-        group_labels = self._group_axis.take(indices)
+    def getGroup(self, name):
+        inds = self.primary.indices[name]
+        group_labels = self._group_axis.take(inds)
         return self.obj.reindex(**{self._group_axis_name : group_labels})
 
     def __iter__(self):
@@ -85,7 +69,7 @@ class GroupBy(object):
         Generator yielding sequence of (groupName, subsetted object)
         for each group
         """
-        groups = self.grouping.indices.keys()
+        groups = self.primary.indices.keys()
         try:
             groupNames = sorted(groups)
         except Exception: # pragma: no cover
@@ -94,6 +78,9 @@ class GroupBy(object):
         for name in groups:
             yield name, self[name]
 
+    def __getitem__(self, key):
+        return self.getGroup(self.primary.indices[key])
+
     def aggregate(self, func):
         raise NotImplementedError
 
@@ -102,8 +89,8 @@ class GroupBy(object):
 
     def _aggregate_generic(self, agger, axis=0):
         result = {}
-        for name, inds in self.grouping.indices.iteritems():
-            data = self.getGroup(inds)
+        for name  in self.primary.indices.iteritems():
+            data = self.getGroup(name)
             try:
                 result[name] = agger(data)
             except Exception:
@@ -127,9 +114,6 @@ class GroupBy(object):
         # TODO: make NaN-friendly
         return self.aggregate(np.sum)
 
-    def __getitem__(self, key):
-        return self.getGroup(self.grouping.indices[key])
-
 def multi_groupby(obj, op, *columns):
     cur = columns[0]
     grouped = obj.groupby(cur)
@@ -189,14 +173,14 @@ class SeriesGroupBy(GroupBy):
     def _aggregate_simple(self, applyfunc):
         values = self.obj.values
         result = {}
-        for k, v in self.grouping.indices.iteritems():
+        for k, v in self.primary.indices.iteritems():
             result[k] = applyfunc(values.take(v))
 
         return result
 
     def _aggregate_named(self, applyfunc):
         result = {}
-        for k, v in self.grouping.indices.iteritems():
+        for k, v in self.primary.indices.iteritems():
             grp = self[k]
             grp.groupName = k
             output = applyfunc(grp)
@@ -283,7 +267,9 @@ class DataFrameGroupBy(GroupBy):
             mappers = [obj[s] for s in grouper]
             self.groupings = [Grouping(obj.index, mapper) for mapper in mappers]
         else:
-            self.groupings = [Grouping(self._group_axis, mapper)]
+            self.groupings = [Grouping(self._group_axis, grouper)]
+
+        self.primary = self.groupings[0]
 
     def __getitem__(self, key):
         if key not in self.obj:
@@ -356,7 +342,7 @@ class DataFrameGroupBy(GroupBy):
 
         result_values = trans(result_values)
 
-        for val, group in self.groups.iteritems():
+        for val, group in self.primary.groups.iteritems():
             if not isinstance(group, list): # pragma: no cover
                 group = list(group)
 
diff --git a/pandas/src/common.pyx b/pandas/src/common.pyx
index d8a311c8a..81edb03b4 100644
--- a/pandas/src/common.pyx
+++ b/pandas/src/common.pyx
@@ -10,6 +10,7 @@ from cpython cimport PyFloat_Check
 import numpy as np
 isnan = np.isnan
 cdef double NaN = <double> np.NaN
+cdef double nan = NaN
 
 from datetime import datetime as pydatetime
 
diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index 61bff6a3f..f1c902b7f 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -18,8 +18,8 @@ def arrmap(ndarray[object, ndim=1] index, object func):
     return result
 
 @cython.boundscheck(False)
-def groupby(object index, object mapper, output=None):
-    cdef dict result
+def groupby(object index, object mapper):
+    cdef dict result = {}
     cdef ndarray[object, ndim=1] mapped_index
     cdef ndarray[object, ndim=1] index_buf
     cdef ndarray[int8_t, ndim=1] mask
@@ -29,19 +29,10 @@ def groupby(object index, object mapper, output=None):
 
     length = len(index)
 
-    if output is None:
-        result = {}
-    else:
-        result = <dict> output
-
     index_buf = np.asarray(index)
     mapped_index = arrmap(index_buf, mapper)
     mask = isnullobj(mapped_index)
 
-    # nullkeys = index_buf[mask.astype(bool)]
-    # if len(nullkeys) > 0:
-    #     result[np.NaN] = nullkeys
-
     for i from 0 <= i < length:
         if mask[i]:
             continue
@@ -100,95 +91,129 @@ def group_labels(ndarray[object] values):
             labels[i] = count
             count += 1
 
-    return count, labels
+    return ids, count, labels
 
 def labelize(*key_arrays):
+    idicts = []
     shape = []
     labels = []
-    for key_arr in key_arrays:
-        ct, lab = group_labels(key_arrays)
+    for arr in key_arrays:
+        ids, ct, lab = group_labels(arr)
         shape.append(ct)
         labels.append(lab)
+        idicts.append(ids)
 
-    return tuple(shape), labels
+    return tuple(shape), labels, idicts
 
-ctypedef double_t (* agg_func)(double_t *out, int32_t *counts,
-                               double_t *values, int32_t *labels,
-                               int start, int end)
+ctypedef double_t (* agg_func)(double_t *out, double_t *values, int32_t *labels,
+                               int start, int end, Py_ssize_t offset)
 
 cdef agg_func get_agg_func(object how):
     if how == 'add':
         return _group_add
+    elif how == 'mean':
+        return _group_mean
 
 def group_aggregate(ndarray[double_t] values, list label_list,
                     object shape, how='add'):
     cdef:
         list sorted_labels
-        ndarray result, counts
+        ndarray result
         agg_func func
 
     func = get_agg_func(how)
+
     values, sorted_labels = _group_reorder(values, label_list)
     result = np.empty(shape, dtype=np.float64)
     result.fill(nan)
-    counts = = np.zeros(shape, dtype=np.int32)
 
-    _aggregate_group(<double_t*> result.data,
-                     <double_t*> values.data,
-                     <int32_t*> counts.data
-                      sorted_labels, 0, len(values),
-                     shape, 0, func)
+    _aggregate_group(<double_t*> result.data, <double_t*> values.data,
+                     sorted_labels, 0, len(values), shape, 0, 0, func)
 
     return result, sorted_labels
 
-cdef _aggregate_group(double_t *out, int32_t *counts, double_t *values,
-                      list labels, int start, int end, tuple shape,
-                      Py_ssize_t which, agg_func func):
+cdef void _aggregate_group(double_t *out, double_t *values,
+                           list labels, int start, int end, tuple shape,
+                           Py_ssize_t which, Py_ssize_t offset,
+                           agg_func func):
     cdef:
-        ndarray[int32_t] axis0
-        int32_t label_end
+        ndarray[int32_t] axis
+        cdef Py_ssize_t stride
 
-    axis0 = labels[which][start:end]
-    label_end = shape[which]
+    axis = labels[which]
 
     # time to actually aggregate
     if which == len(labels) - 1:
-        func(out, values, axis0, start, end)
+        # print axis, start, end
+        func(out, values, <int32_t*> axis.data, start, end, offset)
     else:
-        # get group counts on axis
-        edges = axis0.searchsorted(np.arange(1, label_end + 1), side='left')
+        stride = np.prod(shape[which+1:])
+        # get group counts on axisp
+        edges = axis.searchsorted(np.arange(1, shape[which] + 1), side='left')
+        # print edges, axis
         start = 0
         # aggregate each subgroup
         for end in edges:
-            _aggregate_group(out, counts, values, sorted_labels[1:],
-                             start, end, shape, which + 1, func)
+            _aggregate_group(out, values, labels, start, end,
+                             shape, which + 1, offset, func)
+            offset += stride
             start = end
 
-cdef _group_add(double_t *out, int32_t *counts, double_t *values,
-                int32_t *labels, int start, int end, int rng):
+cdef double_t _group_add(double_t *out, double_t *values, int32_t *labels,
+                         int start, int end, Py_ssize_t offset):
     cdef:
-        Py_ssize_t i, it = start
+        Py_ssize_t i = 0, it = start
         int32_t lab
         int32_t count = 0
         double_t val, cum = 0
 
-    for i in range(rng):
-        while it < end:
-            if labels[it] > i:
-                counts[i] = count
-                out[i] = cum
-                break
+    while it < end:
+        val = values[it]
+        # not nan
+        if val == val:
+            count += 1
+            cum += val
+
+        if it == end - 1 or labels[it + 1] > i:
+            if count == 0:
+                out[offset + i] = nan
+            else:
+                out[offset + i] = cum
+            count = 0
+            cum = 0
+
+            i += 1
+
+        it += 1
+
+cdef double_t _group_mean(double_t *out, double_t *values, int32_t *labels,
+                          int start, int end, Py_ssize_t offset):
+    cdef:
+        Py_ssize_t i = 0, it = start
+        int32_t lab
+        int32_t count = 0
+        double_t val, cum = 0
+
+    while it < end:
+        val = values[it]
+        # not nan
+        if val == val:
+            count += 1
+            cum += val
+
+        if it == end - 1 or labels[it + 1] > i:
+            if count == 0:
+                out[offset + i] = nan
+            else:
+                out[offset + i] = cum / count
+            count = 0
+            cum = 0
 
-            val = values[it]
-            # not nan
-            if val == val:
-                count += 1
-                cum += val
+            i += 1
 
-        count = 0
-        cum = 0
+        it += 1
 
-def _group_reorder(values, label_list)
+def _group_reorder(values, label_list):
     indexer = np.lexsort(label_list[::-1])
     sorted_labels = [labels.take(indexer) for labels in label_list]
     sorted_values = values.take(indexer)
@@ -198,7 +223,7 @@ def _result_shape(label_list):
     # assumed sorted
     shape = []
     for labels in label_list:
-        size.append(1 + labels[-1])
+        shape.append(1 + labels[-1])
     return tuple(shape)
 
 def reduce_mean(ndarray[object, ndim=1] indices,
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index dbbd2f6e6..8ef48c309 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -1792,103 +1792,6 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
 
         result = self.frame.applymap(type)
 
-    def test_groupby(self):
-        grouped = self.tsframe.groupby(lambda x: x.weekday())
-
-        # aggregate
-        aggregated = grouped.aggregate(np.mean)
-        self.assertEqual(len(aggregated), 5)
-        self.assertEqual(len(aggregated.columns), 4)
-
-        # by string
-        tscopy = self.tsframe.copy()
-        tscopy['weekday'] = [x.weekday() for x in tscopy.index]
-        stragged = tscopy.groupby('weekday').aggregate(np.mean)
-        del stragged['weekday']
-        assert_frame_equal(stragged, aggregated)
-
-        # transform
-        transformed = grouped.transform(lambda x: x - x.mean())
-        self.assertEqual(len(transformed), 30)
-        self.assertEqual(len(transformed.columns), 4)
-
-        # transform propagate
-        transformed = grouped.transform(lambda x: x.mean())
-        for name, group in grouped:
-            mean = group.mean()
-            for idx in group.index:
-                assert_almost_equal(transformed.xs(idx), mean)
-
-        # iterate
-        for weekday, group in grouped:
-            self.assert_(group.index[0].weekday() == weekday)
-
-        # groups / group_indices
-        groups = grouped.groups
-        indices = grouped.group_indices
-
-        for k, v in groups.iteritems():
-            samething = self.tsframe.index.take(indices[k])
-            self.assert_(np.array_equal(v, samething))
-
-    def test_groupby_columns(self):
-        mapping = {
-            'A' : 0, 'B' : 0, 'C' : 1, 'D' : 1
-        }
-        grouped = self.tsframe.groupby(mapping, axis=1)
-
-        # aggregate
-        aggregated = grouped.aggregate(np.mean)
-        self.assertEqual(len(aggregated), len(self.tsframe))
-        self.assertEqual(len(aggregated.columns), 2)
-
-        # transform
-        tf = lambda x: x - x.mean()
-        groupedT = self.tsframe.T.groupby(mapping, axis=0)
-        assert_frame_equal(groupedT.transform(tf).T, grouped.transform(tf))
-
-        # iterate
-        for k, v in grouped:
-            self.assertEqual(len(v.columns), 2)
-
-        # tgroupby
-        grouping = {
-            'A' : 0,
-            'B' : 1,
-            'C' : 0,
-            'D' : 1
-        }
-
-        grouped = self.frame.tgroupby(grouping.get, np.mean)
-        self.assertEqual(len(grouped), len(self.frame.index))
-        self.assertEqual(len(grouped.columns), 2)
-
-    def test_groupby_multiple_columns(self):
-        from pandas.util.testing import assert_panel_equal
-        from pandas.core.panel import WidePanel
-        from collections import defaultdict
-
-        data = DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
-                                 'foo', 'bar', 'foo', 'foo'],
-                          'B' : ['one', 'one', 'two', 'three',
-                                 'two', 'two', 'one', 'three'],
-                          'C' : np.random.randn(8),
-                          'D' : np.random.randn(8)})
-
-        result1 = data.groupby('A', 'B').sum()
-        result1_col = data.groupby('A', 'B')['C'].sum()
-        expected = defaultdict(dict)
-        for n1, gp1 in data.groupby('A'):
-            for n2, gp2 in gp1.groupby('B'):
-                expected[n1][n2] = gp2.sum()
-        expected = dict((k, DataFrame(v)) for k, v in expected.iteritems())
-        expected = WidePanel.fromDict(expected)
-        assert_panel_equal(result1, expected)
-        assert_panel_equal(result1['C'], expected['C'])
-
-        # result2 = data.groupby('B', 'A').sum()
-        # assert_panel_equal(result2, expected2)
-
     def test_filter(self):
         # items
 
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 95854890f..9e31d0d62 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -5,6 +5,9 @@ from pandas.core.index import Index
 from pandas.core.common import rands, groupby
 from pandas.core.frame import DataFrame
 from pandas.core.series import Series
+from pandas.util.testing import assert_panel_equal
+from pandas.core.panel import WidePanel
+from collections import defaultdict
 import pandas.core.datetools as dt
 import numpy as np
 
@@ -51,6 +54,180 @@ class GroupByTestCase(unittest.TestCase):
     def testByColumnName(self):
         pass
 
+class TestSeriesGroupBy(unittest.TestCase):
+
+    def test_groupby(self):
+        data = Series(np.arange(9) / 3, index=np.arange(9))
+
+        index = np.arange(9)
+        np.random.shuffle(index)
+        data = data.reindex(index)
+
+        grouped = data.groupby(lambda x: x // 3)
+
+        for k, v in grouped:
+            self.assertEqual(len(v), 3)
+
+        agged = grouped.aggregate(np.mean)
+        self.assertEqual(agged[1], 1)
+
+        assert_series_equal(agged, grouped.agg(np.mean)) # shorthand
+        assert_series_equal(agged, grouped.mean())
+        assert_series_equal(grouped.agg(np.sum), grouped.sum())
+
+        transformed = grouped.transform(lambda x: x * x.sum())
+        self.assertEqual(transformed[7], 12)
+
+        value_grouped = data.groupby(data)
+        assert_series_equal(value_grouped.aggregate(np.mean), agged)
+
+        # complex agg
+        agged = grouped.aggregate([np.mean, np.std])
+        agged = grouped.aggregate({'one' : np.mean,
+                                   'two' : np.std})
+
+        group_constants = {
+            0 : 10,
+            1 : 20,
+            2 : 30
+        }
+        agged = grouped.agg(lambda x: group_constants[x.groupName] + x.mean())
+        self.assertEqual(agged[1], 21)
+
+        # corner cases
+        self.assertRaises(Exception, grouped._aggregate_named,
+                          lambda x: x * 2)
+
+    def test_groupby_transform(self):
+        data = Series(np.arange(9) / 3, index=np.arange(9))
+
+        index = np.arange(9)
+        np.random.shuffle(index)
+        data = data.reindex(index)
+
+        grouped = data.groupby(lambda x: x // 3)
+
+        transformed = grouped.transform(lambda x: x * x.sum())
+        self.assertEqual(transformed[7], 12)
+
+        transformed = grouped.transform(np.mean)
+        for name, group in grouped:
+            mean = group.mean()
+            for idx in group.index:
+                self.assertEqual(transformed[idx], mean)
+
+    def test_groupby_with_na(self):
+        index = Index(np.arange(10))
+        values = Series(np.ones(10), index)
+        labels = Series([nan, 'foo', 'bar', 'bar', nan, nan, 'bar',
+                         'bar', nan, 'foo'], index=index)
+
+        grouped = values.groupby(labels)
+        agged = grouped.agg(len)
+        expected = Series([4, 2], index=['bar', 'foo'])
+        assert_series_equal(agged, expected)
+
+class TestDataFrameGroupBy(unittest.TestCase):
+
+    def setUp(self):
+        self.seriesd = tm.getSeriesData()
+        self.tsd = tm.getTimeSeriesData()
+        self.frame = self.klass(self.seriesd)
+        self.tsframe = self.klass(self.tsd)
+
+    def test_groupby(self):
+        grouped = self.tsframe.groupby(lambda x: x.weekday())
+
+        # aggregate
+        aggregated = grouped.aggregate(np.mean)
+        self.assertEqual(len(aggregated), 5)
+        self.assertEqual(len(aggregated.columns), 4)
+
+        # by string
+        tscopy = self.tsframe.copy()
+        tscopy['weekday'] = [x.weekday() for x in tscopy.index]
+        stragged = tscopy.groupby('weekday').aggregate(np.mean)
+        del stragged['weekday']
+        assert_frame_equal(stragged, aggregated)
+
+        # transform
+        transformed = grouped.transform(lambda x: x - x.mean())
+        self.assertEqual(len(transformed), 30)
+        self.assertEqual(len(transformed.columns), 4)
+
+        # transform propagate
+        transformed = grouped.transform(lambda x: x.mean())
+        for name, group in grouped:
+            mean = group.mean()
+            for idx in group.index:
+                assert_almost_equal(transformed.xs(idx), mean)
+
+        # iterate
+        for weekday, group in grouped:
+            self.assert_(group.index[0].weekday() == weekday)
+
+        # groups / group_indices
+        groups = grouped.groups
+        indices = grouped.group_indices
+
+        for k, v in groups.iteritems():
+            samething = self.tsframe.index.take(indices[k])
+            self.assert_(np.array_equal(v, samething))
+
+    def test_groupby_columns(self):
+        mapping = {
+            'A' : 0, 'B' : 0, 'C' : 1, 'D' : 1
+        }
+        grouped = self.tsframe.groupby(mapping, axis=1)
+
+        # aggregate
+        aggregated = grouped.aggregate(np.mean)
+        self.assertEqual(len(aggregated), len(self.tsframe))
+        self.assertEqual(len(aggregated.columns), 2)
+
+        # transform
+        tf = lambda x: x - x.mean()
+        groupedT = self.tsframe.T.groupby(mapping, axis=0)
+        assert_frame_equal(groupedT.transform(tf).T, grouped.transform(tf))
+
+        # iterate
+        for k, v in grouped:
+            self.assertEqual(len(v.columns), 2)
+
+        # tgroupby
+        grouping = {
+            'A' : 0,
+            'B' : 1,
+            'C' : 0,
+            'D' : 1
+        }
+
+        grouped = self.frame.tgroupby(grouping.get, np.mean)
+        self.assertEqual(len(grouped), len(self.frame.index))
+        self.assertEqual(len(grouped.columns), 2)
+
+    def test_groupby_multiple_columns(self):
+        data = DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
+                                 'foo', 'bar', 'foo', 'foo'],
+                          'B' : ['one', 'one', 'two', 'three',
+                                 'two', 'two', 'one', 'three'],
+                          'C' : np.random.randn(8),
+                          'D' : np.random.randn(8)})
+
+        result1 = data.groupby('A', 'B').sum()
+        result1_col = data.groupby('A', 'B')['C'].sum()
+        expected = defaultdict(dict)
+        for n1, gp1 in data.groupby('A'):
+            for n2, gp2 in gp1.groupby('B'):
+                expected[n1][n2] = gp2.sum()
+        expected = dict((k, DataFrame(v)) for k, v in expected.iteritems())
+        expected = WidePanel.fromDict(expected)
+        assert_panel_equal(result1, expected)
+        assert_panel_equal(result1['C'], expected['C'])
+
+        # result2 = data.groupby('B', 'A').sum()
+        # assert_panel_equal(result2, expected2)
+
 class TestAggregate(unittest.TestCase):
     setUp = commonSetUp
 
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index 470667350..2825f8126 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -1034,81 +1034,6 @@ class TestSeries(unittest.TestCase):
 #-------------------------------------------------------------------------------
 # GroupBy
 
-    def test_groupby(self):
-        data = Series(np.arange(9) / 3, index=np.arange(9))
-
-        index = np.arange(9)
-        np.random.shuffle(index)
-        data = data.reindex(index)
-
-        grouped = data.groupby(lambda x: x // 3)
-
-        repr(grouped.groups) # nothing else here
-
-        for k, v in grouped:
-            self.assertEqual(len(v), 3)
-
-        agged = grouped.aggregate(np.mean)
-        self.assertEqual(agged[1], 1)
-
-        assert_series_equal(agged, grouped.agg(np.mean)) # shorthand
-        assert_series_equal(agged, grouped.mean())
-
-        assert_series_equal(grouped.agg(np.sum), grouped.sum())
-
-
-        transformed = grouped.transform(lambda x: x * x.sum())
-        self.assertEqual(transformed[7], 12)
-
-        value_grouped = data.groupby(data)
-        assert_series_equal(value_grouped.aggregate(np.mean), agged)
-
-        # complex agg
-        agged = grouped.aggregate([np.mean, np.std])
-        agged = grouped.aggregate({'one' : np.mean,
-                                   'two' : np.std})
-
-        group_constants = {
-            0 : 10,
-            1 : 20,
-            2 : 30
-        }
-        agged = grouped.agg(lambda x: group_constants[x.groupName] + x.mean())
-        self.assertEqual(agged[1], 21)
-
-        # corner cases
-        self.assertRaises(Exception, grouped._aggregate_named,
-                          lambda x: x * 2)
-
-    def test_groupby_transform(self):
-        data = Series(np.arange(9) / 3, index=np.arange(9))
-
-        index = np.arange(9)
-        np.random.shuffle(index)
-        data = data.reindex(index)
-
-        grouped = data.groupby(lambda x: x // 3)
-
-        transformed = grouped.transform(lambda x: x * x.sum())
-        self.assertEqual(transformed[7], 12)
-
-        transformed = grouped.transform(np.mean)
-        for name, group in grouped:
-            mean = group.mean()
-            for idx in group.index:
-                self.assertEqual(transformed[idx], mean)
-
-    def test_groupby_with_na(self):
-        index = Index(np.arange(10))
-        values = Series(np.ones(10), index)
-        labels = Series([nan, 'foo', 'bar', 'bar', nan, nan, 'bar',
-                         'bar', nan, 'foo'], index=index)
-
-        grouped = values.groupby(labels)
-        agged = grouped.agg(len)
-        expected = Series([4, 2], index=['bar', 'foo'])
-        assert_series_equal(agged, expected)
-
     def test_select(self):
         n = len(self.ts)
         result = self.ts.select(lambda x: x >= self.ts.index[n // 2])
