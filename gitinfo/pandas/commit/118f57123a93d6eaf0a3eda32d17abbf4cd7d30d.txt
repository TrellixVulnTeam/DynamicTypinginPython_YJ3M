commit 118f57123a93d6eaf0a3eda32d17abbf4cd7d30d
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Wed Sep 28 23:20:51 2011 -0400

    ENH: major Cython code cleanup, left_join_indexer bugfix and speed opt, inner_join_indexer speed opt

diff --git a/pandas/core/index.py b/pandas/core/index.py
index 4fe8c89d8..ff7771970 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -624,16 +624,16 @@ class Int64Index(Index):
         if how == 'left':
             join_index = self
             lidx = None
-            ridx = lib.left_join_indexer(self, other)
+            ridx = lib.left_join_indexer_int64(self, other)
         elif how == 'right':
             join_index = other
-            lidx = lib.left_join_indexer(other, self)
+            lidx = lib.left_join_indexer_int64(other, self)
             ridx = None
         elif how == 'inner':
-            join_index, lidx, ridx = lib.inner_join_indexer(self, other)
+            join_index, lidx, ridx = lib.inner_join_indexer_int64(self, other)
             join_index = Int64Index(join_index)
         elif how == 'outer':
-            join_index, lidx, ridx = lib.outer_join_indexer(self, other)
+            join_index, lidx, ridx = lib.outer_join_indexer_int64(self, other)
             join_index = Int64Index(join_index)
         else:
             raise Exception('do not recognize join method %s' % how)
diff --git a/pandas/src/common.pyx b/pandas/src/common.pyx
deleted file mode 100644
index 0d8a3db9d..000000000
--- a/pandas/src/common.pyx
+++ /dev/null
@@ -1,168 +0,0 @@
-cimport numpy as np
-cimport cython
-
-from numpy cimport *
-
-from cpython cimport (PyDict_New, PyDict_GetItem, PyDict_SetItem,
-                          PyDict_Contains, PyDict_Keys)
-from cpython cimport PyFloat_Check
-
-import numpy as np
-isnan = np.isnan
-cdef double NaN = <double> np.NaN
-cdef double nan = NaN
-
-from datetime import datetime as pydatetime
-
-cdef inline int int_max(int a, int b): return a if a >= b else b
-cdef inline int int_min(int a, int b): return a if a <= b else b
-
-ctypedef unsigned char UChar
-
-cdef int is_contiguous(ndarray arr):
-    return np.PyArray_CHKFLAGS(arr, np.NPY_C_CONTIGUOUS)
-
-cdef int _contiguous_check(ndarray arr):
-    if not is_contiguous(arr):
-        raise ValueError('Tried to use data field on non-contiguous array!')
-
-cdef int16_t *get_int16_ptr(ndarray arr):
-    _contiguous_check(arr)
-
-    return <int16_t *> arr.data
-
-cdef int32_t *get_int32_ptr(ndarray arr):
-    _contiguous_check(arr)
-
-    return <int32_t *> arr.data
-
-cdef int64_t *get_int64_ptr(ndarray arr):
-    _contiguous_check(arr)
-
-    return <int64_t *> arr.data
-
-cdef double_t *get_double_ptr(ndarray arr):
-    _contiguous_check(arr)
-
-    return <double_t *> arr.data
-
-cdef extern from "math.h":
-    double sqrt(double x)
-
-cdef extern from "cobject.h":
-    pass # for datetime API
-
-cdef extern from "datetime.h":
-
-    ctypedef class datetime.datetime [object PyDateTime_DateTime]:
-        # cdef int *data
-        # cdef long hashcode
-        # cdef char hastzinfo
-        pass
-
-    int PyDateTime_GET_YEAR(datetime o)
-    int PyDateTime_GET_MONTH(datetime o)
-    int PyDateTime_GET_DAY(datetime o)
-    int PyDateTime_DATE_GET_HOUR(datetime o)
-    int PyDateTime_DATE_GET_MINUTE(datetime o)
-    int PyDateTime_DATE_GET_SECOND(datetime o)
-    int PyDateTime_DATE_GET_MICROSECOND(datetime o)
-    int PyDateTime_TIME_GET_HOUR(datetime o)
-    int PyDateTime_TIME_GET_MINUTE(datetime o)
-    int PyDateTime_TIME_GET_SECOND(datetime o)
-    int PyDateTime_TIME_GET_MICROSECOND(datetime o)
-    bint PyDateTime_Check(object o)
-    void PyDateTime_IMPORT()
-
-# import datetime C API
-PyDateTime_IMPORT
-
-# initialize numpy
-import_array()
-
-
-cpdef map_indices_list(list index):
-    '''
-    Produce a dict mapping the values of the input array to their respective
-    locations.
-
-    Example:
-        array(['hi', 'there']) --> {'hi' : 0 , 'there' : 1}
-
-    Better to do this with Cython because of the enormous speed boost.
-    '''
-    cdef Py_ssize_t i, length
-    cdef dict result = {}
-
-    length = len(index)
-
-    for i from 0 <= i < length:
-        result[index[i]] = i
-
-    return result
-
-
-from libc.stdlib cimport malloc, free
-
-cdef class MultiMap:
-    '''
-    Need to come up with a better data structure for multi-level indexing
-    '''
-
-    cdef:
-        dict store
-        Py_ssize_t depth, length
-
-    def __init__(self, list label_arrays):
-        cdef:
-            int32_t **ptr
-            Py_ssize_t i
-
-        self.depth = len(label_arrays)
-        self.length = len(label_arrays[0])
-        self.store = {}
-
-        ptr = <int32_t**> malloc(self.depth * sizeof(int32_t*))
-
-        for i in range(self.depth):
-            ptr[i] = <int32_t*> (<ndarray> label_arrays[i]).data
-
-        free(ptr)
-
-    cdef populate(self, int32_t **ptr):
-        cdef Py_ssize_t i, j
-        cdef int32_t* buf
-        cdef dict level
-
-        for i from 0 <= i < self.length:
-
-            for j from 0 <= j < self.depth - 1:
-                pass
-
-    cpdef get(self, tuple key):
-        cdef Py_ssize_t i
-        cdef dict level = self.store
-
-        for i from 0 <= i < self.depth:
-            if i == self.depth - 1:
-                return level[i]
-            else:
-                level = level[i]
-
-        raise KeyError(key)
-
-
-def isAllDates(ndarray[object, ndim=1] arr):
-    cdef int i, size = len(arr)
-    cdef object date
-
-    if size == 0:
-        return False
-
-    for i from 0 <= i < size:
-        date = arr[i]
-
-        if not PyDateTime_Check(date):
-            return False
-
-    return True
diff --git a/pandas/src/generate_code.py b/pandas/src/generate_code.py
index 88b941d49..bb4b51e81 100644
--- a/pandas/src/generate_code.py
+++ b/pandas/src/generate_code.py
@@ -351,24 +351,228 @@ def arrmap_%(name)s(ndarray[%(c_type)s] index, object func):
 
 """
 
+#----------------------------------------------------------------------
+# Joins on ordered, unique indices
+
+left_join_template = """@cython.wraparound(False)
+@cython.boundscheck(False)
+def left_join_indexer_%(name)s(ndarray[%(c_type)s] left,
+                             ndarray[%(c_type)s] right):
+    cdef:
+        Py_ssize_t i, j, nleft, nright
+        ndarray[int32_t] indexer
+        %(c_type)s lval, rval
+
+    i = 0
+    j = 0
+    nleft = len(left)
+    nright = len(right)
+
+    indexer = np.empty(nleft, dtype=np.int32)
+    for i from 0 <= i < nleft:
+        if j == nright:
+            indexer[i] = -1
+            continue
+
+        lval = left[i]
+        rval = right[j]
+
+        if lval == right[j]:
+            indexer[i] = j
+        elif lval > rval:
+            indexer[i] = -1
+            j += 1
+        else:
+            indexer[i] = -1
+
+    return indexer
+
+"""
+
+inner_join_template = """@cython.wraparound(False)
+@cython.boundscheck(False)
+def inner_join_indexer_%(name)s(ndarray[%(c_type)s] left,
+                              ndarray[%(c_type)s] right):
+    '''
+    Two-pass algorithm?
+    '''
+    cdef:
+        Py_ssize_t i, j, k, nright, nleft, count
+        %(c_type)s lval, rval
+        ndarray[int32_t] lindexer, rindexer
+        ndarray[%(c_type)s] result
+
+    nleft = len(left)
+    nright = len(right)
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft or j == nright:
+             break
+        else:
+            lval = left[i]
+            rval = right[j]
+            if lval == rval:
+                i += 1
+                j += 1
+                count += 1
+            elif lval < rval:
+                i += 1
+            else:
+                j += 1
+
+    # do it again now that result size is known
+
+    lindexer = np.empty(count, dtype=np.int32)
+    rindexer = np.empty(count, dtype=np.int32)
+    result = np.empty(count, dtype=%(dtype)s)
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft or j == nright:
+             break
+        else:
+            lval = left[i]
+            rval = right[j]
+            if lval == rval:
+                lindexer[count] = i
+                rindexer[count] = j
+                result[count] = lval
+                i += 1
+                j += 1
+                count += 1
+            elif lval < rval:
+                i += 1
+            else:
+                j += 1
+
+    return result, lindexer, rindexer
+
+"""
+
+outer_join_template = """@cython.wraparound(False)
+@cython.boundscheck(False)
+def outer_join_indexer_%(name)s(ndarray[%(c_type)s] left,
+                                ndarray[%(c_type)s] right):
+    cdef:
+        Py_ssize_t i, j, nright, nleft, count
+        %(c_type)s lval, rval
+        ndarray[int32_t] lindexer, rindexer
+        ndarray[%(c_type)s] result
+
+    nleft = len(left)
+    nright = len(right)
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft:
+            if j == nright:
+                # we are done
+                break
+            else:
+                while j < nright:
+                    j += 1
+                    count += 1
+                break
+        elif j == nright:
+            while i < nleft:
+                i += 1
+                count += 1
+            break
+        else:
+            if left[i] == right[j]:
+                i += 1
+                j += 1
+            elif left[i] < right[j]:
+                i += 1
+            else:
+                j += 1
+
+            count += 1
+
+    lindexer = np.empty(count, dtype=np.int32)
+    rindexer = np.empty(count, dtype=np.int32)
+    result = np.empty(count, dtype=%(dtype)s)
+
+    # do it again, but populate the indexers / result
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft:
+            if j == nright:
+                # we are done
+                break
+            else:
+                while j < nright:
+                    lindexer[count] = -1
+                    rindexer[count] = j
+                    result[count] = right[j]
+                    j += 1
+                    count += 1
+                break
+        elif j == nright:
+            while i < nleft:
+                lindexer[count] = i
+                rindexer[count] = -1
+                result[count] = left[i]
+                i += 1
+                count += 1
+            break
+        else:
+            lval = left[i]
+            rval = right[j]
+            if lval == rval:
+                lindexer[count] = i
+                rindexer[count] = j
+                result[count] = lval
+                i += 1
+                j += 1
+            elif lval < rval:
+                lindexer[count] = i
+                rindexer[count] = -1
+                result[count] = lval
+                i += 1
+            else:
+                lindexer[count] = -1
+                rindexer[count] = j
+                result[count] = rval
+                j += 1
+
+            count += 1
+
+    return result, lindexer, rindexer
+
+"""
+
 # name, ctype, capable of holding NA
 function_list = [
-    ('float64', 'float64_t', True),
-    ('object', 'object', True),
-    ('int32', 'int32_t', False),
-    ('int64', 'int64_t', False),
-    ('bool', 'uint8_t', False)
+    ('float64', 'float64_t', 'np.float64', True),
+    ('object', 'object', 'object', True),
+    ('int32', 'int32_t', 'np.int32', False),
+    ('int64', 'int64_t', 'np.int64', False),
+    ('bool', 'uint8_t', 'np.bool', False)
 ]
 
-def generate_from_template(template, ndim=1):
+def generate_from_template(template, ndim=1, subset=None):
     output = StringIO()
-    for name, c_type, can_hold_na in function_list:
+    for name, c_type, dtype, can_hold_na in function_list:
+        if subset is not None and name not in subset:
+            continue
+
         if ndim == 1:
             na_action = set_na if can_hold_na else raise_on_na
         elif ndim == 2:
             na_action = set_na_2d if can_hold_na else raise_on_na
         func = template % {'name' : name, 'c_type' : c_type,
-                           'na_action' : na_action}
+                           'dtype' : dtype, 'na_action' : na_action}
         output.write(func)
     return output.getvalue()
 
@@ -385,5 +589,12 @@ def generate_take_cython_file(path='generated.pyx'):
         print >> f, generate_from_template(groupby_template)
         print >> f, generate_from_template(arrmap_template)
 
+        print >> f, generate_from_template(left_join_template,
+                                           subset=['object', 'int64'])
+        print >> f, generate_from_template(outer_join_template,
+                                           subset=['object', 'int64'])
+        print >> f, generate_from_template(inner_join_template,
+                                           subset=['object', 'int64'])
+
 if __name__ == '__main__':
     generate_take_cython_file()
diff --git a/pandas/src/generated.pyx b/pandas/src/generated.pyx
index 9ce6efba8..2699e07bc 100644
--- a/pandas/src/generated.pyx
+++ b/pandas/src/generated.pyx
@@ -1403,3 +1403,390 @@ def arrmap_bool(ndarray[uint8_t] index, object func):
     return result
 
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
+def left_join_indexer_object(ndarray[object] left,
+                             ndarray[object] right):
+    cdef:
+        Py_ssize_t i, j, nleft, nright
+        ndarray[int32_t] indexer
+        object lval, rval
+
+    i = 0
+    j = 0
+    nleft = len(left)
+    nright = len(right)
+
+    indexer = np.empty(nleft, dtype=np.int32)
+    for i from 0 <= i < nleft:
+        if j == nright:
+            indexer[i] = -1
+            continue
+
+        lval = left[i]
+        rval = right[j]
+
+        if lval == right[j]:
+            indexer[i] = j
+        elif lval > rval:
+            indexer[i] = -1
+            j += 1
+        else:
+            indexer[i] = -1
+
+    return indexer
+
+@cython.wraparound(False)
+@cython.boundscheck(False)
+def left_join_indexer_int64(ndarray[int64_t] left,
+                             ndarray[int64_t] right):
+    cdef:
+        Py_ssize_t i, j, nleft, nright
+        ndarray[int32_t] indexer
+        int64_t lval, rval
+
+    i = 0
+    j = 0
+    nleft = len(left)
+    nright = len(right)
+
+    indexer = np.empty(nleft, dtype=np.int32)
+    for i from 0 <= i < nleft:
+        if j == nright:
+            indexer[i] = -1
+            continue
+
+        lval = left[i]
+        rval = right[j]
+
+        if lval == right[j]:
+            indexer[i] = j
+        elif lval > rval:
+            indexer[i] = -1
+            j += 1
+        else:
+            indexer[i] = -1
+
+    return indexer
+
+
+@cython.wraparound(False)
+@cython.boundscheck(False)
+def outer_join_indexer_object(ndarray[object] left,
+                                ndarray[object] right):
+    cdef:
+        Py_ssize_t i, j, nright, nleft, count
+        object lval, rval
+        ndarray[int32_t] lindexer, rindexer
+        ndarray[object] result
+
+    nleft = len(left)
+    nright = len(right)
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft:
+            if j == nright:
+                # we are done
+                break
+            else:
+                while j < nright:
+                    j += 1
+                    count += 1
+                break
+        elif j == nright:
+            while i < nleft:
+                i += 1
+                count += 1
+            break
+        else:
+            if left[i] == right[j]:
+                i += 1
+                j += 1
+            elif left[i] < right[j]:
+                i += 1
+            else:
+                j += 1
+
+            count += 1
+
+    lindexer = np.empty(count, dtype=np.int32)
+    rindexer = np.empty(count, dtype=np.int32)
+    result = np.empty(count, dtype=object)
+
+    # do it again, but populate the indexers / result
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft:
+            if j == nright:
+                # we are done
+                break
+            else:
+                while j < nright:
+                    lindexer[count] = -1
+                    rindexer[count] = j
+                    result[count] = right[j]
+                    j += 1
+                    count += 1
+                break
+        elif j == nright:
+            while i < nleft:
+                lindexer[count] = i
+                rindexer[count] = -1
+                result[count] = left[i]
+                i += 1
+                count += 1
+            break
+        else:
+            lval = left[i]
+            rval = right[j]
+            if lval == rval:
+                lindexer[count] = i
+                rindexer[count] = j
+                result[count] = lval
+                i += 1
+                j += 1
+            elif lval < rval:
+                lindexer[count] = i
+                rindexer[count] = -1
+                result[count] = lval
+                i += 1
+            else:
+                lindexer[count] = -1
+                rindexer[count] = j
+                result[count] = rval
+                j += 1
+
+            count += 1
+
+    return result, lindexer, rindexer
+
+@cython.wraparound(False)
+@cython.boundscheck(False)
+def outer_join_indexer_int64(ndarray[int64_t] left,
+                                ndarray[int64_t] right):
+    cdef:
+        Py_ssize_t i, j, nright, nleft, count
+        int64_t lval, rval
+        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] result
+
+    nleft = len(left)
+    nright = len(right)
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft:
+            if j == nright:
+                # we are done
+                break
+            else:
+                while j < nright:
+                    j += 1
+                    count += 1
+                break
+        elif j == nright:
+            while i < nleft:
+                i += 1
+                count += 1
+            break
+        else:
+            if left[i] == right[j]:
+                i += 1
+                j += 1
+            elif left[i] < right[j]:
+                i += 1
+            else:
+                j += 1
+
+            count += 1
+
+    lindexer = np.empty(count, dtype=np.int32)
+    rindexer = np.empty(count, dtype=np.int32)
+    result = np.empty(count, dtype=np.int64)
+
+    # do it again, but populate the indexers / result
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft:
+            if j == nright:
+                # we are done
+                break
+            else:
+                while j < nright:
+                    lindexer[count] = -1
+                    rindexer[count] = j
+                    result[count] = right[j]
+                    j += 1
+                    count += 1
+                break
+        elif j == nright:
+            while i < nleft:
+                lindexer[count] = i
+                rindexer[count] = -1
+                result[count] = left[i]
+                i += 1
+                count += 1
+            break
+        else:
+            lval = left[i]
+            rval = right[j]
+            if lval == rval:
+                lindexer[count] = i
+                rindexer[count] = j
+                result[count] = lval
+                i += 1
+                j += 1
+            elif lval < rval:
+                lindexer[count] = i
+                rindexer[count] = -1
+                result[count] = lval
+                i += 1
+            else:
+                lindexer[count] = -1
+                rindexer[count] = j
+                result[count] = rval
+                j += 1
+
+            count += 1
+
+    return result, lindexer, rindexer
+
+
+@cython.wraparound(False)
+@cython.boundscheck(False)
+def inner_join_indexer_object(ndarray[object] left,
+                              ndarray[object] right):
+    '''
+    Two-pass algorithm?
+    '''
+    cdef:
+        Py_ssize_t i, j, k, nright, nleft, count
+        object lval, rval
+        ndarray[int32_t] lindexer, rindexer
+        ndarray[object] result
+
+    nleft = len(left)
+    nright = len(right)
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft or j == nright:
+             break
+        else:
+            lval = left[i]
+            rval = right[j]
+            if lval == rval:
+                i += 1
+                j += 1
+                count += 1
+            elif lval < rval:
+                i += 1
+            else:
+                j += 1
+
+    # do it again now that result size is known
+
+    lindexer = np.empty(count, dtype=np.int32)
+    rindexer = np.empty(count, dtype=np.int32)
+    result = np.empty(count, dtype=object)
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft or j == nright:
+             break
+        else:
+            lval = left[i]
+            rval = right[j]
+            if lval == rval:
+                lindexer[count] = i
+                rindexer[count] = j
+                result[count] = lval
+                i += 1
+                j += 1
+                count += 1
+            elif lval < rval:
+                i += 1
+            else:
+                j += 1
+
+    return result, lindexer, rindexer
+
+@cython.wraparound(False)
+@cython.boundscheck(False)
+def inner_join_indexer_int64(ndarray[int64_t] left,
+                              ndarray[int64_t] right):
+    '''
+    Two-pass algorithm?
+    '''
+    cdef:
+        Py_ssize_t i, j, k, nright, nleft, count
+        int64_t lval, rval
+        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] result
+
+    nleft = len(left)
+    nright = len(right)
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft or j == nright:
+             break
+        else:
+            lval = left[i]
+            rval = right[j]
+            if lval == rval:
+                i += 1
+                j += 1
+                count += 1
+            elif lval < rval:
+                i += 1
+            else:
+                j += 1
+
+    # do it again now that result size is known
+
+    lindexer = np.empty(count, dtype=np.int32)
+    rindexer = np.empty(count, dtype=np.int32)
+    result = np.empty(count, dtype=np.int64)
+
+    i = 0
+    j = 0
+    count = 0
+    while True:
+        if i == nleft or j == nright:
+             break
+        else:
+            lval = left[i]
+            rval = right[j]
+            if lval == rval:
+                lindexer[count] = i
+                rindexer[count] = j
+                result[count] = lval
+                i += 1
+                j += 1
+                count += 1
+            elif lval < rval:
+                i += 1
+            else:
+                j += 1
+
+    return result, lindexer, rindexer
+
+
diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index ffa4ef9fa..cffac35ed 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -1,9 +1,6 @@
 #-------------------------------------------------------------------------------
 # Groupby-related functions
 
-cdef inline _isnan(object o):
-    return o != o
-
 @cython.boundscheck(False)
 def arrmap(ndarray[object] index, object func):
     cdef int length = index.shape[0]
diff --git a/pandas/src/io.pyx b/pandas/src/io.pyx
deleted file mode 100644
index e962c1e32..000000000
--- a/pandas/src/io.pyx
+++ /dev/null
@@ -1,46 +0,0 @@
-cdef int _EPOCH_ORD = 719163
-
-from datetime import date as pydate
-
-cdef inline int64_t gmtime(object date):
-    cdef int y, m, d, h, mn, s, days
-
-    y = PyDateTime_GET_YEAR(date)
-    m = PyDateTime_GET_MONTH(date)
-    d = PyDateTime_GET_DAY(date)
-    h = PyDateTime_DATE_GET_HOUR(date)
-    mn = PyDateTime_DATE_GET_MINUTE(date)
-    s = PyDateTime_DATE_GET_SECOND(date)
-
-    days = pydate(y, m, 1).toordinal() - _EPOCH_ORD + d - 1
-    return ((<int64_t> (((days * 24 + h) * 60 + mn))) * 60 + s) * 1000
-
-cpdef object to_datetime(int64_t timestamp):
-    return pydatetime.utcfromtimestamp(timestamp / 1000.0)
-
-cpdef object to_timestamp(object dt):
-    return gmtime(dt)
-
-def array_to_timestamp(ndarray[object, ndim=1] arr):
-    cdef int i, n
-    cdef ndarray[int64_t, ndim=1] result
-
-    n = len(arr)
-    result = np.empty(n, dtype=np.int64)
-
-    for i from 0 <= i < n:
-        result[i] = gmtime(arr[i])
-
-    return result
-
-def array_to_datetime(ndarray[int64_t, ndim=1] arr):
-    cdef int i, n
-    cdef ndarray[object, ndim=1] result
-
-    n = len(arr)
-    result = np.empty(n, dtype=object)
-
-    for i from 0 <= i < n:
-        result[i] = to_datetime(arr[i])
-
-    return result
diff --git a/pandas/src/isnull.pyx b/pandas/src/isnull.pyx
deleted file mode 100644
index 725952b81..000000000
--- a/pandas/src/isnull.pyx
+++ /dev/null
@@ -1,35 +0,0 @@
-
-cdef double INF = <double> np.inf
-cdef double NEGINF = -INF
-
-cdef inline _checknull(object val):
-    if isinstance(val, float):
-        return val != val or val == INF or val == NEGINF
-    else:
-        return val is None
-
-cpdef checknull(object val):
-    return _checknull(val)
-
-def isnullobj(ndarray input):
-    cdef int i, length
-    cdef object val
-    cdef ndarray[npy_int8, ndim=1] result
-    cdef flatiter iter
-
-    length = PyArray_SIZE(input)
-
-    result = <ndarray> np.zeros(length, dtype=np.int8)
-
-    iter= PyArray_IterNew(input)
-
-    for i from 0 <= i < length:
-        val = PyArray_GETITEM(input, PyArray_ITER_DATA(iter))
-
-        if _checknull(val):
-            result[i] = 1
-
-        PyArray_ITER_NEXT(iter)
-
-    return result
-
diff --git a/pandas/src/reindex.pyx b/pandas/src/reindex.pyx
index 6ab690304..f1b5a91c2 100644
--- a/pandas/src/reindex.pyx
+++ b/pandas/src/reindex.pyx
@@ -184,207 +184,6 @@ def left_join_1d(ndarray[int64_t] left, ndarray[int64_t] right,
             out[i, 1] = NaN
 
 
-@cython.wraparound(False)
-@cython.boundscheck(False)
-def left_join_indexer(ndarray[int64_t] left, ndarray[int64_t] right):
-    cdef:
-        Py_ssize_t i, j, k, n
-        ndarray[int32_t] indexer
-        int64_t val
-
-    i = 0
-    j = 0
-    n = len(left)
-    k = len(right)
-
-    indexer = np.empty(n, dtype=np.int32)
-    for i from 0 <= i < n:
-        if j == k:
-            indexer[i] = -1
-            continue
-
-        val = left[i]
-
-        while j < k and right[j] < val:
-            j += 1
-
-        if val == right[j]:
-            indexer[i] = j
-        else:
-            indexer[i] = -1
-
-    return indexer
-
-
-@cython.wraparound(False)
-@cython.boundscheck(False)
-def inner_join_indexer(ndarray[int64_t] left, ndarray[int64_t] right):
-    '''
-    Two-pass algorithm?
-    '''
-    cdef:
-        Py_ssize_t i, j, k, nright, nleft, count
-        int64_t val
-        ndarray[int32_t] lindexer, rindexer
-        ndarray[int64_t] result
-
-    nleft = len(left)
-    nright = len(right)
-
-    assert(left.flags.contiguous)
-    assert(right.flags.contiguous)
-
-    cdef int64_t *lptr = <int64_t*> left.data
-    cdef int64_t *rptr = <int64_t*> right.data
-
-    i = 0
-    j = 0
-    count = 0
-    while i < nleft:
-        while j < nright and rptr[j] < lptr[i]:
-            j += 1
-
-        if j == nright:
-            break
-
-        if lptr[i] == rptr[j]:
-            count += 1
-            i += 1
-            j += 1
-        else:
-            while lptr[i] < rptr[j]:
-                i += 1
-
-    # do it again now that result size is known
-
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
-    result = np.empty(count, dtype=np.int64)
-
-    cdef int32_t *liptr = <int32_t*> lindexer.data
-    cdef int32_t *riptr = <int32_t*> rindexer.data
-    cdef int64_t *resptr = <int64_t*> result.data
-
-    i = 0
-    j = 0
-    count = 0
-    while i < nleft:
-        val = lptr[i]
-        while j < nright and rptr[j] < val:
-            j += 1
-
-        if j == nright:
-            break
-
-        if val == rptr[j]:
-            liptr[count] = i
-            riptr[count] = j
-            resptr[count] = val
-            count += 1
-            i += 1
-            j += 1
-        else:
-            while lptr[i] < rptr[j]:
-                i += 1
-
-    return result, lindexer, rindexer
-
-
-@cython.wraparound(False)
-@cython.boundscheck(False)
-def outer_join_indexer(ndarray[int64_t] left, ndarray[int64_t] right):
-    cdef:
-        Py_ssize_t i, j, nright, nleft, count
-        int64_t lval, rval
-        ndarray[int32_t] lindexer, rindexer
-        ndarray[int64_t] result
-
-    nleft = len(left)
-    nright = len(right)
-
-    i = 0
-    j = 0
-    count = 0
-    while True:
-        if i == nleft:
-            if j == nright:
-                # we are done
-                break
-            else:
-                while j < nright:
-                    j += 1
-                    count += 1
-                break
-        elif j == nright:
-            while i < nleft:
-                i += 1
-                count += 1
-            break
-        else:
-            if left[i] == right[j]:
-                i += 1
-                j += 1
-            elif left[i] < right[j]:
-                i += 1
-            else:
-                j += 1
-
-            count += 1
-
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
-    result = np.empty(count, dtype=np.int64)
-
-    # do it again, but populate the indexers / result
-
-    i = 0
-    j = 0
-    count = 0
-    while True:
-        if i == nleft:
-            if j == nright:
-                # we are done
-                break
-            else:
-                while j < nright:
-                    lindexer[count] = -1
-                    rindexer[count] = j
-                    result[count] = right[j]
-                    j += 1
-                    count += 1
-                break
-        elif j == nright:
-            while i < nleft:
-                lindexer[count] = i
-                rindexer[count] = -1
-                result[count] = left[i]
-                i += 1
-                count += 1
-            break
-        else:
-            lval = left[i]
-            rval = right[j]
-            if lval == rval:
-                lindexer[count] = i
-                rindexer[count] = j
-                result[count] = lval
-                i += 1
-                j += 1
-            elif lval < rval:
-                lindexer[count] = i
-                rindexer[count] = -1
-                result[count] = lval
-                i += 1
-            else:
-                lindexer[count] = -1
-                rindexer[count] = j
-                result[count] = rval
-                j += 1
-
-            count += 1
-
-    return result, lindexer, rindexer
-
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_join_contiguous(ndarray[float64_t, ndim=2] lvalues,
@@ -425,20 +224,3 @@ def take_join_contiguous(ndarray[float64_t, ndim=2] lvalues,
             for j from 0 <= j < rk:
                 outbuf[0] = rvalues[ridx, j]
                 outbuf = outbuf + 1
-
-def ordered_put_indexer(ndarray[int64_t] left, ndarray[int64_t] right,
-                        ndarray[float64_t, ndim=2] lvalues,
-                        ndarray[float64_t, ndim=2] rvalues,
-                        ndarray[float64_t, ndim=2] out):
-    pass
-
-def ordered_outer_join(ndarray[int64_t] left, ndarray[int64_t] right):
-    cdef:
-        Py_ssize_t i, j, k, nright, nleft, kright, kleft
-        int64_t val
-    pass
-
-
-def ordered_inner_join(ndarray[object] left, ndarray[object] right):
-    pass
-
diff --git a/pandas/src/tseries.pyx b/pandas/src/tseries.pyx
index a12593a13..72993bcf5 100644
--- a/pandas/src/tseries.pyx
+++ b/pandas/src/tseries.pyx
@@ -1,8 +1,264 @@
-include "common.pyx"
+cimport numpy as np
+cimport cython
+
+from numpy cimport *
+
+from cpython cimport (PyDict_New, PyDict_GetItem, PyDict_SetItem,
+                          PyDict_Contains, PyDict_Keys)
+from cpython cimport PyFloat_Check
+
+import numpy as np
+isnan = np.isnan
+cdef double NaN = <double> np.NaN
+cdef double nan = NaN
+
+from datetime import datetime as pydatetime
+
+cdef inline int int_max(int a, int b): return a if a >= b else b
+cdef inline int int_min(int a, int b): return a if a <= b else b
+
+ctypedef unsigned char UChar
+
+cdef int is_contiguous(ndarray arr):
+    return np.PyArray_CHKFLAGS(arr, np.NPY_C_CONTIGUOUS)
+
+cdef int _contiguous_check(ndarray arr):
+    if not is_contiguous(arr):
+        raise ValueError('Tried to use data field on non-contiguous array!')
+
+cdef int16_t *get_int16_ptr(ndarray arr):
+    _contiguous_check(arr)
+
+    return <int16_t *> arr.data
+
+cdef int32_t *get_int32_ptr(ndarray arr):
+    _contiguous_check(arr)
+
+    return <int32_t *> arr.data
+
+cdef int64_t *get_int64_ptr(ndarray arr):
+    _contiguous_check(arr)
+
+    return <int64_t *> arr.data
+
+cdef double_t *get_double_ptr(ndarray arr):
+    _contiguous_check(arr)
+
+    return <double_t *> arr.data
+
+cdef extern from "math.h":
+    double sqrt(double x)
+
+cdef extern from "cobject.h":
+    pass # for datetime API
+
+cdef extern from "datetime.h":
+
+    ctypedef class datetime.datetime [object PyDateTime_DateTime]:
+        # cdef int *data
+        # cdef long hashcode
+        # cdef char hastzinfo
+        pass
+
+    int PyDateTime_GET_YEAR(datetime o)
+    int PyDateTime_GET_MONTH(datetime o)
+    int PyDateTime_GET_DAY(datetime o)
+    int PyDateTime_DATE_GET_HOUR(datetime o)
+    int PyDateTime_DATE_GET_MINUTE(datetime o)
+    int PyDateTime_DATE_GET_SECOND(datetime o)
+    int PyDateTime_DATE_GET_MICROSECOND(datetime o)
+    int PyDateTime_TIME_GET_HOUR(datetime o)
+    int PyDateTime_TIME_GET_MINUTE(datetime o)
+    int PyDateTime_TIME_GET_SECOND(datetime o)
+    int PyDateTime_TIME_GET_MICROSECOND(datetime o)
+    bint PyDateTime_Check(object o)
+    void PyDateTime_IMPORT()
+
+# import datetime C API
+PyDateTime_IMPORT
+
+# initialize numpy
+import_array()
+
+
+cpdef map_indices_list(list index):
+    '''
+    Produce a dict mapping the values of the input array to their respective
+    locations.
+
+    Example:
+        array(['hi', 'there']) --> {'hi' : 0 , 'there' : 1}
+
+    Better to do this with Cython because of the enormous speed boost.
+    '''
+    cdef Py_ssize_t i, length
+    cdef dict result = {}
+
+    length = len(index)
+
+    for i from 0 <= i < length:
+        result[index[i]] = i
+
+    return result
+
+
+from libc.stdlib cimport malloc, free
+
+cdef class MultiMap:
+    '''
+    Need to come up with a better data structure for multi-level indexing
+    '''
+
+    cdef:
+        dict store
+        Py_ssize_t depth, length
+
+    def __init__(self, list label_arrays):
+        cdef:
+            int32_t **ptr
+            Py_ssize_t i
+
+        self.depth = len(label_arrays)
+        self.length = len(label_arrays[0])
+        self.store = {}
+
+        ptr = <int32_t**> malloc(self.depth * sizeof(int32_t*))
+
+        for i in range(self.depth):
+            ptr[i] = <int32_t*> (<ndarray> label_arrays[i]).data
+
+        free(ptr)
+
+    cdef populate(self, int32_t **ptr):
+        cdef Py_ssize_t i, j
+        cdef int32_t* buf
+        cdef dict level
+
+        for i from 0 <= i < self.length:
+
+            for j from 0 <= j < self.depth - 1:
+                pass
+
+    cpdef get(self, tuple key):
+        cdef Py_ssize_t i
+        cdef dict level = self.store
+
+        for i from 0 <= i < self.depth:
+            if i == self.depth - 1:
+                return level[i]
+            else:
+                level = level[i]
+
+        raise KeyError(key)
+
+
+def isAllDates(ndarray[object, ndim=1] arr):
+    cdef int i, size = len(arr)
+    cdef object date
+
+    if size == 0:
+        return False
+
+    for i from 0 <= i < size:
+        date = arr[i]
+
+        if not PyDateTime_Check(date):
+            return False
+
+    return True
+
+#----------------------------------------------------------------------
+# datetime / io related
+
+cdef int _EPOCH_ORD = 719163
+
+from datetime import date as pydate
+
+cdef inline int64_t gmtime(object date):
+    cdef int y, m, d, h, mn, s, days
+
+    y = PyDateTime_GET_YEAR(date)
+    m = PyDateTime_GET_MONTH(date)
+    d = PyDateTime_GET_DAY(date)
+    h = PyDateTime_DATE_GET_HOUR(date)
+    mn = PyDateTime_DATE_GET_MINUTE(date)
+    s = PyDateTime_DATE_GET_SECOND(date)
+
+    days = pydate(y, m, 1).toordinal() - _EPOCH_ORD + d - 1
+    return ((<int64_t> (((days * 24 + h) * 60 + mn))) * 60 + s) * 1000
+
+cpdef object to_datetime(int64_t timestamp):
+    return pydatetime.utcfromtimestamp(timestamp / 1000.0)
+
+cpdef object to_timestamp(object dt):
+    return gmtime(dt)
+
+def array_to_timestamp(ndarray[object, ndim=1] arr):
+    cdef int i, n
+    cdef ndarray[int64_t, ndim=1] result
+
+    n = len(arr)
+    result = np.empty(n, dtype=np.int64)
+
+    for i from 0 <= i < n:
+        result[i] = gmtime(arr[i])
+
+    return result
+
+def array_to_datetime(ndarray[int64_t, ndim=1] arr):
+    cdef int i, n
+    cdef ndarray[object, ndim=1] result
+
+    n = len(arr)
+    result = np.empty(n, dtype=object)
+
+    for i from 0 <= i < n:
+        result[i] = to_datetime(arr[i])
+
+    return result
+
+#----------------------------------------------------------------------
+# isnull / notnull related
+
+cdef double INF = <double> np.inf
+cdef double NEGINF = -INF
+
+cdef inline _isnan(object o):
+    return o != o
+
+cdef inline _checknull(object val):
+    if isinstance(val, float):
+        return val != val or val == INF or val == NEGINF
+    else:
+        return val is None
+
+cpdef checknull(object val):
+    return _checknull(val)
+
+def isnullobj(ndarray input):
+    cdef int i, length
+    cdef object val
+    cdef ndarray[npy_int8, ndim=1] result
+    cdef flatiter iter
+
+    length = PyArray_SIZE(input)
+
+    result = <ndarray> np.zeros(length, dtype=np.int8)
+
+    iter= PyArray_IterNew(input)
+
+    for i from 0 <= i < length:
+        val = PyArray_GETITEM(input, PyArray_ITER_DATA(iter))
+
+        if _checknull(val):
+            result[i] = 1
+
+        PyArray_ITER_NEXT(iter)
+
+    return result
+
 include "skiplist.pyx"
-include "isnull.pyx"
 include "groupby.pyx"
 include "moments.pyx"
 include "reindex.pyx"
-include "io.pyx"
 include "generated.pyx"
