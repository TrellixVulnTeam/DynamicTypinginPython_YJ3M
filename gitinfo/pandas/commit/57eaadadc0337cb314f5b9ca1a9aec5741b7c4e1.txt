commit 57eaadadc0337cb314f5b9ca1a9aec5741b7c4e1
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Sep 24 16:34:21 2012 -0400

    ENH: refactor to high/low mem functions, consume_rows functions

diff --git a/pandas/io/tests/test_cparser.py b/pandas/io/tests/test_cparser.py
index f1027f34d..bec2bc34b 100644
--- a/pandas/io/tests/test_cparser.py
+++ b/pandas/io/tests/test_cparser.py
@@ -47,32 +47,32 @@ class TestCParser(unittest.TestCase):
         try:
             f = open(self.csv1, 'rb')
             reader = TextReader(f)
-            result = reader.read()
+            names, result = reader.read()
         finally:
             f.close()
 
     def test_string_filename(self):
         reader = TextReader(self.csv1, header=None)
-        result = reader.read()
+        names, result = reader.read()
 
     def test_file_handle_mmap(self):
         try:
             f = open(self.csv1, 'rb')
             reader = TextReader(f, memory_map=True, header=None)
-            result = reader.read()
+            names, result = reader.read()
         finally:
             f.close()
 
     def test_StringIO(self):
         text = open(self.csv1, 'rb').read()
         reader = TextReader(BytesIO(text), header=None)
-        result = reader.read()
+        names, result = reader.read()
 
     def test_string_factorize(self):
         # should this be optional?
         data = 'a\nb\na\nb\na'
         reader = TextReader(StringIO(data), header=None)
-        result = reader.read()
+        names, result = reader.read()
         self.assert_(len(set(map(id, result[0]))) == 2)
 
     def test_skipinitialspace(self):
@@ -83,7 +83,7 @@ class TestCParser(unittest.TestCase):
 
         reader = TextReader(StringIO(data), skipinitialspace=True,
                             header=None)
-        result = reader.read()
+        names, result = reader.read()
 
         self.assert_(np.array_equal(result[0], ['a', 'a', 'a', 'a']))
         self.assert_(np.array_equal(result[1], ['b', 'b', 'b', 'b']))
@@ -92,7 +92,7 @@ class TestCParser(unittest.TestCase):
         data = 'True\nFalse\nTrue\nTrue'
 
         reader = TextReader(StringIO(data), header=None)
-        result = reader.read()
+        names, result = reader.read()
 
         self.assert_(result[0].dtype == np.bool_)
 
@@ -101,7 +101,7 @@ class TestCParser(unittest.TestCase):
 
         reader = TextReader(StringIO(data), delim_whitespace=True,
                             header=None)
-        result = reader.read()
+        names, result = reader.read()
 
         self.assert_(np.array_equal(result[0], ['a', 'a', 'a']))
         self.assert_(np.array_equal(result[1], ['b', 'b', 'b']))
@@ -110,7 +110,7 @@ class TestCParser(unittest.TestCase):
         data = 'a\n"hello\nthere"\nthis'
 
         reader = TextReader(StringIO(data), header=None)
-        result = reader.read()
+        names, result = reader.read()
 
         expected = ['a', 'hello\nthere', 'this']
         self.assert_(np.array_equal(result[0], expected))
@@ -120,7 +120,7 @@ class TestCParser(unittest.TestCase):
 
         reader = TextReader(StringIO(data), delimiter=':',
                             decimal=',', header=None)
-        result = reader.read()
+        names, result = reader.read()
 
         expected = [12345.67, 345.678]
         tm.assert_almost_equal(result[0], expected)
@@ -130,7 +130,7 @@ class TestCParser(unittest.TestCase):
 
         reader = TextReader(StringIO(data), delimiter=':',
                             thousands=',', header=None)
-        result = reader.read()
+        names, result = reader.read()
 
         expected = [123456, 12500]
         tm.assert_almost_equal(result[0], expected)
@@ -150,7 +150,7 @@ class TestCParser(unittest.TestCase):
                             header=None,
                             error_bad_lines=False,
                             warn_bad_lines=False)
-        result = reader.read()
+        names, result = reader.read()
         expected = {0: ['a', 'd', 'g', 'l'],
                     1: ['b', 'e', 'h', 'm'],
                     2: ['c', 'f', 'i', 'n']}
@@ -185,7 +185,7 @@ class TestCParser(unittest.TestCase):
 
         reader = TextReader(StringIO(data), delimiter=',', header=None,
                             escapechar='\\')
-        result = reader.read()
+        names, result = reader.read()
         expected = {0: ['"hello world"'] * 3}
         assert_array_dicts_equal(result, expected)
 
diff --git a/pandas/src/parser.pyx b/pandas/src/parser.pyx
index 2c4ff647e..1ec26e8d1 100644
--- a/pandas/src/parser.pyx
+++ b/pandas/src/parser.pyx
@@ -158,6 +158,8 @@ cdef extern from "parser/parser.h":
     int parser_mmap_init(parser_t *self, FILE* fp)
     int parser_array_source_init(parser_t *self, char *bytes, size_t length)
 
+    int parser_consume_rows(parser_t *self, size_t nrows)
+
     void debug_print_parser(parser_t *self)
 
     int tokenize_all_rows(parser_t *self) nogil
@@ -189,6 +191,7 @@ cdef class TextReader:
         object memory_map
         object as_recarray
         object header
+        object low_memory
 
     def __cinit__(self, source, delimiter=b',',
                   header=0,
@@ -205,7 +208,8 @@ cdef class TextReader:
                   decimal=b'.',
                   error_bad_lines=True,
                   warn_bad_lines=True,
-                  na_filter=True):
+                  na_filter=True,
+                  low_memory=False):
         self.parser = parser_new()
         self.parser.chunksize = tokenize_chunksize
 
@@ -266,6 +270,8 @@ cdef class TextReader:
         self.as_recarray = as_recarray
         self.header = None
 
+        self.low_memory = low_memory
+
     def __init__(self, *args, **kwards):
         pass
 
@@ -351,9 +357,29 @@ cdef class TextReader:
         rows=None --> read all rows
         """
         cdef:
-            int prior_lines
             int status
 
+        if self.low_memory:
+            # Conserve intermediate space
+            names, columns = self._read_low_memory(rows)
+        else:
+            # Don't care about memory usage
+            names, columns = self._read_high_memory(rows)
+
+        if self.as_recarray:
+            # start = time.clock()
+            result = _to_structured_array(columns, names)
+            # end = time.clock()
+            # print 'to_structured_array took %.4f sec' % (end - start)
+
+            return result
+        else:
+            return names, columns
+
+    cdef _read_low_memory(self, rows):
+        pass
+
+    cdef _read_high_memory(self, rows):
         # start = time.clock()
 
         if rows is not None:
@@ -378,18 +404,9 @@ cdef class TextReader:
 
         # end = time.clock()
         # print 'Type conversion took %.4f sec' % (end - start)
-
         # debug_print_parser(self.parser)
 
-        if self.as_recarray:
-            # start = time.clock()
-            result = _to_structured_array(columns, names)
-            # end = time.clock()
-            # print 'to_structured_array took %.4f sec' % (end - start)
-
-            return result
-        else:
-            return columns
+        return names, columns
 
     def _convert_column_data(self):
         cdef:
diff --git a/pandas/src/parser/parser.c b/pandas/src/parser/parser.c
index b45d88efb..c16e86014 100644
--- a/pandas/src/parser/parser.c
+++ b/pandas/src/parser/parser.c
@@ -1652,6 +1652,48 @@ int parser_handle_eof(parser_t *self) {
     }
 }
 
+#define MV(dst, src, n) memmove((void*) dst, (void*) src, n)
+
+int parser_consume_rows(parser_t *self, size_t nrows) {
+    int word_deletions, char_count;
+
+    if (nrows > self->lines) {
+        nrows = self->lines;
+    }
+
+    /* do nothing */
+    if (nrows == 0)
+        return 0;
+
+    /* cannot guarantee that nrows + 1 has been observed */
+    word_deletions = self->line_start[nrows - 1] + self->line_fields[nrows - 1];
+    char_count = self->word_starts[word_deletions];
+
+    /* move stream */
+    MV(self->stream, self->stream + char_count, self->stream_len - char_count);
+
+    /* move token metadata */
+    MV(self->words, self->words + word_deletions,
+       self->words_cap - word_deletions);
+
+    MV(self->word_starts, self->word_starts + word_deletions,
+       self->words_cap - word_deletions);
+
+    MV(self->line_start, self->line_start + nrows, self->lines - nrows);
+    MV(self->line_fields, self->line_fields + nrows, self->lines - nrows);
+
+    /* buffer counts */
+    self->stream_len -= char_count;
+    self->words_len -= word_deletions;
+    self->lines -= nrows;
+
+    /* move current word pointer to stream */
+    self->pword_start -= char_count;
+    self->word_start -= char_count;
+
+    return 0;
+}
+
 void debug_print_parser(parser_t *self) {
     int i, j, line;
     char *token;
diff --git a/pandas/src/parser/parser.h b/pandas/src/parser/parser.h
index 1c59fb2f9..11ab89f9c 100644
--- a/pandas/src/parser/parser.h
+++ b/pandas/src/parser/parser.h
@@ -171,8 +171,6 @@ typedef struct parser_t {
     void **columns;
     int ncols;
 
-    // PyObject *converters;
-
     // error handling
     char *error_msg;
 } parser_t;
@@ -207,6 +205,8 @@ int parser_array_source_init(parser_t *self, char *bytes, size_t length);
 
 int parser_gzip_source_init(parser_t *self, FILE *fp);
 
+int parser_consume_rows(parser_t *self, size_t nrows);
+
 void parser_free(parser_t *self);
 
 void parser_set_default_options(parser_t *self);
diff --git a/setup.py b/setup.py
index 73655b4fa..e968386a7 100755
--- a/setup.py
+++ b/setup.py
@@ -419,7 +419,10 @@ cppsandbox_ext = Extension('pandas._cppsandbox',
                            sources=[srcpath('cppsandbox', suffix=suffix)],
                            include_dirs=[np.get_include()])
 
-extensions = [algos_ext, lib_ext, period_ext, sparse_ext,
+extensions = [algos_ext,
+              # lib_ext,
+              period_ext,
+              sparse_ext,
               parser_ext]
 
 if not ISRELEASED:
