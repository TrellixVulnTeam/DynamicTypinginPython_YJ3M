commit f34dbbf28b4c4d1b241f7bda155284fe0c131d18
Author: jbrockmendel <jbrockmendel@gmail.com>
Date:   Mon Jul 29 09:52:38 2019 -0700

    CLN: Assorted cleanups (#27632)

diff --git a/pandas/core/accessor.py b/pandas/core/accessor.py
index f84033e9c..2d4ded9e2 100644
--- a/pandas/core/accessor.py
+++ b/pandas/core/accessor.py
@@ -51,7 +51,7 @@ class PandasDelegate:
     """
 
     def _delegate_property_get(self, name, *args, **kwargs):
-        raise TypeError("You cannot access the " "property {name}".format(name=name))
+        raise TypeError("You cannot access the property {name}".format(name=name))
 
     def _delegate_property_set(self, name, value, *args, **kwargs):
         raise TypeError("The property {name} cannot be set".format(name=name))
@@ -271,8 +271,7 @@ Back in an interactive IPython session:
 @Appender(
     _doc
     % dict(
-        klass="DataFrame",
-        others=("register_series_accessor, " "register_index_accessor"),
+        klass="DataFrame", others=("register_series_accessor, register_index_accessor")
     )
 )
 def register_dataframe_accessor(name):
@@ -284,8 +283,7 @@ def register_dataframe_accessor(name):
 @Appender(
     _doc
     % dict(
-        klass="Series",
-        others=("register_dataframe_accessor, " "register_index_accessor"),
+        klass="Series", others=("register_dataframe_accessor, register_index_accessor")
     )
 )
 def register_series_accessor(name):
@@ -297,8 +295,7 @@ def register_series_accessor(name):
 @Appender(
     _doc
     % dict(
-        klass="Index",
-        others=("register_dataframe_accessor, " "register_series_accessor"),
+        klass="Index", others=("register_dataframe_accessor, register_series_accessor")
     )
 )
 def register_index_accessor(name):
diff --git a/pandas/core/arrays/base.py b/pandas/core/arrays/base.py
index ee796f989..e517be4f0 100644
--- a/pandas/core/arrays/base.py
+++ b/pandas/core/arrays/base.py
@@ -14,14 +14,17 @@ from pandas.compat import set_function_name
 from pandas.compat.numpy import function as nv
 from pandas.errors import AbstractMethodError
 from pandas.util._decorators import Appender, Substitution
+from pandas.util._validators import validate_fillna_kwargs
 
-from pandas.core.dtypes.common import is_list_like
+from pandas.core.dtypes.common import is_array_like, is_list_like
 from pandas.core.dtypes.dtypes import ExtensionDtype
 from pandas.core.dtypes.generic import ABCExtensionArray, ABCIndexClass, ABCSeries
 from pandas.core.dtypes.missing import isna
 
 from pandas._typing import ArrayLike
 from pandas.core import ops
+from pandas.core.algorithms import _factorize_array, unique
+from pandas.core.missing import backfill_1d, pad_1d
 from pandas.core.sorting import nargsort
 
 _not_implemented_message = "{} does not implement {}."
@@ -484,10 +487,6 @@ class ExtensionArray:
         -------
         filled : ExtensionArray with NA/NaN filled
         """
-        from pandas.api.types import is_array_like
-        from pandas.util._validators import validate_fillna_kwargs
-        from pandas.core.missing import pad_1d, backfill_1d
-
         value, method = validate_fillna_kwargs(value, method)
 
         mask = self.isna()
@@ -584,8 +583,6 @@ class ExtensionArray:
         -------
         uniques : ExtensionArray
         """
-        from pandas import unique
-
         uniques = unique(self.astype(object))
         return self._from_sequence(uniques, dtype=self.dtype)
 
@@ -700,8 +697,6 @@ class ExtensionArray:
         #    original ExtensionArray.
         # 2. ExtensionArray.factorize.
         #    Complete control over factorization.
-        from pandas.core.algorithms import _factorize_array
-
         arr, na_value = self._values_for_factorize()
 
         labels, uniques = _factorize_array(
@@ -874,7 +869,7 @@ class ExtensionArray:
     def __repr__(self):
         from pandas.io.formats.printing import format_object_summary
 
-        template = "{class_name}" "{data}\n" "Length: {length}, dtype: {dtype}"
+        template = "{class_name}{data}\nLength: {length}, dtype: {dtype}"
         # the short repr has no trailing newline, while the truncated
         # repr does. So we include a newline in our template, and strip
         # any trailing newlines from format_object_summary
diff --git a/pandas/core/arrays/categorical.py b/pandas/core/arrays/categorical.py
index c22f7e042..b16217d5d 100644
--- a/pandas/core/arrays/categorical.py
+++ b/pandas/core/arrays/categorical.py
@@ -93,13 +93,13 @@ def _cat_compare_op(op):
         if not self.ordered:
             if op in ["__lt__", "__gt__", "__le__", "__ge__"]:
                 raise TypeError(
-                    "Unordered Categoricals can only compare " "equality or not"
+                    "Unordered Categoricals can only compare equality or not"
                 )
         if isinstance(other, Categorical):
             # Two Categoricals can only be be compared if the categories are
             # the same (maybe up to ordering, depending on ordered)
 
-            msg = "Categoricals can only be compared if " "'categories' are the same."
+            msg = "Categoricals can only be compared if 'categories' are the same."
             if len(self.categories) != len(other.categories):
                 raise TypeError(msg + " Categories are different lengths")
             elif self.ordered and not (self.categories == other.categories).all():
@@ -109,7 +109,7 @@ def _cat_compare_op(op):
 
             if not (self.ordered == other.ordered):
                 raise TypeError(
-                    "Categoricals can only be compared if " "'ordered' is the same"
+                    "Categoricals can only be compared if 'ordered' is the same"
                 )
             if not self.ordered and not self.categories.equals(other.categories):
                 # both unordered and different order
@@ -387,7 +387,7 @@ class Categorical(ExtensionArray, PandasObject):
 
                 # FIXME
                 raise NotImplementedError(
-                    "> 1 ndim Categorical are not " "supported at this time"
+                    "> 1 ndim Categorical are not supported at this time"
                 )
 
             # we're inferring from values
@@ -694,7 +694,7 @@ class Categorical(ExtensionArray, PandasObject):
                 raise ValueError(msg)
 
         if len(codes) and (codes.max() >= len(dtype.categories) or codes.min() < -1):
-            raise ValueError("codes need to be between -1 and " "len(categories)-1")
+            raise ValueError("codes need to be between -1 and len(categories)-1")
 
         return cls(codes, dtype=dtype, fastpath=True)
 
@@ -1019,7 +1019,7 @@ class Categorical(ExtensionArray, PandasObject):
         inplace = validate_bool_kwarg(inplace, "inplace")
         if set(self.dtype.categories) != set(new_categories):
             raise ValueError(
-                "items in new_categories are not the same as in " "old categories"
+                "items in new_categories are not the same as in old categories"
             )
         return self.set_categories(new_categories, ordered=ordered, inplace=inplace)
 
@@ -1481,7 +1481,7 @@ class Categorical(ExtensionArray, PandasObject):
         """
         Replace specific elements in the Categorical with given values.
         """
-        raise NotImplementedError(("'put' is not yet implemented " "for Categorical"))
+        raise NotImplementedError(("'put' is not yet implemented for Categorical"))
 
     def dropna(self):
         """
@@ -1827,7 +1827,7 @@ class Categorical(ExtensionArray, PandasObject):
             value = np.nan
         if limit is not None:
             raise NotImplementedError(
-                "specifying a limit for fillna has not " "been implemented yet"
+                "specifying a limit for fillna has not been implemented yet"
             )
 
         codes = self._codes
@@ -1963,7 +1963,7 @@ class Categorical(ExtensionArray, PandasObject):
             if fill_value in self.categories:
                 fill_value = self.categories.get_loc(fill_value)
             else:
-                msg = "'fill_value' ('{}') is not in this Categorical's " "categories."
+                msg = "'fill_value' ('{}') is not in this Categorical's categories."
                 raise TypeError(msg.format(fill_value))
 
         codes = take(self._codes, indexer, allow_fill=allow_fill, fill_value=fill_value)
@@ -2168,12 +2168,12 @@ class Categorical(ExtensionArray, PandasObject):
             # in a 2-d case be passd (slice(None),....)
             if len(key) == 2:
                 if not com.is_null_slice(key[0]):
-                    raise AssertionError("invalid slicing for a 1-ndim " "categorical")
+                    raise AssertionError("invalid slicing for a 1-ndim categorical")
                 key = key[1]
             elif len(key) == 1:
                 key = key[0]
             else:
-                raise AssertionError("invalid slicing for a 1-ndim " "categorical")
+                raise AssertionError("invalid slicing for a 1-ndim categorical")
 
         # slicing in Series or Categorical
         elif isinstance(key, slice):
@@ -2561,9 +2561,7 @@ class CategoricalAccessor(PandasDelegate, PandasObject, NoNewAttributesMixin):
     @staticmethod
     def _validate(data):
         if not is_categorical_dtype(data.dtype):
-            raise AttributeError(
-                "Can only use .cat accessor with a " "'category' dtype"
-            )
+            raise AttributeError("Can only use .cat accessor with a 'category' dtype")
 
     def _delegate_property_get(self, name):
         return getattr(self._parent, name)
@@ -2607,7 +2605,7 @@ class CategoricalAccessor(PandasDelegate, PandasObject, NoNewAttributesMixin):
         # need to be updated. `name` will need to be removed from
         # `ok_for_cat`.
         warn(
-            "`Series.cat.name` has been deprecated. Use `Series.name` " "instead.",
+            "`Series.cat.name` has been deprecated. Use `Series.name` instead.",
             FutureWarning,
             stacklevel=2,
         )
@@ -2619,7 +2617,7 @@ class CategoricalAccessor(PandasDelegate, PandasObject, NoNewAttributesMixin):
         # need to be updated. `index` will need to be removed from
         # ok_for_cat`.
         warn(
-            "`Series.cat.index` has been deprecated. Use `Series.index` " "instead.",
+            "`Series.cat.index` has been deprecated. Use `Series.index` instead.",
             FutureWarning,
             stacklevel=2,
         )
diff --git a/pandas/core/arrays/datetimelike.py b/pandas/core/arrays/datetimelike.py
index 932d96a37..f86b307e5 100644
--- a/pandas/core/arrays/datetimelike.py
+++ b/pandas/core/arrays/datetimelike.py
@@ -1097,7 +1097,7 @@ class DatetimeLikeArrayMixin(ExtensionOpsMixin, AttributesMixin, ExtensionArray)
             )
 
         if len(self) != len(other):
-            raise ValueError("cannot subtract arrays/indices of " "unequal length")
+            raise ValueError("cannot subtract arrays/indices of unequal length")
         if self.freq != other.freq:
             msg = DIFFERENT_FREQ.format(
                 cls=type(self).__name__, own_freq=self.freqstr, other_freq=other.freqstr
diff --git a/pandas/core/arrays/datetimes.py b/pandas/core/arrays/datetimes.py
index 5b540dcce..8e76ad8a3 100644
--- a/pandas/core/arrays/datetimes.py
+++ b/pandas/core/arrays/datetimes.py
@@ -478,7 +478,7 @@ class DatetimeArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps, dtl.DatelikeOps
 
         periods = dtl.validate_periods(periods)
         if freq is None and any(x is None for x in [periods, start, end]):
-            raise ValueError("Must provide freq argument if no data is " "supplied")
+            raise ValueError("Must provide freq argument if no data is supplied")
 
         if com.count_not_none(start, end, periods, freq) != 3:
             raise ValueError(
@@ -496,7 +496,7 @@ class DatetimeArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps, dtl.DatelikeOps
         if start is None and end is None:
             if closed is not None:
                 raise ValueError(
-                    "Closed has to be None if not both of start" "and end are defined"
+                    "Closed has to be None if not both of startand end are defined"
                 )
         if start is NaT or end is NaT:
             raise ValueError("Neither `start` nor `end` can be NaT")
@@ -786,11 +786,11 @@ class DatetimeArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps, dtl.DatelikeOps
         elif self.tz is None:
             if other_tz is not None:
                 raise TypeError(
-                    "Cannot compare tz-naive and tz-aware " "datetime-like objects."
+                    "Cannot compare tz-naive and tz-aware datetime-like objects."
                 )
         elif other_tz is None:
             raise TypeError(
-                "Cannot compare tz-naive and tz-aware " "datetime-like objects"
+                "Cannot compare tz-naive and tz-aware datetime-like objects"
             )
 
     # -----------------------------------------------------------------
@@ -833,7 +833,7 @@ class DatetimeArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps, dtl.DatelikeOps
 
         except NotImplementedError:
             warnings.warn(
-                "Non-vectorized DateOffset being applied to Series " "or DatetimeIndex",
+                "Non-vectorized DateOffset being applied to Series or DatetimeIndex",
                 PerformanceWarning,
             )
             result = self.astype("O") + offset
@@ -851,7 +851,7 @@ class DatetimeArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps, dtl.DatelikeOps
         if not self._has_same_tz(other):
             # require tz compat
             raise TypeError(
-                "Timestamp subtraction must have the same " "timezones or no timezones"
+                "Timestamp subtraction must have the same timezones or no timezones"
             )
 
         i8 = self.asi8
@@ -957,7 +957,7 @@ class DatetimeArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps, dtl.DatelikeOps
         if self.tz is None:
             # tz naive, use tz_localize
             raise TypeError(
-                "Cannot convert tz-naive timestamps, use " "tz_localize to localize"
+                "Cannot convert tz-naive timestamps, use tz_localize to localize"
             )
 
         # No conversion since timestamps are all UTC to begin with
@@ -1125,7 +1125,7 @@ default 'raise'
                 nonexistent = "raise"
             else:
                 raise ValueError(
-                    "The errors argument must be either 'coerce' " "or 'raise'."
+                    "The errors argument must be either 'coerce' or 'raise'."
                 )
 
         nonexistent_options = ("raise", "NaT", "shift_forward", "shift_backward")
@@ -1274,7 +1274,7 @@ default 'raise'
 
             if freq is None:
                 raise ValueError(
-                    "You must pass a freq argument as " "current index has none."
+                    "You must pass a freq argument as current index has none."
                 )
 
             freq = get_period_alias(freq)
@@ -2047,7 +2047,7 @@ def maybe_convert_dtype(data, copy):
         # Note: without explicitly raising here, PeriodIndex
         #  test_setops.test_join_does_not_recur fails
         raise TypeError(
-            "Passing PeriodDtype data is invalid.  " "Use `data.to_timestamp()` instead"
+            "Passing PeriodDtype data is invalid.  Use `data.to_timestamp()` instead"
         )
 
     elif is_categorical_dtype(data):
@@ -2177,7 +2177,7 @@ def validate_tz_from_dtype(dtype, tz):
         dtz = getattr(dtype, "tz", None)
         if dtz is not None:
             if tz is not None and not timezones.tz_compare(tz, dtz):
-                raise ValueError("cannot supply both a tz and a dtype" " with a tz")
+                raise ValueError("cannot supply both a tz and a dtype with a tz")
             tz = dtz
 
         if tz is not None and is_datetime64_dtype(dtype):
@@ -2216,7 +2216,7 @@ def _infer_tz_from_endpoints(start, end, tz):
         inferred_tz = timezones.infer_tzinfo(start, end)
     except Exception:
         raise TypeError(
-            "Start and end cannot both be tz-aware with " "different timezones"
+            "Start and end cannot both be tz-aware with different timezones"
         )
 
     inferred_tz = timezones.maybe_get_tz(inferred_tz)
@@ -2224,7 +2224,7 @@ def _infer_tz_from_endpoints(start, end, tz):
 
     if tz is not None and inferred_tz is not None:
         if not timezones.tz_compare(inferred_tz, tz):
-            raise AssertionError("Inferred time zone not equal to passed " "time zone")
+            raise AssertionError("Inferred time zone not equal to passed time zone")
 
     elif inferred_tz is not None:
         tz = inferred_tz
diff --git a/pandas/core/arrays/interval.py b/pandas/core/arrays/interval.py
index 2a0d2c877..2b3c02bd1 100644
--- a/pandas/core/arrays/interval.py
+++ b/pandas/core/arrays/interval.py
@@ -33,6 +33,7 @@ from pandas.core.dtypes.generic import (
 )
 from pandas.core.dtypes.missing import isna, notna
 
+from pandas.core.algorithms import take, value_counts
 from pandas.core.arrays.base import ExtensionArray, _extension_array_shared_docs
 from pandas.core.arrays.categorical import Categorical
 import pandas.core.common as com
@@ -206,7 +207,7 @@ class IntervalArray(IntervalMixin, ExtensionArray):
             left = left.astype(right.dtype)
 
         if type(left) != type(right):
-            msg = "must not have differing left [{ltype}] and right " "[{rtype}] types"
+            msg = "must not have differing left [{ltype}] and right [{rtype}] types"
             raise ValueError(
                 msg.format(ltype=type(left).__name__, rtype=type(right).__name__)
             )
@@ -458,13 +459,13 @@ class IntervalArray(IntervalMixin, ExtensionArray):
                     lhs, rhs = d
                 except ValueError:
                     msg = (
-                        "{name}.from_tuples requires tuples of " "length 2, got {tpl}"
+                        "{name}.from_tuples requires tuples of length 2, got {tpl}"
                     ).format(name=name, tpl=d)
                     raise ValueError(msg)
                 except TypeError:
-                    msg = (
-                        "{name}.from_tuples received an invalid " "item, {tpl}"
-                    ).format(name=name, tpl=d)
+                    msg = ("{name}.from_tuples received an invalid item, {tpl}").format(
+                        name=name, tpl=d
+                    )
                     raise TypeError(msg)
             left.append(lhs)
             right.append(rhs)
@@ -590,7 +591,7 @@ class IntervalArray(IntervalMixin, ExtensionArray):
         filled : IntervalArray with NA/NaN filled
         """
         if method is not None:
-            raise TypeError("Filling by method is not supported for " "IntervalArray.")
+            raise TypeError("Filling by method is not supported for IntervalArray.")
         if limit is not None:
             raise TypeError("limit is not supported for IntervalArray.")
 
@@ -796,8 +797,6 @@ class IntervalArray(IntervalMixin, ExtensionArray):
             When `indices` contains negative values other than ``-1``
             and `allow_fill` is True.
         """
-        from pandas.core.algorithms import take
-
         nv.validate_take(tuple(), kwargs)
 
         fill_left = fill_right = fill_value
@@ -843,8 +842,6 @@ class IntervalArray(IntervalMixin, ExtensionArray):
         Series.value_counts
         """
         # TODO: implement this is a non-naive way!
-        from pandas.core.algorithms import value_counts
-
         return value_counts(np.asarray(self), dropna=dropna)
 
     # Formatting
diff --git a/pandas/core/arrays/period.py b/pandas/core/arrays/period.py
index b0336c46d..c29039127 100644
--- a/pandas/core/arrays/period.py
+++ b/pandas/core/arrays/period.py
@@ -286,13 +286,13 @@ class PeriodArray(dtl.DatetimeLikeArrayMixin, dtl.DatelikeOps):
         if start is not None or end is not None:
             if field_count > 0:
                 raise ValueError(
-                    "Can either instantiate from fields " "or endpoints, but not both"
+                    "Can either instantiate from fields or endpoints, but not both"
                 )
             subarr, freq = _get_ordinal_range(start, end, periods, freq)
         elif field_count > 0:
             subarr, freq = _range_from_fields(freq=freq, **fields)
         else:
-            raise ValueError("Not enough parameters to construct " "Period range")
+            raise ValueError("Not enough parameters to construct Period range")
 
         return subarr, freq
 
@@ -839,7 +839,7 @@ def period_array(
         dtype = None
 
     if is_float_dtype(data) and len(data) > 0:
-        raise TypeError("PeriodIndex does not allow " "floating point in construction")
+        raise TypeError("PeriodIndex does not allow floating point in construction")
 
     data = ensure_object(data)
 
@@ -875,7 +875,7 @@ def validate_dtype_freq(dtype, freq):
         if freq is None:
             freq = dtype.freq
         elif freq != dtype.freq:
-            raise IncompatibleFrequency("specified freq and dtype " "are different")
+            raise IncompatibleFrequency("specified freq and dtype are different")
     return freq
 
 
diff --git a/pandas/core/arrays/sparse.py b/pandas/core/arrays/sparse.py
index 048f6c6f5..47c7c7205 100644
--- a/pandas/core/arrays/sparse.py
+++ b/pandas/core/arrays/sparse.py
@@ -121,7 +121,7 @@ class SparseDtype(ExtensionDtype):
 
         if not is_scalar(fill_value):
             raise ValueError(
-                "fill_value must be a scalar. Got {} " "instead".format(fill_value)
+                "fill_value must be a scalar. Got {} instead".format(fill_value)
             )
         self._dtype = dtype
         self._fill_value = fill_value
@@ -1139,7 +1139,7 @@ class SparseArray(PandasObject, ExtensionArray, ExtensionOpsMixin):
     def take(self, indices, allow_fill=False, fill_value=None):
         if is_scalar(indices):
             raise ValueError(
-                "'indices' must be an array, not a " "scalar '{}'.".format(indices)
+                "'indices' must be an array, not a scalar '{}'.".format(indices)
             )
         indices = np.asarray(indices, dtype=np.int32)
 
@@ -1176,7 +1176,7 @@ class SparseArray(PandasObject, ExtensionArray, ExtensionOpsMixin):
                 taken.fill(fill_value)
                 return taken
             else:
-                raise IndexError("cannot do a non-empty take from an empty " "axes.")
+                raise IndexError("cannot do a non-empty take from an empty axes.")
 
         sp_indexer = self.sp_index.lookup_array(indices)
 
@@ -1226,7 +1226,7 @@ class SparseArray(PandasObject, ExtensionArray, ExtensionOpsMixin):
 
         if (indices.max() >= n) or (indices.min() < -n):
             if n == 0:
-                raise IndexError("cannot do a non-empty take from an " "empty axes.")
+                raise IndexError("cannot do a non-empty take from an empty axes.")
             else:
                 raise IndexError("out of bounds value in 'indices'.")
 
diff --git a/pandas/core/arrays/timedeltas.py b/pandas/core/arrays/timedeltas.py
index 9d622d92e..dd0b9a79c 100644
--- a/pandas/core/arrays/timedeltas.py
+++ b/pandas/core/arrays/timedeltas.py
@@ -290,7 +290,7 @@ class TimedeltaArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps):
 
         periods = dtl.validate_periods(periods)
         if freq is None and any(x is None for x in [periods, start, end]):
-            raise ValueError("Must provide freq argument if no data is " "supplied")
+            raise ValueError("Must provide freq argument if no data is supplied")
 
         if com.count_not_none(start, end, periods, freq) != 3:
             raise ValueError(
@@ -307,7 +307,7 @@ class TimedeltaArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps):
         if start is None and end is None:
             if closed is not None:
                 raise ValueError(
-                    "Closed has to be None if not both of start" "and end are defined"
+                    "Closed has to be None if not both of startand end are defined"
                 )
 
         left_closed, right_closed = dtl.validate_endpoints(closed)
@@ -862,17 +862,17 @@ class TimedeltaArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps):
     seconds = _field_accessor(
         "seconds",
         "seconds",
-        "Number of seconds (>= 0 and less than 1 day) " "for each element.",
+        "Number of seconds (>= 0 and less than 1 day) for each element.",
     )
     microseconds = _field_accessor(
         "microseconds",
         "microseconds",
-        "Number of microseconds (>= 0 and less " "than 1 second) for each element.",
+        "Number of microseconds (>= 0 and less than 1 second) for each element.",
     )
     nanoseconds = _field_accessor(
         "nanoseconds",
         "nanoseconds",
-        "Number of nanoseconds (>= 0 and less " "than 1 microsecond) for each element.",
+        "Number of nanoseconds (>= 0 and less than 1 microsecond) for each element.",
     )
 
     @property
@@ -1131,7 +1131,7 @@ def _generate_regular_range(start, end, periods, offset):
         b = e - periods * stride
     else:
         raise ValueError(
-            "at least 'start' or 'end' should be specified " "if a 'period' is given."
+            "at least 'start' or 'end' should be specified if a 'period' is given."
         )
 
     data = np.arange(b, e, stride, dtype=np.int64)
diff --git a/pandas/core/base.py b/pandas/core/base.py
index ce993a513..cfa8d2521 100644
--- a/pandas/core/base.py
+++ b/pandas/core/base.py
@@ -4,7 +4,7 @@ Base and utility classes for pandas objects.
 import builtins
 from collections import OrderedDict
 import textwrap
-from typing import Optional
+from typing import Dict, Optional
 import warnings
 
 import numpy as np
@@ -37,7 +37,7 @@ from pandas.core.algorithms import duplicated, unique1d, value_counts
 from pandas.core.arrays import ExtensionArray
 import pandas.core.nanops as nanops
 
-_shared_docs = dict()
+_shared_docs = dict()  # type: Dict[str, str]
 _indexops_doc_kwargs = dict(
     klass="IndexOpsMixin",
     inplace="",
@@ -437,7 +437,7 @@ class SelectionMixin:
                 colg = self._gotitem(name, ndim=1, subset=subset)
                 if colg.ndim != 1:
                     raise SpecificationError(
-                        "nested dictionary is ambiguous " "in aggregation"
+                        "nested dictionary is ambiguous in aggregation"
                     )
                 return colg.aggregate(how, _level=(_level or 0) + 1)
 
@@ -634,9 +634,7 @@ class SelectionMixin:
 
             result = Series(results, index=keys, name=self.name)
             if is_nested_object(result):
-                raise ValueError(
-                    "cannot combine transform and " "aggregation operations"
-                )
+                raise ValueError("cannot combine transform and aggregation operations")
             return result
 
     def _shallow_copy(self, obj=None, obj_type=None, **kwargs):
@@ -735,7 +733,7 @@ class IndexOpsMixin:
             The first element of %(klass)s.
         """
         warnings.warn(
-            "`item` has been deprecated and will be removed in a " "future version",
+            "`item` has been deprecated and will be removed in a future version",
             FutureWarning,
             stacklevel=2,
         )
diff --git a/pandas/core/common.py b/pandas/core/common.py
index f9a19291b..c12bfecc4 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -443,7 +443,7 @@ def random_state(state=None):
         return np.random
     else:
         raise ValueError(
-            "random_state must be an integer, a numpy " "RandomState, or None"
+            "random_state must be an integer, a numpy RandomState, or None"
         )
 
 
diff --git a/pandas/core/computation/eval.py b/pandas/core/computation/eval.py
index 456ecf4b2..8614230c4 100644
--- a/pandas/core/computation/eval.py
+++ b/pandas/core/computation/eval.py
@@ -333,7 +333,7 @@ def eval(
                     " if all expressions contain an assignment"
                 )
             elif inplace:
-                raise ValueError("Cannot operate inplace " "if there is no assignment")
+                raise ValueError("Cannot operate inplace if there is no assignment")
 
         # assign if needed
         assigner = parsed_expr.assigner
diff --git a/pandas/core/computation/expr.py b/pandas/core/computation/expr.py
index 772fb5475..e10d189bc 100644
--- a/pandas/core/computation/expr.py
+++ b/pandas/core/computation/expr.py
@@ -296,7 +296,7 @@ def _node_not_implemented(node_name, cls):
 
     def f(self, *args, **kwargs):
         raise NotImplementedError(
-            "{name!r} nodes are not " "implemented".format(name=node_name)
+            "{name!r} nodes are not implemented".format(name=node_name)
         )
 
     return f
@@ -433,7 +433,7 @@ class BaseExprVisitor(ast.NodeVisitor):
                 from keyword import iskeyword
 
                 if any(iskeyword(x) for x in clean.split()):
-                    e.msg = "Python keyword not valid identifier" " in numexpr query"
+                    e.msg = "Python keyword not valid identifier in numexpr query"
                 raise e
 
         method = "visit_" + node.__class__.__name__
@@ -642,9 +642,7 @@ class BaseExprVisitor(ast.NodeVisitor):
         if len(node.targets) != 1:
             raise SyntaxError("can only assign a single expression")
         if not isinstance(node.targets[0], ast.Name):
-            raise SyntaxError(
-                "left hand side of an assignment must be a " "single name"
-            )
+            raise SyntaxError("left hand side of an assignment must be a single name")
         if self.env.target is None:
             raise ValueError("cannot assign without a target object")
 
@@ -656,7 +654,7 @@ class BaseExprVisitor(ast.NodeVisitor):
         self.assigner = getattr(assigner, "name", assigner)
         if self.assigner is None:
             raise SyntaxError(
-                "left hand side of an assignment must be a " "single resolvable name"
+                "left hand side of an assignment must be a single resolvable name"
             )
 
         return self.visit(node.value, **kwargs)
diff --git a/pandas/core/computation/expressions.py b/pandas/core/computation/expressions.py
index ea6146708..d9dc194d4 100644
--- a/pandas/core/computation/expressions.py
+++ b/pandas/core/computation/expressions.py
@@ -197,7 +197,7 @@ def _bool_arith_check(
 
         if op_str in not_allowed:
             raise NotImplementedError(
-                "operator {op!r} not implemented for " "bool dtypes".format(op=op_str)
+                "operator {op!r} not implemented for bool dtypes".format(op=op_str)
             )
     return True
 
diff --git a/pandas/core/computation/ops.py b/pandas/core/computation/ops.py
index 59ed7143e..870acc3cc 100644
--- a/pandas/core/computation/ops.py
+++ b/pandas/core/computation/ops.py
@@ -97,7 +97,7 @@ class Term(StringMixin):
 
         if hasattr(res, "ndim") and res.ndim > 2:
             raise NotImplementedError(
-                "N-dimensional objects, where N > 2," " are not supported with eval"
+                "N-dimensional objects, where N > 2, are not supported with eval"
             )
         return res
 
diff --git a/pandas/core/computation/pytables.py b/pandas/core/computation/pytables.py
index 8ba01670b..60cf35163 100644
--- a/pandas/core/computation/pytables.py
+++ b/pandas/core/computation/pytables.py
@@ -306,7 +306,7 @@ class ConditionBinOp(BinOp):
         #    self.condition = "~(%s)" % self.condition
         # return self
         raise NotImplementedError(
-            "cannot use an invert condition when " "passing to numexpr"
+            "cannot use an invert condition when passing to numexpr"
         )
 
     def format(self):
@@ -474,9 +474,7 @@ def _validate_where(w):
     """
 
     if not (isinstance(w, (Expr, str)) or is_list_like(w)):
-        raise TypeError(
-            "where must be passed as a string, Expr, " "or list-like of Exprs"
-        )
+        raise TypeError("where must be passed as a string, Expr, or list-like of Exprs")
 
     return w
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 33066ccef..5980e3d13 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1173,9 +1173,7 @@ class DataFrame(NDFrame):
                     data, index = list(data.values()), list(data.keys())
         elif orient == "columns":
             if columns is not None:
-                raise ValueError(
-                    "cannot use columns parameter with " "orient='columns'"
-                )
+                raise ValueError("cannot use columns parameter with orient='columns'")
         else:  # pragma: no cover
             raise ValueError("only recognize index or columns for orient")
 
@@ -1327,7 +1325,7 @@ class DataFrame(NDFrame):
         """
         if not self.columns.is_unique:
             warnings.warn(
-                "DataFrame columns are not unique, some " "columns will be omitted.",
+                "DataFrame columns are not unique, some columns will be omitted.",
                 UserWarning,
                 stacklevel=2,
             )
@@ -1808,9 +1806,9 @@ class DataFrame(NDFrame):
                 formats.append(dtype_mapping)
             else:
                 element = "row" if i < index_len else "column"
-                msg = (
-                    "Invalid dtype {dtype} specified for " "{element} {name}"
-                ).format(dtype=dtype_mapping, element=element, name=name)
+                msg = ("Invalid dtype {dtype} specified for {element} {name}").format(
+                    dtype=dtype_mapping, element=element, name=name
+                )
                 raise ValueError(msg)
 
         return np.rec.fromarrays(arrays, dtype={"names": names, "formats": formats})
@@ -2086,9 +2084,7 @@ class DataFrame(NDFrame):
             raise ValueError("Only formats 114 and 117 supported.")
         if version == 114:
             if convert_strl is not None:
-                raise ValueError(
-                    "strl support is only available when using " "format 117"
-                )
+                raise ValueError("strl support is only available when using format 117")
             from pandas.io.stata import StataWriter as statawriter
         else:
             from pandas.io.stata import StataWriter117 as statawriter
@@ -2502,7 +2498,7 @@ class DataFrame(NDFrame):
             # returns size in human readable format
             for x in ["bytes", "KB", "MB", "GB", "TB"]:
                 if num < 1024.0:
-                    return "{num:3.1f}{size_q} " "{x}".format(
+                    return "{num:3.1f}{size_q} {x}".format(
                         num=num, size_q=size_qualifier, x=x
                     )
                 num /= 1024.0
@@ -2887,7 +2883,7 @@ class DataFrame(NDFrame):
         # with all other indexing behavior
         if isinstance(key, Series) and not key.index.equals(self.index):
             warnings.warn(
-                "Boolean Series key will be reindexed to match " "DataFrame index.",
+                "Boolean Series key will be reindexed to match DataFrame index.",
                 UserWarning,
                 stacklevel=3,
             )
@@ -3461,7 +3457,7 @@ class DataFrame(NDFrame):
         selection = tuple(map(frozenset, (include, exclude)))
 
         if not any(selection):
-            raise ValueError("at least one of include or exclude must be " "nonempty")
+            raise ValueError("at least one of include or exclude must be nonempty")
 
         # convert the myriad valid dtypes object to a single representation
         include, exclude = map(
@@ -3654,7 +3650,7 @@ class DataFrame(NDFrame):
 
                     # other
                     raise TypeError(
-                        "incompatible index of inserted column " "with frame index"
+                        "incompatible index of inserted column with frame index"
                     )
             return value
 
@@ -4337,7 +4333,7 @@ class DataFrame(NDFrame):
                     found = col in self.columns
                 except TypeError:
                     raise TypeError(
-                        err_msg + " Received column of " "type {}".format(type(col))
+                        err_msg + " Received column of type {}".format(type(col))
                     )
                 else:
                     if not found:
@@ -5714,9 +5710,7 @@ class DataFrame(NDFrame):
         if join != "left":  # pragma: no cover
             raise NotImplementedError("Only left join is supported")
         if errors not in ["ignore", "raise"]:
-            raise ValueError(
-                "The parameter errors must be either " "'ignore' or 'raise'"
-            )
+            raise ValueError("The parameter errors must be either 'ignore' or 'raise'")
 
         if not isinstance(other, DataFrame):
             other = DataFrame(other)
@@ -7213,7 +7207,7 @@ class DataFrame(NDFrame):
         else:
             if on is not None:
                 raise ValueError(
-                    "Joining multiple DataFrames only supported" " for joining on index"
+                    "Joining multiple DataFrames only supported for joining on index"
                 )
 
             frames = [self] + list(other)
@@ -7374,7 +7368,7 @@ class DataFrame(NDFrame):
             # Dispatch to Series.round
             new_cols = [_series_round(v, decimals) for _, v in self.items()]
         else:
-            raise TypeError("decimals must be an integer, a dict-like or a " "Series")
+            raise TypeError("decimals must be an integer, a dict-like or a Series")
 
         if len(new_cols) > 0:
             return self._constructor(
@@ -8376,11 +8370,11 @@ class DataFrame(NDFrame):
             )
         elif isinstance(values, Series):
             if not values.index.is_unique:
-                raise ValueError("cannot compute isin with " "a duplicate axis.")
+                raise ValueError("cannot compute isin with a duplicate axis.")
             return self.eq(values.reindex_like(self), axis="index")
         elif isinstance(values, DataFrame):
             if not (values.columns.is_unique and values.index.is_unique):
-                raise ValueError("cannot compute isin with " "a duplicate axis.")
+                raise ValueError("cannot compute isin with a duplicate axis.")
             return self.eq(values.reindex_like(self))
         else:
             if not is_list_like(values):
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index df97d34ee..821c35e0c 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -5,6 +5,7 @@ import gc
 import json
 import operator
 import pickle
+import re
 from textwrap import dedent
 from typing import Callable, Dict, FrozenSet, List, Optional, Set
 import warnings
@@ -380,7 +381,7 @@ class NDFrame(PandasObject, SelectionMixin):
                     kwargs[a] = args.pop(0)
                 except IndexError:
                     if require_all:
-                        raise TypeError("not enough/duplicate arguments " "specified!")
+                        raise TypeError("not enough/duplicate arguments specified!")
 
         axes = {a: kwargs.pop(a, sentinel) for a in self._AXIS_ORDERS}
         return axes, kwargs
@@ -1297,7 +1298,7 @@ class NDFrame(PandasObject, SelectionMixin):
             if non_mapper:
                 return self._set_axis_name(mapper, axis=axis, inplace=inplace)
             else:
-                raise ValueError("Use `.rename` to alter labels " "with a mapper.")
+                raise ValueError("Use `.rename` to alter labels with a mapper.")
         else:
             # Use new behavior.  Means that index and/or columns
             # is specified
@@ -3869,16 +3870,14 @@ class NDFrame(PandasObject, SelectionMixin):
 
         if labels is not None:
             if index is not None or columns is not None:
-                raise ValueError(
-                    "Cannot specify both 'labels' and " "'index'/'columns'"
-                )
+                raise ValueError("Cannot specify both 'labels' and 'index'/'columns'")
             axis_name = self._get_axis_name(axis)
             axes = {axis_name: labels}
         elif index is not None or columns is not None:
             axes, _ = self._construct_axes_from_arguments((index, columns), {})
         else:
             raise ValueError(
-                "Need to specify at least one of 'labels', " "'index' or 'columns'"
+                "Need to specify at least one of 'labels', 'index' or 'columns'"
             )
 
         obj = self
@@ -4615,8 +4614,6 @@ class NDFrame(PandasObject, SelectionMixin):
                  one  two  three
         rabbit    4    5      6
         """
-        import re
-
         nkw = com.count_not_none(items, like, regex)
         if nkw > 1:
             raise TypeError(
@@ -4886,7 +4883,7 @@ class NDFrame(PandasObject, SelectionMixin):
                             weights = self[weights]
                         except KeyError:
                             raise KeyError(
-                                "String passed to weights not a " "valid column"
+                                "String passed to weights not a valid column"
                             )
                     else:
                         raise ValueError(
@@ -4904,14 +4901,14 @@ class NDFrame(PandasObject, SelectionMixin):
 
             if len(weights) != axis_length:
                 raise ValueError(
-                    "Weights and axis to be sampled must be of " "same length"
+                    "Weights and axis to be sampled must be of same length"
                 )
 
             if (weights == np.inf).any() or (weights == -np.inf).any():
                 raise ValueError("weight vector may not include `inf` values")
 
             if (weights < 0).any():
-                raise ValueError("weight vector many not include negative " "values")
+                raise ValueError("weight vector many not include negative values")
 
             # If has nan, set to zero.
             weights = weights.fillna(0)
@@ -4933,12 +4930,12 @@ class NDFrame(PandasObject, SelectionMixin):
         elif n is None and frac is not None:
             n = int(round(frac * axis_length))
         elif n is not None and frac is not None:
-            raise ValueError("Please enter a value for `frac` OR `n`, not " "both")
+            raise ValueError("Please enter a value for `frac` OR `n`, not both")
 
         # Check for negative sizes
         if n < 0:
             raise ValueError(
-                "A negative number of rows requested. Please " "provide positive value."
+                "A negative number of rows requested. Please provide positive value."
             )
 
         locs = rs.choice(axis_length, size=n, replace=replace, p=weights)
@@ -5565,7 +5562,7 @@ class NDFrame(PandasObject, SelectionMixin):
         dtype: int64
         """
         warnings.warn(
-            "get_ftype_counts is deprecated and will " "be removed in a future version",
+            "get_ftype_counts is deprecated and will be removed in a future version",
             FutureWarning,
             stacklevel=2,
         )
@@ -5686,7 +5683,7 @@ class NDFrame(PandasObject, SelectionMixin):
         values : a dict of dtype -> Constructor Types
         """
         warnings.warn(
-            "as_blocks is deprecated and will " "be removed in a future version",
+            "as_blocks is deprecated and will be removed in a future version",
             FutureWarning,
             stacklevel=2,
         )
@@ -6598,9 +6595,7 @@ class NDFrame(PandasObject, SelectionMixin):
     ):
         inplace = validate_bool_kwarg(inplace, "inplace")
         if not is_bool(regex) and to_replace is not None:
-            raise AssertionError(
-                "'to_replace' must be 'None' if 'regex' is " "not a bool"
-            )
+            raise AssertionError("'to_replace' must be 'None' if 'regex' is not a bool")
 
         self._consolidate_inplace()
 
@@ -6698,7 +6693,7 @@ class NDFrame(PandasObject, SelectionMixin):
                             convert=convert,
                         )
                 else:
-                    raise TypeError("value argument must be scalar, dict, or " "Series")
+                    raise TypeError("value argument must be scalar, dict, or Series")
 
             elif is_list_like(to_replace):  # [NA, ''] -> [0, 'missing']
                 if is_list_like(value):
@@ -6984,7 +6979,7 @@ class NDFrame(PandasObject, SelectionMixin):
 
         if isinstance(_maybe_transposed_self.index, MultiIndex) and method != "linear":
             raise ValueError(
-                "Only `method=linear` interpolation is supported " "on MultiIndexes."
+                "Only `method=linear` interpolation is supported on MultiIndexes."
             )
 
         if _maybe_transposed_self._data.get_dtype_counts().get("object") == len(
@@ -7146,9 +7141,7 @@ class NDFrame(PandasObject, SelectionMixin):
         2018-02-27 09:04:30   40.0 NaN
         """
         if isinstance(where, str):
-            from pandas import to_datetime
-
-            where = to_datetime(where)
+            where = Timestamp(where)
 
         if not self.index.is_monotonic:
             raise ValueError("asof requires a sorted index")
@@ -7598,7 +7591,7 @@ class NDFrame(PandasObject, SelectionMixin):
         dtype: int64
         """
         warnings.warn(
-            "clip_upper(threshold) is deprecated, " "use clip(upper=threshold) instead",
+            "clip_upper(threshold) is deprecated, use clip(upper=threshold) instead",
             FutureWarning,
             stacklevel=2,
         )
@@ -7717,7 +7710,7 @@ class NDFrame(PandasObject, SelectionMixin):
         2  5  6
         """
         warnings.warn(
-            "clip_lower(threshold) is deprecated, " "use clip(lower=threshold) instead",
+            "clip_lower(threshold) is deprecated, use clip(lower=threshold) instead",
             FutureWarning,
             stacklevel=2,
         )
@@ -8720,12 +8713,10 @@ class NDFrame(PandasObject, SelectionMixin):
         fill_axis=0,
         broadcast_axis=None,
     ):
-        from pandas import DataFrame, Series
-
         method = missing.clean_fill_method(method)
 
         if broadcast_axis == 1 and self.ndim != other.ndim:
-            if isinstance(self, Series):
+            if isinstance(self, ABCSeries):
                 # this means other is a DataFrame, and we need to broadcast
                 # self
                 cons = self._constructor_expanddim
@@ -8743,7 +8734,7 @@ class NDFrame(PandasObject, SelectionMixin):
                     limit=limit,
                     fill_axis=fill_axis,
                 )
-            elif isinstance(other, Series):
+            elif isinstance(other, ABCSeries):
                 # this means self is a DataFrame, and we need to broadcast
                 # other
                 cons = other._constructor_expanddim
@@ -8764,7 +8755,7 @@ class NDFrame(PandasObject, SelectionMixin):
 
         if axis is not None:
             axis = self._get_axis_number(axis)
-        if isinstance(other, DataFrame):
+        if isinstance(other, ABCDataFrame):
             return self._align_frame(
                 other,
                 join=join,
@@ -8776,7 +8767,7 @@ class NDFrame(PandasObject, SelectionMixin):
                 limit=limit,
                 fill_axis=fill_axis,
             )
-        elif isinstance(other, Series):
+        elif isinstance(other, ABCSeries):
             return self._align_series(
                 other,
                 join=join,
@@ -8869,7 +8860,7 @@ class NDFrame(PandasObject, SelectionMixin):
         # series/series compat, other must always be a Series
         if is_series:
             if axis:
-                raise ValueError("cannot align series to a series other than " "axis 0")
+                raise ValueError("cannot align series to a series other than axis 0")
 
             # equal
             if self.index.equals(other.index):
@@ -8959,7 +8950,7 @@ class NDFrame(PandasObject, SelectionMixin):
             if not hasattr(cond, "shape"):
                 cond = np.asanyarray(cond)
             if cond.shape != self.shape:
-                raise ValueError("Array conditional must be same shape as " "self")
+                raise ValueError("Array conditional must be same shape as self")
             cond = self._constructor(cond, **self._construct_axes_dict())
 
         # make sure we are boolean
@@ -8999,7 +8990,7 @@ class NDFrame(PandasObject, SelectionMixin):
             # slice me out of the other
             else:
                 raise NotImplementedError(
-                    "cannot align with a higher " "dimensional NDFrame"
+                    "cannot align with a higher dimensional NDFrame"
                 )
 
         if isinstance(other, np.ndarray):
@@ -9042,12 +9033,12 @@ class NDFrame(PandasObject, SelectionMixin):
 
                     else:
                         raise ValueError(
-                            "Length of replacements must equal " "series length"
+                            "Length of replacements must equal series length"
                         )
 
                 else:
                     raise ValueError(
-                        "other must be the same shape as self " "when an ndarray"
+                        "other must be the same shape as self when an ndarray"
                     )
 
             # we are the same shape, so create an actual object for alignment
@@ -9641,7 +9632,7 @@ class NDFrame(PandasObject, SelectionMixin):
                 if len(ax) > 0:
                     ax_name = self._get_axis_name(axis)
                     raise TypeError(
-                        "%s is not a valid DatetimeIndex or " "PeriodIndex" % ax_name
+                        "%s is not a valid DatetimeIndex or PeriodIndex" % ax_name
                     )
                 else:
                     ax = DatetimeIndex([], tz=tz)
@@ -9805,7 +9796,7 @@ class NDFrame(PandasObject, SelectionMixin):
                 if len(ax) > 0:
                     ax_name = self._get_axis_name(axis)
                     raise TypeError(
-                        "%s is not a valid DatetimeIndex or " "PeriodIndex" % ax_name
+                        "%s is not a valid DatetimeIndex or PeriodIndex" % ax_name
                     )
                 else:
                     ax = DatetimeIndex([], tz=tz)
@@ -10249,7 +10240,7 @@ class NDFrame(PandasObject, SelectionMixin):
         Validate percentiles (used by describe and quantile).
         """
 
-        msg = "percentiles should all be in the interval [0, 1]. " "Try {0} instead."
+        msg = "percentiles should all be in the interval [0, 1]. Try {0} instead."
         q = np.asarray(q)
         if q.ndim == 0:
             if not 0 <= q <= 1:
@@ -10769,7 +10760,7 @@ class NDFrame(PandasObject, SelectionMixin):
     def transform(self, func, *args, **kwargs):
         result = self.agg(func, *args, **kwargs)
         if is_scalar(result) or len(result) != len(self):
-            raise ValueError("transforms cannot produce " "aggregated results")
+            raise ValueError("transforms cannot produce aggregated results")
 
         return result
 
@@ -11669,7 +11660,7 @@ def _make_logical_function(
         if level is not None:
             if bool_only is not None:
                 raise NotImplementedError(
-                    "Option bool_only is not " "implemented with option level."
+                    "Option bool_only is not implemented with option level."
                 )
             return self._agg_by_level(name, axis=axis, level=level, skipna=skipna)
         return self._reduce(
diff --git a/pandas/core/missing.py b/pandas/core/missing.py
index 8f0abc91f..5edf95041 100644
--- a/pandas/core/missing.py
+++ b/pandas/core/missing.py
@@ -119,7 +119,7 @@ def clean_interp_method(method, **kwargs):
         "from_derivatives",
     ]
     if method in ("spline", "polynomial") and order is None:
-        raise ValueError("You must specify the order of the spline or " "polynomial.")
+        raise ValueError("You must specify the order of the spline or polynomial.")
     if method not in valid:
         raise ValueError(
             "method must be one of {valid}. Got '{method}' "
@@ -176,7 +176,7 @@ def interpolate_1d(
     valid_limit_directions = ["forward", "backward", "both"]
     limit_direction = limit_direction.lower()
     if limit_direction not in valid_limit_directions:
-        msg = "Invalid limit_direction: expecting one of {valid!r}, " "got {invalid!r}."
+        msg = "Invalid limit_direction: expecting one of {valid!r}, got {invalid!r}."
         raise ValueError(
             msg.format(valid=valid_limit_directions, invalid=limit_direction)
         )
@@ -322,7 +322,7 @@ def _interpolate_scipy_wrapper(
             alt_methods["pchip"] = interpolate.pchip_interpolate
         except AttributeError:
             raise ImportError(
-                "Your version of Scipy does not support " "PCHIP interpolation."
+                "Your version of Scipy does not support PCHIP interpolation."
             )
     elif method == "akima":
         alt_methods["akima"] = _akima_interpolate
@@ -470,7 +470,7 @@ def interpolate_2d(
     ndim = values.ndim
     if values.ndim == 1:
         if axis != 0:  # pragma: no cover
-            raise AssertionError("cannot interpolate on a ndim == 1 with " "axis != 0")
+            raise AssertionError("cannot interpolate on a ndim == 1 with axis != 0")
         values = values.reshape(tuple((1,) + values.shape))
 
     if fill_value is None:
diff --git a/pandas/core/ops/__init__.py b/pandas/core/ops/__init__.py
index 50da5e405..3a5dfe670 100644
--- a/pandas/core/ops/__init__.py
+++ b/pandas/core/ops/__init__.py
@@ -1139,7 +1139,7 @@ def _comp_method_SERIES(cls, op, special):
             return NotImplemented
 
         elif isinstance(other, ABCSeries) and not self._indexed_same(other):
-            raise ValueError("Can only compare identically-labeled " "Series objects")
+            raise ValueError("Can only compare identically-labeled Series objects")
 
         elif is_categorical_dtype(self):
             # Dispatch to Categorical implementation; pd.CategoricalIndex
@@ -1169,9 +1169,7 @@ def _comp_method_SERIES(cls, op, special):
                 if op in {operator.lt, operator.le, operator.gt, operator.ge}:
                     future = "a TypeError will be raised"
                 else:
-                    future = (
-                        "'the values will not compare equal to the " "'datetime.date'"
-                    )
+                    future = "'the values will not compare equal to the 'datetime.date'"
                 msg = "\n".join(textwrap.wrap(msg.format(future=future)))
                 warnings.warn(msg, FutureWarning, stacklevel=2)
                 other = Timestamp(other)
@@ -1404,9 +1402,7 @@ def _align_method_FRAME(left, right, axis):
     """ convert rhs to meet lhs dims if input is list, tuple or np.ndarray """
 
     def to_series(right):
-        msg = (
-            "Unable to coerce to Series, length must be {req_len}: " "given {given_len}"
-        )
+        msg = "Unable to coerce to Series, length must be {req_len}: given {given_len}"
         if axis is not None and left._get_axis_name(axis) == "index":
             if len(left.index) != len(right):
                 raise ValueError(
@@ -1564,7 +1560,7 @@ def _comp_method_FRAME(cls, func, special):
             # Another DataFrame
             if not self._indexed_same(other):
                 raise ValueError(
-                    "Can only compare identically-labeled " "DataFrame objects"
+                    "Can only compare identically-labeled DataFrame objects"
                 )
             return dispatch_to_series(self, other, func, str_rep)
 
diff --git a/pandas/core/reshape/concat.py b/pandas/core/reshape/concat.py
index ca4175e4a..ce2d2ac41 100644
--- a/pandas/core/reshape/concat.py
+++ b/pandas/core/reshape/concat.py
@@ -290,7 +290,7 @@ class _Concatenator:
             self.intersect = True
         else:  # pragma: no cover
             raise ValueError(
-                "Only can inner (intersect) or outer (union) " "join the other axis"
+                "Only can inner (intersect) or outer (union) join the other axis"
             )
 
         if isinstance(objs, dict):
diff --git a/pandas/core/reshape/melt.py b/pandas/core/reshape/melt.py
index 187a1913c..413132db1 100644
--- a/pandas/core/reshape/melt.py
+++ b/pandas/core/reshape/melt.py
@@ -39,7 +39,7 @@ def melt(
             id_vars = [id_vars]
         elif isinstance(frame.columns, ABCMultiIndex) and not isinstance(id_vars, list):
             raise ValueError(
-                "id_vars must be a list of tuples when columns" " are a MultiIndex"
+                "id_vars must be a list of tuples when columns are a MultiIndex"
             )
         else:
             # Check that `id_vars` are in frame
@@ -61,7 +61,7 @@ def melt(
             value_vars, list
         ):
             raise ValueError(
-                "value_vars must be a list of tuples when" " columns are a MultiIndex"
+                "value_vars must be a list of tuples when columns are a MultiIndex"
             )
         else:
             value_vars = list(value_vars)
diff --git a/pandas/core/reshape/merge.py b/pandas/core/reshape/merge.py
index 5f8801619..fc32a8f0d 100644
--- a/pandas/core/reshape/merge.py
+++ b/pandas/core/reshape/merge.py
@@ -1556,7 +1556,7 @@ class _AsOfMerge(_OrderedMerge):
         # set 'by' columns
         if self.by is not None:
             if self.left_by is not None or self.right_by is not None:
-                raise MergeError("Can only pass by OR left_by " "and right_by")
+                raise MergeError("Can only pass by OR left_by and right_by")
             self.left_by = self.right_by = self.by
         if self.left_by is None and self.right_by is not None:
             raise MergeError("missing left_by")
diff --git a/pandas/core/reshape/reshape.py b/pandas/core/reshape/reshape.py
index 1f519d4c0..0519a1159 100644
--- a/pandas/core/reshape/reshape.py
+++ b/pandas/core/reshape/reshape.py
@@ -133,9 +133,7 @@ class _Unstacker:
         num_cells = np.multiply(num_rows, num_columns, dtype=np.int32)
 
         if num_rows > 0 and num_columns > 0 and num_cells <= 0:
-            raise ValueError(
-                "Unstacked DataFrame is too big, " "causing int32 overflow"
-            )
+            raise ValueError("Unstacked DataFrame is too big, causing int32 overflow")
 
         self._make_sorted_values_labels()
         self._make_selectors()
@@ -176,7 +174,7 @@ class _Unstacker:
         mask.put(selector, True)
 
         if mask.sum() < len(self.index):
-            raise ValueError("Index contains duplicate entries, " "cannot reshape")
+            raise ValueError("Index contains duplicate entries, cannot reshape")
 
         self.group_index = comp_index
         self.mask = mask
diff --git a/pandas/core/reshape/tile.py b/pandas/core/reshape/tile.py
index 0446f5334..d1bdbdf51 100644
--- a/pandas/core/reshape/tile.py
+++ b/pandas/core/reshape/tile.py
@@ -230,7 +230,7 @@ def cut(
         if np.isinf(mn) or np.isinf(mx):
             # GH 24314
             raise ValueError(
-                "cannot specify integer `bins` when input data " "contains infinity"
+                "cannot specify integer `bins` when input data contains infinity"
             )
         elif mn == mx:  # adjust end points before binning
             mn -= 0.001 * abs(mn) if mn != 0 else 0.001
@@ -406,7 +406,7 @@ def _bins_to_cuts(
         else:
             if len(labels) != len(bins) - 1:
                 raise ValueError(
-                    "Bin labels must be one fewer than " "the number of bin edges"
+                    "Bin labels must be one fewer than the number of bin edges"
                 )
         if not is_categorical_dtype(labels):
             labels = Categorical(labels, categories=labels, ordered=True)
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 5ae2bfa03..b445ff5f9 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -2614,9 +2614,7 @@ class Series(base.IndexOpsMixin, generic.NDFrame):
         >>> s.dot(arr)
         array([24, 14])
         """
-        from pandas.core.frame import DataFrame
-
-        if isinstance(other, (Series, DataFrame)):
+        if isinstance(other, (Series, ABCDataFrame)):
             common = self.index.union(other.index)
             if len(common) > len(self.index) or len(common) > len(other.index):
                 raise ValueError("matrices are not aligned")
@@ -2633,7 +2631,7 @@ class Series(base.IndexOpsMixin, generic.NDFrame):
                     "Dot product shape mismatch, %s vs %s" % (lvals.shape, rvals.shape)
                 )
 
-        if isinstance(other, DataFrame):
+        if isinstance(other, ABCDataFrame):
             return self._constructor(
                 np.dot(lvals, rvals), index=other.columns
             ).__finalize__(self)
diff --git a/pandas/core/sorting.py b/pandas/core/sorting.py
index 46e8e97c7..5db31fe66 100644
--- a/pandas/core/sorting.py
+++ b/pandas/core/sorting.py
@@ -436,7 +436,7 @@ def safe_sort(values, labels=None, na_sentinel=-1, assume_unique=False, verify=T
     """
     if not is_list_like(values):
         raise TypeError(
-            "Only list-like objects are allowed to be passed to" "safe_sort as values"
+            "Only list-like objects are allowed to be passed to safe_sort as values"
         )
 
     if not isinstance(values, np.ndarray) and not is_extension_array_dtype(values):
diff --git a/pandas/core/sparse/frame.py b/pandas/core/sparse/frame.py
index f2d3e0012..f5add4262 100644
--- a/pandas/core/sparse/frame.py
+++ b/pandas/core/sparse/frame.py
@@ -425,7 +425,7 @@ class SparseDataFrame(DataFrame):
 
         elif isinstance(value, SparseArray):
             if len(value) != len(self.index):
-                raise ValueError("Length of values does not match " "length of index")
+                raise ValueError("Length of values does not match length of index")
             clean = value
 
         elif hasattr(value, "__iter__"):
@@ -435,9 +435,7 @@ class SparseDataFrame(DataFrame):
                     clean = sp_maker(clean)
             else:
                 if len(value) != len(self.index):
-                    raise ValueError(
-                        "Length of values does not match " "length of index"
-                    )
+                    raise ValueError("Length of values does not match length of index")
                 clean = sp_maker(value)
 
         # Scalar
@@ -732,7 +730,7 @@ class SparseDataFrame(DataFrame):
 
         if method is not None or limit is not None:
             raise NotImplementedError(
-                "cannot reindex with a method or limit " "with sparse"
+                "cannot reindex with a method or limit with sparse"
             )
 
         if fill_value is None:
@@ -765,9 +763,7 @@ class SparseDataFrame(DataFrame):
         self, other, on=None, how="left", lsuffix="", rsuffix="", sort=False
     ):
         if on is not None:
-            raise NotImplementedError(
-                "'on' keyword parameter is not yet " "implemented"
-            )
+            raise NotImplementedError("'on' keyword parameter is not yet implemented")
         return self._join_index(other, how, lsuffix, rsuffix)
 
     def _join_index(self, other, how, lsuffix, rsuffix):
diff --git a/pandas/core/sparse/scipy_sparse.py b/pandas/core/sparse/scipy_sparse.py
index 73638f596..e8d8996fd 100644
--- a/pandas/core/sparse/scipy_sparse.py
+++ b/pandas/core/sparse/scipy_sparse.py
@@ -99,7 +99,7 @@ def _sparse_series_to_coo(ss, row_levels=(0,), column_levels=(1,), sort_labels=F
         raise ValueError("to_coo requires MultiIndex with nlevels > 2")
     if not ss.index.is_unique:
         raise ValueError(
-            "Duplicate index entries are not allowed in to_coo " "transformation."
+            "Duplicate index entries are not allowed in to_coo transformation."
         )
 
     # to keep things simple, only rely on integer indexing (not labels)
diff --git a/pandas/core/sparse/series.py b/pandas/core/sparse/series.py
index 5eb9cfbd0..0c417133b 100644
--- a/pandas/core/sparse/series.py
+++ b/pandas/core/sparse/series.py
@@ -590,7 +590,7 @@ class SparseSeries(Series):
         dense_valid = self.to_dense().dropna()
         if inplace:
             raise NotImplementedError(
-                "Cannot perform inplace dropna" " operations on a SparseSeries"
+                "Cannot perform inplace dropna operations on a SparseSeries"
             )
         if isna(self.fill_value):
             return dense_valid
diff --git a/pandas/core/strings.py b/pandas/core/strings.py
index ad8226e56..54882d039 100644
--- a/pandas/core/strings.py
+++ b/pandas/core/strings.py
@@ -603,7 +603,7 @@ def str_replace(arr, pat, repl, n=-1, case=None, flags=0, regex=True):
         if is_compiled_re:
             if (case is not None) or (flags != 0):
                 raise ValueError(
-                    "case and flags cannot be set" " when pat is a compiled regex"
+                    "case and flags cannot be set when pat is a compiled regex"
                 )
         else:
             # not a compiled regex
@@ -623,10 +623,10 @@ def str_replace(arr, pat, repl, n=-1, case=None, flags=0, regex=True):
     else:
         if is_compiled_re:
             raise ValueError(
-                "Cannot use a compiled regex as replacement " "pattern with regex=False"
+                "Cannot use a compiled regex as replacement pattern with regex=False"
             )
         if callable(repl):
-            raise ValueError("Cannot use a callable replacement when " "regex=False")
+            raise ValueError("Cannot use a callable replacement when regex=False")
         f = lambda x: x.replace(pat, repl, n)
 
     return _na_map(f, arr)
@@ -1944,7 +1944,7 @@ class StringMethods(NoNewAttributesMixin):
         """
         if isinstance(data, ABCMultiIndex):
             raise AttributeError(
-                "Can only use .str accessor with Index, " "not MultiIndex"
+                "Can only use .str accessor with Index, not MultiIndex"
             )
 
         # see _libs/lib.pyx for list of inferred types
@@ -1957,7 +1957,7 @@ class StringMethods(NoNewAttributesMixin):
         inferred_dtype = lib.infer_dtype(values, skipna=True)
 
         if inferred_dtype not in allowed_types:
-            raise AttributeError("Can only use .str accessor with string " "values!")
+            raise AttributeError("Can only use .str accessor with string values!")
         return inferred_dtype
 
     def __getitem__(self, key):
@@ -2653,7 +2653,7 @@ class StringMethods(NoNewAttributesMixin):
             "side": "first",
             "return": "3 elements containing the string itself, followed by two "
             "empty strings",
-            "also": "rpartition : Split the string at the last occurrence of " "`sep`.",
+            "also": "rpartition : Split the string at the last occurrence of `sep`.",
         }
     )
     @deprecate_kwarg(old_arg_name="pat", new_arg_name="sep")
@@ -2669,7 +2669,7 @@ class StringMethods(NoNewAttributesMixin):
             "side": "last",
             "return": "3 elements containing two empty strings, followed by the "
             "string itself",
-            "also": "partition : Split the string at the first occurrence of " "`sep`.",
+            "also": "partition : Split the string at the first occurrence of `sep`.",
         }
     )
     @deprecate_kwarg(old_arg_name="pat", new_arg_name="sep")
diff --git a/pandas/core/tools/datetimes.py b/pandas/core/tools/datetimes.py
index 20c4b9422..172084e97 100644
--- a/pandas/core/tools/datetimes.py
+++ b/pandas/core/tools/datetimes.py
@@ -365,7 +365,7 @@ def _convert_listlike_datetimes(
         return result
     elif getattr(arg, "ndim", 1) > 1:
         raise TypeError(
-            "arg must be a string, datetime, list, tuple, " "1-d array, or Series"
+            "arg must be a string, datetime, list, tuple, 1-d array, or Series"
         )
 
     # warn if passing timedelta64, raise for PeriodDtype
@@ -402,9 +402,7 @@ def _convert_listlike_datetimes(
                     orig_arg = ensure_object(orig_arg)
                     result = _attempt_YYYYMMDD(orig_arg, errors=errors)
                 except (ValueError, TypeError, tslibs.OutOfBoundsDatetime):
-                    raise ValueError(
-                        "cannot convert the input to " "'%Y%m%d' date format"
-                    )
+                    raise ValueError("cannot convert the input to '%Y%m%d' date format")
 
             # fallback
             if result is None:
@@ -503,7 +501,7 @@ def _adjust_to_origin(arg, origin, unit):
         try:
             arg = arg - j0
         except TypeError:
-            raise ValueError("incompatible 'arg' type for given " "'origin'='julian'")
+            raise ValueError("incompatible 'arg' type for given 'origin'='julian'")
 
         # preemptively check this for a nice range
         j_max = Timestamp.max.to_julian_date() - j0
@@ -897,7 +895,7 @@ def _assemble_from_unit_mappings(arg, errors, box, tz):
     try:
         values = to_datetime(values, format="%Y%m%d", errors=errors, utc=tz)
     except (TypeError, ValueError) as e:
-        raise ValueError("cannot assemble the " "datetimes: {error}".format(error=e))
+        raise ValueError("cannot assemble the datetimes: {error}".format(error=e))
 
     for u in ["h", "m", "s", "ms", "us", "ns"]:
         value = unit_rev.get(u)
@@ -1029,7 +1027,7 @@ def to_time(arg, format=None, infer_time_format=False, errors="raise"):
 
         elif getattr(arg, "ndim", 1) > 1:
             raise TypeError(
-                "arg must be a string, datetime, list, tuple, " "1-d array, or Series"
+                "arg must be a string, datetime, list, tuple, 1-d array, or Series"
             )
 
         arg = ensure_object(arg)
@@ -1074,7 +1072,7 @@ def to_time(arg, format=None, infer_time_format=False, errors="raise"):
                     times.append(time_object)
                 elif errors == "raise":
                     raise ValueError(
-                        "Cannot convert arg {arg} to " "a time".format(arg=arg)
+                        "Cannot convert arg {arg} to a time".format(arg=arg)
                     )
                 elif errors == "ignore":
                     return arg
diff --git a/pandas/core/tools/timedeltas.py b/pandas/core/tools/timedeltas.py
index 2c594a3df..cc3131798 100644
--- a/pandas/core/tools/timedeltas.py
+++ b/pandas/core/tools/timedeltas.py
@@ -97,11 +97,11 @@ def to_timedelta(arg, unit="ns", box=True, errors="raise"):
     unit = parse_timedelta_unit(unit)
 
     if errors not in ("ignore", "raise", "coerce"):
-        raise ValueError("errors must be one of 'ignore', " "'raise', or 'coerce'}")
+        raise ValueError("errors must be one of 'ignore', 'raise', or 'coerce'}")
 
     if unit in {"Y", "y", "M"}:
         warnings.warn(
-            "M and Y units are deprecated and " "will be removed in a future version.",
+            "M and Y units are deprecated and will be removed in a future version.",
             FutureWarning,
             stacklevel=2,
         )
@@ -120,7 +120,7 @@ def to_timedelta(arg, unit="ns", box=True, errors="raise"):
         return _convert_listlike(arg, unit=unit, box=box, errors=errors)
     elif getattr(arg, "ndim", 1) > 1:
         raise TypeError(
-            "arg must be a string, timedelta, list, tuple, " "1-d array, or Series"
+            "arg must be a string, timedelta, list, tuple, 1-d array, or Series"
         )
 
     # ...so it must be a scalar value. Return scalar.
diff --git a/pandas/core/window.py b/pandas/core/window.py
index 4721d6cfc..323eba36e 100644
--- a/pandas/core/window.py
+++ b/pandas/core/window.py
@@ -120,7 +120,7 @@ class _Window(PandasObject, SelectionMixin):
             "left",
             "neither",
         ]:
-            raise ValueError("closed must be 'right', 'left', 'both' or " "'neither'")
+            raise ValueError("closed must be 'right', 'left', 'both' or 'neither'")
 
     def _create_blocks(self):
         """
@@ -232,9 +232,7 @@ class _Window(PandasObject, SelectionMixin):
             try:
                 values = ensure_float64(values)
             except (ValueError, TypeError):
-                raise TypeError(
-                    "cannot handle this type -> {0}" "".format(values.dtype)
-                )
+                raise TypeError("cannot handle this type -> {0}".format(values.dtype))
 
         # Always convert inf to nan
         values[np.isinf(values)] = np.NaN
@@ -327,9 +325,7 @@ class _Window(PandasObject, SelectionMixin):
         Center the result in the window.
         """
         if self.axis > result.ndim - 1:
-            raise ValueError(
-                "Requested axis is larger then no. of argument " "dimensions"
-            )
+            raise ValueError("Requested axis is larger then no. of argument dimensions")
 
         offset = _offset(window, True)
         if offset > 0:
@@ -1734,7 +1730,7 @@ class Rolling(_Rolling_and_Expanding):
 
         if not self.is_datetimelike and self.closed is not None:
             raise ValueError(
-                "closed only implemented for datetimelike " "and offset based windows"
+                "closed only implemented for datetimelike and offset based windows"
             )
 
     def _validate_monotonic(self):
@@ -1743,7 +1739,7 @@ class Rolling(_Rolling_and_Expanding):
         """
         if not self._on.is_monotonic:
             formatted = self.on or "index"
-            raise ValueError("{0} must be " "monotonic".format(formatted))
+            raise ValueError("{0} must be monotonic".format(formatted))
 
     def _validate_freq(self):
         """
@@ -2738,7 +2734,7 @@ def _flex_binary_moment(arg1, arg2, f, pairwise=False):
 def _get_center_of_mass(comass, span, halflife, alpha):
     valid_count = com.count_not_none(comass, span, halflife, alpha)
     if valid_count > 1:
-        raise ValueError("comass, span, halflife, and alpha " "are mutually exclusive")
+        raise ValueError("comass, span, halflife, and alpha are mutually exclusive")
 
     # Convert to center of mass; domain checks ensure 0 < alpha <= 1
     if comass is not None:
