commit 17486b27defa32b6d195781009a38781abbb8c22
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Thu Aug 25 13:36:46 2011 -0400

    DOC: docstring edits and misc test coverage

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 08d731ded..20c3ebe1b 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -368,7 +368,7 @@ class DataFrame(NDFrame):
         if not data.dtype.names:
             raise Exception('Input was not a structured array!')
 
-        if indexField is not None:
+        if indexField is not None:  # pragma: no cover
             warnings.warn("indexField argument is deprecated. Use index "
                           "instead", FutureWarning)
             index = indexField
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index b6776684a..0ffe717ac 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -1074,7 +1074,7 @@ class WidePanelGroupBy(GroupBy):
 class NDArrayGroupBy(GroupBy):
     pass
 
-#-------------------------------------------------------------------------------
+#----------------------------------------------------------------------
 # Grouping generator for BlockManager
 
 def generate_groups(data, label_list, shape, axis=0, factory=lambda x: x):
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 0df00e363..85e6a4fa0 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -13,14 +13,13 @@ from pandas.core.index import Index
 from pandas.core.frame import DataFrame
 
 def read_csv(filepath_or_buffer, header=0, skiprows=None, index_col=0,
-             na_values=None, date_parser=None):
+             na_values=None, date_parser=None, names=None):
     """
     Read CSV file into DataFrame
 
     Parameters
     ----------
     filepath_or_buffer : string or file handle / StringIO
-
     header : int, default 0
         Row to use for the column labels of the parsed DataFrame
     skiprows : list-like
@@ -33,6 +32,12 @@ def read_csv(filepath_or_buffer, header=0, skiprows=None, index_col=0,
     date_parser : function
         Function to use for converting dates to strings. Defaults to
         dateutil.parser
+    names : array-like
+        List of column names
+
+    Returns
+    -------
+    parsed : DataFrame
     """
     import csv
 
@@ -54,7 +59,8 @@ def read_csv(filepath_or_buffer, header=0, skiprows=None, index_col=0,
         lines = [l for l in reader]
     f.close()
     return _simple_parser(lines, header=header, indexCol=index_col,
-                          na_values=na_values, date_parser=date_parser)
+                          colNames=names, na_values=na_values,
+                          date_parser=date_parser)
 
 def read_table(filepath_or_buffer, sep='\t', header=0, skiprows=None,
                index_col=0, na_values=None, names=None,
@@ -79,6 +85,12 @@ def read_table(filepath_or_buffer, sep='\t', header=0, skiprows=None,
     date_parser : function
         Function to use for converting dates to strings. Defaults to
         dateutil.parser
+    names : array-like
+        List of column names
+
+    Returns
+    -------
+    parsed : DataFrame
     """
     if hasattr(filepath_or_buffer, 'read'):
         reader = filepath_or_buffer
@@ -276,6 +288,10 @@ class ExcelFile(object):
             is no such column
         na_values : list-like, default None
             List of additional strings to recognize as NA/NaN
+
+        Returns
+        -------
+        parsed : DataFrame
         """
         from datetime import MINYEAR, time, datetime
         from xlrd import xldate_as_tuple, XL_CELL_DATE
diff --git a/pandas/stats/interface.py b/pandas/stats/interface.py
index 7fb1962de..796d8b967 100644
--- a/pandas/stats/interface.py
+++ b/pandas/stats/interface.py
@@ -9,11 +9,21 @@ def ols(**kwargs):
     """Returns the appropriate OLS object depending on whether you need
     simple or panel OLS, and a full-sample or rolling/expanding OLS.
 
+    Will be a normal linear regression or a (pooled) panel regression depending
+    on the type of the inputs:
+
+    y : Series, x : DataFrame -> OLS
+    y : Series, x : dict of DataFrame -> OLS
+    y : DataFrame, x : DataFrame -> PanelOLS
+    y : DataFrame, x : dict of DataFrame/WidePanel/LongPanel -> PanelOLS
+    y : Series with MultiIndex, x : WidePanel/LongPanel -> PanelOLS
+
     Parameters
     ----------
-    y: Series for simple OLS.  DataFrame for panel OLS.
-    x: Series, DataFrame, or dict of Series for simple OLS.
-       Dict of DataFrame for panel OLS.
+    y: Series or DataFrame
+        See above for types
+    x: Series, DataFrame, dict of Series, dict of DataFrame, WidePanel, or
+        LongPanel
     intercept: bool
         True if you want an intercept.  Defaults to True.
     nw_lags: None or int
@@ -48,11 +58,6 @@ def ols(**kwargs):
         cluster: {'time', 'entity'}
             cluster variances
 
-    Returns
-    -------
-    The appropriate OLS object, which allows you to obtain betas and various
-    statistics, such as std err, t-stat, etc.
-
     Examples
     --------
     # Run simple OLS.
@@ -73,6 +78,11 @@ def ols(**kwargs):
 
     # Run expanding panel OLS with window 10 and entity clustering.
     result = ols(y=y, x=x, cluster='entity', window_type='expanding', window=10)
+
+    Returns
+    -------
+    The appropriate OLS object, which allows you to obtain betas and various
+    statistics, such as std err, t-stat, etc.
     """
     pool = kwargs.get('pool')
     if 'pool' in kwargs:
diff --git a/pandas/stats/moments.py b/pandas/stats/moments.py
index 1766fc509..763bef8b3 100644
--- a/pandas/stats/moments.py
+++ b/pandas/stats/moments.py
@@ -26,6 +26,10 @@ def rolling_count(arg, window, time_rule=None):
     ----------
     arg :  DataFrame or numpy ndarray-like
     window : Number of observations used for calculating statistic
+
+    Returns
+    -------
+    rolling_count : type of caller
     """
     arg = _conv_timerule(arg, time_rule)
     window = min(window, len(arg))
@@ -374,13 +378,3 @@ def rolling_apply(arg, window, func, min_periods=None, time_rule=None):
         return _tseries.roll_generic(arg, window, minp, func)
     return _rolling_moment(arg, window, call_cython, min_periods,
                            time_rule=time_rule)
-
-# def rolling_apply_frame(frame, window, func):
-#     """
-
-#     """
-#     n = len(frame)
-#     output = np.empty(n, dtype=float)
-#     for i in (n):
-#         output[i] = func(frame[max(i - window + 1, 0) : i + 1])
-#     return output
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index 43638da47..8cf20b7e3 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -20,12 +20,12 @@ _FP_ERR = 1e-8
 
 class OLS(object):
     """
-    Runs a full sample ordinary least squares regression
+    Runs a full sample ordinary least squares regression.
 
     Parameters
     ----------
     y: Series
-    x: Series, DataFrame, or dict of Series
+    x: Series, DataFrame, dict of Series
     intercept: bool
         True if you want an intercept.
     nw_lags: None or int
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 5a1f60973..6cdb5634d 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -966,14 +966,18 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
             for k2, v2 in v.iteritems():
                 self.assertEqual(v2, recons_data[k][k2])
 
-    def test_from_records(self):
+    def test_from_records_to_records(self):
         # from numpy documentation
         arr = np.zeros((2,),dtype=('i4,f4,a10'))
         arr[:] = [(1,2.,'Hello'),(2,3.,"World")]
 
         frame = DataFrame.from_records(arr)
-        indexed_frame = DataFrame.from_records(arr, index='f1')
 
+        index = np.arange(len(arr))[::-1]
+        indexed_frame = DataFrame.from_records(arr, index=index)
+        self.assert_(np.array_equal(indexed_frame.index, index))
+
+        indexed_frame = DataFrame.from_records(arr, index='f1')
         self.assertRaises(Exception, DataFrame.from_records, np.zeros((2, 3)))
 
         # what to do?
diff --git a/pandas/tests/test_index.py b/pandas/tests/test_index.py
index 3176a0d60..2495353c8 100644
--- a/pandas/tests/test_index.py
+++ b/pandas/tests/test_index.py
@@ -605,6 +605,11 @@ class TestMultiIndex(unittest.TestCase):
         self.assertRaises(TypeError, self.index.intersection,
                           self.index.get_tuple_index())
 
+    def test_argsort(self):
+        result = self.index.argsort()
+        expected = self.index.get_tuple_index().argsort()
+        self.assert_(np.array_equal(result, expected))
+
     def test_sortlevel(self):
         import random
 
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index 8d9555470..769817c49 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -675,11 +675,6 @@ class TestSeries(unittest.TestCase):
         ordered = ts.order(ascending=False, na_last=False)
         assert_almost_equal(expected, ordered.valid().values)
 
-    def test_map(self):
-        result = self.ts.map(lambda x: x * 2)
-
-        self.assert_(np.array_equal(result, self.ts * 2))
-
     def test_to_csv(self):
         self.ts.to_csv('_foo')
         os.remove('_foo')
@@ -817,6 +812,10 @@ class TestSeries(unittest.TestCase):
         for k, v in merged.iteritems():
             self.assertEqual(v, source[target[k]])
 
+        # function
+        result = self.ts.map(lambda x: x * 2)
+        self.assert_(np.array_equal(result, self.ts * 2))
+
     def test_map_int(self):
         left = Series({'a' : 1., 'b' : 2., 'c' : 3., 'd' : 4})
         right = Series({1 : 11, 2 : 22, 3 : 33})
diff --git a/pandas/tests/test_sparse.py b/pandas/tests/test_sparse.py
index fdfec2cf9..9e1f1df61 100644
--- a/pandas/tests/test_sparse.py
+++ b/pandas/tests/test_sparse.py
@@ -945,7 +945,7 @@ class TestSparseDataFrame(TestCase):
         self.assert_(isinstance(result, SparseDataFrame))
 
     def test_astype(self):
-        pass
+        self.assertRaises(Exception, self.frame.astype, np.int_)
 
     def test_fillna(self):
         self.assertRaises(NotImplementedError, self.frame.fillna, 0)
