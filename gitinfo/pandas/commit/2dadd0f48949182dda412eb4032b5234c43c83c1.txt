commit 2dadd0f48949182dda412eb4032b5234c43c83c1
Author: rebecca-palmer <rebecca_palmer@zoho.com>
Date:   Fri Jan 24 03:55:08 2020 +0000

    Use https for links where available (#31145)

diff --git a/.github/CODE_OF_CONDUCT.md b/.github/CODE_OF_CONDUCT.md
index a1fbece32..7dd2e0424 100644
--- a/.github/CODE_OF_CONDUCT.md
+++ b/.github/CODE_OF_CONDUCT.md
@@ -54,10 +54,10 @@ incident.
 
 This Code of Conduct is adapted from the [Contributor Covenant][homepage],
 version 1.3.0, available at
-[http://contributor-covenant.org/version/1/3/0/][version],
+[https://www.contributor-covenant.org/version/1/3/0/][version],
 and the [Swift Code of Conduct][swift].
 
-[homepage]: http://contributor-covenant.org
-[version]: http://contributor-covenant.org/version/1/3/0/
+[homepage]: https://www.contributor-covenant.org
+[version]: https://www.contributor-covenant.org/version/1/3/0/
 [swift]: https://swift.org/community/#code-of-conduct
 
diff --git a/.github/CONTRIBUTING.md b/.github/CONTRIBUTING.md
index 2e6e98024..bc31d3621 100644
--- a/.github/CONTRIBUTING.md
+++ b/.github/CONTRIBUTING.md
@@ -16,7 +16,7 @@ If you notice a bug in the code or documentation, or have suggestions for how we
 
 ## Contributing to the Codebase
 
-The code is hosted on [GitHub](https://www.github.com/pandas-dev/pandas), so you will need to use [Git](http://git-scm.com/) to clone the project and make changes to the codebase. Once you have obtained a copy of the code, you should create a development environment that is separate from your existing Python environment so that you can make and test changes without compromising your own work environment. For more information, please refer to the "[Working with the code](https://github.com/pandas-dev/pandas/blob/master/doc/source/development/contributing.rst#working-with-the-code)" section.
+The code is hosted on [GitHub](https://www.github.com/pandas-dev/pandas), so you will need to use [Git](https://git-scm.com/) to clone the project and make changes to the codebase. Once you have obtained a copy of the code, you should create a development environment that is separate from your existing Python environment so that you can make and test changes without compromising your own work environment. For more information, please refer to the "[Working with the code](https://github.com/pandas-dev/pandas/blob/master/doc/source/development/contributing.rst#working-with-the-code)" section.
 
 Before submitting your changes for review, make sure to check that your changes do not break any tests. You can find more information about our test suites in the "[Test-driven development/code writing](https://github.com/pandas-dev/pandas/blob/master/doc/source/development/contributing.rst#test-driven-development-code-writing)" section. We also have guidelines regarding coding style that will be enforced during testing, which can be found in the "[Code standards](https://github.com/pandas-dev/pandas/blob/master/doc/source/development/contributing.rst#code-standards)" section.
 
diff --git a/AUTHORS.md b/AUTHORS.md
index dcaaea101..f576e333f 100644
--- a/AUTHORS.md
+++ b/AUTHORS.md
@@ -14,7 +14,7 @@ About the Copyright Holders
     The PyData Development Team is the collection of developers of the PyData
     project. This includes all of the PyData sub-projects, including pandas. The
     core team that coordinates development on GitHub can be found here:
-    http://github.com/pydata.
+    https://github.com/pydata.
 
 Full credits for pandas contributors can be found in the documentation.
 
diff --git a/RELEASE.md b/RELEASE.md
index 7924ffaff..42cb82dfc 100644
--- a/RELEASE.md
+++ b/RELEASE.md
@@ -3,4 +3,4 @@ Release Notes
 
 The list of changes to Pandas between each release can be found
 [here](https://pandas.pydata.org/pandas-docs/stable/whatsnew/index.html). For full
-details, see the commit logs at http://github.com/pandas-dev/pandas.
+details, see the commit logs at https://github.com/pandas-dev/pandas.
diff --git a/asv_bench/benchmarks/pandas_vb_common.py b/asv_bench/benchmarks/pandas_vb_common.py
index 6da2b2270..fd1770df8 100644
--- a/asv_bench/benchmarks/pandas_vb_common.py
+++ b/asv_bench/benchmarks/pandas_vb_common.py
@@ -56,7 +56,7 @@ except AttributeError:
 def setup(*args, **kwargs):
     # This function just needs to be imported into each benchmark file to
     # set up the random seed before each function.
-    # http://asv.readthedocs.io/en/latest/writing_benchmarks.html
+    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html
     np.random.seed(1234)
 
 
diff --git a/doc/cheatsheet/README.txt b/doc/cheatsheet/README.txt
index 0eae39f31..c57da38b3 100644
--- a/doc/cheatsheet/README.txt
+++ b/doc/cheatsheet/README.txt
@@ -5,4 +5,4 @@ and pick "PDF" as the format.
 This cheat sheet was inspired by the RStudio Data Wrangling Cheatsheet[1], written by Irv Lustig, Princeton Consultants[2].
 
 [1]: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf
-[2]: http://www.princetonoptimization.com/
+[2]: https://www.princetonoptimization.com/
diff --git a/doc/source/conf.py b/doc/source/conf.py
index 7f24d02a4..57c1bede9 100644
--- a/doc/source/conf.py
+++ b/doc/source/conf.py
@@ -408,7 +408,7 @@ if pattern is None:
         "py": ("https://pylib.readthedocs.io/en/latest/", None),
         "python": ("https://docs.python.org/3/", None),
         "scipy": ("https://docs.scipy.org/doc/scipy/reference/", None),
-        "statsmodels": ("http://www.statsmodels.org/devel/", None),
+        "statsmodels": ("https://www.statsmodels.org/devel/", None),
     }
 
 # extlinks alias
@@ -625,10 +625,10 @@ def linkcode_resolve(domain, info):
     fn = os.path.relpath(fn, start=os.path.dirname(pandas.__file__))
 
     if "+" in pandas.__version__:
-        return f"http://github.com/pandas-dev/pandas/blob/master/pandas/{fn}{linespec}"
+        return f"https://github.com/pandas-dev/pandas/blob/master/pandas/{fn}{linespec}"
     else:
         return (
-            f"http://github.com/pandas-dev/pandas/blob/"
+            f"https://github.com/pandas-dev/pandas/blob/"
             f"v{pandas.__version__}/pandas/{fn}{linespec}"
         )
 
@@ -695,7 +695,7 @@ def rstjinja(app, docname, source):
     """
     Render our pages as a jinja template for fancy templating goodness.
     """
-    # http://ericholscher.com/blog/2016/jul/25/integrating-jinja-rst-sphinx/
+    # https://www.ericholscher.com/blog/2016/jul/25/integrating-jinja-rst-sphinx/
     # Make sure we're outputting HTML
     if app.builder.format != "html":
         return
diff --git a/doc/source/development/contributing.rst b/doc/source/development/contributing.rst
index b650b2a2c..9599dc5bd 100644
--- a/doc/source/development/contributing.rst
+++ b/doc/source/development/contributing.rst
@@ -56,7 +56,7 @@ Bug reports and enhancement requests
 Bug reports are an important part of making *pandas* more stable. Having a complete bug report
 will allow others to reproduce the bug and provide insight into fixing. See
 `this stackoverflow article <https://stackoverflow.com/help/mcve>`_ and
-`this blogpost <http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>`_
+`this blogpost <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>`_
 for tips on writing a good bug report.
 
 Trying the bug-producing code out on the *master* branch is often a worthwhile exercise
@@ -67,7 +67,7 @@ Bug reports must:
 
 #. Include a short, self-contained Python snippet reproducing the problem.
    You can format the code nicely by using `GitHub Flavored Markdown
-   <http://github.github.com/github-flavored-markdown/>`_::
+   <https://github.github.com/github-flavored-markdown/>`_::
 
       ```python
       >>> from pandas import DataFrame
@@ -104,19 +104,19 @@ feel free to ask for help.
 
 The code is hosted on `GitHub <https://www.github.com/pandas-dev/pandas>`_. To
 contribute you will need to sign up for a `free GitHub account
-<https://github.com/signup/free>`_. We use `Git <http://git-scm.com/>`_ for
+<https://github.com/signup/free>`_. We use `Git <https://git-scm.com/>`_ for
 version control to allow many people to work together on the project.
 
 Some great resources for learning Git:
 
-* the `GitHub help pages <http://help.github.com/>`_.
-* the `NumPy's documentation <http://docs.scipy.org/doc/numpy/dev/index.html>`_.
-* Matthew Brett's `Pydagogue <http://matthew-brett.github.com/pydagogue/>`_.
+* the `GitHub help pages <https://help.github.com/>`_.
+* the `NumPy's documentation <https://docs.scipy.org/doc/numpy/dev/index.html>`_.
+* Matthew Brett's `Pydagogue <https://matthew-brett.github.com/pydagogue/>`_.
 
 Getting started with Git
 ------------------------
 
-`GitHub has instructions <http://help.github.com/set-up-git-redirect>`__ for installing git,
+`GitHub has instructions <https://help.github.com/set-up-git-redirect>`__ for installing git,
 setting up your SSH key, and configuring git.  All these steps need to be completed before
 you can work seamlessly between your local repository and GitHub.
 
@@ -260,7 +260,7 @@ To return to your root environment::
 
       conda deactivate
 
-See the full conda docs `here <http://conda.pydata.org/docs>`__.
+See the full conda docs `here <https://conda.pydata.org/docs>`__.
 
 .. _contributing.pip:
 
@@ -365,7 +365,7 @@ About the *pandas* documentation
 --------------------------------
 
 The documentation is written in **reStructuredText**, which is almost like writing
-in plain English, and built using `Sphinx <http://www.sphinx-doc.org/en/master/>`__. The
+in plain English, and built using `Sphinx <https://www.sphinx-doc.org/en/master/>`__. The
 Sphinx Documentation has an excellent `introduction to reST
 <https://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html>`__. Review the Sphinx docs to perform more
 complex changes to the documentation as well.
@@ -390,7 +390,7 @@ Some other important things to know about the docs:
      contributing_docstring.rst
 
 * The tutorials make heavy use of the `ipython directive
-  <http://matplotlib.org/sampledoc/ipython_directive.html>`_ sphinx extension.
+  <https://matplotlib.org/sampledoc/ipython_directive.html>`_ sphinx extension.
   This directive lets you put code in the documentation which will be run
   during the doc build. For example::
 
@@ -436,7 +436,7 @@ Some other important things to know about the docs:
     The ``.rst`` files are used to automatically generate Markdown and HTML versions
     of the docs. For this reason, please do not edit ``CONTRIBUTING.md`` directly,
     but instead make any changes to ``doc/source/development/contributing.rst``. Then, to
-    generate ``CONTRIBUTING.md``, use `pandoc <http://johnmacfarlane.net/pandoc/>`_
+    generate ``CONTRIBUTING.md``, use `pandoc <https://johnmacfarlane.net/pandoc/>`_
     with the following command::
 
       pandoc doc/source/development/contributing.rst -t markdown_github > CONTRIBUTING.md
@@ -620,8 +620,8 @@ You can also run this command on an entire directory if necessary::
    cpplint --extensions=c,h --headers=h --filter=-readability/casting,-runtime/int,-build/include_subdir --recursive modified-c-directory
 
 To make your commits compliant with this standard, you can install the
-`ClangFormat <http://clang.llvm.org/docs/ClangFormat.html>`_ tool, which can be
-downloaded `here <http://llvm.org/builds/>`__. To configure, in your home directory,
+`ClangFormat <https://clang.llvm.org/docs/ClangFormat.html>`_ tool, which can be
+downloaded `here <https://llvm.org/builds/>`__. To configure, in your home directory,
 run the following command::
 
     clang-format style=google -dump-config  > .clang-format
@@ -651,7 +651,7 @@ fixes manually.
 Python (PEP8 / black)
 ~~~~~~~~~~~~~~~~~~~~~
 
-*pandas* follows the `PEP8 <http://www.python.org/dev/peps/pep-0008/>`_ standard
+*pandas* follows the `PEP8 <https://www.python.org/dev/peps/pep-0008/>`_ standard
 and uses `Black <https://black.readthedocs.io/en/stable/>`_ and
 `Flake8 <http://flake8.pycqa.org/en/latest/>`_ to ensure a consistent code
 format throughout the project.
@@ -971,9 +971,9 @@ Adding tests is one of the most common requests after code is pushed to *pandas*
 it is worth getting in the habit of writing tests ahead of time so this is never an issue.
 
 Like many packages, *pandas* uses `pytest
-<http://docs.pytest.org/en/latest/>`_ and the convenient
+<https://docs.pytest.org/en/latest/>`_ and the convenient
 extensions in `numpy.testing
-<http://docs.scipy.org/doc/numpy/reference/routines.testing.html>`_.
+<https://docs.scipy.org/doc/numpy/reference/routines.testing.html>`_.
 
 .. note::
 
@@ -1024,7 +1024,7 @@ Transitioning to ``pytest``
     class TestReallyCoolFeature:
         pass
 
-Going forward, we are moving to a more *functional* style using the `pytest <http://docs.pytest.org/en/latest/>`__ framework, which offers a richer testing
+Going forward, we are moving to a more *functional* style using the `pytest <https://docs.pytest.org/en/latest/>`__ framework, which offers a richer testing
 framework that will facilitate testing and developing. Thus, instead of writing test classes, we will write test functions like this:
 
 .. code-block:: python
@@ -1257,7 +1257,7 @@ On Windows, one can type::
 This can significantly reduce the time it takes to locally run tests before
 submitting a pull request.
 
-For more, see the `pytest <http://docs.pytest.org/en/latest/>`_ documentation.
+For more, see the `pytest <https://docs.pytest.org/en/latest/>`_ documentation.
 
 Furthermore one can run
 
diff --git a/doc/source/development/contributing_docstring.rst b/doc/source/development/contributing_docstring.rst
index cb32f0e1e..649dd37b4 100644
--- a/doc/source/development/contributing_docstring.rst
+++ b/doc/source/development/contributing_docstring.rst
@@ -77,8 +77,8 @@ language that allows encoding styles in plain text files. Documentation
 about reStructuredText can be found in:
 
 * `Sphinx reStructuredText primer <https://www.sphinx-doc.org/en/stable/rest.html>`_
-* `Quick reStructuredText reference <http://docutils.sourceforge.net/docs/user/rst/quickref.html>`_
-* `Full reStructuredText specification <http://docutils.sourceforge.net/docs/ref/rst/restructuredtext.html>`_
+* `Quick reStructuredText reference <https://docutils.sourceforge.io/docs/user/rst/quickref.html>`_
+* `Full reStructuredText specification <https://docutils.sourceforge.io/docs/ref/rst/restructuredtext.html>`_
 
 Pandas has some helpers for sharing docstrings between related classes, see
 :ref:`docstring.sharing`.
diff --git a/doc/source/development/extending.rst b/doc/source/development/extending.rst
index 89d43e8a4..270f20e81 100644
--- a/doc/source/development/extending.rst
+++ b/doc/source/development/extending.rst
@@ -306,7 +306,7 @@ Subclassing pandas data structures
 
   1. Extensible method chains with :ref:`pipe <basics.pipe>`
 
-  2. Use *composition*. See `here <http://en.wikipedia.org/wiki/Composition_over_inheritance>`_.
+  2. Use *composition*. See `here <https://en.wikipedia.org/wiki/Composition_over_inheritance>`_.
 
   3. Extending by :ref:`registering an accessor <extending.register-accessors>`
 
diff --git a/doc/source/development/maintaining.rst b/doc/source/development/maintaining.rst
index 0d1088cc8..e65b66fc2 100644
--- a/doc/source/development/maintaining.rst
+++ b/doc/source/development/maintaining.rst
@@ -36,7 +36,7 @@ of what it means to be a maintainer.
 * Provide experience / wisdom on API design questions to ensure consistency and maintainability
 * Project organization (run / attend developer meetings, represent pandas)
 
-http://matthewrocklin.com/blog/2019/05/18/maintainer may be interesting background
+https://matthewrocklin.com/blog/2019/05/18/maintainer may be interesting background
 reading.
 
 .. _maintaining.triage:
@@ -78,7 +78,7 @@ Here's a typical workflow for triaging a newly opened issue.
 4. **Is the issue minimal and reproducible**?
 
    For bug reports, we ask that the reporter provide a minimal reproducible
-   example. See http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports
+   example. See https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports
    for a good explanation. If the example is not reproducible, or if it's
    *clearly* not minimal, feel free to ask the reporter if they can provide
    and example or simplify the provided one. Do acknowledge that writing
diff --git a/doc/source/ecosystem.rst b/doc/source/ecosystem.rst
index 90f839897..fb06ee122 100644
--- a/doc/source/ecosystem.rst
+++ b/doc/source/ecosystem.rst
@@ -303,8 +303,8 @@ dimensional arrays, rather than the tabular data for which pandas excels.
 Out-of-core
 -------------
 
-`Blaze <http://blaze.pydata.org/>`__
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+`Blaze <https://blaze.pydata.org/>`__
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 Blaze provides a standard API for doing computations with various
 in-memory and on-disk backends: NumPy, Pandas, SQLAlchemy, MongoDB, PyTables,
diff --git a/doc/source/getting_started/comparison/comparison_with_r.rst b/doc/source/getting_started/comparison/comparison_with_r.rst
index f67f46fc2..e1a4cfe49 100644
--- a/doc/source/getting_started/comparison/comparison_with_r.rst
+++ b/doc/source/getting_started/comparison/comparison_with_r.rst
@@ -6,9 +6,9 @@ Comparison with R / R libraries
 *******************************
 
 Since ``pandas`` aims to provide a lot of the data manipulation and analysis
-functionality that people use `R <http://www.r-project.org/>`__ for, this page
+functionality that people use `R <https://www.r-project.org/>`__ for, this page
 was started to provide a more detailed look at the `R language
-<http://en.wikipedia.org/wiki/R_(programming_language)>`__ and its many third
+<https://en.wikipedia.org/wiki/R_(programming_language)>`__ and its many third
 party libraries as they relate to ``pandas``. In comparisons with R and CRAN
 libraries, we care about the following things:
 
@@ -517,37 +517,37 @@ For more details and examples see :ref:`categorical introduction <categorical>`
 
 
 .. |c| replace:: ``c``
-.. _c: http://stat.ethz.ch/R-manual/R-patched/library/base/html/c.html
+.. _c: https://stat.ethz.ch/R-manual/R-patched/library/base/html/c.html
 
 .. |aggregate| replace:: ``aggregate``
-.. _aggregate: http://finzi.psych.upenn.edu/R/library/stats/html/aggregate.html
+.. _aggregate: https://stat.ethz.ch/R-manual/R-patched/library/stats/html/aggregate.html
 
 .. |match| replace:: ``match`` / ``%in%``
-.. _match: http://finzi.psych.upenn.edu/R/library/base/html/match.html
+.. _match: https://stat.ethz.ch/R-manual/R-patched/library/base/html/match.html
 
 .. |tapply| replace:: ``tapply``
-.. _tapply: http://finzi.psych.upenn.edu/R/library/base/html/tapply.html
+.. _tapply: https://stat.ethz.ch/R-manual/R-patched/library/base/html/tapply.html
 
 .. |with| replace:: ``with``
-.. _with: http://finzi.psych.upenn.edu/R/library/base/html/with.html
+.. _with: https://stat.ethz.ch/R-manual/R-patched/library/base/html/with.html
 
 .. |subset| replace:: ``subset``
-.. _subset: http://finzi.psych.upenn.edu/R/library/base/html/subset.html
+.. _subset: https://stat.ethz.ch/R-manual/R-patched/library/base/html/subset.html
 
 .. |ddply| replace:: ``ddply``
-.. _ddply: http://www.inside-r.org/packages/cran/plyr/docs/ddply
+.. _ddply: https://cran.r-project.org/web/packages/plyr/plyr.pdf#Rfn.ddply.1
 
 .. |meltarray| replace:: ``melt.array``
-.. _meltarray: http://www.inside-r.org/packages/cran/reshape2/docs/melt.array
+.. _meltarray: https://cran.r-project.org/web/packages/reshape2/reshape2.pdf#Rfn.melt.array.1
 
 .. |meltlist| replace:: ``melt.list``
-.. meltlist: http://www.inside-r.org/packages/cran/reshape2/docs/melt.list
+.. meltlist: https://cran.r-project.org/web/packages/reshape2/reshape2.pdf#Rfn.melt.list.1
 
 .. |meltdf| replace:: ``melt.data.frame``
-.. meltdf: http://www.inside-r.org/packages/cran/reshape2/docs/melt.data.frame
+.. meltdf: https://cran.r-project.org/web/packages/reshape2/reshape2.pdf#Rfn.melt.data.frame.1
 
 .. |cast| replace:: ``cast``
-.. cast: http://www.inside-r.org/packages/cran/reshape2/docs/cast
+.. cast: https://cran.r-project.org/web/packages/reshape2/reshape2.pdf#Rfn.cast.1
 
 .. |factor| replace:: ``factor``
 .. _factor: https://stat.ethz.ch/R-manual/R-devel/library/base/html/factor.html
diff --git a/doc/source/getting_started/comparison/comparison_with_stata.rst b/doc/source/getting_started/comparison/comparison_with_stata.rst
index fec6bae1e..decf12db7 100644
--- a/doc/source/getting_started/comparison/comparison_with_stata.rst
+++ b/doc/source/getting_started/comparison/comparison_with_stata.rst
@@ -673,6 +673,6 @@ Disk vs memory
 Pandas and Stata both operate exclusively in memory. This means that the size of
 data able to be loaded in pandas is limited by your machine's memory.
 If out of core processing is needed, one possibility is the
-`dask.dataframe <http://dask.pydata.org/en/latest/dataframe.html>`_
+`dask.dataframe <https://dask.pydata.org/en/latest/dataframe.html>`_
 library, which provides a subset of pandas functionality for an
 on-disk ``DataFrame``.
diff --git a/doc/source/getting_started/dsintro.rst b/doc/source/getting_started/dsintro.rst
index 81a2f0ae7..5d7c9e405 100644
--- a/doc/source/getting_started/dsintro.rst
+++ b/doc/source/getting_started/dsintro.rst
@@ -609,7 +609,7 @@ union of the column and row labels.
 
 When doing an operation between DataFrame and Series, the default behavior is
 to align the Series **index** on the DataFrame **columns**, thus `broadcasting
-<http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html>`__
+<https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html>`__
 row-wise. For example:
 
 .. ipython:: python
diff --git a/doc/source/getting_started/install.rst b/doc/source/getting_started/install.rst
index 8f5900a2a..ba5a7d929 100644
--- a/doc/source/getting_started/install.rst
+++ b/doc/source/getting_started/install.rst
@@ -7,13 +7,13 @@ Installation
 ============
 
 The easiest way to install pandas is to install it
-as part of the `Anaconda <http://docs.continuum.io/anaconda/>`__ distribution, a
+as part of the `Anaconda <https://docs.continuum.io/anaconda/>`__ distribution, a
 cross platform distribution for data analysis and scientific computing.
 This is the recommended installation method for most users.
 
 Instructions for installing from source,
 `PyPI <https://pypi.org/project/pandas>`__, `ActivePython <https://www.activestate.com/activepython/downloads>`__, various Linux distributions, or a
-`development version <http://github.com/pandas-dev/pandas>`__ are also provided.
+`development version <https://github.com/pandas-dev/pandas>`__ are also provided.
 
 Python version support
 ----------------------
@@ -28,28 +28,28 @@ Installing pandas
 Installing with Anaconda
 ~~~~~~~~~~~~~~~~~~~~~~~~
 
-Installing pandas and the rest of the `NumPy <http://www.numpy.org/>`__ and
-`SciPy <http://www.scipy.org/>`__ stack can be a little
+Installing pandas and the rest of the `NumPy <https://www.numpy.org/>`__ and
+`SciPy <https://www.scipy.org/>`__ stack can be a little
 difficult for inexperienced users.
 
 The simplest way to install not only pandas, but Python and the most popular
-packages that make up the `SciPy <http://www.scipy.org/>`__ stack
-(`IPython <http://ipython.org/>`__, `NumPy <http://www.numpy.org/>`__,
-`Matplotlib <http://matplotlib.org/>`__, ...) is with
-`Anaconda <http://docs.continuum.io/anaconda/>`__, a cross-platform
+packages that make up the `SciPy <https://www.scipy.org/>`__ stack
+(`IPython <https://ipython.org/>`__, `NumPy <https://www.numpy.org/>`__,
+`Matplotlib <https://matplotlib.org/>`__, ...) is with
+`Anaconda <https://docs.continuum.io/anaconda/>`__, a cross-platform
 (Linux, Mac OS X, Windows) Python distribution for data analytics and
 scientific computing.
 
 After running the installer, the user will have access to pandas and the
-rest of the `SciPy <http://www.scipy.org/>`__ stack without needing to install
+rest of the `SciPy <https://www.scipy.org/>`__ stack without needing to install
 anything else, and without needing to wait for any software to be compiled.
 
-Installation instructions for `Anaconda <http://docs.continuum.io/anaconda/>`__
-`can be found here <http://docs.continuum.io/anaconda/install.html>`__.
+Installation instructions for `Anaconda <https://docs.continuum.io/anaconda/>`__
+`can be found here <https://docs.continuum.io/anaconda/install.html>`__.
 
 A full list of the packages available as part of the
-`Anaconda <http://docs.continuum.io/anaconda/>`__ distribution
-`can be found here <http://docs.continuum.io/anaconda/pkg-docs.html>`__.
+`Anaconda <https://docs.continuum.io/anaconda/>`__ distribution
+`can be found here <https://docs.continuum.io/anaconda/packages/pkg-docs/>`__.
 
 Another advantage to installing Anaconda is that you don't need
 admin rights to install it. Anaconda can install in the user's home directory,
@@ -62,28 +62,28 @@ Installing with Miniconda
 ~~~~~~~~~~~~~~~~~~~~~~~~~
 
 The previous section outlined how to get pandas installed as part of the
-`Anaconda <http://docs.continuum.io/anaconda/>`__ distribution.
+`Anaconda <https://docs.continuum.io/anaconda/>`__ distribution.
 However this approach means you will install well over one hundred packages
 and involves downloading the installer which is a few hundred megabytes in size.
 
 If you want to have more control on which packages, or have a limited internet
 bandwidth, then installing pandas with
-`Miniconda <http://conda.pydata.org/miniconda.html>`__ may be a better solution.
+`Miniconda <https://conda.pydata.org/miniconda.html>`__ may be a better solution.
 
-`Conda <http://conda.pydata.org/docs/>`__ is the package manager that the
-`Anaconda <http://docs.continuum.io/anaconda/>`__ distribution is built upon.
+`Conda <https://conda.pydata.org/docs/>`__ is the package manager that the
+`Anaconda <https://docs.continuum.io/anaconda/>`__ distribution is built upon.
 It is a package manager that is both cross-platform and language agnostic
 (it can play a similar role to a pip and virtualenv combination).
 
-`Miniconda <http://conda.pydata.org/miniconda.html>`__ allows you to create a
+`Miniconda <https://conda.pydata.org/miniconda.html>`__ allows you to create a
 minimal self contained Python installation, and then use the
-`Conda <http://conda.pydata.org/docs/>`__ command to install additional packages.
+`Conda <https://conda.pydata.org/docs/>`__ command to install additional packages.
 
-First you will need `Conda <http://conda.pydata.org/docs/>`__ to be installed and
+First you will need `Conda <https://conda.pydata.org/docs/>`__ to be installed and
 downloading and running the `Miniconda
-<http://conda.pydata.org/miniconda.html>`__
+<https://conda.pydata.org/miniconda.html>`__
 will do this for you. The installer
-`can be found here <http://conda.pydata.org/miniconda.html>`__
+`can be found here <https://conda.pydata.org/miniconda.html>`__
 
 The next step is to create a new conda environment. A conda environment is like a
 virtualenv that allows you to specify a specific version of Python and set of libraries.
@@ -113,7 +113,7 @@ To install other packages, IPython for example::
 
     conda install ipython
 
-To install the full `Anaconda <http://docs.continuum.io/anaconda/>`__
+To install the full `Anaconda <https://docs.continuum.io/anaconda/>`__
 distribution::
 
     conda install anaconda
@@ -153,10 +153,10 @@ To install pandas for Python 2, you may need to use the ``python-pandas`` packag
     :widths: 10, 10, 20, 50
 
 
-    Debian, stable, `official Debian repository <http://packages.debian.org/search?keywords=pandas&searchon=names&suite=all&section=all>`__ , ``sudo apt-get install python3-pandas``
+    Debian, stable, `official Debian repository <https://packages.debian.org/search?keywords=pandas&searchon=names&suite=all&section=all>`__ , ``sudo apt-get install python3-pandas``
     Debian & Ubuntu, unstable (latest packages), `NeuroDebian <http://neuro.debian.net/index.html#how-to-use-this-repository>`__ , ``sudo apt-get install python3-pandas``
-    Ubuntu, stable, `official Ubuntu repository <http://packages.ubuntu.com/search?keywords=pandas&searchon=names&suite=all&section=all>`__ , ``sudo apt-get install python3-pandas``
-    OpenSuse, stable, `OpenSuse Repository  <http://software.opensuse.org/package/python-pandas?search_term=pandas>`__ , ``zypper in python3-pandas``
+    Ubuntu, stable, `official Ubuntu repository <https://packages.ubuntu.com/search?keywords=pandas&searchon=names&suite=all&section=all>`__ , ``sudo apt-get install python3-pandas``
+    OpenSuse, stable, `OpenSuse Repository  <https://software.opensuse.org/package/python-pandas?search_term=pandas>`__ , ``zypper in python3-pandas``
     Fedora, stable, `official Fedora repository  <https://admin.fedoraproject.org/pkgdb/package/rpms/python-pandas/>`__ , ``dnf install python3-pandas``
     Centos/RHEL, stable, `EPEL repository <https://admin.fedoraproject.org/pkgdb/package/rpms/python-pandas/>`__ , ``yum install python3-pandas``
 
@@ -177,7 +177,7 @@ pandas is equipped with an exhaustive set of unit tests, covering about 97% of
 the code base as of this writing. To run it on your machine to verify that
 everything is working (and that you have all of the dependencies, soft and hard,
 installed), make sure you have `pytest
-<http://docs.pytest.org/en/latest/>`__ >= 5.0.1 and `Hypothesis
+<https://docs.pytest.org/en/latest/>`__ >= 5.0.1 and `Hypothesis
 <https://hypothesis.readthedocs.io/>`__ >= 3.58, then run:
 
 ::
@@ -204,9 +204,9 @@ Dependencies
 Package                                                          Minimum supported version
 ================================================================ ==========================
 `setuptools <https://setuptools.readthedocs.io/en/latest/>`__    24.2.0
-`NumPy <http://www.numpy.org>`__                                 1.13.3
+`NumPy <https://www.numpy.org>`__                                1.13.3
 `python-dateutil <https://dateutil.readthedocs.io/en/stable/>`__ 2.6.1
-`pytz <http://pytz.sourceforge.net/>`__                          2017.2
+`pytz <https://pypi.org/project/pytz/>`__                        2017.2
 ================================================================ ==========================
 
 .. _install.recommended_dependencies:
@@ -303,6 +303,6 @@ top-level :func:`~pandas.read_html` function:
       usage of the above three libraries.
 
 .. _html5lib: https://github.com/html5lib/html5lib-python
-.. _BeautifulSoup4: http://www.crummy.com/software/BeautifulSoup
-.. _lxml: http://lxml.de
+.. _BeautifulSoup4: https://www.crummy.com/software/BeautifulSoup
+.. _lxml: https://lxml.de
 .. _tabulate: https://github.com/astanin/python-tabulate
diff --git a/doc/source/getting_started/tutorials.rst b/doc/source/getting_started/tutorials.rst
index 1ed0e8f63..434d79147 100644
--- a/doc/source/getting_started/tutorials.rst
+++ b/doc/source/getting_started/tutorials.rst
@@ -23,12 +23,12 @@ Community guides
 pandas Cookbook by Julia Evans
 ------------------------------
 
-The goal of this 2015 cookbook (by `Julia Evans <http://jvns.ca>`_) is to
+The goal of this 2015 cookbook (by `Julia Evans <https://jvns.ca>`_) is to
 give you some concrete examples for getting started with pandas. These
 are examples with real-world data, and all the bugs and weirdness that
 entails.
 For the table of contents, see the `pandas-cookbook GitHub
-repository <http://github.com/jvns/pandas-cookbook>`_.
+repository <https://github.com/jvns/pandas-cookbook>`_.
 
 Learn Pandas by Hernan Rojas
 ----------------------------
@@ -38,10 +38,10 @@ A set of lesson for new pandas users: https://bitbucket.org/hrojas/learn-pandas
 Practical data analysis with Python
 -----------------------------------
 
-This `guide <http://wavedatalab.github.io/datawithpython>`_ is an introduction to the data analysis process using the Python data ecosystem and an interesting open dataset.
-There are four sections covering selected topics as `munging data <http://wavedatalab.github.io/datawithpython/munge.html>`__,
-`aggregating data <http://wavedatalab.github.io/datawithpython/aggregate.html>`_, `visualizing data <http://wavedatalab.github.io/datawithpython/visualize.html>`_
-and `time series <http://wavedatalab.github.io/datawithpython/timeseries.html>`_.
+This `guide <https://wavedatalab.github.io/datawithpython>`_ is an introduction to the data analysis process using the Python data ecosystem and an interesting open dataset.
+There are four sections covering selected topics as `munging data <https://wavedatalab.github.io/datawithpython/munge.html>`__,
+`aggregating data <https://wavedatalab.github.io/datawithpython/aggregate.html>`_, `visualizing data <https://wavedatalab.github.io/datawithpython/visualize.html>`_
+and `time series <https://wavedatalab.github.io/datawithpython/timeseries.html>`_.
 
 .. _tutorial-exercises-new-users:
 
@@ -61,13 +61,13 @@ Tutorial series written in 2016 by
 The source may be found in the GitHub repository
 `TomAugspurger/effective-pandas <https://github.com/TomAugspurger/effective-pandas>`_.
 
-* `Modern Pandas <http://tomaugspurger.github.io/modern-1-intro.html>`_
-* `Method Chaining <http://tomaugspurger.github.io/method-chaining.html>`_
-* `Indexes <http://tomaugspurger.github.io/modern-3-indexes.html>`_
-* `Performance <http://tomaugspurger.github.io/modern-4-performance.html>`_
-* `Tidy Data <http://tomaugspurger.github.io/modern-5-tidy.html>`_
-* `Visualization <http://tomaugspurger.github.io/modern-6-visualization.html>`_
-* `Timeseries <http://tomaugspurger.github.io/modern-7-timeseries.html>`_
+* `Modern Pandas <https://tomaugspurger.github.io/modern-1-intro.html>`_
+* `Method Chaining <https://tomaugspurger.github.io/method-chaining.html>`_
+* `Indexes <https://tomaugspurger.github.io/modern-3-indexes.html>`_
+* `Performance <https://tomaugspurger.github.io/modern-4-performance.html>`_
+* `Tidy Data <https://tomaugspurger.github.io/modern-5-tidy.html>`_
+* `Visualization <https://tomaugspurger.github.io/modern-6-visualization.html>`_
+* `Timeseries <https://tomaugspurger.github.io/modern-7-timeseries.html>`_
 
 Excel charts with pandas, vincent and xlsxwriter
 ------------------------------------------------
@@ -89,21 +89,21 @@ Video tutorials
 * `Data analysis in Python with pandas <https://www.youtube.com/playlist?list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y>`_
   (2016-2018)
   `GitHub repo <https://github.com/justmarkham/pandas-videos>`__ and
-  `Jupyter Notebook <http://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb>`__
+  `Jupyter Notebook <https://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb>`__
 * `Best practices with pandas <https://www.youtube.com/playlist?list=PL5-da3qGB5IBITZj_dYSFqnd_15JgqwA6>`_
   (2018)
   `GitHub repo <https://github.com/justmarkham/pycon-2018-tutorial>`__ and
-  `Jupyter Notebook <http://nbviewer.jupyter.org/github/justmarkham/pycon-2018-tutorial/blob/master/tutorial.ipynb>`__
+  `Jupyter Notebook <https://nbviewer.jupyter.org/github/justmarkham/pycon-2018-tutorial/blob/master/tutorial.ipynb>`__
 
 
 Various tutorials
 -----------------
 
-* `Wes McKinney's (pandas BDFL) blog <http://blog.wesmckinney.com/>`_
+* `Wes McKinney's (pandas BDFL) blog <https://wesmckinney.com/archives.html>`_
 * `Statistical analysis made easy in Python with SciPy and pandas DataFrames, by Randal Olson <http://www.randalolson.com/2012/08/06/statistical-analysis-made-easy-in-python/>`_
-* `Statistical Data Analysis in Python, tutorial videos, by Christopher Fonnesbeck from SciPy 2013 <http://conference.scipy.org/scipy2013/tutorial_detail.php?id=109>`_
-* `Financial analysis in Python, by Thomas Wiecki <http://nbviewer.ipython.org/github/twiecki/financial-analysis-python-tutorial/blob/master/1.%20Pandas%20Basics.ipynb>`_
+* `Statistical Data Analysis in Python, tutorial videos, by Christopher Fonnesbeck from SciPy 2013 <https://conference.scipy.org/scipy2013/tutorial_detail.php?id=109>`_
+* `Financial analysis in Python, by Thomas Wiecki <https://nbviewer.ipython.org/github/twiecki/financial-analysis-python-tutorial/blob/master/1.%20Pandas%20Basics.ipynb>`_
 * `Intro to pandas data structures, by Greg Reda <http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/>`_
-* `Pandas and Python: Top 10, by Manish Amde <http://manishamde.github.io/blog/2013/03/07/pandas-and-python-top-10/>`_
-* `Pandas DataFrames Tutorial, by Karlijn Willems <http://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python>`_
+* `Pandas and Python: Top 10, by Manish Amde <https://manishamde.github.io/blog/2013/03/07/pandas-and-python-top-10/>`_
+* `Pandas DataFrames Tutorial, by Karlijn Willems <https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python>`_
 * `A concise tutorial with real life examples <https://tutswiki.com/pandas-cookbook/chapter1>`_
diff --git a/doc/source/user_guide/computation.rst b/doc/source/user_guide/computation.rst
index aeb32db63..9951642ca 100644
--- a/doc/source/user_guide/computation.rst
+++ b/doc/source/user_guide/computation.rst
@@ -58,7 +58,7 @@ series in the DataFrame, also excluding NA/null values.
     is not guaranteed to be positive semi-definite. This could lead to
     estimated correlations having absolute values which are greater than one,
     and/or a non-invertible covariance matrix. See `Estimation of covariance
-    matrices <http://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_matrices>`_
+    matrices <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_matrices>`_
     for more details.
 
 .. ipython:: python
@@ -346,7 +346,7 @@ if installed as an optional dependency. The apply aggregation can be executed us
 ``engine='numba'`` and ``engine_kwargs`` arguments (``raw`` must also be set to ``True``).
 Numba will be applied in potentially two routines:
 
-1. If ``func`` is a standard Python function, the engine will `JIT <http://numba.pydata.org/numba-doc/latest/user/overview.html>`__
+1. If ``func`` is a standard Python function, the engine will `JIT <https://numba.pydata.org/numba-doc/latest/user/overview.html>`__
 the passed function. ``func`` can also be a JITed function in which case the engine will not JIT the function again.
 
 2. The engine will JIT the for loop where the apply function is applied to each window.
@@ -1064,5 +1064,5 @@ are scaled by debiasing factors
 
 (For :math:`w_i = 1`, this reduces to the usual :math:`N / (N - 1)` factor,
 with :math:`N = t + 1`.)
-See `Weighted Sample Variance <http://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Weighted_sample_variance>`__
+See `Weighted Sample Variance <https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Weighted_sample_variance>`__
 on Wikipedia for further details.
diff --git a/doc/source/user_guide/cookbook.rst b/doc/source/user_guide/cookbook.rst
index f581d183b..4afdb14e5 100644
--- a/doc/source/user_guide/cookbook.rst
+++ b/doc/source/user_guide/cookbook.rst
@@ -927,7 +927,7 @@ CSV
 
 The :ref:`CSV <io.read_csv_table>` docs
 
-`read_csv in action <http://wesmckinney.com/blog/update-on-upcoming-pandas-v0-10-new-file-parser-other-performance-wins/>`__
+`read_csv in action <https://wesmckinney.com/blog/update-on-upcoming-pandas-v0-10-new-file-parser-other-performance-wins/>`__
 
 `appending to a csv
 <https://stackoverflow.com/questions/17134942/pandas-dataframe-output-end-of-csv>`__
@@ -951,7 +951,7 @@ using that handle to read.
 <https://stackoverflow.com/questions/15555005/get-inferred-dataframe-types-iteratively-using-chunksize>`__
 
 `Dealing with bad lines
-<http://github.com/pandas-dev/pandas/issues/2886>`__
+<https://github.com/pandas-dev/pandas/issues/2886>`__
 
 `Dealing with bad lines II
 <http://nipunbatra.github.io/2013/06/reading-unclean-data-csv-using-pandas/>`__
@@ -1082,7 +1082,7 @@ The :ref:`Excel <io.excel>` docs
 <https://stackoverflow.com/questions/15588713/sheets-of-excel-workbook-from-a-url-into-a-pandas-dataframe>`__
 
 `Modifying formatting in XlsxWriter output
-<http://pbpython.com/improve-pandas-excel-output.html>`__
+<https://pbpython.com/improve-pandas-excel-output.html>`__
 
 .. _cookbook.html:
 
@@ -1103,7 +1103,7 @@ The :ref:`HDFStores <io.hdf5>` docs
 <https://stackoverflow.com/questions/13926089/selecting-columns-from-pandas-hdfstore-table>`__
 
 `Managing heterogeneous data using a linked multiple table hierarchy
-<http://github.com/pandas-dev/pandas/issues/3032>`__
+<https://github.com/pandas-dev/pandas/issues/3032>`__
 
 `Merging on-disk tables with millions of rows
 <https://stackoverflow.com/questions/14614512/merging-two-tables-with-millions-of-rows-in-python/14617925#14617925>`__
@@ -1236,7 +1236,7 @@ Computation
 -----------
 
 `Numerical integration (sample-based) of a time series
-<http://nbviewer.ipython.org/5720498>`__
+<https://nbviewer.ipython.org/5720498>`__
 
 Correlation
 ***********
@@ -1284,7 +1284,7 @@ Timedeltas
 The :ref:`Timedeltas <timedeltas.timedeltas>` docs.
 
 `Using timedeltas
-<http://github.com/pandas-dev/pandas/pull/2899>`__
+<https://github.com/pandas-dev/pandas/pull/2899>`__
 
 .. ipython:: python
 
diff --git a/doc/source/user_guide/enhancingperf.rst b/doc/source/user_guide/enhancingperf.rst
index 2df5b9d82..10dce7ee8 100644
--- a/doc/source/user_guide/enhancingperf.rst
+++ b/doc/source/user_guide/enhancingperf.rst
@@ -20,7 +20,7 @@ Cython (writing C extensions for pandas)
 
 For many use cases writing pandas in pure Python and NumPy is sufficient. In some
 computationally heavy applications however, it can be possible to achieve sizable
-speed-ups by offloading work to `cython <http://cython.org/>`__.
+speed-ups by offloading work to `cython <https://cython.org/>`__.
 
 This tutorial assumes you have refactored as much as possible in Python, for example
 by trying to remove for-loops and making use of NumPy vectorization. It's always worth
@@ -69,7 +69,7 @@ We achieve our result by using ``apply`` (row-wise):
 
 But clearly this isn't fast enough for us. Let's take a look and see where the
 time is spent during this operation (limited to the most time consuming
-four calls) using the `prun ipython magic function <http://ipython.org/ipython-doc/stable/api/generated/IPython.core.magics.execution.html#IPython.core.magics.execution.ExecutionMagics.prun>`__:
+four calls) using the `prun ipython magic function <https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-prun>`__:
 
 .. ipython:: python
 
@@ -298,7 +298,7 @@ advanced Cython techniques:
 Even faster, with the caveat that a bug in our Cython code (an off-by-one error,
 for example) might cause a segfault because memory access isn't checked.
 For more about ``boundscheck`` and ``wraparound``, see the Cython docs on
-`compiler directives <http://cython.readthedocs.io/en/latest/src/reference/compilation.html?highlight=wraparound#compiler-directives>`__.
+`compiler directives <https://cython.readthedocs.io/en/latest/src/reference/compilation.html?highlight=wraparound#compiler-directives>`__.
 
 .. _enhancingperf.numba:
 
@@ -423,9 +423,9 @@ prefer that Numba throw an error if it cannot compile a function in a way that
 speeds up your code, pass Numba the argument
 ``nopython=True`` (e.g.  ``@numba.jit(nopython=True)``). For more on
 troubleshooting Numba modes, see the `Numba troubleshooting page
-<http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#the-compiled-code-is-too-slow>`__.
+<https://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#the-compiled-code-is-too-slow>`__.
 
-Read more in the `Numba docs <http://numba.pydata.org/>`__.
+Read more in the `Numba docs <https://numba.pydata.org/>`__.
 
 .. _enhancingperf.eval:
 
diff --git a/doc/source/user_guide/io.rst b/doc/source/user_guide/io.rst
index d0780e4ab..4239033e6 100644
--- a/doc/source/user_guide/io.rst
+++ b/doc/source/user_guide/io.rst
@@ -4262,12 +4262,12 @@ control compression: ``complevel`` and ``complib``.
   - `lzo <https://www.oberhumer.com/opensource/lzo/>`_: Fast
     compression and decompression.
   - `bzip2 <http://bzip.org/>`_: Good compression rates.
-  - `blosc <http://www.blosc.org/>`_: Fast compression and
+  - `blosc <https://www.blosc.org/>`_: Fast compression and
     decompression.
 
     Support for alternative blosc compressors:
 
-    - `blosc:blosclz <http://www.blosc.org/>`_ This is the
+    - `blosc:blosclz <https://www.blosc.org/>`_ This is the
       default compressor for ``blosc``
     - `blosc:lz4
       <https://fastcompression.blogspot.dk/p/lz4.html>`_:
@@ -5021,7 +5021,7 @@ Possible values are:
   like *Presto* and *Redshift*, but has worse performance for
   traditional SQL backend if the table contains many columns.
   For more information check the SQLAlchemy `documention
-  <http://docs.sqlalchemy.org/en/latest/core/dml.html#sqlalchemy.sql.expression.Insert.values.params.*args>`__.
+  <https://docs.sqlalchemy.org/en/latest/core/dml.html#sqlalchemy.sql.expression.Insert.values.params.*args>`__.
 - callable with signature ``(pd_table, conn, keys, data_iter)``:
   This can be used to implement a more performant insertion method based on
   specific backend dialect features.
diff --git a/doc/source/user_guide/missing_data.rst b/doc/source/user_guide/missing_data.rst
index 85f063f13..2e68a0598 100644
--- a/doc/source/user_guide/missing_data.rst
+++ b/doc/source/user_guide/missing_data.rst
@@ -467,9 +467,9 @@ at the new values.
    interp_s = ser.reindex(new_index).interpolate(method='pchip')
    interp_s[49:51]
 
-.. _scipy: http://www.scipy.org
-.. _documentation: http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation
-.. _guide: http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html
+.. _scipy: https://www.scipy.org
+.. _documentation: https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation
+.. _guide: https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html
 
 .. _missing_data.interp_limits:
 
diff --git a/doc/source/user_guide/style.ipynb b/doc/source/user_guide/style.ipynb
index 02550eab8..1f2f8818c 100644
--- a/doc/source/user_guide/style.ipynb
+++ b/doc/source/user_guide/style.ipynb
@@ -6,7 +6,7 @@
    "source": [
     "# Styling\n",
     "\n",
-    "This document is written as a Jupyter Notebook, and can be viewed or downloaded [here](http://nbviewer.ipython.org/github/pandas-dev/pandas/blob/master/doc/source/user_guide/style.ipynb).\n",
+    "This document is written as a Jupyter Notebook, and can be viewed or downloaded [here](https://nbviewer.ipython.org/github/pandas-dev/pandas/blob/master/doc/source/user_guide/style.ipynb).\n",
     "\n",
     "You can apply **conditional formatting**, the visual styling of a DataFrame\n",
     "depending on the data within, by using the ``DataFrame.style`` property.\n",
@@ -462,7 +462,7 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "You can create \"heatmaps\" with the `background_gradient` method. These require matplotlib, and we'll use [Seaborn](http://stanford.edu/~mwaskom/software/seaborn/) to get a nice colormap."
+    "You can create \"heatmaps\" with the `background_gradient` method. These require matplotlib, and we'll use [Seaborn](https://stanford.edu/~mwaskom/software/seaborn/) to get a nice colormap."
    ]
   },
   {
diff --git a/doc/source/user_guide/visualization.rst b/doc/source/user_guide/visualization.rst
index 39051440e..6680ba854 100644
--- a/doc/source/user_guide/visualization.rst
+++ b/doc/source/user_guide/visualization.rst
@@ -264,7 +264,7 @@ horizontal and cumulative histograms can be drawn by
    plt.close('all')
 
 See the :meth:`hist <matplotlib.axes.Axes.hist>` method and the
-`matplotlib hist documentation <http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hist>`__ for more.
+`matplotlib hist documentation <https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hist>`__ for more.
 
 
 The existing interface ``DataFrame.hist`` to plot histogram still can be used.
@@ -370,7 +370,7 @@ For example, horizontal and custom-positioned boxplot can be drawn by
 
 
 See the :meth:`boxplot <matplotlib.axes.Axes.boxplot>` method and the
-`matplotlib boxplot documentation <http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.boxplot>`__ for more.
+`matplotlib boxplot documentation <https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.boxplot>`__ for more.
 
 
 The existing interface ``DataFrame.boxplot`` to plot boxplot still can be used.
@@ -591,7 +591,7 @@ bubble chart using a column of the ``DataFrame`` as the bubble size.
    plt.close('all')
 
 See the :meth:`scatter <matplotlib.axes.Axes.scatter>` method and the
-`matplotlib scatter documentation <http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter>`__ for more.
+`matplotlib scatter documentation <https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter>`__ for more.
 
 .. _visualization.hexbin:
 
@@ -651,7 +651,7 @@ given by column ``z``. The bins are aggregated with NumPy's ``max`` function.
    plt.close('all')
 
 See the :meth:`hexbin <matplotlib.axes.Axes.hexbin>` method and the
-`matplotlib hexbin documentation <http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hexbin>`__ for more.
+`matplotlib hexbin documentation <https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hexbin>`__ for more.
 
 .. _visualization.pie:
 
@@ -749,7 +749,7 @@ If you pass values whose sum total is less than 1.0, matplotlib draws a semicirc
    @savefig series_pie_plot_semi.png
    series.plot.pie(figsize=(6, 6))
 
-See the `matplotlib pie documentation <http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.pie>`__ for more.
+See the `matplotlib pie documentation <https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.pie>`__ for more.
 
 .. ipython:: python
     :suppress:
@@ -1267,7 +1267,7 @@ tick locator methods, it is useful to call the automatic
 date tick adjustment from matplotlib for figures whose ticklabels overlap.
 
 See the :meth:`autofmt_xdate <matplotlib.figure.autofmt_xdate>` method and the
-`matplotlib documentation <http://matplotlib.org/users/recipes.html#fixing-common-date-annoyances>`__ for more.
+`matplotlib documentation <https://matplotlib.org/users/recipes.html#fixing-common-date-annoyances>`__ for more.
 
 Subplots
 ~~~~~~~~
@@ -1476,7 +1476,7 @@ as seen in the example below.
 There also exists a helper function ``pandas.plotting.table``, which creates a
 table from :class:`DataFrame` or :class:`Series`, and adds it to an
 ``matplotlib.Axes`` instance. This function can accept keywords which the
-matplotlib `table <http://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes.table>`__ has.
+matplotlib `table <https://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes.table>`__ has.
 
 .. ipython:: python
 
@@ -1494,7 +1494,7 @@ matplotlib `table <http://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes.
 
    plt.close('all')
 
-**Note**: You can get table instances on the axes using ``axes.tables`` property for further decorations. See the `matplotlib table documentation <http://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes.table>`__ for more.
+**Note**: You can get table instances on the axes using ``axes.tables`` property for further decorations. See the `matplotlib table documentation <https://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes.table>`__ for more.
 
 .. _visualization.colormaps:
 
@@ -1504,7 +1504,7 @@ Colormaps
 A potential issue when plotting a large number of columns is that it can be
 difficult to distinguish some series due to repetition in the default colors. To
 remedy this, ``DataFrame`` plotting supports the use of the ``colormap`` argument,
-which accepts either a Matplotlib `colormap <http://matplotlib.org/api/cm_api.html>`__
+which accepts either a Matplotlib `colormap <https://matplotlib.org/api/cm_api.html>`__
 or a string that is a name of a colormap registered with Matplotlib. A
 visualization of the default matplotlib colormaps is available `here
 <https://matplotlib.org/examples/color/colormaps_reference.html>`__.
diff --git a/doc/source/whatsnew/index.rst b/doc/source/whatsnew/index.rst
index bc463d0ab..a8bd5c401 100644
--- a/doc/source/whatsnew/index.rst
+++ b/doc/source/whatsnew/index.rst
@@ -7,7 +7,7 @@ Release Notes
 *************
 
 This is the list of changes to pandas between each release. For full details,
-see the commit logs at http://github.com/pandas-dev/pandas. For install and
+see the commit logs at https://github.com/pandas-dev/pandas. For install and
 upgrade instructions, see :ref:`install`.
 
 Version 1.1
diff --git a/pandas/_libs/intervaltree.pxi.in b/pandas/_libs/intervaltree.pxi.in
index d09413bfa..a8728050f 100644
--- a/pandas/_libs/intervaltree.pxi.in
+++ b/pandas/_libs/intervaltree.pxi.in
@@ -26,7 +26,7 @@ cdef class IntervalTree(IntervalMixin):
     """A centered interval tree
 
     Based off the algorithm described on Wikipedia:
-    http://en.wikipedia.org/wiki/Interval_tree
+    https://en.wikipedia.org/wiki/Interval_tree
 
     we are emulating the IndexEngine interface
     """
diff --git a/pandas/_libs/src/klib/khash.h b/pandas/_libs/src/klib/khash.h
index bcf6350aa..916838d1e 100644
--- a/pandas/_libs/src/klib/khash.h
+++ b/pandas/_libs/src/klib/khash.h
@@ -53,7 +53,7 @@ int main() {
 	  speed for simple keys. Thank Zilong Tan for the suggestion. Reference:
 
 	   - https://github.com/stefanocasazza/ULib
-	   - http://nothings.org/computer/judy/
+	   - https://nothings.org/computer/judy/
 
 	* Allow to optionally use linear probing which usually has better
 	  performance for random input. Double hashing is still the default as it
diff --git a/pandas/_libs/src/skiplist.h b/pandas/_libs/src/skiplist.h
index 60c1a5672..1679ced17 100644
--- a/pandas/_libs/src/skiplist.h
+++ b/pandas/_libs/src/skiplist.h
@@ -10,7 +10,7 @@ Flexibly-sized, index-able skiplist data structure for maintaining a sorted
 list of values
 
 Port of Wes McKinney's Cython version of Raymond Hettinger's original pure
-Python recipe (http://rhettinger.wordpress.com/2010/02/06/lost-knowledge/)
+Python recipe (https://rhettinger.wordpress.com/2010/02/06/lost-knowledge/)
 */
 
 #ifndef PANDAS__LIBS_SRC_SKIPLIST_H_
diff --git a/pandas/_libs/src/ujson/lib/ultrajson.h b/pandas/_libs/src/ujson/lib/ultrajson.h
index 8d04874b4..b40ac9856 100644
--- a/pandas/_libs/src/ujson/lib/ultrajson.h
+++ b/pandas/_libs/src/ujson/lib/ultrajson.h
@@ -30,7 +30,7 @@ https://github.com/client9/stringencoders
 Copyright (c) 2007  Nick Galbreath -- nickg [at] modp [dot] com. All rights reserved.
 
 Numeric decoder derived from from TCL library
-http://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
+https://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
  * Copyright (c) 1988-1993 The Regents of the University of California.
  * Copyright (c) 1994 Sun Microsystems, Inc.
 */
diff --git a/pandas/_libs/src/ujson/lib/ultrajsondec.c b/pandas/_libs/src/ujson/lib/ultrajsondec.c
index 4eb18ee13..36eb170f8 100644
--- a/pandas/_libs/src/ujson/lib/ultrajsondec.c
+++ b/pandas/_libs/src/ujson/lib/ultrajsondec.c
@@ -33,7 +33,7 @@ Copyright (c) 2007  Nick Galbreath -- nickg [at] modp [dot] com. All rights
 reserved.
 
 Numeric decoder derived from from TCL library
-http://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
+https://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
 * Copyright (c) 1988-1993 The Regents of the University of California.
 * Copyright (c) 1994 Sun Microsystems, Inc.
 */
diff --git a/pandas/_libs/src/ujson/lib/ultrajsonenc.c b/pandas/_libs/src/ujson/lib/ultrajsonenc.c
index 51c9b9244..065e3b2c6 100644
--- a/pandas/_libs/src/ujson/lib/ultrajsonenc.c
+++ b/pandas/_libs/src/ujson/lib/ultrajsonenc.c
@@ -33,7 +33,7 @@ Copyright (c) 2007  Nick Galbreath -- nickg [at] modp [dot] com. All rights
 reserved.
 
 Numeric decoder derived from from TCL library
-http://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
+https://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
  * Copyright (c) 1988-1993 The Regents of the University of California.
  * Copyright (c) 1994 Sun Microsystems, Inc.
 */
diff --git a/pandas/_libs/src/ujson/python/JSONtoObj.c b/pandas/_libs/src/ujson/python/JSONtoObj.c
index b2fc78847..3db10237b 100644
--- a/pandas/_libs/src/ujson/python/JSONtoObj.c
+++ b/pandas/_libs/src/ujson/python/JSONtoObj.c
@@ -30,7 +30,7 @@ https://github.com/client9/stringencoders
 Copyright (c) 2007  Nick Galbreath -- nickg [at] modp [dot] com. All rights reserved.
 
 Numeric decoder derived from from TCL library
-http://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
+https://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
  * Copyright (c) 1988-1993 The Regents of the University of California.
  * Copyright (c) 1994 Sun Microsystems, Inc.
 */
diff --git a/pandas/_libs/src/ujson/python/objToJSON.c b/pandas/_libs/src/ujson/python/objToJSON.c
index 0367661e5..62c2870c1 100644
--- a/pandas/_libs/src/ujson/python/objToJSON.c
+++ b/pandas/_libs/src/ujson/python/objToJSON.c
@@ -31,7 +31,7 @@ Copyright (c) 2007  Nick Galbreath -- nickg [at] modp [dot] com. All rights
 reserved.
 
 Numeric decoder derived from from TCL library
-http://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
+https://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
 * Copyright (c) 1988-1993 The Regents of the University of California.
 * Copyright (c) 1994 Sun Microsystems, Inc.
 */
diff --git a/pandas/_libs/src/ujson/python/ujson.c b/pandas/_libs/src/ujson/python/ujson.c
index 4a88fb7a4..a40f2709c 100644
--- a/pandas/_libs/src/ujson/python/ujson.c
+++ b/pandas/_libs/src/ujson/python/ujson.c
@@ -30,7 +30,7 @@ https://github.com/client9/stringencoders
 Copyright (c) 2007  Nick Galbreath -- nickg [at] modp [dot] com. All rights reserved.
 
 Numeric decoder derived from from TCL library
-http://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
+https://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
 * Copyright (c) 1988-1993 The Regents of the University of California.
 * Copyright (c) 1994 Sun Microsystems, Inc.
 */
diff --git a/pandas/_libs/src/ujson/python/version.h b/pandas/_libs/src/ujson/python/version.h
index ef6d28bf3..3f38642b6 100644
--- a/pandas/_libs/src/ujson/python/version.h
+++ b/pandas/_libs/src/ujson/python/version.h
@@ -30,7 +30,7 @@ https://github.com/client9/stringencoders
 Copyright (c) 2007  Nick Galbreath -- nickg [at] modp [dot] com. All rights reserved.
 
 Numeric decoder derived from from TCL library
-http://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
+https://www.opensource.apple.com/source/tcl/tcl-14/tcl/license.terms
  * Copyright (c) 1988-1993 The Regents of the University of California.
  * Copyright (c) 1994 Sun Microsystems, Inc.
 */
diff --git a/pandas/_libs/tslibs/c_timestamp.pyx b/pandas/_libs/tslibs/c_timestamp.pyx
index ed1df5f4f..2c72cec18 100644
--- a/pandas/_libs/tslibs/c_timestamp.pyx
+++ b/pandas/_libs/tslibs/c_timestamp.pyx
@@ -124,7 +124,7 @@ cdef class _Timestamp(datetime):
 
     def __reduce_ex__(self, protocol):
         # python 3.6 compat
-        # http://bugs.python.org/issue28730
+        # https://bugs.python.org/issue28730
         # now __reduce_ex__ is defined and higher priority than __reduce__
         return self.__reduce__()
 
diff --git a/pandas/_libs/tslibs/nattype.pyx b/pandas/_libs/tslibs/nattype.pyx
index 61b272169..357f183b3 100644
--- a/pandas/_libs/tslibs/nattype.pyx
+++ b/pandas/_libs/tslibs/nattype.pyx
@@ -326,7 +326,7 @@ class NaTType(_NaT):
 
     def __reduce_ex__(self, protocol):
         # python 3.6 compat
-        # http://bugs.python.org/issue28730
+        # https://bugs.python.org/issue28730
         # now __reduce_ex__ is defined and higher priority than __reduce__
         return self.__reduce__()
 
diff --git a/pandas/core/accessor.py b/pandas/core/accessor.py
index 3f1c7b1c0..a04e9c3e6 100644
--- a/pandas/core/accessor.py
+++ b/pandas/core/accessor.py
@@ -186,7 +186,7 @@ class CachedAccessor:
             return self._accessor
         accessor_obj = self._accessor(obj)
         # Replace the property with the accessor object. Inspired by:
-        # http://www.pydanny.com/cached-property.html
+        # https://www.pydanny.com/cached-property.html
         # We need to use object.__setattr__ because we overwrite __setattr__ on
         # NDFrame
         object.__setattr__(obj, self._name, accessor_obj)
diff --git a/pandas/core/arrays/datetimes.py b/pandas/core/arrays/datetimes.py
index 1988b2e9e..4b6b54cce 100644
--- a/pandas/core/arrays/datetimes.py
+++ b/pandas/core/arrays/datetimes.py
@@ -1637,7 +1637,7 @@ default 'raise'
         """
         Convert Datetime Array to float64 ndarray of Julian Dates.
         0 Julian date is noon January 1, 4713 BC.
-        http://en.wikipedia.org/wiki/Julian_day
+        https://en.wikipedia.org/wiki/Julian_day
         """
 
         # http://mysite.verizon.net/aesir_research/date/jdalg2.htm
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index faeebe152..012fb1d0c 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1490,9 +1490,9 @@ class DataFrame(NDFrame):
             when getting user credentials.
 
             .. _local webserver flow:
-                http://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server
+                https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server
             .. _console flow:
-                http://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console
+                https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console
 
             *New in version 0.2.0 of pandas-gbq*.
         table_schema : list of dicts, optional
@@ -3363,7 +3363,7 @@ class DataFrame(NDFrame):
         * To select strings you must use the ``object`` dtype, but note that
           this will return *all* object dtype columns
         * See the `numpy dtype hierarchy
-          <http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__
+          <https://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__
         * To select datetimes, use ``np.datetime64``, ``'datetime'`` or
           ``'datetime64'``
         * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or
@@ -7614,7 +7614,7 @@ Wild         185.0
         semi-definite. This could lead to estimate correlations having
         absolute values which are greater than one, and/or a non-invertible
         covariance matrix. See `Estimation of covariance matrices
-        <http://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_
+        <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_
         matrices>`__ for more details.
 
         Examples
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 52cf59c49..c502adcdb 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -2502,7 +2502,7 @@ class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):
 
         References
         ----------
-        .. [1] http://docs.sqlalchemy.org
+        .. [1] https://docs.sqlalchemy.org
         .. [2] https://www.python.org/dev/peps/pep-0249/
 
         Examples
@@ -2711,7 +2711,7 @@ class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):
 
         Notes
         -----
-        See the `xarray docs <http://xarray.pydata.org/en/stable/>`__
+        See the `xarray docs <https://xarray.pydata.org/en/stable/>`__
 
         Examples
         --------
@@ -6642,9 +6642,9 @@ class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):
         similar names. These use the actual numerical values of the index.
         For more information on their behavior, see the
         `SciPy documentation
-        <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__
+        <https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__
         and `SciPy tutorial
-        <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__.
+        <https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__.
 
         Examples
         --------
diff --git a/pandas/io/formats/format.py b/pandas/io/formats/format.py
index c6496411e..149533bf0 100644
--- a/pandas/io/formats/format.py
+++ b/pandas/io/formats/format.py
@@ -418,7 +418,7 @@ class EastAsianTextAdjustment(TextAdjustment):
             self.ambiguous_width = 1
 
         # Definition of East Asian Width
-        # http://unicode.org/reports/tr11/
+        # https://unicode.org/reports/tr11/
         # Ambiguous width can be changed by option
         self._EAW_MAP = {"Na": 1, "N": 1, "W": 2, "F": 2, "H": 1}
 
diff --git a/pandas/io/gbq.py b/pandas/io/gbq.py
index 69ebc470f..405bf27ca 100644
--- a/pandas/io/gbq.py
+++ b/pandas/io/gbq.py
@@ -64,9 +64,9 @@ def read_gbq(
         when getting user credentials.
 
         .. _local webserver flow:
-            http://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server
+            https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server
         .. _console flow:
-            http://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console
+            https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console
 
         *New in version 0.2.0 of pandas-gbq*.
     dialect : str, default 'legacy'
diff --git a/pandas/io/html.py b/pandas/io/html.py
index 75cb0fafa..c676bfb1f 100644
--- a/pandas/io/html.py
+++ b/pandas/io/html.py
@@ -986,7 +986,7 @@ def read_html(
 
         is a valid attribute dictionary because the 'id' HTML tag attribute is
         a valid HTML attribute for *any* HTML tag as per `this document
-        <http://www.w3.org/TR/html-markup/global-attributes.html>`__. ::
+        <https://html.spec.whatwg.org/multipage/dom.html#global-attributes>`__. ::
 
             attrs = {'asdf': 'table'}
 
@@ -995,7 +995,7 @@ def read_html(
         table attributes can be found `here
         <http://www.w3.org/TR/REC-html40/struct/tables.html#h-11.2>`__. A
         working draft of the HTML 5 spec can be found `here
-        <http://www.w3.org/TR/html-markup/table.html>`__. It contains the
+        <https://html.spec.whatwg.org/multipage/tables.html>`__. It contains the
         latest information on table attributes for the modern web.
 
     parse_dates : bool, optional
diff --git a/pandas/io/json/_table_schema.py b/pandas/io/json/_table_schema.py
index 5f23b95c1..4e42533ca 100644
--- a/pandas/io/json/_table_schema.py
+++ b/pandas/io/json/_table_schema.py
@@ -1,7 +1,7 @@
 """
 Table Schema builders
 
-http://specs.frictionlessdata.io/json-table-schema/
+https://specs.frictionlessdata.io/json-table-schema/
 """
 import warnings
 
diff --git a/pandas/io/stata.py b/pandas/io/stata.py
index cee5f3d28..ec200a1ad 100644
--- a/pandas/io/stata.py
+++ b/pandas/io/stata.py
@@ -7,7 +7,7 @@ project who also developed the StataWriter and was finally added to pandas in
 a once again improved version.
 
 You can find more information on http://presbrey.mit.edu/PyDTA and
-http://www.statsmodels.org/devel/
+https://www.statsmodels.org/devel/
 """
 from collections import abc
 import datetime
@@ -204,7 +204,7 @@ stata_epoch = datetime.datetime(1960, 1, 1)
 
 def _stata_elapsed_date_to_datetime_vec(dates, fmt):
     """
-    Convert from SIF to datetime. http://www.stata.com/help.cgi?datetime
+    Convert from SIF to datetime. https://www.stata.com/help.cgi?datetime
 
     Parameters
     ----------
@@ -369,7 +369,7 @@ def _stata_elapsed_date_to_datetime_vec(dates, fmt):
 
 def _datetime_to_stata_elapsed_vec(dates, fmt):
     """
-    Convert from datetime to SIF. http://www.stata.com/help.cgi?datetime
+    Convert from datetime to SIF. https://www.stata.com/help.cgi?datetime
 
     Parameters
     ----------
@@ -729,7 +729,7 @@ class StataMissingValue:
 
     Notes
     -----
-    More information: <http://www.stata.com/help.cgi?missing>
+    More information: <https://www.stata.com/help.cgi?missing>
 
     Integer missing values make the code '.', '.a', ..., '.z' to the ranges
     101 ... 127 (for int8), 32741 ... 32767  (for int16) and 2147483621 ...
diff --git a/pandas/plotting/_misc.py b/pandas/plotting/_misc.py
index ccd42d394..1369adcd8 100644
--- a/pandas/plotting/_misc.py
+++ b/pandas/plotting/_misc.py
@@ -149,7 +149,7 @@ def radviz(frame, class_column, ax=None, color=None, colormap=None, **kwds):
     influence of all dimensions.
 
     More info available at the `original article
-    <http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.889>`_
+    <https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.889>`_
     describing RadViz.
 
     Parameters
diff --git a/pandas/tests/indexes/multi/test_analytics.py b/pandas/tests/indexes/multi/test_analytics.py
index 2db61d4f4..e64511efd 100644
--- a/pandas/tests/indexes/multi/test_analytics.py
+++ b/pandas/tests/indexes/multi/test_analytics.py
@@ -326,7 +326,7 @@ def test_map_dictlike(idx, mapper):
 )
 def test_numpy_ufuncs(idx, func):
     # test ufuncs of numpy. see:
-    # http://docs.scipy.org/doc/numpy/reference/ufuncs.html
+    # https://docs.scipy.org/doc/numpy/reference/ufuncs.html
 
     if _np_version_under1p17:
         expected_exception = AttributeError
diff --git a/pandas/tests/indexes/test_numpy_compat.py b/pandas/tests/indexes/test_numpy_compat.py
index 7051f2b02..8b62de703 100644
--- a/pandas/tests/indexes/test_numpy_compat.py
+++ b/pandas/tests/indexes/test_numpy_compat.py
@@ -46,7 +46,7 @@ from pandas.core.indexes.datetimelike import DatetimeIndexOpsMixin
 )
 def test_numpy_ufuncs_basic(indices, func):
     # test ufuncs of numpy, see:
-    # http://docs.scipy.org/doc/numpy/reference/ufuncs.html
+    # https://docs.scipy.org/doc/numpy/reference/ufuncs.html
 
     idx = indices
     if isinstance(idx, DatetimeIndexOpsMixin):
@@ -77,7 +77,7 @@ def test_numpy_ufuncs_basic(indices, func):
 )
 def test_numpy_ufuncs_other(indices, func):
     # test ufuncs of numpy, see:
-    # http://docs.scipy.org/doc/numpy/reference/ufuncs.html
+    # https://docs.scipy.org/doc/numpy/reference/ufuncs.html
 
     idx = indices
     if isinstance(idx, (DatetimeIndex, TimedeltaIndex)):
diff --git a/pandas/tests/tseries/offsets/test_fiscal.py b/pandas/tests/tseries/offsets/test_fiscal.py
index 568611959..f0ce104a6 100644
--- a/pandas/tests/tseries/offsets/test_fiscal.py
+++ b/pandas/tests/tseries/offsets/test_fiscal.py
@@ -95,7 +95,7 @@ class TestFY5253LastOfMonth(Base):
 
     on_offset_cases = [
         # From Wikipedia (see:
-        # http://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar#Last_Saturday_of_the_month_at_fiscal_year_end)
+        # https://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar#Last_Saturday_of_the_month_at_fiscal_year_end)
         (offset_lom_sat_aug, datetime(2006, 8, 26), True),
         (offset_lom_sat_aug, datetime(2007, 8, 25), True),
         (offset_lom_sat_aug, datetime(2008, 8, 30), True),
@@ -208,7 +208,7 @@ class TestFY5253NearestEndMonth(Base):
 
     on_offset_cases = [
         #    From Wikipedia (see:
-        #    http://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar
+        #    https://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar
         #    #Saturday_nearest_the_end_of_month)
         #    2006-09-02   2006 September 2
         #    2007-09-01   2007 September 1
diff --git a/pandas/tseries/offsets.py b/pandas/tseries/offsets.py
index 220ff241e..e05cce9c4 100644
--- a/pandas/tseries/offsets.py
+++ b/pandas/tseries/offsets.py
@@ -2062,7 +2062,7 @@ class FY5253(DateOffset):
     such as retail, manufacturing and parking industry.
 
     For more information see:
-    http://en.wikipedia.org/wiki/4-4-5_calendar
+    https://en.wikipedia.org/wiki/4-4-5_calendar
 
     The year may either:
 
@@ -2270,7 +2270,7 @@ class FY5253Quarter(DateOffset):
     such as retail, manufacturing and parking industry.
 
     For more information see:
-    http://en.wikipedia.org/wiki/4-4-5_calendar
+    https://en.wikipedia.org/wiki/4-4-5_calendar
 
     The year may either:
 
diff --git a/pandas/util/_decorators.py b/pandas/util/_decorators.py
index d10d3a1f7..0aab5a9c4 100644
--- a/pandas/util/_decorators.py
+++ b/pandas/util/_decorators.py
@@ -248,7 +248,7 @@ def rewrite_axis_style_signature(
 
 
 # Substitution and Appender are derived from matplotlib.docstring (1.1.0)
-# module http://matplotlib.org/users/license.html
+# module https://matplotlib.org/users/license.html
 
 
 class Substitution:
diff --git a/setup.py b/setup.py
index c7dbde2ff..43be4df4f 100755
--- a/setup.py
+++ b/setup.py
@@ -60,7 +60,7 @@ except ImportError:
 
 # The import of Extension must be after the import of Cython, otherwise
 # we do not get the appropriately patched class.
-# See https://cython.readthedocs.io/en/latest/src/reference/compilation.html
+# See https://cython.readthedocs.io/en/latest/src/userguide/source_files_and_compilation.html # noqa
 from distutils.extension import Extension  # noqa: E402 isort:skip
 from distutils.command.build import build  # noqa: E402 isort:skip
 
diff --git a/versioneer.py b/versioneer.py
index 8a4710da5..5882349f6 100644
--- a/versioneer.py
+++ b/versioneer.py
@@ -1677,7 +1677,7 @@ def do_setup():
     except EnvironmentError:
         pass
     # That doesn't cover everything MANIFEST.in can do
-    # (http://docs.python.org/2/distutils/sourcedist.html#commands), so
+    # (https://docs.python.org/2/distutils/sourcedist.html#commands), so
     # it might give some false negatives. Appending redundant 'include'
     # lines is safe, though.
     if "versioneer.py" not in simple_includes:
diff --git a/web/pandas/about/citing.md b/web/pandas/about/citing.md
index 5cd31d872..d5cb64e58 100644
--- a/web/pandas/about/citing.md
+++ b/web/pandas/about/citing.md
@@ -4,7 +4,7 @@
 
 If you use _pandas_ for a scientific publication, we would appreciate citations to one of the following papers:
 
-- [Data structures for statistical computing in python](http://conference.scipy.org/proceedings/scipy2010/pdfs/mckinney.pdf),
+- [Data structures for statistical computing in python](https://conference.scipy.org/proceedings/scipy2010/pdfs/mckinney.pdf),
    McKinney, Proceedings of the 9th Python in Science Conference, Volume 445, 2010.
 
         @inproceedings{mckinney2010data,
diff --git a/web/pandas/about/index.md b/web/pandas/about/index.md
index 9a0a3923a..02caaa3b8 100644
--- a/web/pandas/about/index.md
+++ b/web/pandas/about/index.md
@@ -2,8 +2,8 @@
 
 ## History of development
 
-In 2008, _pandas_ development began at [AQR Capital Management](http://www.aqr.com).
-By the end of 2009 it had been [open sourced](http://en.wikipedia.org/wiki/Open_source),
+In 2008, _pandas_ development began at [AQR Capital Management](https://www.aqr.com).
+By the end of 2009 it had been [open sourced](https://en.wikipedia.org/wiki/Open_source),
 and is actively supported today by a community of like-minded individuals around the world who
 contribute their valuable time and energy to help make open source _pandas_
 possible. Thank you to [all of our contributors](team.html).
diff --git a/web/pandas/community/coc.md b/web/pandas/community/coc.md
index de0e8120f..bf62f4e00 100644
--- a/web/pandas/community/coc.md
+++ b/web/pandas/community/coc.md
@@ -54,10 +54,10 @@ incident.
 
 This Code of Conduct is adapted from the [Contributor Covenant][homepage],
 version 1.3.0, available at
-[http://contributor-covenant.org/version/1/3/0/][version],
+[https://www.contributor-covenant.org/version/1/3/0/][version],
 and the [Swift Code of Conduct][swift].
 
-[homepage]: http://contributor-covenant.org
-[version]: http://contributor-covenant.org/version/1/3/0/
+[homepage]: https://www.contributor-covenant.org
+[version]: https://www.contributor-covenant.org/version/1/3/0/
 [swift]: https://swift.org/community/#code-of-conduct
 
diff --git a/web/pandas/community/ecosystem.md b/web/pandas/community/ecosystem.md
index a707854c6..715a84c1b 100644
--- a/web/pandas/community/ecosystem.md
+++ b/web/pandas/community/ecosystem.md
@@ -264,7 +264,7 @@ which pandas excels.
 
 ## Out-of-core
 
-### [Blaze](http://blaze.pydata.org/)
+### [Blaze](https://blaze.pydata.org/)
 
 Blaze provides a standard API for doing computations with various
 in-memory and on-disk backends: NumPy, Pandas, SQLAlchemy, MongoDB,
diff --git a/web/pandas/index.html b/web/pandas/index.html
index 0f4598add..fedb0b0c5 100644
--- a/web/pandas/index.html
+++ b/web/pandas/index.html
@@ -7,7 +7,7 @@
                     <h1>pandas</h1>
                     <p>
                         <strong>pandas</strong> is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,<br/>
-                        built on top of the <a href="http://www.python.org">Python</a> programming language.
+                        built on top of the <a href="https://www.python.org">Python</a> programming language.
                     </p>
                     <p>
                         <a class="btn btn-primary" href="{{ base_url }}/getting_started.html">Install pandas now!</a>
