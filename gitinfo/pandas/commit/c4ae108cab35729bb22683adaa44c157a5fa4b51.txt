commit c4ae108cab35729bb22683adaa44c157a5fa4b51
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Fri Dec 23 19:05:55 2011 -0500

    ENH: perf, compute group_index only once for cython aggregation

diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index a8a84811d..9e350fbea 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -350,12 +350,13 @@ class GroupBy(object):
             return self.aggregate(lambda x: np.sum(x, axis=self.axis))
 
     def _cython_agg_general(self, how):
-        label_list = [ping.labels for ping in self.groupings]
         shape = self._group_shape
 
         # TODO: address inefficiencies, like duplicating effort (should
         # aggregate all the columns at once?)
 
+        group_index = self._group_index
+
         output = {}
         for name, obj in self._iterate_slices():
             if issubclass(obj.dtype.type, (np.number, np.bool_)):
@@ -364,8 +365,8 @@ class GroupBy(object):
             else:
                 continue
 
-            result, counts =  cython_aggregate(obj, label_list,
-                                               shape, how=how)
+            result, counts =  cython_aggregate(obj, group_index, shape,
+                                               how=how)
             result = result.ravel()
             mask = counts.ravel() > 0
             output[name] = result[mask]
@@ -1383,12 +1384,10 @@ def get_group_index(label_list, shape):
 # Group aggregations in Cython
 
 
-def cython_aggregate(values, label_list, shape, how='add'):
+def cython_aggregate(values, group_index, shape, how='add'):
     agg_func = _cython_functions[how]
     trans_func = _cython_transforms.get(how, lambda x: x)
 
-    group_index = get_group_index(label_list, shape).astype('i4')
-
     result = np.empty(shape, dtype=np.float64)
     result.fill(np.nan)
 
diff --git a/vb_suite/groupby.py b/vb_suite/groupby.py
index 7dfa0eb83..8c4574dbd 100644
--- a/vb_suite/groupby.py
+++ b/vb_suite/groupby.py
@@ -20,9 +20,11 @@ def get_test_data(ngroups=100, n=N):
     random.shuffle(arr)
     return arr
 
+# aggregate multiple columns
 df = DataFrame({'key1' : get_test_data(ngroups=ngroups),
                 'key2' : get_test_data(ngroups=ngroups),
-                'data' : np.random.randn(N)})
+                'data1' : np.random.randn(N),
+                'data2' : np.random.randn(N)})
 def f():
     df.groupby(['key1', 'key2']).agg(lambda x: x.values.sum())
 """
