commit 02b387a01068cb8657b677041f28331e29acf0c8
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Wed Dec 21 18:33:39 2011 -0500

    BUG: don't cast to int/bool when introducing NAs

diff --git a/RELEASE.rst b/RELEASE.rst
index 12dcd7e6a..bb3291ec6 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -72,12 +72,15 @@ pandas 0.6.2
   - Fix scalar value access in Series to always return NumPy scalars,
     regression from prior versions (GH #510)
   - Handle rows skipped at beginning of file in read_* functions (GH #505)
+  - Handle improper dtype casting in ``set_value`` methods
 
 Thanks
 ------
 - Craig Austin
 - Andreas Hilboll
 - Adam Klein
+- Matt Harrison
+- Gregg Lind
 - Solomon Negusse
 - Wouter Overmeire
 - Christian Prinoth
diff --git a/doc/source/basics.rst b/doc/source/basics.rst
index c382287f2..1cbfeb720 100644
--- a/doc/source/basics.rst
+++ b/doc/source/basics.rst
@@ -513,12 +513,27 @@ It returns a tuple with both of the reindexed Series:
 .. _basics.df_join:
 
 For DataFrames, the join method will be applied to both the index and the
-columns.
+columns by default:
 
 .. ipython:: python
 
    df.align(df2, join='inner')
 
+You can also pass an ``axis`` option to only align on the specified axis:
+
+.. ipython:: python
+
+   df.align(df2, join='inner', axis=0)
+
+.. _basics.align.frame.series:
+
+If you pass a Series to ``DataFrame.align``, you can choose to align both
+objects either on the DataFrame's index or columns using the ``axis`` argument:
+
+.. ipython:: python
+
+   df.align(df2.ix[0], axis=1)
+
 .. _basics.reindex_fill:
 
 Filling while reindexing
diff --git a/doc/source/indexing.rst b/doc/source/indexing.rst
index 78e461c9e..ea9cdaf1e 100644
--- a/doc/source/indexing.rst
+++ b/doc/source/indexing.rst
@@ -69,6 +69,30 @@ Thus, as per above, we have the most basic indexing using ``[]``:
    s[dates[5]]
    panel['two']
 
+.. _indexing.basics.get_value:
+
+Fast scalar value getting and setting
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+Since indexing with ``[]`` must handle a lot of cases (single-label access,
+slicing, boolean indexing, etc.), it has a bit of overhead in order to figure
+out what you're asking for. If you only want to access a scalar value, the
+fastest way is to use the ``get_value`` method, which is implemented on all of
+the data structures:
+
+.. ipython:: python
+
+   s.get_value(dates[5])
+   df.get_value(dates[5], 'A')
+
+There is an analogous ``set_value`` method which has the additional capability
+of enlarging an object. This method *always* returns a reference to the object
+it modified, which in the fast of enlargement, will be a **new object**:
+
+.. ipython:: python
+
+   df.set_value(dates[5], 'E', 7)
+
 Data slices on other axes
 ~~~~~~~~~~~~~~~~~~~~~~~~~
 
@@ -316,7 +340,7 @@ than integer locations. Therefore, advanced indexing with ``.ix`` will always
 attempt label-based indexing, before falling back on integer-based indexing.
 
 Setting values in mixed-type DataFrame
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 .. _indexing.mixed_type_setting:
 
diff --git a/doc/source/merging.rst b/doc/source/merging.rst
index 7157cb1cb..6c5ff0da0 100644
--- a/doc/source/merging.rst
+++ b/doc/source/merging.rst
@@ -14,6 +14,8 @@
 Merging / Joining data sets
 ***************************
 
+.. _merging.append:
+
 Appending DataFrame objects
 ---------------------------
 
@@ -62,6 +64,22 @@ To do this, use the ``ignore_index`` argument:
 
    df1.append(df2, ignore_index=True)
 
+.. _merging.append.row:
+
+Appending single rows to a DataFrame
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+While not especially efficient (since a new object must be created), you can
+append a row to a DataFrame by passing a Series to ``append``, which returns a
+new DataFrame as above:
+
+.. ipython:: python
+
+   df = DataFrame(np.random.randn(8, 4))
+   df
+   s = df.xs(5)
+   df.append(s, ignore_index=True)
+
 
 Joining / merging DataFrames
 ----------------------------
diff --git a/doc/source/themes/agogo/layout.html b/doc/source/themes/agogo/layout.html
index 5debc23ce..cd0f3d7ff 100644
--- a/doc/source/themes/agogo/layout.html
+++ b/doc/source/themes/agogo/layout.html
@@ -51,6 +51,10 @@
           <p class="searchtip" style="font-size: 90%">
             {{ _('Enter search terms or a module, class or function name.') }}
           </p>
+		  <p>
+		  <p>
+			<script type="text/javascript" src="http://www.ohloh.net/p/482908/widgets/project_partner_badge.js"></script>
+	      </p>
           {%- endblock %}
         </div>
         <div class="document">
diff --git a/doc/source/whatsnew/v0.6.1.rst b/doc/source/whatsnew/v0.6.1.rst
index ee31a0efa..c814af808 100644
--- a/doc/source/whatsnew/v0.6.1.rst
+++ b/doc/source/whatsnew/v0.6.1.rst
@@ -3,3 +3,39 @@
 
 v.0.6.1 (December 13, 2011)
 ---------------------------
+
+New features
+~~~~~~~~~~~~
+- Can :ref:`append single rows <merging.append.row>` (as Series) to a DataFrame
+- Add Spearman and Kendall rank correlation options to Series.corr and
+  DataFrame.corr (GH428_)
+- :ref:`Added <indexing.basics.get_value>` ``get_value`` and ``set_value`` methods to
+  Series, DataFrame, and Panel for very low-overhead access (>2x faster in many
+  cases) to scalar elements (GH437_, GH438_). ``set_value`` is capable of
+  producing an enlarged object.
+- Add PyQt table widget to sandbox (PR435_)
+- DataFrame.align can :ref:`accept Series arguments <basics.align.frame.series>`
+  and an :ref:`axis option <basics.df_join>` (GH461_)
+- Implement new SparseList and SparseArray data structures. SparseSeries now
+  derives from SparseArray (GH463_)
+- max_columns / max_rows options in set_printoptions (PR #453)
+- Implement Series.rank and DataFrame.rank, fast versions of
+  scipy.stats.rankdata (GH #428)
+- Implement DataFrame.from_items alternate constructor (GH #444)
+- DataFrame.convert_objects method for inferring better dtypes for object
+  columns (GH #302)
+- Add rolling_corr_pairwise function for computing Panel of correlation
+  matrices (GH #189)
+- Add `margins` option to `pivot_table` for computing subgroup aggregates (GH
+  #114)
+- Add `Series.from_csv` function (PR #482)
+
+Performance improvements
+~~~~~~~~~~~~~~~~~~~~~~~~
+
+.. _GH428: https://github.com/wesm/pandas/issues/428
+.. _GH437: https://github.com/wesm/pandas/issues/437
+.. _GH438: https://github.com/wesm/pandas/issues/438
+.. _GH461: https://github.com/wesm/pandas/issues/461
+.. _GH463: https://github.com/wesm/pandas/issues/463
+.. _PR435: https://github.com/wesm/pandas/pull/435
diff --git a/doc/source/whatsnew/v0.6.2.rst b/doc/source/whatsnew/v0.6.2.rst
index 29c42ce55..59c330c83 100644
--- a/doc/source/whatsnew/v0.6.2.rst
+++ b/doc/source/whatsnew/v0.6.2.rst
@@ -6,17 +6,11 @@ v.0.6.2 (Not Yet Released)
 
 These are new features and improvements of note in this release.
 
-New functions or features
-~~~~~~~~~~~~~~~~~~~~~~~~~
+New features
+~~~~~~~~~~~~
 
-Can set multiple columns in a DataFrame, useful for transformation (Issue342_)
-
-.. ipython:: python
-
-   DataFrame(randn(10, 3), columns=['A', 'B', 'C'])
-
-Improvements to existing features
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+- You can now :ref:`set multiple columns <indexing.columns.multiple>` in a
+  DataFrame via ``__getitem__``, useful for transformation (Issue342_)
 
 - Handle differently-indexed output values in ``DataFrame.apply`` (Issue498_)
 
@@ -25,9 +19,6 @@ Improvements to existing features
    df = DataFrame(randn(10, 4))
    df.apply(lambda x: x.describe())
 
-- You can now :ref:`set multiple columns <indexing.columns.multiple>` in a
-  DataFrame via ``__getitem__``.
-
 Performance improvements
 ~~~~~~~~~~~~~~~~~~~~~~~~
 
@@ -79,7 +70,8 @@ significant speedup (Issue93_)
 Here's a graph of the performance of this operation over time on a dataset with
 100,000 rows and 10,000 unique groups:
 
-.. .. include:: vbench/groupby_multi_cython.rst
+.. image:: vbench/figures/groupby_multi_cython.png
+   :width: 6in
 
 On this similar vein,
 
@@ -87,7 +79,8 @@ GroupBy aggregations with Python functions significantly sped up by clever
 manipulation of the ndarray data type in Cython (Issue496_). Benchmark of a
 similar operation to the above but using a Python function:
 
-.. .. include:: vbench/groupby_multi_python.rst
+.. image:: vbench/figures/groupby_multi_python.png
+   :width: 6in
 
 .. _Issue93: https://github.com/wesm/pandas/issues/93
 .. _Issue342: https://github.com/wesm/pandas/issues/342
diff --git a/pandas/core/common.py b/pandas/core/common.py
index e4988de17..69a38a00d 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -285,13 +285,22 @@ def _need_upcast(values):
 
 def _infer_dtype(value):
     if isinstance(value, (float, np.floating)):
-        return float
+        return np.float_
     elif isinstance(value, (bool, np.bool_)):
-        return bool
+        return np.bool_
     elif isinstance(value, (int, np.integer)):
-        return int
+        return np.int_
     else:
-        return object
+        return np.object_
+
+def _possibly_cast_item(obj, item, dtype):
+    chunk = obj[item]
+
+    if chunk.values.dtype != dtype:
+        if dtype in (np.object_, np.bool_):
+            obj[item] = chunk.astype(np.object_)
+        elif not issubclass(dtype, (np.integer, np.bool_)):
+            obj[item] = chunk.astype(np.object_)
 
 def _is_bool_indexer(key):
     if isinstance(key, np.ndarray) and key.dtype == np.object_:
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index f0e8de7d4..8285b3cf1 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1026,10 +1026,14 @@ class DataFrame(NDFrame):
             result = self.reindex(index=new_index, columns=new_columns,
                                   copy=False)
             likely_dtype = com._infer_dtype(value)
-            if result[col].dtype != likely_dtype:
-                result[col] = result[col].astype(likely_dtype)
-            result.set_value(index, col, value)
-            return result
+
+            made_bigger = not np.array_equal(new_columns, self.columns)
+
+            # how to make this logic simpler?
+            if made_bigger:
+                com._possibly_cast_item(result, col, likely_dtype)
+
+            return result.set_value(index, col, value)
 
     def __getitem__(self, key):
         # slice rows
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 4885ee149..40809525c 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -15,7 +15,7 @@ from pandas.core.frame import DataFrame, _union_indexes
 from pandas.core.generic import AxisProperty, NDFrame
 from pandas.core.series import Series
 from pandas.util import py3compat
-import pandas.core.common as common
+import pandas.core.common as com
 import pandas._tseries as _tseries
 
 
@@ -496,8 +496,14 @@ class Panel(NDFrame):
         except KeyError:
             ax1, ax2, ax3 = self._expand_axes((item, major, minor))
             result = self.reindex(items=ax1, major=ax2, minor=ax3, copy=False)
-            result = result.set_value(item, major, minor, value)
-            return result
+
+            likely_dtype = com._infer_dtype(value)
+            made_bigger = not np.array_equal(ax1, self.items)
+            # how to make this logic simpler?
+            if made_bigger:
+                com._possibly_cast_item(result, item, likely_dtype)
+
+            return result.set_value(item, major, minor, value)
 
     def _box_item_values(self, key, values):
         return DataFrame(values, index=self.major_axis, columns=self.minor_axis)
@@ -562,7 +568,7 @@ class Panel(NDFrame):
 
     def _unpickle_panel_compat(self, state): # pragma: no cover
         "Unpickle the panel"
-        _unpickle = common._unpickle_array
+        _unpickle = com._unpickle_array
         vals, items, major, minor = state
 
         items = _unpickle(items)
@@ -864,7 +870,7 @@ class Panel(NDFrame):
         I, N, K = self.shape
 
         if filter_observations:
-            mask = common.notnull(self.values).all(axis=0)
+            mask = com.notnull(self.values).all(axis=0)
             # size = mask.sum()
             selector = mask.ravel()
         else:
@@ -1023,7 +1029,7 @@ class Panel(NDFrame):
 
     def median(self, axis='major', skipna=True):
         def f(arr):
-            mask = common.notnull(arr)
+            mask = com.notnull(arr)
             if skipna:
                 return _tseries.median(arr[mask])
             else:
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 34f06990d..053dccdc3 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -700,10 +700,11 @@ class CheckIndexing(object):
         self.assert_(res3['baz'].dtype == np.object_)
 
         res3 = res.set_value('foobar', 'baz', True)
-        self.assert_(res3['baz'].dtype == np.bool_)
+        self.assert_(res3['baz'].dtype == np.object_)
 
         res3 = res.set_value('foobar', 'baz', 5)
-        self.assert_(com.is_integer_dtype(res3['baz']))
+        self.assert_(com.is_float_dtype(res3['baz']))
+        self.assert_(isnull(res3['baz'].drop(['foobar'])).values.all())
         self.assertRaises(ValueError, res3.set_value, 'foobar', 'baz', 'sam')
 
     def test_get_set_value_no_partial_indexing(self):
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index 728bf2a5e..2c8932b91 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -13,6 +13,7 @@ from pandas.core.datetools import bday
 from pandas.core.frame import group_agg
 from pandas.core.panel import Panel, LongPanel
 from pandas.core.series import remove_na
+import pandas.core.common as com
 import pandas.core.panel as panelmod
 from pandas.util import py3compat
 
@@ -571,6 +572,9 @@ class CheckIndexing(object):
         self.assert_(res is not self.panel)
         self.assertEqual(res.get_value('ItemE', 'foo', 'bar'), 1.5)
 
+        res3 = self.panel.set_value('ItemE', 'foobar', 'baz', 5)
+        self.assert_(com.is_float_dtype(res3['ItemE'].values))
+
 class TestPanel(unittest.TestCase, PanelTests, CheckIndexing,
                 SafeForLongAndSparse,
                 SafeForSparse):
diff --git a/vb_suite/binary_ops.py b/vb_suite/binary_ops.py
index 561af7364..2aff7672e 100644
--- a/vb_suite/binary_ops.py
+++ b/vb_suite/binary_ops.py
@@ -1,17 +1,13 @@
 from vbench.benchmark import Benchmark
 from datetime import datetime
 
-common_setup = """from pandas_db_common import *
+common_setup = """from pandas_vb_common import *
 """
 
 #----------------------------------------------------------------------
 # data alignment
 
-setup = common_setup + """
-from pandas import *
-from pandas.util.testing import rands
-
-n = 1000000
+setup = common_setup + """n = 1000000
 # indices = Index([rands(10) for _ in xrange(n)])
 def sample(values, k):
     sampler = np.random.permutation(len(values))
@@ -27,4 +23,4 @@ ts2 = Series(np.random.randn(sz), idx2)
 stmt = "ts1 + ts2"
 bm_align1 = Benchmark(stmt, setup,
                       name="series_align_int64_index",
-                      start_date=datetime(2011, 3, 1))
+                      start_date=datetime(2010, 6, 1))
