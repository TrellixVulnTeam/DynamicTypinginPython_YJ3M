commit 93664ed413a64be8e0d374473d52c58372b4e51f
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Jan 8 22:31:34 2012 -0500

    TST: hacking for talk, dict benchmarks

diff --git a/fake_pyrex/Pyrex/Distutils/__init__.py b/fake_pyrex/Pyrex/Distutils/__init__.py
deleted file mode 100644
index 51c8e16b8..000000000
--- a/fake_pyrex/Pyrex/Distutils/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-# work around broken setuptools monkey patching
diff --git a/fake_pyrex/Pyrex/Distutils/build_ext.py b/fake_pyrex/Pyrex/Distutils/build_ext.py
deleted file mode 100644
index 4f846f628..000000000
--- a/fake_pyrex/Pyrex/Distutils/build_ext.py
+++ /dev/null
@@ -1 +0,0 @@
-build_ext = "yes, it's there!"
diff --git a/fake_pyrex/Pyrex/__init__.py b/fake_pyrex/Pyrex/__init__.py
deleted file mode 100644
index 51c8e16b8..000000000
--- a/fake_pyrex/Pyrex/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-# work around broken setuptools monkey patching
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index d5cc45d4a..750933cd6 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -3483,7 +3483,7 @@ class DataFrame(NDFrame):
         if not subplots:
             ax = axes[0]
 
-        for i, col in enumerate(_try_sort(self.columns)):
+        for i, col in enumerate(self.columns):
             empty = self[col].count() == 0
             y = self[col].values if not empty else np.zeros(len(self))
             if subplots:
@@ -3493,7 +3493,7 @@ class DataFrame(NDFrame):
                 ax.set_title(col)
             else:
                 rects.append(ax.bar(xinds + i * 0.5/K, y, 0.5/K,
-                                    bottom=np.zeros(N),
+                                    bottom=np.zeros(N), label=col,
                                     color=colors[i % len(colors)], **kwds))
                 labels.append(col)
 
diff --git a/pandas/src/hashtable.pyx b/pandas/src/hashtable.pyx
index d86e1dbab..28126f068 100644
--- a/pandas/src/hashtable.pyx
+++ b/pandas/src/hashtable.pyx
@@ -222,6 +222,31 @@ cdef class StringHashTable:
                 resbuf[i] = -1
         return labels
 
+    def unique(self, ndarray[object] values):
+        cdef:
+            Py_ssize_t i, n = len(values)
+            Py_ssize_t idx, count = 0
+            int ret
+            object val
+            char *buf
+            khiter_t k
+            list uniques = []
+
+        for i in range(n):
+            val = values[i]
+            buf = PyString_AsString(val)
+            k = kh_get_str(self.table, buf)
+            if k == self.table.n_buckets:
+                k = kh_put_str(self.table, buf, &ret)
+                # print 'putting %s, %s' % (val, count)
+                if not ret:
+                    kh_del_str(self.table, k)
+                count += 1
+                uniques.append(val)
+
+        # return None
+        return uniques
+
     def factorize(self, ndarray[object] values):
         cdef:
             Py_ssize_t i, n = len(values)
@@ -476,6 +501,25 @@ cdef class Int64HashTable:
 
         return labels, counts[:count].copy()
 
+    def unique(self, ndarray[int64_t] values):
+        cdef:
+            Py_ssize_t i, n = len(values)
+            Py_ssize_t idx, count = 0
+            int ret
+            int64_t val
+            khiter_t k
+            list uniques = []
+
+        for i in range(n):
+            val = values[i]
+            k = kh_get_int64(self.table, val)
+            if k == self.table.n_buckets:
+                k = kh_put_int64(self.table, val, &ret)
+                uniques.append(val)
+                count += 1
+
+        return uniques
+
 cdef class PyObjectHashTable:
 
     cdef:
@@ -571,9 +615,6 @@ cdef class PyObjectHashTable:
     def unique(self, ndarray[object] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            ndarray[int32_t] labels = np.empty(n, dtype=np.int32)
-            ndarray[int32_t] counts = np.empty(n, dtype=np.int32)
-            dict reverse = {}
             Py_ssize_t idx, count = 0
             int ret
             object val
@@ -625,6 +666,22 @@ cdef class PyObjectHashTable:
 
         return labels, counts[:count].copy()
 
+    # def unique(self, ndarray[object] values, list uniques):
+    #     cdef:
+    #         Py_ssize_t i, n = len(values)
+    #         Py_ssize_t idx, count = 0
+    #         int ret
+    #         object val
+    #         khiter_t k
+
+    #     for i in range(n):
+    #         val = values[i]
+    #         k = kh_get_pymap(self.table, <PyObject*>val)
+    #         if k == self.table.n_buckets:
+    #             k = kh_put_pymap(self.table, <PyObject*>val, &ret)
+    #             uniques.append(val)
+    #             count += 1
+
 cdef class Factorizer:
 
     cdef public:
@@ -656,6 +713,10 @@ cdef class Factorizer:
         self.count = len(counts)
         return labels, counts
 
+    def unique(self, ndarray[object] values):
+        # just for fun
+        return self.table.unique(values)
+
 cdef class Int64Factorizer:
 
     cdef public:
@@ -753,6 +814,34 @@ cdef class DictFactorizer:
         self.count = len(counts)
         return labels, counts
 
+    def unique(self, ndarray[object] values):
+        cdef:
+            Py_ssize_t i, n = len(values)
+            Py_ssize_t idx, count = self.count
+            object val
+
+        for i in range(n):
+            val = values[i]
+            if val not in self.table:
+                self.table[val] = count
+                self.uniques.append(val)
+                count += 1
+        return self.uniques
+
+
+    def unique_int64(self, ndarray[int64_t] values):
+        cdef:
+            Py_ssize_t i, n = len(values)
+            Py_ssize_t idx, count = self.count
+            int64_t val
+
+        for i in range(n):
+            val = values[i]
+            if val not in self.table:
+                self.table[val] = count
+                self.uniques.append(val)
+                count += 1
+        return self.uniques
 
 def lookup_locations2(ndarray[object] values):
     cdef:
diff --git a/pandas/src/skiplist_test.c b/pandas/src/skiplist_test.c
deleted file mode 100644
index 37590774b..000000000
--- a/pandas/src/skiplist_test.c
+++ /dev/null
@@ -1,36 +0,0 @@
-#include "skiplist.h"
-
-double urand2() {
-  return rand() / ((double) RAND_MAX + 1);
-}
-
-int main(void) {
-  skiplist_t *skp;
-  double *data;
-  int i, n, win, ret;
-
-  n = 10000;
-  win = 1000;
-  skp = skiplist_init(win);
-
-  data = (double*) malloc(n * sizeof(double));
-  for (i = 0; i < n; ++i) {
-    data[i] = urand2();
-  }
-
-  for (i = 0; i < win; ++i) {
-    skiplist_insert(skp, data[i]);
-  }
-
-  double middle;
-  for (i = win; i < n; ++i) {
-    skiplist_remove(skp, data[i - win]);
-    skiplist_insert(skp, data[i]);
-    middle = skiplist_get(skp, win / 2, &ret);
-  }
-
-  skiplist_destroy(skp);
-  free(data);
-  return 0;
-}
-
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 9605db395..a77f17ca7 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -6,7 +6,7 @@ import numpy as np
 
 from pandas.core.frame import DataFrame, _merge_doc
 from pandas.core.groupby import get_group_index
-from pandas.core.index import (Index, MultiIndex, _get_combined_index,
+from pandas.core.index import (Factor, Index, MultiIndex, _get_combined_index,
                                _ensure_index)
 from pandas.core.internals import (IntBlock, BoolBlock, BlockManager,
                                    make_block, _consolidate)
diff --git a/scripts/file_sizes.py b/scripts/file_sizes.py
index e87502c5b..279024e68 100644
--- a/scripts/file_sizes.py
+++ b/scripts/file_sizes.py
@@ -1,25 +1,190 @@
 from pandas import DataFrame
+from pandas.util.testing import set_trace
 import os
+import numpy as np
+import matplotlib.pyplot as plt
 
 dirs = []
 names = []
 lengths = []
 
-walked = list(os.walk('pandas'))
+walked = os.walk('pandas')
 
-for directory, _, files in walked:
-    print directory
-    for path in files:
-        if not path.endswith('.py'):
-            continue
+def _should_count_file(path):
+    return path.endswith('.py') or path.endswith('.pyx')
 
-        full_path = os.path.join(directory, path)
-        print full_path
-        lines = len(open(full_path).readlines())
+def _is_def_line(line):
+    return (line.endswith(':') and
+            (line.startswith('def ') or
+             line.startswith('cdef ') or
+             line.startswith('cpdef ') or
+             ' def ' in line or ' cdef ' in line or ' cpdef ' in line))
 
-        dirs.append(directory)
-        names.append(path)
-        lengths.append(lines)
+class LengthCounter(object):
+    """
+    should add option for subtracting nested function lengths??
+    """
+    def __init__(self, lines):
+        self.lines = lines
+        self.pos = 0
+        self.counts = []
+        self.n = len(lines)
 
-result = DataFrame({'dirs' : dirs, 'names' : names,
-                    'lengths' : lengths})
+    def get_counts(self):
+        self.pos = 0
+        self.counts = []
+        while self.pos < self.n:
+            line = self.lines[self.pos]
+            self.pos += 1
+            if _is_def_line(line):
+                level = _get_indent_level(line)
+                self._count_function(indent_level=level)
+        return self.counts
+
+    def _count_function(self, indent_level=1):
+        indent = '    ' * indent_level
+
+        def _end_of_function(line):
+            return (line != '' and
+                    not line.startswith(indent) and
+                    not line.startswith('#'))
+
+        start_pos = self.pos
+        while self.pos < self.n:
+            line = self.lines[self.pos]
+            if _end_of_function(line):
+                self._push_count(start_pos)
+                return
+
+            self.pos += 1
+
+            if _is_def_line(line):
+                self._count_function(indent_level=indent_level + 1)
+
+        # end of file
+        self._push_count(start_pos)
+
+    def _push_count(self, start_pos):
+        func_lines = self.lines[start_pos:self.pos]
+
+        if len(func_lines) > 300:
+            set_trace()
+
+        # remove blank lines at end
+        while len(func_lines) > 0 and func_lines[-1] == '':
+            func_lines = func_lines[:-1]
+
+        # remove docstrings and comments
+        clean_lines = []
+        in_docstring = False
+        for line in func_lines:
+            line = line.strip()
+            if in_docstring and _is_triplequote(line):
+                in_docstring = False
+                continue
+
+            if line.startswith('#'):
+                continue
+
+            if _is_triplequote(line):
+                in_docstring = True
+                continue
+
+        self.counts.append(len(func_lines))
+
+def _get_indent_level(line):
+    level = 0
+    while line.startswith('    ' * level):
+        level += 1
+    return level
+
+def _is_triplequote(line):
+    return line.startswith('"""') or line.startswith("'''")
+
+def _get_file_function_lengths(path):
+    lines = [x.rstrip() for x in open(path).readlines()]
+    counter = LengthCounter(lines)
+    return counter.get_counts()
+
+# def test_get_function_lengths():
+text = """
+class Foo:
+
+def foo():
+    def bar():
+        a = 1
+
+        b = 2
+
+        c = 3
+
+    foo = 'bar'
+
+def x():
+    a = 1
+
+    b = 3
+
+    c = 7
+
+    pass
+"""
+
+expected = [5, 8, 7]
+
+lines = [x.rstrip() for x in text.splitlines()]
+counter = LengthCounter(lines)
+result = counter.get_counts()
+assert(result == expected)
+
+def doit():
+    for directory, _, files in walked:
+        print directory
+        for path in files:
+            if not _should_count_file(path):
+                continue
+
+            full_path = os.path.join(directory, path)
+            print full_path
+            lines = len(open(full_path).readlines())
+
+            dirs.append(directory)
+            names.append(path)
+            lengths.append(lines)
+
+    result = DataFrame({'dirs' : dirs, 'names' : names,
+                        'lengths' : lengths})
+
+def doit2():
+    counts = {}
+    for directory, _, files in walked:
+        print directory
+        for path in files:
+            if not _should_count_file(path) or path.startswith('test_'):
+                continue
+
+            full_path = os.path.join(directory, path)
+            counts[full_path] = _get_file_function_lengths(full_path)
+
+    return counts
+
+counts = doit2()
+
+# counts = _get_file_function_lengths('pandas/tests/test_series.py')
+
+all_counts = []
+for k, v in counts.iteritems():
+    all_counts.extend(v)
+all_counts = np.array(all_counts)
+
+fig = plt.figure(figsize=(10, 5))
+ax = fig.add_subplot(111)
+ax.hist(all_counts, bins=100)
+n = len(all_counts)
+nmore = (all_counts > 50).sum()
+ax.set_title('pandas function lengths, n=%d' % n)
+ax.set_ylabel('N functions')
+ax.set_xlabel('Function length')
+ax.text(100, 300, '%.3f%% with > 50 lines' % (100 * nmore / float(n)),
+        fontsize=18)
+plt.show()
