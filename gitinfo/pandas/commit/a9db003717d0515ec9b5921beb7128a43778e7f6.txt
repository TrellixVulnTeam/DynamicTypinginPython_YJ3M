commit a9db003717d0515ec9b5921beb7128a43778e7f6
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Thu Aug 30 20:24:14 2012 -0400

    ENH: making some more progress. string factorization conversion

diff --git a/pandas/io/tests/test_cparser.py b/pandas/io/tests/test_cparser.py
index f8457a961..8730c1139 100644
--- a/pandas/io/tests/test_cparser.py
+++ b/pandas/io/tests/test_cparser.py
@@ -54,11 +54,26 @@ class TestCParser(unittest.TestCase):
         finally:
             f.close()
 
-    # def test_StringIO(self):
-    #     text = open(self.csv1, 'rb').read()
+    def test_file_handle_mmap(self):
+        try:
+            f = open(self.csv1, 'rb')
+            reader = parser.TextReader(f, memory_map=True)
+            result = reader.read()
+        finally:
+            f.close()
+
+    def test_StringIO(self):
+        text = open(self.csv1, 'rb').read()
+        reader = parser.TextReader(BytesIO(text))
+        result = reader.read()
+
+    def test_string_factorize(self):
+        # should this be optional?
+        data = 'a\nb\na\nb\na'
+        reader = parser.TextReader(StringIO(data))
+        result = reader.read()
+        self.assert_(len(set(map(id, result[0]))) == 2)
 
-    #     reader = parser.TextReader(BytesIO(text))
-    #     result = reader.read()
 
 if __name__ == '__main__':
     nose.runmodule(argv=[__file__,'-vvs','-x','--pdb', '--pdb-failure'],
diff --git a/pandas/src/khash.h b/pandas/src/khash.h
index df76dcc1c..5822187b6 100644
--- a/pandas/src/khash.h
+++ b/pandas/src/khash.h
@@ -613,6 +613,8 @@ KHASH_SET_INIT_PYOBJECT(pyset)
 
 KHASH_MAP_INIT_STR(str, Py_ssize_t)
 
+KHASH_MAP_INIT_STR(strbox, kh_pyobject_t)
+
 KHASH_MAP_INIT_INT(int32, Py_ssize_t)
 KHASH_MAP_INIT_INT64(int64, Py_ssize_t)
 KHASH_MAP_INIT_FLOAT64(float64, Py_ssize_t)
diff --git a/pandas/src/khash.pxd b/pandas/src/khash.pxd
index ef3f355fc..43e231f54 100644
--- a/pandas/src/khash.pxd
+++ b/pandas/src/khash.pxd
@@ -55,6 +55,7 @@ cdef extern from "khash.h":
 
     bint kh_exist_str(kh_str_t*, khiter_t)
 
+
     ctypedef struct kh_int64_t:
         khint_t n_buckets, size, n_occupied, upper_bound
         uint32_t *flags
@@ -102,3 +103,22 @@ cdef extern from "khash.h":
     inline void kh_del_int32(kh_int32_t*, khint_t)
 
     bint kh_exist_int32(kh_int32_t*, khiter_t)
+
+    # sweep factorize
+
+    ctypedef struct kh_strbox_t:
+        khint_t n_buckets, size, n_occupied, upper_bound
+        uint32_t *flags
+        kh_cstr_t *keys
+        PyObject **vals
+
+    inline kh_strbox_t* kh_init_strbox()
+    inline void kh_destroy_strbox(kh_strbox_t*)
+    inline void kh_clear_strbox(kh_strbox_t*)
+    inline khint_t kh_get_strbox(kh_strbox_t*, kh_cstr_t)
+    inline void kh_resize_strbox(kh_strbox_t*, khint_t)
+    inline khint_t kh_put_strbox(kh_strbox_t*, kh_cstr_t, int*)
+    inline void kh_del_strbox(kh_strbox_t*, khint_t)
+
+    bint kh_exist_strbox(kh_strbox_t*, khiter_t)
+
diff --git a/pandas/src/parser.pyx b/pandas/src/parser.pyx
index f001fa374..1d8b9c00d 100644
--- a/pandas/src/parser.pyx
+++ b/pandas/src/parser.pyx
@@ -3,6 +3,10 @@ import numpy as np
 
 cnp.import_array()
 
+from khash cimport *
+
+from cpython cimport PyString_FromString, Py_INCREF, PyString_AsString
+
 cdef extern from "Python.h":
     ctypedef struct FILE
     FILE* PyFile_AsFile(object)
@@ -143,8 +147,10 @@ cdef class TextReader:
 
     cdef public:
         object delimiter, na_values, converters, thousands, delim_whitespace
+        object memory_map
 
-    def __cinit__(self, source, delimiter=',', header=0, memory_map=False,
+    def __cinit__(self, source, delimiter=',', header=0,
+                  memory_map=False,
                   chunksize=DEFAULT_CHUNKSIZE,
                   delim_whitespace=False,
                   na_values=None,
@@ -173,6 +179,7 @@ cdef class TextReader:
         self.delimiter = delimiter
         self.delim_whitespace = delim_whitespace
 
+        self.memory_map = memory_map
         self.na_values = na_values
         self.converters = converters
         self.thousands = thousands
@@ -185,7 +192,8 @@ cdef class TextReader:
             self.file_handle.close()
 
     cdef _setup_parser_source(self, source):
-        cdef int status
+        cdef:
+            int status
 
         if isinstance(source, (basestring, file)):
             if isinstance(source, basestring):
@@ -193,8 +201,13 @@ cdef class TextReader:
                 self.should_close = True
 
             self.file_handle = source
-            status = parser_file_source_init(self.parser,
-                                             PyFile_AsFile(source))
+
+            if self.memory_map:
+                status = parser_mmap_init(self.parser,
+                                          PyFile_AsFile(source))
+            else:
+                status = parser_file_source_init(self.parser,
+                                                 PyFile_AsFile(source))
 
             if status != 0:
                 raise Exception('Initializing from file failed')
@@ -209,7 +222,8 @@ cdef class TextReader:
                 raise ValueError('Only ascii/bytes supported at the moment')
 
             status = parser_array_source_init(self.parser,
-                                              <char*> bytes, len(bytes))
+                                              PyString_AsString(bytes),
+                                              len(bytes))
             if status != 0:
                 raise Exception('Initializing parser from file-like '
                                 'object failed')
@@ -248,6 +262,10 @@ cdef class TextReader:
         for i in range(ncols):
             col_res = _try_double(self.parser, i, 0, self.parser.lines)
 
+            if col_res is None:
+                col_res = _string_box_factorize(self.parser, i,
+                                                0, self.parser.lines)
+
             results[i] = col_res
 
         return results
@@ -256,6 +274,54 @@ class CParserError(Exception):
     pass
 
 
+# ----------------------------------------------------------------------
+# Type conversions / inference support code
+
+cdef _string_box_factorize(parser_t *parser, int col,
+                           int line_start, int line_end):
+    cdef:
+        int error
+        Py_ssize_t i
+        size_t lines
+        coliter_t it
+        char *word
+        cnp.ndarray[object] result
+
+        int ret = 0
+        kh_strbox_t *table
+        kh_iter_t
+
+        object pyval
+
+
+    table = kh_init_strbox()
+
+    lines = line_end - line_start
+    result = np.empty(lines, dtype=np.object_)
+
+    coliter_setup(&it, parser, col)
+    for i in range(lines):
+        word = COLITER_NEXT(it)
+
+        k = kh_get_strbox(table, word)
+
+        # in the hash table
+        if k != table.n_buckets:
+            # this increments the refcount, but need to test
+            pyval = <object> table.vals[k]
+        else:
+            # box it. new ref?
+            pyval = PyString_FromString(word)
+
+            k = kh_put_strbox(table, word, &ret)
+            table.vals[k] = <PyObject*> pyval
+
+        result[i] = pyval
+
+    return result
+
+
+
 cdef _try_double(parser_t *parser, int col, int line_start, int line_end):
     cdef:
         int error
diff --git a/pandas/src/parser/rows.c b/pandas/src/parser/rows.c
index b79a34a68..3d0256aaf 100644
--- a/pandas/src/parser/rows.c
+++ b/pandas/src/parser/rows.c
@@ -26,6 +26,30 @@
 
 
 
+#define REACHED_EOF 1
+
+#define HAVE_MEMMAP
+#define HAVE_GZIP
+
+#define FB_EOF   -1
+#define FB_ERROR -2
+
+/*
+ * restore:
+ *  RESTORE_NOT     (0):
+ *      Free memory, but leave the file position wherever it
+ *      happend to be.
+ *  RESTORE_INITIAL (1):
+ *      Restore the file position to the location at which
+ *      the file_buffer was created.
+ *  RESTORE_FINAL   (2):
+ *      Put the file position at the next byte after the
+ *      data read from the file_buffer.
+ */
+#define RESTORE_NOT     0
+#define RESTORE_INITIAL 1
+#define RESTORE_FINAL   2
+
 
 
 
@@ -153,7 +177,10 @@ typedef struct _array_source {
 void *new_array_source(char *data, size_t length) {
 	array_source *ars = (array_source *) malloc(sizeof(array_source));
 
-	ars->data = data;
+	// to be safe, copy the data from the Python string
+	ars->data = malloc(length + 1);
+	strcpy(ars->data, data);
+
 	ars->position = 0;
 	ars->length = length;
 
@@ -673,7 +700,125 @@ int parser_file_source_init(parser_t *self, FILE* fp) {
 	return 0;
 }
 
+// XXX handle on systems without the capability
+
+#include <sys/stat.h>
+#include <sys/mman.h>
+
+typedef struct _memory_map {
+
+    FILE *file;
+
+    /* Size of the file, in bytes. */
+    off_t size;
+
+    /* file position when the file_buffer was created. */
+    off_t initial_file_pos;
+
+    int line_number;
+
+    int fileno;
+    off_t position;
+    off_t last_pos;
+    char *memmap;
+
+} memory_map;
+
+#define MM(src) ((memory_map*) src)
+
+
+/*
+ *  void *new_file_buffer(FILE *f, int buffer_size)
+ *
+ *  Allocate a new file_buffer.
+ *  Returns NULL if the memory allocation fails or if the call to mmap fails.
+ *
+ *  buffer_size is ignored.
+ */
+
+void *new_mmap(FILE *f)
+{
+    struct stat buf;
+    int fd;
+    memory_map *mm;
+    off_t position;
+    off_t filesize;
+
+    fd = fileno(f);
+    if (fstat(fd, &buf) == -1) {
+        fprintf(stderr, "new_file_buffer: fstat() failed. errno =%d\n", errno);
+        return NULL;
+    }
+    filesize = buf.st_size;  /* XXX This might be 32 bits. */
+
+    mm = (memory_map *) malloc(sizeof(memory_map));
+    if (mm == NULL) {
+        /* XXX Eventually remove this print statement. */
+        fprintf(stderr, "new_file_buffer: malloc() failed.\n");
+        return NULL;
+    }
+    mm->file = f;
+    mm->size = (off_t) filesize;
+    mm->line_number = 0;
+
+    mm->fileno = fd;
+    mm->position = ftell(f);
+    mm->last_pos = (off_t) filesize;
+
+    mm->memmap = mmap(NULL, filesize, PROT_READ, MAP_SHARED, fd, 0);
+    if (mm->memmap == NULL) {
+        /* XXX Eventually remove this print statement. */
+        fprintf(stderr, "new_file_buffer: mmap() failed.\n");
+        free(mm);
+        mm = NULL;
+    }
+
+    return (void*) mm;
+}
+
+
+void del_mmap(void *src)
+{
+    munmap(MM(src)->memmap, MM(src)->size);
+
+    /*
+     *  With a memory mapped file, there is no need to do
+     *  anything if restore == RESTORE_INITIAL.
+     */
+    /* if (restore == RESTORE_FINAL) { */
+    /*     fseek(FB(fb)->file, FB(fb)->current_pos, SEEK_SET); */
+    /* } */
+    free(src);
+}
+
+int _buffer_mmap_bytes(parser_t *self, size_t nbytes) {
+	memory_map *src = MM(self->source);
+
+	if (src->position == src->last_pos) {
+		return REACHED_EOF;
+	}
+
+	self->data = src->memmap + src->position;
+
+	if (src->position + nbytes > src->last_pos) {
+		// fewer than nbytes remaining
+		self->datalen = src->last_pos - src->position;
+	} else {
+		self->datalen = nbytes;
+	}
+
+	src->position += self->datalen;
+	return 0;
+}
+
 int parser_mmap_init(parser_t *self, FILE* fp) {
+	self->sourcetype = 'M';
+	self->source = new_mmap(fp);
+
+	// TODO: better error message
+	if (NULL == self->source)
+		return -1;
+
 	return 0;
 }
 
@@ -752,7 +897,7 @@ int make_stream_space(parser_t *self, size_t nbytes) {
 
     // Can we fit potentially nbytes tokens (+ null terminators) in the stream?
 
-    TRACE(("maybe growing buffers\n"))
+    TRACE(("maybe growing buffers\n"));
 
     /*
       TOKEN STREAM
@@ -796,6 +941,7 @@ int make_stream_space(parser_t *self, size_t nbytes) {
         return PARSER_OUT_OF_MEMORY;
     }
 
+
     // realloc took place
     if (cap != self->words_cap) {
         self->word_starts = (int*) safe_realloc((void *) self->word_starts,
@@ -805,6 +951,7 @@ int make_stream_space(parser_t *self, size_t nbytes) {
         }
     }
 
+
     /*
       LINE VECTORS
     */
@@ -937,36 +1084,15 @@ int parser_cleanup(parser_t *self) {
     return 0;
 }
 
-#define REACHED_EOF 1
-
-#define HAVE_MEMMAP
-#define HAVE_GZIP
-
-#define FB_EOF   -1
-#define FB_ERROR -2
-
-/*
- * restore:
- *  RESTORE_NOT     (0):
- *      Free memory, but leave the file position wherever it
- *      happend to be.
- *  RESTORE_INITIAL (1):
- *      Restore the file position to the location at which
- *      the file_buffer was created.
- *  RESTORE_FINAL   (2):
- *      Put the file position at the next byte after the
- *      data read from the file_buffer.
- */
-#define RESTORE_NOT     0
-#define RESTORE_INITIAL 1
-#define RESTORE_FINAL   2
-
 int parser_buffer_bytes(parser_t *self, size_t nbytes) {
+	int status;
     size_t bytes;
 	void *src = self->source;
 
 	// This should probably end up as a method table
 
+	status = 0;
+
 	switch(self->sourcetype) {
 		case 'F': // basic FILE*
 
@@ -979,34 +1105,18 @@ int parser_buffer_bytes(parser_t *self, size_t nbytes) {
 			// printf("%s\n", self->data);
 
 			if (bytes == 0) {
-				return REACHED_EOF;
+				status = REACHED_EOF;
 			}
 			break;
 
 		case 'A': // in-memory bytes (e.g. from StringIO)
-			if (ARS(src)->position == ARS(src)->length) {
-				return REACHED_EOF;
-			}
-
-			self->data = ARS(src)->data + ARS(src)->position;
-
-			if (ARS(src)->position + nbytes > ARS(src)->length) {
-				// fewer than nbytes remaining
-				self->datalen = ARS(src)->length - ARS(src)->position;
-			} else {
-				self->datalen = nbytes;
-			}
-
-			ARS(src)->position += self->datalen;
-
-			TRACE(("datalen: %d\n", self->datalen));
-
-			TRACE(("pos: %d, length: %d", ARS(src)->position, ARS(src)->length));
-
+			// ew, side effects
+			status = _buffer_array_bytes(self, nbytes);
 			break;
 
 #ifdef HAVE_MEMMAP
 		case 'M': // memory map
+			status = _buffer_mmap_bytes(self, nbytes);
 
 			break;
 #endif
@@ -1019,9 +1129,34 @@ int parser_buffer_bytes(parser_t *self, size_t nbytes) {
 
 	}
 
-    return 0;
+    return status;
 }
 
+int _buffer_array_bytes(parser_t *self, size_t nbytes) {
+	array_source *src = ARS(self->source);
+
+	if (src->position == src->length) {
+		return REACHED_EOF;
+	}
+
+	self->data = src->data + src->position;
+
+	if (src->position + nbytes > src->length) {
+		// fewer than nbytes remaining
+		self->datalen = src->length - src->position;
+	} else {
+		self->datalen = nbytes;
+	}
+
+	src->position += self->datalen;
+
+	TRACE(("datalen: %d\n", self->datalen));
+
+	TRACE(("pos: %d, length: %d", src->position, src->length));
+	return 0;
+}
+
+
 int parser_cleanup_filebuffers(parser_t *self) {
 	switch(self->sourcetype) {
 
@@ -1035,7 +1170,7 @@ int parser_cleanup_filebuffers(parser_t *self) {
 
 #ifdef HAVE_MEMMAP
 		case 'M': // memory map
-
+			del_mmap(self->source);
 			break;
 #endif
 
@@ -1094,11 +1229,20 @@ int tokenize_buffered_bytes(parser_t *self)
 	stream = self->stream + self->stream_len;
 	slen = self->stream_len;
 
+	TRACE(("%s\n", buf));
+
     for (i = 0; i < self->datalen; ++i)
     {
         // Next character in file
         c = *buf++;
 
+		/* if (c == '\0') { */
+		/* 	continue; */
+		/* } */
+
+		TRACE(("Iter: %d Char: %c Line %d field_count %d\n",
+			   i, c, self->lines + 1, self->line_fields[self->lines]));
+
         switch(self->state) {
         case START_RECORD:
             // start of record
