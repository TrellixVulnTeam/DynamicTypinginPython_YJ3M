commit 8aca32a63834102c912740b8fad46de8000c0c0e
Author: Adam Klein <adamklein@gmail.com>
Date:   Fri Feb 17 21:02:52 2012 -0500

    ENH: added group sum/mean/var by bins, with tests

diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index 991ceafaf..7730077c4 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -216,11 +216,8 @@ def groupsort_indexer(ndarray[int32_t] index, Py_ssize_t ngroups):
 
     return result, counts
 
-
 # TODO: aggregate multiple columns in single pass
 
-# TODO: add passing bin edges, instead of labels
-
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_add(ndarray[float64_t, ndim=2] out,
@@ -384,6 +381,189 @@ def group_var(ndarray[float64_t, ndim=2] out,
                 out[i, j] = ((ct * sumxx[i, j] - sumx[i, j] * sumx[i, j]) /
                              (ct * ct - ct))
 
+
+@cython.boundscheck(False)
+@cython.wraparound(False)
+cdef ndarray[int32_t] counts_by_bins(ndarray[int32_t] bins,
+                                     Py_ssize_t datalen):
+    cdef:
+        Py_ssize_t ngroups = len(bins)
+        i = 0
+
+    counts = np.zeros(ngroups, dtype='i4')
+
+    if ngroups > 0:
+        counts[0] = bins[0]
+        for i in range(1, ngroups):
+            if i == ngroups - 1:
+                counts[i] = datalen - bins[i-1]
+            else:
+                counts[i] = bins[i] - bins[i-1]
+
+    return counts
+
+# add passing bin edges, instead of labels
+
+@cython.boundscheck(False)
+@cython.wraparound(False)
+def group_add_bin(ndarray[float64_t, ndim=2] out,
+                  ndarray[float64_t, ndim=2] values,
+                  ndarray[int32_t] bins):
+    '''
+    Only aggregates on axis=0
+    '''
+    cdef:
+        Py_ssize_t i, j, N, K, ngroups, b
+        float64_t val, count
+        ndarray[float64_t, ndim=2] sumx, nobs
+        ndarray[int32_t] counts
+
+    nobs = np.zeros_like(out)
+    sumx = np.zeros_like(out)
+
+    ngroups = len(bins) + 1
+    N, K = (<object> values).shape
+    counts = counts_by_bins(bins, N)
+
+    b = 0
+    if K > 1:
+        for i in range(N):
+            if b < ngroups - 1 and i >= bins[b]:
+                b += 1
+
+            for j in range(K):
+                val = values[i, j]
+
+                # not nan
+                if val == val:
+                    nobs[b, j] += 1
+                    sumx[b, j] += val
+    else:
+        for i in range(N):
+            if b < ngroups - 1 and i >= bins[b]:
+                b += 1
+
+            val = values[i, 0]
+
+            # not nan
+            if val == val:
+                nobs[b, 0] += 1
+                sumx[b, 0] += val
+
+    for i in range(ngroups):
+        for j in range(K):
+            if nobs[i, j] == 0:
+                out[i, j] = nan
+            else:
+                out[i, j] = sumx[i, j]
+
+@cython.boundscheck(False)
+@cython.wraparound(False)
+def group_mean_bin(ndarray[float64_t, ndim=2] out,
+                   ndarray[float64_t, ndim=2] values,
+                   ndarray[int32_t] bins):
+    cdef:
+        Py_ssize_t i, j, N, K, ngroups, b
+        float64_t val, count
+        ndarray[float64_t, ndim=2] sumx, nobs
+        ndarray[int32_t] counts
+
+    nobs = np.zeros_like(out)
+    sumx = np.zeros_like(out)
+
+    ngroups = len(bins) + 1
+    N, K = (<object> values).shape
+    counts = counts_by_bins(bins, N)
+
+    b = 0
+    if K > 1:
+        for i in range(N):
+            if b < ngroups - 1 and i >= bins[b]:
+                b += 1
+
+            for j in range(K):
+                val = values[i, j]
+
+                # not nan
+                if val == val:
+                    nobs[b, j] += 1
+                    sumx[b, j] += val
+    else:
+        for i in range(N):
+            if b < ngroups - 1 and i >= bins[b]:
+                b += 1
+
+            val = values[i, 0]
+
+            # not nan
+            if val == val:
+                nobs[b, 0] += 1
+                sumx[b, 0] += val
+
+    for i in range(ngroups):
+        for j in range(K):
+            count = nobs[i, j]
+            if nobs[i, j] == 0:
+                out[i, j] = nan
+            else:
+                out[i, j] = sumx[i, j] / count
+
+@cython.boundscheck(False)
+@cython.wraparound(False)
+def group_var_bin(ndarray[float64_t, ndim=2] out,
+                  ndarray[float64_t, ndim=2] values,
+                  ndarray[int32_t] bins):
+
+    cdef:
+        Py_ssize_t i, j, N, K, ngroups, b
+        float64_t val, ct
+        ndarray[float64_t, ndim=2] nobs, sumx, sumxx
+        ndarray[int32_t] counts
+
+    nobs = np.zeros_like(out)
+    sumx = np.zeros_like(out)
+    sumxx = np.zeros_like(out)
+
+    ngroups = len(bins) + 1
+    N, K = (<object> values).shape
+    counts = counts_by_bins(bins, N)
+
+    b = 0
+    if K > 1:
+        for i in range(N):
+            if b < ngroups - 1 and i >= bins[b]:
+                b += 1
+
+            for j in range(K):
+                val = values[i, j]
+
+                # not nan
+                if val == val:
+                    nobs[b, j] += 1
+                    sumx[b, j] += val
+                    sumxx[b, j] += val * val
+    else:
+        for i in range(N):
+            if b < ngroups - 1 and i >= bins[b]:
+                b += 1
+
+            val = values[i, 0]
+
+            # not nan
+            if val == val:
+                nobs[b, 0] += 1
+                sumx[b, 0] += val
+                sumxx[b, 0] += val * val
+
+    for i in range(ngroups):
+        for j in range(K):
+            ct = nobs[i, j]
+            if ct < 2:
+                out[i, j] = nan
+            else:
+                out[i, j] = ((ct * sumxx[i, j] - sumx[i, j] * sumx[i, j]) /
+                             (ct * ct - ct))
+
 def group_count(ndarray[int32_t] values, Py_ssize_t size):
     cdef:
         Py_ssize_t i, n = len(values)
diff --git a/pandas/src/reduce.pyx b/pandas/src/reduce.pyx
index b80a2aace..e987af9c0 100644
--- a/pandas/src/reduce.pyx
+++ b/pandas/src/reduce.pyx
@@ -128,7 +128,7 @@ cdef class SeriesBinGrouper:
         cdef:
             ndarray arr, result
             ndarray[int32_t] counts
-            Py_ssize_t i, n, group_size, lab
+            Py_ssize_t i, n, group_size
             object res, chunk
             bint initialized = 0
             Slider vslider, islider
diff --git a/pandas/tests/test_tseries.py b/pandas/tests/test_tseries.py
index a5f254ec7..788696397 100644
--- a/pandas/tests/test_tseries.py
+++ b/pandas/tests/test_tseries.py
@@ -299,6 +299,54 @@ def test_series_bin_grouper():
     exp_counts = np.array([3, 3, 4], dtype=np.int32)
     assert_almost_equal(counts, exp_counts)
 
+def test_group_add_bin():
+    # original group_add
+    obj = np.random.randn(10, 1)
+
+    lab = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 2], dtype=np.int32)
+    cts = np.array([3, 3, 4], dtype=np.int32)
+    exp = np.zeros((3, 1), np.float64)
+    lib.group_add(exp, cts, obj, lab)
+
+    # bin-based group_add
+    bins = np.array([3, 6], dtype=np.int32)
+    out  = np.zeros((3, 1), np.float64)
+    lib.group_add_bin(out, obj, bins)
+
+    assert_almost_equal(out, exp)
+
+def test_group_mean_bin():
+    # original group_mean
+    obj = np.random.randn(10, 1)
+
+    lab = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 2], dtype=np.int32)
+    cts = np.array([3, 3, 4], dtype=np.int32)
+    exp = np.zeros((3, 1), np.float64)
+    lib.group_mean(exp, cts, obj, lab)
+
+    # bin-based group_mean
+    bins = np.array([3, 6], dtype=np.int32)
+    out  = np.zeros((3, 1), np.float64)
+    lib.group_mean_bin(out, obj, bins)
+
+    assert_almost_equal(out, exp)
+
+def test_group_var_bin():
+    # original group_var
+    obj = np.random.randn(10, 1)
+
+    lab = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 2], dtype=np.int32)
+    cts = np.array([3, 3, 4], dtype=np.int32)
+    exp = np.zeros((3, 1), np.float64)
+    lib.group_var(exp, cts, obj, lab)
+
+    # bin-based group_var
+    bins = np.array([3, 6], dtype=np.int32)
+    out  = np.zeros((3, 1), np.float64)
+    lib.group_var_bin(out, obj, bins)
+
+    assert_almost_equal(out, exp)
+
 class TestTypeInference(unittest.TestCase):
 
     def test_length_zero(self):
