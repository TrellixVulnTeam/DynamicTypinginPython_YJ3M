commit 133a2087d038da035a57ab90aad557a328b3d60b
Author: jschendel <jschendel@users.noreply.github.com>
Date:   Tue Aug 15 12:26:06 2017 -0600

    CLN: replace %s syntax with .format in pandas.core.reshape (#17252)
    
    Replaced %s syntax with .format in pandas.core.reshape.  Additionally, made some of the existing positional .format code more explicit.

diff --git a/pandas/core/reshape/concat.py b/pandas/core/reshape/concat.py
index 20d561738..9e180c624 100644
--- a/pandas/core/reshape/concat.py
+++ b/pandas/core/reshape/concat.py
@@ -220,7 +220,7 @@ class _Concatenator(object):
         if isinstance(objs, (NDFrame, compat.string_types)):
             raise TypeError('first argument must be an iterable of pandas '
                             'objects, you passed an object of type '
-                            '"{0}"'.format(type(objs).__name__))
+                            '"{name}"'.format(name=type(objs).__name__))
 
         if join == 'outer':
             self.intersect = False
@@ -309,8 +309,8 @@ class _Concatenator(object):
 
         self._is_series = isinstance(sample, Series)
         if not 0 <= axis <= sample.ndim:
-            raise AssertionError("axis must be between 0 and {0}, "
-                                 "input was {1}".format(sample.ndim, axis))
+            raise AssertionError("axis must be between 0 and {ndim}, input was"
+                                 " {axis}".format(ndim=sample.ndim, axis=axis))
 
         # if we have mixed ndims, then convert to highest ndim
         # creating column numbers as needed
@@ -431,8 +431,8 @@ class _Concatenator(object):
                 new_axes[i] = self._get_comb_axis(i)
         else:
             if len(self.join_axes) != ndim - 1:
-                raise AssertionError("length of join_axes must not be "
-                                     "equal to {0}".format(ndim - 1))
+                raise AssertionError("length of join_axes must not be equal "
+                                     "to {length}".format(length=ndim - 1))
 
             # ufff...
             indices = compat.lrange(ndim)
@@ -451,7 +451,8 @@ class _Concatenator(object):
                                            intersect=self.intersect)
         except IndexError:
             types = [type(x).__name__ for x in self.objs]
-            raise TypeError("Cannot concatenate list of %s" % types)
+            raise TypeError("Cannot concatenate list of {types}"
+                            .format(types=types))
 
     def _get_concat_axis(self):
         """
@@ -470,8 +471,8 @@ class _Concatenator(object):
                 for i, x in enumerate(self.objs):
                     if not isinstance(x, Series):
                         raise TypeError("Cannot concatenate type 'Series' "
-                                        "with object of type "
-                                        "%r" % type(x).__name__)
+                                        "with object of type {type!r}"
+                                        .format(type=type(x).__name__))
                     if x.name is not None:
                         names[i] = x.name
                         has_names = True
@@ -505,8 +506,8 @@ class _Concatenator(object):
         if self.verify_integrity:
             if not concat_index.is_unique:
                 overlap = concat_index.get_duplicates()
-                raise ValueError('Indexes have overlapping values: %s'
-                                 % str(overlap))
+                raise ValueError('Indexes have overlapping values: '
+                                 '{overlap!s}'.format(overlap=overlap))
 
 
 def _concat_indexes(indexes):
@@ -547,8 +548,8 @@ def _make_concat_multiindex(indexes, keys, levels=None, names=None):
                 try:
                     i = level.get_loc(key)
                 except KeyError:
-                    raise ValueError('Key %s not in level %s'
-                                     % (str(key), str(level)))
+                    raise ValueError('Key {key!s} not in level {level!s}'
+                                     .format(key=key, level=level))
 
                 to_concat.append(np.repeat(i, len(index)))
             label_list.append(np.concatenate(to_concat))
@@ -597,8 +598,8 @@ def _make_concat_multiindex(indexes, keys, levels=None, names=None):
 
         mask = mapped == -1
         if mask.any():
-            raise ValueError('Values not found in passed level: %s'
-                             % str(hlevel[mask]))
+            raise ValueError('Values not found in passed level: {hlevel!s}'
+                             .format(hlevel=hlevel[mask]))
 
         new_labels.append(np.repeat(mapped, n))
 
diff --git a/pandas/core/reshape/merge.py b/pandas/core/reshape/merge.py
index 00828b824..947300a28 100644
--- a/pandas/core/reshape/merge.py
+++ b/pandas/core/reshape/merge.py
@@ -534,28 +534,27 @@ class _MergeOperation(object):
                 'indicator option can only accept boolean or string arguments')
 
         if not isinstance(left, DataFrame):
-            raise ValueError(
-                'can not merge DataFrame with instance of '
-                'type {0}'.format(type(left)))
+            raise ValueError('can not merge DataFrame with instance of '
+                             'type {left}'.format(left=type(left)))
         if not isinstance(right, DataFrame):
-            raise ValueError(
-                'can not merge DataFrame with instance of '
-                'type {0}'.format(type(right)))
+            raise ValueError('can not merge DataFrame with instance of '
+                             'type {right}'.format(right=type(right)))
 
         if not is_bool(left_index):
             raise ValueError(
                 'left_index parameter must be of type bool, not '
-                '{0}'.format(type(left_index)))
+                '{left_index}'.format(left_index=type(left_index)))
         if not is_bool(right_index):
             raise ValueError(
                 'right_index parameter must be of type bool, not '
-                '{0}'.format(type(right_index)))
+                '{right_index}'.format(right_index=type(right_index)))
 
         # warn user when merging between different levels
         if left.columns.nlevels != right.columns.nlevels:
             msg = ('merging between different levels can give an unintended '
-                   'result ({0} levels on the left, {1} on the right)')
-            msg = msg.format(left.columns.nlevels, right.columns.nlevels)
+                   'result ({left} levels on the left, {right} on the right)'
+                   ).format(left=left.columns.nlevels,
+                            right=right.columns.nlevels)
             warnings.warn(msg, UserWarning)
 
         self._validate_specification()
@@ -613,7 +612,8 @@ class _MergeOperation(object):
         for i in ['_left_indicator', '_right_indicator']:
             if i in columns:
                 raise ValueError("Cannot use `indicator=True` option when "
-                                 "data contains a column named {}".format(i))
+                                 "data contains a column named {name}"
+                                 .format(name=i))
         if self.indicator_name in columns:
             raise ValueError(
                 "Cannot use name of an existing column for indicator column")
@@ -717,7 +717,7 @@ class _MergeOperation(object):
                 if name in result:
                     result[name] = key_col
                 else:
-                    result.insert(i, name or 'key_%d' % i, key_col)
+                    result.insert(i, name or 'key_{i}'.format(i=i), key_col)
 
     def _get_join_indexers(self):
         """ return the join indexers """
@@ -952,8 +952,8 @@ class _MergeOperation(object):
                 if len(common_cols) == 0:
                     raise MergeError('No common columns to perform merge on')
                 if not common_cols.is_unique:
-                    raise MergeError("Data columns not unique: %s"
-                                     % repr(common_cols))
+                    raise MergeError("Data columns not unique: {common!r}"
+                                     .format(common=common_cols))
                 self.left_on = self.right_on = common_cols
         elif self.on is not None:
             if self.left_on is not None or self.right_on is not None:
@@ -1119,12 +1119,14 @@ class _OrderedMerge(_MergeOperation):
 
 
 def _asof_function(direction, on_type):
-    return getattr(libjoin, 'asof_join_%s_%s' % (direction, on_type), None)
+    name = 'asof_join_{dir}_{on}'.format(dir=direction, on=on_type)
+    return getattr(libjoin, name, None)
 
 
 def _asof_by_function(direction, on_type, by_type):
-    return getattr(libjoin, 'asof_join_%s_%s_by_%s' %
-                   (direction, on_type, by_type), None)
+    name = 'asof_join_{dir}_{on}_by_{by}'.format(
+        dir=direction, on=on_type, by=by_type)
+    return getattr(libjoin, name, None)
 
 
 _type_casters = {
@@ -1153,7 +1155,7 @@ def _get_cython_type(dtype):
     type_name = _get_dtype(dtype).name
     ctype = _cython_types.get(type_name, 'object')
     if ctype == 'error':
-        raise MergeError('unsupported type: ' + type_name)
+        raise MergeError('unsupported type: {type}'.format(type=type_name))
     return ctype
 
 
@@ -1235,7 +1237,8 @@ class _AsOfMerge(_OrderedMerge):
 
         # check 'direction' is valid
         if self.direction not in ['backward', 'forward', 'nearest']:
-            raise MergeError('direction invalid: ' + self.direction)
+            raise MergeError('direction invalid: {direction}'
+                             .format(direction=self.direction))
 
     @property
     def _asof_key(self):
@@ -1264,7 +1267,7 @@ class _AsOfMerge(_OrderedMerge):
                 lt = left_join_keys[-1]
 
             msg = "incompatible tolerance, must be compat " \
-                  "with type {0}".format(type(lt))
+                  "with type {lt}".format(lt=type(lt))
 
             if is_datetime64_dtype(lt) or is_datetime64tz_dtype(lt):
                 if not isinstance(self.tolerance, Timedelta):
@@ -1283,8 +1286,8 @@ class _AsOfMerge(_OrderedMerge):
 
         # validate allow_exact_matches
         if not is_bool(self.allow_exact_matches):
-            raise MergeError("allow_exact_matches must be boolean, "
-                             "passed {0}".format(self.allow_exact_matches))
+            msg = "allow_exact_matches must be boolean, passed {passed}"
+            raise MergeError(msg.format(passed=self.allow_exact_matches))
 
         return left_join_keys, right_join_keys, join_names
 
@@ -1306,11 +1309,11 @@ class _AsOfMerge(_OrderedMerge):
         tolerance = self.tolerance
 
         # we required sortedness in the join keys
-        msg = " keys must be sorted"
+        msg = "{side} keys must be sorted"
         if not Index(left_values).is_monotonic:
-            raise ValueError('left' + msg)
+            raise ValueError(msg.format(side='left'))
         if not Index(right_values).is_monotonic:
-            raise ValueError('right' + msg)
+            raise ValueError(msg.format(side='right'))
 
         # initial type conversion as needed
         if needs_i8_conversion(left_values):
diff --git a/pandas/core/reshape/pivot.py b/pandas/core/reshape/pivot.py
index e08c307bb..f07123ca1 100644
--- a/pandas/core/reshape/pivot.py
+++ b/pandas/core/reshape/pivot.py
@@ -145,10 +145,10 @@ def _add_margins(table, data, values, rows, cols, aggfunc,
     if not isinstance(margins_name, compat.string_types):
         raise ValueError('margins_name argument must be a string')
 
-    exception_msg = 'Conflicting name "{0}" in margins'.format(margins_name)
+    msg = 'Conflicting name "{name}" in margins'.format(name=margins_name)
     for level in table.index.names:
         if margins_name in table.index.get_level_values(level):
-            raise ValueError(exception_msg)
+            raise ValueError(msg)
 
     grand_margin = _compute_grand_margin(data, values, aggfunc, margins_name)
 
@@ -156,7 +156,7 @@ def _add_margins(table, data, values, rows, cols, aggfunc,
     if hasattr(table, 'columns'):
         for level in table.columns.names[1:]:
             if margins_name in table.columns.get_level_values(level):
-                raise ValueError(exception_msg)
+                raise ValueError(msg)
 
     if len(rows) > 1:
         key = (margins_name,) + ('',) * (len(rows) - 1)
@@ -553,7 +553,7 @@ def _get_names(arrs, names, prefix='row'):
             if isinstance(arr, ABCSeries) and arr.name is not None:
                 names.append(arr.name)
             else:
-                names.append('%s_%d' % (prefix, i))
+                names.append('{prefix}_{i}'.format(prefix=prefix, i=i))
     else:
         if len(names) != len(arrs):
             raise AssertionError('arrays and names must have the same length')
diff --git a/pandas/core/reshape/reshape.py b/pandas/core/reshape/reshape.py
index b7638471f..455da9246 100644
--- a/pandas/core/reshape/reshape.py
+++ b/pandas/core/reshape/reshape.py
@@ -1,6 +1,6 @@
 # pylint: disable=E1101,E1103
 # pylint: disable=W0703,W0622,W0613,W0201
-from pandas.compat import range, zip
+from pandas.compat import range, text_type, zip
 from pandas import compat
 import itertools
 import re
@@ -91,8 +91,8 @@ class _Unstacker(object):
 
         if isinstance(self.index, MultiIndex):
             if index._reference_duplicate_name(level):
-                msg = ("Ambiguous reference to {0}. The index "
-                       "names are not unique.".format(level))
+                msg = ("Ambiguous reference to {level}. The index "
+                       "names are not unique.".format(level=level))
                 raise ValueError(msg)
 
         self.level = self.index._get_level_number(level)
@@ -229,7 +229,7 @@ class _Unstacker(object):
             sorted_values = sorted_values.astype(name, copy=False)
 
         # fill in our values & mask
-        f = getattr(_reshape, "unstack_{}".format(name))
+        f = getattr(_reshape, "unstack_{name}".format(name=name))
         f(sorted_values,
           mask.view('u1'),
           stride,
@@ -516,8 +516,8 @@ def stack(frame, level=-1, dropna=True):
     N, K = frame.shape
     if isinstance(frame.columns, MultiIndex):
         if frame.columns._reference_duplicate_name(level):
-            msg = ("Ambiguous reference to {0}. The column "
-                   "names are not unique.".format(level))
+            msg = ("Ambiguous reference to {level}. The column "
+                   "names are not unique.".format(level=level))
             raise ValueError(msg)
 
     # Will also convert negative level numbers and check if out of bounds.
@@ -747,7 +747,7 @@ def melt(frame, id_vars=None, value_vars=None, var_name=None,
             if len(frame.columns.names) == len(set(frame.columns.names)):
                 var_name = frame.columns.names
             else:
-                var_name = ['variable_%s' % i
+                var_name = ['variable_{i}'.format(i=i)
                             for i in range(len(frame.columns.names))]
         else:
             var_name = [frame.columns.name if frame.columns.name is not None
@@ -1027,7 +1027,8 @@ def wide_to_long(df, stubnames, i, j, sep="", suffix='\d+'):
     in a typicaly case.
     """
     def get_var_names(df, stub, sep, suffix):
-        regex = "^{0}{1}{2}".format(re.escape(stub), re.escape(sep), suffix)
+        regex = "^{stub}{sep}{suffix}".format(
+            stub=re.escape(stub), sep=re.escape(sep), suffix=suffix)
         return df.filter(regex=regex).columns.tolist()
 
     def melt_stub(df, stub, i, j, value_vars, sep):
@@ -1180,13 +1181,14 @@ def get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False,
 
         # validate prefixes and separator to avoid silently dropping cols
         def check_len(item, name):
-            length_msg = ("Length of '{0}' ({1}) did not match the length of "
-                          "the columns being encoded ({2}).")
+            len_msg = ("Length of '{name}' ({len_item}) did not match the "
+                       "length of the columns being encoded ({len_enc}).")
 
             if is_list_like(item):
                 if not len(item) == len(columns_to_encode):
-                    raise ValueError(length_msg.format(name, len(item),
-                                                       len(columns_to_encode)))
+                    len_msg = len_msg.format(name=name, len_item=len(item),
+                                             len_enc=len(columns_to_encode))
+                    raise ValueError(len_msg)
 
         check_len(prefix, 'prefix')
         check_len(prefix_sep, 'prefix_sep')
@@ -1253,7 +1255,10 @@ def _get_dummies_1d(data, prefix, prefix_sep='_', dummy_na=False,
     number_of_cols = len(levels)
 
     if prefix is not None:
-        dummy_cols = ['%s%s%s' % (prefix, prefix_sep, v) for v in levels]
+        dummy_strs = [u'{prefix}{sep}{level}' if isinstance(v, text_type)
+                      else '{prefix}{sep}{level}' for v in levels]
+        dummy_cols = [dummy_str.format(prefix=prefix, sep=prefix_sep, level=v)
+                      for dummy_str, v in zip(dummy_strs, levels)]
     else:
         dummy_cols = levels
 
diff --git a/pandas/core/reshape/tile.py b/pandas/core/reshape/tile.py
index 1cb39faa2..2f5538556 100644
--- a/pandas/core/reshape/tile.py
+++ b/pandas/core/reshape/tile.py
@@ -229,9 +229,9 @@ def _bins_to_cuts(x, bins, right=True, labels=None,
     unique_bins = algos.unique(bins)
     if len(unique_bins) < len(bins) and len(bins) != 2:
         if duplicates == 'raise':
-            raise ValueError("Bin edges must be unique: {}.\nYou "
+            raise ValueError("Bin edges must be unique: {bins!r}.\nYou "
                              "can drop duplicate edges by setting "
-                             "the 'duplicates' kwarg".format(repr(bins)))
+                             "the 'duplicates' kwarg".format(bins=bins))
         else:
             bins = unique_bins
 
