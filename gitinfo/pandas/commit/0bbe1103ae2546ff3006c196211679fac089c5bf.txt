commit 0bbe1103ae2546ff3006c196211679fac089c5bf
Author: Jeff Reback <jeff@reback.net>
Date:   Wed Nov 25 18:06:23 2015 -0500

    DOC: minor doc corrections

diff --git a/doc/source/computation.rst b/doc/source/computation.rst
index d07257bd2..c85ed2675 100644
--- a/doc/source/computation.rst
+++ b/doc/source/computation.rst
@@ -220,7 +220,7 @@ and kurtosis.
 
 .. note::
 
-   The API for window statistics is quite similar to the way one works with ``Groupby`` objects, see the documentation :ref:`here <groupby>`
+   The API for window statistics is quite similar to the way one works with ``GroupBy`` objects, see the documentation :ref:`here <groupby>`
 
 We work with ``rolling``, ``expanding`` and ``exponentially weighted`` data through the corresponding
 objects, :class:`~pandas.core.window.Rolling`, :class:`~pandas.core.window.Expanding` and :class:`~pandas.core.window.EWM`.
@@ -231,7 +231,7 @@ objects, :class:`~pandas.core.window.Rolling`, :class:`~pandas.core.window.Expan
    s = s.cumsum()
    s
 
-These are created from methods on ``Series`` and ``DataFrames``.
+These are created from methods on ``Series`` and ``DataFrame``.
 
 .. ipython:: python
 
@@ -247,7 +247,7 @@ accept the following arguments:
 - ``freq``: optionally specify a :ref:`frequency string <timeseries.alias>`
   or :ref:`DateOffset <timeseries.offsets>` to pre-conform the data to.
 
-We can then call functions on these ``rolling`` objects. Which return like-indexed objects:
+We can then call methods on these ``rolling`` objects. These return like-indexed objects:
 
 .. ipython:: python
 
@@ -304,8 +304,6 @@ We provide a number of the common statistical functions:
     :meth:`~Rolling.apply`, Generic apply
     :meth:`~Rolling.cov`, Unbiased covariance (binary)
     :meth:`~Rolling.corr`, Correlation (binary)
-    :meth:`~Window.mean`, Moving window mean function
-    :meth:`~Window.sum`, Moving window sum function
 
 The :meth:`~Rolling.apply` function takes an extra ``func`` argument and performs
 generic rolling computations. The ``func`` argument should be a single function
@@ -323,9 +321,17 @@ compute the mean absolute deviation on a rolling basis:
 Rolling Windows
 ~~~~~~~~~~~~~~~
 
-The :meth:`~Window.mean`, and :meth:`~Window.sum` functions perform a generic rolling window computation
-on the input data. The weights used in the window are specified by the ``win_type``
-keyword. The list of recognized types are:
+Passing ``win_type`` to ``.rolling`` generates a generic rolling window computation, that is weighted according the ``win_type``.
+The following methods are available:
+
+.. csv-table::
+    :header: "Method", "Description"
+    :widths: 20, 80
+
+    :meth:`~Window.sum`, Sum of values
+    :meth:`~Window.mean`, Mean of values
+
+The weights used in the window are specified by the ``win_type``keyword. The list of recognized types are:
 
 - ``boxcar``
 - ``triang``
@@ -484,9 +490,9 @@ We can aggregate by passing a function to the entire DataFrame, or select a Seri
 
    r['A'].aggregate(np.sum)
 
-   r['A','B'].aggregate(np.sum)
+   r[['A','B']].aggregate(np.sum)
 
-As you can see, the result of the aggregation will have the selection columns, or all
+As you can see, the result of the aggregation will have the selected columns, or all
 columns if none are selected.
 
 .. _stats.aggregate.multifunc:
@@ -531,7 +537,7 @@ columns of a DataFrame:
           'B' : lambda x: np.std(x, ddof=1)})
 
 The function names can also be strings. In order for a string to be valid it
-must be either implemented on the Windowed object
+must be implemented on the Windowed object
 
 .. ipython:: python
 
diff --git a/pandas/core/base.py b/pandas/core/base.py
index fafd6b782..84a127a46 100644
--- a/pandas/core/base.py
+++ b/pandas/core/base.py
@@ -361,8 +361,8 @@ aggregated : DataFrame
 
 See also
 --------
-:func:`pandas.Series.%(name)s`
-:func:`pandas.DataFrame.%(name)s`
+`pandas.Series.%(name)s`
+`pandas.DataFrame.%(name)s`
 """
 
     def aggregate(self, func, *args, **kwargs):
@@ -465,9 +465,9 @@ See also
                     # find a good name, this could be a function that we don't recognize
                     name = self._is_cython_func(a) or a
                     if not isinstance(name, compat.string_types):
-                        name = getattr(a,name,a)
+                        name = getattr(a,'name',a)
                     if not isinstance(name, compat.string_types):
-                        name = getattr(a,func_name,a)
+                        name = getattr(a,'__name__',a)
 
                     keys.append(name)
                 except (TypeError, DataError):
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 61fcf55af..ac07c9487 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -22,6 +22,7 @@ from pandas.core.series import Series
 from pandas.core.panel import Panel
 from pandas.util.decorators import (cache_readonly, Substitution, Appender, make_signature,
                                     deprecate_kwarg)
+from textwrap import dedent
 import pandas.core.algorithms as algos
 import pandas.core.common as com
 from pandas.core.common import(_possibly_downcast_to_dtype, isnull,
@@ -39,15 +40,15 @@ import pandas.hashtable as _hash
 
 _doc_template = """
 
-Returns
--------
-same type as input
+        Returns
+        -------
+        same type as input
 
-See also
---------
-:func:`pandas.Series.%(name)s`
-:func:`pandas.DataFrame.%(name)s`
-:func:`pandas.Panel.%(name)s`
+        See also
+        --------
+        `pandas.Series.%(name)s`
+        `pandas.DataFrame.%(name)s`
+        `pandas.Panel.%(name)s`
 """
 
 # special case to prevent duplicate plots when catching exceptions when
@@ -629,43 +630,45 @@ class GroupBy(PandasObject, SelectionMixin):
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def apply(self, func, *args, **kwargs):
-        """Apply function and combine results together in an intelligent way. The
-split-apply-combine combination rules attempt to be as common sense
-based as possible. For example:
-
-case 1:
-group DataFrame
-apply aggregation function (f(chunk) -> Series)
-yield DataFrame, with group axis having group labels
-
-case 2:
-group DataFrame
-apply transform function ((f(chunk) -> DataFrame with same indexes)
-yield DataFrame with resulting chunks glued together
-
-case 3:
-group Series
-apply function with f(chunk) -> DataFrame
-yield DataFrame with result of chunks glued together
-
-Parameters
-----------
-func : function
-
-Notes
------
-See online documentation for full exposition on how to use apply.
-
-In the current implementation apply calls func twice on the
-first group to decide whether it can take a fast or slow code
-path. This can lead to unexpected behavior if func has
-side-effects, as they will take effect twice for the first
-group.
-
-
-See also
---------
-aggregate, transform"""
+        """
+        Apply function and combine results together in an intelligent way. The
+        split-apply-combine combination rules attempt to be as common sense
+        based as possible. For example:
+
+        case 1:
+        group DataFrame
+        apply aggregation function (f(chunk) -> Series)
+        yield DataFrame, with group axis having group labels
+
+        case 2:
+        group DataFrame
+        apply transform function ((f(chunk) -> DataFrame with same indexes)
+        yield DataFrame with resulting chunks glued together
+
+        case 3:
+        group Series
+        apply function with f(chunk) -> DataFrame
+        yield DataFrame with result of chunks glued together
+
+        Parameters
+        ----------
+        func : function
+
+        Notes
+        -----
+        See online documentation for full exposition on how to use apply.
+
+        In the current implementation apply calls func twice on the
+        first group to decide whether it can take a fast or slow code
+        path. This can lead to unexpected behavior if func has
+        side-effects, as they will take effect twice for the first
+        group.
+
+
+        See also
+        --------
+        aggregate, transform"""
+
         func = self._is_builtin_func(func)
 
         @wraps(func)
@@ -710,7 +713,8 @@ aggregate, transform"""
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def mean(self):
-        """Compute mean of groups, excluding missing values
+        """
+        Compute mean of groups, excluding missing values
 
         For multiple groupings, the result index will be a MultiIndex
         """
@@ -726,7 +730,8 @@ aggregate, transform"""
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def median(self):
-        """Compute median of groups, excluding missing values
+        """
+        Compute median of groups, excluding missing values
 
         For multiple groupings, the result index will be a MultiIndex
         """
@@ -746,14 +751,16 @@ aggregate, transform"""
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def std(self, ddof=1):
-        """Compute standard deviation of groups, excluding missing values
+        """
+        Compute standard deviation of groups, excluding missing values
 
-For multiple groupings, the result index will be a MultiIndex
+        For multiple groupings, the result index will be a MultiIndex
 
-Parameters
-----------
-ddof : integer, default 1
-degrees of freedom"""
+        Parameters
+        ----------
+        ddof : integer, default 1
+        degrees of freedom
+        """
 
         # todo, implement at cython level?
         return np.sqrt(self.var(ddof=ddof))
@@ -761,14 +768,16 @@ degrees of freedom"""
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def var(self, ddof=1):
-        """Compute variance of groups, excluding missing values
+        """
+        Compute variance of groups, excluding missing values
 
-For multiple groupings, the result index will be a MultiIndex
+        For multiple groupings, the result index will be a MultiIndex
 
-Parameters
-----------
-ddof : integer, default 1
-degrees of freedom"""
+        Parameters
+        ----------
+        ddof : integer, default 1
+        degrees of freedom
+        """
 
         if ddof == 1:
             return self._cython_agg_general('var')
@@ -780,14 +789,16 @@ degrees of freedom"""
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def sem(self, ddof=1):
-        """Compute standard error of the mean of groups, excluding missing values
+        """
+        Compute standard error of the mean of groups, excluding missing values
 
-For multiple groupings, the result index will be a MultiIndex
+        For multiple groupings, the result index will be a MultiIndex
 
-Parameters
-----------
-ddof : integer, default 1
-degrees of freedom"""
+        Parameters
+        ----------
+        ddof : integer, default 1
+        degrees of freedom
+        """
 
         return self.std(ddof=ddof)/np.sqrt(self.count())
 
@@ -809,8 +820,10 @@ degrees of freedom"""
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def ohlc(self):
-        """Compute sum of values, excluding missing values
-For multiple groupings, the result index will be a MultiIndex"""
+        """
+        Compute sum of values, excluding missing values
+        For multiple groupings, the result index will be a MultiIndex
+        """
 
         return self._apply_to_column_groupbys(
             lambda x: x._cython_agg_general('ohlc'))
@@ -818,46 +831,48 @@ For multiple groupings, the result index will be a MultiIndex"""
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def nth(self, n, dropna=None):
-        """Take the nth row from each group if n is an int, or a subset of rows
-if n is a list of ints.
-
-If dropna, will take the nth non-null row, dropna is either
-Truthy (if a Series) or 'all', 'any' (if a DataFrame); this is equivalent
-to calling dropna(how=dropna) before the groupby.
-
-Parameters
-----------
-n : int or list of ints
-    a single nth value for the row or a list of nth values
-dropna : None or str, optional
-    apply the specified dropna operation before counting which row is
-    the nth row. Needs to be None, 'any' or 'all'
-
-Examples
---------
->>> df = DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=['A', 'B'])
->>> g = df.groupby('A')
->>> g.nth(0)
-       A   B
-    0  1 NaN
-    2  5   6
->>> g.nth(1)
-       A  B
-    1  1  4
->>> g.nth(-1)
-       A  B
-    1  1  4
-    2  5  6
->>> g.nth(0, dropna='any')
-       B
-       A
-    1  4
-    5  6
->>> g.nth(1, dropna='any')  # NaNs denote group exhausted when using dropna
-        B
-        A
-    1 NaN
-    5 NaN"""
+        """
+        Take the nth row from each group if n is an int, or a subset of rows
+        if n is a list of ints.
+
+        If dropna, will take the nth non-null row, dropna is either
+        Truthy (if a Series) or 'all', 'any' (if a DataFrame); this is equivalent
+        to calling dropna(how=dropna) before the groupby.
+
+        Parameters
+        ----------
+        n : int or list of ints
+            a single nth value for the row or a list of nth values
+        dropna : None or str, optional
+            apply the specified dropna operation before counting which row is
+            the nth row. Needs to be None, 'any' or 'all'
+
+        Examples
+        --------
+        >>> df = DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=['A', 'B'])
+        >>> g = df.groupby('A')
+        >>> g.nth(0)
+           A   B
+        0  1 NaN
+        2  5   6
+        >>> g.nth(1)
+           A  B
+        1  1  4
+        >>> g.nth(-1)
+           A  B
+        1  1  4
+        2  5  6
+        >>> g.nth(0, dropna='any')
+           B
+           A
+        1  4
+        5  6
+        >>> g.nth(1, dropna='any')  # NaNs denote group exhausted when using dropna
+           B
+           A
+        1 NaN
+        5 NaN
+        """
 
         if isinstance(n, int):
             nth_values = [n]
@@ -953,46 +968,48 @@ Examples
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def cumcount(self, ascending=True):
-        """Number each item in each group from 0 to the length of that group - 1.
-
-Essentially this is equivalent to
-
->>> self.apply(lambda x: Series(np.arange(len(x)), x.index))
-
-Parameters
-----------
-ascending : bool, default True
-    If False, number in reverse, from length of group - 1 to 0.
-
-Examples
---------
-
->>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],
-    ...               columns=['A'])
->>> df
-       A
-    0  a
-    1  a
-    2  a
-    3  b
-    4  b
-    5  a
->>> df.groupby('A').cumcount()
-    0    0
-    1    1
-    2    2
-    3    0
-    4    1
-    5    3
-    dtype: int64
->>> df.groupby('A').cumcount(ascending=False)
-    0    3
-    1    2
-    2    1
-    3    1
-    4    0
-    5    0
-    dtype: int64"""
+        """
+        Number each item in each group from 0 to the length of that group - 1.
+
+        Essentially this is equivalent to
+
+        >>> self.apply(lambda x: Series(np.arange(len(x)), x.index))
+
+        Parameters
+        ----------
+        ascending : bool, default True
+        If False, number in reverse, from length of group - 1 to 0.
+
+        Examples
+        --------
+
+        >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],
+        ...               columns=['A'])
+        >>> df
+           A
+        0  a
+        1  a
+        2  a
+        3  b
+        4  b
+        5  a
+        >>> df.groupby('A').cumcount()
+        0    0
+        1    1
+        2    2
+        3    0
+        4    1
+        5    3
+        dtype: int64
+        >>> df.groupby('A').cumcount(ascending=False)
+        0    3
+        1    2
+        2    1
+        3    1
+        4    0
+        5    0
+        dtype: int64
+        """
 
         self._set_selection_from_grouper()
 
@@ -1021,14 +1038,16 @@ Examples
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def shift(self, periods=1, freq=None, axis=0):
-        """Shift each group by periods observations
+        """
+        Shift each group by periods observations
 
-Parameters
-----------
-periods : integer, default 1
-    number of periods to shift
-freq : frequency string
-axis : axis to shift, default 0"""
+        Parameters
+        ----------
+        periods : integer, default 1
+            number of periods to shift
+        freq : frequency string
+        axis : axis to shift, default 0
+        """
 
         if freq is not None or axis != 0:
             return self.apply(lambda x: x.shift(periods, freq, axis))
@@ -1047,24 +1066,27 @@ axis : axis to shift, default 0"""
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def head(self, n=5):
-        """Returns first n rows of each group.
-
-Essentially equivalent to ``.apply(lambda x: x.head(n))``,
-except ignores as_index flag.
-
-Examples
---------
-
->>> df = DataFrame([[1, 2], [1, 4], [5, 6]],
-                   columns=['A', 'B'])
->>> df.groupby('A', as_index=False).head(1)
-       A  B
-    0  1  2
-    2  5  6
->>> df.groupby('A').head(1)
-       A  B
-    0  1  2
-    2  5  6"""
+        """
+        Returns first n rows of each group.
+
+        Essentially equivalent to ``.apply(lambda x: x.head(n))``,
+        except ignores as_index flag.
+
+        Examples
+        --------
+
+        >>> df = DataFrame([[1, 2], [1, 4], [5, 6]],
+                           columns=['A', 'B'])
+        >>> df.groupby('A', as_index=False).head(1)
+           A  B
+        0  1  2
+        2  5  6
+        >>> df.groupby('A').head(1)
+           A  B
+        0  1  2
+        2  5  6
+        """
+
         obj = self._selected_obj
         in_head = self._cumcount_array() < n
         head = obj[in_head]
@@ -1073,24 +1095,27 @@ Examples
     @Substitution(name='groupby')
     @Appender(_doc_template)
     def tail(self, n=5):
-        """Returns last n rows of each group
-
-Essentially equivalent to ``.apply(lambda x: x.tail(n))``,
-except ignores as_index flag.
-
-Examples
---------
-
->>> df = DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],
-                   columns=['A', 'B'])
->>> df.groupby('A').tail(1)
-       A  B
-    1  a  2
-    3  b  2
->>> df.groupby('A').head(1)
-       A  B
-    0  a  1
-    2  b  1"""
+        """
+        Returns last n rows of each group
+
+        Essentially equivalent to ``.apply(lambda x: x.tail(n))``,
+        except ignores as_index flag.
+
+        Examples
+        --------
+
+        >>> df = DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],
+                           columns=['A', 'B'])
+        >>> df.groupby('A').tail(1)
+           A  B
+        1  a  2
+        3  b  2
+        >>> df.groupby('A').head(1)
+           A  B
+        0  a  1
+        2  b  1
+        """
+
         obj = self._selected_obj
         rng = np.arange(0, -self.grouper._max_groupsize, -1, dtype='int64')
         in_tail = self._cumcount_array(rng, ascending=False) > -n
@@ -1098,10 +1123,13 @@ Examples
         return tail
 
     def _cumcount_array(self, arr=None, ascending=True):
-        """arr is where cumcount gets its values from
+        """
+        arr is where cumcount gets its values from
 
-        note: this is currently implementing sort=False (though the default is sort=True)
-              for groupby in general
+        Note
+        ----
+        this is currently implementing sort=False (though the default is sort=True)
+        for groupby in general
         """
         if arr is None:
             arr = np.arange(self.grouper._max_groupsize, dtype='int64')
@@ -3379,8 +3407,8 @@ class DataFrameGroupBy(NDFrameGroupBy):
     _block_agg_axis = 1
 
     @Substitution(name='groupby')
-    @Appender(SelectionMixin._agg_doc)
     @Appender(SelectionMixin._see_also_template)
+    @Appender(SelectionMixin._agg_doc)
     def aggregate(self, arg, *args, **kwargs):
         return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)
 
@@ -3550,8 +3578,8 @@ DataFrameGroupBy.boxplot = boxplot_frame_groupby
 class PanelGroupBy(NDFrameGroupBy):
 
     @Substitution(name='groupby')
-    @Appender(SelectionMixin._agg_doc)
     @Appender(SelectionMixin._see_also_template)
+    @Appender(SelectionMixin._agg_doc)
     def aggregate(self, arg, *args, **kwargs):
         return super(PanelGroupBy, self).aggregate(arg, *args, **kwargs)
 
diff --git a/pandas/core/window.py b/pandas/core/window.py
index 09dc528f6..003b2d7bd 100644
--- a/pandas/core/window.py
+++ b/pandas/core/window.py
@@ -18,6 +18,7 @@ import pandas.core.common as com
 import pandas.algos as algos
 from pandas import compat
 from pandas.util.decorators import Substitution, Appender
+from textwrap import dedent
 
 _shared_docs = dict()
 _doc_template = """
@@ -28,8 +29,8 @@ same type as input
 
 See also
 --------
-:func:`pandas.Series.%(name)s`
-:func:`pandas.DataFrame.%(name)s`
+`pandas.Series.%(name)s`
+`pandas.DataFrame.%(name)s`
 """
 
 class _Window(PandasObject, SelectionMixin):
@@ -257,21 +258,21 @@ class Window(_Window):
 
     The recognized window types are:
 
-        * ``boxcar``
-        * ``triang``
-        * ``blackman``
-        * ``hamming``
-        * ``bartlett``
-        * ``parzen``
-        * ``bohman``
-        * ``blackmanharris``
-        * ``nuttall``
-        * ``barthann``
-        * ``kaiser`` (needs beta)
-        * ``gaussian`` (needs std)
-        * ``general_gaussian`` (needs power, width)
-        * ``slepian`` (needs width).
-    """
+    * ``boxcar``
+    * ``triang``
+    * ``blackman``
+    * ``hamming``
+    * ``bartlett``
+    * ``parzen``
+    * ``bohman``
+    * ``blackmanharris``
+    * ``nuttall``
+    * ``barthann``
+    * ``kaiser`` (needs beta)
+    * ``gaussian`` (needs std)
+    * ``general_gaussian`` (needs power, width)
+    * ``slepian`` (needs width).
+"""
 
     def _prep_window(self, **kwargs):
         """ provide validation for our window type, return the window """
@@ -340,7 +341,13 @@ class Window(_Window):
     @Appender(SelectionMixin._agg_doc)
     @Appender(SelectionMixin._see_also_template)
     def aggregate(self, arg, *args, **kwargs):
-        return super(Window, self).aggregate(arg, *args, **kwargs)
+        result, how = self._aggregate(arg, *args, **kwargs)
+        if result is None:
+
+            # these must apply directly
+            result = arg(self)
+
+        return result
 
     agg = aggregate
 
@@ -451,13 +458,15 @@ class _Rolling_and_Expanding(_Rolling):
         result[result.isnull()] = 0
         return result
 
-    _shared_docs['apply'] = """%(name)s function apply
+    _shared_docs['apply'] = dedent("""
+    %(name)s function apply
 
-Parameters
-----------
-func : function
+    Parameters
+    ----------
+    func : function
     Must produce a single value from an ndarray input
-*args and **kwargs are passed to the function"""
+    *args and **kwargs are passed to the function""")
+
     def apply(self, func, args=(), kwargs={}):
         _level = kwargs.pop('_level',None)
         window = self._get_window()
@@ -472,21 +481,25 @@ func : function
     def sum(self):
         return self._apply('roll_sum')
 
-    _shared_docs['max'] = """%(name)s maximum
+    _shared_docs['max'] = dedent("""
+    %(name)s maximum
+
+    Parameters
+    ----------
+    how : string, default max
+    Method for down- or re-sampling""")
 
-Parameters
-----------
-how : string, default max
-    Method for down- or re-sampling"""
     def max(self, how='max'):
         return self._apply('roll_max', how=how)
 
-    _shared_docs['min'] = """%(name)s minimum
+    _shared_docs['min'] = dedent("""
+    %(name)s minimum
+
+    Parameters
+    ----------
+    how : string, default min
+    Method for down- or re-sampling""")
 
-Parameters
-----------
-how : string, default min
-    Method for down- or re-sampling"""
     def min(self, how='min'):
         return self._apply('roll_min', how=how)
 
@@ -494,22 +507,26 @@ how : string, default min
     def mean(self):
         return self._apply('roll_mean')
 
-    _shared_docs['median'] = """%(name)s median
+    _shared_docs['median'] = dedent("""
+    %(name)s median
+
+    Parameters
+    ----------
+    how : string, default median
+    Method for down- or re-sampling""")
 
-Parameters
-----------
-how : string, default median
-    Method for down- or re-sampling"""
     def median(self, how='median'):
         return self._apply('roll_median_c', how=how)
 
-    _shared_docs['std'] = """%(name)s standard deviation
+    _shared_docs['std'] = dedent("""
+    %(name)s standard deviation
 
-Parameters
-----------
-ddof : int, default 1
+    Parameters
+    ----------
+    ddof : int, default 1
     Delta Degrees of Freedom.  The divisor used in calculations
-    is ``N - ddof``, where ``N`` represents the number of elements."""
+    is ``N - ddof``, where ``N`` represents the number of elements.""")
+
     def std(self, ddof=1):
         window = self._get_window()
         def f(arg, *args, **kwargs):
@@ -518,13 +535,15 @@ ddof : int, default 1
 
         return self._apply(f, check_minp=_require_min_periods(1))
 
-    _shared_docs['var'] = """%(name)s variance
+    _shared_docs['var'] = dedent("""
+    %(name)s variance
 
-Parameters
-----------
-ddof : int, default 1
+    Parameters
+    ----------
+    ddof : int, default 1
     Delta Degrees of Freedom.  The divisor used in calculations
-    is ``N - ddof``, where ``N`` represents the number of elements."""
+    is ``N - ddof``, where ``N`` represents the number of elements.""")
+
     def var(self, ddof=1):
         return self._apply('roll_var',
                            check_minp=_require_min_periods(1),
@@ -540,12 +559,14 @@ ddof : int, default 1
         return self._apply('roll_kurt',
                            check_minp=_require_min_periods(4))
 
-    _shared_docs['quantile'] = """%(name)s quantile
+    _shared_docs['quantile'] = dedent("""
+    %(name)s quantile
+
+    Parameters
+    ----------
+    quantile : float
+    0 <= quantile <= 1""")
 
-Parameters
-----------
-quantile : float
-0 <= quantile <= 1"""
     def quantile(self, quantile):
         window = self._get_window()
         def f(arg, *args, **kwargs):
@@ -554,21 +575,23 @@ quantile : float
 
         return self._apply(f)
 
-    _shared_docs['cov'] = """%(name)s sample covariance
-
-Parameters
-----------
-other : Series, DataFrame, or ndarray, optional
-    if not supplied then will default to self and produce pairwise output
-pairwise : bool, default None
-    If False then only matching columns between self and other will be used and
-    the output will be a DataFrame.
-    If True then all pairwise combinations will be calculated and the output
-    will be a Panel in the case of DataFrame inputs. In the case of missing
-    elements, only complete pairwise observations will be used.
-ddof : int, default 1
-    Delta Degrees of Freedom.  The divisor used in calculations
-    is ``N - ddof``, where ``N`` represents the number of elements."""
+    _shared_docs['cov'] = dedent("""
+    %(name)s sample covariance
+
+    Parameters
+    ----------
+    other : Series, DataFrame, or ndarray, optional
+        if not supplied then will default to self and produce pairwise output
+    pairwise : bool, default None
+        If False then only matching columns between self and other will be used and
+        the output will be a DataFrame.
+        If True then all pairwise combinations will be calculated and the output
+        will be a Panel in the case of DataFrame inputs. In the case of missing
+        elements, only complete pairwise observations will be used.
+    ddof : int, default 1
+        Delta Degrees of Freedom.  The divisor used in calculations
+        is ``N - ddof``, where ``N`` represents the number of elements.""")
+
     def cov(self, other=None, pairwise=None, ddof=1):
         if other is None:
             other = self._selected_obj
@@ -583,19 +606,20 @@ ddof : int, default 1
             return (mean(X * Y) - mean(X) * mean(Y)) * bias_adj
         return _flex_binary_moment(self._selected_obj, other._selected_obj, _get_cov, pairwise=bool(pairwise))
 
-    _shared_docs['corr'] = """
-%(name)s sample correlation
-
-Parameters
-----------
-other : Series, DataFrame, or ndarray, optional
-    if not supplied then will default to self and produce pairwise output
-pairwise : bool, default None
-    If False then only matching columns between self and other will be used and
-    the output will be a DataFrame.
-    If True then all pairwise combinations will be calculated and the output
-    will be a Panel in the case of DataFrame inputs. In the case of missing
-    elements, only complete pairwise observations will be used."""
+    _shared_docs['corr'] = dedent("""
+    %(name)s sample correlation
+
+    Parameters
+    ----------
+    other : Series, DataFrame, or ndarray, optional
+        if not supplied then will default to self and produce pairwise output
+    pairwise : bool, default None
+        If False then only matching columns between self and other will be used and
+        the output will be a DataFrame.
+        If True then all pairwise combinations will be calculated and the output
+        will be a Panel in the case of DataFrame inputs. In the case of missing
+        elements, only complete pairwise observations will be used.""")
+
     def corr(self, other=None, pairwise=None):
         if other is None:
             other = self._selected_obj
@@ -625,8 +649,8 @@ class Rolling(_Rolling_and_Expanding):
     Parameters
     ----------
     window : int
-       Size of the moving window. This is the number of observations used for
-       calculating the statistic.
+        Size of the moving window. This is the number of observations used for
+        calculating the statistic.
     min_periods : int, default None
         Minimum number of observations in window required to have a value
         (otherwise result is NA).
@@ -884,10 +908,10 @@ class Expanding(_Rolling_and_Expanding):
 
 class EWM(_Rolling):
     """
-    .. versionadded:: 0.18.0
-
     Provides exponential weighted functions
 
+    .. versionadded:: 0.18.0
+
     Parameters
     ----------
     com : float. optional
diff --git a/pandas/tests/test_window.py b/pandas/tests/test_window.py
index 5517ce967..1f1371597 100644
--- a/pandas/tests/test_window.py
+++ b/pandas/tests/test_window.py
@@ -52,9 +52,13 @@ class TestApi(Base):
         r = self.frame.rolling(window=5)[1]
         self.assertEqual(r._selected_obj.name,self.frame.columns[1])
 
+        # technically this is allowed
         r = self.frame.rolling(window=5)[1,3]
         tm.assert_index_equal(r._selected_obj.columns,self.frame.columns[[1,3]])
 
+        r = self.frame.rolling(window=5)[[1,3]]
+        tm.assert_index_equal(r._selected_obj.columns,self.frame.columns[[1,3]])
+
     def test_select_bad_cols(self):
         df = DataFrame([[1, 2]], columns=['A', 'B'])
         g = df.rolling(window=5)
@@ -73,7 +77,7 @@ class TestApi(Base):
         tm.assert_series_equal(r.A.sum(),r['A'].sum())
         self.assertRaises(AttributeError, lambda : r.F)
 
-    def tests_skip_nuiscance(self):
+    def tests_skip_nuisance(self):
 
         df = DataFrame({'A' : range(5), 'B' : range(5,10), 'C' : 'foo'})
 
@@ -168,6 +172,25 @@ class TestApi(Base):
         expected = pd.concat([a_sum,rcustom],axis=1)
         compare(result, expected)
 
+    def test_window_with_args(self):
+
+        # make sure that we are aggregating window functions correctly with arg
+
+        r = Series(np.random.randn(100)).rolling(window=10,min_periods=1,win_type='gaussian')
+        expected = pd.concat([r.mean(std=10),r.mean(std=.01)],axis=1)
+        expected.columns = ['<lambda>','<lambda>']
+        result = r.aggregate([lambda x: x.mean(std=10), lambda x: x.mean(std=.01)])
+        assert_frame_equal(result, expected)
+
+        def a(x):
+            return x.mean(std=10)
+        def b(x):
+            return x.mean(std=0.01)
+        expected = pd.concat([r.mean(std=10),r.mean(std=.01)],axis=1)
+        expected.columns = ['a','b']
+        result = r.aggregate([a,b])
+        assert_frame_equal(result, expected)
+
 class TestDeprecations(Base):
     """ test that we are catching deprecation warnings """
 
diff --git a/pandas/util/decorators.py b/pandas/util/decorators.py
index a6aa5ff66..5c3cb5737 100644
--- a/pandas/util/decorators.py
+++ b/pandas/util/decorators.py
@@ -2,6 +2,7 @@ from pandas.compat import StringIO, callable
 from pandas.lib import cache_readonly
 import sys
 import warnings
+from textwrap import dedent
 from functools import wraps
 
 
@@ -180,7 +181,7 @@ class Appender(object):
         func.__doc__ = func.__doc__ if func.__doc__ else ''
         self.addendum = self.addendum if self.addendum else ''
         docitems = [func.__doc__, self.addendum]
-        func.__doc__ = self.join.join(docitems)
+        func.__doc__ = dedent(self.join.join(docitems))
         return func
 
 
