commit 5882607a09b9d99db585d1f115d81594005d69b5
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Fri Feb 26 22:12:47 2010 +0000

    loads of cleanup, tests, and DataFrame / DataMatrix API consistency. removed DataFrame.fromDict and fromMatrix methods, incorporated into default constructor
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@131 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 6e8e7660c..eccc70a62 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -41,13 +41,15 @@ class DataFrame(Picklable, Groupable):
 
     Parameters
     ----------
-    data : dict
-        Mapping of column name --> array or Series/TimeSeries objects
-    index : array-like, optional
-        Specific index to use for the Frame, Series will be conformed
-        to this if you provide it. If not input, index will be
-        inferred from input Series
-    columns : array-like, optional
+    data : numpy ndarray or dict of sequence-like objects
+        Dict can contain Series, arrays, or list-like objects
+        Constructor can understand various kinds of inputs
+    index : Index or array-like
+        Index to use for resulting frame (optional if provided dict of Series)
+    columns : Index or array-like
+        Required if data is ndarray
+    dtype : dtype, default None (infer)
+        Data type to force
 
     Notes
     -----
@@ -65,30 +67,119 @@ class DataFrame(Picklable, Groupable):
         >>> df = DataFrame(data=d, index=someIndex)
     """
 
-    def __init__(self, data=None, index=None, columns=None):
-        self._series = {}
-        if data is not None and len(data) > 0:
+    def __init__(self, data=None, index=None, columns=None, dtype=None):
+        if isinstance(data, dict):
+            self._series, self.index = self._initDict(data, index,
+                                                      columns, dtype)
+
+        elif isinstance(data, np.ndarray):
+            if columns is None:
+                raise Exception('Must pass column names with ndarray!')
             if index is None:
-                s = data.values()[0]
-                if isinstance(s, Series):
-                    self.index = s.index
-                else:
-                    self.index = np.arange(len(s))
+                raise Exception('Must pass index with ndarray!')
+
+            if data.ndim == 1:
+                data = data.reshape((len(data), 1))
+            elif data.ndim != 2:
+                raise Exception('Must pass 2-d input!')
+
+            self._series, self.index = self._initMatrix(data, index,
+                                                        columns, dtype)
+
+        elif data is None:
+            if index is None:
+                index = NULL_INDEX
+
+            self._series, self.index = {}, index
+
+    def _initDict(self, data, index, columns, dtype):
+        # pre-filter out columns if we passed it
+        if columns is not None:
+            colset = set(columns)
+            data = dict((k, v) for k, v in data.iteritems() if k in colset)
+
+        index = self._extract_index(data, index)
+
+        series = {}
+        for k, v in data.iteritems():
+            if isinstance(v, Series):
+                # Forces alignment and copies data
+                series[k] = v.reindex(index)
             else:
-                self.index = index
+                if isinstance(v, dict):
+                    v = [v.get(i, NaN) for i in index]
 
+                try:
+                    v = Series(v, dtype=dtype, index=index)
+                except Exception:
+                    v = Series(v, index=index)
+
+                series[k] = v.copy()
+
+        # add in any other columns we want to have (completeness)
+        if columns is not None:
+            for c in columns:
+                if c not in series:
+                    series[c] = Series.fromValue(np.NaN, index=index)
+
+        return series, index
+
+    @staticmethod
+    def _extract_index(data, index):
+        if len(data) == 0:
+            index = NULL_INDEX
+        elif len(data) > 0 and index is None:
+            # aggregate union of indices
+            need_labels = False
+
+            # this is pretty kludgy, better way?
             for k, v in data.iteritems():
                 if isinstance(v, Series):
-                    # Forces homogeneity and copies data
-                    self._series[k] = v.reindex(self.index)
-                else:
-                    # Copies data and checks length
-                    self._series[k] = Series(v, index=self.index)
+                    if index is None:
+                        index = v.index
+                    elif need_labels:
+                        raise Exception('Cannot mix Series / dict objects'
+                                        ' with ndarray / sequence input')
+                    elif not index.equals(v.index):
+                        index = index + v.index
+
+                elif isinstance(v, dict):
+                    if index is None:
+                        index = Index(sorted(v.keys()))
+                    elif need_labels:
+                        raise Exception('Cannot mix Series / dict objects'
+                                        ' with ndarray / sequence input')
+                    else:
+                        index = index + Index(v.keys())
+
+                else: # not dict-like, assign integer labels
+                    if index is not None and not need_labels:
+                        raise Exception('Cannot mix Series / dict objects'
+                                        ' with ndarray / sequence input')
+
+                    need_labels = True
+                    index = Index(np.arange(len(v)))
+
+        if len(index) == 0 or index is None:
+            index = NULL_INDEX
 
-        elif index is not None:
-            self.index = index
-        else:
-            self.index = NULL_INDEX
+        if not isinstance(index, Index):
+            index = Index(index)
+
+        return index
+
+    def _initMatrix(self, data, index, columns, dtype):
+        N, K = data.shape
+
+        if len(index) != N:
+            raise Exception('Index length mismatch: %d vs. %d' %
+                            (len(index), N))
+        if len(columns) != K:
+            raise Exception('Index length mismatch: %d vs. %d' %
+                            (len(columns), K))
+
+        data = dict([(idx, data[:, i]) for i, idx in enumerate(columns)])
+        return self._initDict(data, index, columns, dtype)
 
     @property
     def _constructor(self):
@@ -119,76 +210,6 @@ class DataFrame(Picklable, Groupable):
 
     index = property(fget=_get_index, fset=_set_index)
 
-    # Alternate constructors
-    @classmethod
-    def fromDict(cls, inputDict=None, castFloat=True, **kwds):
-        """
-        Convert a two-level tree representation of a series or time series
-        to a DataFrame.
-
-        tree is structured as:
-            {'col1' : {
-                idx1 : value1,
-                ...
-                idxn : valueN
-                    },
-            ...}
-        e.g. tree['returns'][curDate] --> return value for curDate
-
-        Parameters
-        ----------
-        input : dict object
-            Keys become column names of returned frame
-        kwds : optionally provide arguments as keywords
-
-        Returns
-        -------
-        DataFrame
-
-        Examples
-        --------
-        df1 = DataFrame.fromDict(myDict)
-        df2 = DataFrame.fromDict(A=seriesA, B=seriesB)
-        """
-        if inputDict is None:
-            inputDict = {}
-        else:
-            if not hasattr(inputDict, 'iteritems'):
-                raise Exception('Input must be a dict or dict-like!')
-            inputDict = inputDict.copy()
-
-        inputDict.update(kwds)
-
-        if len(inputDict) == 0:
-            return DataFrame(index=NULL_INDEX)
-        elif len(inputDict) == 1:
-            index = inputDict.values()[0].keys()
-            if not isinstance(index, Index):
-                index = Index(sorted(index))
-        else:
-            # GET set of indices
-            indices = set([])
-            for key, branch in inputDict.iteritems():
-                indices = indices | set(branch.keys())
-            index = Index(sorted(indices))
-
-        columns = {}
-        for key, branch in inputDict.iteritems():
-            if isinstance(branch, Series):
-                tmp = branch.reindex(index)
-            else:
-                tmp = [branch.get(i, NaN) for i in index]
-
-            try:
-                if castFloat:
-                    columns[key] = Series(tmp, dtype=float, index=index)
-                else:
-                    columns[key] = Series(tmp, index=index)
-            except Exception:
-                columns[key] = Series(tmp, index=index)
-
-        return DataFrame(data=columns, index=index)
-
     def toDict(self):
         """
         Simpler pseudo-inverse operation of DataFrame.fromDict, NaN
@@ -240,40 +261,6 @@ class DataFrame(Picklable, Groupable):
 
         return np.rec.fromarrays(arrays, names=names)
 
-    @classmethod
-    def fromMatrix(cls, mat, colNames, rowNames):
-        """
-        Convert input matrix to DataFrame given column and row names (index)
-
-        Parameters
-        ----------
-        mat : ndarray
-            Dimension T x N
-        colNames : iterable
-            Dimension N
-        rowNames : iterable
-            Dimension T
-
-        Returns
-        -------
-        DataFrame
-        """
-        rows, cols = mat.shape
-        try:
-            assert(rows == len(rowNames))
-            assert(cols == len(colNames))
-        except AssertionError:
-            raise Exception('Dimensions do not match: %s, %s, %s' %
-                            (mat.shape, len(rowNames), len(colNames)))
-
-        index = Index(rowNames)
-        colIndex = Index(colNames)
-
-        idxMap = colIndex.indexMap
-
-        data = dict([(idx, mat[:, idxMap[idx]]) for idx in colIndex])
-        return DataFrame(data=data, index=index)
-
 #-------------------------------------------------------------------------------
 # Magic methods
 
@@ -450,17 +437,15 @@ class DataFrame(Picklable, Groupable):
         if len(other) == 0:
             return self * NaN
 
-        if self.index._allDates and other.index._allDates:
-            if not self:
-                return DataFrame(index=other.index)
+        if not self:
+            return DataFrame(index=NULL_INDEX)
 
+        if self.index._allDates and other.index._allDates:
             if self.index.equals(other.index):
                 newIndex = self.index
-
                 this = self
             else:
                 newIndex = self.index + other.index
-
                 this = self.reindex(newIndex)
                 other = other.reindex(newIndex)
 
@@ -468,7 +453,6 @@ class DataFrame(Picklable, Groupable):
                 newColumns[col] = func(series, other)
 
             result = DataFrame(newColumns, index=newIndex)
-
         else:
             union = other.index.union(self.cols())
             intersection = other.index.intersection(self.cols())
@@ -555,7 +539,7 @@ class DataFrame(Picklable, Groupable):
         return DataMatrix(self._series, index=self.index)
 
     def toString(self, buffer=sys.stdout, verbose=False,
-                 columns=None, colSpace=15, nanRep='NaN',
+                 columns=None, colSpace=10, nanRep='NaN',
                  formatters=None, float_format=None):
         """Output a tab-separated version of this DataFrame"""
         series = self._series
@@ -717,7 +701,7 @@ class DataFrame(Picklable, Groupable):
                         correl[i, j] = c
                         correl[j, i] = c
 
-        return self.fromMatrix(correl, cols, cols)
+        return self._constructor(correl, index=cols, columns=cols)
 
     def dropEmptyRows(self, specificColumns=None):
         """
@@ -806,41 +790,6 @@ class DataFrame(Picklable, Groupable):
 
         return mycopy
 
-    def getTS(self, colName=None, fromDate=None, toDate=None, nPeriods=None):
-        """
-        Return a DataFrame / TimeSeries corresponding to given arguments
-
-        Parameters
-        ----------
-        colName : particular column name requested
-        fromDate : datetime
-        toDate : datetime
-        nPeriods : int/float
-
-        Note
-        ----
-        Error thrown if all of fromDate, toDate, nPeriods specified.
-        """
-        beg_slice, end_slice = self._getIndices(fromDate, toDate)
-
-        if nPeriods:
-            if fromDate and toDate:
-                raise Exception('fromDate/toDate, toDate/nPeriods, ' + \
-                                ' fromDate/nPeriods are mutually exclusive')
-            elif fromDate:
-                end_slice = min(len(self), beg_slice + nPeriods)
-            elif toDate:
-                beg_slice = max(0, end_slice - nPeriods)
-            else:
-                raise Exception('Not enough arguments provided to getTS')
-
-        dateRange = self.index[beg_slice:end_slice]
-
-        if colName:
-            return self[colName].reindex(dateRange)
-        else:
-            return self.reindex(dateRange)
-
     def truncate(self, before=None, after=None):
         """Function truncate a sorted DataFrame before and/or after
         some particular dates.
@@ -900,11 +849,10 @@ class DataFrame(Picklable, Groupable):
         if key not in self.index:
             raise Exception('No cross-section for %s' % key)
 
-        subset = sorted(self._series)
-
+        subset = self.cols()
         rowValues = [self._series[k][key] for k in subset]
 
-        if len(set(map(type, rowValues))) > 1:
+        if len(set((type(x) for x in rowValues))) > 1:
             return Series(np.array(rowValues, dtype=np.object_), index=subset)
         else:
             return Series(np.array(rowValues), index=subset)
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 0b9444d4d..4ddb0e82e 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -158,7 +158,7 @@ class SeriesGroupBy(GroupBy):
 
                 results[func.__name__] = result
 
-            retVal = DataFrame.fromDict(results)
+            retVal = DataFrame(results)
         else:
             try:
                 result = groupby(self.obj.index, self.obj,
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index 7e2b165f0..f0371a60f 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -26,13 +26,15 @@ class DataMatrix(DataFrame):
 
     Parameters
     ----------
-    data : numpy ndarray or dict of Series
+    data : numpy ndarray or dict of sequence-like objects
+        Dict can contain Series, arrays, or list-like objects
         Constructor can understand various kinds of inputs
     index : Index or array-like
         Index to use for resulting frame (optional if provided dict of Series)
     columns : Index or array-like
-    dtype : dtype, default=float
-        Data type to use
+        Required if data is ndarray
+    dtype : dtype, default None (infer)
+        Data type to force
 
     Notes
     -----
@@ -43,98 +45,14 @@ class DataMatrix(DataFrame):
     def __init__(self, data=None, index=None, columns=None, dtype=None,
                  objects=None):
 
-        def handleDict(data, index, columns, objects, dtype):
-            """
-            Segregate Series based on type and coerce into matrices.
-
-            Needs to handle a lot of exceptional cases.
-            """
-            if len(data) == 0:
-                if index is None:
-                    index = NULL_INDEX
-                values = np.empty((len(index), 0), dtype=dtype)
-                columns = NULL_INDEX
-            else:
-                if index is None:
-                    s = data.values()[0]
-                    if isinstance(s, Series):
-                        index = s.index
-                    else:
-                        index = Index(np.arange(len(s)))
-
-                if columns is not None:
-                    if len(columns) != len(data):
-                        raise Exception('Supplied columns does not match dict!')
-
-                if not isinstance(index, Index):
-                    index = Index(index)
-
-                objectDict = {}
-                if objects is not None and isinstance(objects, dict):
-                    objectDict.update(objects)
-
-                valueDict = {}
-                for k, v in data.iteritems():
-                    # Forces homogoneity
-                    if isinstance(v, Series):
-                        v = v.reindex(index)
-                    else:
-                        assert(len(v) == len(index))
-                        v = Series(v, index=index)
-
-                    if issubclass(v.dtype.type, (np.bool_, float, int)):
-                        valueDict[k] = v
-                    else:
-                        objectDict[k] = v
-
-                if columns is None:
-                    columns = Index(sorted(valueDict))
-                    objectColumns = Index(sorted(objectDict))
-                else:
-                    objectColumns = Index([c for c in columns if c in objectDict])
-                    columns = Index([c for c in columns if c in valueDict])
-
-                if len(valueDict) == 0:
-                    dtype = np.object_
-                    valueDict = objectDict
-                    columns = objectColumns
-                else:
-                    dtype = np.float_
-                    if len(objectDict) > 0:
-                        new_objects = DataMatrix(objectDict,
-                                                 dtype=np.object_,
-                                                 index=index,
-                                                 columns=objectColumns)
-                        if isinstance(objects, DataMatrix):
-                            objects = objects.leftJoin(new_objects)
-                        else:
-                            objects = new_objects
-
-                values = np.empty((len(index), len(columns)), dtype=dtype)
-
-                for i, col in enumerate(columns):
-                    values[:, i] = valueDict[col]
-
-            return index, columns, values, objects
-
         if isinstance(data, dict):
-            index, columns, values, objects = handleDict(data, index,
-                                                         columns, objects,
-                                                         dtype)
+            (index, columns,
+             values, objects) = self._initDict(data, index, columns, objects,
+                                               dtype)
         elif isinstance(data, np.ndarray):
-            if data.ndim == 1:
-                N = data.shape[0]
-                if N == 0:
-                    data = data.reshape((data.shape[0], 0))
-                else:
-                    data = data.reshape((data.shape[0], 1))
-
-            if issubclass(data.dtype.type, (np.str_, np.object_)):
-                values = np.asarray(data, dtype=object)
-            else:
-                # We're allowing things to be boolean
-                values = np.asarray(data)
-
+            (index, columns,
+             values, objects) = self._initMatrix(data, index, columns, objects,
+                                                 dtype)
         elif data is None:
             if index is None:
                 N = 0
@@ -166,6 +84,123 @@ class DataMatrix(DataFrame):
         self.columns = columns
         self.objects = objects
 
+    def _initDict(self, data, index, columns, objects, dtype):
+        """
+        Segregate Series based on type and coerce into matrices.
+
+        Needs to handle a lot of exceptional cases.
+
+        Somehow this got outrageously complicated
+        """
+        if len(data) == 0:
+            if index is None:
+                index = NULL_INDEX
+            values = np.empty((len(index), 0), dtype=dtype)
+            columns = NULL_INDEX
+            return index, columns, values, objects
+
+        # pre-filter out columns if we passed it
+        if columns is not None:
+            colset = set(columns)
+            data = dict((k, v) for k, v in data.iteritems() if k in colset)
+
+        index = self._extract_index(data, index)
+
+        objectDict = {}
+        if objects is not None and isinstance(objects, dict):
+            objectDict.update(objects)
+
+        valueDict = {}
+        for k, v in data.iteritems():
+            if isinstance(v, Series):
+                # Forces alignment, copies data
+                v = v.reindex(index)
+            else:
+                if isinstance(v, dict):
+                    v = [v.get(i, NaN) for i in index]
+                else:
+                    assert(len(v) == len(index))
+
+                try:
+                    v = Series(v, dtype=dtype, index=index)
+                except Exception:
+                    v = Series(v, index=index)
+
+                # copy data
+                v = v.copy()
+
+            if issubclass(v.dtype.type, (np.bool_, float, int)):
+                valueDict[k] = v
+            else:
+                objectDict[k] = v
+
+        if columns is None:
+            columns = Index(sorted(valueDict))
+            objectColumns = Index(sorted(objectDict))
+        else:
+            objectColumns = Index([c for c in columns if c in objectDict])
+            columns = Index([c for c in columns if c not in objectDict])
+
+        if len(valueDict) == 0:
+            dtype = np.object_
+            valueDict = objectDict
+            columns = objectColumns
+        else:
+            dtype = np.float_
+            if len(objectDict) > 0:
+                new_objects = DataMatrix(objectDict,
+                                         dtype=np.object_,
+                                         index=index,
+                                         columns=objectColumns)
+                if isinstance(objects, DataMatrix):
+                    objects = objects.leftJoin(new_objects)
+                else:
+                    objects = new_objects
+
+        values = np.empty((len(index), len(columns)), dtype=dtype)
+
+        for i, col in enumerate(columns):
+            if col in valueDict:
+                values[:, i] = valueDict[col]
+            else:
+                values[:, i] = np.NaN
+
+        return index, columns, values, objects
+
+    def _initMatrix(self, data, index, columns, objects, dtype):
+        if data.ndim == 1:
+            N = data.shape[0]
+            if N == 0:
+                data = data.reshape((data.shape[0], 0))
+            else:
+                data = data.reshape((data.shape[0], 1))
+
+        if issubclass(data.dtype.type, (np.str_, np.object_)):
+            values = np.asarray(data, dtype=object)
+        else:
+            # We're allowing things to be boolean
+            values = np.asarray(data)
+
+        if dtype is not None:
+            try:
+                data = data.astype(dtype)
+            except Exception:
+                pass
+
+        if index is None:
+            if data.shape[0] == 0:
+                index = NULL_INDEX
+            else:
+                raise Exception('Must pass index!')
+
+        if columns is None:
+            if data.shape[1] == 0:
+                columns = NULL_INDEX
+            else:
+                raise Exception('Must pass columns!')
+
+        return index, columns, values, objects
+
     @property
     def _constructor(self):
         return DataMatrix
@@ -207,94 +242,6 @@ class DataMatrix(DataFrame):
 
     # Because of DataFrame property
     values = None
-#-------------------------------------------------------------------------------
-# Alternate constructors
-
-    @classmethod
-    def fromDict(cls, inputDict=None, castFloat=True, **kwds):
-        """
-        Convert a two-level tree representation of a series or time series
-        to a DataMatrix.
-
-        tree is structured as:
-            {'col1' : {
-                idx1 : value1,
-                ...
-                idxn : valueN
-                    },
-            ...}
-        e.g. tree['returns'][curDate] --> return value for curDate
-
-        Parameters
-        ----------
-        input : dict object
-            Keys become column names of returned frame
-        kwds : optionally provide arguments as keywords
-
-        Examples
-        --------
-        df1 = DataMatrix.fromDict(myDict)
-        df2 = DataMatrix.fromDict(A=seriesA, B=seriesB)
-        """
-        if inputDict is None:
-            inputDict = {}
-        else:
-            if not hasattr(inputDict, 'iteritems'):
-                raise Exception('Input must be a dict or dict-like!')
-            inputDict = inputDict.copy()
-
-        inputDict.update(kwds)
-
-        # Get set of indices
-        indices = set([])
-        for branch in inputDict.values():
-            indices = indices | set(branch.keys())
-
-        index = Index(sorted(indices))
-        # Convert to Series
-        series = {}
-        for col, mapping in inputDict.iteritems():
-            if not isinstance(mapping, Series):
-                mapping = Series.fromDict(mapping, castFloat=castFloat)
-            series[col] = mapping.reindex(index)
-
-        return DataMatrix(series, index=index)
-
-    @classmethod
-    def fromMatrix(cls, mat, colNames, rowNames):
-        """
-        Compatibility method for operations in DataFrame that use
-        fromMatrix.
-
-        Parameters
-        ----------
-        mat : ndarray
-            Dimension T x N
-        colNames : iterable
-            Dimension N
-        rowNames : iterable
-            Dimension T
-
-        Returns
-        -------
-        DataMatrix
-
-        See also
-        --------
-        DataFrame.fromMatrix
-        """
-        rows, cols = mat.shape
-        try:
-            assert(rows == len(rowNames))
-            assert(cols == len(colNames))
-        except AssertionError:
-            raise Exception('Dimensions do not match: %s, %s, %s' %
-                            (mat.shape, len(rowNames), len(colNames)))
-
-        index = Index(rowNames)
-        colIndex = Index(colNames)
-
-        return DataMatrix(mat, index=index, columns=colIndex)
 
 #-------------------------------------------------------------------------------
 # Outputting
@@ -349,7 +296,7 @@ class DataMatrix(DataFrame):
             print 'CSV file written successfully: %s' % path
 
     def toString(self, buffer=sys.stdout, verbose=False,
-                 columns=None, colSpace=15, nanRep='NaN',
+                 columns=None, colSpace=10, nanRep='NaN',
                  formatters=None, float_format=None):
         """
         Output a string version of this DataMatrix
@@ -445,13 +392,6 @@ class DataMatrix(DataFrame):
         return self._columns
 
     def _set_columns(self, cols):
-        if cols is None:
-            if self.values is not None and self.values.shape[1] > 0:
-                raise Exception('Columns cannot be None here!')
-            else:
-                self._columns = NULL_INDEX
-                return
-
         if len(cols) != self.values.shape[1]:
             raise Exception('Columns length %d did not match values %d!' %
                             (len(cols), self.values.shape[1]))
@@ -464,13 +404,6 @@ class DataMatrix(DataFrame):
     columns = property(fget=_get_columns, fset=_set_columns)
 
     def _set_index(self, index):
-        if index is None:
-            if self.values is not None and self.values.shape[0] > 0:
-                raise Exception('Index cannot be None here!')
-            else:
-                self._index = NULL_INDEX
-                return
-
         if len(index) > 0:
             if len(index) != self.values.shape[0]:
                 raise Exception('Index length %d did not match values %d!' %
@@ -668,8 +601,7 @@ class DataMatrix(DataFrame):
         """
         if key in self.columns:
             loc = self.columns.indexMap[key]
-            T, N = self.values.shape
-            if loc == N:
+            if loc == self.values.shape[1]:
                 newValues = self.values[:, :loc]
                 newColumns = self.columns[:loc]
             else:
@@ -790,6 +722,10 @@ class DataMatrix(DataFrame):
     def _combineSeries(self, other, func):
         newIndex = self.index
         newCols = self.columns
+
+        if not self:
+            return DataFrame(index=NULL_INDEX)
+
         if self.index._allDates and other.index._allDates:
             # Operate row-wise
             if self.index.equals(other.index):
@@ -797,9 +733,6 @@ class DataMatrix(DataFrame):
             else:
                 newIndex = self.index + other.index
 
-            if not self:
-                return DataMatrix(index=newIndex)
-
             other = other.reindex(newIndex).view(np.ndarray)
             myReindex = self.reindex(newIndex)
             resultMatrix = func(myReindex.values.T, other).T
@@ -985,7 +918,8 @@ class DataMatrix(DataFrame):
         -------
         This DataFrame with rows containing any NaN values deleted
         """
-        T, N = self.values.shape
+        N = self.values.shape[1]
+
         if specificColumns:
             cols = self.columns.intersection(specificColumns)
             theCount = self.filterItems(cols).count(axis=1)
@@ -1349,7 +1283,6 @@ class DataMatrix(DataFrame):
         else:
             return super(DataMatrix, self).append(otherFrame)
 
-    # TODO, works though.
     def outerJoin(self, *frames):
         """
         Form union of input frames.
@@ -1377,7 +1310,7 @@ class DataMatrix(DataFrame):
                     raise Exception('Overlapping columns!')
                 mergedSeries[col] = series
 
-        return DataMatrix.fromDict(mergedSeries)
+        return DataMatrix(mergedSeries)
 
     def leftJoin(self, *frames):
         """
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 695b62fa8..7d00f3170 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -1916,7 +1916,7 @@ def _slow_pivot(index, columns, values):
         branch = tree[col]
         branch[idx] = values[i]
 
-    return DataFrame.fromDict(tree)
+    return DataFrame(tree)
 
 def test():
     return pivot(np.array([1, 2, 3, 4, 4]),
diff --git a/pandas/core/tests/test_daterange.py b/pandas/core/tests/test_daterange.py
new file mode 100644
index 000000000..36172d857
--- /dev/null
+++ b/pandas/core/tests/test_daterange.py
@@ -0,0 +1,3 @@
+from pandas.core.daterange import DateRange
+
+
diff --git a/pandas/core/tests/test_frame.py b/pandas/core/tests/test_frame.py
index 0cdff0de0..109b8c6c1 100644
--- a/pandas/core/tests/test_frame.py
+++ b/pandas/core/tests/test_frame.py
@@ -59,23 +59,54 @@ class TestDataFrame(unittest.TestCase):
         indexed_frame = self.klass(data, index=index)
         unindexed_frame = self.klass(data)
 
-    def test_fromDict(self):
-        frame = self.klass.fromDict(col1=self.ts1, col2 = self.ts2)
+    def test_constructor_dict(self):
+        frame = self.klass({'col1' : self.ts1,
+                            'col2' : self.ts2})
 
         common.assert_dict_equal(self.ts1, frame['col1'], compare_keys=False)
         common.assert_dict_equal(self.ts2, frame['col2'], compare_keys=False)
 
+        frame = self.klass({'col1' : self.ts1,
+                            'col2' : self.ts2},
+                           columns=['col2', 'col3', 'col4'])
+
+        self.assertEqual(len(frame), len(self.ts2))
+        self.assert_('col1' not in frame)
+        self.assert_(np.isnan(frame['col3']).all())
+
+        # Corner cases
+        self.assertEqual(len(self.klass({})), 0)
+        self.assertRaises(Exception, lambda x: self.klass([self.ts1, self.ts2]))
+
+        # pass dict and array, nicht nicht
+        self.assertRaises(Exception, self.klass,
+                          {'A' : {'a' : 'a', 'b' : 'b'},
+                           'B' : ['a', 'b']})
+
+        # can I rely on the order?
+        self.assertRaises(Exception, self.klass,
+                          {'A' : ['a', 'b'],
+                           'B' : {'a' : 'a', 'b' : 'b'}})
+        self.assertRaises(Exception, self.klass,
+                          {'A' : ['a', 'b'],
+                           'B' : Series(['a', 'b'], index=['a', 'b'])})
+
+        # Length-one dict micro-optimization
+        frame = self.klass({'A' : {'1' : 1, '2' : 2}})
+        self.assert_(np.array_equal(frame.index, ['1', '2']))
+
+    def test_constructor_dict_cast(self):
         # cast float tests
         test_data = {
                 'A' : {'1' : 1, '2' : 2},
                 'B' : {'1' : '1', '2' : '2', '3' : '3'},
         }
-        frame = self.klass.fromDict(test_data)
+        frame = self.klass(test_data, dtype=float)
         self.assertEqual(len(frame), 3)
         self.assert_(frame['B'].dtype == np.float_)
         self.assert_(frame['A'].dtype == np.float_)
 
-        frame = self.klass.fromDict(test_data, castFloat=False)
+        frame = self.klass(test_data)
         self.assertEqual(len(frame), 3)
         self.assert_(frame['B'].dtype == np.object_)
         self.assert_(frame['A'].dtype == np.float_)
@@ -85,26 +116,47 @@ class TestDataFrame(unittest.TestCase):
                 'A' : dict(zip(range(20), common.makeDateIndex(20))),
                 'B' : dict(zip(range(15), randn(15)))
         }
-        frame = self.klass.fromDict(test_data)
+        frame = self.klass(test_data, dtype=float)
         self.assertEqual(len(frame), 20)
         self.assert_(frame['A'].dtype == np.object_)
         self.assert_(frame['B'].dtype == np.float_)
 
-        # Corner cases
-        self.assertEqual(len(self.klass.fromDict({})), 0)
-        self.assertEqual(len(self.klass.fromDict()), 0)
-        self.assertRaises(Exception, self.klass.fromDict, [self.ts1, self.ts2])
+    def test_constructor_ndarray(self):
+        mat = np.zeros((2, 3), dtype=float)
+
+        # 2-D input
+        frame = self.klass(mat, columns=['A', 'B', 'C'], index=[1, 2])
+
+        self.assertEqual(len(frame.index), 2)
+        self.assertEqual(len(frame.cols()), 3)
+
+        # 1-D input
+        frame = self.klass(np.zeros(3), columns=['A'], index=[1, 2, 3])
+        self.assertEqual(len(frame.index), 3)
+        self.assertEqual(len(frame.cols()), 1)
+
+        # higher dim raise exception
+        self.assertRaises(Exception, self.klass, np.zeros((3, 3, 3)),
+                          columns=['A', 'B', 'C'], index=[1])
+
+        # wrong size axis labels
+        self.assertRaises(Exception, self.klass, mat,
+                          columns=['A', 'B', 'C'], index=[1])
+
+        self.assertRaises(Exception, self.klass, mat,
+                          columns=['A', 'B'], index=[1, 2])
+
+        # have to pass columns and index
+        self.assertRaises(Exception, self.klass, mat, index=[1])
+        self.assertRaises(Exception, self.klass, mat, columns=['A', 'B', 'C'])
 
-        # Length-one dict micro-optimization
-        frame = self.klass.fromDict({'A' : {'1' : 1, '2' : 2}})
-        self.assert_(np.array_equal(frame.index, ['1', '2']))
 
     def test_toDict(self):
         test_data = {
                 'A' : {'1' : 1, '2' : 2},
                 'B' : {'1' : '1', '2' : '2', '3' : '3'},
         }
-        recons_data = self.klass.fromDict(test_data, castFloat=False).toDict()
+        recons_data = self.klass(test_data).toDict()
 
         for k, v in test_data.iteritems():
             for k2, v2 in v.iteritems():
@@ -124,19 +176,6 @@ class TestDataFrame(unittest.TestCase):
         records = indexed_frame.toRecords()
         self.assertEqual(len(records.dtype.names), 3)
 
-    def test_fromMatrix(self):
-        mat = np.zeros((2, 3), dtype=float)
-
-        frame = self.klass.fromMatrix(mat, ['A', 'B', 'C'], [1, 2])
-
-        self.assertEqual(len(frame.index), 2)
-        self.assertEqual(len(frame.cols()), 3)
-
-        self.assertRaises(Exception, self.klass.fromMatrix,
-                          mat, ['A', 'B', 'C'], [1])
-        self.assertRaises(Exception, self.klass.fromMatrix,
-                          mat, ['A', 'B'], [1, 2])
-
     def test_nonzero(self):
         self.assertFalse(self.empty)
 
@@ -162,8 +201,8 @@ class TestDataFrame(unittest.TestCase):
         foo = repr(self.frame)
 
         # big one
-        biggie = self.klass.fromMatrix(np.zeros((1000, 4)),
-                                       range(4), range(1000))
+        biggie = self.klass(np.zeros((1000, 4)), columns=range(4),
+                            index=range(1000))
         foo = repr(biggie)
 
         # mixed
@@ -190,6 +229,7 @@ class TestDataFrame(unittest.TestCase):
         biggie.toString(buffer=buf)
 
         biggie.toString(buffer=buf, columns=['B', 'A'], colSpace=17)
+        biggie.toString(buffer=buf, columns=['B', 'A'], verbose=True)
         biggie.toString(buffer=buf, columns=['B', 'A'],
                         formatters={'A' : lambda x: '%.1f' % x})
 
@@ -270,8 +310,10 @@ class TestDataFrame(unittest.TestCase):
     def test_operators(self):
         garbage = random.random(4)
         colSeries = Series(garbage, index=np.array(self.frame.cols()))
+
         idSum = self.frame + self.frame
         seriesSum = self.frame + colSeries
+
         for col, series in idSum.iteritems():
             for idx, val in series.iteritems():
                 origVal = self.frame[col][idx] * 2
@@ -279,6 +321,7 @@ class TestDataFrame(unittest.TestCase):
                     self.assertEqual(val, origVal)
                 else:
                     self.assert_(np.isnan(origVal))
+
         for col, series in seriesSum.iteritems():
             for idx, val in series.iteritems():
                 origVal = self.frame[col][idx] + colSeries[col]
@@ -375,6 +418,13 @@ class TestDataFrame(unittest.TestCase):
 
         self.assert_(smaller_added.index.equals(self.tsframe.index))
 
+        # length 0
+        result = self.tsframe + ts[:0]
+
+        # Frame is length 0
+        result = self.tsframe[:0] + ts
+        self.assertEqual(len(result), 0)
+
     def test_combineFunc(self):
         pass
 
@@ -397,10 +447,10 @@ class TestDataFrame(unittest.TestCase):
         pass
 
     def test_rows(self):
-        pass
+        self.assert_(self.tsframe.rows() is self.tsframe.index)
 
     def test_cols(self):
-        pass
+        self.assert_(self.tsframe.cols() == list(self.tsframe.columns))
 
     def test_columns(self):
         pass
@@ -517,23 +567,6 @@ class TestDataFrame(unittest.TestCase):
 
         result = self.mixed_frame.fill(value=0)
 
-    def test_getTS(self):
-        frame = self.tsframe
-
-        tsFrame = frame.getTS(fromDate=frame.index[5], nPeriods=5)
-        assert_frame_equal(tsFrame, frame[5:10])
-
-        tsFrame = frame.getTS(fromDate=frame.index[5], toDate=frame.index[9])
-        assert_frame_equal(tsFrame, frame[5:10])
-
-        tsFrame = frame.getTS(nPeriods=5, toDate=frame.index[9])
-        assert_frame_equal(tsFrame, frame[5:10])
-
-        A = frame.getTS(colName='A', nPeriods=5, toDate=frame.index[9])
-        assert_series_equal(A, frame['A'][5:10])
-
-        self.assertRaises(Exception, frame.getTS, nPeriods=5)
-
     def test_truncate(self):
         offset = datetools.bday
 
@@ -597,7 +630,7 @@ class TestDataFrame(unittest.TestCase):
         frame = DataFrame(data)
         pivoted = frame.pivot(index='index', columns='columns', values='values')
 
-        expected = DataFrame.fromDict({
+        expected = DataFrame({
             'One' : {'A' : 1., 'B' : 2., 'C' : 3.},
             'Two' : {'A' : 1., 'B' : 2., 'C' : 3.}
         })
diff --git a/pandas/core/tests/test_index.py b/pandas/core/tests/test_index.py
index 3c346d0fa..b83db9349 100644
--- a/pandas/core/tests/test_index.py
+++ b/pandas/core/tests/test_index.py
@@ -14,6 +14,12 @@ class TestIndex(unittest.TestCase):
         self.dateIndex = common.makeDateIndex(100)
         self.intIndex = common.makeIntIndex(100)
 
+    def test_deepcopy(self):
+        from copy import deepcopy
+
+        copy = deepcopy(self.strIndex)
+        self.assert_(copy is self.strIndex)
+
     def test_duplicates(self):
         self.assertRaises(Exception, Index, [0, 0, 0])
 
diff --git a/pandas/core/tests/test_matrix.py b/pandas/core/tests/test_matrix.py
index 786d8e159..90dfdb817 100644
--- a/pandas/core/tests/test_matrix.py
+++ b/pandas/core/tests/test_matrix.py
@@ -44,11 +44,11 @@ class TestDataMatrix(test_frame.TestDataFrame):
     def test_combineFirst_mixed(self):
         a = Series(['a','b'], index=range(2))
         b = Series(range(2), index=range(2))
-        f = DataMatrix.fromDict({'A' : a, 'B' : b})
+        f = DataMatrix({'A' : a, 'B' : b})
 
         a = Series(['a','b'], index=range(5, 7))
         b = Series(range(2), index=range(5, 7))
-        g = DataMatrix.fromDict({'A' : a, 'B' : b})
+        g = DataMatrix({'A' : a, 'B' : b})
 
         combined = f.combineFirst(g)
 
diff --git a/pandas/core/tests/test_pytools.py b/pandas/core/tests/test_pytools.py
new file mode 100644
index 000000000..2be3af1b4
--- /dev/null
+++ b/pandas/core/tests/test_pytools.py
@@ -0,0 +1,52 @@
+import pandas.core.pytools as pytools
+
+def test_rands():
+    r = pytools.rands(10)
+    assert(len(r) == 10)
+
+def test_adjoin():
+    data = [['a', 'b', 'c'],
+            ['dd', 'ee', 'ff'],
+            ['ggg', 'hhh', 'iii']]
+    expected = 'a  dd  ggg\nb  ee  hhh\nc  ff  iii'
+
+    adjoined = pytools.adjoin(2, *data)
+
+    assert(adjoined == expected)
+
+def test_iterpairs():
+    data = [1, 2, 3, 4]
+    expected = [(1, 2),
+                (2, 3),
+                (3, 4)]
+
+    result = list(pytools.iterpairs(data))
+
+    assert(result == expected)
+
+def test_indent():
+    s = 'a b c\nd e f'
+    result = pytools.indent(s, spaces=6)
+
+    assert(result == '      a b c\n      d e f')
+
+def test_banner():
+    ban = pytools.banner('hi')
+    assert(ban == ('%s\nhi\n%s' % ('=' * 80, '=' * 80)))
+
+def test_map_indices_py():
+    data = [4, 3, 2, 1]
+    expected = {4 : 0, 3 : 1, 2 : 2, 1 : 3}
+
+    result = pytools.map_indices_py(data)
+
+    assert(result == expected)
+
+def test_union():
+    pass
+
+def test_difference():
+    pass
+
+def test_intersection():
+    pass
diff --git a/pandas/stats/moments.py b/pandas/stats/moments.py
index c008f4f20..46ed1217b 100644
--- a/pandas/stats/moments.py
+++ b/pandas/stats/moments.py
@@ -8,7 +8,6 @@ from pandas.core.api import (DataFrame, TimeSeries, DataMatrix,
                                  Series, notnull)
 
 import pandas.lib.tseries as tseries
-from pandas.lib.tseries import median as wirth_median
 import numpy as np
 
 __all__ = ['rolling_count', 'rolling_sum', 'rolling_mean',
@@ -195,7 +194,8 @@ def rolling_var(arg, window, minPeriods=None, timeRule=None):
     timeRule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
         Name of time rule to conform to before computing statistic
     """
-    return rolling_std(arg, window, minp=minPeriods, timeRule=timeRule)**2
+    return _rollingMoment(arg, window, tseries.rolling_var,
+                          minp=minPeriods, timeRule=timeRule)
 
 def rolling_skew(arg, window, minPeriods=None, timeRule=None):
     """
@@ -210,8 +210,8 @@ def rolling_skew(arg, window, minPeriods=None, timeRule=None):
     timeRule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
         Name of time rule to conform to before computing statistic
     """
-    return _rollingMoment(arg, window, tseries.rolling_skew, minp=minPeriods,
-                          timeRule=timeRule)
+    return _rollingMoment(arg, window, tseries.rolling_skew,
+                          minp=minPeriods, timeRule=timeRule)
 
 def rolling_kurt(arg, window, minPeriods=None, timeRule=None):
     """
@@ -229,30 +229,9 @@ def rolling_kurt(arg, window, minPeriods=None, timeRule=None):
     return _rollingMoment(arg, window, tseries.rolling_kurt,
                           minp=minPeriods, timeRule=timeRule)
 
-def _median(arr, mask):
-    arr = arr[mask]
-    return wirth_median(arr)
-
-def _rollmedian(series, window, minp=None):
-    if len(series) < window:
-        window = len(series)
-
-    minp = int(minp)
-    mask = notnull(series)
-
-    result = np.empty(len(series), dtype=float)
-    result[:minp - 1] = np.nan
-    result[minp - 1:] = [_median(series[max(i-window, 0):i],
-                                 mask[max(i-window, 0):i])
-                         for i in xrange(minp, len(series)+1)]
-
-    return result
-
 def rolling_median(arg, window, minPeriods=None, timeRule=None):
-    # Sort at each point, can't really do much better.
-
-    return _rollingMoment(arg, window, _rollmedian, minp=minPeriods,
-                          timeRule=timeRule)
+    return _rollingMoment(arg, window, tseries.rolling_median,
+                          minp=minPeriods, timeRule=timeRule)
 
 def test_rolling_median():
     arr = np.random.randn(100)
@@ -264,6 +243,12 @@ def test_rolling_median():
 
     assert(result[-1] == np.median(arr[-50:]))
 
+    result = rolling_median(arr, 49)
+
+    assert(np.isnan(result[20]))
+
+    assert(result[-1] == np.median(arr[-49:]))
+
 #-------------------------------------------------------------------------------
 # Exponential moving moments
 
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index c99a8987a..4d415b9c9 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -218,10 +218,8 @@ class OLS(object):
     @cache_readonly
     def _p_value_raw(self):
         """Returns the raw p values."""
-        t_stat = self._t_stat_raw
-        p_value = 2 * (1 - stats.t.cdf(np.fabs(t_stat),
-            (self._nobs - self._df_raw)))
-        return np.array(p_value)
+        return 2 * stats.t.sf(np.fabs(self._t_stat_raw),
+                              self._df_resid_raw)
 
     @cache_readonly
     def p_value(self):
@@ -276,7 +274,7 @@ class OLS(object):
     @cache_readonly
     def _std_err_raw(self):
         """Returns the raw standard err values."""
-        return np.nan_to_num(np.sqrt(np.diag(self._var_beta_raw)))
+        return np.sqrt(np.diag(self._var_beta_raw))
 
     @cache_readonly
     def std_err(self):
@@ -286,7 +284,7 @@ class OLS(object):
     @cache_readonly
     def _t_stat_raw(self):
         """Returns the raw t-stat value."""
-        return np.nan_to_num(self._beta_raw / self._std_err_raw)
+        return self._beta_raw / self._std_err_raw
 
     @cache_readonly
     def t_stat(self):
@@ -554,7 +552,7 @@ class MovingOLS(OLS):
                             for date, f_stat in zip(self.beta.index,
                                                     self._f_stat_raw))
 
-        return DataFrame.fromDict(f_stat_dicts).T
+        return DataFrame(f_stat_dicts).T
 
     def f_test(self, hypothesis):
         raise Exception('f_test not supported for rolling/expanding OLS')
@@ -804,14 +802,11 @@ class MovingOLS(OLS):
     @cache_readonly
     def _p_value_raw(self):
         """Returns the raw p values."""
-        get_prob = lambda a, b: 2 * (1 - stats.t.cdf(a, b))
+        result = [2 * stats.t.sf(a, b)
+                  for a, b in izip(np.fabs(self._t_stat_raw),
+                                   self._df_resid_raw)]
 
-        result = starmap(get_prob,
-                         izip(np.fabs(self._t_stat_raw), self._df_resid_raw))
-
-        result = np.array(list(result))
-
-        return result
+        return np.array(result)
 
     @cache_readonly
     def _resid_stats(self):
@@ -885,12 +880,12 @@ class MovingOLS(OLS):
         for i in xrange(len(self._var_beta_raw)):
             results.append(np.sqrt(np.diag(self._var_beta_raw[i])))
 
-        return np.nan_to_num(np.array(results))
+        return np.array(results)
 
     @cache_readonly
     def _t_stat_raw(self):
         """Returns the raw t-stat value."""
-        return np.nan_to_num(self._beta_raw / self._std_err_raw)
+        return self._beta_raw / self._std_err_raw
 
     @cache_readonly
     def _var_beta_raw(self):
@@ -1070,11 +1065,11 @@ def _filter_data(lhs, rhs):
 
     combined_rhs = _combine_rhs(rhs)
 
-    pre_filtered_rhs = DataMatrix.fromDict(combined_rhs).dropIncompleteRows()
+    pre_filtered_rhs = DataMatrix(combined_rhs).dropIncompleteRows()
 
     # Union of all indices
     combined_rhs['_y'] = lhs
-    full_dataset = DataMatrix.fromDict(combined_rhs)
+    full_dataset = DataMatrix(combined_rhs)
 
     index = full_dataset.index
 
diff --git a/pandas/stats/var.py b/pandas/stats/var.py
index fb929e711..34006058f 100644
--- a/pandas/stats/var.py
+++ b/pandas/stats/var.py
@@ -14,7 +14,7 @@ from pandas.stats.ols import _combine_rhs
 
 class VAR(object):
     def __init__(self, data, lags):
-        self._data = DataFrame.fromDict(_combine_rhs(data))
+        self._data = DataFrame(_combine_rhs(data))
         self._p = lags
 
         self._columns = self._data.columns
@@ -43,7 +43,7 @@ class VAR(object):
         """
         d = dict([(key, value.beta)
                   for (key, value) in self.ols_results.iteritems()])
-        return DataFrame.fromDict(d)
+        return DataFrame(d)
 
     def forecast(self, h):
         """
@@ -148,8 +148,8 @@ class VAR(object):
             f_stat_dict[col] = Series(f_stats, self._columns)
             p_value_dict[col] = Series(p_values, self._columns)
 
-        f_stat_mat = DataFrame.fromDict(f_stat_dict)
-        p_value_mat = DataFrame.fromDict(p_value_dict)
+        f_stat_mat = DataFrame(f_stat_dict)
+        p_value_mat = DataFrame(p_value_dict)
 
         return {
             'f-stat' : f_stat_mat,
