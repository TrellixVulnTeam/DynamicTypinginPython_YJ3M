commit 0d0b9b0399fbc332ee9464478880a7f0a57e76cf
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Jul 25 22:44:30 2011 -0400

    TST: unit testing for groupby

diff --git a/RELEASE.rst b/RELEASE.rst
index d4633a7e1..cd7c4046b 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -45,12 +45,21 @@ Release notes
   * series.ix[[d1, d2, d3]]
   * frame.ix[5:10, ['C', 'B', 'A']], frame.ix[5:10, 'A':'C']
   * frame.ix[date1:date2]
+* Significantly enhanced `groupby` functionality
+  * Can groupby multiple keys, e.g. df.groupby(['key1', 'key2']). Iteration with
+    multiple groupings products a flattened tuple
+  * "Nuisance" columns (non-aggregatable) will automatically be excluded from
+    DataFrame aggregation operations
+  * Added automatic "dispatching to Series / DataFrame methods to more easily
+    invoke methods on groups. e.g. s.groupby(crit).std() will work even though
+    `std` is not implemented on the `GroupBy` class
 * `Series` arithmetic methods with optional fill_value for missing data,
   e.g. a.add(b, fill_value=0). If a location is missing for both it will still
   be missing in the result though.
 * fill_value option has been added to `DataFrame`.{add, mul, sub, div} methods
   similar to `Series`
-* Boolean indexing with `DataFrame` objects: data[data > 0.1] = 0.1
+* Boolean indexing with `DataFrame` objects: data[data > 0.1] = 0.1 or
+  data[data> other] = 1.
 * `pytz` / tzinfo support in `DateRange`
   * `tz_localize`, `tz_normalize`, and `tz_validate` methods added
 * Added `ExcelFile` class to `pandas.io.parsers` for parsing multiple sheets out
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 290e7cb4a..fc604d3cd 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -135,20 +135,6 @@ class GroupBy(object):
     def agg(self, func):
         return self.aggregate(func)
 
-    def _aggregate_generic(self, agger, axis=0):
-        result = {}
-
-        obj = self._get_obj_with_exclusions()
-
-        for name in self.primary:
-            data = self.get_group(name, obj=obj)
-            try:
-                result[name] = agger(data)
-            except Exception:
-                result[name] = data.apply(agger, axis=axis)
-
-        return result
-
     def _get_name_dict(self):
         axes = [ping.names for ping in self.groupings]
         grouping_names = [ping.name for ping in self.groupings]
@@ -191,9 +177,7 @@ class GroupBy(object):
         # TODO: get counts in cython
 
         output = {}
-
         cannot_agg = []
-
         for name, obj in self._iterate_columns():
             try:
                 obj = np.asarray(obj, dtype=float)
@@ -210,9 +194,10 @@ class GroupBy(object):
 
             output[name] = result[mask]
 
-        if cannot_agg:
-            print ('Note: excluded %s which could not '
-                   'be aggregated' % cannot_agg)
+        # do I want a warning message or silently exclude?
+        # if cannot_agg:
+        #     print ('Note: excluded %s which could not '
+        #            'be aggregated' % cannot_agg)
 
         name_dict = self._get_name_dict()
 
@@ -595,12 +580,52 @@ class DataFrameGroupBy(GroupBy):
             result = DataFrame(result)
         else:
             result = self._aggregate_generic(arg, axis=self.axis)
-            result = DataFrame(result)
-            if self.axis == 0:
-                result = result.T
 
         return result
 
+    def _aggregate_generic(self, agger, axis=0):
+        result = {}
+
+        obj = self._get_obj_with_exclusions()
+
+        try:
+            for name in self.primary:
+                data = self.get_group(name, obj=obj)
+                try:
+                    result[name] = agger(data)
+                except Exception:
+                    result[name] = data.apply(agger, axis=axis)
+        except Exception, e1:
+            if axis == 0:
+                try:
+                    return self._aggregate_item_by_item(agger)
+                except Exception:
+                    raise e1
+            else:
+                raise e1
+
+        result = DataFrame(result)
+        if axis == 0:
+            result = result.T
+
+        return result
+
+    def _aggregate_item_by_item(self, agger):
+        # only for axis==0
+
+        obj = self._get_obj_with_exclusions()
+
+        result = {}
+        cannot_agg = []
+        for item in obj:
+            try:
+                result[item] = self[item].agg(agger)
+            except (ValueError, TypeError):
+                cannot_agg.append(item)
+                continue
+
+        return DataFrame(result)
+
     def transform(self, func):
         """
         For given DataFrame, group index by given mapper function or dict, take
@@ -687,11 +712,24 @@ class WidePanelGroupBy(GroupBy):
 
         Optional: provide set mapping as dictionary
         """
-        result_d = self._aggregate_generic(func, axis=self.axis)
-        result = WidePanel.fromDict(result_d, intersect=False)
+        return self._aggregate_generic(func, axis=self.axis)
+
+    def _aggregate_generic(self, agger, axis=0):
+        result = {}
+
+        obj = self._get_obj_with_exclusions()
+
+        for name in self.primary:
+            data = self.get_group(name, obj=obj)
+            try:
+                result[name] = agger(data)
+            except Exception:
+                result[name] = data.apply(agger, axis=axis)
+
+        result = WidePanel.fromDict(result, intersect=False)
 
-        if self.axis > 0:
-            result = result.swapaxes(0, self.axis)
+        if axis > 0:
+            result = result.swapaxes(0, axis)
 
         return result
 
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 53fc018da..6428592e7 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -49,11 +49,23 @@ class GroupByTestCase(unittest.TestCase):
             groupSet = setDict[key]
             assert(idx in groupSet)
 
-class TestSeriesGroupBy(unittest.TestCase):
+class TestGroupBy(unittest.TestCase):
 
     def setUp(self):
         self.ts = tm.makeTimeSeries()
 
+        self.seriesd = tm.getSeriesData()
+        self.tsd = tm.getTimeSeriesData()
+        self.frame = DataFrame(self.seriesd)
+        self.tsframe = DataFrame(self.tsd)
+
+        self.df = DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
+                                    'foo', 'bar', 'foo', 'foo'],
+                             'B' : ['one', 'one', 'two', 'three',
+                                    'two', 'two', 'one', 'three'],
+                             'C' : np.random.randn(8),
+                             'D' : np.random.randn(8)})
+
     def test_basic(self):
         data = Series(np.arange(9) / 3, index=np.arange(9))
 
@@ -197,15 +209,7 @@ class TestSeriesGroupBy(unittest.TestCase):
         # make sure raises error
         self.assertRaises(AttributeError, getattr, grouped, 'foo')
 
-class TestDataFrameGroupBy(unittest.TestCase):
-
-    def setUp(self):
-        self.seriesd = tm.getSeriesData()
-        self.tsd = tm.getTimeSeriesData()
-        self.frame = DataFrame(self.seriesd)
-        self.tsframe = DataFrame(self.tsd)
-
-    def test_groupby(self):
+    def test_frame_groupby(self):
         grouped = self.tsframe.groupby(lambda x: x.weekday())
 
         # aggregate
@@ -243,7 +247,7 @@ class TestDataFrameGroupBy(unittest.TestCase):
             samething = self.tsframe.index.take(indices[k])
             self.assert_(np.array_equal(v, samething))
 
-    def test_groupby_columns(self):
+    def test_frame_groupby_columns(self):
         mapping = {
             'A' : 0, 'B' : 0, 'C' : 1, 'D' : 1
         }
@@ -276,38 +280,46 @@ class TestDataFrameGroupBy(unittest.TestCase):
         self.assertEqual(len(grouped.columns), 2)
 
     def test_groupby_multiple_columns(self):
-        data = DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
-                                 'foo', 'bar', 'foo', 'foo'],
-                          'B' : ['one', 'one', 'two', 'three',
-                                 'two', 'two', 'one', 'three'],
-                          'C' : np.random.randn(8),
-                          'D' : np.random.randn(8)})
-
+        data = self.df
         grouped = data.groupby(['A', 'B'])
-        result1 = grouped.sum()
-
-        expected = defaultdict(dict)
-        for n1, gp1 in data.groupby('A'):
-            for n2, gp2 in gp1.groupby('B'):
-                expected[n1][n2] = gp2.ix[:, ['C', 'D']].sum()
-        expected = dict((k, DataFrame(v)) for k, v in expected.iteritems())
-        expected = WidePanel.fromDict(expected).swapaxes(0, 1)
-
-        # a little bit crude
-        # TODO: fix when have hierarchical Index
-        for col in ['C', 'D']:
-            result_col = grouped[col].sum()
-            exp = expected[col]
-            pivoted = result1.pivot('A', 'B', col)
-            pivoted2 = result_col.pivot('A', 'B', col)
-            assert_frame_equal(pivoted.reindex_like(exp), exp)
-            assert_frame_equal(pivoted2.reindex_like(exp), exp)
-
-        # assert_panel_equal(result1, expected)
-        # assert_panel_equal(result1['C'], expected['C'])
-
-        # result2 = data.groupby('B', 'A').sum()
-        # assert_panel_equal(result2, expected2)
+
+        def _check_op(op):
+
+            result1 = op(grouped)
+
+            expected = defaultdict(dict)
+            for n1, gp1 in data.groupby('A'):
+                for n2, gp2 in gp1.groupby('B'):
+                    expected[n1][n2] = op(gp2.ix[:, ['C', 'D']])
+            expected = dict((k, DataFrame(v)) for k, v in expected.iteritems())
+            expected = WidePanel.fromDict(expected).swapaxes(0, 1)
+
+            # a little bit crude
+            # TODO: fix when have hierarchical Index
+            for col in ['C', 'D']:
+                result_col = op(grouped[col])
+                exp = expected[col]
+                pivoted = result1.pivot('A', 'B', col)
+                pivoted2 = result_col.pivot('A', 'B', col)
+                assert_frame_equal(pivoted.reindex_like(exp), exp)
+                assert_frame_equal(pivoted2.reindex_like(exp), exp)
+
+        _check_op(lambda x: x.sum())
+        _check_op(lambda x: x.mean())
+
+        # test single series works the same
+        result = data['C'].groupby([data['A'], data['B']]).mean()
+        expected = data.groupby(['A', 'B']).mean()['C']
+
+        # choice of "result" is pretty arbitrary, should eventually return a
+        # hierarchical index
+        assert_series_equal(result['result'], expected)
+
+    def test_omit_nuisance(self):
+        grouped = self.df.groupby('A')
+        result = grouped.mean()
+        expected = self.df.ix[:, ['A', 'C', 'D']].groupby('A').mean()
+        assert_frame_equal(result, expected)
 
 class TestPanelGroupBy(unittest.TestCase):
 
