commit 4fce7846be56e12999fe8758abb2ea2f2794259d
Author: Matthew Roeschke <emailformattr@gmail.com>
Date:   Fri Nov 24 11:27:13 2017 -0800

    CLN: Replace comprehensions list/set/dict functions with corresponding symbols (#18383)

diff --git a/asv_bench/benchmarks/frame_ctor.py b/asv_bench/benchmarks/frame_ctor.py
index 7f95e8d06..2ee5f5da7 100644
--- a/asv_bench/benchmarks/frame_ctor.py
+++ b/asv_bench/benchmarks/frame_ctor.py
@@ -23,9 +23,9 @@ class FromDicts(object):
         self.some_dict = list(self.data.values())[0]
         self.dict_list = [dict(zip(self.columns, row)) for row in self.frame.values]
 
-        self.data2 = dict(
-            ((i, dict(((j, float(j)) for j in range(100)))) for i in
-             range(2000)))
+        self.data2 = {i: {j: float(j) for j in range(100)}
+                      for i in range(2000)}
+
 
     def time_frame_ctor_list_of_dict(self):
         DataFrame(self.dict_list)
diff --git a/asv_bench/benchmarks/packers.py b/asv_bench/benchmarks/packers.py
index 927f1505e..758162f00 100644
--- a/asv_bench/benchmarks/packers.py
+++ b/asv_bench/benchmarks/packers.py
@@ -18,7 +18,7 @@ class _Packers(object):
         self.N = 100000
         self.C = 5
         self.index = date_range('20000101', periods=self.N, freq='H')
-        self.df = DataFrame(dict(('float{0}'.format(i), randn(self.N)) for i in range(self.C)), index=self.index)
+        self.df = DataFrame({'float{0}'.format(i): randn(self.N) for i in range(self.C)}, index=self.index)
         self.df2 = self.df.copy()
         self.df2['object'] = [('%08x' % randrange((16 ** 8))) for _ in range(self.N)]
         self.remove(self.f)
diff --git a/asv_bench/benchmarks/replace.py b/asv_bench/benchmarks/replace.py
index 63562f90e..157d5fe1e 100644
--- a/asv_bench/benchmarks/replace.py
+++ b/asv_bench/benchmarks/replace.py
@@ -23,7 +23,7 @@ class replace_large_dict(object):
     def setup(self):
         self.n = (10 ** 6)
         self.start_value = (10 ** 5)
-        self.to_rep = dict(((i, (self.start_value + i)) for i in range(self.n)))
+        self.to_rep = {i: self.start_value + i for i in range(self.n)}
         self.s = Series(np.random.randint(self.n, size=(10 ** 3)))
 
     def time_replace_large_dict(self):
@@ -35,8 +35,8 @@ class replace_convert(object):
 
     def setup(self):
         self.n = (10 ** 3)
-        self.to_ts = dict(((i, pd.Timestamp(i)) for i in range(self.n)))
-        self.to_td = dict(((i, pd.Timedelta(i)) for i in range(self.n)))
+        self.to_ts = {i: pd.Timestamp(i) for i in range(self.n)}
+        self.to_td = {i: pd.Timedelta(i) for i in range(self.n)}
         self.s = Series(np.random.randint(self.n, size=(10 ** 3)))
         self.df = DataFrame({'A': np.random.randint(self.n, size=(10 ** 3)),
                              'B': np.random.randint(self.n, size=(10 ** 3))})
diff --git a/doc/sphinxext/numpydoc/phantom_import.py b/doc/sphinxext/numpydoc/phantom_import.py
index e0bd645f5..f33dd838e 100755
--- a/doc/sphinxext/numpydoc/phantom_import.py
+++ b/doc/sphinxext/numpydoc/phantom_import.py
@@ -60,8 +60,8 @@ def import_phantom_module(xml_file):
     # Sort items so that
     # - Base classes come before classes inherited from them
     # - Modules come before their contents
-    all_nodes = dict((n.attrib['id'], n) for n in root)
-    
+    all_nodes = {n.attrib['id']: n for n in root}
+
     def _get_bases(node, recurse=False):
         bases = [x.attrib['ref'] for x in node.findall('base')]
         if recurse:
diff --git a/pandas/_libs/tslibs/offsets.pyx b/pandas/_libs/tslibs/offsets.pyx
index 526595e3a..b03d48bba 100644
--- a/pandas/_libs/tslibs/offsets.pyx
+++ b/pandas/_libs/tslibs/offsets.pyx
@@ -33,7 +33,7 @@ from np_datetime cimport (pandas_datetimestruct,
 _MONTHS = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL',
            'AUG', 'SEP', 'OCT', 'NOV', 'DEC']
 _int_to_month = {(k + 1): v for k, v in enumerate(_MONTHS)}
-_month_to_int = dict((v, k) for k, v in _int_to_month.items())
+_month_to_int = {v: k for k, v in _int_to_month.items()}
 
 
 class WeekDay(object):
diff --git a/pandas/_libs/tslibs/resolution.pyx b/pandas/_libs/tslibs/resolution.pyx
index 388075903..0692d985b 100644
--- a/pandas/_libs/tslibs/resolution.pyx
+++ b/pandas/_libs/tslibs/resolution.pyx
@@ -53,7 +53,7 @@ _ONE_HOUR = 60 * _ONE_MINUTE
 _ONE_DAY = 24 * _ONE_HOUR
 
 DAYS = ['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN']
-_weekday_rule_aliases = dict((k, v) for k, v in enumerate(DAYS))
+_weekday_rule_aliases = {k: v for k, v in enumerate(DAYS)}
 
 _MONTHS = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL',
            'AUG', 'SEP', 'OCT', 'NOV', 'DEC']
diff --git a/pandas/_version.py b/pandas/_version.py
index 4a469ebb8..624c7b5cd 100644
--- a/pandas/_version.py
+++ b/pandas/_version.py
@@ -141,11 +141,11 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         if verbose:
             print("keywords are unexpanded, not using")
         raise NotThisMethod("unexpanded keywords, not a git-archive tarball")
-    refs = set(r.strip() for r in refnames.strip("()").split(","))
+    refs = {r.strip() for r in refnames.strip("()").split(",")}
     # starting in git-1.8.3, tags are listed as "tag: foo-1.0" instead of
     # just "foo-1.0". If we see a "tag: " prefix, prefer those.
     TAG = "tag: "
-    tags = set(r[len(TAG):] for r in refs if r.startswith(TAG))
+    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}
     if not tags:
         # Either we're using git < 1.8.3, or there really are no tags. We use
         # a heuristic: assume all version tags have a digit. The old git %d
@@ -154,7 +154,7 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         # between branches and tags. By ignoring refnames without digits, we
         # filter out many common branch names like "release" and
         # "stabilization", as well as "HEAD" and "master".
-        tags = set(r for r in refs if re.search(r'\d', r))
+        tags = {r for r in refs if re.search(r'\d', r)}
         if verbose:
             print("discarding '{}', no digits".format(",".join(refs - tags)))
     if verbose:
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 8e12ce364..76a690304 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -347,7 +347,7 @@ def map_indices_py(arr):
     Returns a dictionary with (element, index) pairs for each element in the
     given array/list
     """
-    return dict((x, i) for i, x in enumerate(arr))
+    return {x: i for i, x in enumerate(arr)}
 
 
 def union(*seqs):
diff --git a/pandas/core/dtypes/concat.py b/pandas/core/dtypes/concat.py
index 7f9245bb3..c1ba018ad 100644
--- a/pandas/core/dtypes/concat.py
+++ b/pandas/core/dtypes/concat.py
@@ -459,7 +459,7 @@ def _concat_datetimetz(to_concat, name=None):
     it is used in DatetimeIndex.append also
     """
     # do not pass tz to set because tzlocal cannot be hashed
-    if len(set(str(x.dtype) for x in to_concat)) != 1:
+    if len({str(x.dtype) for x in to_concat}) != 1:
         raise ValueError('to_concat must have the same tz')
     tz = to_concat[0].tz
     # no need to localize because internal repr will not be changed
@@ -525,7 +525,7 @@ def _concat_sparse(to_concat, axis=0, typs=None):
     if len(typs) == 1:
         # concat input as it is if all inputs are sparse
         # and have the same fill_value
-        fill_values = set(c.fill_value for c in to_concat)
+        fill_values = {c.fill_value for c in to_concat}
         if len(fill_values) == 1:
             sp_values = [c.sp_values for c in to_concat]
             indexes = [c.sp_index.to_int_index() for c in to_concat]
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 20ed3f69d..e82eb8635 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -347,7 +347,7 @@ class DataFrame(NDFrame):
         elif isinstance(data, (np.ndarray, Series, Index)):
             if data.dtype.names:
                 data_columns = list(data.dtype.names)
-                data = dict((k, data[k]) for k in data_columns)
+                data = {k: data[k] for k in data_columns}
                 if columns is None:
                     columns = data_columns
                 mgr = self._init_dict(data, index, columns, dtype=dtype)
@@ -417,8 +417,7 @@ class DataFrame(NDFrame):
                 extract_index(list(data.values()))
 
             # prefilter if columns passed
-            data = dict((k, v) for k, v in compat.iteritems(data)
-                        if k in columns)
+            data = {k: v for k, v in compat.iteritems(data) if k in columns}
 
             if index is None:
                 index = extract_index(list(data.values()))
@@ -3895,7 +3894,7 @@ class DataFrame(NDFrame):
                     return self._constructor_sliced(r, index=new_index,
                                                     dtype=r.dtype)
 
-                result = dict((col, f(col)) for col in this)
+                result = {col: f(col) for col in this}
 
             # non-unique
             else:
@@ -3906,7 +3905,7 @@ class DataFrame(NDFrame):
                     return self._constructor_sliced(r, index=new_index,
                                                     dtype=r.dtype)
 
-                result = dict((i, f(i)) for i, col in enumerate(this.columns))
+                result = {i: f(i) for i, col in enumerate(this.columns)}
                 result = self._constructor(result, index=new_index, copy=False)
                 result.columns = new_columns
                 return result
@@ -3984,7 +3983,7 @@ class DataFrame(NDFrame):
         if self.columns.is_unique:
 
             def _compare(a, b):
-                return dict((col, func(a[col], b[col])) for col in a.columns)
+                return {col: func(a[col], b[col]) for col in a.columns}
 
             new_data = expressions.evaluate(_compare, str_rep, self, other)
             return self._constructor(data=new_data, index=self.index,
@@ -3993,8 +3992,8 @@ class DataFrame(NDFrame):
         else:
 
             def _compare(a, b):
-                return dict((i, func(a.iloc[:, i], b.iloc[:, i]))
-                            for i, col in enumerate(a.columns))
+                return {i: func(a.iloc[:, i], b.iloc[:, i])
+                        for i, col in enumerate(a.columns)}
 
             new_data = expressions.evaluate(_compare, str_rep, self, other)
             result = self._constructor(data=new_data, index=self.index,
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 782971a74..548f228cd 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -235,10 +235,10 @@ class NDFrame(PandasObject, SelectionMixin):
         """
 
         cls._AXIS_ORDERS = axes
-        cls._AXIS_NUMBERS = dict((a, i) for i, a in enumerate(axes))
+        cls._AXIS_NUMBERS = {a: i for i, a in enumerate(axes)}
         cls._AXIS_LEN = len(axes)
         cls._AXIS_ALIASES = aliases or dict()
-        cls._AXIS_IALIASES = dict((v, k) for k, v in cls._AXIS_ALIASES.items())
+        cls._AXIS_IALIASES = {v: k for k, v in cls._AXIS_ALIASES.items()}
         cls._AXIS_NAMES = dict(enumerate(axes))
         cls._AXIS_SLICEMAP = slicers or None
         cls._AXIS_REVERSED = axes_are_reversed
@@ -279,21 +279,21 @@ class NDFrame(PandasObject, SelectionMixin):
 
     def _construct_axes_dict(self, axes=None, **kwargs):
         """Return an axes dictionary for myself."""
-        d = dict((a, self._get_axis(a)) for a in (axes or self._AXIS_ORDERS))
+        d = {a: self._get_axis(a) for a in (axes or self._AXIS_ORDERS)}
         d.update(kwargs)
         return d
 
     @staticmethod
     def _construct_axes_dict_from(self, axes, **kwargs):
         """Return an axes dictionary for the passed axes."""
-        d = dict((a, ax) for a, ax in zip(self._AXIS_ORDERS, axes))
+        d = {a: ax for a, ax in zip(self._AXIS_ORDERS, axes)}
         d.update(kwargs)
         return d
 
     def _construct_axes_dict_for_slice(self, axes=None, **kwargs):
         """Return an axes dictionary for myself."""
-        d = dict((self._AXIS_SLICEMAP[a], self._get_axis(a))
-                 for a in (axes or self._AXIS_ORDERS))
+        d = {self._AXIS_SLICEMAP[a]: self._get_axis(a)
+             for a in (axes or self._AXIS_ORDERS)}
         d.update(kwargs)
         return d
 
@@ -329,7 +329,7 @@ class NDFrame(PandasObject, SelectionMixin):
                         raise TypeError("not enough/duplicate arguments "
                                         "specified!")
 
-        axes = dict((a, kwargs.pop(a, None)) for a in self._AXIS_ORDERS)
+        axes = {a: kwargs.pop(a, None) for a in self._AXIS_ORDERS}
         return axes, kwargs
 
     @classmethod
@@ -1172,7 +1172,7 @@ class NDFrame(PandasObject, SelectionMixin):
     # Picklability
 
     def __getstate__(self):
-        meta = dict((k, getattr(self, k, None)) for k in self._metadata)
+        meta = {k: getattr(self, k, None) for k in self._metadata}
         return dict(_data=self._data, _typ=self._typ, _metadata=self._metadata,
                     **meta)
 
@@ -4277,8 +4277,8 @@ class NDFrame(PandasObject, SelectionMixin):
             elif self.ndim == 3:
 
                 # fill in 2d chunks
-                result = dict((col, s.fillna(method=method, value=value))
-                              for col, s in self.iteritems())
+                result = {col: s.fillna(method=method, value=value)
+                          for col, s in self.iteritems()}
                 new_obj = self._constructor.\
                     from_dict(result).__finalize__(self)
                 new_data = new_obj._data
@@ -5681,7 +5681,7 @@ class NDFrame(PandasObject, SelectionMixin):
                 # this means other is a DataFrame, and we need to broadcast
                 # self
                 cons = self._constructor_expanddim
-                df = cons(dict((c, self) for c in other.columns),
+                df = cons({c: self for c in other.columns},
                           **other._construct_axes_dict())
                 return df._align_frame(other, join=join, axis=axis,
                                        level=level, copy=copy,
@@ -5691,7 +5691,7 @@ class NDFrame(PandasObject, SelectionMixin):
                 # this means self is a DataFrame, and we need to broadcast
                 # other
                 cons = other._constructor_expanddim
-                df = cons(dict((c, other) for c in self.columns),
+                df = cons({c: other for c in self.columns},
                           **self._construct_axes_dict())
                 return self._align_frame(df, join=join, axis=axis, level=level,
                                          copy=copy, fill_value=fill_value,
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 8338df33f..ba180cc98 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -3840,7 +3840,7 @@ class NDFrameGroupBy(GroupBy):
                             # if all series have a consistent name.  If the
                             # series do not have a consistent name, do
                             # nothing.
-                            names = set(v.name for v in values)
+                            names = {v.name for v in values}
                             if len(names) == 1:
                                 index.name = list(names)[0]
 
diff --git a/pandas/core/indexes/base.py b/pandas/core/indexes/base.py
index 7a34e6472..1cb40b3ec 100644
--- a/pandas/core/indexes/base.py
+++ b/pandas/core/indexes/base.py
@@ -732,7 +732,7 @@ class Index(IndexOpsMixin, PandasObject):
 
     def _get_attributes_dict(self):
         """ return an attributes dict for my class """
-        return dict((k, getattr(self, k, None)) for k in self._attributes)
+        return {k: getattr(self, k, None) for k in self._attributes}
 
     def view(self, cls=None):
 
@@ -1784,7 +1784,7 @@ class Index(IndexOpsMixin, PandasObject):
             if not isinstance(obj, Index):
                 raise TypeError('all inputs must be Index')
 
-        names = set(obj.name for obj in to_concat)
+        names = {obj.name for obj in to_concat}
         name = None if len(names) > 1 else self.name
 
         return self._concat(to_concat, name)
diff --git a/pandas/core/indexes/interval.py b/pandas/core/indexes/interval.py
index cca7a06a2..c7c739b76 100644
--- a/pandas/core/indexes/interval.py
+++ b/pandas/core/indexes/interval.py
@@ -1024,7 +1024,7 @@ class IntervalIndex(IntervalMixin, Index):
         assert that we all have the same .closed
         we allow a 0-len index here as well
         """
-        if not len(set(i.closed for i in to_concat if len(i))) == 1:
+        if not len({i.closed for i in to_concat if len(i)}) == 1:
             msg = ('can only append two IntervalIndex objects '
                    'that are closed on the same side')
             raise ValueError(msg)
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index ca4984cc1..e537cb2ed 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -3377,7 +3377,7 @@ class BlockManager(PandasObject):
             blocks.append(block)
 
         # note that some DatetimeTZ, Categorical are always ndim==1
-        ndim = set(b.ndim for b in blocks)
+        ndim = {b.ndim for b in blocks}
 
         if 2 in ndim:
 
@@ -3891,7 +3891,7 @@ class BlockManager(PandasObject):
         """
         Retrieve single item
         """
-        full_loc = list(ax.get_loc(x) for ax, x in zip(self.axes, tup))
+        full_loc = [ax.get_loc(x) for ax, x in zip(self.axes, tup)]
         blk = self.blocks[self._blknos[full_loc[0]]]
         values = blk.values
 
@@ -4871,7 +4871,7 @@ def _merge_blocks(blocks, dtype=None, _can_consolidate=True):
     if _can_consolidate:
 
         if dtype is None:
-            if len(set(b.dtype for b in blocks)) != 1:
+            if len({b.dtype for b in blocks}) != 1:
                 raise AssertionError("_merge_blocks are invalid!")
             dtype = blocks[0].dtype
 
diff --git a/pandas/core/ops.py b/pandas/core/ops.py
index fa50036b6..934570602 100644
--- a/pandas/core/ops.py
+++ b/pandas/core/ops.py
@@ -146,7 +146,7 @@ def _create_methods(arith_method, comp_method, bool_method,
             construct_result=_construct_divmod_result,
         )
 
-    new_methods = dict((names(k), v) for k, v in new_methods.items())
+    new_methods = {names(k): v for k, v in new_methods.items()}
     return new_methods
 
 
diff --git a/pandas/core/panelnd.py b/pandas/core/panelnd.py
index 691787125..80ee680d2 100644
--- a/pandas/core/panelnd.py
+++ b/pandas/core/panelnd.py
@@ -105,7 +105,7 @@ def create_nd_panel_factory(klass_name, orders, slices, slicer, aliases=None,
             new_axes.append(getattr(self, a).union(getattr(other, a)))
 
         # reindex: could check that everything's the same size, but forget it
-        d = dict((a, ax) for a, ax in zip(self._AXIS_ORDERS, new_axes))
+        d = {a: ax for a, ax in zip(self._AXIS_ORDERS, new_axes)}
         d['copy'] = False
         this = self.reindex(**d)
         other = other.reindex(**d)
diff --git a/pandas/core/reshape/concat.py b/pandas/core/reshape/concat.py
index 6139f0932..9bd5abb2c 100644
--- a/pandas/core/reshape/concat.py
+++ b/pandas/core/reshape/concat.py
@@ -568,7 +568,7 @@ def _make_concat_multiindex(indexes, keys, levels=None, names=None):
             names = list(names)
         else:
             # make sure that all of the passed indices have the same nlevels
-            if not len(set(idx.nlevels for idx in indexes)) == 1:
+            if not len({idx.nlevels for idx in indexes}) == 1:
                 raise AssertionError("Cannot concat indices that do"
                                      " not have the same number of levels")
 
diff --git a/pandas/core/reshape/melt.py b/pandas/core/reshape/melt.py
index 36e52f147..16439b30d 100644
--- a/pandas/core/reshape/melt.py
+++ b/pandas/core/reshape/melt.py
@@ -149,7 +149,7 @@ def lreshape(data, groups, dropna=True, label=None):
         for c in pivot_cols:
             mask &= notna(mdata[c])
         if not mask.all():
-            mdata = dict((k, v[mask]) for k, v in compat.iteritems(mdata))
+            mdata = {k: v[mask] for k, v in compat.iteritems(mdata)}
 
     from pandas import DataFrame
     return DataFrame(mdata, columns=id_cols + pivot_cols)
diff --git a/pandas/core/sparse/frame.py b/pandas/core/sparse/frame.py
index 0c9a55e0c..36a18d8f8 100644
--- a/pandas/core/sparse/frame.py
+++ b/pandas/core/sparse/frame.py
@@ -131,8 +131,7 @@ class SparseDataFrame(DataFrame):
         # pre-filter out columns if we passed it
         if columns is not None:
             columns = _ensure_index(columns)
-            data = dict((k, v) for k, v in compat.iteritems(data)
-                        if k in columns)
+            data = {k: v for k, v in compat.iteritems(data) if k in columns}
         else:
             columns = Index(_try_sort(list(data.keys())))
 
@@ -173,7 +172,7 @@ class SparseDataFrame(DataFrame):
         """ Init self from ndarray or list of lists """
         data = _prep_ndarray(data, copy=False)
         index, columns = self._prep_index(data, index, columns)
-        data = dict((idx, data[:, i]) for i, idx in enumerate(columns))
+        data = {idx: data[:, i] for i, idx in enumerate(columns)}
         return self._init_dict(data, index, columns, dtype)
 
     def _init_spmatrix(self, data, index, columns, dtype=None,
@@ -307,7 +306,7 @@ class SparseDataFrame(DataFrame):
         -------
         df : DataFrame
         """
-        data = dict((k, v.to_dense()) for k, v in compat.iteritems(self))
+        data = {k: v.to_dense() for k, v in compat.iteritems(self)}
         return DataFrame(data, index=self.index, columns=self.columns)
 
     def _apply_columns(self, func):
@@ -697,7 +696,7 @@ class SparseDataFrame(DataFrame):
             raise NotImplementedError("'method' argument is not supported")
 
         # TODO: fill value handling
-        sdict = dict((k, v) for k, v in compat.iteritems(self) if k in columns)
+        sdict = {k: v for k, v in compat.iteritems(self) if k in columns}
         return self._constructor(
             sdict, index=self.index, columns=columns,
             default_fill_value=self._default_fill_value).__finalize__(self)
diff --git a/pandas/io/clipboards.py b/pandas/io/clipboards.py
index 117c96d00..8e9b54970 100644
--- a/pandas/io/clipboards.py
+++ b/pandas/io/clipboards.py
@@ -53,7 +53,7 @@ def read_clipboard(sep='\s+', **kwargs):  # pragma: no cover
     # 0  1  2
     # 1  3  4
 
-    counts = set(x.lstrip().count('\t') for x in lines)
+    counts = {x.lstrip().count('\t') for x in lines}
     if len(lines) > 1 and len(counts) == 1 and counts.pop() != 0:
         sep = '\t'
 
diff --git a/pandas/io/json/json.py b/pandas/io/json/json.py
index 32bab09a0..11bf3a936 100644
--- a/pandas/io/json/json.py
+++ b/pandas/io/json/json.py
@@ -715,10 +715,8 @@ class SeriesParser(Parser):
         json = self.json
         orient = self.orient
         if orient == "split":
-            decoded = dict((str(k), v)
-                           for k, v in compat.iteritems(loads(
-                               json,
-                               precise_float=self.precise_float)))
+            decoded = {str(k): v for k, v in compat.iteritems(
+                loads(json, precise_float=self.precise_float))}
             self.check_keys_split(decoded)
             self.obj = Series(dtype=None, **decoded)
         else:
@@ -732,7 +730,7 @@ class SeriesParser(Parser):
         if orient == "split":
             decoded = loads(json, dtype=None, numpy=True,
                             precise_float=self.precise_float)
-            decoded = dict((str(k), v) for k, v in compat.iteritems(decoded))
+            decoded = {str(k): v for k, v in compat.iteritems(decoded)}
             self.check_keys_split(decoded)
             self.obj = Series(**decoded)
         elif orient == "columns" or orient == "index":
@@ -770,7 +768,7 @@ class FrameParser(Parser):
         elif orient == "split":
             decoded = loads(json, dtype=None, numpy=True,
                             precise_float=self.precise_float)
-            decoded = dict((str(k), v) for k, v in compat.iteritems(decoded))
+            decoded = {str(k): v for k, v in compat.iteritems(decoded)}
             self.check_keys_split(decoded)
             self.obj = DataFrame(**decoded)
         elif orient == "values":
@@ -790,10 +788,8 @@ class FrameParser(Parser):
             self.obj = DataFrame(
                 loads(json, precise_float=self.precise_float), dtype=None)
         elif orient == "split":
-            decoded = dict((str(k), v)
-                           for k, v in compat.iteritems(loads(
-                               json,
-                               precise_float=self.precise_float)))
+            decoded = {str(k): v for k, v in compat.iteritems(
+                loads(json, precise_float=self.precise_float))}
             self.check_keys_split(decoded)
             self.obj = DataFrame(dtype=None, **decoded)
         elif orient == "index":
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 558a1f6d7..8f6b01355 100755
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -1133,8 +1133,7 @@ def _evaluate_usecols(usecols, names):
     If not a callable, returns 'usecols'.
     """
     if callable(usecols):
-        return set(i for i, name in enumerate(names)
-                   if usecols(name))
+        return {i for i, name in enumerate(names) if usecols(name)}
     return usecols
 
 
@@ -1906,7 +1905,7 @@ class CParserWrapper(ParserBase):
 
             # rename dict keys
             data = sorted(data.items())
-            data = dict((k, v) for k, (i, v) in zip(names, data))
+            data = {k: v for k, (i, v) in zip(names, data)}
 
             names, data = self._do_date_conversions(names, data)
 
@@ -1924,7 +1923,7 @@ class CParserWrapper(ParserBase):
             # columns as list
             alldata = [x[1] for x in data]
 
-            data = dict((k, v) for k, (i, v) in zip(names, data))
+            data = {k: v for k, (i, v) in zip(names, data)}
 
             names, data = self._do_date_conversions(names, data)
             index, names = self._make_index(data, alldata, names)
@@ -2300,7 +2299,7 @@ class PythonParser(ParserBase):
                     offset += 1
                 data[col] = alldata[i + offset]
         else:
-            data = dict((k, v) for k, v in zip(names, alldata))
+            data = {k: v for k, v in zip(names, alldata)}
 
         return data
 
@@ -3233,9 +3232,8 @@ def _get_empty_meta(columns, index_col, index_names, dtype=None):
         for i, n in enumerate(index_col):
             columns.pop(n - i)
 
-    col_dict = dict((col_name,
-                     Series([], dtype=dtype[col_name]))
-                    for col_name in columns)
+    col_dict = {col_name: Series([], dtype=dtype[col_name])
+                for col_name in columns}
 
     return index, columns, col_dict
 
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index b9cddce55..2a66aea88 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -815,7 +815,7 @@ class HDFStore(StringMixin):
                     "all tables must have exactly the same nrows!")
 
         # axis is the concentation axes
-        axis = list(set(t.non_index_axes[0][0] for t in tbls))[0]
+        axis = list({t.non_index_axes[0][0] for t in tbls})[0]
 
         def func(_start, _stop, _where):
 
@@ -2374,8 +2374,7 @@ class GenericFixed(Fixed):
 
     """ a generified fixed version """
     _index_type_map = {DatetimeIndex: 'datetime', PeriodIndex: 'period'}
-    _reverse_index_map = dict((v, k)
-                              for k, v in compat.iteritems(_index_type_map))
+    _reverse_index_map = {v: k for k, v in compat.iteritems(_index_type_map)}
     attributes = []
 
     # indexer helpders
@@ -3510,8 +3509,8 @@ class Table(Fixed):
 
         # reorder the blocks in the same order as the existing_table if we can
         if existing_table is not None:
-            by_items = dict((tuple(b_items.tolist()), (b, b_items))
-                            for b, b_items in zip(blocks, blk_items))
+            by_items = {tuple(b_items.tolist()): (b, b_items)
+                        for b, b_items in zip(blocks, blk_items)}
             new_blocks = []
             new_blk_items = []
             for ea in existing_table.values_axes:
@@ -3659,7 +3658,7 @@ class Table(Fixed):
         d = dict(name='table', expectedrows=expectedrows)
 
         # description from the axes & values
-        d['description'] = dict((a.cname, a.typ) for a in self.axes)
+        d['description'] = {a.cname: a.typ for a in self.axes}
 
         if complib:
             if complevel is None:
diff --git a/pandas/io/sql.py b/pandas/io/sql.py
index 401a9c11a..975ad1e4f 100644
--- a/pandas/io/sql.py
+++ b/pandas/io/sql.py
@@ -641,7 +641,7 @@ class SQLTable(PandasObject):
         return column_names, data_list
 
     def _execute_insert(self, conn, keys, data_iter):
-        data = [dict((k, v) for k, v in zip(keys, row)) for row in data_iter]
+        data = [{k: v for k, v in zip(keys, row)} for row in data_iter]
         conn.execute(self.insert_statement(), data)
 
     def insert(self, chunksize=None):
diff --git a/pandas/plotting/_converter.py b/pandas/plotting/_converter.py
index 0f06d8772..9daee918b 100644
--- a/pandas/plotting/_converter.py
+++ b/pandas/plotting/_converter.py
@@ -994,7 +994,7 @@ class TimeSeries_DateFormatter(Formatter):
                                  info)
         else:
             format = np.compress(info['maj'], info)
-        self.formatdict = dict((x, f) for (x, _, _, f) in format)
+        self.formatdict = {x: f for (x, _, _, f) in format}
         return self.formatdict
 
     def set_locs(self, locs):
diff --git a/pandas/tests/frame/common.py b/pandas/tests/frame/common.py
index 3786facdd..c85fea3c3 100644
--- a/pandas/tests/frame/common.py
+++ b/pandas/tests/frame/common.py
@@ -10,8 +10,8 @@ _tsd = tm.getTimeSeriesData()
 
 _frame = pd.DataFrame(_seriesd)
 _frame2 = pd.DataFrame(_seriesd, columns=['D', 'C', 'B', 'A'])
-_intframe = pd.DataFrame(dict((k, v.astype(int))
-                              for k, v in compat.iteritems(_seriesd)))
+_intframe = pd.DataFrame({k: v.astype(int)
+                          for k, v in compat.iteritems(_seriesd)})
 
 _tsframe = pd.DataFrame(_tsd)
 
@@ -32,8 +32,7 @@ class TestData(object):
     @cache_readonly
     def intframe(self):
         # force these all to int64 to avoid platform testing issues
-        return pd.DataFrame(dict((c, s) for c, s in
-                                 compat.iteritems(_intframe)),
+        return pd.DataFrame({c: s for c, s in compat.iteritems(_intframe)},
                             dtype=np.int64)
 
     @cache_readonly
@@ -112,7 +111,7 @@ def _check_mixed_float(df, dtype=None):
     # float16 are most likely to be upcasted to float32
     dtypes = dict(A='float32', B='float32', C='float16', D='float64')
     if isinstance(dtype, compat.string_types):
-        dtypes = dict((k, dtype) for k, v in dtypes.items())
+        dtypes = {k: dtype for k, v in dtypes.items()}
     elif isinstance(dtype, dict):
         dtypes.update(dtype)
     if dtypes.get('A'):
@@ -128,7 +127,7 @@ def _check_mixed_float(df, dtype=None):
 def _check_mixed_int(df, dtype=None):
     dtypes = dict(A='int32', B='uint64', C='uint8', D='int64')
     if isinstance(dtype, compat.string_types):
-        dtypes = dict((k, dtype) for k, v in dtypes.items())
+        dtypes = {k: dtype for k, v in dtypes.items()}
     elif isinstance(dtype, dict):
         dtypes.update(dtype)
     if dtypes.get('A'):
diff --git a/pandas/tests/frame/test_api.py b/pandas/tests/frame/test_api.py
index c50aa858a..e81e31b71 100644
--- a/pandas/tests/frame/test_api.py
+++ b/pandas/tests/frame/test_api.py
@@ -234,7 +234,7 @@ class SharedWithSparse(object):
         if sys.version >= LooseVersion('2.7'):
             assert tup2._fields == ('Index', '_1', '_2')
 
-        df3 = DataFrame(dict(('f' + str(i), [i]) for i in range(1024)))
+        df3 = DataFrame({'f' + str(i): [i] for i in range(1024)})
         # will raise SyntaxError if trying to create namedtuple
         tup3 = next(df3.itertuples())
         assert not hasattr(tup3, '_fields')
diff --git a/pandas/tests/frame/test_constructors.py b/pandas/tests/frame/test_constructors.py
index 6ca90d715..2f947527c 100644
--- a/pandas/tests/frame/test_constructors.py
+++ b/pandas/tests/frame/test_constructors.py
@@ -120,7 +120,7 @@ class TestDataFrameConstructors(TestData):
                 assert(a.dtype == d)
             if ad is None:
                 ad = dict()
-            ad.update(dict((d, a) for d, a in zipper))
+            ad.update({d: a for d, a in zipper})
             return DataFrame(ad)
 
         def _check_mixed_dtypes(df, dtypes=None):
@@ -349,8 +349,8 @@ class TestDataFrameConstructors(TestData):
         data = {'col1': tm.TestSubDict((x, 10.0 * x) for x in range(10)),
                 'col2': tm.TestSubDict((x, 20.0 * x) for x in range(10))}
         df = DataFrame(data)
-        refdf = DataFrame(dict((col, dict(compat.iteritems(val)))
-                               for col, val in compat.iteritems(data)))
+        refdf = DataFrame({col: dict(compat.iteritems(val))
+                           for col, val in compat.iteritems(data)})
         tm.assert_frame_equal(refdf, df)
 
         data = tm.TestSubDict(compat.iteritems(data))
@@ -413,8 +413,7 @@ class TestDataFrameConstructors(TestData):
         data = {'a': (1, 2, 3), 'b': (4, 5, 6)}
 
         result = DataFrame(data)
-        expected = DataFrame(dict((k, list(v))
-                                  for k, v in compat.iteritems(data)))
+        expected = DataFrame({k: list(v) for k, v in compat.iteritems(data)})
         tm.assert_frame_equal(result, expected, check_dtype=False)
 
     def test_constructor_dict_multiindex(self):
@@ -447,8 +446,8 @@ class TestDataFrameConstructors(TestData):
         dates_as_str = ['1984-02-19', '1988-11-06', '1989-12-03', '1990-03-15']
 
         def create_data(constructor):
-            return dict((i, {constructor(s): 2 * i})
-                        for i, s in enumerate(dates_as_str))
+            return {i: {constructor(s): 2 * i}
+                    for i, s in enumerate(dates_as_str)}
 
         data_datetime64 = create_data(np.datetime64)
         data_datetime = create_data(lambda x: datetime.strptime(x, '%Y-%m-%d'))
@@ -472,8 +471,8 @@ class TestDataFrameConstructors(TestData):
         td_as_int = [1, 2, 3, 4]
 
         def create_data(constructor):
-            return dict((i, {constructor(s): 2 * i})
-                        for i, s in enumerate(td_as_int))
+            return {i: {constructor(s): 2 * i}
+                    for i, s in enumerate(td_as_int)}
 
         data_timedelta64 = create_data(lambda x: np.timedelta64(x, 'D'))
         data_timedelta = create_data(lambda x: timedelta(days=x))
@@ -696,8 +695,8 @@ class TestDataFrameConstructors(TestData):
             mrecs = mrecords.fromarrays(data, names=names)
 
             # fill the comb
-            comb = dict((k, v.filled()) if hasattr(
-                v, 'filled') else (k, v) for k, v in comb)
+            comb = {k: (v.filled() if hasattr(v, 'filled') else v)
+                    for k, v in comb}
 
             expected = DataFrame(comb, columns=names)
             result = DataFrame(mrecs)
@@ -1854,8 +1853,8 @@ class TestDataFrameConstructors(TestData):
         for dtype, b in compat.iteritems(blocks):
             columns.extend(b.columns)
 
-        asdict = dict((x, y) for x, y in compat.iteritems(df))
-        asdict2 = dict((x, y.values) for x, y in compat.iteritems(df))
+        asdict = {x: y for x, y in compat.iteritems(df)}
+        asdict2 = {x: y.values for x, y in compat.iteritems(df)}
 
         # dict of series & dict of ndarrays (have dtype info)
         results = []
diff --git a/pandas/tests/groupby/test_groupby.py b/pandas/tests/groupby/test_groupby.py
index 91a5569b3..81153e834 100644
--- a/pandas/tests/groupby/test_groupby.py
+++ b/pandas/tests/groupby/test_groupby.py
@@ -257,7 +257,7 @@ class TestGroupBy(MixIn):
         assert len(grouped) == len(df)
 
         grouped = df.groupby([lambda x: x.year, lambda x: x.month])
-        expected = len(set((x.year, x.month) for x in df.index))
+        expected = len({(x.year, x.month) for x in df.index})
         assert len(grouped) == expected
 
         # issue 11016
diff --git a/pandas/tests/groupby/test_whitelist.py b/pandas/tests/groupby/test_whitelist.py
index 977c639d7..de0deb442 100644
--- a/pandas/tests/groupby/test_whitelist.py
+++ b/pandas/tests/groupby/test_whitelist.py
@@ -238,7 +238,7 @@ def test_groupby_blacklist(df_letters):
 
 def test_tab_completion(mframe):
     grp = mframe.groupby(level='second')
-    results = set(v for v in dir(grp) if not v.startswith('_'))
+    results = {v for v in dir(grp) if not v.startswith('_')}
     expected = {
         'A', 'B', 'C', 'agg', 'aggregate', 'apply', 'boxplot', 'filter',
         'first', 'get_group', 'groups', 'hist', 'indices', 'last', 'max',
diff --git a/pandas/tests/indexes/test_multi.py b/pandas/tests/indexes/test_multi.py
index 506a9e1c6..2f8c27f1a 100644
--- a/pandas/tests/indexes/test_multi.py
+++ b/pandas/tests/indexes/test_multi.py
@@ -2178,7 +2178,7 @@ class TestMultiIndex(Base):
 
             if with_nulls:  # inject some null values
                 labels[500] = -1  # common nan value
-                labels = list(labels.copy() for i in range(nlevels))
+                labels = [labels.copy() for i in range(nlevels)]
                 for i in range(nlevels):
                     labels[i][500 + i - nlevels // 2] = -1
 
@@ -2773,7 +2773,7 @@ class TestMultiIndex(Base):
 
         # GH5620
         groups = self.index.groupby(self.index)
-        exp = dict((key, [key]) for key in self.index)
+        exp = {key: [key] for key in self.index}
         tm.assert_dict_equal(groups, exp)
 
     def test_index_name_retained(self):
diff --git a/pandas/tests/indexing/test_panel.py b/pandas/tests/indexing/test_panel.py
index 4d7768c9e..c4f7bd28e 100644
--- a/pandas/tests/indexing/test_panel.py
+++ b/pandas/tests/indexing/test_panel.py
@@ -119,7 +119,7 @@ class TestPanel(object):
             df = DataFrame(
                 np.random.randn(
                     len(ind), 5), index=ind, columns=list('ABCDE'))
-            panel = Panel(dict(('frame_' + c, df) for c in list('ABC')))
+            panel = Panel({'frame_' + c: df for c in list('ABC')})
 
             test2 = panel.loc[:, "2002":"2002-12-31"]
             test1 = panel.loc[:, "2002"]
diff --git a/pandas/tests/io/formats/test_format.py b/pandas/tests/io/formats/test_format.py
index 47632b139..6553dd66c 100644
--- a/pandas/tests/io/formats/test_format.py
+++ b/pandas/tests/io/formats/test_format.py
@@ -1505,11 +1505,11 @@ c  10  11  12  13  14\
         max_rows = get_option('display.max_rows')
 
         h, w = max_rows - 1, max_cols - 1
-        df = DataFrame(dict((k, np.arange(1, 1 + h)) for k in np.arange(w)))
+        df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})
         assert '...' not in df._repr_html_()
 
         h, w = max_rows + 1, max_cols + 1
-        df = DataFrame(dict((k, np.arange(1, 1 + h)) for k in np.arange(w)))
+        df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})
         assert '...' in df._repr_html_()
 
     def test_info_repr(self):
@@ -1517,14 +1517,14 @@ c  10  11  12  13  14\
         max_cols = get_option('display.max_columns')
         # Long
         h, w = max_rows + 1, max_cols - 1
-        df = DataFrame(dict((k, np.arange(1, 1 + h)) for k in np.arange(w)))
+        df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})
         assert has_vertically_truncated_repr(df)
         with option_context('display.large_repr', 'info'):
             assert has_info_repr(df)
 
         # Wide
         h, w = max_rows - 1, max_cols + 1
-        df = DataFrame(dict((k, np.arange(1, 1 + h)) for k in np.arange(w)))
+        df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})
         assert has_horizontally_truncated_repr(df)
         with option_context('display.large_repr', 'info'):
             assert has_info_repr(df)
@@ -1550,14 +1550,14 @@ c  10  11  12  13  14\
         max_cols = get_option('display.max_columns')
         # Long
         h, w = max_rows + 1, max_cols - 1
-        df = DataFrame(dict((k, np.arange(1, 1 + h)) for k in np.arange(w)))
+        df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})
         assert r'&lt;class' not in df._repr_html_()
         with option_context('display.large_repr', 'info'):
             assert r'&lt;class' in df._repr_html_()
 
         # Wide
         h, w = max_rows - 1, max_cols + 1
-        df = DataFrame(dict((k, np.arange(1, 1 + h)) for k in np.arange(w)))
+        df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})
         assert '<class' not in df._repr_html_()
         with option_context('display.large_repr', 'info'):
             assert '&lt;class' in df._repr_html_()
@@ -2058,7 +2058,7 @@ class TestSeriesFormatting(object):
         lines = res.split('\n')
         lines = [line for line in repr(s).split('\n')
                  if not re.match(r'[^\.]*\.+', line)][:-1]
-        ncolsizes = len(set(len(line.strip()) for line in lines))
+        ncolsizes = len({len(line.strip()) for line in lines})
         assert ncolsizes == 1
 
     def test_format_explicit(self):
diff --git a/pandas/tests/io/formats/test_to_latex.py b/pandas/tests/io/formats/test_to_latex.py
index 639c11a3d..35ef5a1cf 100644
--- a/pandas/tests/io/formats/test_to_latex.py
+++ b/pandas/tests/io/formats/test_to_latex.py
@@ -146,11 +146,11 @@ x & y &  a \\
         assert result == expected
 
         df = DataFrame.from_dict({
-            ('c1', 0): pd.Series(dict((x, x) for x in range(4))),
-            ('c1', 1): pd.Series(dict((x, x + 4) for x in range(4))),
-            ('c2', 0): pd.Series(dict((x, x) for x in range(4))),
-            ('c2', 1): pd.Series(dict((x, x + 4) for x in range(4))),
-            ('c3', 0): pd.Series(dict((x, x) for x in range(4))),
+            ('c1', 0): pd.Series({x: x for x in range(4)}),
+            ('c1', 1): pd.Series({x: x + 4 for x in range(4)}),
+            ('c2', 0): pd.Series({x: x for x in range(4)}),
+            ('c2', 1): pd.Series({x: x + 4 for x in range(4)}),
+            ('c3', 0): pd.Series({x: x for x in range(4)}),
         }).T
         result = df.to_latex()
         expected = r"""\begin{tabular}{llrrrr}
@@ -223,11 +223,11 @@ a &       &      &           &      &       &      &       &      \\
 
     def test_to_latex_multicolumnrow(self):
         df = pd.DataFrame({
-            ('c1', 0): dict((x, x) for x in range(5)),
-            ('c1', 1): dict((x, x + 5) for x in range(5)),
-            ('c2', 0): dict((x, x) for x in range(5)),
-            ('c2', 1): dict((x, x + 5) for x in range(5)),
-            ('c3', 0): dict((x, x) for x in range(5))
+            ('c1', 0): {x: x for x in range(5)},
+            ('c1', 1): {x: x + 5 for x in range(5)},
+            ('c2', 0): {x: x for x in range(5)},
+            ('c2', 1): {x: x + 5 for x in range(5)},
+            ('c3', 0): {x: x for x in range(5)}
         })
         result = df.to_latex()
         expected = r"""\begin{tabular}{lrrrrr}
diff --git a/pandas/tests/io/json/test_ujson.py b/pandas/tests/io/json/test_ujson.py
index 18b91bb3d..a1c0ec3bc 100644
--- a/pandas/tests/io/json/test_ujson.py
+++ b/pandas/tests/io/json/test_ujson.py
@@ -1643,4 +1643,4 @@ class TestPandasJSONTests(object):
 
 
 def _clean_dict(d):
-    return dict((str(k), v) for k, v in compat.iteritems(d))
+    return {str(k): v for k, v in compat.iteritems(d)}
diff --git a/pandas/tests/io/msgpack/test_case.py b/pandas/tests/io/msgpack/test_case.py
index 9bb34a70e..c0e76b37e 100644
--- a/pandas/tests/io/msgpack/test_case.py
+++ b/pandas/tests/io/msgpack/test_case.py
@@ -98,10 +98,10 @@ def test_match():
         (tuple(range(16)), (b"\xdc\x00\x10\x00\x01\x02\x03\x04\x05\x06\x07"
                             b"\x08\x09\x0a\x0b\x0c\x0d\x0e\x0f")),
         ({}, b'\x80'),
-        (dict((x, x) for x in range(15)),
+        ({x: x for x in range(15)},
          (b'\x8f\x00\x00\x01\x01\x02\x02\x03\x03\x04\x04\x05\x05\x06\x06\x07'
           b'\x07\x08\x08\t\t\n\n\x0b\x0b\x0c\x0c\r\r\x0e\x0e')),
-        (dict((x, x) for x in range(16)),
+        ({x: x for x in range(16)},
          (b'\xde\x00\x10\x00\x00\x01\x01\x02\x02\x03\x03\x04\x04\x05\x05\x06'
           b'\x06\x07\x07\x08\x08\t\t\n\n\x0b\x0b\x0c\x0c\r\r\x0e\x0e'
           b'\x0f\x0f')),
diff --git a/pandas/tests/io/msgpack/test_pack.py b/pandas/tests/io/msgpack/test_pack.py
index c0b3e1b24..3afd1fc08 100644
--- a/pandas/tests/io/msgpack/test_pack.py
+++ b/pandas/tests/io/msgpack/test_pack.py
@@ -132,7 +132,7 @@ class TestPack(object):
         bio.seek(0)
         unpacker = Unpacker(bio)
         for size in sizes:
-            assert unpacker.unpack() == dict((i, i * 2) for i in range(size))
+            assert unpacker.unpack() == {i: i * 2 for i in range(size)}
 
     def test_odict(self):
         seq = [(b'one', 1), (b'two', 2), (b'three', 3), (b'four', 4)]
diff --git a/pandas/tests/io/test_packers.py b/pandas/tests/io/test_packers.py
index bc58ea1c7..2d1671840 100644
--- a/pandas/tests/io/test_packers.py
+++ b/pandas/tests/io/test_packers.py
@@ -618,8 +618,8 @@ class TestCompression(TestPackers):
             'E': [datetime.timedelta(days=x) for x in range(1000)],
         }
         self.frame = {
-            'float': DataFrame(dict((k, data[k]) for k in ['A', 'A'])),
-            'int': DataFrame(dict((k, data[k]) for k in ['B', 'B'])),
+            'float': DataFrame({k: data[k] for k in ['A', 'A']}),
+            'int': DataFrame({k: data[k] for k in ['B', 'B']}),
             'mixed': DataFrame(data),
         }
 
@@ -805,8 +805,8 @@ class TestEncoding(TestPackers):
             'G': [400] * 1000
         }
         self.frame = {
-            'float': DataFrame(dict((k, data[k]) for k in ['A', 'A'])),
-            'int': DataFrame(dict((k, data[k]) for k in ['B', 'B'])),
+            'float': DataFrame({k: data[k] for k in ['A', 'A']}),
+            'int': DataFrame({k: data[k] for k in ['B', 'B']}),
             'mixed': DataFrame(data),
         }
         self.utf_encodings = ['utf8', 'utf16', 'utf32']
diff --git a/pandas/tests/io/test_pytables.py b/pandas/tests/io/test_pytables.py
index ca20d089e..5e5fc6e7e 100644
--- a/pandas/tests/io/test_pytables.py
+++ b/pandas/tests/io/test_pytables.py
@@ -1391,7 +1391,7 @@ class TestHDFStore(Base):
             with catch_warnings(record=True):
                 wp = tm.makePanel()
                 wp2 = wp.rename_axis(
-                    dict((x, "%s_extra" % x) for x in wp.minor_axis), axis=2)
+                    {x: "%s_extra" % x for x in wp.minor_axis}, axis=2)
 
                 def check_col(key, name, size):
                     assert getattr(store.get_storer(key)
diff --git a/pandas/tests/io/test_stata.py b/pandas/tests/io/test_stata.py
index 78b47960e..b3ead7d9c 100644
--- a/pandas/tests/io/test_stata.py
+++ b/pandas/tests/io/test_stata.py
@@ -590,7 +590,7 @@ class TestStata(object):
 
     def test_date_export_formats(self):
         columns = ['tc', 'td', 'tw', 'tm', 'tq', 'th', 'ty']
-        conversions = dict(((c, c) for c in columns))
+        conversions = {c: c for c in columns}
         data = [datetime(2006, 11, 20, 23, 13, 20)] * len(columns)
         original = DataFrame([data], columns=columns)
         original.index.name = 'index'
@@ -774,7 +774,7 @@ class TestStata(object):
         tm.assert_frame_equal(expected, parsed_117,
                               check_datetimelike_compat=True)
 
-        date_conversion = dict((c, c[-2:]) for c in columns)
+        date_conversion = {c: c[-2:] for c in columns}
         # {c : c[-2:] for c in columns}
         with tm.ensure_clean() as path:
             expected.index.name = 'index'
diff --git a/pandas/tests/plotting/test_series.py b/pandas/tests/plotting/test_series.py
index d04065ee3..fdfd87d1e 100644
--- a/pandas/tests/plotting/test_series.py
+++ b/pandas/tests/plotting/test_series.py
@@ -3,7 +3,7 @@
 """ Test cases for Series.plot """
 
 
-import itertools
+from itertools import chain
 import pytest
 
 from datetime import datetime
@@ -333,8 +333,7 @@ class TestSeriesPlots(TestPlotBase):
                                autopct='%.2f', fontsize=7)
         pcts = ['{0:.2f}'.format(s * 100)
                 for s in series.values / float(series.sum())]
-        iters = [iter(series.index), iter(pcts)]
-        expected_texts = list(next(it) for it in itertools.cycle(iters))
+        expected_texts = list(chain.from_iterable(zip(series.index, pcts)))
         self._check_text_labels(ax.texts, expected_texts)
         for t in ax.texts:
             assert t.get_fontsize() == 7
diff --git a/pandas/tests/reshape/test_join.py b/pandas/tests/reshape/test_join.py
index 75c01fabe..76791b08a 100644
--- a/pandas/tests/reshape/test_join.py
+++ b/pandas/tests/reshape/test_join.py
@@ -788,7 +788,7 @@ def _assert_same_contents(join_chunk, source):
     jvalues = join_chunk.fillna(NA_SENTINEL).drop_duplicates().values
     svalues = source.fillna(NA_SENTINEL).drop_duplicates().values
 
-    rows = set(tuple(row) for row in jvalues)
+    rows = {tuple(row) for row in jvalues}
     assert(len(rows) == len(source))
     assert(all(tuple(row) in rows for row in svalues))
 
diff --git a/pandas/tests/series/test_constructors.py b/pandas/tests/series/test_constructors.py
index 86e5cc54b..7ffda3a58 100644
--- a/pandas/tests/series/test_constructors.py
+++ b/pandas/tests/series/test_constructors.py
@@ -251,7 +251,7 @@ class TestSeriesConstructors(TestData):
 
     def test_series_ctor_plus_datetimeindex(self):
         rng = date_range('20090415', '20090519', freq='B')
-        data = dict((k, 1) for k in rng)
+        data = {k: 1 for k in rng}
 
         result = Series(data, index=rng)
         assert result.index is rng
diff --git a/pandas/tests/series/test_indexing.py b/pandas/tests/series/test_indexing.py
index d141b378f..c0ef5a369 100644
--- a/pandas/tests/series/test_indexing.py
+++ b/pandas/tests/series/test_indexing.py
@@ -1734,7 +1734,7 @@ class TestSeriesIndexing(TestData):
     def test_underlying_data_conversion(self):
 
         # GH 4080
-        df = DataFrame(dict((c, [1, 2, 3]) for c in ['a', 'b', 'c']))
+        df = DataFrame({c: [1, 2, 3] for c in ['a', 'b', 'c']})
         df.set_index(['a', 'b', 'c'], inplace=True)
         s = Series([1], index=[(2, 2, 2)])
         df['val'] = 0
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index 0e783d675..f51bf0c4e 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -1094,21 +1094,21 @@ class TestPanel(PanelTests, CheckIndexing, SafeForLongAndSparse,
             assert_panel_equal(Panel(d4), Panel(items=['A', 'B']))
 
             # cast
-            dcasted = dict((k, v.reindex(wp.major_axis).fillna(0))
-                           for k, v in compat.iteritems(d))
+            dcasted = {k: v.reindex(wp.major_axis).fillna(0)
+                       for k, v in compat.iteritems(d)}
             result = Panel(dcasted, dtype=int)
-            expected = Panel(dict((k, v.astype(int))
-                                  for k, v in compat.iteritems(dcasted)))
+            expected = Panel({k: v.astype(int)
+                              for k, v in compat.iteritems(dcasted)})
             assert_panel_equal(result, expected)
 
             result = Panel(dcasted, dtype=np.int32)
-            expected = Panel(dict((k, v.astype(np.int32))
-                                  for k, v in compat.iteritems(dcasted)))
+            expected = Panel({k: v.astype(np.int32)
+                              for k, v in compat.iteritems(dcasted)})
             assert_panel_equal(result, expected)
 
     def test_constructor_dict_mixed(self):
         with catch_warnings(record=True):
-            data = dict((k, v.values) for k, v in self.panel.iteritems())
+            data = {k: v.values for k, v in self.panel.iteritems()}
             result = Panel(data)
             exp_major = Index(np.arange(len(self.panel.major_axis)))
             tm.assert_index_equal(result.major_axis, exp_major)
@@ -1350,18 +1350,18 @@ class TestPanel(PanelTests, CheckIndexing, SafeForLongAndSparse,
 
             # make sure that we don't trigger any warnings
             result = self.panel.apply(f, axis=['items', 'major_axis'])
-            expected = Panel(dict((ax, f(self.panel.loc[:, :, ax]))
-                                  for ax in self.panel.minor_axis))
+            expected = Panel({ax: f(self.panel.loc[:, :, ax])
+                              for ax in self.panel.minor_axis})
             assert_panel_equal(result, expected)
 
             result = self.panel.apply(f, axis=['major_axis', 'minor_axis'])
-            expected = Panel(dict((ax, f(self.panel.loc[ax]))
-                                  for ax in self.panel.items))
+            expected = Panel({ax: f(self.panel.loc[ax])
+                              for ax in self.panel.items})
             assert_panel_equal(result, expected)
 
             result = self.panel.apply(f, axis=['minor_axis', 'items'])
-            expected = Panel(dict((ax, f(self.panel.loc[:, ax]))
-                                  for ax in self.panel.major_axis))
+            expected = Panel({ax: f(self.panel.loc[:, ax])
+                              for ax in self.panel.major_axis})
             assert_panel_equal(result, expected)
 
             # with multi-indexes
@@ -1994,8 +1994,8 @@ class TestPanel(PanelTests, CheckIndexing, SafeForLongAndSparse,
 
             # negative numbers, #2164
             result = self.panel.shift(-1)
-            expected = Panel(dict((i, f.shift(-1)[:-1])
-                                  for i, f in self.panel.iteritems()))
+            expected = Panel({i: f.shift(-1)[:-1]
+                              for i, f in self.panel.iteritems()})
             assert_panel_equal(result, expected)
 
             # mixed dtypes #6959
diff --git a/pandas/tests/test_panel4d.py b/pandas/tests/test_panel4d.py
index c0e8770df..c42bedebe 100644
--- a/pandas/tests/test_panel4d.py
+++ b/pandas/tests/test_panel4d.py
@@ -689,7 +689,7 @@ class TestPanel4d(CheckIndexing, SafeForSparse,
 
     def test_constructor_dict_mixed(self):
         with catch_warnings(record=True):
-            data = dict((k, v.values) for k, v in self.panel4d.iteritems())
+            data = {k: v.values for k, v in self.panel4d.iteritems()}
             result = Panel4D(data)
 
             exp_major = Index(np.arange(len(self.panel4d.major_axis)))
diff --git a/pandas/tseries/holiday.py b/pandas/tseries/holiday.py
index 957352d9f..0e6cbea21 100644
--- a/pandas/tseries/holiday.py
+++ b/pandas/tseries/holiday.py
@@ -430,7 +430,7 @@ class AbstractHolidayCalendar(object):
 
         if not isinstance(other, list):
             other = [other]
-        other_holidays = dict((holiday.name, holiday) for holiday in other)
+        other_holidays = {holiday.name: holiday for holiday in other}
 
         try:
             base = base.rules
@@ -439,7 +439,7 @@ class AbstractHolidayCalendar(object):
 
         if not isinstance(base, list):
             base = [base]
-        base_holidays = dict((holiday.name, holiday) for holiday in base)
+        base_holidays = {holiday.name: holiday for holiday in base}
 
         other_holidays.update(base_holidays)
         return list(other_holidays.values())
diff --git a/pandas/tseries/offsets.py b/pandas/tseries/offsets.py
index eef9d165e..904967295 100644
--- a/pandas/tseries/offsets.py
+++ b/pandas/tseries/offsets.py
@@ -237,9 +237,9 @@ class DateOffset(BaseOffset):
                 i = (i.to_period('W') + weeks).to_timestamp() + \
                     i.to_perioddelta('W')
 
-            timedelta_kwds = dict((k, v) for k, v in self.kwds.items()
-                                  if k in ['days', 'hours', 'minutes',
-                                           'seconds', 'microseconds'])
+            timedelta_kwds = {k: v for k, v in self.kwds.items()
+                              if k in ['days', 'hours', 'minutes',
+                                       'seconds', 'microseconds']}
             if timedelta_kwds:
                 delta = Timedelta(**timedelta_kwds)
                 i = i + (self.n * delta)
@@ -1639,7 +1639,7 @@ class BQuarterEnd(QuarterOffset):
 
 
 _int_to_month = tslib._MONTH_ALIASES
-_month_to_int = dict((v, k) for k, v in _int_to_month.items())
+_month_to_int = {v: k for k, v in _int_to_month.items()}
 
 
 # TODO: This is basically the same as BQuarterEnd
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index 1c4c63acb..0da59ba5f 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -1741,7 +1741,7 @@ def makeObjectSeries(name=None):
 
 def getSeriesData():
     index = makeStringIndex(N)
-    return dict((c, Series(randn(N), index=index)) for c in getCols(K))
+    return {c: Series(randn(N), index=index) for c in getCols(K)}
 
 
 def makeTimeSeries(nper=None, freq='B', name=None):
@@ -1757,11 +1757,11 @@ def makePeriodSeries(nper=None, name=None):
 
 
 def getTimeSeriesData(nper=None, freq='B'):
-    return dict((c, makeTimeSeries(nper, freq)) for c in getCols(K))
+    return {c: makeTimeSeries(nper, freq) for c in getCols(K)}
 
 
 def getPeriodData(nper=None):
-    return dict((c, makePeriodSeries(nper)) for c in getCols(K))
+    return {c: makePeriodSeries(nper) for c in getCols(K)}
 
 
 # make frame
@@ -1800,14 +1800,14 @@ def makePeriodFrame(nper=None):
 def makePanel(nper=None):
     with warnings.catch_warnings(record=True):
         cols = ['Item' + c for c in string.ascii_uppercase[:K - 1]]
-        data = dict((c, makeTimeDataFrame(nper)) for c in cols)
+        data = {c: makeTimeDataFrame(nper) for c in cols}
         return Panel.fromDict(data)
 
 
 def makePeriodPanel(nper=None):
     with warnings.catch_warnings(record=True):
         cols = ['Item' + c for c in string.ascii_uppercase[:K - 1]]
-        data = dict((c, makePeriodFrame(nper)) for c in cols)
+        data = {c: makePeriodFrame(nper) for c in cols}
         return Panel.fromDict(data)
 
 
diff --git a/versioneer.py b/versioneer.py
index 59228ec63..b0ae4fa2d 100644
--- a/versioneer.py
+++ b/versioneer.py
@@ -606,11 +606,11 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         if verbose:
             print("keywords are unexpanded, not using")
         raise NotThisMethod("unexpanded keywords, not a git-archive tarball")
-    refs = set(r.strip() for r in refnames.strip("()").split(","))
+    refs = {r.strip() for r in refnames.strip("()").split(",")}
     # starting in git-1.8.3, tags are listed as "tag: foo-1.0" instead of
     # just "foo-1.0". If we see a "tag: " prefix, prefer those.
     TAG = "tag: "
-    tags = set(r[len(TAG):] for r in refs if r.startswith(TAG))
+    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}
     if not tags:
         # Either we're using git < 1.8.3, or there really are no tags. We use
         # a heuristic: assume all version tags have a digit. The old git %%d
@@ -619,7 +619,7 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         # between branches and tags. By ignoring refnames without digits, we
         # filter out many common branch names like "release" and
         # "stabilization", as well as "HEAD" and "master".
-        tags = set(r for r in refs if re.search(r'\d', r))
+        tags = {r for r in refs if re.search(r'\d', r)}
         if verbose:
             print("discarding '%%s', no digits" %% ",".join(refs-tags))
     if verbose:
@@ -960,11 +960,11 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         if verbose:
             print("keywords are unexpanded, not using")
         raise NotThisMethod("unexpanded keywords, not a git-archive tarball")
-    refs = set(r.strip() for r in refnames.strip("()").split(","))
+    refs = {r.strip() for r in refnames.strip("()").split(",")}
     # starting in git-1.8.3, tags are listed as "tag: foo-1.0" instead of
     # just "foo-1.0". If we see a "tag: " prefix, prefer those.
     TAG = "tag: "
-    tags = set(r[len(TAG):] for r in refs if r.startswith(TAG))
+    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}
     if not tags:
         # Either we're using git < 1.8.3, or there really are no tags. We use
         # a heuristic: assume all version tags have a digit. The old git %d
@@ -973,7 +973,7 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         # between branches and tags. By ignoring refnames without digits, we
         # filter out many common branch names like "release" and
         # "stabilization", as well as "HEAD" and "master".
-        tags = set(r for r in refs if re.search(r'\d', r))
+        tags = {r for r in refs if re.search(r'\d', r)}
         if verbose:
             print("discarding '%s', no digits" % ",".join(refs-tags))
     if verbose:
