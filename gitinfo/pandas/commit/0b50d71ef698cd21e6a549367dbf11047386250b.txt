commit 0b50d71ef698cd21e6a549367dbf11047386250b
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Fri Jan 6 14:31:06 2012 -0500

    BUG: test concatenation of panels on other axes and fix bug

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index bccb58299..d3700ebde 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -3116,7 +3116,7 @@ class DataFrame(NDFrame):
         return self._reduce(nanops.nanmedian, axis=axis, skipna=skipna,
                             numeric_only=None)
 
-    @Substitution(name='median absolute deviation', shortname='mad', 
+    @Substitution(name='median absolute deviation', shortname='mad',
                   na_action=_doc_exclude_na, extras='')
     @Appender(_stat_doc)
     def mad(self, axis=0, skipna=True, level=None):
@@ -3660,7 +3660,7 @@ def extract_index(data):
             index = _union_indexes(indexes)
 
         if have_raw_arrays:
-            lengths = list(set(len(x) for x in data.values()))
+            lengths = list(set(raw_lengths))
             if len(lengths) > 1:
                 raise ValueError('arrays must all be same length')
 
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index a11a4ddde..cdfed87f7 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -516,7 +516,6 @@ class Grouping(object):
       * indices : dict of {group -> index_list}
       * labels : ndarray, group labels
       * ids : mapping of label -> group
-      * reverse_ids : mapping of group -> label
       * counts : array of group counts
       * group_index : unique groups
       * groups : dict of {group -> label_list}
@@ -592,10 +591,6 @@ class Grouping(object):
                 self._make_labels()
         return self._ids
 
-    @cache_readonly
-    def reverse_ids(self):
-        return dict((v, k) for k, v in self.ids.iteritems())
-
     @property
     def counts(self):
         if self._counts is None:
diff --git a/pandas/core/index.py b/pandas/core/index.py
index abf91261a..5a8f7f2c1 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -1875,6 +1875,8 @@ def _validate_join_method(method):
 
 def _get_combined_index(indexes, intersect=False):
     indexes = _get_distinct_indexes(indexes)
+    if len(indexes) == 0:
+        return NULL_INDEX
     if len(indexes) == 1:
         return indexes[0]
     if intersect:
@@ -1890,9 +1892,7 @@ def _get_distinct_indexes(indexes):
 
 
 def _union_indexes(indexes):
-    if len(indexes) == 0:
-        return Index([])
-
+    assert(len(indexes) > 0)
     if len(indexes) == 1:
         result = indexes[0]
         if isinstance(result, list):
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index b091b8e5d..f39ad4d25 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -10,7 +10,7 @@ import numpy as np
 from pandas.core.common import (PandasError, _mut_exclusive,
                                 _try_sort, _default_index, _infer_dtype)
 from pandas.core.index import (Factor, Index, MultiIndex, _ensure_index,
-                               _get_combined_index, _union_indexes)
+                               _get_combined_index, NULL_INDEX)
 from pandas.core.indexing import _NDFrameIndexer
 from pandas.core.internals import BlockManager, make_block, form_blocks
 from pandas.core.frame import DataFrame
@@ -246,36 +246,34 @@ class Panel(NDFrame):
             items = Index(_try_sort(data.keys()))
 
         for k, v in data.iteritems():
-            if not isinstance(v, DataFrame):
+            if isinstance(v, dict):
                 data[k] = DataFrame(v)
 
         if major is None:
-            indexes = [v.index for v in data.values()]
-            major = _union_indexes(indexes)
+            major = _extract_axis(data, axis=0)
 
         if minor is None:
-            indexes = [v.columns for v in data.values()]
-            minor = _union_indexes(indexes)
+            minor = _extract_axis(data, axis=1)
 
         axes = [items, major, minor]
-
         reshaped_data = data.copy() # shallow
-        # homogenize
 
         item_shape = (1, len(major), len(minor))
-        for k in items:
-            if k not in data:
+        for item in items:
+            v = values = data.get(item)
+            if v is None:
                 values = np.empty(item_shape, dtype=dtype)
                 values.fill(np.nan)
-                reshaped_data[k] = values
-            else:
-                v = data[k]
+            elif isinstance(v, DataFrame):
                 v = v.reindex(index=major, columns=minor, copy=False)
                 if dtype is not None:
                     v = v.astype(dtype)
                 values = v.values
-                shape = values.shape
-                reshaped_data[k] = values.reshape((1,) + shape)
+
+            if values.ndim == 2:
+                values = values[None, :, :]
+
+            reshaped_data[item] = values
 
         # segregates dtypes and forms blocks matching to columns
         blocks = form_blocks(reshaped_data, axes)
@@ -1180,11 +1178,8 @@ def _homogenize_dict(frames, intersect=True, dtype=None):
         else:
             adj_frames[k] = v
 
-    all_indexes = [df.index for df in adj_frames.values()]
-    all_columns = [df.columns for df in adj_frames.values()]
-
-    index = _get_combined_index(all_indexes, intersect=intersect)
-    columns = _get_combined_index(all_columns, intersect=intersect)
+    index = _extract_axis(adj_frames, axis=0, intersect=intersect)
+    columns = _extract_axis(adj_frames, axis=1, intersect=intersect)
 
     for key, frame in adj_frames.iteritems():
         result[key] = frame.reindex(index=index, columns=columns,
@@ -1192,6 +1187,46 @@ def _homogenize_dict(frames, intersect=True, dtype=None):
 
     return result, index, columns
 
+
+def _extract_axis(data, axis=0, intersect=False):
+    from pandas.core.index import _union_indexes
+
+    if len(data) == 0:
+        index = NULL_INDEX
+    elif len(data) > 0:
+        raw_lengths = []
+        indexes = []
+
+        have_raw_arrays = False
+        have_frames = False
+
+        for v in data.values():
+            if isinstance(v, DataFrame):
+                have_frames = True
+                indexes.append(v._get_axis(axis))
+            else:
+                have_raw_arrays = True
+                raw_lengths.append(v.shape[axis])
+
+        if have_frames:
+            index = _get_combined_index(indexes, intersect=intersect)
+
+        if have_raw_arrays:
+            lengths = list(set(raw_lengths))
+            if len(lengths) > 1:
+                raise ValueError('ndarrays must match shape on axis %d' % axis)
+
+            if have_frames:
+                assert(lengths[0] == len(index))
+            else:
+                index = Index(np.arange(lengths[0]))
+
+    if len(index) == 0:
+        index = NULL_INDEX
+
+    return _ensure_index(index)
+
+
 def _monotonic(arr):
     return not (arr[1:] < arr[:-1]).any()
 
diff --git a/pandas/sparse/frame.py b/pandas/sparse/frame.py
index 8b9959482..4a8dd527e 100644
--- a/pandas/sparse/frame.py
+++ b/pandas/sparse/frame.py
@@ -28,6 +28,11 @@ class _SparseMockBlockManager(object):
     def get(self, item):
         return self.sp_frame[item].values
 
+    @property
+    def shape(self):
+        x, y = self.sp_frame.shape
+        return y, x
+
     @property
     def axes(self):
         return [self.sp_frame.columns, self.sp_frame.index]
diff --git a/pandas/src/skiplist.h b/pandas/src/skiplist.h
index 9f26d8416..0188d5921 100644
--- a/pandas/src/skiplist.h
+++ b/pandas/src/skiplist.h
@@ -7,11 +7,14 @@
   Python recipe (http://rhettinger.wordpress.com/2010/02/06/lost-knowledge/)
  */
 
+// #include <numpy/arrayobject.h>
+// #include <numpy/npy_math.h>
+
+
 #include <stdio.h>
 #include <stdlib.h>
-#include <numpy/arrayobject.h>
-#include <numpy/npy_math.h>
-
+#include <string.h>
+#include <math.h>
 
 #ifndef PANDAS_INLINE
   #if defined(__GNUC__)
@@ -25,6 +28,14 @@
   #endif
 #endif
 
+PANDAS_INLINE static float __npy_nanf(void)
+{
+    const union { int __i; float __f;} __bint = {0x7fc00000UL};
+    return __bint.__f;
+}
+#define PANDAS_NAN ((double) __npy_nanf())
+
+
 static PANDAS_INLINE double Log2(double val) {
   return log(val) / log(2.);
 }
@@ -110,7 +121,7 @@ static PANDAS_INLINE skiplist_t *skiplist_init(int expected_size) {
   result->tmp_steps = (int*) malloc(maxlevels * sizeof(int));
   result->maxlevels = maxlevels;
 
-  head = result->head = node_init(NPY_NAN, maxlevels);
+  head = result->head = node_init(PANDAS_NAN, maxlevels);
   node_incref(head);
 
   NIL = node_init(0, 0);
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index ff13ae8ba..ebac84e35 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -1030,6 +1030,10 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assert_(frame.columns is idx)
         self.assertEqual(len(frame._series), 3)
 
+        # with dict of empty list and Series
+        frame = DataFrame({'A' : [], 'B' : []}, columns=['A', 'B'])
+        self.assert_(frame.index is NULL_INDEX)
+
     def test_constructor_dict_block(self):
         expected = [[4., 3., 2., 1.]]
         df = DataFrame({'d' : [4.],'c' : [3.],'b' : [2.],'a' : [1.]},
diff --git a/pandas/tests/test_index.py b/pandas/tests/test_index.py
index 66e8255ad..82b223369 100644
--- a/pandas/tests/test_index.py
+++ b/pandas/tests/test_index.py
@@ -1271,6 +1271,12 @@ class TestFactor(unittest.TestCase):
             self.assertEqual(f(arr[labels == i]), agged[i])
 
 
+def test_get_combined_index():
+    from pandas.core.index import _get_combined_index, NULL_INDEX
+
+    result = _get_combined_index([])
+    assert(result is NULL_INDEX)
+
 if __name__ == '__main__':
     import nose
     nose.runmodule(argv=[__file__,'-vvs','-x','--pdb', '--pdb-failure'],
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index 9a248525f..df558511c 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -676,6 +676,28 @@ class TestPanel(unittest.TestCase, PanelTests, CheckIndexing,
         result = Panel(d, dtype=int)
         expected = Panel(dict((k, v.astype(int)) for k, v in d.iteritems()))
 
+    def test_constructor_dict_mixed(self):
+        data = dict((k, v.values) for k, v in self.panel.iteritems())
+        result = Panel(data)
+        exp_major = Index(np.arange(len(self.panel.major_axis)))
+        self.assert_(result.major_axis.equals(exp_major))
+
+        result = Panel(data, items=self.panel.items,
+                       major_axis=self.panel.major_axis,
+                       minor_axis=self.panel.minor_axis)
+        assert_panel_equal(result, self.panel)
+
+        data['ItemC'] = self.panel['ItemC']
+        result = Panel(data)
+        assert_panel_equal(result, self.panel)
+
+        # corner, blow up
+        data['ItemB'] = data['ItemB'][:-1]
+        self.assertRaises(Exception, Panel, data)
+
+        data['ItemB'] = self.panel['ItemB'].values[:, :-1]
+        self.assertRaises(Exception, Panel, data)
+
     def test_constructor_resize(self):
         data = self.panel._data
         items = self.panel.items[:-1]
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index 58b70c47d..c429e618b 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -195,7 +195,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         result = Series(data)
         expected = Series([nan, nan, nan])
         assert_series_equal(result, expected)
-        
+
         data[0] = 0.0
         data[2] = 2.0
         index = ['a', 'b', 'c']
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 4828ce681..cb71f6950 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -743,15 +743,18 @@ class Concatenator(object):
             empty_dtype = np.float64
 
         to_concat = []
-        for df, col_values in zip(self.objs, all_values):
-            if col_values is None:
-                missing_arr = np.empty(len(df), dtype=empty_dtype)
+        for obj, item_values in zip(self.objs, all_values):
+            if item_values is None:
+                shape = obj._data.shape[1:]
+                missing_arr = np.empty(shape, dtype=empty_dtype)
                 missing_arr.fill(np.nan)
                 to_concat.append(missing_arr)
             else:
-                to_concat.append(col_values)
+                to_concat.append(item_values)
 
-        return np.concatenate(to_concat)
+        # this method only gets called with axis >= 1
+        assert(self.axis >= 1)
+        return np.concatenate(to_concat, axis=self.axis - 1)
 
     def _get_new_axes(self):
         ndim = self.objs[0].ndim
diff --git a/pandas/tools/tests/test_merge.py b/pandas/tools/tests/test_merge.py
index 76e9aa3f8..0936576a7 100644
--- a/pandas/tools/tests/test_merge.py
+++ b/pandas/tools/tests/test_merge.py
@@ -848,6 +848,39 @@ class TestConcatenate(unittest.TestCase):
         expected = Panel.from_dict(data_dict, intersect=False)
         tm.assert_panel_equal(joined, expected)
 
+        # edge cases
+        self.assertRaises(ValueError, panels[0].join, panels[1:],
+                          how='outer', lsuffix='foo', rsuffix='bar')
+        self.assertRaises(ValueError, panels[0].join, panels[1:],
+                          how='right')
+
+    def test_panel_concat_other_axes(self):
+        panel = tm.makePanel()
+
+        p1 = panel.ix[:, :5, :]
+        p2 = panel.ix[:, 5:, :]
+
+        result = concat([p1, p2], axis=1)
+        tm.assert_panel_equal(result, panel)
+
+        p1 = panel.ix[:, :, :2]
+        p2 = panel.ix[:, :, 2:]
+
+        result = concat([p1, p2], axis=2)
+        tm.assert_panel_equal(result, panel)
+
+        # if things are a bit misbehaved
+        p1 = panel.ix[:2, :, :2]
+        p2 = panel.ix[:, :, 2:]
+        p1['ItemC'] = 'baz'
+
+        result = concat([p1, p2], axis=2)
+
+        expected = panel.copy()
+        expected['ItemC'] = expected['ItemC'].astype('O')
+        expected.ix['ItemC', :, :2] = 'baz'
+        tm.assert_panel_equal(result, expected)
+
 if __name__ == '__main__':
     import nose
     nose.runmodule(argv=[__file__,'-vvs','-x','--pdb', '--pdb-failure'],
diff --git a/scripts/roll_median_leak.py b/scripts/roll_median_leak.py
index 7cdec4865..27415f7aa 100644
--- a/scripts/roll_median_leak.py
+++ b/scripts/roll_median_leak.py
@@ -17,6 +17,6 @@ proc = psutil.Process(pid)
 
 s = Series(np.random.randn(10000))
 
-for _ in xrange(1000):
+for _ in xrange(5):
     # print proc.get_memory_info()
     result = rolling_median(s, 1000)
