commit 740b10fe1d5de2bf027a65c668cbb692d7237867
Author: jreback <jeff@reback.net>
Date:   Thu Jun 13 11:30:05 2013 -0400

    PERF: changed default to numpy=False to have correct parsing using unordered JSON
    
          eliminated fallback parsing with numpy=True; This will raise ValueError
          if it fails to parse (a known case are strings in the frame data)

diff --git a/doc/source/io.rst b/doc/source/io.rst
index aec963ca8..c182d4563 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -954,13 +954,21 @@ with optional parameters:
 
 - path_or_buf : the pathname or buffer to write the output
   This can be ``None`` in which case a JSON string is returned
-- orient : The format of the JSON string, default is ``index`` for ``Series``, ``columns`` for ``DataFrame``
+- orient :
 
-  * split   : dict like {index -> [index], columns -> [columns], data -> [values]}
-  * records : list like [{column -> value}, ... , {column -> value}]
-  * index   : dict like {index -> {column -> value}}
-  * columns : dict like {column -> {index -> value}}
-  * values  : just the values array
+  Series :
+    default is 'index', allowed values are: {'split','records','index'}
+
+  DataFrame :
+    default is 'columns', allowed values are: {'split','records','index','columns','values'}
+
+  The format of the JSON string
+
+    * split : dict like {index -> [index], columns -> [columns], data -> [values]}
+    * records : list like [{column -> value}, ... , {column -> value}]
+    * index : dict like {index -> {column -> value}}
+    * columns : dict like {column -> {index -> value}}
+    * values : just the values array
 
 - date_format : type of date conversion (epoch = epoch milliseconds, iso = ISO8601), default is epoch
 - double_precision : The number of decimal places to use when encoding floating point values, default 10.
@@ -1007,17 +1015,28 @@ is ``None``. To explicity force ``Series`` parsing, pass ``typ=series``
   is expected. For instance, a local file could be
   file ://localhost/path/to/table.json
 - typ    : type of object to recover (series or frame), default 'frame'
-- orient : The format of the JSON string, one of the following
+- orient :
+
+  Series :
+    default is 'index', allowed values are: {'split','records','index'}
+
+  DataFrame :
+    default is 'columns', allowed values are: {'split','records','index','columns','values'}
+
+  The format of the JSON string
 
-  * split : dict like {index -> [index], name -> name, data -> [values]}
-  * records : list like [value, ... , value]
-  * index : dict like {index -> value}
+    * split : dict like {index -> [index], columns -> [columns], data -> [values]}
+    * records : list like [{column -> value}, ... , {column -> value}]
+    * index : dict like {index -> {column -> value}}
+    * columns : dict like {column -> {index -> value}}
+    * values : just the values array
 
 - dtype : if True, infer dtypes, if a dict of column to dtype, then use those, if False, then don't infer dtypes at all, default is True, apply only to the data
 - convert_axes : boolean, try to convert the axes to the proper dtypes, default is True
 - convert_dates : a list of columns to parse for dates; If True, then try to parse datelike columns, default is True
 - keep_default_dates : boolean, default True. If parsing dates, then parse the default datelike columns
-- numpy: direct decoding to numpy arrays. default True but falls back to standard decoding if a problem occurs.
+- numpy: direct decoding to numpy arrays. default is False;
+  Note that the JSON ordering **MUST** be the same for each term if ``numpy=True``
 
 The parser will raise one of ``ValueError/TypeError/AssertionError`` if the JSON is
 not parsable.
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 0d2612d7a..55347aef0 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -507,8 +507,15 @@ class PandasObject(object):
         ----------
         path_or_buf : the path or buffer to write the result string
             if this is None, return a StringIO of the converted string
-        orient : {'split', 'records', 'index', 'columns', 'values'},
-            default is 'index' for Series, 'columns' for DataFrame
+        orient :
+
+            Series :
+              default is 'index'
+              allowed values are: {'split','records','index'}
+
+            DataFrame :
+              default is 'columns'
+              allowed values are: {'split','records','index','columns','values'}
 
             The format of the JSON string
             split : dict like
@@ -517,6 +524,7 @@ class PandasObject(object):
             index : dict like {index -> {column -> value}}
             columns : dict like {column -> {index -> value}}
             values : just the values array
+
         date_format : type of date conversion (epoch = epoch milliseconds, iso = ISO8601),
             default is epoch
         double_precision : The number of decimal places to use when encoding
diff --git a/pandas/io/json.py b/pandas/io/json.py
index 537d06f09..fcecb31bb 100644
--- a/pandas/io/json.py
+++ b/pandas/io/json.py
@@ -119,7 +119,7 @@ class FrameWriter(Writer):
                     self.obj[c] = self._format_to_date(self.obj[c])
 
 def read_json(path_or_buf=None, orient=None, typ='frame', dtype=True,
-              convert_axes=True, convert_dates=True, keep_default_dates=True, numpy=True):
+              convert_axes=True, convert_dates=True, keep_default_dates=True, numpy=False):
     """
     Convert JSON string to pandas object
 
@@ -129,12 +129,22 @@ def read_json(path_or_buf=None, orient=None, typ='frame', dtype=True,
         a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host
         is expected. For instance, a local file could be
         file ://localhost/path/to/table.json
-    orient : {'split', 'records', 'index'}, default 'index'
+    orient :
+        Series :
+          default is 'index'
+          allowed values are: {'split','records','index'}
+
+        DataFrame :
+          default is 'columns'
+          allowed values are: {'split','records','index','columns','values'}
+
         The format of the JSON string
-        split : dict like
-            {index -> [index], name -> name, data -> [values]}
-        records : list like [value, ... , value]
-        index : dict like {index -> value}
+          split : dict like {index -> [index], columns -> [columns], data -> [values]}
+          records : list like [{column -> value}, ... , {column -> value}]
+          index : dict like {index -> {column -> value}}
+          columns : dict like {column -> {index -> value}}
+          values : just the values array
+
     typ : type of object to recover (series or frame), default 'frame'
     dtype : if True, infer dtypes, if a dict of column to dtype, then use those,
         if False, then don't infer dtypes at all, default is True,
@@ -144,8 +154,8 @@ def read_json(path_or_buf=None, orient=None, typ='frame', dtype=True,
         default is True
     keep_default_dates : boolean, default True. If parsing dates,
         then parse the default datelike columns
-    numpy: direct decoding to numpy arrays. default True but falls back
-        to standard decoding if a problem occurs.
+    numpy: direct decoding to numpy arrays. default is False.Note that the JSON ordering MUST be the same
+        for each term if numpy=True.
 
     Returns
     -------
@@ -177,7 +187,7 @@ def read_json(path_or_buf=None, orient=None, typ='frame', dtype=True,
 
 class Parser(object):
     
-    def __init__(self, json, orient, dtype=True, convert_axes=True, convert_dates=True, keep_default_dates=False, numpy=True):
+    def __init__(self, json, orient, dtype=True, convert_axes=True, convert_dates=True, keep_default_dates=False, numpy=False):
         self.json = json
 
         if orient is None:
@@ -196,7 +206,15 @@ class Parser(object):
         self.obj = None
 
     def parse(self):
-        self._parse()
+
+        # try numpy 
+        numpy = self.numpy
+        if numpy:
+            self._parse_numpy()
+
+        else:
+            self._parse_no_numpy()
+
         if self.obj is None: return None
         if self.convert_axes:
             self._convert_axes()
@@ -304,33 +322,30 @@ class Parser(object):
 class SeriesParser(Parser):
     _default_orient = 'index'
 
-    def _parse(self):
+    def _parse_no_numpy(self):
+    
+        json = self.json
+        orient = self.orient
+        if orient == "split":
+            decoded = dict((str(k), v)
+                           for k, v in loads(json).iteritems())
+            self.obj = Series(dtype=None, **decoded)
+        else:
+            self.obj = Series(loads(json), dtype=None)
+
+    def _parse_numpy(self):
 
         json = self.json
         orient = self.orient
-        numpy = self.numpy
-    
-        if numpy:
-            try:
-                if orient == "split":
-                    decoded = loads(json, dtype=None, numpy=True)
-                    decoded = dict((str(k), v) for k, v in decoded.iteritems())
-                    self.obj = Series(**decoded)
-                elif orient == "columns" or orient == "index":
-                    self.obj = Series(*loads(json, dtype=None, numpy=True,
-                                             labelled=True))
-                else:
-                    self.obj = Series(loads(json, dtype=None, numpy=True))
-            except (ValueError,TypeError):
-                numpy = False
-
-        if not numpy:
-            if orient == "split":
-                decoded = dict((str(k), v)
-                               for k, v in loads(json).iteritems())
-                self.obj = Series(dtype=None, **decoded)
-            else:
-                self.obj = Series(loads(json), dtype=None)
+        if orient == "split":
+            decoded = loads(json, dtype=None, numpy=True)
+            decoded = dict((str(k), v) for k, v in decoded.iteritems())
+            self.obj = Series(**decoded)
+        elif orient == "columns" or orient == "index":
+            self.obj = Series(*loads(json, dtype=None, numpy=True,
+                                     labelled=True))
+        else:
+            self.obj = Series(loads(json, dtype=None, numpy=True))
 
     def _try_convert_types(self):
         if self.obj is None: return
@@ -341,42 +356,40 @@ class SeriesParser(Parser):
 class FrameParser(Parser):
     _default_orient = 'columns'
 
-    def _parse(self):
+    def _parse_numpy(self):
 
         json = self.json
         orient = self.orient
-        numpy = self.numpy
 
-        if numpy:
-            try:
-                if orient == "columns":
-                    args = loads(json, dtype=None, numpy=True, labelled=True)
-                    if args:
-                        args = (args[0].T, args[2], args[1])
-                    self.obj = DataFrame(*args)
-                elif orient == "split":
-                    decoded = loads(json, dtype=None, numpy=True)
-                    decoded = dict((str(k), v) for k, v in decoded.iteritems())
-                    self.obj = DataFrame(**decoded)
-                elif orient == "values":
-                    self.obj = DataFrame(loads(json, dtype=None, numpy=True))
-                else:
-                    self.obj = DataFrame(*loads(json, dtype=None, numpy=True,
-                                         labelled=True))
-            except (ValueError,TypeError):
-                numpy = False
-
-        if not numpy:
-            if orient == "columns":
-                self.obj = DataFrame(loads(json), dtype=None)
-            elif orient == "split":
-                decoded = dict((str(k), v)
-                               for k, v in loads(json).iteritems())
-                self.obj = DataFrame(dtype=None, **decoded)
-            elif orient == "index":
-                self.obj = DataFrame(loads(json), dtype=None).T
-            else:
-                self.obj = DataFrame(loads(json), dtype=None)
+        if orient == "columns":
+            args = loads(json, dtype=None, numpy=True, labelled=True)
+            if args:
+                args = (args[0].T, args[2], args[1])
+            self.obj = DataFrame(*args)
+        elif orient == "split":
+            decoded = loads(json, dtype=None, numpy=True)
+            decoded = dict((str(k), v) for k, v in decoded.iteritems())
+            self.obj = DataFrame(**decoded)
+        elif orient == "values":
+            self.obj = DataFrame(loads(json, dtype=None, numpy=True))
+        else:
+            self.obj = DataFrame(*loads(json, dtype=None, numpy=True, labelled=True))
+
+    def _parse_no_numpy(self):
+
+        json = self.json
+        orient = self.orient
+
+        if orient == "columns":
+            self.obj = DataFrame(loads(json), dtype=None)
+        elif orient == "split":
+            decoded = dict((str(k), v)
+                           for k, v in loads(json).iteritems())
+            self.obj = DataFrame(dtype=None, **decoded)
+        elif orient == "index":
+            self.obj = DataFrame(loads(json), dtype=None).T
+        else:
+            self.obj = DataFrame(loads(json), dtype=None)
 
     def _try_convert_types(self):
         if self.obj is None: return
diff --git a/pandas/io/tests/test_json/test_pandas.py b/pandas/io/tests/test_json/test_pandas.py
index 23ac4c4df..bdd700bdb 100644
--- a/pandas/io/tests/test_json/test_pandas.py
+++ b/pandas/io/tests/test_json/test_pandas.py
@@ -56,11 +56,19 @@ class TestPandasObjects(unittest.TestCase):
 
     def test_frame_from_json_to_json(self):
 
-        def _check_orient(df, orient, dtype=None, numpy=True, convert_axes=True, check_dtype=True):
+        def _check_orient(df, orient, dtype=None, numpy=False, convert_axes=True, check_dtype=True, raise_ok=None):
             df = df.sort()
             dfjson = df.to_json(orient=orient)
-            unser = read_json(dfjson, orient=orient, dtype=dtype,
-                              numpy=numpy, convert_axes=convert_axes)
+
+            try:
+                unser = read_json(dfjson, orient=orient, dtype=dtype,
+                                  numpy=numpy, convert_axes=convert_axes)
+            except (Exception), detail:
+                if raise_ok is not None:
+                    if type(detail) == raise_ok:
+                        return
+                    raise
+                    
             unser = unser.sort()
 
             if not convert_axes and df.index.dtype.type == np.datetime64:
@@ -84,7 +92,9 @@ class TestPandasObjects(unittest.TestCase):
                 else:
                     assert_frame_equal(df, unser, check_less_precise=False, check_dtype=check_dtype)
 
-        def _check_all_orients(df, dtype=None, convert_axes=True):
+        def _check_all_orients(df, dtype=None, convert_axes=True, raise_ok=None):
+
+            # numpy=False
             if convert_axes:
                 _check_orient(df, "columns", dtype=dtype)
                 _check_orient(df, "records", dtype=dtype)
@@ -98,18 +108,19 @@ class TestPandasObjects(unittest.TestCase):
             _check_orient(df, "index", dtype=dtype, convert_axes=False)
             _check_orient(df, "values", dtype=dtype ,convert_axes=False)
 
+            # numpy=True and raise_ok might be not None, so ignore the error
             if convert_axes:
-                _check_orient(df, "columns", dtype=dtype, numpy=False)
-                _check_orient(df, "records", dtype=dtype, numpy=False)
-                _check_orient(df, "split", dtype=dtype, numpy=False)
-                _check_orient(df, "index", dtype=dtype, numpy=False)
-                _check_orient(df, "values", dtype=dtype, numpy=False)
-
-            _check_orient(df, "columns", dtype=dtype, numpy=False, convert_axes=False)
-            _check_orient(df, "records", dtype=dtype, numpy=False, convert_axes=False)
-            _check_orient(df, "split", dtype=dtype, numpy=False, convert_axes=False)
-            _check_orient(df, "index", dtype=dtype, numpy=False, convert_axes=False)
-            _check_orient(df, "values", dtype=dtype, numpy=False, convert_axes=False)
+                _check_orient(df, "columns", dtype=dtype, numpy=True, raise_ok=raise_ok)
+                _check_orient(df, "records", dtype=dtype, numpy=True, raise_ok=raise_ok)
+                _check_orient(df, "split", dtype=dtype, numpy=True, raise_ok=raise_ok)
+                _check_orient(df, "index", dtype=dtype, numpy=True, raise_ok=raise_ok)
+                _check_orient(df, "values", dtype=dtype, numpy=True, raise_ok=raise_ok)
+
+            _check_orient(df, "columns", dtype=dtype, numpy=True, convert_axes=False, raise_ok=raise_ok)
+            _check_orient(df, "records", dtype=dtype, numpy=True, convert_axes=False, raise_ok=raise_ok)
+            _check_orient(df, "split", dtype=dtype, numpy=True, convert_axes=False, raise_ok=raise_ok)
+            _check_orient(df, "index", dtype=dtype, numpy=True, convert_axes=False, raise_ok=raise_ok)
+            _check_orient(df, "values", dtype=dtype, numpy=True, convert_axes=False, raise_ok=raise_ok)
 
         # basic
         _check_all_orients(self.frame)
@@ -131,7 +142,8 @@ class TestPandasObjects(unittest.TestCase):
         _check_all_orients(DataFrame(biggie, dtype=np.float64),
                            dtype=np.float64, convert_axes=False)
         _check_all_orients(DataFrame(biggie, dtype=np.int), dtype=np.int, convert_axes=False)
-        _check_all_orients(DataFrame(biggie, dtype='<U3'), dtype='<U3', convert_axes=False)
+        _check_all_orients(DataFrame(biggie, dtype='<U3'), dtype='<U3', convert_axes=False,
+                           raise_ok=ValueError)
 
         # empty
         _check_all_orients(self.empty_frame)
@@ -223,7 +235,7 @@ class TestPandasObjects(unittest.TestCase):
 
     def test_series_from_json_to_json(self):
 
-        def _check_orient(series, orient, dtype=None, numpy=True):
+        def _check_orient(series, orient, dtype=None, numpy=False):
             series = series.sort_index()
             unser = read_json(series.to_json(orient=orient), typ='series',
                               orient=orient, numpy=numpy, dtype=dtype)
@@ -247,11 +259,11 @@ class TestPandasObjects(unittest.TestCase):
             _check_orient(series, "index", dtype=dtype)
             _check_orient(series, "values", dtype=dtype)
 
-            _check_orient(series, "columns", dtype=dtype, numpy=False)
-            _check_orient(series, "records", dtype=dtype, numpy=False)
-            _check_orient(series, "split", dtype=dtype, numpy=False)
-            _check_orient(series, "index", dtype=dtype, numpy=False)
-            _check_orient(series, "values", dtype=dtype, numpy=False)
+            _check_orient(series, "columns", dtype=dtype, numpy=True)
+            _check_orient(series, "records", dtype=dtype, numpy=True)
+            _check_orient(series, "split", dtype=dtype, numpy=True)
+            _check_orient(series, "index", dtype=dtype, numpy=True)
+            _check_orient(series, "values", dtype=dtype, numpy=True)
 
         # basic
         _check_all_orients(self.series)
@@ -384,12 +396,13 @@ class TestPandasObjects(unittest.TestCase):
         assert_frame_equal(result,result)
 
     def test_misc_example(self):
-        #import pdb; pdb.set_trace()
+
+        # parsing unordered input fails
         result = read_json('[{"a": 1, "b": 2}, {"b":2, "a" :1}]',numpy=True)
         expected = DataFrame([[1,2],[1,2]],columns=['a','b'])
         #assert_frame_equal(result,expected)
 
-        result = read_json('[{"a": 1, "b": 2}, {"b":2, "a" :1}]',numpy=False)
+        result = read_json('[{"a": 1, "b": 2}, {"b":2, "a" :1}]')
         expected = DataFrame([[1,2],[1,2]],columns=['a','b'])
         assert_frame_equal(result,expected)
 
