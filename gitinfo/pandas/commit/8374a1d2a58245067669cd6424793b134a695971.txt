commit 8374a1d2a58245067669cd6424793b134a695971
Author: Marc Garcia <garcia.marc@gmail.com>
Date:   Fri Jun 14 07:45:12 2019 +0100

    DOC: Fixing some more warnings (#26810)

diff --git a/doc/source/user_guide/advanced.rst b/doc/source/user_guide/advanced.rst
index 0e68cddde..3235e3c2a 100644
--- a/doc/source/user_guide/advanced.rst
+++ b/doc/source/user_guide/advanced.rst
@@ -703,6 +703,8 @@ faster than fancy indexing.
    %timeit arr[indexer]
    %timeit arr.take(indexer, axis=0)
 
+.. ipython:: python
+
    ser = pd.Series(arr[:, 0])
    %timeit ser.iloc[indexer]
    %timeit ser.take(indexer)
diff --git a/doc/source/user_guide/cookbook.rst b/doc/source/user_guide/cookbook.rst
index 538acbd7d..772362cab 100644
--- a/doc/source/user_guide/cookbook.rst
+++ b/doc/source/user_guide/cookbook.rst
@@ -1260,24 +1260,19 @@ The `method` argument within `DataFrame.corr` can accept a callable in addition
        n = len(x)
        a = np.zeros(shape=(n, n))
        b = np.zeros(shape=(n, n))
-
        for i in range(n):
            for j in range(i + 1, n):
                a[i, j] = abs(x[i] - x[j])
                b[i, j] = abs(y[i] - y[j])
-
        a += a.T
        b += b.T
-
        a_bar = np.vstack([np.nanmean(a, axis=0)] * n)
        b_bar = np.vstack([np.nanmean(b, axis=0)] * n)
-
        A = a - a_bar - a_bar.T + np.full(shape=(n, n), fill_value=a_bar.mean())
        B = b - b_bar - b_bar.T + np.full(shape=(n, n), fill_value=b_bar.mean())
        cov_ab = np.sqrt(np.nansum(A * B)) / n
        std_a = np.sqrt(np.sqrt(np.nansum(A**2)) / n)
        std_b = np.sqrt(np.sqrt(np.nansum(B**2)) / n)
-
        return cov_ab / std_a / std_b
 
    df = pd.DataFrame(np.random.normal(size=(100, 3)))
diff --git a/doc/source/user_guide/io.rst b/doc/source/user_guide/io.rst
index 4aacb6fa1..725af8ef8 100644
--- a/doc/source/user_guide/io.rst
+++ b/doc/source/user_guide/io.rst
@@ -4703,6 +4703,7 @@ See the documentation for `pyarrow <https://arrow.apache.org/docs/python/>`__ an
 Write to a parquet file.
 
 .. ipython:: python
+   :okwarning:
 
    df.to_parquet('example_pa.parquet', engine='pyarrow')
    df.to_parquet('example_fp.parquet', engine='fastparquet')
@@ -4720,6 +4721,7 @@ Read from a parquet file.
 Read only certain columns of a parquet file.
 
 .. ipython:: python
+   :okwarning:
 
    result = pd.read_parquet('example_fp.parquet',
                             engine='fastparquet', columns=['a', 'b'])
@@ -4742,6 +4744,7 @@ Serializing a ``DataFrame`` to parquet may include the implicit index as one or
 more columns in the output file. Thus, this code:
 
 .. ipython:: python
+   :okwarning:
 
     df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
     df.to_parquet('test.parquet', engine='pyarrow')
@@ -4758,6 +4761,7 @@ If you want to omit a dataframe's indexes when writing, pass ``index=False`` to
 :func:`~pandas.DataFrame.to_parquet`:
 
 .. ipython:: python
+   :okwarning:
 
     df.to_parquet('test.parquet', index=False)
 
diff --git a/doc/source/user_guide/missing_data.rst b/doc/source/user_guide/missing_data.rst
index e8fb2b135..417eead3a 100644
--- a/doc/source/user_guide/missing_data.rst
+++ b/doc/source/user_guide/missing_data.rst
@@ -348,7 +348,8 @@ that, by default, performs linear interpolation at missing data points.
    np.random.seed(123456)
    idx = pd.date_range('1/1/2000', periods=100, freq='BM')
    ts = pd.Series(np.random.randn(100), index=idx)
-   ts[1:20] = np.nan
+   ts[1:5] = np.nan
+   ts[20:30] = np.nan
    ts[60:80] = np.nan
    ts = ts.cumsum()
 
@@ -356,6 +357,12 @@ that, by default, performs linear interpolation at missing data points.
 
    ts
    ts.count()
+   @savefig series_before_interpolate.png
+   ts.plot()
+
+.. ipython:: python
+
+   ts.interpolate()
    ts.interpolate().count()
 
    @savefig series_interpolate.png
@@ -435,9 +442,9 @@ Compare several methods:
 
    np.random.seed(2)
 
-   ser = pd.Series(np.arange(1, 10.1, .25)**2 + np.random.randn(37))
-   bad = np.array([4, 13, 14, 15, 16, 17, 18, 20, 29])
-   ser[bad] = np.nan
+   ser = pd.Series(np.arange(1, 10.1, .25) ** 2 + np.random.randn(37))
+   missing = np.array([4, 13, 14, 15, 16, 17, 18, 20, 29])
+   ser[missing] = np.nan
    methods = ['linear', 'quadratic', 'cubic']
 
    df = pd.DataFrame({m: ser.interpolate(method=m) for m in methods})
@@ -451,6 +458,7 @@ You can mix pandas' ``reindex`` and ``interpolate`` methods to interpolate
 at the new values.
 
 .. ipython:: python
+   :okexcept:
 
    ser = pd.Series(np.sort(np.random.uniform(size=100)))
 
@@ -476,6 +484,7 @@ filled since the last valid observation:
 
    ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan,
                     np.nan, 13, np.nan, np.nan])
+   ser
 
    # fill all consecutive values in a forward direction
    ser.interpolate()
diff --git a/doc/source/whatsnew/v0.17.0.rst b/doc/source/whatsnew/v0.17.0.rst
index c53fee425..8a3f87e84 100644
--- a/doc/source/whatsnew/v0.17.0.rst
+++ b/doc/source/whatsnew/v0.17.0.rst
@@ -5,10 +5,6 @@ v0.17.0 (October 9, 2015)
 
 {{ header }}
 
-.. ipython:: python
-   :suppress:
-
-
 
 This is a major release from 0.16.2 and includes a small number of API changes, several new features,
 enhancements, and performance improvements along with a large number of bug fixes. We recommend that all
diff --git a/doc/source/whatsnew/v0.17.1.rst b/doc/source/whatsnew/v0.17.1.rst
index 233414dae..c4dc442bd 100644
--- a/doc/source/whatsnew/v0.17.1.rst
+++ b/doc/source/whatsnew/v0.17.1.rst
@@ -5,10 +5,6 @@ v0.17.1 (November 21, 2015)
 
 {{ header }}
 
-.. ipython:: python
-   :suppress:
-
-
 
 .. note::
 
