commit 472af55268b59635e526e2d02105da04e812a27b
Author: Terji Petersen <contribute@tensortable.com>
Date:   Wed Jul 10 21:16:54 2019 +0200

    CLN: replace usage internally of .iteritems with .items (#26114)

diff --git a/asv_bench/benchmarks/frame_methods.py b/asv_bench/benchmarks/frame_methods.py
index 5008b77d9..e2f6764c7 100644
--- a/asv_bench/benchmarks/frame_methods.py
+++ b/asv_bench/benchmarks/frame_methods.py
@@ -115,15 +115,15 @@ class Iteration:
         )
         self.df4 = DataFrame(np.random.randn(N * 1000, 10))
 
-    def time_iteritems(self):
+    def time_items(self):
         # (monitor no-copying behaviour)
         if hasattr(self.df, "_item_cache"):
             self.df._item_cache.clear()
-        for name, col in self.df.iteritems():
+        for name, col in self.df.items():
             pass
 
-    def time_iteritems_cached(self):
-        for name, col in self.df.iteritems():
+    def time_items_cached(self):
+        for name, col in self.df.items():
             pass
 
     def time_iteritems_indexing(self):
diff --git a/doc/source/development/contributing_docstring.rst b/doc/source/development/contributing_docstring.rst
index 62216f168..34bc5f44e 100644
--- a/doc/source/development/contributing_docstring.rst
+++ b/doc/source/development/contributing_docstring.rst
@@ -522,7 +522,7 @@ examples:
 * ``loc`` and ``iloc``, as they do the same, but in one case providing indices
   and in the other positions
 * ``max`` and ``min``, as they do the opposite
-* ``iterrows``, ``itertuples`` and ``iteritems``, as it is easy that a user
+* ``iterrows``, ``itertuples`` and ``items``, as it is easy that a user
   looking for the method to iterate over columns ends up in the method to
   iterate over rows, and vice-versa
 * ``fillna`` and ``dropna``, as both methods are used to handle missing values
diff --git a/doc/source/getting_started/basics.rst b/doc/source/getting_started/basics.rst
index 682d6c1ef..bc3b7b4c7 100644
--- a/doc/source/getting_started/basics.rst
+++ b/doc/source/getting_started/basics.rst
@@ -1475,7 +1475,7 @@ Thus, for example, iterating over a DataFrame gives you the column names:
        print(col)
 
 
-Pandas objects also have the dict-like :meth:`~DataFrame.iteritems` method to
+Pandas objects also have the dict-like :meth:`~DataFrame.items` method to
 iterate over the (key, value) pairs.
 
 To iterate over the rows of a DataFrame, you can use the following methods:
@@ -1524,10 +1524,10 @@ To iterate over the rows of a DataFrame, you can use the following methods:
 
     df
 
-iteritems
-~~~~~~~~~
+items
+~~~~~
 
-Consistent with the dict-like interface, :meth:`~DataFrame.iteritems` iterates
+Consistent with the dict-like interface, :meth:`~DataFrame.items` iterates
 through key-value pairs:
 
 * **Series**: (index, scalar value) pairs
@@ -1537,7 +1537,7 @@ For example:
 
 .. ipython:: python
 
-   for label, ser in df.iteritems():
+   for label, ser in df.items():
        print(label)
        print(ser)
 
diff --git a/doc/source/reference/frame.rst b/doc/source/reference/frame.rst
index 1a316c2f2..c0b58fd2d 100644
--- a/doc/source/reference/frame.rst
+++ b/doc/source/reference/frame.rst
@@ -67,8 +67,8 @@ Indexing, iteration
    DataFrame.insert
    DataFrame.__iter__
    DataFrame.items
-   DataFrame.keys
    DataFrame.iteritems
+   DataFrame.keys
    DataFrame.iterrows
    DataFrame.itertuples
    DataFrame.lookup
diff --git a/doc/source/reference/series.rst b/doc/source/reference/series.rst
index e8e2f64e2..8d2a764c3 100644
--- a/doc/source/reference/series.rst
+++ b/doc/source/reference/series.rst
@@ -76,8 +76,8 @@ Indexing, iteration
    Series.loc
    Series.iloc
    Series.__iter__
-   Series.iteritems
    Series.items
+   Series.iteritems
    Series.keys
    Series.pop
    Series.item
diff --git a/doc/source/whatsnew/v0.25.0.rst b/doc/source/whatsnew/v0.25.0.rst
index 237d2fec8..042c97a0c 100644
--- a/doc/source/whatsnew/v0.25.0.rst
+++ b/doc/source/whatsnew/v0.25.0.rst
@@ -889,6 +889,7 @@ Other deprecations
 - :meth:`DataFrame.get_dtype_counts` is deprecated. (:issue:`18262`)
 - :meth:`Categorical.ravel` will return a :class:`Categorical` instead of a ``np.ndarray`` (:issue:`27199`)
 
+
 .. _whatsnew_0250.prior_deprecations:
 
 Removal of prior version deprecations/changes
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index ce1b99b31..55a9eb6a0 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -771,15 +771,15 @@ class DataFrame(NDFrame):
 
         return Styler(self)
 
-    def iteritems(self):
-        r"""
+    _shared_docs[
+        "items"
+    ] = r"""
         Iterator over (column name, Series) pairs.
 
         Iterates over the DataFrame columns, returning a tuple with
         the column name and the content as a Series.
 
-        Yields
-        ------
+        %s
         label : object
             The column names for the DataFrame being iterated over.
         content : Series
@@ -802,7 +802,7 @@ class DataFrame(NDFrame):
         panda 	bear 	  1864
         polar 	bear 	  22000
         koala 	marsupial 80000
-        >>> for label, content in df.iteritems():
+        >>> for label, content in df.items():
         ...     print('label:', label)
         ...     print('content:', content, sep='\n')
         ...
@@ -819,6 +819,9 @@ class DataFrame(NDFrame):
         koala    80000
         Name: population, dtype: int64
         """
+
+    @Appender(_shared_docs["items"] % "Yields\n        ------")
+    def items(self):
         if self.columns.is_unique and hasattr(self, "_item_cache"):
             for k in self.columns:
                 yield k, self._get_item_cache(k)
@@ -826,6 +829,10 @@ class DataFrame(NDFrame):
             for i, k in enumerate(self.columns):
                 yield k, self._ixs(i, axis=1)
 
+    @Appender(_shared_docs["items"] % "Returns\n        -------")
+    def iteritems(self):
+        return self.items()
+
     def iterrows(self):
         """
         Iterate over DataFrame rows as (index, Series) pairs.
@@ -843,7 +850,7 @@ class DataFrame(NDFrame):
         See Also
         --------
         itertuples : Iterate over DataFrame rows as namedtuples of the values.
-        iteritems : Iterate over (column name, Series) pairs.
+        items : Iterate over (column name, Series) pairs.
 
         Notes
         -----
@@ -901,7 +908,7 @@ class DataFrame(NDFrame):
         --------
         DataFrame.iterrows : Iterate over DataFrame rows as (index, Series)
             pairs.
-        DataFrame.iteritems : Iterate over (column name, Series) pairs.
+        DataFrame.items : Iterate over (column name, Series) pairs.
 
         Notes
         -----
@@ -958,8 +965,6 @@ class DataFrame(NDFrame):
         # fallback to regular tuples
         return zip(*arrays)
 
-    items = iteritems
-
     def __len__(self):
         """
         Returns length of info axis, but here we use the index.
@@ -2634,7 +2639,7 @@ class DataFrame(NDFrame):
         5216
         """
         result = Series(
-            [c.memory_usage(index=False, deep=deep) for col, c in self.iteritems()],
+            [c.memory_usage(index=False, deep=deep) for col, c in self.items()],
             index=self.columns,
         )
         if index:
@@ -4955,7 +4960,7 @@ class DataFrame(NDFrame):
         if not diff.empty:
             raise KeyError(diff)
 
-        vals = (col.values for name, col in self.iteritems() if name in subset)
+        vals = (col.values for name, col in self.items() if name in subset)
         labels, shape = map(list, zip(*map(f, vals)))
 
         ids = get_group_index(labels, shape, sort=False, xnull=False)
@@ -7343,7 +7348,7 @@ class DataFrame(NDFrame):
         from pandas.core.reshape.concat import concat
 
         def _dict_round(df, decimals):
-            for col, vals in df.iteritems():
+            for col, vals in df.items():
                 try:
                     yield _series_round(vals, decimals[col])
                 except KeyError:
@@ -7363,7 +7368,7 @@ class DataFrame(NDFrame):
             new_cols = [col for col in _dict_round(self, decimals)]
         elif is_integer(decimals):
             # Dispatch to Series.round
-            new_cols = [_series_round(v, decimals) for _, v in self.iteritems()]
+            new_cols = [_series_round(v, decimals) for _, v in self.items()]
         else:
             raise TypeError("decimals must be an integer, a dict-like or a " "Series")
 
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 5db06d328..4e05dfca4 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -494,7 +494,7 @@ class NDFrame(PandasObject, SelectionMixin):
         """
         from pandas.core.computation.common import _remove_spaces_column_name
 
-        return {_remove_spaces_column_name(k): v for k, v in self.iteritems()}
+        return {_remove_spaces_column_name(k): v for k, v in self.items()}
 
     @property
     def _info_axis(self):
@@ -1936,15 +1936,22 @@ class NDFrame(PandasObject, SelectionMixin):
         """
         return self._info_axis
 
-    def iteritems(self):
-        """
-        Iterate over (label, values) on info axis
+    def items(self):
+        """Iterate over (label, values) on info axis
 
-        This is index for Series, columns for DataFrame and so on.
+        This is index for Series and columns for DataFrame.
+
+        Returns
+        -------
+        Generator
         """
         for h in self._info_axis:
             yield h, self[h]
 
+    @Appender(items.__doc__)
+    def iteritems(self):
+        return self.items()
+
     def __len__(self):
         """Returns length of info axis"""
         return len(self._info_axis)
@@ -5912,7 +5919,7 @@ class NDFrame(PandasObject, SelectionMixin):
                         "key in a dtype mappings argument."
                     )
             results = []
-            for col_name, col in self.iteritems():
+            for col_name, col in self.items():
                 if col_name in dtype:
                     results.append(
                         col.astype(
@@ -10328,7 +10335,7 @@ class NDFrame(PandasObject, SelectionMixin):
         else:
             data = self.select_dtypes(include=include, exclude=exclude)
 
-        ldesc = [describe_1d(s) for _, s in data.iteritems()]
+        ldesc = [describe_1d(s) for _, s in data.items()]
         # set a convenient order for rows
         names = []
         ldesc_indexes = sorted((x.index for x in ldesc), key=len)
diff --git a/pandas/core/indexes/multi.py b/pandas/core/indexes/multi.py
index ff0bffacd..670a4666a 100644
--- a/pandas/core/indexes/multi.py
+++ b/pandas/core/indexes/multi.py
@@ -601,7 +601,7 @@ class MultiIndex(Index):
         if not isinstance(df, ABCDataFrame):
             raise TypeError("Input must be a DataFrame")
 
-        column_names, columns = zip(*df.iteritems())
+        column_names, columns = zip(*df.items())
         names = column_names if names is None else names
         return cls.from_arrays(columns, sortorder=sortorder, names=names)
 
diff --git a/pandas/core/reshape/pivot.py b/pandas/core/reshape/pivot.py
index 188f2edd9..23bf89b2b 100644
--- a/pandas/core/reshape/pivot.py
+++ b/pandas/core/reshape/pivot.py
@@ -272,7 +272,7 @@ def _compute_grand_margin(data, values, aggfunc, margins_name="All"):
 
     if values:
         grand_margin = {}
-        for k, v in data[values].iteritems():
+        for k, v in data[values].items():
             try:
                 if isinstance(aggfunc, str):
                     grand_margin[k] = getattr(v, aggfunc)()
diff --git a/pandas/core/reshape/reshape.py b/pandas/core/reshape/reshape.py
index 5d932d7de..540a06cae 100644
--- a/pandas/core/reshape/reshape.py
+++ b/pandas/core/reshape/reshape.py
@@ -478,7 +478,7 @@ def _unstack_extension_series(series, level, fill_value):
     out = []
     values = extract_array(series, extract_numpy=False)
 
-    for col, indices in result.iteritems():
+    for col, indices in result.items():
         out.append(
             Series(
                 values.take(indices.values, allow_fill=True, fill_value=fill_value),
@@ -544,7 +544,7 @@ def stack(frame, level=-1, dropna=True):
         if is_extension_array_dtype(dtype):
             arr = dtype.construct_array_type()
             new_values = arr._concat_same_type(
-                [col._values for _, col in frame.iteritems()]
+                [col._values for _, col in frame.items()]
             )
             new_values = _reorder_for_extension_array_stack(new_values, N, K)
         else:
@@ -695,7 +695,7 @@ def _stack_multi_columns(frame, level_num=-1, dropna=True):
                 subset = this[this.columns[loc]]
 
                 value_slice = dtype.construct_array_type()._concat_same_type(
-                    [x._values for _, x in subset.iteritems()]
+                    [x._values for _, x in subset.items()]
                 )
                 N, K = this.shape
                 idx = np.arange(N * K).reshape(K, N).T.ravel()
@@ -909,7 +909,7 @@ def get_dummies(
             # columns to prepend to result.
             with_dummies = [data.select_dtypes(exclude=dtypes_to_encode)]
 
-        for (col, pre, sep) in zip(data_to_encode.iteritems(), prefix, prefix_sep):
+        for (col, pre, sep) in zip(data_to_encode.items(), prefix, prefix_sep):
             # col is (column_name, column), use just column data here
             dummy = _get_dummies_1d(
                 col[1],
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 1943b6681..4b78907e6 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -1693,13 +1693,12 @@ class Series(base.IndexOpsMixin, generic.NDFrame):
 
     # ----------------------------------------------------------------------
 
-    def iteritems(self):
+    def items(self):
         """
         Lazily iterate over (index, value) tuples.
 
         This method returns an iterable tuple (index, value). This is
-        convenient if you want to create a lazy iterator. Note that the
-        methods Series.items and Series.iteritems are the same methods.
+        convenient if you want to create a lazy iterator.
 
         Returns
         -------
@@ -1709,12 +1708,12 @@ class Series(base.IndexOpsMixin, generic.NDFrame):
 
         See Also
         --------
-        DataFrame.iteritems : Equivalent to Series.iteritems for DataFrame.
+        DataFrame.items : Equivalent to Series.items for DataFrame.
 
         Examples
         --------
         >>> s = pd.Series(['A', 'B', 'C'])
-        >>> for index, value in s.iteritems():
+        >>> for index, value in s.items():
         ...     print("Index : {}, Value : {}".format(index, value))
         Index : 0, Value : A
         Index : 1, Value : B
@@ -1722,7 +1721,9 @@ class Series(base.IndexOpsMixin, generic.NDFrame):
         """
         return zip(iter(self.index), iter(self))
 
-    items = iteritems
+    @Appender(items.__doc__)
+    def iteritems(self):
+        return self.items()
 
     # ----------------------------------------------------------------------
     # Misc public methods
diff --git a/pandas/core/sparse/frame.py b/pandas/core/sparse/frame.py
index 60060a4a2..54998eb66 100644
--- a/pandas/core/sparse/frame.py
+++ b/pandas/core/sparse/frame.py
@@ -698,7 +698,7 @@ class SparseDataFrame(DataFrame):
         need_mask = mask.any()
 
         new_series = {}
-        for col, series in self.iteritems():
+        for col, series in self.items():
             if mask.all():
                 continue
 
diff --git a/pandas/core/strings.py b/pandas/core/strings.py
index 70700653c..7c293ca4e 100644
--- a/pandas/core/strings.py
+++ b/pandas/core/strings.py
@@ -998,7 +998,7 @@ def str_extractall(arr, pat, flags=0):
     index_list = []
     is_mi = arr.index.nlevels > 1
 
-    for subject_key, subject in arr.iteritems():
+    for subject_key, subject in arr.items():
         if isinstance(subject, str):
 
             if not is_mi:
diff --git a/pandas/core/util/hashing.py b/pandas/core/util/hashing.py
index f07133bae..f5ab81ad9 100644
--- a/pandas/core/util/hashing.py
+++ b/pandas/core/util/hashing.py
@@ -113,7 +113,7 @@ def hash_pandas_object(
         h = Series(h, index=obj.index, dtype="uint64", copy=False)
 
     elif isinstance(obj, ABCDataFrame):
-        hashes = (hash_array(series.values) for _, series in obj.iteritems())
+        hashes = (hash_array(series.values) for _, series in obj.items())
         num_items = len(obj.columns)
         if index:
             index_hash_generator = (
diff --git a/pandas/io/formats/style.py b/pandas/io/formats/style.py
index e7aa5d229..98349fe1e 100644
--- a/pandas/io/formats/style.py
+++ b/pandas/io/formats/style.py
@@ -538,7 +538,7 @@ class Styler:
         matter.
         """
         for row_label, v in attrs.iterrows():
-            for col_label, col in v.iteritems():
+            for col_label, col in v.items():
                 i = self.index.get_indexer([row_label])[0]
                 j = self.columns.get_indexer([col_label])[0]
                 for pair in col.rstrip(";").split(";"):
diff --git a/pandas/io/json/_json.py b/pandas/io/json/_json.py
index 1f0728ee9..f3c966bb1 100644
--- a/pandas/io/json/_json.py
+++ b/pandas/io/json/_json.py
@@ -1105,7 +1105,7 @@ class FrameParser(Parser):
 
         needs_new_obj = False
         new_obj = dict()
-        for i, (col, c) in enumerate(self.obj.iteritems()):
+        for i, (col, c) in enumerate(self.obj.items()):
             if filt(col, c):
                 new_data, result = f(col, c)
                 if result:
diff --git a/pandas/io/json/_table_schema.py b/pandas/io/json/_table_schema.py
index 045127c63..1e7cd54d9 100644
--- a/pandas/io/json/_table_schema.py
+++ b/pandas/io/json/_table_schema.py
@@ -249,7 +249,7 @@ def build_table_schema(data, index=True, primary_key=None, version=True):
             fields.append(convert_pandas_type_to_json_field(data.index))
 
     if data.ndim > 1:
-        for column, s in data.iteritems():
+        for column, s in data.items():
             fields.append(convert_pandas_type_to_json_field(s))
     else:
         fields.append(convert_pandas_type_to_json_field(data))
diff --git a/pandas/io/msgpack/_packer.pyx b/pandas/io/msgpack/_packer.pyx
index a0d2b013c..0ed188074 100644
--- a/pandas/io/msgpack/_packer.pyx
+++ b/pandas/io/msgpack/_packer.pyx
@@ -194,7 +194,7 @@ cdef class Packer:
                     raise ValueError("dict is too large")
                 ret = msgpack_pack_map(&self.pk, L)
                 if ret == 0:
-                    for k, v in d.iteritems():
+                    for k, v in d.items():
                         ret = self._pack(k, nest_limit - 1)
                         if ret != 0: break
                         ret = self._pack(v, nest_limit - 1)
diff --git a/pandas/io/sql.py b/pandas/io/sql.py
index 211571c7d..6fe34e4e9 100644
--- a/pandas/io/sql.py
+++ b/pandas/io/sql.py
@@ -108,7 +108,7 @@ def _parse_date_columns(data_frame, parse_dates):
     # we want to coerce datetime64_tz dtypes for now to UTC
     # we could in theory do a 'nice' conversion from a FixedOffset tz
     # GH11216
-    for col_name, df_col in data_frame.iteritems():
+    for col_name, df_col in data_frame.items():
         if is_datetime64tz_dtype(df_col) or col_name in parse_dates:
             try:
                 fmt = parse_dates[col_name]
diff --git a/pandas/io/stata.py b/pandas/io/stata.py
index 7087d2ee9..29cb2a5dc 100644
--- a/pandas/io/stata.py
+++ b/pandas/io/stata.py
@@ -2302,7 +2302,7 @@ class StataWriter(StataParser):
     def _set_formats_and_types(self, data, dtypes):
         self.typlist = []
         self.fmtlist = []
-        for col, dtype in dtypes.iteritems():
+        for col, dtype in dtypes.items():
             self.fmtlist.append(_dtype_to_default_stata_fmt(dtype, data[col]))
             self.typlist.append(_dtype_to_stata_type(dtype, data[col]))
 
@@ -3168,7 +3168,7 @@ class StataWriter117(StataWriter):
     def _set_formats_and_types(self, data, dtypes):
         self.typlist = []
         self.fmtlist = []
-        for col, dtype in dtypes.iteritems():
+        for col, dtype in dtypes.items():
             force_strl = col in self._convert_strl
             fmt = _dtype_to_default_stata_fmt(
                 dtype, data[col], dta_version=117, force_strl=force_strl
diff --git a/pandas/plotting/_matplotlib/core.py b/pandas/plotting/_matplotlib/core.py
index d25715e6d..519465802 100644
--- a/pandas/plotting/_matplotlib/core.py
+++ b/pandas/plotting/_matplotlib/core.py
@@ -258,7 +258,7 @@ class MPLPlot:
         # else:
         #     columns = data.columns
 
-        for col, values in data.iteritems():
+        for col, values in data.items():
             if keep_index is True:
                 yield col, values
             else:
diff --git a/pandas/tests/frame/test_api.py b/pandas/tests/frame/test_api.py
index fe59f0574..b4b081cfe 100644
--- a/pandas/tests/frame/test_api.py
+++ b/pandas/tests/frame/test_api.py
@@ -319,7 +319,7 @@ class SharedWithSparse:
         for row, s in df.iterrows():
             str(s)
 
-        for c, col in df.iteritems():
+        for c, col in df.items():
             str(s)
 
     def test_len(self, float_frame):
@@ -430,7 +430,7 @@ class SharedWithSparse:
         expected = "              X\nNaT        a  1\n2013-01-01 b  2"
         assert result == expected
 
-    def test_iteritems_names(self, float_string_frame):
+    def test_items_names(self, float_string_frame):
         for k, v in float_string_frame.items():
             assert v.name == k
 
diff --git a/pandas/tests/frame/test_indexing.py b/pandas/tests/frame/test_indexing.py
index c2d38b293..3c102f49c 100644
--- a/pandas/tests/frame/test_indexing.py
+++ b/pandas/tests/frame/test_indexing.py
@@ -2712,7 +2712,7 @@ class TestDataFrameIndexing(TestData):
             other1 = _safe_add(df)
             rs = df.where(cond, other1)
             rs2 = df.where(cond.values, other1)
-            for k, v in rs.iteritems():
+            for k, v in rs.items():
                 exp = Series(np.where(cond[k], df[k], other1[k]), index=v.index)
                 assert_series_equal(v, exp, check_names=False)
             assert_frame_equal(rs, rs2)
diff --git a/pandas/tests/frame/test_operators.py b/pandas/tests/frame/test_operators.py
index 67482ddf6..bffdf17a4 100644
--- a/pandas/tests/frame/test_operators.py
+++ b/pandas/tests/frame/test_operators.py
@@ -281,7 +281,7 @@ class TestDataFrameOperators:
             result = getattr(df, op)(x, level="third", axis=0)
 
             expected = pd.concat(
-                [opa(df.loc[idx[:, :, i], :], v) for i, v in x.iteritems()]
+                [opa(df.loc[idx[:, :, i], :], v) for i, v in x.items()]
             ).sort_index()
             assert_frame_equal(result, expected)
 
@@ -289,7 +289,7 @@ class TestDataFrameOperators:
             result = getattr(df, op)(x, level="second", axis=0)
 
             expected = (
-                pd.concat([opa(df.loc[idx[:, i], :], v) for i, v in x.iteritems()])
+                pd.concat([opa(df.loc[idx[:, i], :], v) for i, v in x.items()])
                 .reindex_like(df)
                 .sort_index()
             )
diff --git a/pandas/tests/indexing/test_indexing.py b/pandas/tests/indexing/test_indexing.py
index ba1449097..a2a22bf60 100644
--- a/pandas/tests/indexing/test_indexing.py
+++ b/pandas/tests/indexing/test_indexing.py
@@ -839,7 +839,7 @@ class TestMisc(Base):
 
     def test_float_index_at_iat(self):
         s = Series([1, 2, 3], index=[0.1, 0.2, 0.3])
-        for el, item in s.iteritems():
+        for el, item in s.items():
             assert s.at[el] == item
         for i in range(len(s)):
             assert s.iat[i] == i + 1
diff --git a/pandas/tests/indexing/test_scalar.py b/pandas/tests/indexing/test_scalar.py
index e6ccee684..38b4897e5 100644
--- a/pandas/tests/indexing/test_scalar.py
+++ b/pandas/tests/indexing/test_scalar.py
@@ -198,7 +198,7 @@ class TestScalar(Base):
     def test_mixed_index_at_iat_loc_iloc_series(self):
         # GH 19860
         s = Series([1, 2, 3, 4, 5], index=["a", "b", "c", 1, 2])
-        for el, item in s.iteritems():
+        for el, item in s.items():
             assert s.at[el] == s.loc[el] == item
         for i in range(len(s)):
             assert s.iat[i] == s.iloc[i] == i + 1
@@ -214,7 +214,7 @@ class TestScalar(Base):
             [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]], columns=["a", "b", "c", 1, 2]
         )
         for rowIdx, row in df.iterrows():
-            for el, item in row.iteritems():
+            for el, item in row.items():
                 assert df.at[rowIdx, el] == df.loc[rowIdx, el] == item
 
         for row in range(2):
diff --git a/pandas/tests/io/test_html.py b/pandas/tests/io/test_html.py
index 6d06113df..615e2735c 100644
--- a/pandas/tests/io/test_html.py
+++ b/pandas/tests/io/test_html.py
@@ -380,7 +380,7 @@ class TestReadHtml:
         dfs = self.read_html(macau_data, index_col=0, attrs={"class": "style1"})
         df = dfs[all_non_nan_table_index]
 
-        assert not any(s.isna().any() for _, s in df.iteritems())
+        assert not any(s.isna().any() for _, s in df.items())
 
     @pytest.mark.slow
     def test_thousands_macau_index_col(self, datapath):
@@ -389,7 +389,7 @@ class TestReadHtml:
         dfs = self.read_html(macau_data, index_col=0, header=0)
         df = dfs[all_non_nan_table_index]
 
-        assert not any(s.isna().any() for _, s in df.iteritems())
+        assert not any(s.isna().any() for _, s in df.items())
 
     def test_empty_tables(self):
         """
diff --git a/pandas/tests/series/test_api.py b/pandas/tests/series/test_api.py
index 2870677e4..d204d7d2a 100644
--- a/pandas/tests/series/test_api.py
+++ b/pandas/tests/series/test_api.py
@@ -338,10 +338,10 @@ class TestSeriesMisc(TestData, SharedWithSparse):
         tm.assert_almost_equal(self.ts.values, self.ts, check_dtype=False)
 
     def test_iteritems(self):
-        for idx, val in self.series.items():
+        for idx, val in self.series.iteritems():
             assert val == self.series[idx]
 
-        for idx, val in self.ts.items():
+        for idx, val in self.ts.iteritems():
             assert val == self.ts[idx]
 
         # assert is lazy (genrators don't define reverse, lists do)
diff --git a/pandas/tests/series/test_io.py b/pandas/tests/series/test_io.py
index 538939050..0686b397c 100644
--- a/pandas/tests/series/test_io.py
+++ b/pandas/tests/series/test_io.py
@@ -268,5 +268,5 @@ class TestSeriesIO:
             Series(datetime_series.to_dict(mapping), name="ts"), datetime_series
         )
         from_method = Series(datetime_series.to_dict(collections.Counter))
-        from_constructor = Series(collections.Counter(datetime_series.iteritems()))
+        from_constructor = Series(collections.Counter(datetime_series.items()))
         tm.assert_series_equal(from_method, from_constructor)
diff --git a/pandas/tests/test_base.py b/pandas/tests/test_base.py
index 279d6dd84..d75016824 100644
--- a/pandas/tests/test_base.py
+++ b/pandas/tests/test_base.py
@@ -1107,13 +1107,13 @@ class TestToIterable:
     @pytest.mark.parametrize("dtype, rdtype", dtypes)
     def test_iterable_items(self, dtype, rdtype):
         # gh-13258
-        # test items / iteritems yields the correct boxed scalars
+        # test if items yields the correct boxed scalars
         # this only applies to series
         s = Series([1], dtype=dtype)
         _, result = list(s.items())[0]
         assert isinstance(result, rdtype)
 
-        _, result = list(s.iteritems())[0]
+        _, result = list(s.items())[0]
         assert isinstance(result, rdtype)
 
     @pytest.mark.parametrize(
