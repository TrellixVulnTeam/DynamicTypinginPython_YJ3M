commit c33eb36b1c1d57956114caa18d793c1e437ee111
Author: Jeff Reback <jeff@reback.net>
Date:   Tue Apr 26 14:06:28 2016 -0400

    DOC: minor whatsnew edits

diff --git a/doc/source/reshaping.rst b/doc/source/reshaping.rst
index 5c727b8bc..21765b3f6 100644
--- a/doc/source/reshaping.rst
+++ b/doc/source/reshaping.rst
@@ -28,7 +28,7 @@ Reshaping by pivoting DataFrame objects
       ...:                 'variable' : np.asarray(frame.columns).repeat(N),
       ...:                 'date' : np.tile(np.asarray(frame.index), K)}
       ...:         columns = ['date', 'variable', 'value']
-      ...:         return DataFrame(data, columns=columns)
+      ...:         return pd.DataFrame(data, columns=columns)
       ...:
 
    In [3]: df = unpivot(tm.makeTimeDataFrame())
@@ -318,8 +318,8 @@ some very expressive and fast data manipulations.
    df.mean().unstack(0)
 
 
-Pivot tables and cross-tabulations
-----------------------------------
+Pivot tables
+------------
 
 .. _reshaping.pivot:
 
@@ -371,7 +371,7 @@ Also, you can use ``Grouper`` for ``index`` and ``columns`` keywords. For detail
 
 .. ipython:: python
 
-   pd.pivot_table(df, values='D', index=Grouper(freq='M', key='F'), columns='C')
+   pd.pivot_table(df, values='D', index=pd.Grouper(freq='M', key='F'), columns='C')
 
 You can render a nice output of the table omitting the missing values by
 calling ``to_string`` if you wish:
@@ -383,11 +383,23 @@ calling ``to_string`` if you wish:
 
 Note that ``pivot_table`` is also available as an instance method on DataFrame.
 
+.. _reshaping.pivot.margins:
+
+Adding margins
+~~~~~~~~~~~~~~
+
+If you pass ``margins=True`` to ``pivot_table``, special ``All`` columns and
+rows will be added with partial group aggregates across the categories on the
+rows and columns:
+
+.. ipython:: python
+
+   df.pivot_table(index=['A', 'B'], columns='C', margins=True, aggfunc=np.std)
+
 .. _reshaping.crosstabulations:
 
 Cross tabulations
-~~~~~~~~~~~~~~~~~
-
+-----------------
 
 Use the ``crosstab`` function to compute a cross-tabulation of two (or more)
 factors. By default ``crosstab`` computes a frequency table of the factors
@@ -401,11 +413,11 @@ It takes a number of arguments
   the factors
 - ``aggfunc``: function, optional, If no values array is passed, computes a
   frequency table
-- ``rownames``: sequence, default None, must match number of row arrays passed
-- ``colnames``: sequence, default None, if passed, must match number of column
+- ``rownames``: sequence, default ``None``, must match number of row arrays passed
+- ``colnames``: sequence, default ``None``, if passed, must match number of column
   arrays passed
-- ``margins``: boolean, default False, Add row/column margins (subtotals)
-- ``normalize``: boolean, {'all', 'index', 'columns'}, or {0,1}, default False.
+- ``margins``: boolean, default ``False``, Add row/column margins (subtotals)
+- ``normalize``: boolean, {'all', 'index', 'columns'}, or {0,1}, default ``False``.
   Normalize by dividing all values by the sum of values.
 
 
@@ -427,11 +439,14 @@ If ``crosstab`` receives only two Series, it will provide a frequency table.
 
 .. ipython:: python
 
-    df = pd.DataFrame({'a': [1, 2, 2, 2, 2], 'b': [3, 3, 4, 4, 4],
-                       'c': [1, 1, np.nan, 1, 1]})
+    df = pd.DataFrame({'A': [1, 2, 2, 2, 2], 'B': [3, 3, 4, 4, 4],
+                       'C': [1, 1, np.nan, 1, 1]})
     df
 
-    pd.crosstab(df.a, df.b)
+    pd.crosstab(df.A, df.B)
+
+Normalization
+~~~~~~~~~~~~~
 
 .. versionadded:: 0.18.1
 
@@ -440,13 +455,13 @@ using the ``normalize`` argument:
 
 .. ipython:: python
 
-   pd.crosstab(df.a, df.b, normalize=True)
+   pd.crosstab(df.A, df.B, normalize=True)
 
 ``normalize`` can also normalize values within each row or within each column:
 
 .. ipython:: python
 
-   pd.crosstab(df.a, df.b, normalize='columns')
+   pd.crosstab(df.A, df.B, normalize='columns')
 
 ``crosstab`` can also be passed a third Series and an aggregation function
 (``aggfunc``) that will be applied to the values of the third Series within each
@@ -454,35 +469,24 @@ group defined by the first two Series:
 
 .. ipython:: python
 
-   pd.crosstab(df.a, df.b, values=df.c, aggfunc=np.sum)
+   pd.crosstab(df.A, df.B, values=df.C, aggfunc=np.sum)
 
-And finally, one can also add margins or normalize this output.
+Adding Margins
+~~~~~~~~~~~~~~
 
-.. ipython:: python
-
-   pd.crosstab(df.a, df.b, values=df.c, aggfunc=np.sum, normalize=True,
-               margins=True)
-
-.. _reshaping.pivot.margins:
-
-Adding margins (partial aggregates)
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-If you pass ``margins=True`` to ``pivot_table``, special ``All`` columns and
-rows will be added with partial group aggregates across the categories on the
-rows and columns:
+Finally, one can also add margins or normalize this output.
 
 .. ipython:: python
 
-   df.pivot_table(index=['A', 'B'], columns='C', margins=True, aggfunc=np.std)
+   pd.crosstab(df.A, df.B, values=df.C, aggfunc=np.sum, normalize=True,
+               margins=True)
 
 .. _reshaping.tile:
+.. _reshaping.tile.cut:
 
 Tiling
 ------
 
-.. _reshaping.tile.cut:
-
 The ``cut`` function computes groupings for the values of the input array and
 is often used to transform continuous variables to discrete or categorical
 variables:
@@ -491,7 +495,6 @@ variables:
 
    ages = np.array([10, 15, 13, 12, 23, 25, 28, 59, 60])
 
-
    pd.cut(ages, bins=3)
 
 If the ``bins`` keyword is an integer, then equal-width bins are formed.
diff --git a/doc/source/whatsnew/v0.18.1.txt b/doc/source/whatsnew/v0.18.1.txt
index d19a177b7..c4a4f03e9 100644
--- a/doc/source/whatsnew/v0.18.1.txt
+++ b/doc/source/whatsnew/v0.18.1.txt
@@ -1,7 +1,7 @@
 .. _whatsnew_0181:
 
-v0.18.1 (April ??, 2016)
-------------------------
+v0.18.1 (Mayl ??, 2016)
+-----------------------
 
 This is a minor bug-fix release from 0.18.0 and includes a large number of
 bug fixes along with several new features, enhancements, and performance improvements.
@@ -9,8 +9,10 @@ We recommend that all users upgrade to this version.
 
 Highlights include:
 
+- ``.groupby(...)`` has been enhanced to provide convenient syntax when working with ``.rolling(..)``, ``.expanding(..)`` and ``.resample(..)`` per group, see :ref:`here <whatsnew_0181.deferred_ops>`
+- ``pd.to_datetime()`` has gained the ability to assemble dates from a ``DataFrame``, see :ref:`here <whatsnew_0181.enhancements.assembling>`
 - Custom business hour offset, see :ref:`here <whatsnew_0181.enhancements.custombusinesshour>`.
-
+- Many bug fixes in the handling of ``sparse``, see :ref:`here <whatsnew_0181.sparse>`
 
 .. contents:: What's new in v0.18.1
     :local:
@@ -18,7 +20,6 @@ Highlights include:
 
 .. _whatsnew_0181.new_features:
 
-- ``.groupby(...)`` has been enhanced to provide convenient syntax when working with ``.rolling(..)``, ``.expanding(..)`` and ``.resample(..)`` per group, see :ref:`here <whatsnew_0181.deferred_ops>`
 
 New features
 ~~~~~~~~~~~~
@@ -149,6 +150,7 @@ Other Enhancements
 - ``pd.read_msgpack()`` now always gives writeable ndarrays even when compression is used (:issue:`12359`).
 - ``pd.read_msgpack()`` now supports serializing and de-serializing categoricals with msgpack (:issue:`12573`)
 - ``interpolate()`` now supports ``method='akima'`` (:issue:`7588`).
+- ``pd.read_excel()`` now accepts path objects (e.g. ``pathlib.Path``, ``py.path.local``) for the file path, in line with other ``read_*`` functions (:issue:`12655`)
 - ``Index.take`` now handles ``allow_fill`` and ``fill_value`` consistently (:issue:`12631`)
 - Added ``weekday_name`` as a component to ``DatetimeIndex`` and ``.dt`` accessor. (:issue:`11128`)
 
@@ -375,11 +377,11 @@ New behaviour:
 In addition to this error change, several others have been made as well:
 
 - ``CParserError`` is now a ``ValueError`` instead of just an ``Exception`` (:issue:`12551`)
-- A ``CParserError`` is now raised instead of a generic ``Exception`` in ``read_csv`` when the C engine cannot parse a column
-- A ``ValueError`` is now raised instead of a generic ``Exception`` in ``read_csv`` when the C engine encounters a ``NaN`` value in an integer column
-- A ``ValueError`` is now raised instead of a generic ``Exception`` in ``read_csv`` when ``true_values`` is specified, and the C engine encounters an element in a column containing unencodable bytes
-- ``pandas.parser.OverflowError`` exception has been removed and has been replaced with Python's built-in ``OverflowError`` exception
-- ``read_csv`` no longer allows a combination of strings and integers for the ``usecols`` parameter (:issue:`12678`)
+- A ``CParserError`` is now raised instead of a generic ``Exception`` in ``read_csv`` when the C engine cannot parse a column (:issue:`12506`)
+- A ``ValueError`` is now raised instead of a generic ``Exception`` in ``read_csv`` when the C engine encounters a ``NaN`` value in an integer column (:issue:`12506`)
+- A ``ValueError`` is now raised instead of a generic ``Exception`` in ``read_csv`` when ``true_values`` is specified, and the C engine encounters an element in a column containing unencodable bytes (:issue:`12506`)
+- ``pandas.parser.OverflowError`` exception has been removed and has been replaced with Python's built-in ``OverflowError`` exception (:issue:`12506`)
+- ``pd.read_csv()`` no longer allows a combination of strings and integers for the ``usecols`` parameter (:issue:`12678`)
 
 .. _whatsnew_0181.deprecations:
 
@@ -459,15 +461,15 @@ Bug Fixes
 
 
 
-- Bug in ``read_csv`` with the C engine when specifying ``skiprows`` with newlines in quoted items (:issue:`10911`, `12775`)
-- Bug in ``DataFrame`` timezone lost when assigning tz-aware datetime ``Series`` with alignment (:issue `12981`)
+- Bug in ``read_csv`` with the C engine when specifying ``skiprows`` with newlines in quoted items (:issue:`10911`, :issue:`12775`)
+- Bug in ``DataFrame`` timezone lost when assigning tz-aware datetime ``Series`` with alignment (:issue:`12981`)
 
 
 
 
 - Bug in ``value_counts`` when ``normalize=True`` and ``dropna=True`` where nulls still contributed to the normalized count (:issue:`12558`)
 - Bug in ``Panel.fillna()`` ignoring ``inplace=True`` (:issue:`12633`)
-- Bug in ``read_csv`` when specifying ``names``, ```usecols``, and ``parse_dates`` simultaneously with the C engine (:issue:`9755`)
+- Bug in ``read_csv`` when specifying ``names``, ``usecols``, and ``parse_dates`` simultaneously with the C engine (:issue:`9755`)
 - Bug in ``read_csv`` when specifying ``delim_whitespace=True`` and ``lineterminator`` simultaneously with the C engine (:issue:`12912`)
 - Bug in ``Series.rename``, ``DataFrame.rename`` and ``DataFrame.rename_axis`` not treating ``Series`` as mappings to relabel (:issue:`12623`).
 - Clean in ``.rolling.min`` and ``.rolling.max`` to enhance dtype handling (:issue:`12373`)
@@ -475,7 +477,7 @@ Bug Fixes
 - Bug in ``Series.map`` raises ``TypeError`` if its dtype is ``category`` or tz-aware ``datetime`` (:issue:`12473`)
 
 
-- Bug in index coercion when falling back from ```RangeIndex``` construction (:issue:`12893`)
+- Bug in index coercion when falling back from ``RangeIndex`` construction (:issue:`12893`)
 
 - Bug in slicing subclassed ``DataFrame`` defined to return subclassed ``Series`` may return normal ``Series`` (:issue:`11559`)
 
@@ -494,9 +496,9 @@ Bug Fixes
 
 
 
-- Bug in ``fill_value`` is ignored if the argument to a binary operator is a constant (:issue `12723`)
+- Bug in ``fill_value`` is ignored if the argument to a binary operator is a constant (:issue:`12723`)
 
-- Bug in ``pd.read_html`` when using bs4 flavor and parsing table with a header and only one column (:issue `9178`)
+- Bug in ``pd.read_html`` when using bs4 flavor and parsing table with a header and only one column (:issue:`9178`)
 
 - Bug in ``pivot_table`` when ``margins=True`` and ``dropna=True`` where nulls still contributed to margin count (:issue:`12577`)
 - Bug in ``pivot_table`` when ``dropna=False`` where table index/column names disappear (:issue:`12133`)
@@ -505,5 +507,4 @@ Bug Fixes
 - Bug in ``Series.name`` when ``name`` attribute can be a hashable type (:issue:`12610`)
 - Bug in ``.describe()`` resets categorical columns information (:issue:`11558`)
 - Bug where ``loffset`` argument was not applied when calling ``resample().count()`` on a timeseries (:issue:`12725`)
-- ``pd.read_excel()`` now accepts path objects (e.g. ``pathlib.Path``, ``py.path.local``) for the file path, in line with other ``read_*`` functions (:issue:`12655`)
-- ``pd.read_excel()`` now accepts column names associated with keyword argument ``names``(:issue `12870`)
+- ``pd.read_excel()`` now accepts column names associated with keyword argument ``names``(:issue:`12870`)
