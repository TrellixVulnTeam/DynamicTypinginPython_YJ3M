commit bc271d8d2f227ca3bafd224ecd5d3b0205dffdb6
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Thu Nov 22 15:33:54 2012 -0500

    BUG: resolve memory use problems in unstack for potentially very large key spaces. close #2278

diff --git a/RELEASE.rst b/RELEASE.rst
index 12b8cb4c0..887c0a1dd 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -42,6 +42,9 @@ pandas 0.10.0
 
   - Grouped histogram via `by` keyword in Series/DataFrame.hist (#2186)
   - Add ``nrows`` option to DataFrame.from_records for iterators (#1794)
+  - Unstack/reshape algorithm rewrite to avoid high memory use in cases where
+    the number of observed key-tuples is much smaller than the total possible
+    number that could occur (#2278). Also improves performance in most cases.
 
 **Bug fixes**
 
diff --git a/pandas/core/reshape.py b/pandas/core/reshape.py
index 09946c9e0..3a4cdf2eb 100644
--- a/pandas/core/reshape.py
+++ b/pandas/core/reshape.py
@@ -72,10 +72,6 @@ class _Unstacker(object):
         self.removed_name = self.new_index_names.pop(self.level)
         self.removed_level = self.new_index_levels.pop(self.level)
 
-        v = self.level
-        lshape = self.index.levshape
-        self.full_shape = np.prod(lshape[:v] + lshape[v + 1:]), lshape[v]
-
         self._make_sorted_values_labels()
         self._make_selectors()
 
@@ -88,17 +84,13 @@ class _Unstacker(object):
         sizes = [len(x) for x in levs[:v] + levs[v + 1:] + [levs[v]]]
 
         group_index = get_group_index(to_sort, sizes)
-        max_groups = np.prod(sizes)
-        if max_groups > 1000000:
-            comp_index, obs_ids = _compress_group_index(group_index)
-            ngroups = len(obs_ids)
-        else:
-            comp_index, ngroups = group_index, max_groups
+        comp_index, obs_ids = _compress_group_index(group_index)
+        ngroups = len(obs_ids)
 
         indexer = lib.groupsort_indexer(comp_index, ngroups)[0]
         indexer = _ensure_platform_int(indexer)
 
-        self.sorted_values = self.values.take(indexer, axis=0)
+        self.sorted_values = com.take_2d(self.values, indexer, axis=0)
         self.sorted_labels = [l.take(indexer) for l in to_sort]
 
     def _make_selectors(self):
@@ -108,29 +100,25 @@ class _Unstacker(object):
         group_index = get_group_index(self.sorted_labels[:-1],
                                       [len(x) for x in new_levels])
 
-        group_index = _ensure_platform_int(group_index)
-
-        group_mask = np.zeros(self.full_shape[0], dtype=bool)
-        group_mask.put(group_index, True)
+        comp_index, obs_ids = _compress_group_index(group_index)
+        ngroups = len(obs_ids)
 
+        comp_index = _ensure_platform_int(comp_index)
         stride = self.index.levshape[self.level]
-        selector = self.sorted_labels[-1] + stride * group_index
+        self.full_shape = ngroups, stride
+
+        selector = self.sorted_labels[-1] + stride * comp_index
         mask = np.zeros(np.prod(self.full_shape), dtype=bool)
         mask.put(selector, True)
 
-        # compress labels
-        unique_groups = np.arange(self.full_shape[0])[group_mask]
-        compressor = group_index.searchsorted(unique_groups)
-
         if mask.sum() < len(self.index):
             raise ReshapeError('Index contains duplicate entries, '
                                'cannot reshape')
 
-        self.group_mask = group_mask
-        self.group_index = group_index
+        self.group_index = comp_index
         self.mask = mask
-        self.unique_groups = unique_groups
-        self.compressor = compressor
+        self.unique_groups = obs_ids
+        self.compressor = comp_index.searchsorted(np.arange(ngroups))
 
     def get_result(self):
         # TODO: find a better way than this masking business
@@ -141,9 +129,12 @@ class _Unstacker(object):
 
         # filter out missing levels
         if values.shape[1] > 0:
-            mask = value_mask.sum(0) > 0
-            values = values[:, mask]
-            columns = columns[mask]
+            col_inds, obs_ids = _compress_group_index(self.sorted_labels[-1])
+            # rare case, level values not observed
+            if len(obs_ids) < self.full_shape[1]:
+                inds = (value_mask.sum(0) > 0).nonzero()[0]
+                values = com.take_2d(values, inds, axis=1)
+                columns = columns[inds]
 
         return DataFrame(values, index=index, columns=columns)
 
@@ -168,9 +159,6 @@ class _Unstacker(object):
             chunk.flat[self.mask] = self.sorted_values[:, i]
             mask_chunk.flat[self.mask] = True
 
-        new_values = new_values.take(self.unique_groups, axis=0)
-        new_mask = new_mask.take(self.unique_groups, axis=0)
-
         return new_values, new_mask
 
     def get_new_columns(self):
diff --git a/pandas/tests/test_multilevel.py b/pandas/tests/test_multilevel.py
index 8afeb8ebb..6e73013e9 100644
--- a/pandas/tests/test_multilevel.py
+++ b/pandas/tests/test_multilevel.py
@@ -835,6 +835,38 @@ Thur,Lunch,Yes,51.51,17"""
         expected = grouped.transform(lambda x: x * 2)
         assert_series_equal(applied.reindex(expected.index), expected)
 
+    def test_unstack_sparse_keyspace(self):
+        # memory problems with naive impl #2278
+        # Generate Long File & Test Pivot
+        NUM_ROWS = 1000
+
+        df = DataFrame({'A' : np.random.randint(100, size=NUM_ROWS),
+                        'B' : np.random.randint(300, size=NUM_ROWS),
+                        'C' : np.random.randint(-7, 7, size=NUM_ROWS),
+                        'D' : np.random.randint(-19,19, size=NUM_ROWS),
+                        'E' : np.random.randint(3000, size=NUM_ROWS),
+                        'F' : np.random.randn(NUM_ROWS)})
+
+        idf = df.set_index(['A', 'B', 'C', 'D', 'E'])
+
+        # it works! is sufficient
+        idf.unstack('E')
+
+    def test_unstack_unobserved_keys(self):
+        # related to #2278 refactoring
+        levels = [[0, 1], [0, 1, 2, 3]]
+        labels = [[0, 0, 1, 1], [0, 2, 0, 2]]
+
+        index = MultiIndex(levels, labels)
+
+        df = DataFrame(np.random.randn(4, 2), index=index)
+
+        result = df.unstack()
+        self.assertEquals(len(result.columns), 4)
+
+        recons = result.stack()
+        assert_frame_equal(recons, df)
+
     def test_groupby_corner(self):
         midx = MultiIndex(levels=[['foo'],['bar'],['baz']],
                           labels=[[0],[0],[0]], names=['one','two','three'])
diff --git a/vb_suite/reshape.py b/vb_suite/reshape.py
index 6212d11d5..19d05e51d 100644
--- a/vb_suite/reshape.py
+++ b/vb_suite/reshape.py
@@ -32,3 +32,19 @@ f = lambda: pdf.pivot('date', 'variable', 'value')
 
 reshape_pivot_time_series = Benchmark('f()', setup,
                                       start_date=datetime(2012, 5, 1))
+
+# Sparse key space, re: #2278
+
+setup = common_setup + """
+NUM_ROWS = 10000
+df = DataFrame({'A' : np.random.randint(100, size=NUM_ROWS),
+                'B' : np.random.randint(300, size=NUM_ROWS),
+                'C' : np.random.randint(-7, 7, size=NUM_ROWS),
+                'D' : np.random.randint(-19,19, size=NUM_ROWS),
+                'E' : np.random.randint(100, size=NUM_ROWS),
+                'F' : np.random.randn(NUM_ROWS)})
+idf = df.set_index(['A', 'B', 'C', 'D', 'E'])
+"""
+
+unstack_sparse_keyspace = Benchmark('idf.unstack()', setup,
+                                    start_date=datetime(2011, 10, 1))
