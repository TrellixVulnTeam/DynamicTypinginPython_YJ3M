commit c9a27ede0925ddbaa8d3ec9efd3c332a636505cf
Author: Joris Van den Bossche <jorisvandenbossche@gmail.com>
Date:   Thu Jul 14 16:26:07 2016 +0200

    CLN: fix some issues in asv benchmark suite (#13630)
    
    * CLN: fix params list
    
    * Fix issue in asv.conf.json for win32+other environment
    
    Fix mistaken exclusion of virtualenv or existing:same on win32 in the config.
    
    Credits: @pv
    
    * CLN: remove DataMatrix
    
    * ASV: fix exlusion of tables package for non-conda environments

diff --git a/asv_bench/asv.conf.json b/asv_bench/asv.conf.json
index 7b9fe353d..f5fa84946 100644
--- a/asv_bench/asv.conf.json
+++ b/asv_bench/asv.conf.json
@@ -77,11 +77,11 @@
         // On conda install pytables, otherwise tables
         {"environment_type": "conda", "tables": ""},
         {"environment_type": "conda", "pytables": null},
-        {"environment_type": "virtualenv", "tables": null},
-        {"environment_type": "virtualenv", "pytables": ""},
+        {"environment_type": "(?!conda).*", "tables": null},
+        {"environment_type": "(?!conda).*", "pytables": ""},
         // On conda&win32, install libpython
         {"sys_platform": "(?!win32).*", "libpython": ""},
-        {"sys_platform": "win32", "libpython": null},
+        {"environment_type": "conda", "sys_platform": "win32", "libpython": null},
         {"environment_type": "(?!conda).*", "libpython": ""}
     ],
     "include": [],
diff --git a/asv_bench/benchmarks/indexing.py b/asv_bench/benchmarks/indexing.py
index 53d37a816..094ae23a9 100644
--- a/asv_bench/benchmarks/indexing.py
+++ b/asv_bench/benchmarks/indexing.py
@@ -19,24 +19,6 @@ class dataframe_getitem_scalar(object):
         self.df[self.col][self.idx]
 
 
-class datamatrix_getitem_scalar(object):
-    goal_time = 0.2
-
-    def setup(self):
-        try:
-            self.klass = DataMatrix
-        except:
-            self.klass = DataFrame
-        self.index = tm.makeStringIndex(1000)
-        self.columns = tm.makeStringIndex(30)
-        self.df = self.klass(np.random.rand(1000, 30), index=self.index, columns=self.columns)
-        self.idx = self.index[100]
-        self.col = self.columns[10]
-
-    def time_datamatrix_getitem_scalar(self):
-        self.df[self.col][self.idx]
-
-
 class series_get_value(object):
     goal_time = 0.2
 
@@ -498,5 +480,3 @@ class float_loc(object):
 
     def time_float_loc(self):
         self.ind.get_loc(0)
-
-
diff --git a/asv_bench/benchmarks/inference.py b/asv_bench/benchmarks/inference.py
index 6809c351b..ee9d3104b 100644
--- a/asv_bench/benchmarks/inference.py
+++ b/asv_bench/benchmarks/inference.py
@@ -143,12 +143,12 @@ class to_numeric(object):
 
     param_names = ['data', 'downcast']
     params = [
-        [(['1'] * N / 2) + ([2] * N / 2),
-         (['-1'] * N / 2) + ([2] * N / 2),
-         np.repeat(np.array('1970-01-01', '1970-01-02',
+        [(['1'] * (N / 2)) + ([2] * (N / 2)),
+         (['-1'] * (N / 2)) + ([2] * (N / 2)),
+         np.repeat(np.array(['1970-01-01', '1970-01-02'],
                             dtype='datetime64[D]'), N),
-         (['1.1'] * N / 2) + ([2] * N / 2),
-         ([1] * N / 2) + ([2] * N / 2),
+         (['1.1'] * (N / 2)) + ([2] * (N / 2)),
+         ([1] * (N / 2)) + ([2] * (N / 2)),
          np.repeat(np.int32(1), N)],
         [None, 'integer', 'signed', 'unsigned', 'float'],
     ]
diff --git a/asv_bench/benchmarks/join_merge.py b/asv_bench/benchmarks/join_merge.py
index 39ebd9cb1..dcd07911f 100644
--- a/asv_bench/benchmarks/join_merge.py
+++ b/asv_bench/benchmarks/join_merge.py
@@ -179,10 +179,6 @@ class join_dataframe_index_multi(object):
             self.df_multi = DataFrame(np.random.randn(len(self.index2), 4), index=self.index2, columns=['A', 'B', 'C', 'D'])
         except:
             pass
-        try:
-            self.DataFrame = DataMatrix
-        except:
-            pass
         self.df = pd.DataFrame({'data1': np.random.randn(100000), 'data2': np.random.randn(100000), 'key1': self.key1, 'key2': self.key2, })
         self.df_key1 = pd.DataFrame(np.random.randn(len(self.level1), 4), index=self.level1, columns=['A', 'B', 'C', 'D'])
         self.df_key2 = pd.DataFrame(np.random.randn(len(self.level2), 4), index=self.level2, columns=['A', 'B', 'C', 'D'])
@@ -210,10 +206,6 @@ class join_dataframe_index_single_key_bigger(object):
             self.df_multi = DataFrame(np.random.randn(len(self.index2), 4), index=self.index2, columns=['A', 'B', 'C', 'D'])
         except:
             pass
-        try:
-            self.DataFrame = DataMatrix
-        except:
-            pass
         self.df = pd.DataFrame({'data1': np.random.randn(100000), 'data2': np.random.randn(100000), 'key1': self.key1, 'key2': self.key2, })
         self.df_key1 = pd.DataFrame(np.random.randn(len(self.level1), 4), index=self.level1, columns=['A', 'B', 'C', 'D'])
         self.df_key2 = pd.DataFrame(np.random.randn(len(self.level2), 4), index=self.level2, columns=['A', 'B', 'C', 'D'])
@@ -241,10 +233,6 @@ class join_dataframe_index_single_key_bigger_sort(object):
             self.df_multi = DataFrame(np.random.randn(len(self.index2), 4), index=self.index2, columns=['A', 'B', 'C', 'D'])
         except:
             pass
-        try:
-            self.DataFrame = DataMatrix
-        except:
-            pass
         self.df = pd.DataFrame({'data1': np.random.randn(100000), 'data2': np.random.randn(100000), 'key1': self.key1, 'key2': self.key2, })
         self.df_key1 = pd.DataFrame(np.random.randn(len(self.level1), 4), index=self.level1, columns=['A', 'B', 'C', 'D'])
         self.df_key2 = pd.DataFrame(np.random.randn(len(self.level2), 4), index=self.level2, columns=['A', 'B', 'C', 'D'])
@@ -272,10 +260,6 @@ class join_dataframe_index_single_key_small(object):
             self.df_multi = DataFrame(np.random.randn(len(self.index2), 4), index=self.index2, columns=['A', 'B', 'C', 'D'])
         except:
             pass
-        try:
-            self.DataFrame = DataMatrix
-        except:
-            pass
         self.df = pd.DataFrame({'data1': np.random.randn(100000), 'data2': np.random.randn(100000), 'key1': self.key1, 'key2': self.key2, })
         self.df_key1 = pd.DataFrame(np.random.randn(len(self.level1), 4), index=self.level1, columns=['A', 'B', 'C', 'D'])
         self.df_key2 = pd.DataFrame(np.random.randn(len(self.level2), 4), index=self.level2, columns=['A', 'B', 'C', 'D'])
