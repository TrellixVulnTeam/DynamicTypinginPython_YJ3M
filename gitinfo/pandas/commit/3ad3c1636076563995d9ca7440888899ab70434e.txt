commit 3ad3c1636076563995d9ca7440888899ab70434e
Author: jreback <jeff@reback.net>
Date:   Mon Jul 29 11:19:13 2013 -0400

    ENH: added interpretation of 'in' in pytables Term syntax
    
    which is syntactically equivalent of '='

diff --git a/doc/source/indexing.rst b/doc/source/indexing.rst
index 9f68934f6..e5e6e84cc 100644
--- a/doc/source/indexing.rst
+++ b/doc/source/indexing.rst
@@ -1037,8 +1037,8 @@ with the name ``a``.
 
 .. ipython:: python
 
-   index = Index(np.arange(n), name='a')
-   df = DataFrame(randint(n, size=(n, 2)), index=index, columns=list('bc'))
+   df = DataFrame(randint(n, size=(n, 2)), columns=list('bc'))
+   df.index.name = 'a'
    df
    df.query('a < b and b < c')
 
diff --git a/doc/source/io.rst b/doc/source/io.rst
index dff1b4836..19fcbd6f4 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -2011,6 +2011,7 @@ The following are valid expressions:
 
    - ``'index>=date'``
    - ``"columns=['A', 'D']"``
+   - ``"columns in ['A', 'D']"``
    - ``'columns=A'``
    - ``'columns==A'``
    - ``"~(columns=['A','B'])"``
diff --git a/pandas/compat/__init__.py b/pandas/compat/__init__.py
index 12c929cd5..10e146473 100644
--- a/pandas/compat/__init__.py
+++ b/pandas/compat/__init__.py
@@ -46,11 +46,13 @@ try:
     from StringIO import StringIO
     BytesIO = StringIO
     import cPickle
+    import httplib
 except ImportError:
     import builtins
     from io import StringIO, BytesIO
     cStringIO = StringIO
     import pickle as cPickle
+    import http.client as httplib
 
 
 if PY3:
diff --git a/pandas/computation/align.py b/pandas/computation/align.py
index 5f81fcd60..794a209b5 100644
--- a/pandas/computation/align.py
+++ b/pandas/computation/align.py
@@ -1,10 +1,11 @@
 import warnings
 from functools import partial, wraps
-from itertools import izip
+from pandas.compat import zip, range
 
 import numpy as np
 
 import pandas as pd
+from pandas import compat
 import pandas.core.common as com
 from pandas.computation.ops import is_const
 
@@ -25,7 +26,7 @@ def _align_core_single_unary_op(term):
 
 def _zip_axes_from_type(typ, new_axes):
     axes = {}
-    for ax_ind, ax_name in typ._AXIS_NAMES.iteritems():
+    for ax_ind, ax_name in compat.iteritems(typ._AXIS_NAMES):
         axes[ax_name] = new_axes[ax_ind]
     return axes
 
@@ -47,7 +48,7 @@ def _maybe_promote_shape(values, naxes):
     axes_slice = [slice(None)] * naxes
 
     # set difference of numaxes and ndims
-    slices = com.difference(nax, ndim)
+    slices = list(set(nax) - set(ndim))
 
     if ndims == naxes:
         if slices:
@@ -100,7 +101,7 @@ def _align_core(terms):
     term_index = [i for i, term in enumerate(terms) if hasattr(term.value,
                                                                'axes')]
     term_dims = [terms[i].value.ndim for i in term_index]
-    ndims = pd.Series(dict(izip(term_index, term_dims)))
+    ndims = pd.Series(dict(zip(term_index, term_dims)))
 
     # initial axes are the axes of the largest-axis'd term
     biggest = terms[ndims.idxmax()].value
@@ -114,11 +115,10 @@ def _align_core(terms):
                 ax, itm = naxes - 1, term.value.index
             else:
                 ax, itm = axis, items
-            if not axes[ax].equals(itm):
-                axes[ax] = axes[ax].join(itm, how='outer')
+            axes[ax] = axes[ax].join(itm, how='outer')
 
-    for i, ndim in ndims.iteritems():
-        for axis, items in izip(xrange(ndim), axes):
+    for i, ndim in compat.iteritems(ndims):
+        for axis, items in zip(range(ndim), axes):
             ti = terms[i].value
 
             if hasattr(ti, 'reindex_axis'):
@@ -216,17 +216,21 @@ def _reconstruct_object(typ, obj, axes, dtype):
         An object of type ``typ`` with the value `obj` and possible axes
         `axes`.
     """
-    #import ipdb; ipdb.set_trace()
     try:
         typ = typ.type
     except AttributeError:
         pass
 
+    try:
+        res_t = np.result_type(obj.dtype, dtype)
+    except AttributeError:
+        res_t = dtype
+
     if (not isinstance(typ, partial) and
         issubclass(typ, pd.core.generic.PandasObject)):
-        return typ(obj, dtype=dtype, **axes)
+        return typ(obj, dtype=res_t, **axes)
 
-    ret_value = typ(obj).astype(dtype)
+    ret_value = typ(obj).astype(res_t)
 
     try:
         ret = ret_value.item()
diff --git a/pandas/computation/common.py b/pandas/computation/common.py
index e69de29bb..325303905 100644
--- a/pandas/computation/common.py
+++ b/pandas/computation/common.py
@@ -0,0 +1,12 @@
+import numpy as np
+
+
+def _ensure_decoded(s):
+    """ if we have bytes, decode them to unicode """
+    if isinstance(s, (np.bytes_, bytes)):
+        s = s.decode('UTF-8')
+    return s
+
+
+class NameResolutionError(NameError):
+    pass
diff --git a/pandas/computation/engines.py b/pandas/computation/engines.py
index cd161352b..794b80615 100644
--- a/pandas/computation/engines.py
+++ b/pandas/computation/engines.py
@@ -1,8 +1,9 @@
 import abc
 
+from pandas import compat
 from pandas.core import common as com
 from pandas.computation.align import _align, _reconstruct_object
-
+from pandas.computation.ops import UndefinedVariableError
 
 class AbstractEngine(object):
     """AbstractEngine object serving as a base class for all engines."""
@@ -22,6 +23,9 @@ class AbstractEngine(object):
         """
         return com.pprint_thing(self.expr)
 
+    def pre_evaluate(self):
+        self.expr.check_name_clashes()
+
     def evaluate(self):
         """Run the engine on the expression
 
@@ -36,7 +40,9 @@ class AbstractEngine(object):
         if not self._is_aligned:
             self.result_type, self.aligned_axes = _align(self.expr.terms)
 
-        res = self._evaluate(self.expr.env)
+        # make sure no names in resolvers and locals/globals clash
+        self.pre_evaluate()
+        res = self._evaluate()
         return _reconstruct_object(self.result_type, res, self.aligned_axes,
                                    self.expr.terms.return_type)
 
@@ -45,7 +51,7 @@ class AbstractEngine(object):
         return self.aligned_axes is not None and self.result_type is not None
 
     @abc.abstractmethod
-    def _evaluate(self, env):
+    def _evaluate(self):
         """Return an evaluated expression.
 
         Parameters
@@ -68,16 +74,26 @@ class NumExprEngine(AbstractEngine):
     def __init__(self, expr):
         super(NumExprEngine, self).__init__(expr)
 
-    def _evaluate(self, env):
+    def _evaluate(self):
         import numexpr as ne
 
+        # add the resolvers to locals
+        self.expr.add_resolvers_to_locals()
+
+        # convert the expression to syntactically valid Python
+        s = self.convert()
+
         try:
-            s = self.convert()
-            return ne.evaluate(s, local_dict=env.locals,
-                               global_dict=env.globals,
+            return ne.evaluate(s, local_dict=self.expr.env.locals,
+                               global_dict=self.expr.env.globals,
                                truediv=self.expr.truediv)
         except KeyError as e:
-            raise NameError('{0!r} is not defined'.format(e.message))
+            # python 3 compat kludge
+            try:
+                msg = e.message
+            except AttributeError:
+                msg = compat.text_type(e)
+            raise UndefinedVariableError(msg)
 
 
 class PythonEngine(AbstractEngine):
@@ -91,9 +107,10 @@ class PythonEngine(AbstractEngine):
         super(PythonEngine, self).__init__(expr)
 
     def evaluate(self):
-        return self.expr(self.expr.env)
+        self.pre_evaluate()
+        return self.expr()
 
-    def _evaluate(self, env):
+    def _evaluate(self):
         pass
 
 
diff --git a/pandas/computation/eval.py b/pandas/computation/eval.py
index 072bd3feb..cb8af9892 100644
--- a/pandas/computation/eval.py
+++ b/pandas/computation/eval.py
@@ -1,10 +1,12 @@
 #!/usr/bin/env python
 
 import numbers
-
 import numpy as np
 
-from pandas.computation.expr import Expr, _parsers, _ensure_scope
+from pandas import compat
+from pandas.compat import string_types
+from pandas.computation.expr import (Expr, _parsers, _ensure_scope,
+                                     _check_syntax)
 from pandas.computation.engines import _engines
 
 
@@ -29,7 +31,7 @@ def _check_parser(parser):
 
 
 def eval(expr, parser='pandas', engine='numexpr', truediv=True,
-         local_dict=None, global_dict=None, resolvers=None):
+         local_dict=None, global_dict=None, resolvers=None, level=2):
     """Evaluate a Python expression as a string using various backends.
 
     The following arithmetic operations are supported: ``+``, ``-``, ``*``,
@@ -74,6 +76,9 @@ def eval(expr, parser='pandas', engine='numexpr', truediv=True,
         :attr:`~pandas.DataFrame.index` and :attr:`~pandas.DataFrame.columns`
         variables that refer to their respective :class:`~pandas.DataFrame`
         instance attributes.
+    level : int, optional, default 2
+        The number of prior stack frames to traverse and add to the current
+        scope.
 
     Returns
     -------
@@ -96,9 +101,9 @@ def eval(expr, parser='pandas', engine='numexpr', truediv=True,
     _check_parser(parser)
 
     env = _ensure_scope(global_dict=global_dict, local_dict=local_dict,
-                        resolvers=resolvers)
+                        resolvers=resolvers, level=level)
 
-    if isinstance(expr, basestring):
+    if isinstance(expr, string_types):
         parsed_expr = Expr(expr, engine=engine, parser=parser, env=env,
                            truediv=truediv)
     else:
diff --git a/pandas/computation/expr.py b/pandas/computation/expr.py
index f968a6d3f..5cff96872 100644
--- a/pandas/computation/expr.py
+++ b/pandas/computation/expr.py
@@ -2,20 +2,21 @@ import ast
 import operator
 import sys
 import inspect
-import itertools
 import tokenize
 import datetime
 
-from cStringIO import StringIO
 from functools import partial
 
 import pandas as pd
+from pandas import compat
+from pandas.compat import StringIO, zip, reduce, string_types
 from pandas.core.base import StringMixin
 from pandas.core import common as com
+from pandas.computation.common import NameResolutionError
 from pandas.computation.ops import (_cmp_ops_syms, _bool_ops_syms,
-                                    _arith_ops_syms, _unary_ops_syms)
-from pandas.computation.ops import _reductions, _mathops
-from pandas.computation.ops import BinOp, UnaryOp, Term, Constant
+                                    _arith_ops_syms, _unary_ops_syms, is_term)
+from pandas.computation.ops import _reductions, _mathops, _LOCAL_TAG
+from pandas.computation.ops import BinOp, UnaryOp, Term, Constant, Div
 
 
 def _ensure_scope(level=2, global_dict=None, local_dict=None, resolvers=None,
@@ -24,6 +25,18 @@ def _ensure_scope(level=2, global_dict=None, local_dict=None, resolvers=None,
     return Scope(global_dict, local_dict, level=level, resolvers=resolvers)
 
 
+def _check_disjoint_resolver_names(resolver_keys, local_keys, global_keys):
+    res_locals = com.intersection(resolver_keys, local_keys)
+    if res_locals:
+        msg = "resolvers and locals overlap on names {0}".format(res_locals)
+        raise NameResolutionError(msg)
+
+    res_globals = com.intersection(resolver_keys, global_keys)
+    if res_globals:
+        msg = "resolvers and globals overlap on names {0}".format(res_globals)
+        raise NameResolutionError(msg)
+
+
 class Scope(StringMixin):
     """Object to hold scope, with a few bells to deal with some custom syntax
     added by pandas.
@@ -75,12 +88,15 @@ class Scope(StringMixin):
         self.globals['True'] = True
         self.globals['False'] = False
 
+
         self.resolver_keys = frozenset(reduce(operator.add, (list(o.keys()) for
                                                              o in
                                                              self.resolvers),
                                               []))
         self._global_resolvers = self.resolvers + (self.locals, self.globals)
         self._resolver = None
+        self.resolver_dict = dict((k, self.resolve(k))
+                                  for k in self.resolver_keys)
 
     def __unicode__(self):
         return com.pprint_thing("locals: {0}\nglobals: {0}\nresolvers: "
@@ -89,20 +105,18 @@ class Scope(StringMixin):
                                              self.resolver_keys))
 
     def __getitem__(self, key):
-        return self.resolver(key)
+        return self.resolve(key, globally=False)
 
-    @property
-    def resolver(self):
-        if self._resolver is None:
-            def resolve_key(key):
-                for resolver in self._global_resolvers:
-                    try:
-                        return resolver[key]
-                    except KeyError:
-                        pass
-            self._resolver = resolve_key
-
-        return self._resolver
+    def resolve(self, key, globally=False):
+        resolvers = self.locals, self.globals
+        if globally:
+            resolvers = self._global_resolvers
+
+        for resolver in resolvers:
+            try:
+                return resolver[key]
+            except KeyError:
+                pass
 
     def update(self, level=None):
         """Update the current scope by going back `level` levels.
@@ -178,6 +192,10 @@ def _replace_booleans(source):
     return source.replace('|', ' or ').replace('&', ' and ')
 
 
+def _replace_locals(source, local_symbol='@'):
+    return source.replace(local_symbol, _LOCAL_TAG)
+
+
 def _preparse(source):
     return _replace_booleans(_rewrite_assign(source))
 
@@ -265,12 +283,14 @@ _op_classes = {'binary': BinOp, 'unary': UnaryOp}
 
 def add_ops(op_classes):
     def f(cls):
-        for op_attr_name, op_class in op_classes.iteritems():
+        for op_attr_name, op_class in compat.iteritems(op_classes):
             ops = getattr(cls, '{0}_ops'.format(op_attr_name))
             ops_map = getattr(cls, '{0}_op_nodes_map'.format(op_attr_name))
             for op in ops:
-                setattr(cls, 'visit_{0}'.format(ops_map[op]),
-                        _op_maker(op_class, op))
+                op_node = ops_map[op]
+                if op_node is not None:
+                    setattr(cls, 'visit_{0}'.format(op_node),
+                            _op_maker(op_class, op))
         return cls
     return f
 
@@ -278,26 +298,30 @@ def add_ops(op_classes):
 @disallow(_unsupported_nodes)
 @add_ops(_op_classes)
 class BaseExprVisitor(ast.NodeVisitor):
+    const_type = Constant
+    term_type = Term
 
     """Custom ast walker
     """
     binary_ops = _cmp_ops_syms + _bool_ops_syms + _arith_ops_syms
     binary_op_nodes = ('Gt', 'Lt', 'GtE', 'LtE', 'Eq', 'NotEq', 'BitAnd',
-                       'BitOr', 'And', 'Or', 'Add', 'Sub', 'Mult', 'Div',
+                       'BitOr', 'And', 'Or', 'Add', 'Sub', 'Mult', None,
                        'Pow', 'FloorDiv', 'Mod')
-    binary_op_nodes_map = dict(itertools.izip(binary_ops, binary_op_nodes))
+    binary_op_nodes_map = dict(zip(binary_ops, binary_op_nodes))
 
     unary_ops = _unary_ops_syms
     unary_op_nodes = 'UAdd', 'USub', 'Invert', 'Not'
-    unary_op_nodes_map = dict(itertools.izip(unary_ops, unary_op_nodes))
+    unary_op_nodes_map = dict(zip(unary_ops, unary_op_nodes))
 
-    def __init__(self, env, preparser=_preparse):
+    def __init__(self, env, engine, parser, preparser=_preparse):
         self.env = env
+        self.engine = engine
+        self.parser = parser
         self.preparser = preparser
 
     def visit(self, node, **kwargs):
         parse = ast.parse
-        if isinstance(node, basestring):
+        if isinstance(node, string_types):
             clean = self.preparser(node)
         elif isinstance(node, ast.AST):
             clean = node
@@ -325,21 +349,27 @@ class BaseExprVisitor(ast.NodeVisitor):
         right = self.visit(node.right, side='right')
         return op(left, right)
 
+    def visit_Div(self, node, **kwargs):
+        return lambda lhs, rhs: Div(lhs, rhs,
+                                    truediv=self.env.locals['truediv'])
+
     def visit_UnaryOp(self, node, **kwargs):
         op = self.visit(node.op)
-        return op(self.visit(node.operand))
+        operand = self.visit(node.operand)
+        return op(operand)
 
     def visit_Name(self, node, **kwargs):
-        return Term(node.id, self.env)
+        return self.term_type(node.id, self.env, **kwargs)
 
     def visit_Num(self, node, **kwargs):
-        return Constant(node.n, self.env)
+        return self.const_type(node.n, self.env)
 
     def visit_Str(self, node, **kwargs):
-        return Constant(node.s, self.env)
+        return self.const_type(node.s, self.env)
 
     def visit_List(self, node, **kwargs):
-        return Constant([self.visit(e).value for e in node.elts], self.env)
+        return self.const_type([self.visit(e).value for e in node.elts],
+                               self.env)
 
     visit_Tuple = visit_List
 
@@ -351,20 +381,18 @@ class BaseExprVisitor(ast.NodeVisitor):
         value = self.visit(node.value)
         slobj = self.visit(node.slice)
         expr = com.pprint_thing(slobj)
-        result = pd.eval(expr, local_dict=self.env.locals,
-                         global_dict=self.env.globals,
-                         resolvers=self.env.resolvers)
+        result = pd.eval(expr, local_dict=self.env, engine=self.engine,
+                         parser=self.parser)
         try:
             # a Term instance
             v = value.value[result]
         except AttributeError:
             # an Op instance
-            lhs = pd.eval(com.pprint_thing(value), local_dict=self.env.locals,
-                          global_dict=self.env.globals,
-                          resolvers=self.env.resolvers)
+            lhs = pd.eval(com.pprint_thing(value), local_dict=self.env,
+                          engine=self.engine, parser=self.parser)
             v = lhs[result]
         name = self.env.add_tmp(v)
-        return Term(name, env=self.env)
+        return self.term_type(name, env=self.env)
 
     def visit_Slice(self, node, **kwargs):
         """ df.index[slice(4,6)] """
@@ -396,7 +424,7 @@ class BaseExprVisitor(ast.NodeVisitor):
             try:
                 v = getattr(resolved, attr)
                 name = self.env.add_tmp(v)
-                return Term(name, self.env)
+                return self.term_type(name, self.env)
             except AttributeError:
                 # something like datetime.datetime where scope is overriden
                 if isinstance(value, ast.Name) and value.id == attr:
@@ -432,19 +460,25 @@ class BaseExprVisitor(ast.NodeVisitor):
         if node.kwargs is not None:
             keywords.update(self.visit(node.kwargs).value)
 
-        return Constant(res(*args, **keywords), self.env)
+        return self.const_type(res(*args, **keywords), self.env)
 
     def visit_Compare(self, node, **kwargs):
         ops = node.ops
         comps = node.comparators
+
+        def translate(op):
+            if isinstance(op,ast.In):
+                return ast.Eq()
+            return op
+
         if len(comps) == 1:
-            return self.visit(ops[0])(self.visit(node.left, side='left'),
-                                      self.visit(comps[0], side='right'))
+            return self.visit(translate(ops[0]))(self.visit(node.left, side='left'),
+                                                 self.visit(comps[0], side='right'))
         left = node.left
         values = []
-        for op, comp in itertools.izip(ops, comps):
+        for op, comp in zip(ops, comps):
             new_node = self.visit(ast.Compare(comparators=[comp], left=left,
-                                              ops=[op]))
+                                              ops=[translate(op)]))
             left = comp
             values.append(new_node)
         return self.visit(ast.BoolOp(op=ast.And(), values=values))
@@ -476,32 +510,43 @@ _numexpr_supported_calls = frozenset(_reductions + _mathops)
 @disallow((_unsupported_nodes | _python_not_supported) -
           (_boolop_nodes | frozenset(['BoolOp', 'Attribute'])))
 class PandasExprVisitor(BaseExprVisitor):
-    def __init__(self, env, preparser=_replace_booleans):
-        super(PandasExprVisitor, self).__init__(env, preparser)
+    def __init__(self, env, engine, parser,
+                 preparser=lambda x: _replace_locals(_replace_booleans(x))):
+        super(PandasExprVisitor, self).__init__(env, engine, parser, preparser)
 
 
 @disallow(_unsupported_nodes | _python_not_supported | frozenset(['Not']))
 class PythonExprVisitor(BaseExprVisitor):
-    def __init__(self, env, preparser=lambda x: x):
-        super(PythonExprVisitor, self).__init__(env, preparser=preparser)
+    def __init__(self, env, engine, parser, preparser=lambda x: x):
+        super(PythonExprVisitor, self).__init__(env, engine, parser,
+                                                preparser=preparser)
 
 
 class Expr(StringMixin):
+    """Expr object holding scope
 
-    """Expr object"""
-
+    Parameters
+    ----------
+    expr : str
+    engine : str, optional, default 'numexpr'
+    parser : str, optional, default 'pandas'
+    env : Scope, optional, default None
+    truediv : bool, optional, default True
+    level : int, optional, default 2
+    """
     def __init__(self, expr, engine='numexpr', parser='pandas', env=None,
-                 truediv=True):
+                 truediv=True, level=2):
         self.expr = expr
-        self.env = _ensure_scope(level=2,local_dict=env)
-        self._visitor = _parsers[parser](self.env)
-        self.terms = self.parse()
+        self.env = _ensure_scope(level=level, local_dict=env)
         self.engine = engine
+        self.parser = parser
+        self._visitor = _parsers[parser](self.env, self.engine, self.parser)
+        self.terms = self.parse()
         self.truediv = truediv
 
-    def __call__(self, env):
-        env.locals['truediv'] = self.truediv
-        return self.terms(env)
+    def __call__(self):
+        self.env.locals['truediv'] = self.truediv
+        return self.terms(self.env)
 
     def __unicode__(self):
         return com.pprint_thing(self.terms)
@@ -510,20 +555,38 @@ class Expr(StringMixin):
         return len(self.expr)
 
     def parse(self):
-        """return a Termset"""
+        """Parse an expression"""
         return self._visitor.visit(self.expr)
 
     def align(self):
         """align a set of Terms"""
         return self.terms.align(self.env)
 
+    @property
+    def names(self):
+        """Get the names in an expression"""
+        if is_term(self.terms):
+            return frozenset([self.terms.name])
+        return frozenset(term.name for term in com.flatten(self.terms))
+
+    def check_name_clashes(self):
+        env = self.env
+        names = self.names
+        res_keys = frozenset(env.resolver_dict.iterkeys()) & names
+        lcl_keys = frozenset(env.locals.iterkeys()) & names
+        gbl_keys = frozenset(env.globals.iterkeys()) & names
+        _check_disjoint_resolver_names(res_keys, lcl_keys, gbl_keys)
+
+    def add_resolvers_to_locals(self):
+        self.env.locals.update(self.env.resolver_dict)
+
 
 _needs_filter = frozenset(['and', 'or', 'not'])
 
 
 def maybe_expression(s, kind='pandas'):
     """ loose checking if s is an expression """
-    if not isinstance(s, basestring):
+    if not isinstance(s, string_types):
         return False
     visitor = _parsers[kind]
     ops = visitor.binary_ops + visitor.unary_ops
@@ -534,15 +597,17 @@ def maybe_expression(s, kind='pandas'):
 
 
 def isexpr(s, check_names=True):
-    env = _ensure_scope()
     try:
-        Expr(s,env=env)
+        Expr(s, env=_ensure_scope() if check_names else None)
     except SyntaxError:
         return False
     except NameError:
         return not check_names
-    else:
-        return True
+    return True
+
+
+def _check_syntax(s):
+    ast.parse(s)
 
 
 _parsers = {'python': PythonExprVisitor, 'pandas': PandasExprVisitor}
diff --git a/pandas/computation/ops.py b/pandas/computation/ops.py
index d1c8484cb..c0d3c7bdd 100644
--- a/pandas/computation/ops.py
+++ b/pandas/computation/ops.py
@@ -1,10 +1,13 @@
 import operator as op
+from functools import partial
 
 import numpy as np
 
-from pandas.util.py3compat import PY3
+import pandas as pd
+from pandas.compat import PY3, string_types
 import pandas.core.common as com
 from pandas.core.base import StringMixin
+from pandas.computation.common import _ensure_decoded
 
 
 _reductions = 'sum', 'prod'
@@ -26,11 +29,12 @@ class BinaryOperatorError(OperatorError):
 
 
 class Term(StringMixin):
-    def __init__(self, name, env, side=None):
-        self.name = name
+    def __init__(self, name, env, side=None, encoding=None):
+        self._name = name
         self.env = env
         self.side = side
-        self.value = self._resolve_name()
+        self._value = self._resolve_name()
+        self.encoding = encoding
 
     def __unicode__(self):
         return com.pprint_thing(self.name)
@@ -45,7 +49,7 @@ class Term(StringMixin):
         self.update(res)
 
         if res is None:
-            if not isinstance(key, basestring):
+            if not isinstance(key, string_types):
                 return key
             raise NameError('name {0!r} is not defined'.format(key))
 
@@ -57,7 +61,7 @@ class Term(StringMixin):
     def update(self, value):
         env = self.env
         key = self.name
-        if isinstance(key, basestring):
+        if isinstance(key, string_types):
             try:
                 del env.locals[key]
                 env.locals[key] = value
@@ -76,20 +80,20 @@ class Term(StringMixin):
 
     @property
     def isscalar(self):
-        return np.isscalar(self.value)
+        return np.isscalar(self._value)
 
     @property
     def type(self):
         try:
-            # ndframe potentially very slow for large, mixed dtype frames
-            return self.value.values.dtype
+            # potentially very slow for large, mixed dtype frames
+            return self._value.values.dtype
         except AttributeError:
             try:
                 # ndarray
-                return self.value.dtype
+                return self._value.dtype
             except AttributeError:
                 # scalar
-                return type(self.value)
+                return type(self._value)
 
     return_type = type
 
@@ -99,13 +103,50 @@ class Term(StringMixin):
                                 ''.format(self.__class__.__name__, self.name,
                                           self.type))
 
+    @property
+    def kind(self):
+        try:
+            return self.type.__name__
+        except AttributeError:
+            return self.type.type.__name__
+
+    @property
+    def value(self):
+        kind = self.kind.lower()
+        if kind == 'datetime64':
+            try:
+                return self._value.asi8
+            except AttributeError:
+                return self._value.view('i8')
+        elif kind == 'datetime':
+            return pd.Timestamp(self._value)
+        elif kind == 'timestamp':
+            return self._value.asm8.view('i8')
+        return self._value
+
+    @value.setter
+    def value(self, new_value):
+        self._value = new_value
+
+    @property
+    def name(self):
+        return self._name
+
+    @name.setter
+    def name(self, new_name):
+        self._name = new_name
+
 
 class Constant(Term):
     def __init__(self, value, env):
         super(Constant, self).__init__(value, env)
 
     def _resolve_name(self):
-        return self.name
+        return self._name
+
+    @property
+    def name(self):
+        return self.value
 
 
 def _print_operand(opr):
@@ -122,6 +163,7 @@ class Op(StringMixin):
     def __init__(self, op, operands, *args, **kwargs):
         self.op = _get_op(op)
         self.operands = operands
+        self.encoding = kwargs.get('encoding', None)
 
     def __iter__(self):
         return iter(self.operands)
@@ -148,6 +190,7 @@ class Op(StringMixin):
                                                       opr in self.operands)))
         return parened
 
+
 _cmp_ops_syms = '>', '<', '>=', '<=', '==', '!='
 _cmp_ops_funcs = op.gt, op.lt, op.ge, op.le, op.eq, op.ne
 _cmp_ops_dict = dict(zip(_cmp_ops_syms, _cmp_ops_funcs))
@@ -175,16 +218,11 @@ for d in (_cmp_ops_dict, _bool_ops_dict, _arith_ops_dict):
 def _cast_inplace(terms, dtype):
     dt = np.dtype(dtype)
     for term in terms:
-        # cast all the way down the tree since operands must be
         try:
-            _cast_inplace(term.operands, dtype)
+            new_value = term.value.astype(dt)
         except AttributeError:
-            # we've bottomed out so actually do the cast
-            try:
-                new_value = term.value.astype(dt)
-            except AttributeError:
-                new_value = dt.type(term.value)
-            term.update(new_value)
+            new_value = dt.type(term.value)
+        term.update(new_value)
 
 
 def is_term(obj):
@@ -209,11 +247,13 @@ class BinOp(Op):
         self.lhs = lhs
         self.rhs = rhs
 
+        self.convert_values()
+
         try:
             self.func = _binary_ops_dict[op]
         except KeyError:
             keys = _binary_ops_dict.keys()
-            raise BinaryOperatorError('Invalid binary operator {0}, valid'
+            raise BinaryOperatorError('Invalid binary operator {0!r}, valid'
                                       ' operators are {1}'.format(op, keys))
 
     def __call__(self, env):
@@ -245,11 +285,45 @@ class BinOp(Op):
 
         return res
 
-
-class Mod(BinOp):
-    def __init__(self, lhs, rhs, *args, **kwargs):
-        super(Mod, self).__init__('%', lhs, rhs, *args, **kwargs)
-        _cast_inplace(self.operands, np.float_)
+    def convert_values(self):
+        def stringify(value):
+            if self.encoding is not None:
+                encoder = partial(com.pprint_thing_encoded,
+                                  encoding=self.encoding)
+            else:
+                encoder = com.pprint_thing
+            return encoder(value)
+
+        lhs, rhs = self.lhs, self.rhs
+
+        if (is_term(lhs) and lhs.kind.startswith('datetime') and is_term(rhs)
+            and rhs.isscalar):
+            v = rhs.value
+            if isinstance(v, (int, float)):
+                v = stringify(v)
+            v = _ensure_decoded(v)
+            v = pd.Timestamp(v)
+            if v.tz is not None:
+                v = v.tz_convert('UTC')
+            self.rhs.update(v)
+
+        if (is_term(rhs) and rhs.kind.startswith('datetime') and
+            is_term(lhs) and lhs.isscalar):
+            v = lhs.value
+            if isinstance(v, (int, float)):
+                v = stringify(v)
+            v = _ensure_decoded(v)
+            v = pd.Timestamp(v)
+            if v.tz is not None:
+                v = v.tz_convert('UTC')
+            self.lhs.update(v)
+
+
+class Div(BinOp):
+    def __init__(self, lhs, rhs, truediv=True, *args, **kwargs):
+        super(Div, self).__init__('/', lhs, rhs, *args, **kwargs)
+        if truediv or PY3:
+            _cast_inplace(com.flatten(self), np.float_)
 
 
 _unary_ops_syms = '+', '-', '~', 'not'
diff --git a/pandas/computation/pytables.py b/pandas/computation/pytables.py
index 7a4ab6e1b..2d9839736 100644
--- a/pandas/computation/pytables.py
+++ b/pandas/computation/pytables.py
@@ -6,22 +6,13 @@ import warnings
 from functools import partial
 from datetime import datetime
 
-import numpy as np
-
+import pandas as pd
+from pandas.compat import u, string_types
 import pandas.core.common as com
-import pandas.lib as lib
 from pandas.computation import expr, ops
-from pandas.computation.ops import is_term, Constant
+from pandas.computation.ops import is_term
 from pandas.computation.expr import BaseExprVisitor
-from pandas import Index
-from pandas.core.common import is_list_like
-
-
-def _ensure_decoded(s):
-    """ if we have bytes, decode them to unicode """
-    if isinstance(s, (np.bytes_, bytes)):
-        s = s.decode('UTF-8')
-    return s
+from pandas.computation.common import _ensure_decoded
 
 
 class Scope(expr.Scope):
@@ -42,7 +33,6 @@ class Term(ops.Term):
         super(Term, self).__init__(name, env, side=side)
 
     def _resolve_name(self):
-
         # must be a queryables
         if self.side == 'left':
             if self.name not in self.env.queryables:
@@ -53,6 +43,22 @@ class Term(ops.Term):
         return self.env.locals.get(self.name,
                                    self.env.globals.get(self.name, self.name))
 
+    @property
+    def value(self):
+        return self._value
+
+
+class Constant(Term):
+    def __init__(self, value, env):
+        super(Constant, self).__init__(value, env)
+
+    def _resolve_name(self):
+        return self._name
+
+    @property
+    def name(self):
+        return self._value
+
 
 class BinOp(ops.BinOp):
 
@@ -112,7 +118,7 @@ class BinOp(ops.BinOp):
 
     def conform(self, rhs):
         """ inplace conform rhs """
-        if not is_list_like(rhs):
+        if not com.is_list_like(rhs):
             rhs = [rhs]
         if hasattr(self.rhs, 'ravel'):
             rhs = rhs.ravel()
@@ -144,43 +150,48 @@ class BinOp(ops.BinOp):
         accepted by pytables """
 
         def stringify(value):
-            value = str(value)
             if self.encoding is not None:
-                value = value.encode(self.encoding)
-            return value
+                encoder = partial(com.pprint_thing_encoded,
+                                  encoding=self.encoding)
+            else:
+                encoder = com.pprint_thing
+            return encoder(value)
 
         kind = _ensure_decoded(self.kind)
-        if kind == u'datetime64' or kind == u'datetime':
-
+        if kind == u('datetime64') or kind == u('datetime'):
             if isinstance(v, (int, float)):
                 v = stringify(v)
             v = _ensure_decoded(v)
-            v = lib.Timestamp(v)
+            v = pd.Timestamp(v)
             if v.tz is not None:
                 v = v.tz_convert('UTC')
             return TermValue(v, v.value, kind)
-        elif isinstance(v, datetime) or hasattr(v, 'timetuple') or kind == u'date':
+        elif isinstance(v, datetime) or hasattr(v, 'timetuple') or kind == u('date'):
             v = time.mktime(v.timetuple())
-            return TermValue(v, lib.Timestamp(v), kind)
-        elif kind == u'integer':
+            return TermValue(v, pd.Timestamp(v), kind)
+        elif kind == u('integer'):
             v = int(float(v))
             return TermValue(v, v, kind)
-        elif kind == u'float':
+        elif kind == u('float'):
             v = float(v)
             return TermValue(v, v, kind)
-        elif kind == u'bool':
-            if isinstance(v, basestring):
-                v = not v.strip().lower() in [u'false', u'f', u'no', u'n',
-                                              u'none', u'0', u'[]', u'{}', u'']
+        elif kind == u('bool'):
+            if isinstance(v, string_types):
+                v = not v.strip().lower() in [u('false'), u('f'), u('no'),
+                                              u('n'), u('none'), u('0'),
+                                              u('[]'), u('{}'), u('')]
             else:
                 v = bool(v)
             return TermValue(v, v, kind)
-        elif not isinstance(v, basestring):
+        elif not isinstance(v, string_types):
             v = stringify(v)
-            return TermValue(v, stringify(v), u'string')
+            return TermValue(v, stringify(v), u('string'))
 
         # string quoting
-        return TermValue(v, stringify(v), u'string')
+        return TermValue(v, stringify(v), u('string'))
+
+    def convert_values(self):
+        pass
 
 
 class FilterBinOp(BinOp):
@@ -203,7 +214,7 @@ class FilterBinOp(BinOp):
 
     def evaluate(self):
 
-        if not isinstance(self.lhs, basestring):
+        if not isinstance(self.lhs, string_types):
             return self
 
         if not self.is_valid:
@@ -221,7 +232,7 @@ class FilterBinOp(BinOp):
                 self.filter = (
                     self.lhs,
                     filter_op,
-                    Index([v.value for v in values]))
+                    pd.Index([v.value for v in values]))
 
                 return self
             return None
@@ -233,7 +244,7 @@ class FilterBinOp(BinOp):
             self.filter = (
                 self.lhs,
                 filter_op,
-                Index([v.value for v in values]))
+                pd.Index([v.value for v in values]))
 
         else:
             raise TypeError(
@@ -276,7 +287,7 @@ class ConditionBinOp(BinOp):
 
     def evaluate(self):
 
-        if not isinstance(self.lhs, basestring):
+        if not isinstance(self.lhs, string_types):
             return self
 
         if not self.is_valid:
@@ -341,26 +352,26 @@ class UnaryOp(ops.UnaryOp):
 _op_classes = {'unary': UnaryOp}
 
 class ExprVisitor(BaseExprVisitor):
-    def __init__(self, env, **kwargs):
-        super(ExprVisitor, self).__init__(env)
+    const_type = Constant
+    term_type = Term
+
+    def __init__(self, env, engine, parser, **kwargs):
+        super(ExprVisitor, self).__init__(env, engine, parser)
         for bin_op in self.binary_ops:
             setattr(self, 'visit_{0}'.format(self.binary_op_nodes_map[bin_op]),
                     lambda node, bin_op=bin_op: partial(BinOp, bin_op,
                                                         **kwargs))
 
-    def visit_Name(self, node, side=None, **kwargs):
-        return Term(node.id, self.env, side=side, **kwargs)
-
     def visit_UnaryOp(self, node, **kwargs):
         if isinstance(node.op, (ast.Not, ast.Invert)):
             return UnaryOp('~', self.visit(node.operand))
         elif isinstance(node.op, ast.USub):
-            return Constant(-self.visit(node.operand).value, self.env)
+            return self.const_type(-self.visit(node.operand).value, self.env)
         elif isinstance(node.op, ast.UAdd):
             raise NotImplementedError('Unary addition not supported')
 
     def visit_USub(self, node, **kwargs):
-        return Constant(-self.visit(node.operand).value, self.env)
+        return self.const_type(-self.visit(node.operand).value, self.env)
 
     def visit_Index(self, node, **kwargs):
         return self.visit(node.value).value
@@ -369,7 +380,7 @@ class ExprVisitor(BaseExprVisitor):
         value = self.visit(node.value)
         slobj = self.visit(node.slice)
         try:
-            return Constant(value[slobj], self.env)
+            return self.const_type(value[slobj], self.env)
         except TypeError:
             raise ValueError("cannot subscript {0!r} with "
                             "{1!r}".format(value, slobj))
@@ -400,7 +411,7 @@ class Expr(expr.Expr):
     Parameters
     ----------
     where : string term expression, Expr, or list-like of Exprs
-    queryables : a kinds map (dict of column name -> kind), or None i column is non-indexable
+    queryables : a "kinds" map (dict of column name -> kind), or None if column is non-indexable
     encoding : an encoding that will encode the query terms
 
     Returns
@@ -457,6 +468,7 @@ class Expr(expr.Expr):
         if queryables is not None:
             self.env.queryables.update(queryables)
             self._visitor = ExprVisitor(self.env, queryables=queryables,
+                                        parser='pytables', engine='pytables',
                                         encoding=encoding)
             self.terms = self.parse()
 
@@ -465,7 +477,7 @@ class Expr(expr.Expr):
 
         if isinstance(w, dict):
             w, op, value = w.get('field'), w.get('op'), w.get('value')
-            if not isinstance(w, basestring):
+            if not isinstance(w, string_types):
                 raise TypeError(
                     "where must be passed as a string if op/value are passed")
             warnings.warn("passing a dict to Expr is deprecated, "
@@ -473,7 +485,7 @@ class Expr(expr.Expr):
                           DeprecationWarning)
 
         if op is not None:
-            if not isinstance(w, basestring):
+            if not isinstance(w, string_types):
                 raise TypeError(
                     "where must be passed as a string if op/value are passed")
 
@@ -493,7 +505,7 @@ class Expr(expr.Expr):
 
     def __unicode__(self):
         if self.terms is not None:
-            return unicode(self.terms)
+            return com.pprint_thing(self.terms)
         return self.expr
 
     def evaluate(self):
@@ -525,7 +537,7 @@ class TermValue(object):
     def tostring(self, encoding):
         """ quote the string if not encoded
             else encode and return """
-        if self.kind == u'string':
+        if self.kind == u('string'):
             if encoding is not None:
                 return self.converted
             return '"%s"' % self.converted
diff --git a/pandas/computation/tests/test_eval.py b/pandas/computation/tests/test_eval.py
index 1881b4716..8a8a04824 100755
--- a/pandas/computation/tests/test_eval.py
+++ b/pandas/computation/tests/test_eval.py
@@ -16,7 +16,7 @@ from numpy.testing.decorators import slow
 
 import pandas as pd
 from pandas.core import common as com
-from pandas import DataFrame, Series, Panel
+from pandas import DataFrame, Series, Panel, date_range
 from pandas.util.testing import makeCustomDataframe as mkdf
 from pandas.computation.engines import _engines
 from pandas.computation.expr import PythonExprVisitor, PandasExprVisitor
@@ -29,12 +29,11 @@ from pandas.computation.expressions import _USE_NUMEXPR
 from pandas.util.testing import (assert_frame_equal, randbool,
                                  assertRaisesRegexp,
                                  assert_produces_warning, assert_series_equal)
-from pandas.util.py3compat import PY3
+from pandas.compat import PY3, u
 
-
-def skip_numexpr_engine(engine):
+def skip_if_no_ne(engine='numexpr'):
     if not _USE_NUMEXPR and engine == 'numexpr':
-        raise nose.SkipTest("not using numexpr")
+        raise nose.SkipTest("numexpr engine not installed or disabled")
 
 
 def engine_has_neg_frac(engine):
@@ -47,8 +46,13 @@ def _eval_single_bin(lhs, cmp1, rhs, engine):
         try:
             return c(lhs, rhs)
         except ValueError as e:
-            if e.message == ('negative number cannot be raised to a '
-                             'fractional power'):
+            try:
+                msg = e.message
+            except AttributeError:
+                msg = e
+            msg = u(msg)
+            if msg == u('negative number cannot be raised to a fractional'
+                        ' power'):
                 return np.nan
             raise
     return c(lhs, rhs)
@@ -76,26 +80,27 @@ def skip_incompatible_operand(f):
     return wrapper
 
 
-_good_arith_ops = com.difference(_arith_ops_syms, _special_case_arith_ops_syms)
+def _is_py3_complex_incompat(result, expected):
+    return (PY3 and isinstance(expected, (complex, np.complexfloating)) and
+            np.isnan(result))
 
-class TestEvalPandas(unittest.TestCase):
 
+_good_arith_ops = com.difference(_arith_ops_syms, _special_case_arith_ops_syms)
+
+class TestEvalNumexprPandas(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
-        cls.cmp_ops = expr._cmp_ops_syms
-        cls.cmp2_ops = cls.cmp_ops[::-1]
-        cls.bin_ops = expr._bool_ops_syms
-        cls.special_case_ops = _special_case_arith_ops_syms
-        cls.arith_ops = _good_arith_ops
-        cls.unary_ops = '+', '-'
+        skip_if_no_ne()
+        import numexpr as ne
+        cls.ne = ne
+        cls.engine = 'numexpr'
+        cls.parser = 'pandas'
 
     @classmethod
     def tearDownClass(cls):
-        del cls.cmp_ops, cls.cmp2_ops, cls.bin_ops, cls.special_case_ops
-        del cls.arith_ops, cls.unary_ops
-
-    def set_current_engine(self):
-        self.engine = 'numexpr'
+        del cls.engine, cls.parser
+        if hasattr(cls, 'ne'):
+            del cls.ne
 
     def setup_data(self):
         nan_df1 = DataFrame(rand(10, 5))
@@ -115,20 +120,22 @@ class TestEvalPandas(unittest.TestCase):
         self.rhses = self.pandas_rhses + self.scalar_rhses + (randn(10, 5),
                                                               randn(5))
 
+    def setup_ops(self):
+        self.cmp_ops = expr._cmp_ops_syms
+        self.cmp2_ops = self.cmp_ops[::-1]
+        self.bin_ops = expr._bool_ops_syms
+        self.special_case_ops = _special_case_arith_ops_syms
+        self.arith_ops = _good_arith_ops
+        self.unary_ops = '+', '-', '~', 'not '
+
     def setUp(self):
-        try:
-            import numexpr as ne
-            self.ne = ne
-        except ImportError:
-            raise nose.SkipTest
-        self.set_current_engine()
+        self.setup_ops()
         self.setup_data()
         self.current_engines = filter(lambda x: x != self.engine, _engines)
 
     def tearDown(self):
         del self.lhses, self.rhses, self.scalar_rhses, self.scalar_lhses
-        del self.pandas_rhses, self.pandas_lhses, self.current_engines, self.ne
-        del self.engine
+        del self.pandas_rhses, self.pandas_lhses, self.current_engines
 
     @slow
     def test_complex_cmp_ops(self):
@@ -196,7 +203,7 @@ class TestEvalPandas(unittest.TestCase):
         lhs_new = _eval_single_bin(lhs, cmp1, rhs, self.engine)
         rhs_new = _eval_single_bin(lhs, cmp2, rhs, self.engine)
         expected = _eval_single_bin(lhs_new, binop, rhs_new, self.engine)
-        result = pd.eval(ex, engine=self.engine)
+        result = pd.eval(ex, engine=self.engine, parser=self.parser)
         assert_array_equal(result, expected)
 
     def check_chained_cmp_op(self, lhs, cmp1, mid, cmp2, rhs):
@@ -236,24 +243,25 @@ class TestEvalPandas(unittest.TestCase):
                 expected = _eval_single_bin(lhs_new, '&', rhs_new, self.engine)
 
                 for ex in (ex1, ex2, ex3):
-                    result = pd.eval(ex, engine=self.engine)
+                    result = pd.eval(ex, engine=self.engine,
+                                     parser=self.parser)
                     assert_array_equal(result, expected)
 
     @skip_incompatible_operand
     def check_simple_cmp_op(self, lhs, cmp1, rhs):
         ex = 'lhs {0} rhs'.format(cmp1)
         expected = _eval_single_bin(lhs, cmp1, rhs, self.engine)
-        result = pd.eval(ex, engine=self.engine)
+        result = pd.eval(ex, engine=self.engine, parser=self.parser)
         assert_array_equal(result, expected)
 
     @skip_incompatible_operand
     def check_binary_arith_op(self, lhs, arith1, rhs):
         ex = 'lhs {0} rhs'.format(arith1)
-        result = pd.eval(ex, engine=self.engine)
+        result = pd.eval(ex, engine=self.engine, parser=self.parser)
         expected = _eval_single_bin(lhs, arith1, rhs, self.engine)
         assert_array_equal(result, expected)
         ex = 'lhs {0} rhs {0} rhs'.format(arith1)
-        result = pd.eval(ex, engine=self.engine)
+        result = pd.eval(ex, engine=self.engine, parser=self.parser)
         nlhs = _eval_single_bin(lhs, arith1, rhs,
                                 self.engine)
         self.check_alignment(result, nlhs, rhs, arith1)
@@ -274,7 +282,7 @@ class TestEvalPandas(unittest.TestCase):
     @skip_incompatible_operand
     def check_modulus(self, lhs, arith1, rhs):
         ex = 'lhs {0} rhs'.format(arith1)
-        result = pd.eval(ex, engine=self.engine)
+        result = pd.eval(ex, engine=self.engine, parser=self.parser)
         expected = lhs % rhs
         assert_allclose(result, expected)
         expected = self.ne.evaluate('expected {0} rhs'.format(arith1))
@@ -285,25 +293,31 @@ class TestEvalPandas(unittest.TestCase):
         ex = 'lhs {0} rhs'.format(arith1)
 
         if self.engine == 'python':
-            res = pd.eval(ex, engine=self.engine)
+            res = pd.eval(ex, engine=self.engine, parser=self.parser)
             expected = lhs // rhs
             assert_array_equal(res, expected)
         else:
             self.assertRaises(TypeError, pd.eval, ex, local_dict={'lhs': lhs,
                                                                   'rhs': rhs},
-                              engine=self.engine)
+                              engine=self.engine, parser=self.parser)
 
     def get_expected_pow_result(self, lhs, rhs):
         try:
             expected = _eval_single_bin(lhs, '**', rhs, self.engine)
         except ValueError as e:
             msg = 'negative number cannot be raised to a fractional power'
-            if e.message == msg:
+            try:
+                emsg = e.message
+            except AttributeError:
+                emsg = e
+
+            emsg = u(emsg)
+
+            if emsg == msg:
                 if self.engine == 'python':
-                    raise nose.SkipTest(e.message)
+                    raise nose.SkipTest(emsg)
                 else:
                     expected = np.nan
-            # raise on other, possibly valid ValueErrors
             else:
                 raise
         return expected
@@ -312,14 +326,20 @@ class TestEvalPandas(unittest.TestCase):
     def check_pow(self, lhs, arith1, rhs):
         ex = 'lhs {0} rhs'.format(arith1)
         expected = self.get_expected_pow_result(lhs, rhs)
-        result = pd.eval(ex, engine=self.engine)
-        assert_array_equal(result, expected)
+        result = pd.eval(ex, engine=self.engine, parser=self.parser)
 
-        ex = '(lhs {0} rhs) {0} rhs'.format(arith1)
-        result = pd.eval(ex, engine=self.engine)
-        expected = self.get_expected_pow_result(
-            self.get_expected_pow_result(lhs, rhs), rhs)
-        assert_array_equal(result, expected)
+        if (np.isscalar(lhs) and np.isscalar(rhs) and
+            _is_py3_complex_incompat(result, expected)):
+            self.assertRaises(AssertionError, assert_array_equal, result,
+                              expected)
+        else:
+            assert_array_equal(result, expected)
+
+            ex = '(lhs {0} rhs) {0} rhs'.format(arith1)
+            result = pd.eval(ex, engine=self.engine, parser=self.parser)
+            expected = self.get_expected_pow_result(
+                self.get_expected_pow_result(lhs, rhs), rhs)
+            assert_array_equal(result, expected)
 
     @skip_incompatible_operand
     def check_single_invert_op(self, lhs, cmp1, rhs):
@@ -330,11 +350,13 @@ class TestEvalPandas(unittest.TestCase):
             except AttributeError:
                 elb = np.array([bool(el)])
             expected = ~elb
-            result = pd.eval('~elb', engine=self.engine)
+            result = pd.eval('~elb', engine=self.engine, parser=self.parser)
             assert_array_equal(expected, result)
 
             for engine in self.current_engines:
-                assert_array_equal(result, pd.eval('~elb', engine=engine))
+                skip_if_no_ne(engine)
+                assert_array_equal(result, pd.eval('~elb', engine=engine,
+                                                   parser=self.parser))
 
     @skip_incompatible_operand
     def check_compound_invert_op(self, lhs, cmp1, rhs):
@@ -343,12 +365,13 @@ class TestEvalPandas(unittest.TestCase):
         if np.isscalar(lhs) and np.isscalar(rhs):
             lhs, rhs = map(lambda x: np.array([x]), (lhs, rhs))
         expected = ~_eval_single_bin(lhs, cmp1, rhs, self.engine)
-        result = pd.eval(ex, engine=self.engine)
+        result = pd.eval(ex, engine=self.engine, parser=self.parser)
         assert_array_equal(expected, result)
 
         # make sure the other engines work the same as this one
         for engine in self.current_engines:
-            ev = pd.eval(ex, engine=self.engine)
+            skip_if_no_ne(engine)
+            ev = pd.eval(ex, engine=self.engine, parser=self.parser)
             assert_array_equal(ev, result)
 
     @skip_incompatible_operand
@@ -367,100 +390,202 @@ class TestEvalPandas(unittest.TestCase):
             expected = f(lhs.values)
         except AttributeError:
             expected = f(lhs)
-        result = pd.eval(ex, engine=self.engine)
+
+        result = pd.eval(ex, engine=self.engine, parser=self.parser)
         assert_array_equal(result, expected)
 
         for engine in self.current_engines:
-            assert_array_equal(result, pd.eval(ex, engine=engine))
+            skip_if_no_ne(engine)
+            assert_array_equal(result, pd.eval(ex, engine=engine,
+                                               parser=self.parser))
 
         ex = '{0}(lhs {1} rhs)'.format(unary_op, arith1)
-        result = pd.eval(ex, engine=self.engine)
+        result = pd.eval(ex, engine=self.engine, parser=self.parser)
 
 
-class TestEvalPython(TestEvalPandas):
+class TestEvalNumexprPython(TestEvalNumexprPandas):
+    @classmethod
+    def setUpClass(cls):
+        skip_if_no_ne()
+        import numexpr as ne
+        cls.ne = ne
+        cls.engine = 'numexpr'
+        cls.parser = 'python'
+
+    def setup_ops(self):
+        self.cmp_ops = expr._cmp_ops_syms
+        self.cmp2_ops = self.cmp_ops[::-1]
+        self.bin_ops = (s for s in expr._bool_ops_syms if s not in ('and', 'or'))
+        self.special_case_ops = _special_case_arith_ops_syms
+        self.arith_ops = _good_arith_ops
+        self.unary_ops = '+', '-', '~'
 
-    def set_current_engine(self):
-        self.engine = 'python'
+    def check_chained_cmp_op(self, lhs, cmp1, mid, cmp2, rhs):
+        ex1 = 'lhs {0} mid {1} rhs'.format(cmp1, cmp2)
+        self.assertRaises(NotImplementedError, pd.eval, ex1,
+                          local_dict={'lhs': lhs, 'mid': mid, 'rhs': rhs},
+                          engine=self.engine, parser=self.parser)
 
 
-f = lambda *args, **kwargs: np.random.randn()
+class TestEvalPythonPython(TestEvalNumexprPython):
+    @classmethod
+    def setUpClass(cls):
+        cls.engine = 'python'
+        cls.parser = 'python'
 
+    @skip_incompatible_operand
+    def check_modulus(self, lhs, arith1, rhs):
+        ex = 'lhs {0} rhs'.format(arith1)
+        result = pd.eval(ex, engine=self.engine)
+        expected = lhs % rhs
+        assert_allclose(result, expected)
+        expected = eval('expected {0} rhs'.format(arith1))
+        assert_allclose(result, expected)
 
-class TestAlignment(unittest.TestCase):
+    def check_alignment(self, result, nlhs, ghs, op):
+        try:
+            nlhs, ghs = nlhs.align(ghs)
+        except (ValueError, TypeError, AttributeError):
+            # ValueError: series frame or frame series align
+            # TypeError, AttributeError: series or frame with scalar align
+            pass
+        else:
+            expected = eval('nlhs {0} ghs'.format(op))
+            assert_array_equal(result, expected)
 
+
+class TestEvalPythonPandas(TestEvalPythonPython):
     @classmethod
     def setUpClass(cls):
-        cls.index_types = 'i', 'f', 's', 'u', 'dt', # 'p'
+        cls.engine = 'python'
+        cls.parser = 'pandas'
 
-    @classmethod
-    def tearDownClass(cls):
-        del cls.index_types
+    def check_chained_cmp_op(self, lhs, cmp1, mid, cmp2, rhs):
+        # these are not compatible operands
+        if _series_and_2d_ndarray(lhs, mid):
+            self.assertRaises(ValueError, _eval_single_bin, lhs, cmp2, mid,
+                              self.engine)
+        else:
+            lhs_new = _eval_single_bin(lhs, cmp1, mid, self.engine)
+
+        if _series_and_2d_ndarray(mid, rhs):
+            self.assertRaises(ValueError, _eval_single_bin, mid, cmp2, rhs,
+                              self.engine)
+        else:
+            rhs_new = _eval_single_bin(mid, cmp2, rhs, self.engine)
+
+        try:
+            lhs_new
+            rhs_new
+        except NameError:
+            pass
+        else:
+            # these are not compatible operands
+            if (com.is_series(lhs_new) and com.is_frame(rhs_new) or
+                _bool_and_frame(lhs_new, rhs_new)):
+                self.assertRaises(TypeError, _eval_single_bin, lhs_new, '&',
+                                  rhs_new, self.engine)
+            elif _series_and_2d_ndarray(lhs_new, rhs_new):
+                # TODO: once #4319 is fixed add this test back in
+                #self.assertRaises(Exception, _eval_single_bin, lhs_new, '&',
+                                  #rhs_new, self.engine)
+                pass
+            else:
+                ex1 = 'lhs {0} mid {1} rhs'.format(cmp1, cmp2)
+                ex2 = 'lhs {0} mid and mid {1} rhs'.format(cmp1, cmp2)
+                ex3 = '(lhs {0} mid) & (mid {1} rhs)'.format(cmp1, cmp2)
+                expected = _eval_single_bin(lhs_new, '&', rhs_new, self.engine)
 
-    def check_align_nested_unary_op(self, engine):
-        skip_numexpr_engine(engine)
+                for ex in (ex1, ex2, ex3):
+                    result = pd.eval(ex, engine=self.engine,
+                                     parser=self.parser)
+                    assert_array_equal(result, expected)
+
+
+
+f = lambda *args, **kwargs: np.random.randn()
+
+
+ENGINES_PARSERS = list(product(_engines, expr._parsers))
+
+
+#-------------------------------------
+# basic and complex alignment
+
+class TestAlignment(object):
+
+    index_types = 'i', 'f', 's', 'u', 'dt', # 'p'
+
+    def check_align_nested_unary_op(self, engine, parser):
+        skip_if_no_ne(engine)
         s = 'df * ~2'
-        df = mkdf(10, 10, data_gen_f=f)
-        res = pd.eval(s, engine=engine)
+        df = mkdf(5, 3, data_gen_f=f)
+        res = pd.eval(s, engine=engine, parser=parser)
         assert_frame_equal(res, df * ~2)
 
     def test_align_nested_unary_op(self):
-        for engine in _engines:
-            self.check_align_nested_unary_op(engine)
+        for engine, parser in ENGINES_PARSERS:
+            yield self.check_align_nested_unary_op, engine, parser
 
-    def check_basic_frame_alignment(self, engine, r_idx_type, c_idx_type):
-        df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
-                  c_idx_type=c_idx_type)
-        df2 = mkdf(20, 10, data_gen_f=f, r_idx_type=r_idx_type,
-                   c_idx_type=c_idx_type)
-        res = pd.eval('df + df2', engine=engine)
-        assert_frame_equal(res, df + df2)
+    def check_basic_frame_alignment(self, engine, parser):
+        skip_if_no_ne(engine)
+        args = product(self.index_types, repeat=2)
+        for r_idx_type, c_idx_type in args:
+            df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
+                    c_idx_type=c_idx_type)
+            df2 = mkdf(20, 10, data_gen_f=f, r_idx_type=r_idx_type,
+                    c_idx_type=c_idx_type)
+            res = pd.eval('df + df2', engine=engine, parser=parser)
+            assert_frame_equal(res, df + df2)
 
     @slow
     def test_basic_frame_alignment(self):
-        args = product(_engines, self.index_types, self.index_types)
-        for engine, r, c in args:
-            self.check_basic_frame_alignment(engine, r, c)
+        for engine, parser in ENGINES_PARSERS:
+            yield self.check_basic_frame_alignment, engine, parser
 
-    def check_frame_comparison(self, engine, r_idx_type, c_idx_type):
-        df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
-                  c_idx_type=c_idx_type)
-        res = pd.eval('df < 2', engine=engine)
-        assert_frame_equal(res, df < 2)
+    def check_frame_comparison(self, engine, parser):
+        skip_if_no_ne(engine)
+        args = product(self.index_types, repeat=2)
+        for r_idx_type, c_idx_type in args:
+            df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
+                    c_idx_type=c_idx_type)
+            res = pd.eval('df < 2', engine=engine, parser=parser)
+            assert_frame_equal(res, df < 2)
 
-        df3 = DataFrame(randn(*df.shape), index=df.index, columns=df.columns)
-        res = pd.eval('df < df3', engine=engine)
-        assert_frame_equal(res, df < df3)
+            df3 = DataFrame(randn(*df.shape), index=df.index,
+                            columns=df.columns)
+            res = pd.eval('df < df3', engine=engine, parser=parser)
+            assert_frame_equal(res, df < df3)
 
     @slow
     def test_frame_comparison(self):
-        args = product(_engines, self.index_types, self.index_types)
-        for engine, r, c in args:
-            self.check_frame_comparison(engine, r, c)
-
-    def check_medium_complex_frame_alignment(self, engine, r1, r2, c1, c2):
-        skip_numexpr_engine(engine)
-        df = mkdf(5, 2, data_gen_f=f, r_idx_type=r1, c_idx_type=c1)
-        df2 = mkdf(10, 2, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
-        df3 = mkdf(15, 2, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
-        res = pd.eval('df + df2 + df3', engine=engine)
-        assert_frame_equal(res, df + df2 + df3)
+        for engine, parser in ENGINES_PARSERS:
+            yield self.check_frame_comparison, engine, parser
+
+    def check_medium_complex_frame_alignment(self, engine, parser):
+        skip_if_no_ne(engine)
+        args = product(self.index_types, repeat=4)
+        for r1, c1, r2, c2 in args:
+            df = mkdf(5, 2, data_gen_f=f, r_idx_type=r1, c_idx_type=c1)
+            df2 = mkdf(10, 2, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
+            df3 = mkdf(15, 2, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
+            res = pd.eval('df + df2 + df3', engine=engine, parser=parser)
+            assert_frame_equal(res, df + df2 + df3)
 
     @slow
     def test_medium_complex_frame_alignment(self):
-        args = product(_engines, *([self.index_types] * 4))
-        for engine, r1, r2, c1, c2 in args:
-            self.check_medium_complex_frame_alignment(engine, r1, r2, c1, c2)
-
-    def check_basic_frame_series_alignment(self, engine, r_idx_type,
-                                           c_idx_type, index_name):
-        def testit():
-            skip_numexpr_engine(engine)
+        for engine, parser in ENGINES_PARSERS:
+            yield self.check_medium_complex_frame_alignment, engine, parser
+
+    def check_basic_frame_series_alignment(self, engine, parser):
+        skip_if_no_ne(engine)
+        def testit(r_idx_type, c_idx_type, index_name):
             df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
                     c_idx_type=c_idx_type)
             index = getattr(df, index_name)
             s = Series(np.random.randn(5), index[:5])
 
-            res = pd.eval('df + s', engine=engine)
+            res = pd.eval('df + s', engine=engine, parser=parser)
             if r_idx_type == 'dt' or c_idx_type == 'dt':
                 if engine == 'numexpr':
                     expected = df.add(s)
@@ -470,26 +595,25 @@ class TestAlignment(unittest.TestCase):
                 expected = df + s
             assert_frame_equal(res, expected)
 
-        testit()
+        args = product(self.index_types, self.index_types, ('index',
+                                                            'columns'))
+        for r_idx_type, c_idx_type, index_name in args:
+            testit(r_idx_type, c_idx_type, index_name)
 
     @slow
     def test_basic_frame_series_alignment(self):
-        args = product(_engines, self.index_types, self.index_types,
-                       ('index', 'columns'))
-        for engine, r_idx_type, c_idx_type, index_name in args:
-            self.check_basic_frame_series_alignment(engine, r_idx_type,
-                                                    c_idx_type, index_name)
-
-    def check_basic_series_frame_alignment(self, engine, r_idx_type,
-                                           c_idx_type, index_name):
-        def testit():
-            skip_numexpr_engine(engine)
+        for engine, parser in ENGINES_PARSERS:
+            yield self.check_basic_frame_series_alignment, engine, parser
+
+    def check_basic_series_frame_alignment(self, engine, parser):
+        skip_if_no_ne(engine)
+        def testit(r_idx_type, c_idx_type, index_name):
             df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
                     c_idx_type=c_idx_type)
             index = getattr(df, index_name)
             s = Series(np.random.randn(5), index[:5])
 
-            res = pd.eval('s + df', engine=engine)
+            res = pd.eval('s + df', engine=engine, parser=parser)
             if r_idx_type == 'dt' or c_idx_type == 'dt':
                 if engine == 'numexpr':
                     expected = df.add(s)
@@ -499,247 +623,237 @@ class TestAlignment(unittest.TestCase):
                 expected = s + df
             assert_frame_equal(res, expected)
 
-        testit()
+        args = product(self.index_types, self.index_types, ('index',
+                                                            'columns'))
+        for r_idx_type, c_idx_type, index_name in args:
+            testit(r_idx_type, c_idx_type, index_name)
 
     @slow
     def test_basic_series_frame_alignment(self):
-        args = product(_engines, self.index_types, self.index_types,
+        for engine, parser in ENGINES_PARSERS:
+            yield self.check_basic_series_frame_alignment, engine, parser
+
+    def check_series_frame_commutativity(self, engine, parser):
+        skip_if_no_ne(engine)
+        args = product(self.index_types, self.index_types, ('+', '*'),
                        ('index', 'columns'))
-        for engine, r_idx_type, c_idx_type, index_name in args:
-            self.check_basic_series_frame_alignment(engine, r_idx_type,
-                                                    c_idx_type, index_name)
-
-    def check_series_frame_commutativity(self, engine, r_idx_type, c_idx_type,
-                                         op, index_name):
-        skip_numexpr_engine(engine)
-        df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
-                  c_idx_type=c_idx_type)
-        index = getattr(df, index_name)
-        s = Series(np.random.randn(5), index[:5])
-
-        lhs = 's {0} df'.format(op)
-        rhs = 'df {0} s'.format(op)
-        a = pd.eval(lhs, engine=engine)
-        b = pd.eval(rhs, engine=engine)
-
-        if r_idx_type != 'dt' and c_idx_type != 'dt':
-            if engine == 'numexpr':
-                assert_frame_equal(a, b)
+        for r_idx_type, c_idx_type, op, index_name in args:
+            df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
+                    c_idx_type=c_idx_type)
+            index = getattr(df, index_name)
+            s = Series(np.random.randn(5), index[:5])
+
+            lhs = 's {0} df'.format(op)
+            rhs = 'df {0} s'.format(op)
+            a = pd.eval(lhs, engine=engine, parser=parser)
+            b = pd.eval(rhs, engine=engine, parser=parser)
+
+            if r_idx_type != 'dt' and c_idx_type != 'dt':
+                if engine == 'numexpr':
+                    assert_frame_equal(a, b)
 
     @slow
     def test_series_frame_commutativity(self):
-        args = product(_engines, self.index_types, self.index_types, ('+',
-                                                                      '*'),
-                       ('index', 'columns'))
-        for engine, r_idx_type, c_idx_type, op, index_name in args:
-            self.check_series_frame_commutativity(engine, r_idx_type,
-                                                  c_idx_type, op, index_name)
-
-    def check_complex_series_frame_alignment(self, engine, index_name, obj, r1,
-                                             r2, c1, c2):
-        skip_numexpr_engine(engine)
-        df = mkdf(10, 5, data_gen_f=f, r_idx_type=r1, c_idx_type=c1)
-        df2 = mkdf(20, 5, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
-        index = getattr(locals()[obj], index_name)
-        s = Series(np.random.randn(5), index[:5])
-
-        if r2 == 'dt' or c2 == 'dt':
-            if engine == 'numexpr':
-                expected2 = df2.add(s)
+        for engine, parser in ENGINES_PARSERS:
+            yield self.check_series_frame_commutativity, engine, parser
+
+    def check_complex_series_frame_alignment(self, engine, parser):
+        skip_if_no_ne(engine)
+        index_types = [self.index_types] * 4
+        args = product(('index', 'columns'), ('df', 'df2'), *index_types)
+        for index_name, obj, r1, r2, c1, c2 in args:
+            df = mkdf(10, 5, data_gen_f=f, r_idx_type=r1, c_idx_type=c1)
+            df2 = mkdf(20, 5, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
+            index = getattr(locals()[obj], index_name)
+            s = Series(np.random.randn(5), index[:5])
+
+            if r2 == 'dt' or c2 == 'dt':
+                if engine == 'numexpr':
+                    expected2 = df2.add(s)
+                else:
+                    expected2 = df2 + s
             else:
                 expected2 = df2 + s
-        else:
-            expected2 = df2 + s
 
-        if r1 == 'dt' or c1 == 'dt':
-            if engine == 'numexpr':
-                expected = expected2.add(df)
+            if r1 == 'dt' or c1 == 'dt':
+                if engine == 'numexpr':
+                    expected = expected2.add(df)
+                else:
+                    expected = expected2 + df
             else:
                 expected = expected2 + df
-        else:
-            expected = expected2 + df
 
-        res = pd.eval('df2 + s + df', engine=engine)
-        self.assertEqual(res.shape, expected.shape)
-        assert_frame_equal(res, expected)
+            res = pd.eval('df2 + s + df', engine=engine, parser=parser)
+            assert_equal(res.shape, expected.shape)
+            assert_frame_equal(res, expected)
 
     @slow
     def test_complex_series_frame_alignment(self):
-        index_types = [self.index_types] * 4
-        args = product(_engines, ('index', 'columns'), ('df', 'df2'),
-                       *index_types)
-        for engine, index_name, obj, r1, r2, c1, c2 in args:
-            self.check_complex_series_frame_alignment(engine, index_name, obj,
-                                                      r1, r2, c1, c2)
+        for engine, parser in ENGINES_PARSERS:
+            yield self.check_complex_series_frame_alignment, engine, parser
 
-    @slow
-    def test_performance_warning_for_asenine_alignment(self):
+    def check_performance_warning_for_asenine_alignment(self, engine, parser):
+        skip_if_no_ne(engine)
         df = DataFrame(randn(1000, 10))
         s = Series(randn(10000))
-        with assert_produces_warning(pd.io.common.PerformanceWarning):
-            pd.eval('df + s')
+        if engine == 'numexpr':
+            seen = pd.io.common.PerformanceWarning
+        else:
+            seen = False
+
+        with assert_produces_warning(seen):
+            pd.eval('df + s', engine=engine, parser=parser)
 
         s = Series(randn(1000))
         with assert_produces_warning(False):
-            pd.eval('df + s')
+            pd.eval('df + s', engine=engine, parser=parser)
 
         df = DataFrame(randn(10, 10000))
         s = Series(randn(10000))
         with assert_produces_warning(False):
-            pd.eval('df + s')
+            pd.eval('df + s', engine=engine, parser=parser)
+
+    def test_performance_warning_for_asenine_alignment(self):
+        for engine, parser in ENGINES_PARSERS:
+            yield self.check_performance_warning_for_asenine_alignment, engine, parser
 
 
-class TestOperations(unittest.TestCase):
+#------------------------------------
+# slightly more complex ops
 
-    def check_simple_arith_ops(self, engine):
+class TestOperationsNumExprPandas(unittest.TestCase):
+    @classmethod
+    def setUpClass(cls):
+        skip_if_no_ne()
+        cls.engine = 'numexpr'
+        cls.parser = 'pandas'
+
+    @classmethod
+    def tearDownClass(cls):
+        del cls.engine, cls.parser
+
+    def eval(self, *args, **kwargs):
+        kwargs['engine'] = self.engine
+        kwargs['parser'] = self.parser
+        return pd.eval(*args, **kwargs)
+
+    def test_simple_arith_ops(self):
         ops = expr._arith_ops_syms + expr._cmp_ops_syms
 
         for op in filter(lambda x: x != '//', ops):
-            expec = _eval_single_bin(1, op, 1, engine)
-            x = pd.eval('1 {0} 1'.format(op), engine=engine)
+            expec = _eval_single_bin(1, op, 1, self.engine)
+            x = self.eval('1 {0} 1'.format(op))
             assert_equal(x, expec)
 
-            expec = _eval_single_bin(x, op, 1, engine)
-            y = pd.eval('x {0} 1'.format(op), engine=engine)
+            expec = _eval_single_bin(x, op, 1, self.engine)
+            y = self.eval('x {0} 1'.format(op), local_dict={'x': x})
             assert_equal(y, expec)
 
-            expec = _eval_single_bin(1, op, x + 1, engine)
-            y = pd.eval('1 {0} (x + 1)'.format(op), engine=engine)
+            expec = _eval_single_bin(1, op, x + 1, self.engine)
+            y = self.eval('1 {0} (x + 1)'.format(op), local_dict={'x': x})
             assert_equal(y, expec)
 
-    def check_simple_bool_ops(self, engine):
+    def test_simple_bool_ops(self):
         for op, lhs, rhs in product(expr._bool_ops_syms, (True, False), (True,
                                                                         False)):
-            expec = _eval_single_bin(lhs, op, rhs, engine)
-            x = pd.eval('lhs {0} rhs'.format(op), engine=engine)
+            expec = _eval_single_bin(lhs, op, rhs, self.engine)
+            x = self.eval('lhs {0} rhs'.format(op), local_dict={'lhs': lhs,
+                                                                'rhs': rhs})
             assert_equal(x, expec)
 
-    def check_bool_ops_with_constants(self, engine):
+    def test_bool_ops_with_constants(self):
         asteval = ast.literal_eval
         for op, lhs, rhs in product(expr._bool_ops_syms, ('True', 'False'),
                                     ('True', 'False')):
-            expec = _eval_single_bin(asteval(lhs), op, asteval(rhs), engine)
-            x = pd.eval('{0} {1} {2}'.format(lhs, op, rhs), engine=engine)
+            expec = _eval_single_bin(asteval(lhs), op, asteval(rhs),
+                                     self.engine)
+            x = self.eval('{0} {1} {2}'.format(lhs, op, rhs),
+                          local_dict={'lhs': lhs, 'rhs': rhs})
             assert_equal(x, expec)
 
-    def test_simple_arith_ops(self):
-        for engine in _engines:
-            self.check_simple_arith_ops(engine)
-
-    def test_simple_bool_ops(self):
-        for engine in _engines:
-            self.check_simple_bool_ops(engine)
-
-    def test_bool_ops_with_constants(self):
-        for engine in _engines:
-            self.check_bool_ops_with_constants(engine)
-
-    def check_panel_fails(self, engine):
+    def test_panel_fails(self):
         x = Panel(randn(3, 4, 5))
         y = Series(randn(10))
-        assert_raises(NotImplementedError, pd.eval, 'x + y',
-                      local_dict={'x': x, 'y': y}, engine=engine)
-
-    def test_panel_fails(self):
-        for engine in _engines:
-            self.check_panel_fails(engine)
+        assert_raises(NotImplementedError, self.eval, 'x + y',
+                      local_dict={'x': x, 'y': y})
 
-    def check_4d_ndarray_fails(self, engine):
+    def test_4d_ndarray_fails(self):
         x = randn(3, 4, 5, 6)
         y = Series(randn(10))
-        assert_raises(NotImplementedError, pd.eval, 'x + y', local_dict={'x': x,
-                                                                        'y': y},
-                    engine=engine)
-
-    def test_4d_ndarray_fails(self):
-        for engine in _engines:
-            self.check_4d_ndarray_fails(engine)
-
-    def check_constant(self, engine):
-        x = pd.eval('1', engine=engine)
-        assert_equal(x, 1)
+        assert_raises(NotImplementedError, self.eval, 'x + y',
+                      local_dict={'x': x, 'y': y})
 
     def test_constant(self):
-        for engine in _engines:
-            self.check_constant(engine)
+        x = self.eval('1')
+        assert_equal(x, 1)
 
-    def check_single_variable(self, engine):
+    def test_single_variable(self):
         df = DataFrame(randn(10, 2))
-        df2 = pd.eval('df', engine=engine)
+        df2 = self.eval('df', local_dict={'df': df})
         assert_frame_equal(df, df2)
 
-    def test_single_variable(self):
-        for engine in _engines:
-            self.check_single_variable(engine)
-
     def test_truediv(self):
-        for engine in _engines:
-            self.check_truediv(engine)
-
-    def check_truediv(self, engine):
         s = np.array([1])
         ex = 's / 1'
+        d = {'s': s}
 
         if PY3:
-            res = pd.eval(ex, truediv=False)
+            res = self.eval(ex, truediv=False, local_dict=d)
             assert_array_equal(res, np.array([1.0]))
 
-            res = pd.eval(ex, truediv=True)
+            res = self.eval(ex, truediv=True, local_dict=d)
             assert_array_equal(res, np.array([1.0]))
+
+            res = self.eval('1 / 2', truediv=True)
+            expec = 0.5
+            self.assertEqual(res, expec)
+
+            res = self.eval('1 / 2', truediv=False)
+            expec = 0.5
+            self.assertEqual(res, expec)
+
+            res = self.eval('s / 2', truediv=False, local_dict={'s': s})
+            expec = 0.5
+            self.assertEqual(res, expec)
+
+            res = self.eval('s / 2', truediv=True, local_dict={'s': s})
+            expec = 0.5
+            self.assertEqual(res, expec)
         else:
-            res = pd.eval(ex, truediv=False)
+            res = self.eval(ex, truediv=False, local_dict=d)
             assert_array_equal(res, np.array([1]))
 
-            res = pd.eval(ex, truediv=True)
+            res = self.eval(ex, truediv=True, local_dict=d)
             assert_array_equal(res, np.array([1.0]))
 
-    def test_python_fails_and(self):
-        df = DataFrame(np.random.randn(5, 3))
-        self.assertRaises(NotImplementedError, pd.eval, 'df > 2 and df > 3',
-                          local_dict={'df': df}, parser='python')
-
-    def test_python_fails_or(self):
-        df = DataFrame(np.random.randn(5, 3))
-        self.assertRaises(NotImplementedError, pd.eval, 'df > 2 or df > 3',
-                          local_dict={'df': df}, parser='python')
+            res = self.eval('1 / 2', truediv=True)
+            expec = 0.5
+            self.assertEqual(res, expec)
 
-    def test_python_fails_not(self):
-        df = DataFrame(np.random.randn(5, 3))
-        self.assertRaises(NotImplementedError, pd.eval, 'not df > 2',
-                          local_dict={'df': df}, parser='python')
+            res = self.eval('1 / 2', truediv=False)
+            expec = 0
+            self.assertEqual(res, expec)
 
-    def test_python_fails_ampersand(self):
-        df = DataFrame(np.random.randn(5, 3))
-        self.assertRaises(TypeError, pd.eval,
-                          '(df + 2)[df > 1] > 0 & (df > 0)',
-                          local_dict={'df': df}, parser='python')
-
-    def test_python_fails_pipe(self):
-        df = DataFrame(np.random.randn(5, 3))
-        self.assertRaises(TypeError, pd.eval,
-                          '(df + 2)[df > 1] > 0 | (df > 0)',
-                          local_dict={'df': df}, parser='python')
+            res = self.eval('s / 2', truediv=False, local_dict={'s': s})
+            expec = 0
+            self.assertEqual(res, expec)
 
-    def check_failing_subscript_with_name_error(self, engine):
-        df = DataFrame(np.random.randn(5, 3))
-        self.assertRaises(NameError, pd.eval, 'df[x > 2] > 2',
-                          local_dict={'df': df}, engine=engine)
+            res = self.eval('s / 2', truediv=True, local_dict={'s': s})
+            expec = 0.5
+            self.assertEqual(res, expec)
 
     def test_failing_subscript_with_name_error(self):
-        for engine in _engines:
-            self.check_failing_subscript_with_name_error(engine)
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(NameError, self.eval, 'df[x > 2] > 2',
+                          local_dict={'df': df})
 
-    def check_lhs_expression_subscript(self, engine):
+    def test_lhs_expression_subscript(self):
         df = DataFrame(np.random.randn(5, 3))
-        result = pd.eval('(df + 1)[df > 2]', engine=engine)
+        result = self.eval('(df + 1)[df > 2]', local_dict={'df': df})
         expected = (df + 1)[df > 2]
         assert_frame_equal(result, expected)
 
-    def test_lhs_expression_subscript(self):
-        for engine in _engines:
-            self.check_lhs_expression_subscript(engine)
-
-    def check_attr_expression(self, engine):
+    def test_attr_expression(self):
         df = DataFrame(np.random.randn(5, 3), columns=list('abc'))
         expr1 = 'df.a < df.b'
         expec1 = df.a < df.b
@@ -750,197 +864,265 @@ class TestOperations(unittest.TestCase):
         exprs = expr1, expr2, expr3
         expecs = expec1, expec2, expec3
         for e, expec in zip(exprs, expecs):
-            assert_series_equal(expec, pd.eval(e, engine=engine))
+            assert_series_equal(expec, self.eval(e, local_dict={'df': df}))
 
-    def test_attr_expression(self):
-        for engine in _engines:
-            self.check_attr_expression(engine)
-
-    def check_assignment_fails(self, engine, parser):
+    def test_assignment_fails(self):
         df = DataFrame(np.random.randn(5, 3), columns=list('abc'))
         df2 = DataFrame(np.random.randn(5, 3))
         expr1 = 'df = df2'
-        self.assertRaises(NotImplementedError, pd.eval, expr1,
-                          local_dict={'df': df, 'df2': df2}, engine=engine,
-                          parser=parser)
+        self.assertRaises(NotImplementedError, self.eval, expr1,
+                          local_dict={'df': df, 'df2': df2})
 
-    def test_assignment_fails(self):
-        for engine, parser in product(_engines.iterkeys(), ('pandas',
-                                                            'python')):
-            self.check_assignment_fails(engine, parser)
-
-    def check_basic_period_index_boolean_expression(self, engine):
+    def test_basic_period_index_boolean_expression(self):
         df = mkdf(2, 2, data_gen_f=f, c_idx_type='p', r_idx_type='i')
 
         e = df < 2
-        r = pd.eval('df < 2', engine=engine)
+        r = self.eval('df < 2', local_dict={'df': df})
         x = df < 2
 
         assert_frame_equal(r, e)
         assert_frame_equal(x, e)
 
-    def test_basic_period_index_expression_python(self):
-        for engine in _engines:
-            self.check_basic_period_index_boolean_expression(engine)
-
-    def check_basic_period_index_subscript_expression(self, engine):
+    def test_basic_period_index_subscript_expression(self):
         df = mkdf(2, 2, data_gen_f=f, c_idx_type='p', r_idx_type='i')
-        r = pd.eval('df[df < 2 + 3]', engine=engine)
+        r = self.eval('df[df < 2 + 3]', local_dict={'df': df})
         e = df[df < 2 + 3]
         assert_frame_equal(r, e)
 
-    def test_basic_period_index_subscript_expression(self):
-        for engine in _engines:
-            self.check_basic_period_index_subscript_expression(engine)
-
-    def check_nested_period_index_subscript_expression(self, engine):
+    def test_nested_period_index_subscript_expression(self):
         df = mkdf(2, 2, data_gen_f=f, c_idx_type='p', r_idx_type='i')
-        r = pd.eval('df[df[df < 2] < 2] + df * 2', engine=engine)
+        r = self.eval('df[df[df < 2] < 2] + df * 2', local_dict={'df': df})
         e = df[df[df < 2] < 2] + df * 2
         assert_frame_equal(r, e)
 
-    def test_nested_period_index_subscript_expression(self):
-        for engine in _engines:
-            self.check_nested_period_index_subscript_expression(engine)
-
-    def test_simple_not_expression(self):
-        df = DataFrame(randn(10, 3), columns=list('abc'))
-        df['bools'] = rand(len(df)) > 0.5
-        res = df['not bools']
-        res2 = df['~bools']
-        expec = df[~df.bools]
-        assert_frame_equal(res, expec)
-        assert_frame_equal(res2, expec)
-
-    def test_complex_boolean_expression(self):
-        df = DataFrame(randn(10, 3), columns=list('abc'))
-        df['bools'] = rand(len(df)) > 0.5
-        res = df['a < b < c and (not bools) or bools > 2']
-        expec = df[(df.a < df.b) & (df.b < df.c) & (~df.bools) | (df.bools > 2)]
-        assert_frame_equal(res, expec)
+    def test_date_boolean(self):
+        df = DataFrame(randn(5, 3))
+        df['dates1'] = date_range('1/1/2012', periods=5)
+        res = self.eval('df.dates1 < 20130101', local_dict={'df': df})
+        expec = df.dates1 < '20130101'
+        assert_series_equal(res, expec)
+
+
+class TestOperationsNumExprPython(TestOperationsNumExprPandas):
+    @classmethod
+    def setUpClass(cls):
+        if not _USE_NUMEXPR:
+            raise nose.SkipTest("numexpr engine not installed")
+        cls.engine = 'numexpr'
+        cls.parser = 'python'
+
+    def test_fails_and(self):
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(NotImplementedError, pd.eval, 'df > 2 and df > 3',
+                          local_dict={'df': df}, parser=self.parser,
+                          engine=self.engine)
+
+    def test_fails_or(self):
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(NotImplementedError, pd.eval, 'df > 2 or df > 3',
+                          local_dict={'df': df}, parser=self.parser,
+                          engine=self.engine)
+
+    def test_fails_not(self):
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(NotImplementedError, pd.eval, 'not df > 2',
+                          local_dict={'df': df}, parser=self.parser,
+                          engine=self.engine)
+
+    def test_fails_ampersand(self):
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(TypeError, pd.eval,
+                          '(df + 2)[df > 1] > 0 & (df > 0)',
+                          local_dict={'df': df}, parser=self.parser,
+                          engine=self.engine)
+
+    def test_fails_pipe(self):
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(TypeError, pd.eval,
+                          '(df + 2)[df > 1] > 0 | (df > 0)',
+                          local_dict={'df': df}, parser=self.parser,
+                          engine=self.engine)
+
+    def test_bool_ops_with_constants(self):
+        from ast import literal_eval as asteval
+        for op, lhs, rhs in product(expr._bool_ops_syms, ('True', 'False'),
+                                    ('True', 'False')):
+            if op not in ('and', 'or'):
+                expec = _eval_single_bin(asteval(lhs), op, asteval(rhs),
+                                        self.engine)
+                x = self.eval('{0} {1} {2}'.format(lhs, op, rhs),
+                            local_dict={'lhs': lhs, 'rhs': rhs})
+                assert_equal(x, expec)
+            else:
+                self.assertRaises(NotImplementedError,
+                                  self.eval,
+                                  '{0} {1} {2}'.format(lhs, op, rhs),
+                                  local_dict={'lhs': lhs, 'rhs': rhs})
+
+    def test_simple_bool_ops(self):
+        for op, lhs, rhs in product(expr._bool_ops_syms, (True, False), (True,
+                                                                        False)):
+            if op not in ('and', 'or'):
+                expec = _eval_single_bin(lhs, op, rhs, self.engine)
+                x = self.eval('lhs {0} rhs'.format(op), local_dict={'lhs': lhs,
+                                                                    'rhs': rhs})
+                assert_equal(x, expec)
+            else:
+                self.assertRaises(NotImplementedError,
+                                  self.eval,
+                                  'lhs {0} rhs'.format(op),
+                                  local_dict={'lhs': lhs, 'rhs': rhs})
+
+
+class TestOperationsPythonPython(TestOperationsNumExprPython):
+    @classmethod
+    def setUpClass(cls):
+        cls.engine = cls.parser = 'python'
+
+    def test_fails_ampersand(self):
+        raise nose.SkipTest("known failer for now")
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(TypeError, pd.eval,
+                          '(df + 2)[df > 1] > 0 & (df > 0)',
+                          local_dict={'df': df}, parser=self.parser,
+                          engine=self.engine)
+
+    def test_fails_pipe(self):
+        raise nose.SkipTest("known failer for now")
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(TypeError, pd.eval,
+                          '(df + 2)[df > 1] > 0 | (df > 0)',
+                          local_dict={'df': df}, parser=self.parser,
+                          engine=self.engine)
+
+
+class TestOperationsPythonPandas(TestOperationsNumExprPandas):
+    @classmethod
+    def setUpClass(cls):
+        cls.engine = 'python'
+        cls.parser = 'pandas'
+
 
 _var_s = randn(10)
 
-class TestScope(unittest.TestCase):
 
-    def check_global_scope(self, engine):
-        e = '_var_s * 2'
-        assert_array_equal(_var_s * 2, pd.eval(e, engine=engine))
+class TestScope(object):
+    def check_global_scope(self, e, engine, parser):
+        skip_if_no_ne(engine)
+        assert_array_equal(_var_s * 2, pd.eval(e, engine=engine,
+                                               parser=parser))
 
     def test_global_scope(self):
-        for engine in _engines:
-            self.check_global_scope(engine)
+        e = '_var_s * 2'
+        for engine, parser in product(_engines, expr._parsers):
+            yield self.check_global_scope, e, engine, parser
 
-    def check_no_new_locals(self, engine):
+    def check_no_new_locals(self, engine, parser):
+        skip_if_no_ne(engine)
         x = 1
         lcls = locals().copy()
-        pd.eval('x + 1', local_dict=lcls)
+        pd.eval('x + 1', local_dict=lcls, engine=engine, parser=parser)
         lcls2 = locals().copy()
         lcls2.pop('lcls')
         assert_equal(lcls, lcls2)
 
     def test_no_new_locals(self):
-        for engine in _engines:
-            self.check_no_new_locals(engine)
+        for engine, parser in product(_engines, expr._parsers):
+            yield self.check_no_new_locals, engine, parser
 
-    def check_no_new_globals(self, engine):
+    def check_no_new_globals(self, engine, parser):
+        skip_if_no_ne(engine)
         x = 1
         gbls = globals().copy()
-        pd.eval('x + 1')
+        pd.eval('x + 1', engine=engine, parser=parser)
         gbls2 = globals().copy()
         assert_equal(gbls, gbls2)
 
     def test_no_new_globals(self):
-        for engine in _engines:
-            self.check_no_new_globals(engine)
-
-    def check_nested_scope(self, engine):
-        # smoke test
-        x = 1
-        result = pd.eval('x + 1', engine=engine)
-        self.assertEqual(result, 2)
-
-        df  = DataFrame(np.random.randn(5, 3))
-        df2 = DataFrame(np.random.randn(5, 3))
-        expected = df[(df>0) & (df2>0)]
-
-        result = df['(df>0) & (df2>0)']
-        assert_frame_equal(result, expected)
-
-        result = df.query('(df>0) & (df2>0)', engine=engine)
-        assert_frame_equal(result, expected)
-
-        result = pd.eval('df[(df > 0) and (df2 > 0)]', engine=engine)
-        assert_frame_equal(result, expected)
-
-        result = pd.eval('df[(df > 0) and (df2 > 0) and df[df > 0] > 0]', engine=engine)
-        expected = df[(df > 0) & (df2 > 0) & (df[df > 0] > 0)]
-        assert_frame_equal(result, expected)
-
-        result = pd.eval('df[(df>0) & (df2>0)]',engine=engine)
-        expected = df.query('(df>0) & (df2>0)', engine=engine)
-        assert_frame_equal(result, expected)
-
-    def test_nested_scope(self):
-        for engine in _engines:
-            self.check_nested_scope(engine)
+        for engine, parser in product(_engines, expr._parsers):
+            yield self.check_no_new_globals, engine, parser
 
 
 def test_invalid_engine():
+    skip_if_no_ne()
     assertRaisesRegexp(KeyError, 'Invalid engine \'asdf\' passed',
                        pd.eval, 'x + y', local_dict={'x': 1, 'y': 2},
                        engine='asdf')
 
 
 def test_invalid_parser():
+    skip_if_no_ne()
     assertRaisesRegexp(KeyError, 'Invalid parser \'asdf\' passed',
                        pd.eval, 'x + y', local_dict={'x': 1, 'y': 2},
                        parser='asdf')
 
 
-def check_is_expr(engine):
+def check_is_expr_syntax(engine):
+    skip_if_no_ne(engine)
     s = 1
-    valid = 's + 1'
-    invalid = 's +'
+    valid1 = 's + 1'
+    valid2 = '__y + _xx'
+    assert_true(expr.isexpr(valid1, check_names=False))
+    assert_true(expr.isexpr(valid2, check_names=False))
+
+
+def check_is_expr_names(engine):
+    skip_if_no_ne(engine)
+    r, s = 1, 2
+    valid = 's + r'
+    invalid = '__y + __x'
     assert_true(expr.isexpr(valid, check_names=True))
-    assert_true(expr.isexpr(valid, check_names=False))
-    assert_false(expr.isexpr(invalid, check_names=False))
     assert_false(expr.isexpr(invalid, check_names=True))
 
 
-def test_is_expr():
+def test_is_expr_syntax():
     for engine in _engines:
-        check_is_expr(engine)
+        yield check_is_expr_syntax, engine
+
+
+def test_is_expr_names():
+    for engine in _engines:
+        yield check_is_expr_names, engine
 
 
 _parsers = {'python': PythonExprVisitor, 'pytables': pytables.ExprVisitor,
             'pandas': PandasExprVisitor}
 
-def check_disallowed_nodes(visitor):
-    """make sure the disallowed decorator works"""
-    VisitorClass = _parsers[visitor]
+def check_disallowed_nodes(engine, parser):
+    skip_if_no_ne(engine)
+    VisitorClass = _parsers[parser]
     uns_ops = VisitorClass.unsupported_nodes
-    inst = VisitorClass('x + 1')
+    inst = VisitorClass('x + 1', engine, parser)
 
     for ops in uns_ops:
         assert_raises(NotImplementedError, getattr(inst, ops))
 
 
 def test_disallowed_nodes():
-    for visitor in _parsers:
-        check_disallowed_nodes(visitor)
+    for engine, visitor in product(_parsers, repeat=2):
+        yield check_disallowed_nodes, engine, visitor
+
+
+def check_syntax_error_exprs(engine, parser):
+    skip_if_no_ne(engine)
+    e = 's +'
+    assert_raises(SyntaxError, pd.eval, e, engine=engine, parser=parser)
 
 
 def test_syntax_error_exprs():
-    for engine in _engines:
-        e = 's +'
-        assert_raises(SyntaxError, pd.eval, e, engine=engine)
+    for engine, parser in ENGINES_PARSERS:
+        yield check_syntax_error_exprs, engine, parser
+
+
+def check_name_error_exprs(engine, parser):
+    skip_if_no_ne(engine)
+    e = 's + t'
+    assert_raises(NameError, pd.eval, e, engine=engine, parser=parser)
 
 
 def test_name_error_exprs():
-    for engine in _engines:
-        e = 's + t'
-        assert_raises(NameError, pd.eval, e, engine=engine)
+    for engine, parser in ENGINES_PARSERS:
+        yield check_name_error_exprs, engine, parser
 
 
 if __name__ == '__main__':
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 757d3eb6f..8ada14485 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -9,8 +9,11 @@ import codecs
 import csv
 import sys
 
+from distutils.version import LooseVersion
+
 from numpy.lib.format import read_array, write_array
 import numpy as np
+
 import pandas.algos as algos
 import pandas.lib as lib
 import pandas.tslib as tslib
@@ -227,6 +230,21 @@ def notnull(obj):
 
 
 def flatten(l):
+    """Flatten an arbitrarily nested sequence.
+
+    Parameters
+    ----------
+    l : sequence
+        The non string sequence to flatten
+
+    Notes
+    -----
+    This doesn't consider strings sequences.
+
+    Returns
+    -------
+    flattened : generator
+    """
     for el in l:
         if isinstance(el, collections.Iterable) and not is_string(el):
             for s in flatten(el):
@@ -1669,7 +1687,7 @@ def is_bool(obj):
 
 
 def is_string(obj):
-    return isinstance(obj, basestring)
+    return isinstance(obj, string_types)
 
 
 def is_series(obj):
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 3695a994b..374436313 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -2,12 +2,9 @@
 High level interface to PyTables for reading and writing pandas data structures
 to disk
 """
-from __future__ import print_function
 
 # pylint: disable-msg=E1101,W0613,W0603
 from datetime import datetime, date
-from pandas.compat import map, range, zip, lrange, lmap, u
-from pandas import compat
 import time
 import re
 import copy
@@ -22,7 +19,7 @@ from pandas.sparse.api import SparseSeries, SparseDataFrame, SparsePanel
 from pandas.sparse.array import BlockIndex, IntIndex
 from pandas.tseries.api import PeriodIndex, DatetimeIndex
 from pandas.core.base import StringMixin
-from pandas.core.common import adjoin, is_list_like, pprint_thing
+from pandas.core.common import adjoin, pprint_thing
 from pandas.core.algorithms import match, unique
 from pandas.core.categorical import Categorical
 from pandas.core.common import _asarray_tuplesafe
@@ -32,6 +29,8 @@ from pandas.core.index import _ensure_index
 from pandas.tseries.timedeltas import _coerce_scalar_to_timedelta_type
 import pandas.core.common as com
 from pandas.tools.merge import concat
+from pandas import compat
+from pandas.compat import u, PY3, range
 from pandas.io.common import PerformanceWarning
 from pandas.core.config import get_option
 from pandas.computation.pytables import Expr
@@ -59,7 +58,7 @@ def _ensure_decoded(s):
 def _ensure_encoding(encoding):
     # set the encoding if we need
     if encoding is None:
-        if compat.PY3:
+        if PY3:
             encoding = _default_encoding
     return encoding
 
@@ -264,7 +263,8 @@ def to_hdf(path_or_buf, key, value, mode=None, complevel=None, complib=None,
         f = lambda store: store.put(key, value, **kwargs)
 
     if isinstance(path_or_buf, compat.string_types):
-        with get_store(path_or_buf, mode=mode, complevel=complevel, complib=complib) as store:
+        with get_store(path_or_buf, mode=mode, complevel=complevel,
+                       complib=complib) as store:
             f(store)
     else:
         f(path_or_buf)
@@ -499,7 +499,7 @@ class HDFStore(StringMixin):
             self._handle = h5_open(self._path, self._mode)
         except IOError as e:  # pragma: no cover
             if 'can not be written' in str(e):
-                print('Opening %s in read-only mode' % self._path)
+                print ('Opening %s in read-only mode' % self._path)
                 self._handle = h5_open(self._path, 'r')
             else:
                 raise
@@ -654,7 +654,9 @@ class HDFStore(StringMixin):
         if isinstance(keys, (list, tuple)) and len(keys) == 1:
             keys = keys[0]
         if isinstance(keys, compat.string_types):
-            return self.select(key=keys, where=where, columns=columns, start=start, stop=stop, iterator=iterator, chunksize=chunksize, **kwargs)
+            return self.select(key=keys, where=where, columns=columns,
+                               start=start, stop=stop, iterator=iterator,
+                               chunksize=chunksize, **kwargs)
 
         if not isinstance(keys, (list, tuple)):
             raise TypeError("keys must be a list/tuple")
@@ -1537,7 +1539,7 @@ class DataCol(IndexCol):
         super(DataCol, self).__init__(
             values=values, kind=kind, typ=typ, cname=cname, **kwargs)
         self.dtype = None
-        self.dtype_attr = u("%s_dtype") % self.name
+        self.dtype_attr = u("%s_dtype" % self.name)
         self.set_data(data)
 
     def __unicode__(self):
@@ -3474,15 +3476,14 @@ class AppendableTable(LegacyTable):
             rows = rows[~mask.ravel().astype(bool)]
 
         except Exception as detail:
-            raise Exception("cannot create row-data -> %s" % str(detail))
+            raise Exception("cannot create row-data -> %s" % detail)
 
         try:
             if len(rows):
                 self.table.append(rows)
                 self.table.flush()
         except Exception as detail:
-            raise Exception(
-                "tables cannot write this data -> %s" % str(detail))
+            raise TypeError("tables cannot write this data -> %s" % detail)
 
     def delete(self, where=None, **kwargs):
 
@@ -3526,7 +3527,7 @@ class AppendableTable(LegacyTable):
             # we must remove in reverse order!
             pg = groups.pop()
             for g in reversed(groups):
-                rows = l.take(lrange(g, pg))
+                rows = l.take(range(g, pg))
                 table.removeRows(start=rows[rows.index[0]
                                             ], stop=rows[rows.index[-1]] + 1)
                 pg = g
@@ -4239,19 +4240,7 @@ class Selection(object):
         if where is None:
             return None
 
-        if not isinstance(where, (list, tuple)):
-            where = [where]
-        else:
-
-            # make this a list of we think that we only have a sigle term & no
-            # operands inside any terms
-            if not any([isinstance(w, (list, tuple, Term)) for w in where]):
-
-                if not any([isinstance(w, compat.string_types) and Term._search.match(w) for w in where]):
-                    where = [where]
-
-        queryables = self.table.queryables()
-        return [Term(c, queryables=queryables, encoding=self.table.encoding) for c in where]
+        return Expr(where, queryables=self.table.queryables(), encoding=self.table.encoding)
 
     def select(self):
         """
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index dfcbf0a98..b13c8e83d 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -1,5 +1,3 @@
-from __future__ import print_function
-from pandas.compat import range, lrange, u
 import nose
 import unittest
 import sys
@@ -24,8 +22,8 @@ from pandas.util.testing import (assert_panel4d_equal,
                                  assert_series_equal)
 from pandas import concat, Timestamp
 from pandas import compat, _np_version_under1p7
-from pandas.core import common as com
-
+from pandas.compat import range, lrange, u
+from pandas.util.testing import assert_produces_warning
 
 try:
     import tables
@@ -752,7 +750,7 @@ class TestHDFStore(unittest.TestCase):
             raise nose.SkipTest('system byteorder is not little, skipping test_encoding!')
 
         with ensure_clean(self.path) as store:
-            df = DataFrame(dict(A='foo',B='bar'),index=lrange(5))
+            df = DataFrame(dict(A='foo',B='bar'),index=range(5))
             df.loc[2,'A'] = np.nan
             df.loc[3,'B'] = np.nan
             _maybe_remove(store, 'df')
@@ -906,7 +904,7 @@ class TestHDFStore(unittest.TestCase):
             for i in range(10):
 
                 df = DataFrame(np.random.randn(10,2),columns=list('AB'))
-                df['index'] = lrange(10)
+                df['index'] = range(10)
                 df['index'] += i*10
                 df['int64'] = Series([1]*len(df),dtype='int64')
                 df['int16'] = Series([1]*len(df),dtype='int16')
@@ -1082,7 +1080,7 @@ class TestHDFStore(unittest.TestCase):
             def check_col(key,name,size):
                 self.assert_(getattr(store.get_storer(key).table.description,name).itemsize == size)
 
-            df = DataFrame(dict(A = 'foo', B = 'bar'),index=lrange(10))
+            df = DataFrame(dict(A = 'foo', B = 'bar'),index=range(10))
 
             # a min_itemsize that creates a data_column
             _maybe_remove(store, 'df')
@@ -1317,9 +1315,8 @@ class TestHDFStore(unittest.TestCase):
         raise nose.SkipTest('no big table frame')
 
         # create and write a big table
-        df = DataFrame(np.random.randn(2000 * 100, 100),
-                       index=lrange(2000 * 100),
-                       columns=['E%03d' % i for i in range(100)])
+        df = DataFrame(np.random.randn(2000 * 100, 100), index=range(
+            2000 * 100), columns=['E%03d' % i for i in range(100)])
         for x in range(20):
             df['String%03d' % x] = 'string%03d' % x
 
@@ -1331,7 +1328,7 @@ class TestHDFStore(unittest.TestCase):
             recons = store.select('df')
             assert isinstance(recons, DataFrame)
 
-        print("\nbig_table frame [%s] -> %5.2f" % (rows, time.time() - x))
+        print ("\nbig_table frame [%s] -> %5.2f" % (rows, time.time() - x))
 
     def test_big_table2_frame(self):
         # this is a really big table: 1m rows x 60 float columns, 20 string, 20 datetime
@@ -1342,15 +1339,14 @@ class TestHDFStore(unittest.TestCase):
         print ("\nbig_table2 start")
         import time
         start_time = time.time()
-        df = DataFrame(np.random.randn(1000 * 1000, 60),
-                       index=lrange(int(1000 * 1000)),
-                       columns=['E%03d' % i for i in range(60)])
+        df = DataFrame(np.random.randn(1000 * 1000, 60), index=range(int(
+            1000 * 1000)), columns=['E%03d' % i for i in range(60)])
         for x in range(20):
             df['String%03d' % x] = 'string%03d' % x
         for x in range(20):
             df['datetime%03d' % x] = datetime.datetime(2001, 1, 2, 0, 0)
 
-        print("\nbig_table2 frame (creation of df) [rows->%s] -> %5.2f"
+        print ("\nbig_table2 frame (creation of df) [rows->%s] -> %5.2f"
                     % (len(df.index), time.time() - start_time))
 
         def f(chunksize):
@@ -1361,9 +1357,9 @@ class TestHDFStore(unittest.TestCase):
 
         for c in [10000, 50000, 250000]:
             start_time = time.time()
-            print("big_table2 frame [chunk->%s]" % c)
+            print ("big_table2 frame [chunk->%s]" % c)
             rows = f(c)
-            print("big_table2 frame [rows->%s,chunk->%s] -> %5.2f"
+            print ("big_table2 frame [rows->%s,chunk->%s] -> %5.2f"
                     % (rows, c, time.time() - start_time))
 
     def test_big_put_frame(self):
@@ -1372,14 +1368,14 @@ class TestHDFStore(unittest.TestCase):
         print ("\nbig_put start")
         import time
         start_time = time.time()
-        df = DataFrame(np.random.randn(1000 * 1000, 60), index=lrange(int(
+        df = DataFrame(np.random.randn(1000 * 1000, 60), index=range(int(
             1000 * 1000)), columns=['E%03d' % i for i in range(60)])
         for x in range(20):
             df['String%03d' % x] = 'string%03d' % x
         for x in range(20):
             df['datetime%03d' % x] = datetime.datetime(2001, 1, 2, 0, 0)
 
-        print("\nbig_put frame (creation of df) [rows->%s] -> %5.2f"
+        print ("\nbig_put frame (creation of df) [rows->%s] -> %5.2f"
                 % (len(df.index), time.time() - start_time))
 
         with ensure_clean(self.path, mode='w') as store:
@@ -1387,8 +1383,8 @@ class TestHDFStore(unittest.TestCase):
             store = HDFStore(self.path, mode='w')
             store.put('df', df)
 
-            print(df.get_dtype_counts())
-            print("big_put frame [shape->%s] -> %5.2f"
+            print (df.get_dtype_counts())
+            print ("big_put frame [shape->%s] -> %5.2f"
                     % (df.shape, time.time() - start_time))
 
     def test_big_table_panel(self):
@@ -1414,7 +1410,7 @@ class TestHDFStore(unittest.TestCase):
             recons = store.select('wp')
             assert isinstance(recons, Panel)
 
-        print("\nbig_table panel [%s] -> %5.2f" % (rows, time.time() - x))
+        print ("\nbig_table panel [%s] -> %5.2f" % (rows, time.time() - x))
 
     def test_append_diff_item_order(self):
 
@@ -1715,7 +1711,7 @@ class TestHDFStore(unittest.TestCase):
 
             # py3 ok for unicode
             if not compat.PY3:
-                l.append(('unicode', u('\u03c3')))
+                l.append(('unicode', u('\\u03c3')))
 
             ### currently not supported dtypes ####
             for n, f in l:
@@ -1764,14 +1760,14 @@ class TestHDFStore(unittest.TestCase):
             compare(store.select('df_tz',where=Term('A>=df.A[3]')),df[df.A>=df.A[3]])
 
             _maybe_remove(store, 'df_tz')
-            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130103',tz='US/Eastern')),index=lrange(5))
+            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130103',tz='US/Eastern')),index=range(5))
             store.append('df_tz',df)
             result = store['df_tz']
             compare(result,df)
             assert_frame_equal(result,df)
 
             _maybe_remove(store, 'df_tz')
-            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130102',tz='EET')),index=lrange(5))
+            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130102',tz='EET')),index=range(5))
             self.assertRaises(TypeError, store.append, 'df_tz', df)
 
             # this is ok
@@ -1782,7 +1778,7 @@ class TestHDFStore(unittest.TestCase):
             assert_frame_equal(result,df)
 
             # can't append with diff timezone
-            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130102',tz='CET')),index=lrange(5))
+            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130102',tz='CET')),index=range(5))
             self.assertRaises(ValueError, store.append, 'df_tz', df)
 
         # as index
@@ -2679,7 +2675,7 @@ class TestHDFStore(unittest.TestCase):
 
             df = DataFrame(dict(ts=bdate_range('2012-01-01', periods=300),
                                 A=np.random.randn(300),
-                                B=lrange(300),
+                                B=range(300),
                                 users = ['a']*50 + ['b']*50 + ['c']*100 + ['a%03d' % i for i in range(100)]))
             _maybe_remove(store, 'df')
             store.append('df', df, data_columns=['ts', 'A', 'B', 'users'])
@@ -2700,7 +2696,7 @@ class TestHDFStore(unittest.TestCase):
             expected = df[ (df.ts >= Timestamp('2012-02-01')) & df.users.isin(selector) ]
             tm.assert_frame_equal(expected, result)
 
-            selector = lrange(100,200)
+            selector = range(100,200)
             result = store.select('df', [Term('B=selector')])
             expected = df[ df.B.isin(selector) ]
             tm.assert_frame_equal(expected, result)
@@ -2948,6 +2944,11 @@ class TestHDFStore(unittest.TestCase):
             expected = df.loc[:,df.columns-['A','B']]
             tm.assert_frame_equal(result, expected)
 
+            # in
+            result = store.select('df', "index>df.index[3] & columns in ['A','B']")
+            expected = df.loc[df.index>df.index[3]].reindex(columns=['A','B'])
+            tm.assert_frame_equal(result, expected)
+
     def test_invalid_filtering(self):
 
         # can't use more than one filter (atm)
@@ -3029,7 +3030,7 @@ class TestHDFStore(unittest.TestCase):
             # valid
             result = store.select_column('df', 'index')
             tm.assert_almost_equal(result.values, Series(df.index).values)
-            tm.assert_isinstance(result,Series)
+            self.assert_(isinstance(result,Series))
 
             # not a data indexable column
             self.assertRaises(
@@ -3228,18 +3229,6 @@ class TestHDFStore(unittest.TestCase):
             tm.assert_frame_equal(result, expected)
 
             # multiple (diff selector)
-            try:
-                result = store.select_as_multiple(['df1', 'df2'], where=[Term(
-                            'index', '>', df2.index[4])], selector='df2')
-                expected = concat([df1, df2], axis=1)
-                expected = expected[5:]
-                tm.assert_frame_equal(result, expected)
-            except (Exception), detail:
-                print ("error in select_as_multiple %s" % str(detail))
-                print ("store: %s" % store)
-                print ("df1: %s" % df1)
-                print ("df2: %s" % df2)
-
             result = store.select_as_multiple(['df1', 'df2'], where=[Term(
                 'index>df2.index[4]')], selector='df2')
             expected = concat([df1, df2], axis=1)
@@ -3267,7 +3256,7 @@ class TestHDFStore(unittest.TestCase):
             result = store.select(
                 'df', [Term("columns=['A']")], start=30, stop=40)
             assert(len(result) == 0)
-            tm.assert_isinstance(result, DataFrame)
+            assert(type(result) == DataFrame)
 
     def test_select_filter_corner(self):
 
@@ -3505,7 +3494,7 @@ class TestHDFStore(unittest.TestCase):
 
                 # check keys
                 if keys is None:
-                    keys = list(store.keys())
+                    keys = store.keys()
                 self.assert_(set(keys) == set(tstore.keys()))
 
                 # check indicies & nrows
diff --git a/pandas/tests/test_common.py b/pandas/tests/test_common.py
index 96131d782..5fc02d97b 100644
--- a/pandas/tests/test_common.py
+++ b/pandas/tests/test_common.py
@@ -4,12 +4,12 @@ import unittest
 
 import nose
 from nose.tools import assert_equal
-import unittest
 import numpy as np
 from pandas.tslib import iNaT
 
-from pandas import Series, DataFrame, date_range, DatetimeIndex, Timestamp
-import pandas.compat as compat
+from pandas import (Series, DataFrame, date_range, DatetimeIndex, Timestamp,
+                    Panel)
+from pandas import compat
 from pandas.compat import range, long, lrange, lmap, u
 from pandas.core.common import notnull, isnull
 import pandas.compat as compat
@@ -17,11 +17,8 @@ import pandas.core.common as com
 import pandas.util.testing as tm
 import pandas.core.config as cf
 
-import numpy as np
 from numpy.random import randn
 
-from pandas.tslib import iNaT
-
 _multiprocess_can_split_ = True
 
 
@@ -114,15 +111,18 @@ def test_isnull_lists():
 
 
 def test_is_string():
-    class MyString(str):
+    class MyUnicode(compat.text_type):
         pass
 
-    class MyUnicode(unicode):
-        pass
+    if not compat.PY3:
+        class MyString(str):
+            pass
+    else:
+        MyString = MyUnicode
 
     strings = ('s', np.str_('a'), np.unicode_('unicode_string'),
-               MyString('a _string blah'), u'asdf', MyUnicode(u'asdf'))
-    not_strings = [], 1, {}, set(), np.array(['1']), np.array([u'1'])
+               MyString('asdfasdfasdf'), u('asdf'), MyUnicode(u('asdf')))
+    not_strings = [], 1, {}, set(), np.array(['1']), np.array([u('1')])
 
     for string in strings:
         assert com.is_string(string), '{0} is not a string'.format(string)
diff --git a/pandas/tests/test_expressions.py b/pandas/tests/test_expressions.py
index ff76c7c07..f81620b89 100644
--- a/pandas/tests/test_expressions.py
+++ b/pandas/tests/test_expressions.py
@@ -4,31 +4,25 @@ from __future__ import print_function
 import unittest
 import nose
 
-import operator
-from numpy import random, nan
 from numpy.random import randn
+
+import operator
 import numpy as np
 from numpy.testing import assert_array_equal
 
-import pandas as pan
-from pandas.core.api import DataFrame, Series, notnull, isnull
-from pandas.core import expressions as expr
+from pandas.core.api import DataFrame
+from pandas.computation import expressions as expr
 
-from pandas.util.testing import (assert_almost_equal,
-                                 assert_series_equal,
-                                 assert_frame_equal)
+from pandas.util.testing import assert_series_equal, assert_frame_equal
 from pandas import compat
 
-import pandas.util.testing as tm
-import pandas.lib as lib
-
-from numpy.testing.decorators import slow
 
 if not expr._USE_NUMEXPR:
-    raise nose.SkipTest
+    raise nose.SkipTest("numexpr not available")
+
 
-_frame  = DataFrame(np.random.randn(10000, 4), columns = list('ABCD'), dtype='float64')
-_frame2 = DataFrame(np.random.randn(100, 4),   columns = list('ABCD'), dtype='float64')
+_frame  = DataFrame(randn(10000, 4), columns=list('ABCD'), dtype='float64')
+_frame2 = DataFrame(randn(100, 4),   columns = list('ABCD'), dtype='float64')
 _mixed  = DataFrame({ 'A' : _frame['A'].copy(), 'B' : _frame['B'].astype('float32'), 'C' : _frame['C'].astype('int64'), 'D' : _frame['D'].astype('int32') })
 _mixed2 = DataFrame({ 'A' : _frame2['A'].copy(), 'B' : _frame2['B'].astype('float32'), 'C' : _frame2['C'].astype('int64'), 'D' : _frame2['D'].astype('int32') })
 _integer  = DataFrame(np.random.randint(1, 100, size=(10001, 4)), columns = list('ABCD'), dtype='int64')
@@ -128,11 +122,11 @@ class TestExpressions(unittest.TestCase):
                         result   = expr.evaluate(op, op_str, f, f, use_numexpr=True)
                         expected = expr.evaluate(op, op_str, f, f, use_numexpr=False)
                         assert_array_equal(result,expected.values)
-                
+
                         result   = expr._can_use_numexpr(op, op_str, f2, f2, 'evaluate')
                         self.assert_(result == False)
 
-        
+
         expr.set_use_numexpr(False)
         testit()
         expr.set_use_numexpr(True)
@@ -149,7 +143,7 @@ class TestExpressions(unittest.TestCase):
 
                 f11 = f
                 f12 = f + 1
-            
+
                 f21 = f2
                 f22 = f2 + 1
 
@@ -163,7 +157,7 @@ class TestExpressions(unittest.TestCase):
                     result   = expr.evaluate(op, op_str, f11, f12, use_numexpr=True)
                     expected = expr.evaluate(op, op_str, f11, f12, use_numexpr=False)
                     assert_array_equal(result,expected.values)
-                    
+
                     result   = expr._can_use_numexpr(op, op_str, f21, f22, 'evaluate')
                     self.assert_(result == False)
 
@@ -180,7 +174,7 @@ class TestExpressions(unittest.TestCase):
         def testit():
             for f in [ self.frame, self.frame2, self.mixed, self.mixed2 ]:
 
-                
+
                 for cond in [ True, False ]:
 
                     c = np.empty(f.shape,dtype=np.bool_)
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index dccd7a8d1..7ba62a75a 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -18,7 +18,7 @@ from pandas.compat import(
 from pandas import compat
 
 from numpy import random, nan
-from numpy.random import randn
+from numpy.random import randn, rand
 import numpy as np
 import numpy.ma as ma
 from numpy.testing import assert_array_equal
@@ -8097,129 +8097,9 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         expec = DataFrame([[nan, 2]])
         assert_frame_equal(res, expec)
 
-    def test_query_expressions_correct_failure(self):
-        try:
-            import numexpr as ne
-        except ImportError:
-            raise nose.SkipTest("cannot query engine numexpr when numexpr not installed")
-        df = self.frame
-        exprs = 'and', 'or', 'not'
-        exprs += tuple(x + tm.rands(5) for x in exprs)
-        exprs += tuple(tm.rands(5) + x for x in exprs)
-
-        for e in exprs:
-            self.assertRaises(KeyError, df.__getitem__, e)
-
-        for e in (' and ', ' or ', ' not '):
-            self.assertRaises(SyntaxError, df.__getitem__, e)
-
-        x = tm.randbool(size=(self.frame.shape[0],))
-        self.assertRaises(KeyError, df.__getitem__, 'x')
-
-    def test_query_expressions(self):
-        try:
-            import numexpr as ne
-        except ImportError:
-            raise nose.SkipTest("cannot query engine numexpr when numexpr not installed")
-        df = DataFrame(np.random.randn(10, 3), columns=['a', 'b', 'c'])
-        assert_frame_equal(df['a < b'], df[df.a < df.b])
-        assert_frame_equal(df['a + b > b * c'],
-                           df[df.a + df.b > df.b * df.c])
-
-    def test_query_expressions_with_index(self):
-        try:
-            import numexpr as ne
-        except ImportError:
-            raise nose.SkipTest("cannot query engine numexpr when numexpr not installed")
-        df = DataFrame(np.random.randint(10, size=(10, 3)),
-                       index=Index(range(10), name='blob'),
-                       columns=['a', 'b', 'c'])
-        assert_frame_equal(df['index < b'], df[df.index < df.b])
-        assert_frame_equal(df['index < 5'], df[df.index < 5])
-        assert_frame_equal(df['(blob < 5) & (a < b)'],
-                           df[(df.index < 5) & (df.a < df.b)])
-        assert_frame_equal(df['blob < b'], df[df.index < df.b])
-
-    def test_query(self):
-        import itertools
-        for engine, parser in itertools.product(comp.engines._engines,
-                                                comp.expr._parsers):
-            self.check_query(engine, parser)
-
-    def check_query(self, engine, parser):
-        if engine == 'numexpr':
-            try:
-                import numexpr as ne
-            except ImportError:
-                raise nose.SkipTest("cannot query engine numexpr when numexpr not installed")
-
-        df = DataFrame(np.random.randn(10, 3), columns=['a', 'b', 'c'])
-        assert_frame_equal(df.query('a < b', engine=engine, parser=parser), df[df.a < df.b])
-        assert_frame_equal(df.query('a + b > b * c', engine=engine, parser=parser),
-                           df[df.a + df.b > df.b * df.c])
-
-        local_dict = dict(df.iteritems())
-        local_dict.update({'df': df})
-        self.assertRaises(NameError, df.query, 'a < d & b < f',
-                          local_dict=local_dict, engine=engine, parser=parser)
-
-        # make sure that it's not just because we didn't pass the locals in
-        self.assertRaises(AssertionError, self.assertRaises, NameError,
-                          df.query, 'a < b', local_dict=local_dict,
-                          engine=engine, parser=parser)
-
-    def test_query_index(self):
-        import itertools
-        for engine, parser in itertools.product(comp.engines._engines,
-                                                comp.expr._parsers):
-            self.check_query_index(engine, parser)
-
-    def check_query_index(self, engine, parser):
-        if engine == 'numexpr':
-            try:
-                import numexpr as ne
-            except ImportError:
-                raise nose.SkipTest("cannot query engine numexpr when numexpr not installed")
-
-        df = DataFrame(np.random.randint(10, size=(10, 3)),
-                       index=Index(range(10), name='blob'),
-                       columns=['a', 'b', 'c'])
-        assert_frame_equal(df.query('index < b', engine=engine, parser=parser),
-                           df[df.index < df.b])
-        assert_frame_equal(df.query('index < 5', engine=engine, parser=parser),
-                           df[df.index < 5])
-        assert_frame_equal(df.query('(blob < 5) & (a < b)', engine=engine,
-                                    parser=parser),
-                           df[(df.index < 5) & (df.a < df.b)])
-        assert_frame_equal(df.query('blob < b', engine=engine, parser=parser),
-                           df[df.index < df.b])
-
-    def test_query_different_parsers(self):
-        for engine in comp.engines._engines:
-            self.check_query_different_parsers(engine)
-
-    def check_query_different_parsers(self, engine):
-        if engine == 'numexpr':
-            try:
-                import numexpr as ne
-            except ImportError:
-                raise nose.SkipTest("cannot query engine numexpr when numexpr not installed")
-        df = DataFrame(np.random.randn(10, 3), columns=['a', 'b', 'c'])
-        assert_frame_equal(df.query('(a < 5) & (a < b)', parser='python',
-                                    engine=engine),
-                           df.query('a < 5 & a < b', parser='pandas',
-                                    engine=engine))
-        df = DataFrame(np.random.randint(10, size=(10, 3)),
-                       index=Index(range(10), name='blob'),
-                       columns=['a', 'b', 'c'])
-        assert_frame_equal(df.query('(blob < 5) & (a < b)', parser='python',
-                                    engine=engine),
-                           df.query('blob < 5 & a < b', parser='pandas',
-                                    engine=engine))
-
-
     #----------------------------------------------------------------------
     # Transposing
+
     def test_transpose(self):
         frame = self.frame
         dft = frame.T
@@ -11224,10 +11104,270 @@ starting,ending,measure
         with tm.assertRaises(TypeError):
             df.isin('aaa')
 
+def skip_if_no_ne(engine='numexpr'):
+    if engine == 'numexpr':
+        try:
+            import numexpr as ne
+        except ImportError:
+            raise nose.SkipTest("cannot query engine numexpr when numexpr not "
+                                "installed")
+
+
+class TestDataFrameQueryNumExprPandas(unittest.TestCase):
+    @classmethod
+    def setUpClass(cls):
+        cls.engine = 'numexpr'
+        cls.parser = 'pandas'
+        skip_if_no_ne(cls.engine)
+        cls.frame = _frame.copy()
+
+    @classmethod
+    def tearDownClass(cls):
+        del cls.frame, cls.engine, cls.parser
+
+    def test_date_query_method(self):
+        engine, parser = self.engine, self.parser
+        df = DataFrame(randn(5, 3))
+        df['dates1'] = date_range('1/1/2012', periods=5)
+        df['dates2'] = date_range('1/1/2013', periods=5)
+        df['dates3'] = date_range('1/1/2014', periods=5)
+        res = df.query('dates1 < 20130101 < dates3', engine=engine,
+                       parser=parser)
+        expec = df[(df.dates1 < '20130101') & ('20130101' < df.dates3)]
+        assert_frame_equal(res, expec)
+
+    def test_query_scope(self):
+        engine, parser = self.engine, self.parser
+        from pandas.computation.common import NameResolutionError
+
+        df = DataFrame({"i": lrange(10),
+                        "+": lrange(3, 13), "r": lrange(4, 14)})
+        i, s = 5, 6
+        self.assertRaises(NameResolutionError, df.query, 'i < 5',
+                          local_dict=locals(), global_dict=globals(),
+                          engine=engine, parser=parser)
+        self.assertRaises(NameResolutionError, df.query, 'i - +', engine=engine,
+                          local_dict=locals(), global_dict=globals(),
+                          parser=parser)
+        self.assertRaises(NameResolutionError, df.query, 'i == s',
+                          engine=engine, local_dict=locals(),
+                          global_dict=globals(), parser=parser)
+        df.index.name = 'sin'
+        self.assertRaises(NameResolutionError, df.query, 'sin > 5',
+                          engine=engine, parser=parser, local_dict=locals(),
+                          global_dict=globals())
+
+    def test_query(self):
+        engine, parser = self.engine, self.parser
+        df = DataFrame(np.random.randn(10, 3), columns=['a', 'b', 'c'])
+        assert_frame_equal(df.query('a < b', engine=engine, parser=parser), df[df.a < df.b])
+        assert_frame_equal(df.query('a + b > b * c', engine=engine, parser=parser),
+                           df[df.a + df.b > df.b * df.c])
+
+        local_dict = dict(df.iteritems())
+        local_dict.update({'df': df})
+        self.assertRaises(NameError, df.query, 'a < d & b < f',
+                          local_dict=local_dict, engine=engine, parser=parser)
+
+        # make sure that it's not just because we didn't pass the locals in
+        self.assertRaises(AssertionError, self.assertRaises, NameError,
+                          df.query, 'a < b', local_dict={'df': df},
+                          engine=engine, parser=parser)
+
+    def test_query_index(self):
+        engine, parser = self.engine, self.parser
+        df = DataFrame(np.random.randint(10, size=(10, 3)),
+                       index=Index(range(10), name='blob'),
+                       columns=['a', 'b', 'c'])
+        assert_frame_equal(df.query('index < b', engine=engine, parser=parser),
+                           df[df.index < df.b])
+        assert_frame_equal(df.query('index < 5', engine=engine, parser=parser),
+                           df[df.index < 5])
+        assert_frame_equal(df.query('(blob < 5) & (a < b)', engine=engine,
+                                    parser=parser),
+                           df[(df.index < 5) & (df.a < df.b)])
+        assert_frame_equal(df.query('blob < b', engine=engine, parser=parser),
+                           df[df.index < df.b])
+
+    def test_nested_scope(self):
+        engine = self.engine
+        parser = self.parser
+        # smoke test
+        x = 1
+        result = pd.eval('x + 1', engine=engine, parser=parser)
+        self.assertEqual(result, 2)
+
+        df  = DataFrame(np.random.randn(5, 3))
+        df2 = DataFrame(np.random.randn(5, 3))
+        expected = df[(df>0) & (df2>0)]
+
+        result = df.query('(df>0) & (df2>0)', engine=engine, parser=parser)
+        assert_frame_equal(result, expected)
+
+        result = pd.eval('df[(df > 0) and (df2 > 0)]', engine=engine,
+                         parser=parser)
+        assert_frame_equal(result, expected)
+
+        result = pd.eval('df[(df > 0) and (df2 > 0) and df[df > 0] > 0]',
+                         engine=engine, parser=parser)
+        expected = df[(df > 0) & (df2 > 0) & (df[df > 0] > 0)]
+        assert_frame_equal(result, expected)
+
+        result = pd.eval('df[(df>0) & (df2>0)]', engine=engine, parser=parser)
+        expected = df.query('(df>0) & (df2>0)', engine=engine, parser=parser)
+        assert_frame_equal(result, expected)
+
+
+class TestDataFrameQueryNumExprPython(TestDataFrameQueryNumExprPandas):
+    @classmethod
+    def setUpClass(cls):
+        cls.engine = 'numexpr'
+        cls.parser = 'python'
+        skip_if_no_ne(cls.engine)
+        cls.frame = _frame.copy()
+
+    @classmethod
+    def tearDownClass(cls):
+        del cls.frame, cls.engine, cls.parser
+
+    def test_date_query_method(self):
+        engine, parser = self.engine, self.parser
+        df = DataFrame(randn(5, 3))
+        df['dates1'] = date_range('1/1/2012', periods=5)
+        df['dates2'] = date_range('1/1/2013', periods=5)
+        df['dates3'] = date_range('1/1/2014', periods=5)
+        res = df.query('(df.dates1 < 20130101) & (20130101 < df.dates3)',
+                       engine=engine, parser=parser)
+        expec = df[(df.dates1 < '20130101') & ('20130101' < df.dates3)]
+        assert_frame_equal(res, expec)
+
+    def test_nested_scope(self):
+        engine = self.engine
+        parser = self.parser
+        # smoke test
+        x = 1
+        result = pd.eval('x + 1', engine=engine, parser=parser)
+        self.assertEqual(result, 2)
+
+        df  = DataFrame(np.random.randn(5, 3))
+        df2 = DataFrame(np.random.randn(5, 3))
+        expected = df[(df>0) & (df2>0)]
+
+        result = df.query('(df>0) & (df2>0)', engine=engine, parser=parser)
+        assert_frame_equal(result, expected)
+
+        result = pd.eval('df[(df > 0) & (df2 > 0)]', engine=engine,
+                         parser=parser)
+        assert_frame_equal(result, expected)
+
+        result = pd.eval('df[(df > 0) & (df2 > 0) & (df[df > 0] > 0)]',
+                         engine=engine, parser=parser)
+        expected = df[(df > 0) & (df2 > 0) & (df[df > 0] > 0)]
+        assert_frame_equal(result, expected)
+
+        result = pd.eval('df[(df>0) & (df2>0)]', engine=engine, parser=parser)
+        expected = df.query('(df>0) & (df2>0)', engine=engine, parser=parser)
+        assert_frame_equal(result, expected)
+
+
+class TestDataFrameQueryPythonPandas(TestDataFrameQueryNumExprPandas):
+    @classmethod
+    def setUpClass(cls):
+        cls.engine = 'python'
+        cls.parser = 'pandas'
+        cls.frame = _frame.copy()
+
+    @classmethod
+    def tearDownClass(cls):
+        del cls.frame, cls.engine, cls.parser
+
+
+class TestDataFrameQueryPythonPython(TestDataFrameQueryNumExprPython):
+    @classmethod
+    def setUpClass(cls):
+        cls.engine = cls.parser = 'python'
+        cls.frame = _frame.copy()
+
+    @classmethod
+    def tearDownClass(cls):
+        del cls.frame, cls.engine, cls.parser
+
+
+class TestDataFrameQueryGetitem(unittest.TestCase):
+    @classmethod
+    def setUpClass(cls):
+        skip_if_no_ne()
+        cls.frame = _frame.copy()
+
+    @classmethod
+    def tearDownClass(cls):
+        del cls.frame
+
+    def test_nested_scope(self):
+        df  = DataFrame(np.random.randn(5, 3))
+        df2 = DataFrame(np.random.randn(5, 3))
+        expected = df[(df>0) & (df2>0)]
+
+        result = df['(df>0) & (df2>0)']
+        assert_frame_equal(result, expected)
+
+    def test_date_query_getitem(self):
+        df = DataFrame(randn(5, 3))
+        df['dates1'] = date_range('1/1/2012', periods=5)
+        df['dates2'] = date_range('1/1/2013', periods=5)
+        df['dates3'] = date_range('1/1/2014', periods=5)
+        res = df['dates1 < 20130101 < dates3']
+        expec = df[(df.dates1 < '20130101') & ('20130101' < df.dates3)]
+        assert_frame_equal(res, expec)
+
+    def test_query_expressions_correct_failure(self):
+        df = self.frame
+        exprs = 'and', 'or', 'not'
+        exprs += tuple(x + tm.rands(5) for x in exprs)
+        exprs += tuple(tm.rands(5) + x for x in exprs)
+
+        for e in exprs:
+            self.assertRaises(KeyError, df.__getitem__, e)
+
+        for e in (' and ', ' or ', ' not '):
+            self.assertRaises(SyntaxError, df.__getitem__, e)
+
+        x = tm.randbool(size=(self.frame.shape[0],))
+        self.assertRaises(KeyError, df.__getitem__, 'x')
+
+    def test_query_expressions_with_index(self):
+        df = DataFrame(np.random.randint(10, size=(10, 3)),
+                       index=Index(range(10), name='blob'),
+                       columns=['a', 'b', 'c'])
+        assert_frame_equal(df['index < b'], df[df.index < df.b])
+        assert_frame_equal(df['index < 5'], df[df.index < 5])
+        assert_frame_equal(df['(blob < 5) & (a < b)'],
+                           df[(df.index < 5) & (df.a < df.b)])
+        assert_frame_equal(df['blob < b'], df[df.index < df.b])
+
+    def test_query_expressions(self):
+        df = DataFrame(np.random.randn(10, 3), columns=['a', 'b', 'c'])
+        assert_frame_equal(df['a < b'], df[df.a < df.b])
+        assert_frame_equal(df['a + b > b * c'],
+                           df[df.a + df.b > df.b * df.c])
+
+    def test_simple_not_expression(self):
+        df = DataFrame(randn(10, 3), columns=list('abc'))
+        df['bools'] = rand(len(df)) > 0.5
+        res = df['not bools']
+        res2 = df['~bools']
+        expec = df[~df.bools]
+        assert_frame_equal(res, expec)
+        assert_frame_equal(res2, expec)
+
+    def test_complex_boolean_expression(self):
+        df = DataFrame(randn(10, 3), columns=list('abc'))
+        df['bools'] = rand(len(df)) > 0.5
+        res = df['a < b < c and (not bools) or bools > 2']
+        expec = df[(df.a < df.b) & (df.b < df.c) & (~df.bools) | (df.bools > 2)]
+        assert_frame_equal(res, expec)
+
+
 if __name__ == '__main__':
-    # unittest.main()
-    import nose
-    # nose.runmodule(argv=[__file__,'-vvs','-x', '--ipdb-failure'],
-    #                exit=False)
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
                    exit=False)
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index e82aef137..bf895e2ab 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -13,7 +13,6 @@ import os
 from datetime import datetime
 from functools import wraps, partial
 from contextlib import contextmanager
-from httplib import HTTPException
 from distutils.version import LooseVersion
 
 from numpy.random import randn, rand
@@ -28,7 +27,7 @@ import pandas.core.panel4d as panel4d
 import pandas.compat as compat
 from pandas.compat import(
     map, zip, range, unichr, lrange, lmap, lzip, u, callable, Counter,
-    raise_with_traceback
+    raise_with_traceback, httplib
 )
 
 from pandas import bdate_range
@@ -52,6 +51,7 @@ _RAISE_NETWORK_ERROR_DEFAULT = False
 def randbool(size=(), p=0.5):
     return rand(*size) <= p
 
+
 def rands(n):
     choices = string.ascii_letters + string.digits
     return ''.join(random.choice(choices) for _ in range(n))
@@ -65,7 +65,6 @@ def randu(n):
 #------------------------------------------------------------------------------
 # Console debugging tools
 
-
 def debug(f, *args, **kwargs):
     from pdb import Pdb as OldPdb
     try:
@@ -756,7 +755,7 @@ def optional_args(decorator):
     return wrapper
 
 
-_network_error_classes = IOError, HTTPException
+_network_error_classes = IOError, httplib.HTTPException
 
 
 @optional_args
@@ -800,13 +799,13 @@ def network(t, raise_on_error=_RAISE_NETWORK_ERROR_DEFAULT,
       >>> import nose
       >>> @network
       ... def test_network():
-      ...   with urlopen("rabbit://bonanza.com") as f:
-      ...     pass
+      ...     with urlopen("rabbit://bonanza.com") as f:
+      ...         pass
       ...
       >>> try:
-      ...   test_network()
+      ...     test_network()
       ... except nose.SkipTest:
-      ...   print "SKIPPING!"
+      ...     print("SKIPPING!")
       ...
       SKIPPING!
 
@@ -815,8 +814,8 @@ def network(t, raise_on_error=_RAISE_NETWORK_ERROR_DEFAULT,
 
       >>> @network(raise_on_error=True)
       ... def test_network():
-      ...   with urlopen("complaint://deadparrot.com") as f:
-      ...     pass
+      ...     with urlopen("complaint://deadparrot.com") as f:
+      ...         pass
       ...
       >>> test_network()
       Traceback (most recent call last):
diff --git a/setup.py b/setup.py
index 955dedb74..ffd6089bd 100755
--- a/setup.py
+++ b/setup.py
@@ -507,6 +507,7 @@ setup(name=DISTNAME,
       packages=['pandas',
                 'pandas.compat',
                 'pandas.computation',
+                'pandas.computation.tests',
                 'pandas.core',
                 'pandas.io',
                 'pandas.rpy',
