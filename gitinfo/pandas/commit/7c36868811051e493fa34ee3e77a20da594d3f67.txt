commit 7c36868811051e493fa34ee3e77a20da594d3f67
Author: Matthew Roeschke <emailformattr@gmail.com>
Date:   Sun Nov 4 21:19:00 2018 -0800

    DOC: Remove dead link and update links to https (#23476)
    
    * DOC: Remove dead links and update links to https
    
    * Add missing ~

diff --git a/doc/source/basics.rst b/doc/source/basics.rst
index 16ab345fd..81efbfd6d 100644
--- a/doc/source/basics.rst
+++ b/doc/source/basics.rst
@@ -767,7 +767,7 @@ We encourage you to view the source code of :meth:`~DataFrame.pipe`.
 
 .. _dplyr: https://github.com/hadley/dplyr
 .. _magrittr: https://github.com/smbache/magrittr
-.. _R: http://www.r-project.org
+.. _R: https://www.r-project.org
 
 
 Row or Column-wise Function Application
@@ -2296,7 +2296,7 @@ For example, to select ``bool`` columns:
    df.select_dtypes(include=[bool])
 
 You can also pass the name of a dtype in the `NumPy dtype hierarchy
-<http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__:
+<https://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__:
 
 .. ipython:: python
 
diff --git a/doc/source/comparison_with_sas.rst b/doc/source/comparison_with_sas.rst
index 0354ad473..4d7acdf9a 100644
--- a/doc/source/comparison_with_sas.rst
+++ b/doc/source/comparison_with_sas.rst
@@ -365,8 +365,8 @@ Length
 ~~~~~~
 
 SAS determines the length of a character string with the 
-`LENGTHN <http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a002284668.htm>`__  
-and `LENGTHC <http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a002283942.htm>`__ 
+`LENGTHN <https://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a002284668.htm>`__
+and `LENGTHC <https://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a002283942.htm>`__
 functions. ``LENGTHN`` excludes trailing blanks and ``LENGTHC`` includes trailing blanks.
 
 .. code-block:: sas
@@ -391,7 +391,7 @@ Find
 ~~~~
 
 SAS determines the position of a character in a string with the 
-`FINDW <http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a002978282.htm>`__ function. 
+`FINDW <https://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a002978282.htm>`__ function.
 ``FINDW`` takes the string defined by the first argument and searches for the first position of the substring 
 you supply as the second argument.
 
@@ -417,7 +417,7 @@ Substring
 ~~~~~~~~~
 
 SAS extracts a substring from a string based on its position with the 
-`SUBSTR <http://www2.sas.com/proceedings/sugi25/25/cc/25p088.pdf>`__ function. 
+`SUBSTR <https://www2.sas.com/proceedings/sugi25/25/cc/25p088.pdf>`__ function.
 
 .. code-block:: sas
 
@@ -438,7 +438,7 @@ indexes are zero-based.
 Scan
 ~~~~
 
-The SAS `SCAN <http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000214639.htm>`__ 
+The SAS `SCAN <https://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000214639.htm>`__
 function returns the nth word from a string. The first argument is the string you want to parse and the 
 second argument specifies which word you want to extract.
 
@@ -469,9 +469,9 @@ approaches, but this just shows a simple approach.
 Upcase, Lowcase, and Propcase
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-The SAS `UPCASE <http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000245965.htm>`__ 
-`LOWCASE <http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000245912.htm>`__ and 
-`PROPCASE <http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/a002598106.htm>`__ 
+The SAS `UPCASE <https://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000245965.htm>`__
+`LOWCASE <https://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000245912.htm>`__ and
+`PROPCASE <https://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/a002598106.htm>`__
 functions change the case of the argument.
 
 .. code-block:: sas
@@ -709,7 +709,7 @@ This means that the size of data able to be loaded in pandas is limited by your
 machine's memory, but also that the operations on that data may be faster.
 
 If out of core processing is needed, one possibility is the
-`dask.dataframe <http://dask.pydata.org/en/latest/dataframe.html>`_
+`dask.dataframe <https://dask.pydata.org/en/latest/dataframe.html>`_
 library (currently in development) which
 provides a subset of pandas functionality for an on-disk ``DataFrame``
 
diff --git a/doc/source/comparison_with_sql.rst b/doc/source/comparison_with_sql.rst
index ba069b5a4..db143cd58 100644
--- a/doc/source/comparison_with_sql.rst
+++ b/doc/source/comparison_with_sql.rst
@@ -4,7 +4,7 @@
 Comparison with SQL
 ********************
 Since many potential pandas users have some familiarity with
-`SQL <http://en.wikipedia.org/wiki/SQL>`_, this page is meant to provide some examples of how
+`SQL <https://en.wikipedia.org/wiki/SQL>`_, this page is meant to provide some examples of how
 various SQL operations would be performed using pandas.
 
 If you're new to pandas, you might want to first read through :ref:`10 Minutes to pandas<10min>`
@@ -59,7 +59,7 @@ Filtering in SQL is done via a WHERE clause.
     LIMIT 5;
 
 DataFrames can be filtered in multiple ways; the most intuitive of which is using
-`boolean indexing <http://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing>`_.
+`boolean indexing <https://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing>`_.
 
 .. ipython:: python
 
diff --git a/doc/source/contributing_docstring.rst b/doc/source/contributing_docstring.rst
index afb554aef..38e4baa66 100644
--- a/doc/source/contributing_docstring.rst
+++ b/doc/source/contributing_docstring.rst
@@ -16,7 +16,7 @@ function or method, so programmers can understand what it does without having
 to read the details of the implementation.
 
 Also, it is a common practice to generate online (html) documentation
-automatically from docstrings. `Sphinx <http://www.sphinx-doc.org>`_ serves
+automatically from docstrings. `Sphinx <https://www.sphinx-doc.org>`_ serves
 this purpose.
 
 Next example gives an idea on how a docstring looks like:
@@ -68,7 +68,7 @@ As PEP-257 is quite open, and some other standards exist on top of it. In the
 case of pandas, the numpy docstring convention is followed. The conventions is
 explained in this document:
 
-* `numpydoc docstring guide <http://numpydoc.readthedocs.io/en/latest/format.html>`_
+* `numpydoc docstring guide <https://numpydoc.readthedocs.io/en/latest/format.html>`_
   (which is based in the original `Guide to NumPy/SciPy documentation
   <https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt>`_)
 
@@ -78,7 +78,7 @@ The standard uses reStructuredText (reST). reStructuredText is a markup
 language that allows encoding styles in plain text files. Documentation
 about reStructuredText can be found in:
 
-* `Sphinx reStructuredText primer <http://www.sphinx-doc.org/en/stable/rest.html>`_
+* `Sphinx reStructuredText primer <https://www.sphinx-doc.org/en/stable/rest.html>`_
 * `Quick reStructuredText reference <http://docutils.sourceforge.net/docs/user/rst/quickref.html>`_
 * `Full reStructuredText specification <http://docutils.sourceforge.net/docs/ref/rst/restructuredtext.html>`_
 
@@ -119,7 +119,7 @@ backticks. It is considered inline code:
     function, prefix it with ``~``. For example, ``:class:`~pandas.Series```
     will link to ``pandas.Series`` but only display the last part, ``Series``
     as the link text. See `Sphinx cross-referencing syntax
-    <http://www.sphinx-doc.org/en/stable/domains.html#cross-referencing-syntax>`_
+    <https://www.sphinx-doc.org/en/stable/domains.html#cross-referencing-syntax>`_
     for details.
 
 **Good:**
diff --git a/doc/source/cookbook.rst b/doc/source/cookbook.rst
index 21d1f11ba..3d26a9c7d 100644
--- a/doc/source/cookbook.rst
+++ b/doc/source/cookbook.rst
@@ -52,7 +52,7 @@ Idioms
 These are some neat pandas ``idioms``
 
 `if-then/if-then-else on one column, and assignment to another one or more columns:
-<http://stackoverflow.com/questions/17128302/python-pandas-idiom-for-if-then-else>`__
+<https://stackoverflow.com/questions/17128302/python-pandas-idiom-for-if-then-else>`__
 
 .. ipython:: python
 
@@ -88,7 +88,7 @@ Or use pandas where after you've set up a mask
    df.where(df_mask,-1000)
 
 `if-then-else using numpy's where()
-<http://stackoverflow.com/questions/19913659/pandas-conditional-creation-of-a-series-dataframe-column>`__
+<https://stackoverflow.com/questions/19913659/pandas-conditional-creation-of-a-series-dataframe-column>`__
 
 .. ipython:: python
 
@@ -101,7 +101,7 @@ Splitting
 *********
 
 `Split a frame with a boolean criterion
-<http://stackoverflow.com/questions/14957116/how-to-split-a-dataframe-according-to-a-boolean-criterion>`__
+<https://stackoverflow.com/questions/14957116/how-to-split-a-dataframe-according-to-a-boolean-criterion>`__
 
 .. ipython:: python
 
@@ -115,7 +115,7 @@ Building Criteria
 *****************
 
 `Select with multi-column criteria
-<http://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe>`__
+<https://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe>`__
 
 .. ipython:: python
 
@@ -141,7 +141,7 @@ Building Criteria
    df.loc[(df['BBB'] > 25) | (df['CCC'] >= 75), 'AAA'] = 0.1; df
 
 `Select rows with data closest to certain value using argsort
-<http://stackoverflow.com/questions/17758023/return-rows-in-a-dataframe-closest-to-a-user-defined-number>`__
+<https://stackoverflow.com/questions/17758023/return-rows-in-a-dataframe-closest-to-a-user-defined-number>`__
 
 .. ipython:: python
 
@@ -152,7 +152,7 @@ Building Criteria
    df.loc[(df.CCC-aValue).abs().argsort()]
 
 `Dynamically reduce a list of criteria using a binary operators
-<http://stackoverflow.com/questions/21058254/pandas-boolean-operation-in-a-python-list/21058331>`__
+<https://stackoverflow.com/questions/21058254/pandas-boolean-operation-in-a-python-list/21058331>`__
 
 .. ipython:: python
 
@@ -189,7 +189,7 @@ DataFrames
 The :ref:`indexing <indexing>` docs.
 
 `Using both row labels and value conditionals
-<http://stackoverflow.com/questions/14725068/pandas-using-row-labels-in-boolean-indexing>`__
+<https://stackoverflow.com/questions/14725068/pandas-using-row-labels-in-boolean-indexing>`__
 
 .. ipython:: python
 
@@ -232,7 +232,7 @@ Ambiguity arises when an index consists of integers with a non-zero start or non
    df2.loc[1:3] #Label-oriented
 
 `Using inverse operator (~) to take the complement of a mask
-<http://stackoverflow.com/questions/14986510/picking-out-elements-based-on-complement-of-indices-in-python-pandas>`__
+<https://stackoverflow.com/questions/14986510/picking-out-elements-based-on-complement-of-indices-in-python-pandas>`__
 
 .. ipython:: python
 
@@ -259,13 +259,13 @@ Panels
    pf.loc[:,:,'F'] = pd.DataFrame(data, rng, cols);pf
 
 `Mask a panel by using np.where and then reconstructing the panel with the new masked values
-<http://stackoverflow.com/questions/14650341/boolean-mask-in-pandas-panel>`__
+<https://stackoverflow.com/questions/14650341/boolean-mask-in-pandas-panel>`__
 
 New Columns
 ***********
 
 `Efficiently and dynamically creating new columns using applymap
-<http://stackoverflow.com/questions/16575868/efficiently-creating-additional-columns-in-a-pandas-dataframe-using-map>`__
+<https://stackoverflow.com/questions/16575868/efficiently-creating-additional-columns-in-a-pandas-dataframe-using-map>`__
 
 .. ipython:: python
 
@@ -279,7 +279,7 @@ New Columns
    df[new_cols] = df[source_cols].applymap(categories.get);df
 
 `Keep other columns when using min() with groupby
-<http://stackoverflow.com/questions/23394476/keep-other-columns-when-using-min-with-groupby>`__
+<https://stackoverflow.com/questions/23394476/keep-other-columns-when-using-min-with-groupby>`__
 
 .. ipython:: python
 
@@ -308,7 +308,7 @@ MultiIndexing
 The :ref:`multindexing <advanced.hierarchical>` docs.
 
 `Creating a MultiIndex from a labeled frame
-<http://stackoverflow.com/questions/14916358/reshaping-dataframes-in-pandas-based-on-column-labels>`__
+<https://stackoverflow.com/questions/14916358/reshaping-dataframes-in-pandas-based-on-column-labels>`__
 
 .. ipython:: python
 
@@ -331,7 +331,7 @@ Arithmetic
 **********
 
 `Performing arithmetic with a MultiIndex that needs broadcasting
-<http://stackoverflow.com/questions/19501510/divide-entire-pandas-multiindex-dataframe-by-dataframe-variable/19502176#19502176>`__
+<https://stackoverflow.com/questions/19501510/divide-entire-pandas-multiindex-dataframe-by-dataframe-variable/19502176#19502176>`__
 
 .. ipython:: python
 
@@ -343,7 +343,7 @@ Slicing
 *******
 
 `Slicing a MultiIndex with xs
-<http://stackoverflow.com/questions/12590131/how-to-slice-multindex-columns-in-pandas-dataframes>`__
+<https://stackoverflow.com/questions/12590131/how-to-slice-multindex-columns-in-pandas-dataframes>`__
 
 .. ipython:: python
 
@@ -364,7 +364,7 @@ To take the cross section of the 1st level and 1st axis the index:
    df.xs('six',level=1,axis=0)
 
 `Slicing a MultiIndex with xs, method #2
-<http://stackoverflow.com/questions/14964493/multiindex-based-indexing-in-pandas>`__
+<https://stackoverflow.com/questions/14964493/multiindex-based-indexing-in-pandas>`__
 
 .. ipython:: python
 
@@ -387,13 +387,13 @@ To take the cross section of the 1st level and 1st axis the index:
    df.loc[(All,'Math'),(All,'II')]
 
 `Setting portions of a MultiIndex with xs
-<http://stackoverflow.com/questions/19319432/pandas-selecting-a-lower-level-in-a-dataframe-to-do-a-ffill>`__
+<https://stackoverflow.com/questions/19319432/pandas-selecting-a-lower-level-in-a-dataframe-to-do-a-ffill>`__
 
 Sorting
 *******
 
 `Sort by specific column or an ordered list of columns, with a MultiIndex
-<http://stackoverflow.com/questions/14733871/mutli-index-sorting-in-pandas>`__
+<https://stackoverflow.com/questions/14733871/mutli-index-sorting-in-pandas>`__
 
 .. ipython:: python
 
diff --git a/doc/source/dsintro.rst b/doc/source/dsintro.rst
index efa52a6f7..d02912294 100644
--- a/doc/source/dsintro.rst
+++ b/doc/source/dsintro.rst
@@ -249,7 +249,7 @@ pandas object. Like Series, DataFrame accepts many different kinds of input:
 * Dict of 1D ndarrays, lists, dicts, or Series
 * 2-D numpy.ndarray
 * `Structured or record
-  <http://docs.scipy.org/doc/numpy/user/basics.rec.html>`__ ndarray
+  <https://docs.scipy.org/doc/numpy/user/basics.rec.html>`__ ndarray
 * A ``Series``
 * Another ``DataFrame``
 
@@ -476,7 +476,7 @@ Assigning New Columns in Method Chains
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 Inspired by `dplyr's
-<http://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html#mutate>`__
+<https://dplyr.tidyverse.org/reference/mutate.html>`__
 ``mutate`` verb, DataFrame has an :meth:`~pandas.DataFrame.assign`
 method that allows you to easily create new columns that are potentially
 derived from existing columns.
@@ -815,7 +815,7 @@ accessed like an attribute:
    df
    df.foo1
 
-The columns are also connected to the `IPython <http://ipython.org>`__
+The columns are also connected to the `IPython <https://ipython.org>`__
 completion mechanism so they can be tab-completed:
 
 .. code-block:: ipython
@@ -834,7 +834,7 @@ Panel
     a future version. See the section :ref:`Deprecate Panel <dsintro.deprecate_panel>`.
 
 Panel is a somewhat less-used, but still important container for 3-dimensional
-data. The term `panel data <http://en.wikipedia.org/wiki/Panel_data>`__ is
+data. The term `panel data <https://en.wikipedia.org/wiki/Panel_data>`__ is
 derived from econometrics and is partially responsible for the name pandas:
 pan(el)-da(ta)-s. The names for the 3 axes are intended to give some semantic
 meaning to describing operations involving panel data and, in particular,
@@ -1024,7 +1024,7 @@ Oftentimes, one can simply use a MultiIndex ``DataFrame`` for easily working wit
 
 In addition, the ``xarray`` package was built from the ground up, specifically in order to
 support the multi-dimensional analysis that is one of ``Panel`` s main use cases.
-`Here is a link to the xarray panel-transition documentation <http://xarray.pydata.org/en/stable/pandas.html#panel-transition>`__.
+`Here is a link to the xarray panel-transition documentation <https://xarray.pydata.org/en/stable/pandas.html#panel-transition>`__.
 
 .. ipython:: python
    :okwarning:
@@ -1046,4 +1046,4 @@ Alternatively, one can convert to an xarray ``DataArray``.
 
    p.to_xarray()
 
-You can see the full-documentation for the `xarray package <http://xarray.pydata.org/en/stable/>`__.
+You can see the full-documentation for the `xarray package <https://xarray.pydata.org/en/stable/>`__.
diff --git a/doc/source/ecosystem.rst b/doc/source/ecosystem.rst
index 7fffcadd8..edbd6629a 100644
--- a/doc/source/ecosystem.rst
+++ b/doc/source/ecosystem.rst
@@ -27,8 +27,8 @@ substantial projects that you feel should be on this list, please let us know.
 Statistics and Machine Learning
 -------------------------------
 
-`Statsmodels <http://www.statsmodels.org/>`__
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+`Statsmodels <https://www.statsmodels.org/>`__
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 Statsmodels is the prominent Python "statistics and econometrics library" and it has
 a long-standing special relationship with pandas. Statsmodels provides powerful statistics,
@@ -38,7 +38,7 @@ Statsmodels leverages pandas objects as the underlying data container for comput
 `sklearn-pandas <https://github.com/paulgb/sklearn-pandas>`__
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-Use pandas DataFrames in your `scikit-learn <http://scikit-learn.org/>`__
+Use pandas DataFrames in your `scikit-learn <https://scikit-learn.org/>`__
 ML pipeline.
 
 `Featuretools <https://github.com/featuretools/featuretools/>`__
@@ -62,8 +62,8 @@ simplicity produces beautiful and effective visualizations with a
 minimal amount of code. Altair works with Pandas DataFrames.
 
 
-`Bokeh <http://bokeh.pydata.org>`__
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+`Bokeh <https://bokeh.pydata.org>`__
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 Bokeh is a Python interactive visualization library for large datasets that natively uses
 the latest web technologies. Its goal is to provide elegant, concise construction of novel
@@ -74,7 +74,7 @@ large data to thin clients.
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 Seaborn is a Python visualization library based on
-`matplotlib <http://matplotlib.org>`__. It provides a high-level, dataset-oriented
+`matplotlib <https://matplotlib.org>`__. It provides a high-level, dataset-oriented
 interface for creating attractive statistical graphics. The plotting functions
 in seaborn understand pandas objects and leverage pandas grouping operations
 internally to support concise specification of complex visualizations. Seaborn
@@ -85,8 +85,8 @@ fit of statistical models to emphasize patterns in a dataset.
 `yhat/ggpy <https://github.com/yhat/ggpy>`__
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-Hadley Wickham's `ggplot2 <http://ggplot2.org/>`__ is a foundational exploratory visualization package for the R language.
-Based on `"The Grammar of Graphics" <http://www.cs.uic.edu/~wilkinson/TheGrammarOfGraphics/GOG.html>`__ it
+Hadley Wickham's `ggplot2 <https://ggplot2.tidyverse.org/>`__ is a foundational exploratory visualization package for the R language.
+Based on `"The Grammar of Graphics" <https://www.cs.uic.edu/~wilkinson/TheGrammarOfGraphics/GOG.html>`__ it
 provides a powerful, declarative and extremely general way to generate bespoke plots of any kind of data.
 It's really quite incredible. Various implementations to other languages are available,
 but a faithful implementation for Python users has long been missing. Although still young
@@ -102,7 +102,7 @@ progressing quickly in that direction.
 `Plotly <https://plot.ly/python>`__
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-`Plotly’s <https://plot.ly/>`__ `Python API <https://plot.ly/python/>`__ enables interactive figures and web shareability. Maps, 2D, 3D, and live-streaming graphs are rendered with WebGL and `D3.js <http://d3js.org/>`__. The library supports plotting directly from a pandas DataFrame and cloud-based collaboration. Users of `matplotlib, ggplot for Python, and Seaborn <https://plot.ly/python/matplotlib-to-plotly-tutorial/>`__ can convert figures into interactive web-based plots. Plots can be drawn in `IPython Notebooks <https://plot.ly/ipython-notebooks/>`__ , edited with R or MATLAB, modified in a GUI, or embedded in apps and dashboards. Plotly is free for unlimited sharing, and has `cloud <https://plot.ly/product/plans/>`__, `offline <https://plot.ly/python/offline/>`__, or `on-premise <https://plot.ly/product/enterprise/>`__ accounts for private use.
+`Plotly’s <https://plot.ly/>`__ `Python API <https://plot.ly/python/>`__ enables interactive figures and web shareability. Maps, 2D, 3D, and live-streaming graphs are rendered with WebGL and `D3.js <https://d3js.org/>`__. The library supports plotting directly from a pandas DataFrame and cloud-based collaboration. Users of `matplotlib, ggplot for Python, and Seaborn <https://plot.ly/python/matplotlib-to-plotly-tutorial/>`__ can convert figures into interactive web-based plots. Plots can be drawn in `IPython Notebooks <https://plot.ly/ipython-notebooks/>`__ , edited with R or MATLAB, modified in a GUI, or embedded in apps and dashboards. Plotly is free for unlimited sharing, and has `cloud <https://plot.ly/product/plans/>`__, `offline <https://plot.ly/python/offline/>`__, or `on-premise <https://plot.ly/product/enterprise/>`__ accounts for private use.
 
 `QtPandas <https://github.com/draperjames/qtpandas>`__
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
@@ -116,8 +116,8 @@ library enables DataFrame visualization and manipulation in PyQt4 and PySide app
 IDE
 ------
 
-`IPython <http://ipython.org/documentation.html>`__
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+`IPython <https://ipython.org/documentation.html>`__
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 IPython is an interactive command shell and distributed computing
 environment. IPython tab completion works with Pandas methods and also
@@ -221,7 +221,7 @@ This package requires valid credentials for this API (non free).
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 pandaSDMX is a library to retrieve and acquire statistical data
 and metadata disseminated in
-`SDMX <http://www.sdmx.org>`_ 2.1, an ISO-standard
+`SDMX <https://www.sdmx.org>`_ 2.1, an ISO-standard
 widely used by institutions such as statistics offices, central banks,
 and international organisations. pandaSDMX can expose datasets and related
 structural metadata including data flows, code-lists,
@@ -230,7 +230,7 @@ or MultiIndexed DataFrames.
 
 `fredapi <https://github.com/mortada/fredapi>`__
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-fredapi is a Python interface to the `Federal Reserve Economic Data (FRED) <http://research.stlouisfed.org/fred2/>`__
+fredapi is a Python interface to the `Federal Reserve Economic Data (FRED) <https://fred.stlouisfed.org/>`__
 provided by the Federal Reserve Bank of St. Louis. It works with both the FRED database and ALFRED database that
 contains point-in-time data (i.e. historic data revisions). fredapi provides a wrapper in Python to the FRED
 HTTP API, and also provides several convenient methods for parsing and analyzing point-in-time data from ALFRED.
@@ -316,7 +316,7 @@ Increasingly, packages are being built on top of pandas to address specific need
 Data validation
 ---------------
 
-`Engarde <http://engarde.readthedocs.io/en/latest/>`__
+`Engarde <https://engarde.readthedocs.io/en/latest/>`__
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 Engarde is a lightweight library used to explicitly state your assumptions about your datasets
diff --git a/doc/source/index.rst.template b/doc/source/index.rst.template
index f5ac7b77f..d2b88e794 100644
--- a/doc/source/index.rst.template
+++ b/doc/source/index.rst.template
@@ -14,15 +14,15 @@ pandas: powerful Python data analysis toolkit
 
 **Binary Installers:** https://pypi.org/project/pandas
 
-**Source Repository:** http://github.com/pandas-dev/pandas
+**Source Repository:** https://github.com/pandas-dev/pandas
 
 **Issues & Ideas:** https://github.com/pandas-dev/pandas/issues
 
-**Q&A Support:** http://stackoverflow.com/questions/tagged/pandas
+**Q&A Support:** https://stackoverflow.com/questions/tagged/pandas
 
-**Developer Mailing List:** http://groups.google.com/group/pydata
+**Developer Mailing List:** https://groups.google.com/forum/#!forum/pydata
 
-**pandas** is a `Python <http://www.python.org>`__ package providing fast,
+**pandas** is a `Python <https://www.python.org>`__ package providing fast,
 flexible, and expressive data structures designed to make working with
 "relational" or "labeled" data both easy and intuitive. It aims to be the
 fundamental high-level building block for doing practical, **real world** data
@@ -45,7 +45,7 @@ and :class:`DataFrame` (2-dimensional), handle the vast majority of typical use
 cases in finance, statistics, social science, and many areas of
 engineering. For R users, :class:`DataFrame` provides everything that R's
 ``data.frame`` provides and much more. pandas is built on top of `NumPy
-<http://www.numpy.org>`__ and is intended to integrate well within a scientific
+<https://www.numpy.org>`__ and is intended to integrate well within a scientific
 computing environment with many other 3rd party libraries.
 
 Here are just a few of the things that pandas does well:
@@ -86,13 +86,13 @@ is the ideal tool for all of these tasks.
 Some other notes
 
  - pandas is **fast**. Many of the low-level algorithmic bits have been
-   extensively tweaked in `Cython <http://cython.org>`__ code. However, as with
+   extensively tweaked in `Cython <https://cython.org>`__ code. However, as with
    anything else generalization usually sacrifices performance. So if you focus
    on one feature for your application you may be able to create a faster
    specialized tool.
 
  - pandas is a dependency of `statsmodels
-   <http://www.statsmodels.org/stable/index.html>`__, making it an important part of the
+   <https://www.statsmodels.org/stable/index.html>`__, making it an important part of the
    statistical computing ecosystem in Python.
 
  - pandas has been used extensively in production in financial applications.
@@ -101,7 +101,7 @@ Some other notes
 
    This documentation assumes general familiarity with NumPy. If you haven't
    used NumPy much or at all, do invest some time in `learning about NumPy
-   <http://docs.scipy.org>`__ first.
+   <https://docs.scipy.org>`__ first.
 
 See the package overview for more detail about what's in the library.
 
diff --git a/doc/source/io.rst b/doc/source/io.rst
index 56da4dbea..68faefa87 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -40,14 +40,14 @@ The pandas I/O API is a set of top level ``reader`` functions accessed like
     :delim: ;
 
     text;`CSV <https://en.wikipedia.org/wiki/Comma-separated_values>`__;:ref:`read_csv<io.read_csv_table>`;:ref:`to_csv<io.store_in_csv>`
-    text;`JSON <http://www.json.org/>`__;:ref:`read_json<io.json_reader>`;:ref:`to_json<io.json_writer>`
+    text;`JSON <https://www.json.org/>`__;:ref:`read_json<io.json_reader>`;:ref:`to_json<io.json_writer>`
     text;`HTML <https://en.wikipedia.org/wiki/HTML>`__;:ref:`read_html<io.read_html>`;:ref:`to_html<io.html>`
     text; Local clipboard;:ref:`read_clipboard<io.clipboard>`;:ref:`to_clipboard<io.clipboard>`
     binary;`MS Excel <https://en.wikipedia.org/wiki/Microsoft_Excel>`__;:ref:`read_excel<io.excel_reader>`;:ref:`to_excel<io.excel_writer>`
     binary;`HDF5 Format <https://support.hdfgroup.org/HDF5/whatishdf5.html>`__;:ref:`read_hdf<io.hdf5>`;:ref:`to_hdf<io.hdf5>`
     binary;`Feather Format <https://github.com/wesm/feather>`__;:ref:`read_feather<io.feather>`;:ref:`to_feather<io.feather>`
     binary;`Parquet Format <https://parquet.apache.org/>`__;:ref:`read_parquet<io.parquet>`;:ref:`to_parquet<io.parquet>`
-    binary;`Msgpack <http://msgpack.org/index.html>`__;:ref:`read_msgpack<io.msgpack>`;:ref:`to_msgpack<io.msgpack>`
+    binary;`Msgpack <https://msgpack.org/index.html>`__;:ref:`read_msgpack<io.msgpack>`;:ref:`to_msgpack<io.msgpack>`
     binary;`Stata <https://en.wikipedia.org/wiki/Stata>`__;:ref:`read_stata<io.stata_reader>`;:ref:`to_stata<io.stata_writer>`
     binary;`SAS <https://en.wikipedia.org/wiki/SAS_(software)>`__;:ref:`read_sas<io.sas_reader>`;
     binary;`Python Pickle Format <https://docs.python.org/3/library/pickle.html>`__;:ref:`read_pickle<io.pickle>`;:ref:`to_pickle<io.pickle>`
@@ -2273,7 +2273,7 @@ indicate missing values and the subsequent read cannot distinguish the intent.
    new_df = pd.read_json('test.json', orient='table')
    print(new_df.index.name)
 
-.. _Table Schema: http://specs.frictionlessdata.io/json-table-schema/
+.. _Table Schema: https://specs.frictionlessdata.io/json-table-schema/
 
 HTML
 ----
@@ -2301,7 +2301,7 @@ Read a URL with no options:
 
 .. ipython:: python
 
-   url = 'http://www.fdic.gov/bank/individual/failed/banklist.html'
+   url = 'https://www.fdic.gov/bank/individual/failed/banklist.html'
    dfs = pd.read_html(url)
    dfs
 
@@ -2341,7 +2341,7 @@ You can even pass in an instance of ``StringIO`` if you so desire:
    that having so many network-accessing functions slows down the documentation
    build. If you spot an error or an example that doesn't run, please do not
    hesitate to report it over on `pandas GitHub issues page
-   <http://www.github.com/pandas-dev/pandas/issues>`__.
+   <https://www.github.com/pandas-dev/pandas/issues>`__.
 
 
 Read a URL and match a table that contains specific text:
@@ -2650,16 +2650,16 @@ parse HTML tables in the top-level pandas io function ``read_html``.
 
 
 .. |svm| replace:: **strictly valid markup**
-.. _svm: http://validator.w3.org/docs/help.html#validation_basics
+.. _svm: https://validator.w3.org/docs/help.html#validation_basics
 
 .. |html5lib| replace:: **html5lib**
 .. _html5lib: https://github.com/html5lib/html5lib-python
 
 .. |BeautifulSoup4| replace:: **BeautifulSoup4**
-.. _BeautifulSoup4: http://www.crummy.com/software/BeautifulSoup
+.. _BeautifulSoup4: https://www.crummy.com/software/BeautifulSoup
 
 .. |lxml| replace:: **lxml**
-.. _lxml: http://lxml.de
+.. _lxml: https://lxml.de
 
 
 
@@ -3143,10 +3143,10 @@ any pickled pandas object (or any other pickled object) from file:
    for such cases, pickled ``DataFrames``, ``Series`` etc, must be read with
    ``pd.read_pickle``, rather than ``pickle.load``.
 
-   See `here <http://pandas.pydata.org/pandas-docs/stable/whatsnew.html#whatsnew-0130-refactoring>`__
-   and `here <http://pandas.pydata.org/pandas-docs/stable/whatsnew.html#whatsnew-0150-refactoring>`__
+   See `here <https://pandas.pydata.org/pandas-docs/stable/whatsnew.html#whatsnew-0130-refactoring>`__
+   and `here <https://pandas.pydata.org/pandas-docs/stable/whatsnew.html#whatsnew-0150-refactoring>`__
    for some examples of compatibility-breaking changes. See
-   `this question <http://stackoverflow.com/questions/20444593/pandas-compiled-from-source-default-pickle-behavior-changed>`__
+   `this question <https://stackoverflow.com/questions/20444593/pandas-compiled-from-source-default-pickle-behavior-changed>`__
    for a detailed explanation.
 
 .. _io.pickle.compression:
@@ -3294,7 +3294,7 @@ HDF5 (PyTables)
 
 ``HDFStore`` is a dict-like object which reads and writes pandas using
 the high performance HDF5 format using the excellent `PyTables
-<http://www.pytables.org/>`__ library. See the :ref:`cookbook <cookbook.hdf>`
+<https://www.pytables.org/>`__ library. See the :ref:`cookbook <cookbook.hdf>`
 for some advanced strategies
 
 .. warning::
@@ -3878,7 +3878,7 @@ Then create the index when finished appending.
 
    os.remove('appends.h5')
 
-See `here <http://stackoverflow.com/questions/17893370/ptrepack-sortby-needs-full-index>`__ for how to create a completely-sorted-index (CSI) on an existing store.
+See `here <https://stackoverflow.com/questions/17893370/ptrepack-sortby-needs-full-index>`__ for how to create a completely-sorted-index (CSI) on an existing store.
 
 .. _io.hdf5-query-data-columns:
 
@@ -4151,8 +4151,8 @@ control compression: ``complevel`` and ``complib``.
             compression to choose depends on your specific needs and
             data. The list of supported compression libraries:
 
-             - `zlib <http://zlib.net/>`_: The default compression library. A classic in terms of compression, achieves good compression rates but is somewhat slow.
-             - `lzo <http://www.oberhumer.com/opensource/lzo/>`_: Fast compression and decompression.
+             - `zlib <https://zlib.net/>`_: The default compression library. A classic in terms of compression, achieves good compression rates but is somewhat slow.
+             - `lzo <https://www.oberhumer.com/opensource/lzo/>`_: Fast compression and decompression.
              - `bzip2 <http://bzip.org/>`_: Good compression rates.
              - `blosc <http://www.blosc.org/>`_: Fast compression and decompression.
 
@@ -4171,7 +4171,7 @@ control compression: ``complevel`` and ``complib``.
                   compression ratios at the expense of speed.
                 - `blosc:snappy <https://google.github.io/snappy/>`_:
                   A popular compressor used in many places.
-                - `blosc:zlib <http://zlib.net/>`_: A classic;
+                - `blosc:zlib <https://zlib.net/>`_: A classic;
                   somewhat slower than the previous ones, but
                   achieving better compression ratios.
                 - `blosc:zstd <https://facebook.github.io/zstd/>`_: An
@@ -4372,7 +4372,7 @@ tables.
 It is possible to write an ``HDFStore`` object that can easily be imported into ``R`` using the
 ``rhdf5`` library (`Package website`_). Create a table format store like this:
 
-.. _package website: http://www.bioconductor.org/packages/release/bioc/html/rhdf5.html
+.. _package website: https://www.bioconductor.org/packages/release/bioc/html/rhdf5.html
 
 .. ipython:: python
 
@@ -4471,7 +4471,7 @@ Performance
 * A ``PerformanceWarning`` will be raised if you are attempting to
   store types that will be pickled by PyTables (rather than stored as
   endemic types). See
-  `Here <http://stackoverflow.com/questions/14355151/how-to-make-pandas-hdfstore-put-operation-faster/14370190#14370190>`__
+  `Here <https://stackoverflow.com/questions/14355151/how-to-make-pandas-hdfstore-put-operation-faster/14370190#14370190>`__
   for more information and some solutions.
 
 
@@ -4579,7 +4579,7 @@ You can specify an ``engine`` to direct the serialization. This can be one of ``
 If the engine is NOT specified, then the ``pd.options.io.parquet.engine`` option is checked; if this is also ``auto``,
 then ``pyarrow`` is tried, and falling back to ``fastparquet``.
 
-See the documentation for `pyarrow <http://arrow.apache.org/docs/python/>`__ and `fastparquet <https://fastparquet.readthedocs.io/en/latest/>`__.
+See the documentation for `pyarrow <https://arrow.apache.org/docs/python/>`__ and `fastparquet <https://fastparquet.readthedocs.io/en/latest/>`__.
 
 .. note::
 
@@ -4681,13 +4681,13 @@ for PostgreSQL or `pymysql <https://github.com/PyMySQL/PyMySQL>`__ for MySQL.
 For `SQLite <https://docs.python.org/3/library/sqlite3.html>`__ this is
 included in Python's standard library by default.
 You can find an overview of supported drivers for each SQL dialect in the
-`SQLAlchemy docs <http://docs.sqlalchemy.org/en/latest/dialects/index.html>`__.
+`SQLAlchemy docs <https://docs.sqlalchemy.org/en/latest/dialects/index.html>`__.
 
 If SQLAlchemy is not installed, a fallback is only provided for sqlite (and
 for mysql for backwards compatibility, but this is deprecated and will be
 removed in a future version).
 This mode requires a Python database adapter which respect the `Python
-DB-API <http://www.python.org/dev/peps/pep-0249/>`__.
+DB-API <https://www.python.org/dev/peps/pep-0249/>`__.
 
 See also some :ref:`cookbook examples <cookbook.sql>` for some advanced strategies.
 
@@ -4709,7 +4709,7 @@ The key functions are:
     the provided input (database table name or sql query).
     Table names do not need to be quoted if they have special characters.
 
-In the following example, we use the `SQlite <http://www.sqlite.org/>`__ SQL database
+In the following example, we use the `SQlite <https://www.sqlite.org/>`__ SQL database
 engine. You can use a temporary SQLite database where data are stored in
 "memory".
 
@@ -4717,7 +4717,7 @@ To connect with SQLAlchemy you use the :func:`create_engine` function to create
 object from database URI. You only need to create the engine once per database you are
 connecting to.
 For more information on :func:`create_engine` and the URI formatting, see the examples
-below and the SQLAlchemy `documentation <http://docs.sqlalchemy.org/en/latest/core/engines.html>`__
+below and the SQLAlchemy `documentation <https://docs.sqlalchemy.org/en/latest/core/engines.html>`__
 
 .. ipython:: python
 
@@ -4930,7 +4930,7 @@ connecting to.
    # or absolute, starting with a slash:
    engine = create_engine('sqlite:////absolute/path/to/foo.db')
 
-For more information see the examples the SQLAlchemy `documentation <http://docs.sqlalchemy.org/en/latest/core/engines.html>`__
+For more information see the examples the SQLAlchemy `documentation <https://docs.sqlalchemy.org/en/latest/core/engines.html>`__
 
 
 Advanced SQLAlchemy queries
@@ -4975,7 +4975,7 @@ Sqlite fallback
 
 The use of sqlite is supported without using SQLAlchemy.
 This mode requires a Python database adapter which respect the `Python
-DB-API <http://www.python.org/dev/peps/pep-0249/>`__.
+DB-API <https://www.python.org/dev/peps/pep-0249/>`__.
 
 You can create connections like so:
 
@@ -5233,7 +5233,7 @@ xarray_ provides data structures inspired by the pandas ``DataFrame`` for workin
 with multi-dimensional datasets, with a focus on the netCDF file format and
 easy conversion to and from pandas.
 
-.. _xarray: http://xarray.pydata.org/
+.. _xarray: https://xarray.pydata.org/
 
 .. _io.perf:
 
diff --git a/doc/source/options.rst b/doc/source/options.rst
index cbe0264f4..dc4d0da32 100644
--- a/doc/source/options.rst
+++ b/doc/source/options.rst
@@ -137,7 +137,7 @@ Using startup scripts for the python/ipython environment to import pandas and se
   $IPYTHONDIR/profile_default/startup
 
 More information can be found in the `ipython documentation
-<http://ipython.org/ipython-doc/stable/interactive/tutorial.html#startup-files>`__.  An example startup script for pandas is displayed below:
+<https://ipython.org/ipython-doc/stable/interactive/tutorial.html#startup-files>`__.  An example startup script for pandas is displayed below:
 
 .. code-block:: python
 
diff --git a/doc/source/overview.rst b/doc/source/overview.rst
index 6ba9501ba..b71f4bfa2 100644
--- a/doc/source/overview.rst
+++ b/doc/source/overview.rst
@@ -82,7 +82,7 @@ Getting Support
 The first stop for pandas issues and ideas is the `Github Issue Tracker
 <https://github.com/pandas-dev/pandas/issues>`__. If you have a general question,
 pandas community experts can answer through `Stack Overflow
-<http://stackoverflow.com/questions/tagged/pandas>`__.
+<https://stackoverflow.com/questions/tagged/pandas>`__.
 
 Community
 ---------
@@ -92,7 +92,7 @@ the world who contribute their valuable time and energy to help make open source
 pandas possible. Thanks to `all of our contributors <https://github.com/pandas-dev/pandas/graphs/contributors>`__.
 
 If you're interested in contributing, please
-visit `Contributing to pandas webpage <http://pandas.pydata.org/pandas-docs/stable/contributing.html>`__.
+visit `Contributing to pandas webpage <https://pandas.pydata.org/pandas-docs/stable/contributing.html>`__.
 
 pandas is a `NumFOCUS <https://www.numfocus.org/open-source-projects/>`__ sponsored project.
 This will help ensure the success of development of pandas as a world-class open-source
diff --git a/doc/source/release.rst b/doc/source/release.rst
index cd04288dc..af6fc23e1 100644
--- a/doc/source/release.rst
+++ b/doc/source/release.rst
@@ -20,7 +20,7 @@ Release Notes
 *************
 
 This is the list of changes to pandas between each release. For full details,
-see the commit logs at http://github.com/pandas-dev/pandas
+see the commit logs at https://github.com/pandas-dev/pandas
 
 **What is it**
 
@@ -33,9 +33,9 @@ analysis / manipulation tool available in any language.
 
 **Where to get it**
 
-* Source code: http://github.com/pandas-dev/pandas
+* Source code: https://github.com/pandas-dev/pandas
 * Binary installers on PyPI: https://pypi.org/project/pandas
-* Documentation: http://pandas.pydata.org
+* Documentation: https://pandas.pydata.org
 
 pandas 0.23.2
 -------------
@@ -586,7 +586,7 @@ Highlights include:
 - Integration with `Apache Parquet <https://parquet.apache.org/>`__, including a new top-level :func:`read_parquet` function and :meth:`DataFrame.to_parquet` method, see :ref:`here <whatsnew_0210.enhancements.parquet>`.
 - New user-facing :class:`pandas.api.types.CategoricalDtype` for specifying
   categoricals independent of the data, see :ref:`here <whatsnew_0210.enhancements.categorical_dtype>`.
-- The behavior of ``sum`` and ``prod`` on all-NaN Series/DataFrames is now consistent and no longer depends on whether `bottleneck <http://berkeleyanalytics.com/bottleneck>`__ is installed, and ``sum`` and ``prod`` on empty Series now return NaN instead of 0, see :ref:`here <whatsnew_0210.api_breaking.bottleneck>`.
+- The behavior of ``sum`` and ``prod`` on all-NaN Series/DataFrames is now consistent and no longer depends on whether `bottleneck <https://berkeleyanalytics.com/bottleneck>`__ is installed, and ``sum`` and ``prod`` on empty Series now return NaN instead of 0, see :ref:`here <whatsnew_0210.api_breaking.bottleneck>`.
 - Compatibility fixes for pypy, see :ref:`here <whatsnew_0210.pypy>`.
 - Additions to the ``drop``, ``reindex`` and ``rename`` API to make them more consistent, see :ref:`here <whatsnew_0210.enhancements.drop_api>`.
 - Addition of the new methods ``DataFrame.infer_objects`` (see :ref:`here <whatsnew_0210.enhancements.infer_objects>`) and ``GroupBy.pipe`` (see :ref:`here <whatsnew_0210.enhancements.GroupBy_pipe>`).
@@ -1171,7 +1171,7 @@ Highlights include:
 - Sparse data structures gained enhanced support of ``int`` and ``bool`` dtypes, see :ref:`here <whatsnew_0190.sparse>`
 - Comparison operations with ``Series`` no longer ignores the index, see :ref:`here <whatsnew_0190.api.series_ops>` for an overview of the API changes.
 - Introduction of a pandas development API for utility functions, see :ref:`here <whatsnew_0190.dev_api>`.
-- Deprecation of ``Panel4D`` and ``PanelND``. We recommend to represent these types of n-dimensional data with the `xarray package <http://xarray.pydata.org/en/stable/>`__.
+- Deprecation of ``Panel4D`` and ``PanelND``. We recommend to represent these types of n-dimensional data with the `xarray package <https://xarray.pydata.org/en/stable/>`__.
 - Removal of the previously deprecated modules ``pandas.io.data``, ``pandas.io.wb``, ``pandas.tools.rplot``.
 
 See the :ref:`v0.19.0 Whatsnew <whatsnew_0190>` overview for an extensive list
@@ -1402,7 +1402,7 @@ Highlights include:
 - Removal of support for positional indexing with floats, which was deprecated
   since 0.14.0. This will now raise a ``TypeError``, see :ref:`here <whatsnew_0180.float_indexers>`.
 - The ``.to_xarray()`` function has been added for compatibility with the
-  `xarray package <http://xarray.pydata.org/en/stable/>`__, see :ref:`here <whatsnew_0180.enhancements.xarray>`.
+  `xarray package <https://xarray.pydata.org/en/stable/>`__, see :ref:`here <whatsnew_0180.enhancements.xarray>`.
 - The ``read_sas`` function has been enhanced to read ``sas7bdat`` files, see :ref:`here <whatsnew_0180.enhancements.sas>`.
 - Addition of the :ref:`.str.extractall() method <whatsnew_0180.enhancements.extract>`,
   and API changes to the :ref:`.str.extract() method <whatsnew_0180.enhancements.extract>`
@@ -1757,7 +1757,7 @@ along with several new features, enhancements, and performance improvements.
 Highlights include:
 
 - A new ``pipe`` method, see :ref:`here <whatsnew_0162.enhancements.pipe>`
-- Documentation on how to use `numba <http://numba.pydata.org>`_ with *pandas*, see :ref:`here <enhancingperf.numba>`
+- Documentation on how to use `numba <https://numba.pydata.org>`_ with *pandas*, see :ref:`here <enhancingperf.numba>`
 
 See the :ref:`v0.16.2 Whatsnew <whatsnew_0162>` overview for an extensive list
 of all enhancements and bugs that have been fixed in 0.16.2.
@@ -1889,9 +1889,9 @@ Highlights include:
 - Changes to the default for ordering in the ``Categorical`` constructor, see :ref:`here <whatsnew_0160.api_breaking.categorical>`
 - The ``pandas.tools.rplot``, ``pandas.sandbox.qtpandas`` and ``pandas.rpy``
   modules are deprecated. We refer users to external packages like
-  `seaborn <http://stanford.edu/~mwaskom/software/seaborn/>`_,
+  `seaborn <https://stanford.edu/~mwaskom/software/seaborn/>`_,
   `pandas-qt <https://github.com/datalyze-solutions/pandas-qt>`_ and
-  `rpy2 <http://rpy2.bitbucket.org/>`_ for similar or equivalent
+  `rpy2 <https://rpy2.bitbucket.org/>`_ for similar or equivalent
   functionality, see :ref:`here <whatsnew_0160.deprecations>`
 
 See the :ref:`v0.16.0 Whatsnew <whatsnew_0160>` overview or the issue tracker on GitHub for an extensive list
diff --git a/doc/source/tutorials.rst b/doc/source/tutorials.rst
index 381031fa1..83c891c0c 100644
--- a/doc/source/tutorials.rst
+++ b/doc/source/tutorials.rst
@@ -7,7 +7,7 @@ Tutorials
 This is a guide to many pandas tutorials, geared mainly for new users.
 
 Internal Guides
----------------
+===============
 
 pandas' own :ref:`10 Minutes to pandas<10min>`.
 
@@ -15,6 +15,9 @@ More complex recipes are in the :ref:`Cookbook<cookbook>`.
 
 A handy pandas `cheat sheet <http://pandas.pydata.org/Pandas_Cheat_Sheet.pdf>`_.
 
+Community Guides
+================
+
 pandas Cookbook
 ---------------
 
@@ -200,6 +203,5 @@ Various Tutorials
 * `Financial analysis in Python, by Thomas Wiecki <http://nbviewer.ipython.org/github/twiecki/financial-analysis-python-tutorial/blob/master/1.%20Pandas%20Basics.ipynb>`_
 * `Intro to pandas data structures, by Greg Reda <http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/>`_
 * `Pandas and Python: Top 10, by Manish Amde <http://manishamde.github.io/blog/2013/03/07/pandas-and-python-top-10/>`_
-* `Pandas Tutorial, by Mikhail Semeniuk <http://www.bearrelroll.com/2013/05/python-pandas-tutorial>`_
 * `Pandas DataFrames Tutorial, by Karlijn Willems <http://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python>`_
 * `A concise tutorial with real life examples <https://tutswiki.com/pandas-cookbook/chapter1>`_
