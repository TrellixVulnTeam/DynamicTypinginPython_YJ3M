commit 1acdb31d9348f70f1cc77790fbc7bee568366cdd
Author: Wes McKinney <wes@cloudera.com>
Date:   Tue Jan 19 03:44:39 2016 -0800

    CLN: fix all flake8 warnings (except pandas/tseries/resample.py) in pandas/tseries

diff --git a/pandas/tseries/api.py b/pandas/tseries/api.py
index 7c47bd9a2..9a07983b4 100644
--- a/pandas/tseries/api.py
+++ b/pandas/tseries/api.py
@@ -2,6 +2,7 @@
 
 """
 
+# flake8: noqa
 
 from pandas.tseries.index import DatetimeIndex, date_range, bdate_range
 from pandas.tseries.frequencies import infer_freq
diff --git a/pandas/tseries/base.py b/pandas/tseries/base.py
index b7fddf37d..4b8192edc 100644
--- a/pandas/tseries/base.py
+++ b/pandas/tseries/base.py
@@ -17,29 +17,28 @@ import pandas.tseries.frequencies as frequencies
 import pandas.algos as _algos
 
 
-
 class DatelikeOps(object):
     """ common ops for DatetimeIndex/PeriodIndex, but not TimedeltaIndex """
 
     def strftime(self, date_format):
-        """
-        Return an array of formatted strings specified by date_format, which
-        supports the same string format as the python standard library. Details
-        of the string format can be found in the `python string format doc
-        <https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior>`__
+        return np.asarray(self.format(date_format=date_format))
+    strftime.__doc__ = """
+    Return an array of formatted strings specified by date_format, which
+    supports the same string format as the python standard library. Details
+    of the string format can be found in `python string format doc <{0}>`__
 
-        .. versionadded:: 0.17.0
+    .. versionadded:: 0.17.0
 
-        Parameters
-        ----------
-        date_format : str
-            date format string (e.g. "%Y-%m-%d")
+    Parameters
+    ----------
+    date_format : str
+        date format string (e.g. "%Y-%m-%d")
 
-        Returns
-        -------
-        ndarray of formatted strings
-        """
-        return np.asarray(self.format(date_format=date_format))
+    Returns
+    -------
+    ndarray of formatted strings
+    """.format("https://docs.python.org/2/library/datetime.html"
+               "#strftime-and-strptime-behavior")
 
 
 class TimelikeOps(object):
@@ -68,7 +67,7 @@ class TimelikeOps(object):
         unit = to_offset(freq).nanos
 
         # round the local times
-        if getattr(self,'tz',None) is not None:
+        if getattr(self, 'tz', None) is not None:
             values = self.tz_localize(None).asi8
         else:
             values = self.asi8
@@ -81,7 +80,7 @@ class TimelikeOps(object):
         result = self._shallow_copy(result, **attribs)
 
         # reconvert to local tz
-        if getattr(self,'tz',None) is not None:
+        if getattr(self, 'tz', None) is not None:
             result = result.tz_localize(self.tz)
         return result
 
@@ -181,7 +180,9 @@ class DatetimeIndexOpsMixin(object):
 
     @property
     def freqstr(self):
-        """ return the frequency object as a string if its set, otherwise None """
+        """
+        Return the frequency object as a string if its set, otherwise None
+        """
         if self.freq is None:
             return None
         return self.freq.freqstr
@@ -291,7 +292,8 @@ class DatetimeIndexOpsMixin(object):
         -------
         result : ndarray with values replace by the fill_value
 
-        mask the result if needed, convert to the provided dtype if its not None
+        mask the result if needed, convert to the provided dtype if its not
+        None
 
         This is an internal routine
         """
@@ -408,7 +410,7 @@ class DatetimeIndexOpsMixin(object):
                 freq = self.freqstr
                 if freq is not None:
                     freq = "'%s'" % freq
-                attrs.append(('freq',freq))
+                attrs.append(('freq', freq))
         return attrs
 
     @cache_readonly
@@ -424,7 +426,8 @@ class DatetimeIndexOpsMixin(object):
 
     def _convert_scalar_indexer(self, key, kind=None):
         """
-        we don't allow integer or float indexing on datetime-like when using loc
+        we don't allow integer or float indexing on datetime-like when using
+        loc
 
         Parameters
         ----------
@@ -432,10 +435,12 @@ class DatetimeIndexOpsMixin(object):
         kind : optional, type of the indexing operation (loc/ix/iloc/None)
         """
 
-        if kind in ['loc'] and lib.isscalar(key) and (is_integer(key) or is_float(key)):
-            self._invalid_indexer('index',key)
+        if (kind in ['loc'] and lib.isscalar(key) and
+                (is_integer(key) or is_float(key))):
+            self._invalid_indexer('index', key)
 
-        return super(DatetimeIndexOpsMixin, self)._convert_scalar_indexer(key, kind=kind)
+        return (super(DatetimeIndexOpsMixin, self)
+                ._convert_scalar_indexer(key, kind=kind))
 
     def _add_datelike(self, other):
         raise AbstractMethodError(self)
@@ -445,7 +450,10 @@ class DatetimeIndexOpsMixin(object):
 
     @classmethod
     def _add_datetimelike_methods(cls):
-        """ add in the datetimelike methods (as we may have to override the superclass) """
+        """
+        add in the datetimelike methods (as we may have to override the
+        superclass)
+        """
 
         def __add__(self, other):
             from pandas.core.index import Index
@@ -454,14 +462,17 @@ class DatetimeIndexOpsMixin(object):
             if isinstance(other, TimedeltaIndex):
                 return self._add_delta(other)
             elif isinstance(self, TimedeltaIndex) and isinstance(other, Index):
-                if hasattr(other,'_add_delta'):
+                if hasattr(other, '_add_delta'):
                     return other._add_delta(self)
-                raise TypeError("cannot add TimedeltaIndex and {typ}".format(typ=type(other)))
+                raise TypeError("cannot add TimedeltaIndex and {typ}"
+                                .format(typ=type(other)))
             elif isinstance(other, Index):
-                warnings.warn("using '+' to provide set union with datetimelike Indexes is deprecated, "
-                              "use .union()",FutureWarning, stacklevel=2)
+                warnings.warn("using '+' to provide set union with "
+                              "datetimelike Indexes is deprecated, "
+                              "use .union()", FutureWarning, stacklevel=2)
                 return self.union(other)
-            elif isinstance(other, (DateOffset, timedelta, np.timedelta64, tslib.Timedelta)):
+            elif isinstance(other, (DateOffset, timedelta, np.timedelta64,
+                                    tslib.Timedelta)):
                 return self._add_delta(other)
             elif com.is_integer(other):
                 return self.shift(other)
@@ -480,13 +491,16 @@ class DatetimeIndexOpsMixin(object):
                 return self._add_delta(-other)
             elif isinstance(self, TimedeltaIndex) and isinstance(other, Index):
                 if not isinstance(other, TimedeltaIndex):
-                    raise TypeError("cannot subtract TimedeltaIndex and {typ}".format(typ=type(other)))
+                    raise TypeError("cannot subtract TimedeltaIndex and {typ}"
+                                    .format(typ=type(other)))
                 return self._add_delta(-other)
             elif isinstance(other, Index):
-                warnings.warn("using '-' to provide set differences with datetimelike Indexes is deprecated, "
-                              "use .difference()",FutureWarning, stacklevel=2)
+                warnings.warn("using '-' to provide set differences with "
+                              "datetimelike Indexes is deprecated, "
+                              "use .difference()", FutureWarning, stacklevel=2)
                 return self.difference(other)
-            elif isinstance(other, (DateOffset, timedelta, np.timedelta64, tslib.Timedelta)):
+            elif isinstance(other, (DateOffset, timedelta, np.timedelta64,
+                                    tslib.Timedelta)):
                 return self._add_delta(-other)
             elif com.is_integer(other):
                 return self.shift(-other)
@@ -630,5 +644,5 @@ class DatetimeIndexOpsMixin(object):
             result += '\nFreq: %s' % self.freqstr
 
         # display as values, not quoted
-        result = result.replace("'","")
+        result = result.replace("'", "")
         return result
diff --git a/pandas/tseries/common.py b/pandas/tseries/common.py
index 345bea18f..f9f90a937 100644
--- a/pandas/tseries/common.py
+++ b/pandas/tseries/common.py
@@ -1,4 +1,6 @@
-## datetimelike delegation ##
+"""
+datetimelike delegation
+"""
 
 import numpy as np
 from pandas.core.base import PandasDelegate, NoNewAttributesMixin
@@ -8,13 +10,17 @@ from pandas.tseries.period import PeriodIndex
 from pandas.tseries.tdi import TimedeltaIndex
 from pandas import tslib
 from pandas.core.common import (_NS_DTYPE, _TD_DTYPE, is_period_arraylike,
-                                is_datetime_arraylike, is_integer_dtype, is_list_like,
+                                is_datetime_arraylike, is_integer_dtype,
+                                is_list_like,
                                 is_datetime64_dtype, is_datetime64tz_dtype,
                                 is_timedelta64_dtype, is_categorical_dtype,
                                 get_dtype_kinds, take_1d)
 
+
 def is_datetimelike(data):
-    """ return a boolean if we can be successfully converted to a datetimelike """
+    """
+    return a boolean if we can be successfully converted to a datetimelike
+    """
     try:
         maybe_to_datetimelike(data)
         return True
@@ -22,6 +28,7 @@ def is_datetimelike(data):
         pass
     return False
 
+
 def maybe_to_datetimelike(data, copy=False):
     """
     return a DelegatedClass of a Series that is datetimelike
@@ -42,7 +49,8 @@ def maybe_to_datetimelike(data, copy=False):
     from pandas import Series
 
     if not isinstance(data, Series):
-        raise TypeError("cannot convert an object of type {0} to a datetimelike index".format(type(data)))
+        raise TypeError("cannot convert an object of type {0} to a "
+                        "datetimelike index".format(type(data)))
 
     index = data.index
     name = data.name
@@ -51,22 +59,28 @@ def maybe_to_datetimelike(data, copy=False):
         data = orig.values.categories
 
     if is_datetime64_dtype(data.dtype):
-        return DatetimeProperties(DatetimeIndex(data, copy=copy, freq='infer'), index, name=name,
-                                                orig=orig)
+        return DatetimeProperties(DatetimeIndex(data, copy=copy, freq='infer'),
+                                  index, name=name, orig=orig)
     elif is_datetime64tz_dtype(data.dtype):
-        return DatetimeProperties(DatetimeIndex(data, copy=copy, freq='infer', ambiguous='infer'),
+        return DatetimeProperties(DatetimeIndex(data, copy=copy, freq='infer',
+                                                ambiguous='infer'),
                                   index, data.name, orig=orig)
     elif is_timedelta64_dtype(data.dtype):
-        return TimedeltaProperties(TimedeltaIndex(data, copy=copy, freq='infer'), index,
+        return TimedeltaProperties(TimedeltaIndex(data, copy=copy,
+                                                  freq='infer'), index,
                                    name=name, orig=orig)
     else:
         if is_period_arraylike(data):
-            return PeriodProperties(PeriodIndex(data, copy=copy), index, name=name, orig=orig)
+            return PeriodProperties(PeriodIndex(data, copy=copy), index,
+                                    name=name, orig=orig)
         if is_datetime_arraylike(data):
-            return DatetimeProperties(DatetimeIndex(data, copy=copy, freq='infer'), index,
+            return DatetimeProperties(DatetimeIndex(data, copy=copy,
+                                                    freq='infer'), index,
                                       name=name, orig=orig)
 
-    raise TypeError("cannot convert an object of type {0} to a datetimelike index".format(type(data)))
+    raise TypeError("cannot convert an object of type {0} to a "
+                    "datetimelike index".format(type(data)))
+
 
 class Properties(PandasDelegate, NoNewAttributesMixin):
 
@@ -80,7 +94,7 @@ class Properties(PandasDelegate, NoNewAttributesMixin):
     def _delegate_property_get(self, name):
         from pandas import Series
 
-        result = getattr(self.values,name)
+        result = getattr(self.values, name)
 
         # maybe need to upcast (ints)
         if isinstance(result, np.ndarray):
@@ -97,14 +111,16 @@ class Properties(PandasDelegate, NoNewAttributesMixin):
         result = Series(result, index=self.index, name=self.name)
 
         # setting this object will show a SettingWithCopyWarning/Error
-        result.is_copy = ("modifications to a property of a datetimelike object are not "
-                          "supported and are discarded. Change values on the original.")
+        result.is_copy = ("modifications to a property of a datetimelike "
+                          "object are not supported and are discarded. "
+                          "Change values on the original.")
 
         return result
 
     def _delegate_property_set(self, name, value, *args, **kwargs):
-        raise ValueError("modifications to a property of a datetimelike object are not "
-                         "supported. Change values on the original.")
+        raise ValueError("modifications to a property of a datetimelike "
+                         "object are not supported. Change values on the "
+                         "original.")
 
     def _delegate_method(self, name, *args, **kwargs):
         from pandas import Series
@@ -118,8 +134,9 @@ class Properties(PandasDelegate, NoNewAttributesMixin):
         result = Series(result, index=self.index, name=self.name)
 
         # setting this object will show a SettingWithCopyWarning/Error
-        result.is_copy = ("modifications to a method of a datetimelike object are not "
-                          "supported and are discarded. Change values on the original.")
+        result.is_copy = ("modifications to a method of a datetimelike object "
+                          "are not supported and are discarded. Change "
+                          "values on the original.")
 
         return result
 
@@ -205,9 +222,10 @@ class PeriodProperties(Properties):
     Raises TypeError if the Series does not contain datetimelike values.
     """
 
-PeriodProperties._add_delegate_accessors(delegate=PeriodIndex,
-                                         accessors=PeriodIndex._datetimelike_ops,
-                                         typ='property')
+PeriodProperties._add_delegate_accessors(
+    delegate=PeriodIndex,
+    accessors=PeriodIndex._datetimelike_ops,
+    typ='property')
 PeriodProperties._add_delegate_accessors(delegate=PeriodIndex,
                                          accessors=["strftime"],
                                          typ='method')
@@ -222,8 +240,8 @@ class CombinedDatetimelikeProperties(DatetimeProperties, TimedeltaProperties):
 
 def _concat_compat(to_concat, axis=0):
     """
-    provide concatenation of an datetimelike array of arrays each of which is a single
-    M8[ns], datetimet64[ns, tz] or m8[ns] dtype
+    provide concatenation of an datetimelike array of arrays each of which is a
+    single M8[ns], datetimet64[ns, tz] or m8[ns] dtype
 
     Parameters
     ----------
@@ -258,19 +276,21 @@ def _concat_compat(to_concat, axis=0):
     if 'datetimetz' in typs:
 
         # we require ALL of the same tz for datetimetz
-        tzs = set([ getattr(x,'tz',None) for x in to_concat ])-set([None])
+        tzs = set([getattr(x, 'tz', None) for x in to_concat]) - set([None])
         if len(tzs) == 1:
-            return DatetimeIndex(np.concatenate([ x.tz_localize(None).asi8 for x in to_concat ]), tz=list(tzs)[0])
+            return DatetimeIndex(np.concatenate([x.tz_localize(None).asi8
+                                                 for x in to_concat]),
+                                 tz=list(tzs)[0])
 
     # single dtype
     if len(typs) == 1:
 
-        if not len(typs-set(['datetime'])):
+        if not len(typs - set(['datetime'])):
             new_values = np.concatenate([x.view(np.int64) for x in to_concat],
                                         axis=axis)
             return new_values.view(_NS_DTYPE)
 
-        elif not len(typs-set(['timedelta'])):
+        elif not len(typs - set(['timedelta'])):
             new_values = np.concatenate([x.view(np.int64) for x in to_concat],
                                         axis=axis)
             return new_values.view(_TD_DTYPE)
@@ -278,4 +298,4 @@ def _concat_compat(to_concat, axis=0):
     # need to coerce to object
     to_concat = [convert_to_pydatetime(x, axis) for x in to_concat]
 
-    return np.concatenate(to_concat,axis=axis)
+    return np.concatenate(to_concat, axis=axis)
diff --git a/pandas/tseries/converter.py b/pandas/tseries/converter.py
index 9bcb6348f..8ccfdfa05 100644
--- a/pandas/tseries/converter.py
+++ b/pandas/tseries/converter.py
@@ -23,9 +23,6 @@ import pandas.tseries.frequencies as frequencies
 from pandas.tseries.frequencies import FreqGroup
 from pandas.tseries.period import Period, PeriodIndex
 
-from matplotlib.dates import (HOURS_PER_DAY, MINUTES_PER_DAY,
-                              SEC_PER_DAY, MUSECONDS_PER_DAY)
-
 
 def register():
     units.registry[lib.Timestamp] = DatetimeConverter()
@@ -81,7 +78,7 @@ class TimeConverter(units.ConversionInterface):
         return 'time'
 
 
-### time formatter
+# time formatter
 class TimeFormatter(Formatter):
 
     def __init__(self, locs):
@@ -103,7 +100,7 @@ class TimeFormatter(Formatter):
         return pydt.time(h, m, s, us).strftime(fmt)
 
 
-### Period Conversion
+# Period Conversion
 
 
 class PeriodConverter(dates.DateConverter):
@@ -112,7 +109,8 @@ class PeriodConverter(dates.DateConverter):
     def convert(values, units, axis):
         if not hasattr(axis, 'freq'):
             raise TypeError('Axis must have `freq` set to convert to Periods')
-        valid_types = (compat.string_types, datetime, Period, pydt.date, pydt.time)
+        valid_types = (compat.string_types, datetime,
+                       Period, pydt.date, pydt.time)
         if (isinstance(values, valid_types) or com.is_integer(values) or
                 com.is_float(values)):
             return get_datevalue(values, axis.freq)
@@ -130,7 +128,8 @@ class PeriodConverter(dates.DateConverter):
 def get_datevalue(date, freq):
     if isinstance(date, Period):
         return date.asfreq(freq).ordinal
-    elif isinstance(date, (compat.string_types, datetime, pydt.date, pydt.time)):
+    elif isinstance(date, (compat.string_types, datetime,
+                           pydt.date, pydt.time)):
         return Period(date, freq).ordinal
     elif (com.is_integer(date) or com.is_float(date) or
           (isinstance(date, (np.ndarray, Index)) and (date.size == 1))):
@@ -146,14 +145,15 @@ def _dt_to_float_ordinal(dt):
     preserving hours, minutes, seconds and microseconds.  Return value
     is a :func:`float`.
     """
-    if isinstance(dt, (np.ndarray, Index, Series)) and com.is_datetime64_ns_dtype(dt):
+    if (isinstance(dt, (np.ndarray, Index, Series)) and
+            com.is_datetime64_ns_dtype(dt)):
         base = dates.epoch2num(dt.asi8 / 1.0E9)
     else:
         base = dates.date2num(dt)
     return base
 
 
-### Datetime Conversion
+# Datetime Conversion
 class DatetimeConverter(dates.DateConverter):
 
     @staticmethod
@@ -274,19 +274,20 @@ class MilliSecondLocator(dates.DateLocator):
 
         if dmin > dmax:
             dmax, dmin = dmin, dmax
-        delta = relativedelta(dmax, dmin)
-
         # We need to cap at the endpoints of valid datetime
-        try:
-            start = dmin - delta
-        except ValueError:
-            start = _from_ordinal(1.0)
 
-        try:
-            stop = dmax + delta
-        except ValueError:
-            # The magic number!
-            stop = _from_ordinal(3652059.9999999)
+        # TODO(wesm) unused?
+        # delta = relativedelta(dmax, dmin)
+        # try:
+        #     start = dmin - delta
+        # except ValueError:
+        #     start = _from_ordinal(1.0)
+
+        # try:
+        #     stop = dmax + delta
+        # except ValueError:
+        #     # The magic number!
+        #     stop = _from_ordinal(3652059.9999999)
 
         nmax, nmin = dates.date2num((dmax, dmin))
 
@@ -306,7 +307,7 @@ class MilliSecondLocator(dates.DateLocator):
             raise RuntimeError(('MillisecondLocator estimated to generate %d '
                                 'ticks from %s to %s: exceeds Locator.MAXTICKS'
                                 '* 2 (%d) ') %
-                              (estimate, dmin, dmax, self.MAXTICKS * 2))
+                               (estimate, dmin, dmax, self.MAXTICKS * 2))
 
         freq = '%dL' % self._get_interval()
         tz = self.tz.tzname(None)
@@ -318,7 +319,7 @@ class MilliSecondLocator(dates.DateLocator):
             if len(all_dates) > 0:
                 locs = self.raise_if_exceeds(dates.date2num(all_dates))
                 return locs
-        except Exception as e:  # pragma: no cover
+        except Exception:  # pragma: no cover
             pass
 
         lims = dates.date2num([dmin, dmax])
@@ -335,19 +336,21 @@ class MilliSecondLocator(dates.DateLocator):
         if dmin > dmax:
             dmax, dmin = dmin, dmax
 
-        delta = relativedelta(dmax, dmin)
-
         # We need to cap at the endpoints of valid datetime
-        try:
-            start = dmin - delta
-        except ValueError:
-            start = _from_ordinal(1.0)
 
-        try:
-            stop = dmax + delta
-        except ValueError:
-            # The magic number!
-            stop = _from_ordinal(3652059.9999999)
+        # TODO(wesm): unused?
+
+        # delta = relativedelta(dmax, dmin)
+        # try:
+        #     start = dmin - delta
+        # except ValueError:
+        #     start = _from_ordinal(1.0)
+
+        # try:
+        #     stop = dmax + delta
+        # except ValueError:
+        #     # The magic number!
+        #     stop = _from_ordinal(3652059.9999999)
 
         dmin, dmax = self.datalim_to_dt()
 
@@ -377,11 +380,11 @@ def _from_ordinal(x, tz=None):
 
     return dt
 
-### Fixed frequency dynamic tick locators and formatters
+# Fixed frequency dynamic tick locators and formatters
 
-##### -------------------------------------------------------------------------
-#---- --- Locators ---
-##### -------------------------------------------------------------------------
+# -------------------------------------------------------------------------
+# --- Locators ---
+# -------------------------------------------------------------------------
 
 
 def _get_default_annual_spacing(nyears):
@@ -660,7 +663,6 @@ def _daily_finder(vmin, vmax, freq):
         minor_idx = year_start[(year_break % min_anndef == 0)]
         info_min[minor_idx] = True
         info_fmt[major_idx] = '%Y'
-    #............................................
 
     return info
 
@@ -671,7 +673,7 @@ def _monthly_finder(vmin, vmax, freq):
     vmin_orig = vmin
     (vmin, vmax) = (int(vmin), int(vmax))
     span = vmax - vmin + 1
-    #..............
+
     # Initialize the output
     info = np.zeros(span,
                     dtype=[('val', int), ('maj', bool), ('min', bool),
@@ -682,7 +684,7 @@ def _monthly_finder(vmin, vmax, freq):
     year_start = (dates_ % 12 == 0).nonzero()[0]
     info_maj = info['maj']
     info_fmt = info['fmt']
-    #..............
+
     if span <= 1.15 * periodsperyear:
         info_maj[year_start] = True
         info['min'] = True
@@ -696,7 +698,7 @@ def _monthly_finder(vmin, vmax, freq):
             else:
                 idx = 0
             info_fmt[idx] = '%b\n%Y'
-    #..............
+
     elif span <= 2.5 * periodsperyear:
         quarter_start = (dates_ % 3 == 0).nonzero()
         info_maj[year_start] = True
@@ -706,7 +708,7 @@ def _monthly_finder(vmin, vmax, freq):
 
         info_fmt[quarter_start] = '%b'
         info_fmt[year_start] = '%b\n%Y'
-    #..............
+
     elif span <= 4 * periodsperyear:
         info_maj[year_start] = True
         info['min'] = True
@@ -714,14 +716,14 @@ def _monthly_finder(vmin, vmax, freq):
         jan_or_jul = (dates_ % 12 == 0) | (dates_ % 12 == 6)
         info_fmt[jan_or_jul] = '%b'
         info_fmt[year_start] = '%b\n%Y'
-    #..............
+
     elif span <= 11 * periodsperyear:
         quarter_start = (dates_ % 3 == 0).nonzero()
         info_maj[year_start] = True
         info['min'][quarter_start] = True
 
         info_fmt[year_start] = '%Y'
-    #..................
+
     else:
         nyears = span / periodsperyear
         (min_anndef, maj_anndef) = _get_default_annual_spacing(nyears)
@@ -731,7 +733,7 @@ def _monthly_finder(vmin, vmax, freq):
         info['min'][year_start[(years % min_anndef == 0)]] = True
 
         info_fmt[major_idx] = '%Y'
-    #..............
+
     return info
 
 
@@ -740,7 +742,7 @@ def _quarterly_finder(vmin, vmax, freq):
     vmin_orig = vmin
     (vmin, vmax) = (int(vmin), int(vmax))
     span = vmax - vmin + 1
-    #............................................
+
     info = np.zeros(span,
                     dtype=[('val', int), ('maj', bool), ('min', bool),
                            ('fmt', '|S8')])
@@ -750,7 +752,7 @@ def _quarterly_finder(vmin, vmax, freq):
     info_maj = info['maj']
     info_fmt = info['fmt']
     year_start = (dates_ % 4 == 0).nonzero()[0]
-    #..............
+
     if span <= 3.5 * periodsperyear:
         info_maj[year_start] = True
         info['min'] = True
@@ -763,12 +765,12 @@ def _quarterly_finder(vmin, vmax, freq):
             else:
                 idx = 0
             info_fmt[idx] = 'Q%q\n%F'
-    #..............
+
     elif span <= 11 * periodsperyear:
         info_maj[year_start] = True
         info['min'] = True
         info_fmt[year_start] = '%F'
-    #..............
+
     else:
         years = dates_[year_start] // 4 + 1
         nyears = span / periodsperyear
@@ -777,27 +779,27 @@ def _quarterly_finder(vmin, vmax, freq):
         info_maj[major_idx] = True
         info['min'][year_start[(years % min_anndef == 0)]] = True
         info_fmt[major_idx] = '%F'
-    #..............
+
     return info
 
 
 def _annual_finder(vmin, vmax, freq):
     (vmin, vmax) = (int(vmin), int(vmax + 1))
     span = vmax - vmin + 1
-    #..............
+
     info = np.zeros(span,
                     dtype=[('val', int), ('maj', bool), ('min', bool),
                            ('fmt', '|S8')])
     info['val'] = np.arange(vmin, vmax + 1)
     info['fmt'] = ''
     dates_ = info['val']
-    #..............
+
     (min_anndef, maj_anndef) = _get_default_annual_spacing(span)
     major_idx = dates_ % maj_anndef == 0
     info['maj'][major_idx] = True
     info['min'][(dates_ % min_anndef == 0)] = True
     info['fmt'][major_idx] = '%Y'
-    #..............
+
     return info
 
 
@@ -896,9 +898,9 @@ class TimeSeries_DateLocator(Locator):
             vmax += 1
         return nonsingular(vmin, vmax)
 
-#####-------------------------------------------------------------------------
-#---- --- Formatter ---
-#####-------------------------------------------------------------------------
+# -------------------------------------------------------------------------
+# --- Formatter ---
+# -------------------------------------------------------------------------
 
 
 class TimeSeries_DateFormatter(Formatter):
diff --git a/pandas/tseries/frequencies.py b/pandas/tseries/frequencies.py
index fced24c70..d83b0e3f2 100644
--- a/pandas/tseries/frequencies.py
+++ b/pandas/tseries/frequencies.py
@@ -1,4 +1,4 @@
-from datetime import datetime,timedelta
+from datetime import timedelta
 from pandas.compat import range, long, zip
 from pandas import compat
 import re
@@ -17,6 +17,7 @@ import pandas._period as period
 from pandas.tslib import Timedelta
 from pytz import AmbiguousTimeError
 
+
 class FreqGroup(object):
     FR_ANN = 1000
     FR_QTR = 2000
@@ -44,28 +45,29 @@ class Resolution(object):
     RESO_DAY = period.D_RESO
 
     _reso_str_map = {
-    RESO_US: 'microsecond',
-    RESO_MS: 'millisecond',
-    RESO_SEC: 'second',
-    RESO_MIN: 'minute',
-    RESO_HR: 'hour',
-    RESO_DAY: 'day'}
+        RESO_US: 'microsecond',
+        RESO_MS: 'millisecond',
+        RESO_SEC: 'second',
+        RESO_MIN: 'minute',
+        RESO_HR: 'hour',
+        RESO_DAY: 'day'}
 
     _str_reso_map = dict([(v, k) for k, v in compat.iteritems(_reso_str_map)])
 
     _reso_freq_map = {
-    'year': 'A',
-    'quarter': 'Q',
-    'month': 'M',
-    'day': 'D',
-    'hour': 'H',
-    'minute': 'T',
-    'second': 'S',
-    'millisecond': 'L',
-    'microsecond': 'U',
-    'nanosecond': 'N'}
-
-    _freq_reso_map = dict([(v, k) for k, v in compat.iteritems(_reso_freq_map)])
+        'year': 'A',
+        'quarter': 'Q',
+        'month': 'M',
+        'day': 'D',
+        'hour': 'H',
+        'minute': 'T',
+        'second': 'S',
+        'millisecond': 'L',
+        'microsecond': 'U',
+        'nanosecond': 'N'}
+
+    _freq_reso_map = dict([(v, k)
+                           for k, v in compat.iteritems(_reso_freq_map)])
 
     @classmethod
     def get_str(cls, reso):
@@ -277,11 +279,12 @@ def _get_freq_str(base, mult=1):
     return str(mult) + code
 
 
-#----------------------------------------------------------------------
+# ---------------------------------------------------------------------
 # Offset names ("time rules") and related functions
 
 
-from pandas.tseries.offsets import (Nano, Micro, Milli, Second, Minute, Hour,
+from pandas.tseries.offsets import (Nano, Micro, Milli, Second,  # noqa
+                                    Minute, Hour,
                                     Day, BDay, CDay, Week, MonthBegin,
                                     MonthEnd, BMonthBegin, BMonthEnd,
                                     QuarterBegin, QuarterEnd, BQuarterBegin,
@@ -384,7 +387,7 @@ _lite_rule_alias = {
     'us': 'U'
 }
 
-#TODO: Can this be killed?
+# TODO: Can this be killed?
 for _i, _weekday in enumerate(['MON', 'TUE', 'WED', 'THU', 'FRI']):
     for _iweek in range(4):
         _name = 'WOM-%d%s' % (_iweek + 1, _weekday)
@@ -404,6 +407,7 @@ _name_to_offset_map = {'days': Day(1),
                        'microseconds': Micro(1),
                        'nanoseconds': Nano(1)}
 
+
 def to_offset(freqstr):
     """
     Return DateOffset object from string representation or
@@ -548,7 +552,8 @@ def get_offset(name):
         try:
             split = name.split('-')
             klass = prefix_mapping[split[0]]
-            # handles case where there's no suffix (and will TypeError if too many '-')
+            # handles case where there's no suffix (and will TypeError if too
+            # many '-')
             offset = klass._from_name(*split[1:])
         except (ValueError, TypeError, KeyError):
             # bad prefix or suffix
@@ -586,6 +591,7 @@ def get_legacy_offset_name(offset):
     name = offset.name
     return _legacy_reverse_map.get(name, name)
 
+
 def get_standard_freq(freq):
     """
     Return the standardized frequency string
@@ -599,7 +605,7 @@ def get_standard_freq(freq):
     code, stride = get_freq_code(freq)
     return _get_freq_str(code, stride)
 
-#----------------------------------------------------------------------
+# ---------------------------------------------------------------------
 # Period codes
 
 # period frequency constants corresponding to scikits timeseries
@@ -815,7 +821,7 @@ def infer_freq(index, warn=True):
     Parameters
     ----------
     index : DatetimeIndex or TimedeltaIndex
-            if passed a Series will use the values of the series (NOT THE INDEX)
+      if passed a Series will use the values of the series (NOT THE INDEX)
     warn : boolean, default True
 
     Returns
@@ -829,8 +835,11 @@ def infer_freq(index, warn=True):
 
     if isinstance(index, com.ABCSeries):
         values = index._values
-        if not (com.is_datetime64_dtype(values) or com.is_timedelta64_dtype(values) or values.dtype == object):
-            raise TypeError("cannot infer freq from a non-convertible dtype on a Series of {0}".format(index.dtype))
+        if not (com.is_datetime64_dtype(values) or
+                com.is_timedelta64_dtype(values) or
+                values.dtype == object):
+            raise TypeError("cannot infer freq from a non-convertible "
+                            "dtype on a Series of {0}".format(index.dtype))
         index = values
 
     if com.is_period_arraylike(index):
@@ -842,7 +851,8 @@ def infer_freq(index, warn=True):
 
     if isinstance(index, pd.Index) and not isinstance(index, pd.DatetimeIndex):
         if isinstance(index, (pd.Int64Index, pd.Float64Index)):
-            raise TypeError("cannot infer freq from a non-convertible index type {0}".format(type(index)))
+            raise TypeError("cannot infer freq from a non-convertible index "
+                            "type {0}".format(type(index)))
         index = index.values
 
     if not isinstance(index, pd.DatetimeIndex):
@@ -873,7 +883,7 @@ class _FrequencyInferer(object):
 
         # This moves the values, which are implicitly in UTC, to the
         # the timezone so they are in local time
-        if hasattr(index,'tz'):
+        if hasattr(index, 'tz'):
             if index.tz is not None:
                 self.values = tslib.tz_convert(self.values, 'UTC', index.tz)
 
@@ -1069,10 +1079,10 @@ class _FrequencyInferer(object):
                 'ce': 'M', 'be': 'BM'}.get(pos_check)
 
     def _get_wom_rule(self):
-#         wdiffs = unique(np.diff(self.index.week))
-        #We also need -47, -49, -48 to catch index spanning year boundary
-#         if not lib.ismember(wdiffs, set([4, 5, -47, -49, -48])).all():
-#             return None
+        #         wdiffs = unique(np.diff(self.index.week))
+        # We also need -47, -49, -48 to catch index spanning year boundary
+        #     if not lib.ismember(wdiffs, set([4, 5, -47, -49, -48])).all():
+        #         return None
 
         weekdays = unique(self.index.weekday)
         if len(weekdays) > 1:
@@ -1092,6 +1102,7 @@ class _FrequencyInferer(object):
 
 import pandas.core.algorithms as algos
 
+
 class _TimedeltaFrequencyInferer(_FrequencyInferer):
 
     def _infer_daily_rule(self):
@@ -1262,5 +1273,6 @@ _month_numbers = tslib._MONTH_NUMBERS
 _month_aliases = tslib._MONTH_ALIASES
 _weekday_rule_aliases = dict((k, v) for k, v in enumerate(DAYS))
 
+
 def _is_multiple(us, mult):
     return us % mult == 0
diff --git a/pandas/tseries/holiday.py b/pandas/tseries/holiday.py
index 813354b2d..31e40c6bc 100644
--- a/pandas/tseries/holiday.py
+++ b/pandas/tseries/holiday.py
@@ -3,7 +3,7 @@ import warnings
 from pandas import DateOffset, DatetimeIndex, Series, Timestamp
 from pandas.compat import add_metaclass
 from datetime import datetime, timedelta
-from dateutil.relativedelta import MO, TU, WE, TH, FR, SA, SU
+from dateutil.relativedelta import MO, TU, WE, TH, FR, SA, SU  # noqa
 from pandas.tseries.offsets import Easter, Day
 import numpy as np
 
@@ -19,6 +19,7 @@ def next_monday(dt):
         return dt + timedelta(1)
     return dt
 
+
 def next_monday_or_tuesday(dt):
     """
     For second holiday of two adjacent ones!
@@ -33,6 +34,7 @@ def next_monday_or_tuesday(dt):
         return dt + timedelta(1)
     return dt
 
+
 def previous_friday(dt):
     """
     If holiday falls on Saturday or Sunday, use previous Friday instead.
@@ -43,6 +45,7 @@ def previous_friday(dt):
         return dt - timedelta(2)
     return dt
 
+
 def sunday_to_monday(dt):
     """
     If holiday falls on Sunday, use day thereafter (Monday) instead.
@@ -119,6 +122,7 @@ class Holiday(object):
     Class that defines a holiday with start/end dates and rules
     for observance.
     """
+
     def __init__(self, name, year=None, month=None, day=None, offset=None,
                  observance=None, start_date=None, end_date=None,
                  days_of_week=None):
@@ -159,8 +163,10 @@ class Holiday(object):
         self.month = month
         self.day = day
         self.offset = offset
-        self.start_date = Timestamp(start_date) if start_date is not None else start_date
-        self.end_date = Timestamp(end_date) if end_date is not None else end_date
+        self.start_date = Timestamp(
+            start_date) if start_date is not None else start_date
+        self.end_date = Timestamp(
+            end_date) if end_date is not None else end_date
         self.observance = observance
         assert (days_of_week is None or type(days_of_week) == tuple)
         self.days_of_week = days_of_week
@@ -212,16 +218,17 @@ class Holiday(object):
                                                   self.days_of_week)]
 
         if self.start_date is not None:
-            filter_start_date = max(self.start_date.tz_localize(filter_start_date.tz), filter_start_date)
+            filter_start_date = max(self.start_date.tz_localize(
+                filter_start_date.tz), filter_start_date)
         if self.end_date is not None:
-            filter_end_date = min(self.end_date.tz_localize(filter_end_date.tz), filter_end_date)
+            filter_end_date = min(self.end_date.tz_localize(
+                filter_end_date.tz), filter_end_date)
         holiday_dates = holiday_dates[(holiday_dates >= filter_start_date) &
                                       (holiday_dates <= filter_end_date)]
         if return_name:
             return Series(self.name, index=holiday_dates)
         return holiday_dates
 
-
     def _reference_dates(self, start_date, end_date):
         """
         Get reference dates for the holiday.
@@ -239,12 +246,13 @@ class Holiday(object):
 
         year_offset = DateOffset(years=1)
         reference_start_date = Timestamp(
-            datetime(start_date.year-1, self.month, self.day))
+            datetime(start_date.year - 1, self.month, self.day))
 
         reference_end_date = Timestamp(
-            datetime(end_date.year+1, self.month, self.day))
+            datetime(end_date.year + 1, self.month, self.day))
         # Don't process unnecessary holidays
-        dates = DatetimeIndex(start=reference_start_date, end=reference_end_date,
+        dates = DatetimeIndex(start=reference_start_date,
+                              end=reference_end_date,
                               freq=year_offset, tz=start_date.tz)
 
         return dates
@@ -279,6 +287,8 @@ class Holiday(object):
         return dates
 
 holiday_calendars = {}
+
+
 def register(cls):
     try:
         name = cls.name
@@ -286,6 +296,7 @@ def register(cls):
         name = cls.__name__
     holiday_calendars[name] = cls
 
+
 def get_calendar(name):
     """
     Return an instance of a calendar based on its name.
@@ -297,12 +308,16 @@ def get_calendar(name):
     """
     return holiday_calendars[name]()
 
+
 class HolidayCalendarMetaClass(type):
+
     def __new__(cls, clsname, bases, attrs):
-        calendar_class = super(HolidayCalendarMetaClass, cls).__new__(cls, clsname, bases, attrs)
+        calendar_class = super(HolidayCalendarMetaClass, cls).__new__(
+            cls, clsname, bases, attrs)
         register(calendar_class)
         return calendar_class
 
+
 @add_metaclass(HolidayCalendarMetaClass)
 class AbstractHolidayCalendar(object):
     """
@@ -371,8 +386,10 @@ class AbstractHolidayCalendar(object):
         end = Timestamp(end)
 
         holidays = None
-        # If we don't have a cache or the dates are outside the prior cache, we get them again
-        if self._cache is None or start < self._cache[0] or end > self._cache[1]:
+        # If we don't have a cache or the dates are outside the prior cache, we
+        # get them again
+        if (self._cache is None or start < self._cache[0] or
+                end > self._cache[1]):
             for rule in self.rules:
                 rule_holidays = rule.dates(start, end, return_name=True)
 
@@ -400,8 +417,10 @@ class AbstractHolidayCalendar(object):
 
         Parameters
         ----------
-        base : AbstractHolidayCalendar instance/subclass or array of Holiday objects
-        other : AbstractHolidayCalendar instance/subclass or array of Holiday objects
+        base : AbstractHolidayCalendar
+          instance/subclass or array of Holiday objects
+        other : AbstractHolidayCalendar
+          instance/subclass or array of Holiday objects
         """
         try:
             other = other.rules
@@ -450,34 +469,39 @@ USColumbusDay = Holiday('Columbus Day', month=10, day=1,
                         offset=DateOffset(weekday=MO(2)))
 USThanksgivingDay = Holiday('Thanksgiving', month=11, day=1,
                             offset=DateOffset(weekday=TH(4)))
-USMartinLutherKingJr = Holiday('Dr. Martin Luther King Jr.', start_date=datetime(1986,1,1), month=1, day=1,
+USMartinLutherKingJr = Holiday('Dr. Martin Luther King Jr.',
+                               start_date=datetime(1986, 1, 1), month=1, day=1,
                                offset=DateOffset(weekday=MO(3)))
 USPresidentsDay = Holiday('President''s Day', month=2, day=1,
                           offset=DateOffset(weekday=MO(3)))
 GoodFriday = Holiday("Good Friday", month=1, day=1, offset=[Easter(), Day(-2)])
 
-EasterMonday = Holiday("Easter Monday", month=1, day=1, offset=[Easter(), Day(1)])
+EasterMonday = Holiday("Easter Monday", month=1, day=1,
+                       offset=[Easter(), Day(1)])
 
 
 class USFederalHolidayCalendar(AbstractHolidayCalendar):
     """
-    US Federal Government Holiday Calendar based on rules specified
-    by: https://www.opm.gov/policy-data-oversight/snow-dismissal-procedures/federal-holidays/
+    US Federal Government Holiday Calendar based on rules specified by:
+    https://www.opm.gov/policy-data-oversight/
+       snow-dismissal-procedures/federal-holidays/
     """
     rules = [
-        Holiday('New Years Day', month=1,  day=1,  observance=nearest_workday),
+        Holiday('New Years Day', month=1, day=1, observance=nearest_workday),
         USMartinLutherKingJr,
         USPresidentsDay,
         USMemorialDay,
-        Holiday('July 4th', month=7,  day=4,  observance=nearest_workday),
+        Holiday('July 4th', month=7, day=4, observance=nearest_workday),
         USLaborDay,
         USColumbusDay,
         Holiday('Veterans Day', month=11, day=11, observance=nearest_workday),
         USThanksgivingDay,
         Holiday('Christmas', month=12, day=25, observance=nearest_workday)
-        ]
+    ]
+
 
-def HolidayCalendarFactory(name, base, other, base_class=AbstractHolidayCalendar):
+def HolidayCalendarFactory(name, base, other,
+                           base_class=AbstractHolidayCalendar):
     rules = AbstractHolidayCalendar.merge_class(base, other)
     calendar_class = type(name, (base_class,), {"rules": rules, "name": name})
     return calendar_class
diff --git a/pandas/tseries/index.py b/pandas/tseries/index.py
index 0dae56435..bb4f87815 100644
--- a/pandas/tseries/index.py
+++ b/pandas/tseries/index.py
@@ -52,14 +52,18 @@ def _field_accessor(name, field, docstring=None):
                 values = self._local_timestamps()
 
         if field in ['is_month_start', 'is_month_end',
-                    'is_quarter_start', 'is_quarter_end',
-                    'is_year_start', 'is_year_end']:
-            month_kw = self.freq.kwds.get('startingMonth', self.freq.kwds.get('month', 12)) if self.freq else 12
-            result = tslib.get_start_end_field(values, field, self.freqstr, month_kw)
+                     'is_quarter_start', 'is_quarter_end',
+                     'is_year_start', 'is_year_end']:
+            month_kw = (self.freq.kwds.get('startingMonth',
+                                           self.freq.kwds.get('month', 12))
+                        if self.freq else 12)
+
+            result = tslib.get_start_end_field(
+                values, field, self.freqstr, month_kw)
         else:
             result = tslib.get_date_field(values, field)
 
-        return self._maybe_mask_results(result,convert='float64')
+        return self._maybe_mask_results(result, convert='float64')
 
     f.__name__ = name
     f.__doc__ = docstring
@@ -70,9 +74,11 @@ def _dt_index_cmp(opname, nat_result=False):
     """
     Wrap comparison operations to convert datetime-like to datetime64
     """
+
     def wrapper(self, other):
         func = getattr(super(DatetimeIndex, self), opname)
-        if isinstance(other, datetime) or isinstance(other, compat.string_types):
+        if (isinstance(other, datetime) or
+                isinstance(other, compat.string_types)):
             other = _to_m8(other, tz=self.tz)
             result = func(other)
             if com.isnull(other):
@@ -118,14 +124,16 @@ def _new_DatetimeIndex(cls, d):
 
     # data are already in UTC
     # so need to localize
-    tz = d.pop('tz',None)
+    tz = d.pop('tz', None)
 
     result = cls.__new__(cls, verify_integrity=False, **d)
     if tz is not None:
         result = result.tz_localize('UTC').tz_convert(tz)
     return result
 
-class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index):
+
+class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
+                    Int64Index):
     """
     Immutable ndarray of datetime64 data, represented internally as int64, and
     which can be boxed to Timestamp objects that are subclasses of datetime and
@@ -153,9 +161,11 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
         the 'left', 'right', or both sides (None)
     tz : pytz.timezone or dateutil.tz.tzfile
     ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'
-        - 'infer' will attempt to infer fall dst-transition hours based on order
-        - bool-ndarray where True signifies a DST time, False signifies
-          a non-DST time (note that this flag is only applicable for ambiguous times)
+        - 'infer' will attempt to infer fall dst-transition hours based on
+          order
+        - bool-ndarray where True signifies a DST time, False signifies a
+          non-DST time (note that this flag is only applicable for ambiguous
+          times)
         - 'NaT' will return NaT where there are ambiguous times
         - 'raise' will raise an AmbiguousTimeError if there are ambiguous times
     infer_dst : boolean, default False (DEPRECATED)
@@ -168,7 +178,8 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
     _join_precedence = 10
 
     def _join_i8_wrapper(joinf, **kwargs):
-        return DatetimeIndexOpsMixin._join_i8_wrapper(joinf, dtype='M8[ns]', **kwargs)
+        return DatetimeIndexOpsMixin._join_i8_wrapper(joinf, dtype='M8[ns]',
+                                                      **kwargs)
 
     _inner_indexer = _join_i8_wrapper(_algos.inner_join_indexer_int64)
     _outer_indexer = _join_i8_wrapper(_algos.outer_join_indexer_int64)
@@ -190,11 +201,13 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
     offset = None
     _comparables = ['name', 'freqstr', 'tz']
     _attributes = ['name', 'freq', 'tz']
-    _datetimelike_ops = ['year','month','day','hour','minute','second',
-                         'weekofyear','week','dayofweek','weekday','dayofyear','quarter', 'days_in_month', 'daysinmonth',
-                         'date','time','microsecond','nanosecond','is_month_start','is_month_end',
-                         'is_quarter_start','is_quarter_end','is_year_start','is_year_end',
-                         'tz','freq']
+    _datetimelike_ops = ['year', 'month', 'day', 'hour', 'minute', 'second',
+                         'weekofyear', 'week', 'dayofweek', 'weekday',
+                         'dayofyear', 'quarter', 'days_in_month',
+                         'daysinmonth', 'date', 'time', 'microsecond',
+                         'nanosecond', 'is_month_start', 'is_month_end',
+                         'is_quarter_start', 'is_quarter_end', 'is_year_start',
+                         'is_year_end', 'tz', 'freq']
     _is_numeric_dtype = False
     _infer_as_myclass = True
 
@@ -300,14 +313,14 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
                 values = data
 
             if lib.is_string_array(values):
-                subarr = tslib.parse_str_array_to_datetime(values, freq=freq, dayfirst=dayfirst,
-                                                     yearfirst=yearfirst)
-
+                subarr = tslib.parse_str_array_to_datetime(
+                    values, freq=freq, dayfirst=dayfirst, yearfirst=yearfirst)
             else:
                 try:
                     subarr = tools.to_datetime(data, box=False)
 
-                    # make sure that we have a index/ndarray like (and not a Series)
+                    # make sure that we have a index/ndarray like (and not a
+                    # Series)
                     if isinstance(subarr, ABCSeries):
                         subarr = subarr._values
                         if subarr.dtype == np.object_:
@@ -318,7 +331,8 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
                     subarr = tools._to_datetime(data, box=False, utc=True)
 
                 # we may not have been able to convert
-                if not (is_datetimetz(subarr) or np.issubdtype(subarr.dtype, np.datetime64)):
+                if not (is_datetimetz(subarr) or
+                        np.issubdtype(subarr.dtype, np.datetime64)):
                     raise ValueError('Unable to convert %s to datetime dtype'
                                      % str(data))
 
@@ -354,10 +368,13 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
             if freq is not None and not freq_infer:
                 inferred = subarr.inferred_freq
                 if inferred != freq.freqstr:
-                    on_freq = cls._generate(subarr[0], None, len(subarr), None, freq, tz=tz, ambiguous=ambiguous)
+                    on_freq = cls._generate(subarr[0], None, len(
+                        subarr), None, freq, tz=tz, ambiguous=ambiguous)
                     if not np.array_equal(subarr.asi8, on_freq.asi8):
-                        raise ValueError('Inferred frequency {0} from passed dates does not '
-                                         'conform to passed frequency {1}'.format(inferred, freq.freqstr))
+                        raise ValueError('Inferred frequency {0} from passed '
+                                         'dates does not conform to passed '
+                                         'frequency {1}'
+                                         .format(inferred, freq.freqstr))
 
         if freq_infer:
             inferred = subarr.inferred_freq
@@ -402,7 +419,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
             inferred_tz = tools._infer_tzinfo(start, end)
         except:
             raise TypeError('Start and end cannot both be tz-aware with '
-                             'different timezones')
+                            'different timezones')
 
         inferred_tz = tslib.maybe_get_tz(inferred_tz)
 
@@ -486,7 +503,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
                 index = index.view(_NS_DTYPE)
 
         index = cls._simple_new(index, name=name, freq=offset, tz=tz)
-        if not left_closed and len(index) and  index[0] == start:
+        if not left_closed and len(index) and index[0] == start:
             index = index[1:]
         if not right_closed and len(index) and index[-1] == end:
             index = index[:-1]
@@ -519,21 +536,24 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
             return result.take(reverse)
 
     @classmethod
-    def _simple_new(cls, values, name=None, freq=None, tz=None, dtype=None, **kwargs):
+    def _simple_new(cls, values, name=None, freq=None, tz=None,
+                    dtype=None, **kwargs):
         """
         we require the we have a dtype compat for the values
         if we are passed a non-dtype compat, then coerce using the constructor
         """
 
-        if not getattr(values,'dtype',None):
+        if not getattr(values, 'dtype', None):
             # empty, but with dtype compat
             if values is None:
                 values = np.empty(0, dtype=_NS_DTYPE)
-                return cls(values, name=name, freq=freq, tz=tz, dtype=dtype, **kwargs)
-            values = np.array(values,copy=False)
+                return cls(values, name=name, freq=freq, tz=tz,
+                           dtype=dtype, **kwargs)
+            values = np.array(values, copy=False)
 
         if is_object_dtype(values):
-            return cls(values, name=name, freq=freq, tz=tz, dtype=dtype, **kwargs).values
+            return cls(values, name=name, freq=freq, tz=tz,
+                       dtype=dtype, **kwargs).values
         elif not is_datetime64_dtype(values):
             values = com._ensure_int64(values).view(_NS_DTYPE)
 
@@ -571,18 +591,20 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
     def _cached_range(cls, start=None, end=None, periods=None, offset=None,
                       name=None):
         if start is None and end is None:
-            # I somewhat believe this should never be raised externally and therefore
-            # should be a `PandasError` but whatever...
+            # I somewhat believe this should never be raised externally and
+            # therefore should be a `PandasError` but whatever...
             raise TypeError('Must specify either start or end.')
         if start is not None:
             start = Timestamp(start)
         if end is not None:
             end = Timestamp(end)
         if (start is None or end is None) and periods is None:
-            raise TypeError('Must either specify period or provide both start and end.')
+            raise TypeError(
+                'Must either specify period or provide both start and end.')
 
         if offset is None:
-            # This can't happen with external-facing code, therefore PandasError
+            # This can't happen with external-facing code, therefore
+            # PandasError
             raise TypeError('Must provide offset.')
 
         drc = _daterange_cache
@@ -700,12 +722,13 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
 
         # require tz compat
         if not self._has_same_tz(other):
-            raise TypeError("Timestamp subtraction must have the same timezones or no timezones")
+            raise TypeError("Timestamp subtraction must have the same "
+                            "timezones or no timezones")
 
         i8 = self.asi8
         result = i8 - other.value
-        result = self._maybe_mask_results(result,fill_value=tslib.iNaT)
-        return TimedeltaIndex(result,name=self.name,copy=False)
+        result = self._maybe_mask_results(result, fill_value=tslib.iNaT)
+        return TimedeltaIndex(result, name=self.name, copy=False)
 
     def _maybe_update_attributes(self, attrs):
         """ Update Index attributes (e.g. freq) depending on op """
@@ -749,8 +772,8 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
             return result
 
         except NotImplementedError:
-            warnings.warn("Non-vectorized DateOffset being applied to Series or DatetimeIndex",
-                           PerformanceWarning)
+            warnings.warn("Non-vectorized DateOffset being applied to Series "
+                          "or DatetimeIndex", PerformanceWarning)
             return self.astype('O') + offset
 
     def _format_native_types(self, na_rep=u('NaT'),
@@ -795,20 +818,20 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
         Parameters
         ----------
         keep_tz : optional, defaults False.
-                  return the data keeping the timezone.
+            return the data keeping the timezone.
 
-                  If keep_tz is True:
+            If keep_tz is True:
 
-                    If the timezone is not set, the resulting
-                    Series will have a datetime64[ns] dtype.
+              If the timezone is not set, the resulting
+              Series will have a datetime64[ns] dtype.
 
-                    Otherwise the Series will have an datetime64[ns, tz] dtype; the
-                    tz will be preserved.
+              Otherwise the Series will have an datetime64[ns, tz] dtype; the
+              tz will be preserved.
 
-                  If keep_tz is False:
+            If keep_tz is False:
 
-                    Series will have a datetime64[ns] dtype. TZ aware
-                    objects will have the tz removed.
+              Series will have a datetime64[ns] dtype. TZ aware
+              objects will have the tz removed.
 
         Returns
         -------
@@ -850,7 +873,8 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
             freq = self.freqstr or self.inferred_freq
 
             if freq is None:
-                msg = "You must pass a freq argument as current index has none."
+                msg = ("You must pass a freq argument as "
+                       "current index has none.")
                 raise ValueError(msg)
 
             freq = get_period_alias(freq)
@@ -931,7 +955,8 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
         -------
         y : TimedeltaIndex
         """
-        return to_timedelta(self.asi8 - self.to_period(freq).to_timestamp().asi8)
+        return to_timedelta(self.asi8 - self.to_period(freq)
+                            .to_timestamp().asi8)
 
     def union_many(self, others):
         """
@@ -1116,9 +1141,10 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
         chunksize = 10000
         chunks = int(l / chunksize) + 1
         for i in range(chunks):
-            start_i = i*chunksize
-            end_i = min((i+1)*chunksize,l)
-            converted = tslib.ints_to_pydatetime(data[start_i:end_i], tz=self.tz, offset=self.offset, box=True)
+            start_i = i * chunksize
+            end_i = min((i + 1) * chunksize, l)
+            converted = tslib.ints_to_pydatetime(
+                data[start_i:end_i], tz=self.tz, offset=self.offset, box=True)
             for v in converted:
                 yield v
 
@@ -1199,23 +1225,28 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
         lower, upper: pd.Timestamp
 
         """
-        is_monotonic = self.is_monotonic
         if reso == 'year':
             return (Timestamp(datetime(parsed.year, 1, 1), tz=self.tz),
-                    Timestamp(datetime(parsed.year, 12, 31, 23, 59, 59, 999999), tz=self.tz))
+                    Timestamp(datetime(parsed.year, 12, 31, 23,
+                                       59, 59, 999999), tz=self.tz))
         elif reso == 'month':
             d = tslib.monthrange(parsed.year, parsed.month)[1]
-            return (Timestamp(datetime(parsed.year, parsed.month, 1), tz=self.tz),
-                    Timestamp(datetime(parsed.year, parsed.month, d, 23, 59, 59, 999999), tz=self.tz))
+            return (Timestamp(datetime(parsed.year, parsed.month, 1),
+                              tz=self.tz),
+                    Timestamp(datetime(parsed.year, parsed.month, d, 23,
+                                       59, 59, 999999), tz=self.tz))
         elif reso == 'quarter':
             qe = (((parsed.month - 1) + 2) % 12) + 1  # two months ahead
             d = tslib.monthrange(parsed.year, qe)[1]   # at end of month
-            return (Timestamp(datetime(parsed.year, parsed.month, 1), tz=self.tz),
-                    Timestamp(datetime(parsed.year, qe, d, 23, 59, 59, 999999), tz=self.tz))
+            return (Timestamp(datetime(parsed.year, parsed.month, 1),
+                              tz=self.tz),
+                    Timestamp(datetime(parsed.year, qe, d, 23, 59,
+                                       59, 999999), tz=self.tz))
         elif reso == 'day':
             st = datetime(parsed.year, parsed.month, parsed.day)
             return (Timestamp(st, tz=self.tz),
-                    Timestamp(Timestamp(st + offsets.Day(), tz=self.tz).value - 1))
+                    Timestamp(Timestamp(st + offsets.Day(),
+                                        tz=self.tz).value - 1))
         elif reso == 'hour':
             st = datetime(parsed.year, parsed.month, parsed.day,
                           hour=parsed.hour)
@@ -1230,7 +1261,8 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
                                         tz=self.tz).value - 1))
         elif reso == 'second':
             st = datetime(parsed.year, parsed.month, parsed.day,
-                          hour=parsed.hour, minute=parsed.minute, second=parsed.second)
+                          hour=parsed.hour, minute=parsed.minute,
+                          second=parsed.second)
             return (Timestamp(st, tz=self.tz),
                     Timestamp(Timestamp(st + offsets.Second(),
                                         tz=self.tz).value - 1))
@@ -1265,14 +1297,17 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
         if is_monotonic:
 
             # we are out of range
-            if len(stamps) and (
-                (use_lhs and t1.value < stamps[0] and t2.value < stamps[0]) or (
-                (use_rhs and t1.value > stamps[-1] and t2.value > stamps[-1]))):
+            if (len(stamps) and ((use_lhs and t1.value < stamps[0] and
+                                  t2.value < stamps[0]) or
+                                 ((use_rhs and t1.value > stamps[-1] and
+                                   t2.value > stamps[-1])))):
                 raise KeyError
 
             # a monotonic (sorted) series can be sliced
-            left = stamps.searchsorted(t1.value, side='left') if use_lhs else None
-            right = stamps.searchsorted(t2.value, side='right') if use_rhs else None
+            left = stamps.searchsorted(
+                t1.value, side='left') if use_lhs else None
+            right = stamps.searchsorted(
+                t2.value, side='right') if use_rhs else None
 
             return slice(left, right)
 
@@ -1306,7 +1341,8 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
             return series.take(locs)
 
         try:
-            return _maybe_box(self, Index.get_value(self, series, key), series, key)
+            return _maybe_box(self, Index.get_value(self, series, key),
+                              series, key)
         except KeyError:
             try:
                 loc = self._get_string_slice(key)
@@ -1386,7 +1422,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
 
         """
         if is_float(label) or isinstance(label, time) or is_integer(label):
-            self._invalid_indexer('slice',label)
+            self._invalid_indexer('slice', label)
 
         if isinstance(label, compat.string_types):
             freq = getattr(self, 'freqstr',
@@ -1437,14 +1473,16 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
             # value-based partial (aka string) slices on non-monotonic arrays,
             # let's try that.
             if ((start is None or isinstance(start, compat.string_types)) and
-                (end is None or isinstance(end, compat.string_types))):
+                    (end is None or isinstance(end, compat.string_types))):
                 mask = True
                 if start is not None:
-                    start_casted = self._maybe_cast_slice_bound(start, 'left', kind)
+                    start_casted = self._maybe_cast_slice_bound(
+                        start, 'left', kind)
                     mask = start_casted <= self
 
                 if end is not None:
-                    end_casted = self._maybe_cast_slice_bound(end, 'right', kind)
+                    end_casted = self._maybe_cast_slice_bound(
+                        end, 'right', kind)
                     mask = (self <= end_casted) & mask
 
                 indexer = mask.nonzero()[0][::step]
@@ -1461,10 +1499,12 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
 
     def _set_freq(self, value):
         self.offset = value
-    freq = property(fget=_get_freq, fset=_set_freq, doc="get/set the frequncy of the Index")
+    freq = property(fget=_get_freq, fset=_set_freq,
+                    doc="get/set the frequncy of the Index")
 
     year = _field_accessor('year', 'Y', "The year of the datetime")
-    month = _field_accessor('month', 'M', "The month as January=1, December=12")
+    month = _field_accessor(
+        'month', 'M', "The month as January=1, December=12")
     day = _field_accessor('day', 'D', "The days of the datetime")
     hour = _field_accessor('hour', 'h', "The hours of the datetime")
     minute = _field_accessor('minute', 'm', "The minutes of the datetime")
@@ -1530,15 +1570,17 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
         """
         Returns numpy array of datetime.time. The time part of the Timestamps.
         """
-        return self._maybe_mask_results(_algos.arrmap_object(self.asobject.values,
-                                                             lambda x: np.nan if x is tslib.NaT else x.time()))
+        return self._maybe_mask_results(_algos.arrmap_object(
+            self.asobject.values,
+            lambda x: np.nan if x is tslib.NaT else x.time()))
 
     @property
     def date(self):
         """
         Returns numpy array of datetime.date. The date part of the Timestamps.
         """
-        return self._maybe_mask_results(_algos.arrmap_object(self.asobject.values, lambda x: x.date()))
+        return self._maybe_mask_results(_algos.arrmap_object(
+            self.asobject.values, lambda x: x.date()))
 
     def normalize(self):
         """
@@ -1573,7 +1615,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
     def dtype(self):
         if self.tz is None:
             return _NS_DTYPE
-        return com.DatetimeTZDtype('ns',self.tz)
+        return com.DatetimeTZDtype('ns', self.tz)
 
     @property
     def is_all_dates(self):
@@ -1631,10 +1673,12 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
         if isinstance(item, (datetime, np.datetime64)):
             self._assert_can_do_op(item)
             if not self._has_same_tz(item):
-                raise ValueError('Passed item and index have different timezone')
+                raise ValueError(
+                    'Passed item and index have different timezone')
             # check freq can be preserved on edge cases
             if self.size and self.freq is not None:
-                if (loc == 0 or loc == -len(self)) and item + self.freq == self[0]:
+                if ((loc == 0 or loc == -len(self)) and
+                        item + self.freq == self[0]):
                     freq = self.freq
                 elif (loc == len(self)) and item - self.freq == self[-1]:
                     freq = self.freq
@@ -1644,14 +1688,16 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
                                         self[loc:].asi8))
             if self.tz is not None:
                 new_dates = tslib.tz_convert(new_dates, 'UTC', self.tz)
-            return DatetimeIndex(new_dates, name=self.name, freq=freq, tz=self.tz)
+            return DatetimeIndex(new_dates, name=self.name, freq=freq,
+                                 tz=self.tz)
 
         except (AttributeError, TypeError):
 
             # fall back to object index
-            if isinstance(item,compat.string_types):
+            if isinstance(item, compat.string_types):
                 return self.asobject.insert(loc, item)
-            raise TypeError("cannot insert DatetimeIndex with incompatible label")
+            raise TypeError(
+                "cannot insert DatetimeIndex with incompatible label")
 
     def delete(self, loc):
         """
@@ -1674,7 +1720,8 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
                 freq = self.freq
         else:
             if com.is_list_like(loc):
-                loc = lib.maybe_indices_to_slice(com._ensure_int64(np.array(loc)), len(self))
+                loc = lib.maybe_indices_to_slice(
+                    com._ensure_int64(np.array(loc)), len(self))
             if isinstance(loc, slice) and loc.step in (1, None):
                 if (loc.start in (0, None) or loc.stop in (len(self), None)):
                     freq = self.freq
@@ -1685,7 +1732,8 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
 
     def tz_convert(self, tz):
         """
-        Convert tz-aware DatetimeIndex from one time zone to another (using pytz/dateutil)
+        Convert tz-aware DatetimeIndex from one time zone to another (using
+        pytz/dateutil)
 
         Parameters
         ----------
@@ -1714,11 +1762,11 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
         return self._shallow_copy(tz=tz)
 
     @deprecate_kwarg(old_arg_name='infer_dst', new_arg_name='ambiguous',
-                 mapping={True: 'infer', False: 'raise'})
+                     mapping={True: 'infer', False: 'raise'})
     def tz_localize(self, tz, ambiguous='raise'):
         """
-        Localize tz-naive DatetimeIndex to given time zone (using pytz/dateutil),
-        or remove timezone from tz-aware DatetimeIndex
+        Localize tz-naive DatetimeIndex to given time zone (using
+        pytz/dateutil), or remove timezone from tz-aware DatetimeIndex
 
         Parameters
         ----------
@@ -1727,11 +1775,14 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
             time zone of the TimeSeries.
             None will remove timezone holding local time.
         ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'
-            - 'infer' will attempt to infer fall dst-transition hours based on order
-            - bool-ndarray where True signifies a DST time, False signifies
-              a non-DST time (note that this flag is only applicable for ambiguous times)
+            - 'infer' will attempt to infer fall dst-transition hours based on
+              order
+            - bool-ndarray where True signifies a DST time, False signifies a
+              non-DST time (note that this flag is only applicable for
+              ambiguous times)
             - 'NaT' will return NaT where there are ambiguous times
-            - 'raise' will raise an AmbiguousTimeError if there are ambiguous times
+            - 'raise' will raise an AmbiguousTimeError if there are ambiguous
+              times
         infer_dst : boolean, default False (DEPRECATED)
             Attempt to infer fall dst-transition hours based on order
 
@@ -1851,18 +1902,18 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin, Int64Index)
         year[testarr] -= 1
         month[testarr] += 12
         return Float64Index(day +
-                            np.fix((153*month - 457)/5) +
-                            365*year +
+                            np.fix((153 * month - 457) / 5) +
+                            365 * year +
                             np.floor(year / 4) -
                             np.floor(year / 100) +
                             np.floor(year / 400) +
                             1721118.5 +
                             (self.hour +
-                             self.minute/60.0 +
-                             self.second/3600.0 +
-                             self.microsecond/3600.0/1e+6 +
-                             self.nanosecond/3600.0/1e+9
-                            )/24.0)
+                             self.minute / 60.0 +
+                             self.second / 3600.0 +
+                             self.microsecond / 3600.0 / 1e+6 +
+                             self.nanosecond / 3600.0 / 1e+9
+                             ) / 24.0)
 
 
 DatetimeIndex._add_numeric_methods_disabled()
@@ -1877,7 +1928,7 @@ def _generate_regular_range(start, end, periods, offset):
             b = Timestamp(start).value
             # cannot just use e = Timestamp(end) + 1 because arange breaks when
             # stride is too large, see GH10887
-            e = b + (Timestamp(end).value - b)//stride * stride + stride//2
+            e = b + (Timestamp(end).value - b) // stride * stride + stride // 2
             # end.tz == start.tz by this point due to _generate implementation
             tz = start.tz
         elif start is not None:
@@ -2038,7 +2089,7 @@ def cdate_range(start=None, end=None, periods=None, freq='C', tz=None,
     rng : DatetimeIndex
     """
 
-    if freq=='C':
+    if freq == 'C':
         holidays = kwargs.pop('holidays', [])
         weekmask = kwargs.pop('weekmask', 'Mon Tue Wed Thu Fri')
         freq = CDay(holidays=holidays, weekmask=weekmask)
@@ -2076,10 +2127,12 @@ def _naive_in_cache_range(start, end):
 def _in_range(start, end, rng_start, rng_end):
     return start > rng_start and end < rng_end
 
+
 def _use_cached_range(offset, _normalized, start, end):
     return (offset._should_cache() and
-                not (offset._normalize_cache and not _normalized) and
-                    _naive_in_cache_range(start, end))
+            not (offset._normalize_cache and not _normalized) and
+            _naive_in_cache_range(start, end))
+
 
 def _time_to_micros(time):
     seconds = time.hour * 60 * 60 + 60 * time.minute + time.second
diff --git a/pandas/tseries/interval.py b/pandas/tseries/interval.py
index bcce64c3a..6698c7e92 100644
--- a/pandas/tseries/interval.py
+++ b/pandas/tseries/interval.py
@@ -14,7 +14,8 @@ class Interval(object):
 
 class PeriodInterval(object):
     """
-    Represents an interval of time defined by two Period objects (time ordinals)
+    Represents an interval of time defined by two Period objects (time
+    ordinals)
     """
 
     def __init__(self, start, end):
@@ -26,6 +27,7 @@ class IntervalIndex(Index):
     """
 
     """
+
     def __new__(self, starts, ends):
         pass
 
diff --git a/pandas/tseries/offsets.py b/pandas/tseries/offsets.py
index 5beb65f0b..50c0a1ab7 100644
--- a/pandas/tseries/offsets.py
+++ b/pandas/tseries/offsets.py
@@ -3,8 +3,7 @@ from pandas.compat import range
 from pandas import compat
 import numpy as np
 
-from pandas.tseries.tools import to_datetime
-from pandas.tseries.timedeltas import to_timedelta
+from pandas.tseries.tools import to_datetime, normalize_date
 from pandas.core.common import ABCSeries, ABCDatetimeIndex
 
 # import after tools, dateutil check
@@ -16,7 +15,7 @@ from pandas.tslib import Timestamp, OutOfBoundsDatetime, Timedelta
 import functools
 
 __all__ = ['Day', 'BusinessDay', 'BDay', 'CustomBusinessDay', 'CDay',
-           'CBMonthEnd','CBMonthBegin',
+           'CBMonthEnd', 'CBMonthBegin',
            'MonthBegin', 'BMonthBegin', 'MonthEnd', 'BMonthEnd',
            'BusinessHour',
            'YearBegin', 'BYearBegin', 'YearEnd', 'BYearEnd',
@@ -26,7 +25,10 @@ __all__ = ['Day', 'BusinessDay', 'BDay', 'CustomBusinessDay', 'CDay',
            'Hour', 'Minute', 'Second', 'Milli', 'Micro', 'Nano',
            'DateOffset']
 
-# convert to/from datetime/timestamp to allow invalid Timestamp ranges to pass thru
+# convert to/from datetime/timestamp to allow invalid Timestamp ranges to
+# pass thru
+
+
 def as_timestamp(obj):
     if isinstance(obj, Timestamp):
         return obj
@@ -36,12 +38,14 @@ def as_timestamp(obj):
         pass
     return obj
 
+
 def as_datetime(obj):
-    f = getattr(obj,'to_pydatetime',None)
+    f = getattr(obj, 'to_pydatetime', None)
     if f is not None:
         obj = f()
     return obj
 
+
 def apply_wraps(func):
     @functools.wraps(func)
     def wrapper(self, other):
@@ -73,7 +77,8 @@ def apply_wraps(func):
                 if not isinstance(self, Nano) and result.nanosecond != nano:
                     if result.tz is not None:
                         # convert to UTC
-                        value = tslib.tz_convert_single(result.value, 'UTC', result.tz)
+                        value = tslib.tz_convert_single(
+                            result.value, 'UTC', result.tz)
                     else:
                         value = result.value
                     result = Timestamp(value + nano)
@@ -100,17 +105,18 @@ def apply_index_wraps(func):
     def wrapper(self, other):
         result = func(self, other)
         if self.normalize:
-            result  = result.to_period('D').to_timestamp()
+            result = result.to_period('D').to_timestamp()
         return result
     return wrapper
 
+
 def _is_normalized(dt):
     if (dt.hour != 0 or dt.minute != 0 or dt.second != 0
-        or dt.microsecond != 0 or getattr(dt, 'nanosecond', 0) != 0):
+            or dt.microsecond != 0 or getattr(dt, 'nanosecond', 0) != 0):
         return False
     return True
 
-#----------------------------------------------------------------------
+# ---------------------------------------------------------------------
 # DateOffset
 
 
@@ -172,7 +178,7 @@ class DateOffset(object):
         'years', 'months', 'weeks', 'days',
         'year', 'month', 'week', 'day', 'weekday',
         'hour', 'minute', 'second', 'microsecond'
-        )
+    )
     _use_relativedelta = False
     _adjust_dst = False
 
@@ -186,13 +192,13 @@ class DateOffset(object):
         self._offset, self._use_relativedelta = self._determine_offset()
 
     def _determine_offset(self):
-        # timedelta is used for sub-daily plural offsets and all singular offsets
-        # relativedelta is used for plural offsets of daily length or more
-        # nanosecond(s) are handled by apply_wraps
+        # timedelta is used for sub-daily plural offsets and all singular
+        # offsets relativedelta is used for plural offsets of daily length or
+        # more nanosecond(s) are handled by apply_wraps
         kwds_no_nanos = dict(
             (k, v) for k, v in self.kwds.items()
             if k not in ('nanosecond', 'nanoseconds')
-            )
+        )
         use_relativedelta = False
 
         if len(kwds_no_nanos) > 0:
@@ -252,29 +258,30 @@ class DateOffset(object):
 
         if not type(self) is DateOffset:
             raise NotImplementedError("DateOffset subclass %s "
-                                     "does not have a vectorized "
-                                     "implementation"
-                                     % (self.__class__.__name__,))
+                                      "does not have a vectorized "
+                                      "implementation"
+                                      % (self.__class__.__name__,))
         relativedelta_fast = set(['years', 'months', 'weeks',
-                                'days', 'hours', 'minutes',
-                                'seconds', 'microseconds'])
+                                  'days', 'hours', 'minutes',
+                                  'seconds', 'microseconds'])
         # relativedelta/_offset path only valid for base DateOffset
         if (self._use_relativedelta and
-            set(self.kwds).issubset(relativedelta_fast)):
+                set(self.kwds).issubset(relativedelta_fast)):
 
             months = ((self.kwds.get('years', 0) * 12
-                        + self.kwds.get('months', 0)) * self.n)
+                       + self.kwds.get('months', 0)) * self.n)
             if months:
                 shifted = tslib.shift_months(i.asi8, months)
                 i = i._shallow_copy(shifted)
 
             weeks = (self.kwds.get('weeks', 0)) * self.n
             if weeks:
-                i = (i.to_period('W') + weeks).to_timestamp() + i.to_perioddelta('W')
+                i = (i.to_period('W') + weeks).to_timestamp() + \
+                    i.to_perioddelta('W')
 
-            timedelta_kwds = dict((k,v) for k,v in self.kwds.items()
-                                    if k in ['days','hours','minutes',
-                                            'seconds','microseconds'])
+            timedelta_kwds = dict((k, v) for k, v in self.kwds.items()
+                                  if k in ['days', 'hours', 'minutes',
+                                           'seconds', 'microseconds'])
             if timedelta_kwds:
                 delta = Timedelta(**timedelta_kwds)
                 i = i + (self.n * delta)
@@ -302,8 +309,9 @@ class DateOffset(object):
         all_paras = dict(list(vars(self).items()) + list(self.kwds.items()))
         if 'holidays' in all_paras and not all_paras['holidays']:
             all_paras.pop('holidays')
-        exclude = ['kwds', 'name','normalize', 'calendar']
-        attrs = [(k, v) for k, v in all_paras.items() if (k not in exclude ) and (k[0] != '_')]
+        exclude = ['kwds', 'name', 'normalize', 'calendar']
+        attrs = [(k, v) for k, v in all_paras.items()
+                 if (k not in exclude) and (k[0] != '_')]
         attrs = sorted(set(attrs))
         params = tuple([str(self.__class__)] + attrs)
         return params
@@ -384,17 +392,20 @@ class DateOffset(object):
         if isinstance(other, datetime):
             raise TypeError('Cannot subtract datetime from offset.')
         elif type(other) == type(self):
-            return self.__class__(self.n - other.n, normalize=self.normalize, **self.kwds)
+            return self.__class__(self.n - other.n, normalize=self.normalize,
+                                  **self.kwds)
         else:  # pragma: no cover
             return NotImplemented
 
     def __rsub__(self, other):
         if isinstance(other, (ABCDatetimeIndex, ABCSeries)):
             return other - self
-        return self.__class__(-self.n, normalize=self.normalize, **self.kwds) + other
+        return self.__class__(-self.n, normalize=self.normalize,
+                              **self.kwds) + other
 
     def __mul__(self, someInt):
-        return self.__class__(n=someInt * self.n, normalize=self.normalize, **self.kwds)
+        return self.__class__(n=someInt * self.n, normalize=self.normalize,
+                              **self.kwds)
 
     def __rmul__(self, someInt):
         return self.__mul__(someInt)
@@ -454,7 +465,6 @@ class DateOffset(object):
 
         off = i.to_perioddelta('D')
 
-        import pandas.tseries.frequencies as frequencies
         from pandas.tseries.frequencies import get_freq_code
         base, mult = get_freq_code(freq)
         base_period = i.to_period(base)
@@ -495,6 +505,7 @@ class DateOffset(object):
     def nanos(self):
         raise ValueError("{0} is a non-fixed frequency".format(self))
 
+
 class SingleConstructorOffset(DateOffset):
 
     @classmethod
@@ -504,6 +515,7 @@ class SingleConstructorOffset(DateOffset):
             raise ValueError("Bad freq suffix %s" % suffix)
         return cls()
 
+
 class BusinessMixin(object):
     """ mixin to business types to provide related functions """
 
@@ -535,6 +547,7 @@ class BusinessMixin(object):
             out += ': ' + ', '.join(attrs)
         return out
 
+
 class BusinessDay(BusinessMixin, SingleConstructorOffset):
     """
     DateOffset subclass representing possibly n business days
@@ -694,7 +707,8 @@ class BusinessHour(BusinessMixin, SingleConstructorOffset):
                 raise ValueError("time data must match '%H:%M' format")
         elif isinstance(t_input, dt_time):
             if t_input.second != 0 or t_input.microsecond != 0:
-                raise ValueError("time data must be specified only with hour and minute")
+                raise ValueError(
+                    "time data must be specified only with hour and minute")
             return t_input
         else:
             raise ValueError("time data must be string or datetime.time")
@@ -768,9 +782,11 @@ class BusinessHour(BusinessMixin, SingleConstructorOffset):
         if not self.onOffset(dt):
             businesshours = self._get_business_hours_by_sec()
             if self.n >= 0:
-                dt = self._prev_opening_time(dt) + timedelta(seconds=businesshours)
+                dt = self._prev_opening_time(
+                    dt) + timedelta(seconds=businesshours)
             else:
-                dt = self._next_opening_time(dt) + timedelta(seconds=businesshours)
+                dt = self._next_opening_time(
+                    dt) + timedelta(seconds=businesshours)
         return dt
 
     @apply_wraps
@@ -801,7 +817,7 @@ class BusinessHour(BusinessMixin, SingleConstructorOffset):
             n = self.n
             if n >= 0:
                 if (other.time() == self.end or
-                    not self._onOffset(other, businesshours)):
+                        not self._onOffset(other, businesshours)):
                     other = self._next_opening_time(other)
             else:
                 if other.time() == self.start:
@@ -828,8 +844,9 @@ class BusinessHour(BusinessMixin, SingleConstructorOffset):
             result = other + timedelta(hours=hours, minutes=minutes)
 
             # because of previous adjustment, time will be larger than start
-            if ((daytime and (result.time() < self.start or self.end < result.time())) or
-                not daytime and (self.end < result.time() < self.start)):
+            if ((daytime and (result.time() < self.start or
+                              self.end < result.time())) or
+                    not daytime and (self.end < result.time() < self.start)):
                 if n >= 0:
                     bday_edge = self._prev_opening_time(other)
                     bday_edge = bday_edge + bhdelta
@@ -849,11 +866,13 @@ class BusinessHour(BusinessMixin, SingleConstructorOffset):
             else:
                 if result.time() == self.start and nanosecond == 0:
                     # adjustment to move to previous business day
-                    result = self._next_opening_time(result- timedelta(seconds=1)) +bhdelta
+                    result = self._next_opening_time(
+                        result - timedelta(seconds=1)) + bhdelta
 
             return result
         else:
-            raise ApplyTypeError('Only know how to combine business hour with ')
+            raise ApplyTypeError(
+                'Only know how to combine business hour with ')
 
     def onOffset(self, dt):
         if self.normalize and not _is_normalized(dt):
@@ -919,8 +938,8 @@ class CustomBusinessDay(BusinessDay):
         self.kwds = kwds
         self.offset = kwds.get('offset', timedelta(0))
         calendar, holidays = self.get_calendar(weekmask=weekmask,
-                                                         holidays=holidays,
-                                                         calendar=calendar)
+                                               holidays=holidays,
+                                               calendar=calendar)
         # CustomBusinessDay instances are identified by the
         # following two attributes. See DateOffset._params()
         # holidays, weekmask
@@ -937,8 +956,8 @@ class CustomBusinessDay(BusinessDay):
             elif not isinstance(holidays, tuple):
                 holidays = tuple(holidays)
             else:
-                 # trust that calendar.holidays and holidays are
-                 # consistent
+                # trust that calendar.holidays and holidays are
+                # consistent
                 pass
             return calendar, holidays
 
@@ -963,9 +982,9 @@ class CustomBusinessDay(BusinessDay):
             from distutils.version import LooseVersion
 
             if LooseVersion(np.__version__) < '1.7.0':
-                raise NotImplementedError("CustomBusinessDay requires numpy >= "
-                                          "1.7.0. Current version: " +
-                                          np.__version__)
+                raise NotImplementedError(
+                    "CustomBusinessDay requires numpy >= "
+                    "1.7.0. Current version: " + np.__version__)
             else:
                 raise
         return busdaycalendar, holidays
@@ -1006,7 +1025,7 @@ class CustomBusinessDay(BusinessDay):
             np_dt = np.datetime64(date_in.date())
 
             np_incr_dt = np.busday_offset(np_dt, self.n, roll=roll,
-                                  busdaycal=self.calendar)
+                                          busdaycal=self.calendar)
 
             dt_date = np_incr_dt.astype(datetime)
             result = datetime.combine(dt_date, date_in.time())
@@ -1043,7 +1062,7 @@ class CustomBusinessDay(BusinessDay):
     def onOffset(self, dt):
         if self.normalize and not _is_normalized(dt):
             return False
-        day64 = self._to_dt64(dt,'datetime64[D]')
+        day64 = self._to_dt64(dt, 'datetime64[D]')
         return np.is_busday(day64, busdaycal=self.calendar)
 
 
@@ -1156,7 +1175,8 @@ class BusinessMonthBegin(MonthOffset):
         other = other + relativedelta(months=n)
         wkday, _ = tslib.monthrange(other.year, other.month)
         first = _get_firstbday(wkday)
-        result = datetime(other.year, other.month, first, other.hour, other.minute,
+        result = datetime(other.year, other.month, first,
+                          other.hour, other.minute,
                           other.second, other.microsecond)
         return result
 
@@ -1199,7 +1219,8 @@ class CustomBusinessMonthEnd(BusinessMixin, MonthOffset):
 
     _cacheable = False
     _prefix = 'CBM'
-    def __init__(self, n=1, normalize=False,  weekmask='Mon Tue Wed Thu Fri',
+
+    def __init__(self, n=1, normalize=False, weekmask='Mon Tue Wed Thu Fri',
                  holidays=None, calendar=None, **kwds):
         self.n = int(n)
         self.normalize = normalize
@@ -1212,7 +1233,7 @@ class CustomBusinessMonthEnd(BusinessMixin, MonthOffset):
         self.kwds['calendar'] = self.cbday.calendar  # cache numpy calendar
 
     @apply_wraps
-    def apply(self,other):
+    def apply(self, other):
         n = self.n
         # First move to month offset
         cur_mend = self.m_offset.rollforward(other)
@@ -1232,6 +1253,7 @@ class CustomBusinessMonthEnd(BusinessMixin, MonthOffset):
         result = self.cbday.rollback(new)
         return result
 
+
 class CustomBusinessMonthBegin(BusinessMixin, MonthOffset):
     """
     **EXPERIMENTAL** DateOffset of one custom business month
@@ -1257,7 +1279,8 @@ class CustomBusinessMonthBegin(BusinessMixin, MonthOffset):
 
     _cacheable = False
     _prefix = 'CBMS'
-    def __init__(self, n=1, normalize=False,  weekmask='Mon Tue Wed Thu Fri',
+
+    def __init__(self, n=1, normalize=False, weekmask='Mon Tue Wed Thu Fri',
                  holidays=None, calendar=None, **kwds):
         self.n = int(n)
         self.normalize = normalize
@@ -1270,7 +1293,7 @@ class CustomBusinessMonthBegin(BusinessMixin, MonthOffset):
         self.kwds['calendar'] = self.cbday.calendar  # cache numpy calendar
 
     @apply_wraps
-    def apply(self,other):
+    def apply(self, other):
         n = self.n
         dt_in = other
         # First move to month offset
@@ -1291,6 +1314,7 @@ class CustomBusinessMonthBegin(BusinessMixin, MonthOffset):
         result = self.cbday.rollforward(new)
         return result
 
+
 class Week(DateOffset):
     """
     Weekly offset
@@ -1301,6 +1325,7 @@ class Week(DateOffset):
         Always generate specific day of week. 0 for Monday
     """
     _adjust_dst = True
+
     def __init__(self, n=1, normalize=False, **kwds):
         self.n = n
         self.normalize = normalize
@@ -1347,7 +1372,8 @@ class Week(DateOffset):
     @apply_index_wraps
     def apply_index(self, i):
         if self.weekday is None:
-            return (i.to_period('W') + self.n).to_timestamp() + i.to_perioddelta('W')
+            return ((i.to_period('W') + self.n).to_timestamp() +
+                    i.to_perioddelta('W'))
         else:
             return self._end_apply_index(i, self.freqstr)
 
@@ -1373,6 +1399,7 @@ class Week(DateOffset):
             weekday = _weekday_to_int[suffix]
         return cls(weekday=weekday)
 
+
 class WeekDay(object):
     MON = 0
     TUE = 1
@@ -1452,7 +1479,8 @@ class WeekOfMonth(DateOffset):
             else:
                 months = self.n + 1
 
-        other = self.getOffsetOfMonth(other + relativedelta(months=months, day=1))
+        other = self.getOffsetOfMonth(
+            other + relativedelta(months=months, day=1))
         other = datetime(other.year, other.month, other.day, base.hour,
                          base.minute, base.second, base.microsecond)
         return other
@@ -1490,9 +1518,11 @@ class WeekOfMonth(DateOffset):
         weekday = _weekday_to_int[suffix[1:]]
         return cls(week=week, weekday=weekday)
 
+
 class LastWeekOfMonth(DateOffset):
     """
-    Describes monthly dates in last week of month like "the last Tuesday of each month"
+    Describes monthly dates in last week of month like "the last Tuesday of
+    each month"
 
     Parameters
     ----------
@@ -1506,6 +1536,7 @@ class LastWeekOfMonth(DateOffset):
         5: Saturdays
         6: Sundays
     """
+
     def __init__(self, n=1, normalize=False, **kwds):
         self.n = n
         self.normalize = normalize
@@ -1516,7 +1547,7 @@ class LastWeekOfMonth(DateOffset):
 
         if self.weekday < 0 or self.weekday > 6:
             raise ValueError('Day must be 0<=day<=6, got %d' %
-                            self.weekday)
+                             self.weekday)
 
         self.kwds = kwds
 
@@ -1537,10 +1568,11 @@ class LastWeekOfMonth(DateOffset):
             else:
                 months = self.n + 1
 
-        return self.getOffsetOfMonth(other + relativedelta(months=months, day=1))
+        return self.getOffsetOfMonth(
+            other + relativedelta(months=months, day=1))
 
     def getOffsetOfMonth(self, dt):
-        m =  MonthEnd()
+        m = MonthEnd()
         d = datetime(dt.year, dt.month, 1, dt.hour, dt.minute,
                      dt.second, dt.microsecond, tzinfo=dt.tzinfo)
         eom = m.rollforward(d)
@@ -1577,6 +1609,7 @@ class QuarterOffset(DateOffset):
     _adjust_dst = True
     # TODO: Consider combining QuarterOffset and YearOffset __init__ at some
     #       point
+
     def __init__(self, n=1, normalize=False, **kwds):
         self.n = n
         self.normalize = normalize
@@ -1769,12 +1802,14 @@ class QuarterBegin(QuarterOffset):
     def apply_index(self, i):
         freq_month = 12 if self.startingMonth == 1 else self.startingMonth - 1
         # freq_month = self.startingMonth
-        freqstr =  'Q-%s' % (_int_to_month[freq_month],)
+        freqstr = 'Q-%s' % (_int_to_month[freq_month],)
         return self._beg_apply_index(i, freqstr)
 
+
 class YearOffset(DateOffset):
     """DateOffset that just needs a month"""
     _adjust_dst = True
+
     def __init__(self, n=1, normalize=False, **kwds):
         self.month = kwds.get('month', self._default_month)
 
@@ -1967,7 +2002,7 @@ class YearBegin(YearOffset):
     @apply_index_wraps
     def apply_index(self, i):
         freq_month = 12 if self.month == 1 else self.month - 1
-        freqstr =  'A-%s' % (_int_to_month[freq_month],)
+        freqstr = 'A-%s' % (_int_to_month[freq_month],)
         return self._beg_apply_index(i, freqstr)
 
     def onOffset(self, dt):
@@ -2044,8 +2079,8 @@ class FY5253(DateOffset):
 
     def isAnchored(self):
         return self.n == 1 \
-                and self.startingMonth is not None \
-                and self.weekday is not None
+            and self.startingMonth is not None \
+            and self.weekday is not None
 
     def onOffset(self, dt):
         if self.normalize and not _is_normalized(dt):
@@ -2064,11 +2099,11 @@ class FY5253(DateOffset):
     def apply(self, other):
         n = self.n
         prev_year = self.get_year_end(
-                        datetime(other.year - 1, self.startingMonth, 1))
+            datetime(other.year - 1, self.startingMonth, 1))
         cur_year = self.get_year_end(
-                        datetime(other.year, self.startingMonth, 1))
+            datetime(other.year, self.startingMonth, 1))
         next_year = self.get_year_end(
-                        datetime(other.year + 1, self.startingMonth, 1))
+            datetime(other.year + 1, self.startingMonth, 1))
         prev_year = tslib._localize_pydatetime(prev_year, other.tzinfo)
         cur_year = tslib._localize_pydatetime(cur_year, other.tzinfo)
         next_year = tslib._localize_pydatetime(next_year, other.tzinfo)
@@ -2092,10 +2127,12 @@ class FY5253(DateOffset):
             else:
                 assert False
 
-            result = self.get_year_end(datetime(year + n, self.startingMonth, 1))
+            result = self.get_year_end(
+                datetime(year + n, self.startingMonth, 1))
 
             result = datetime(result.year, result.month, result.day,
-                              other.hour, other.minute, other.second, other.microsecond)
+                              other.hour, other.minute, other.second,
+                              other.microsecond)
             return result
         else:
             n = -n
@@ -2117,10 +2154,12 @@ class FY5253(DateOffset):
             else:
                 assert False
 
-            result = self.get_year_end(datetime(year - n, self.startingMonth, 1))
+            result = self.get_year_end(
+                datetime(year - n, self.startingMonth, 1))
 
             result = datetime(result.year, result.month, result.day,
-                              other.hour, other.minute, other.second, other.microsecond)
+                              other.hour, other.minute, other.second,
+                              other.microsecond)
             return result
 
     def get_year_end(self, dt):
@@ -2130,7 +2169,8 @@ class FY5253(DateOffset):
             return self._get_year_end_last(dt)
 
     def get_target_month_end(self, dt):
-        target_month = datetime(dt.year, self.startingMonth, 1, tzinfo=dt.tzinfo)
+        target_month = datetime(
+            dt.year, self.startingMonth, 1, tzinfo=dt.tzinfo)
         next_month_first_of = target_month + relativedelta(months=+1)
         return next_month_first_of + relativedelta(days=-1)
 
@@ -2148,7 +2188,8 @@ class FY5253(DateOffset):
                 return backward
 
     def _get_year_end_last(self, dt):
-        current_year = datetime(dt.year, self.startingMonth, 1, tzinfo=dt.tzinfo)
+        current_year = datetime(
+            dt.year, self.startingMonth, 1, tzinfo=dt.tzinfo)
         return current_year + self._offset_lwom
 
     @property
@@ -2166,9 +2207,9 @@ class FY5253(DateOffset):
             return self._suffix_prefix_last
 
     def get_rule_code_suffix(self):
-        return '%s-%s-%s' % (self._get_suffix_prefix(), \
-                           _int_to_month[self.startingMonth], \
-                         _int_to_weekday[self.weekday])
+        return '%s-%s-%s' % (self._get_suffix_prefix(),
+                             _int_to_month[self.startingMonth],
+                             _int_to_weekday[self.weekday])
 
     @classmethod
     def _parse_suffix(cls, varion_code, startingMonth_code, weekday_code):
@@ -2184,10 +2225,10 @@ class FY5253(DateOffset):
         weekday = _weekday_to_int[weekday_code]
 
         return {
-                "weekday": weekday,
-                "startingMonth": startingMonth,
-                "variation": variation,
-                }
+            "weekday": weekday,
+            "startingMonth": startingMonth,
+            "variation": variation,
+        }
 
     @classmethod
     def _from_name(cls, *args):
@@ -2252,10 +2293,10 @@ class FY5253Quarter(DateOffset):
         if self.n == 0:
             raise ValueError('N cannot be 0')
 
-        self._offset = FY5253( \
-                            startingMonth=kwds['startingMonth'], \
-                            weekday=kwds["weekday"],
-                            variation=kwds["variation"])
+        self._offset = FY5253(
+            startingMonth=kwds['startingMonth'],
+            weekday=kwds["weekday"],
+            variation=kwds["variation"])
 
     def isAnchored(self):
         return self.n == 1 and self._offset.isAnchored()
@@ -2351,6 +2392,7 @@ class FY5253Quarter(DateOffset):
         return cls(**dict(FY5253._parse_suffix(*args[:-1]),
                           qtr_with_extra_week=int(args[-1])))
 
+
 class Easter(DateOffset):
     '''
     DateOffset for the Easter holiday using
@@ -2366,10 +2408,12 @@ class Easter(DateOffset):
     @apply_wraps
     def apply(self, other):
         currentEaster = easter(other.year)
-        currentEaster = datetime(currentEaster.year, currentEaster.month, currentEaster.day)
+        currentEaster = datetime(
+            currentEaster.year, currentEaster.month, currentEaster.day)
         currentEaster = tslib._localize_pydatetime(currentEaster, other.tzinfo)
 
-        # NOTE: easter returns a datetime.date so we have to convert to type of other
+        # NOTE: easter returns a datetime.date so we have to convert to type of
+        # other
         if self.n >= 0:
             if other >= currentEaster:
                 new = easter(other.year + self.n)
@@ -2390,7 +2434,7 @@ class Easter(DateOffset):
             return False
         return date(dt.year, dt.month, dt.day) == easter(dt.year)
 
-#----------------------------------------------------------------------
+# ---------------------------------------------------------------------
 # Ticks
 
 import operator
@@ -2472,7 +2516,6 @@ class Tick(SingleConstructorOffset):
 
     _prefix = 'undefined'
 
-
     def isAnchored(self):
         return False
 
@@ -2643,7 +2686,7 @@ prefix_mapping = dict((offset._prefix, offset) for offset in [
     BusinessHour,             # 'BH'
     CustomBusinessDay,        # 'C'
     CustomBusinessMonthEnd,   # 'CBM'
-    CustomBusinessMonthBegin, # 'CBMS'
+    CustomBusinessMonthBegin,  # 'CBMS'
     MonthEnd,                 # 'M'
     MonthBegin,               # 'MS'
     Week,                     # 'W'
diff --git a/pandas/tseries/period.py b/pandas/tseries/period.py
index 534804900..911277429 100644
--- a/pandas/tseries/period.py
+++ b/pandas/tseries/period.py
@@ -19,15 +19,13 @@ from pandas._period import (
 import pandas.core.common as com
 from pandas.core.common import (isnull, _INT64_DTYPE, _maybe_box,
                                 _values_from_object, ABCSeries,
-                                is_integer, is_float, is_object_dtype,
-                                is_float_dtype)
+                                is_integer, is_float, is_object_dtype)
 from pandas import compat
 from pandas.util.decorators import cache_readonly
 
-from pandas.lib import Timestamp, Timedelta
+from pandas.lib import Timedelta
 import pandas.lib as lib
 import pandas.tslib as tslib
-import pandas.algos as _algos
 from pandas.compat import zip, u
 
 
@@ -59,10 +57,12 @@ def dt64arr_to_periodarr(data, freq, tz):
 
 _DIFFERENT_FREQ_INDEX = period._DIFFERENT_FREQ_INDEX
 
+
 def _period_index_cmp(opname, nat_result=False):
     """
     Wrap comparison operations to convert datetime-like to datetime64
     """
+
     def wrapper(self, other):
         if isinstance(other, Period):
             func = getattr(self.values, opname)
@@ -152,9 +152,11 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
     """
     _box_scalars = True
     _typ = 'periodindex'
-    _attributes = ['name','freq']
-    _datetimelike_ops = ['year','month','day','hour','minute','second',
-                         'weekofyear','week','dayofweek','weekday','dayofyear','quarter', 'qyear', 'freq', 'days_in_month', 'daysinmonth']
+    _attributes = ['name', 'freq']
+    _datetimelike_ops = ['year', 'month', 'day', 'hour', 'minute', 'second',
+                         'weekofyear', 'week', 'dayofweek', 'weekday',
+                         'dayofyear', 'quarter', 'qyear', 'freq',
+                         'days_in_month', 'daysinmonth']
     _is_numeric_dtype = False
     _infer_as_myclass = True
 
@@ -207,8 +209,8 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
 
     @classmethod
     def _from_arraylike(cls, data, freq, tz):
-
-        if not isinstance(data, (np.ndarray, PeriodIndex, DatetimeIndex, Int64Index)):
+        if not isinstance(data, (np.ndarray, PeriodIndex,
+                                 DatetimeIndex, Int64Index)):
             if np.isscalar(data) or isinstance(data, Period):
                 raise ValueError('PeriodIndex() must be called with a '
                                  'collection of some kind, %s was passed'
@@ -267,8 +269,8 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
 
     @classmethod
     def _simple_new(cls, values, name=None, freq=None, **kwargs):
-        if not getattr(values,'dtype',None):
-            values = np.array(values,copy=False)
+        if not getattr(values, 'dtype', None):
+            values = np.array(values, copy=False)
         if is_object_dtype(values):
             return PeriodIndex(values, name=name, freq=freq, **kwargs)
 
@@ -344,12 +346,10 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
     def _box_func(self):
         return lambda x: Period._from_ordinal(ordinal=x, freq=self.freq)
 
-    def _convert_for_op(self):
-        """ Convert value to be insertable to ndarray """
-        return self._box_func(value)
-
     def _to_embed(self, keep_tz=False):
-        """ return an array repr of this object, potentially casting to object """
+        """
+        return an array repr of this object, potentially casting to object
+        """
         return self.asobject.values
 
     @property
@@ -487,17 +487,21 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
     second = _field_accessor('second', 7, "The second of the period")
     weekofyear = _field_accessor('week', 8, "The week ordinal of the year")
     week = weekofyear
-    dayofweek = _field_accessor('dayofweek', 10, "The day of the week with Monday=0, Sunday=6")
+    dayofweek = _field_accessor(
+        'dayofweek', 10, "The day of the week with Monday=0, Sunday=6")
     weekday = dayofweek
-    dayofyear = day_of_year = _field_accessor('dayofyear', 9, "The ordinal day of the year")
+    dayofyear = day_of_year = _field_accessor(
+        'dayofyear', 9, "The ordinal day of the year")
     quarter = _field_accessor('quarter', 2, "The quarter of the date")
     qyear = _field_accessor('qyear', 1)
-    days_in_month = _field_accessor('days_in_month', 11, "The number of days in the month")
+    days_in_month = _field_accessor(
+        'days_in_month', 11, "The number of days in the month")
     daysinmonth = days_in_month
 
     def _get_object_array(self):
         freq = self.freq
-        return np.array([ Period._from_ordinal(ordinal=x, freq=freq) for x in self.values], copy=False)
+        return np.array([Period._from_ordinal(ordinal=x, freq=freq)
+                         for x in self.values], copy=False)
 
     def _mpl_repr(self):
         # how to represent ourselves to matplotlib
@@ -547,7 +551,8 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
         return DatetimeIndex(new_data, freq='infer', name=self.name)
 
     def _maybe_convert_timedelta(self, other):
-        if isinstance(other, (timedelta, np.timedelta64, offsets.Tick, Timedelta)):
+        if isinstance(other, (timedelta, np.timedelta64,
+                              offsets.Tick, Timedelta)):
             offset = frequencies.to_offset(self.freq.rule_code)
             if isinstance(offset, offsets.Tick):
                 nanos = tslib._delta_to_nanoseconds(other)
@@ -612,7 +617,8 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
         """
         s = _values_from_object(series)
         try:
-            return _maybe_box(self, super(PeriodIndex, self).get_value(s, key), series, key)
+            return _maybe_box(self, super(PeriodIndex, self).get_value(s, key),
+                              series, key)
         except (KeyError, IndexError):
             try:
                 asdt, parsed, reso = parse_time_string(key, self.freq)
@@ -635,14 +641,16 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
                     return series[key]
                 elif grp == freqn:
                     key = Period(asdt, freq=self.freq).ordinal
-                    return _maybe_box(self, self._engine.get_value(s, key), series, key)
+                    return _maybe_box(self, self._engine.get_value(s, key),
+                                      series, key)
                 else:
                     raise KeyError(key)
             except TypeError:
                 pass
 
             key = Period(key, self.freq).ordinal
-            return _maybe_box(self, self._engine.get_value(s, key), series, key)
+            return _maybe_box(self, self._engine.get_value(s, key),
+                              series, key)
 
     def get_indexer(self, target, method=None, limit=None, tolerance=None):
         if hasattr(target, 'freq') and target.freq != self.freq:
@@ -678,8 +686,8 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
 
     def _maybe_cast_slice_bound(self, label, side, kind):
         """
-        If label is a string or a datetime, cast it to Period.ordinal according to
-        resolution.
+        If label is a string or a datetime, cast it to Period.ordinal according
+        to resolution.
 
         Parameters
         ----------
@@ -706,7 +714,7 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
             except Exception:
                 raise KeyError(label)
         elif is_integer(label) or is_float(label):
-            self._invalid_indexer('slice',label)
+            self._invalid_indexer('slice', label)
 
         return label
 
@@ -729,10 +737,10 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
                         hour=parsed.hour, minute=parsed.minute, freq='T')
         elif reso == 'second':
             t1 = Period(year=parsed.year, month=parsed.month, day=parsed.day,
-                        hour=parsed.hour, minute=parsed.minute, second=parsed.second,
-                        freq='S')
+                        hour=parsed.hour, minute=parsed.minute,
+                        second=parsed.second, freq='S')
         else:
-            raise KeyError(key)
+            raise KeyError(reso)
         return (t1.asfreq(self.freq, how='start'),
                 t1.asfreq(self.freq, how='end'))
 
@@ -809,7 +817,8 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
 
             return PeriodIndex(result, name=self.name, freq=self.freq)
 
-    def _format_native_types(self, na_rep=u('NaT'), date_format=None, **kwargs):
+    def _format_native_types(self, na_rep=u('NaT'), date_format=None,
+                             **kwargs):
 
         values = np.array(list(self), dtype=object)
         mask = isnull(self.values)
@@ -911,7 +920,8 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
 
     def tz_convert(self, tz):
         """
-        Convert tz-aware DatetimeIndex from one time zone to another (using pytz/dateutil)
+        Convert tz-aware DatetimeIndex from one time zone to another (using
+        pytz/dateutil)
 
         Parameters
         ----------
@@ -932,8 +942,8 @@ class PeriodIndex(DatelikeOps, DatetimeIndexOpsMixin, Int64Index):
 
     def tz_localize(self, tz, infer_dst=False):
         """
-        Localize tz-naive DatetimeIndex to given time zone (using pytz/dateutil),
-        or remove timezone from tz-aware DatetimeIndex
+        Localize tz-naive DatetimeIndex to given time zone (using
+        pytz/dateutil), or remove timezone from tz-aware DatetimeIndex
 
         Parameters
         ----------
@@ -978,7 +988,7 @@ def _get_ordinal_range(start, end, periods, freq, mult=1):
     if is_start_per and is_end_per and start.freq != end.freq:
         raise ValueError('Start and end must have same freq')
     if ((is_start_per and start.ordinal == tslib.iNaT) or
-        (is_end_per and end.ordinal == tslib.iNaT)):
+            (is_end_per and end.ordinal == tslib.iNaT)):
         raise ValueError('Start and end must not be NaT')
 
     if freq is None:
@@ -1035,7 +1045,8 @@ def _range_from_fields(year=None, month=None, quarter=None, day=None,
         base, mult = _gfc(freq)
         arrays = _make_field_arrays(year, month, day, hour, minute, second)
         for y, mth, d, h, mn, s in zip(*arrays):
-            ordinals.append(period.period_ordinal(y, mth, d, h, mn, s, 0, 0, base))
+            ordinals.append(period.period_ordinal(
+                y, mth, d, h, mn, s, 0, 0, base))
 
     return np.array(ordinals, dtype=np.int64), freq
 
diff --git a/pandas/tseries/plotting.py b/pandas/tseries/plotting.py
index ad27b412c..729e85b0a 100644
--- a/pandas/tseries/plotting.py
+++ b/pandas/tseries/plotting.py
@@ -3,7 +3,7 @@ Period formatters and locators adapted from scikits.timeseries by
 Pierre GF Gerard-Marchant & Matt Knox
 """
 
-#!!! TODO: Use the fact that axis can have units to simplify the process
+# TODO: Use the fact that axis can have units to simplify the process
 
 import numpy as np
 
@@ -18,7 +18,7 @@ import pandas.compat as compat
 from pandas.tseries.converter import (TimeSeries_DateLocator,
                                       TimeSeries_DateFormatter)
 
-#----------------------------------------------------------------------
+# ---------------------------------------------------------------------
 # Plotting functions and monkey patches
 
 
@@ -139,7 +139,8 @@ def _replot_ax(ax, freq, kwargs):
                 from pandas.tools.plotting import _plot_klass
                 plotf = _plot_klass[plotf]._plot
 
-            lines.append(plotf(ax, series.index._mpl_repr(), series.values, **kwds)[0])
+            lines.append(plotf(ax, series.index._mpl_repr(),
+                               series.values, **kwds)[0])
             labels.append(com.pprint_thing(series.name))
 
     return lines, labels
@@ -287,7 +288,7 @@ def format_dateaxis(subplot, freq):
     subplot.xaxis.set_minor_formatter(minformatter)
 
     # x and y coord info
-    subplot.format_coord = lambda t, y: ("t = {0}  "
-        "y = {1:8f}".format(Period(ordinal=int(t), freq=freq), y))
+    subplot.format_coord = lambda t, y: (
+        "t = {0}  y = {1:8f}".format(Period(ordinal=int(t), freq=freq), y))
 
     pylab.draw_if_interactive()
diff --git a/pandas/tseries/tdi.py b/pandas/tseries/tdi.py
index ea61e4f24..fafe13e1f 100644
--- a/pandas/tseries/tdi.py
+++ b/pandas/tseries/tdi.py
@@ -3,18 +3,17 @@
 from datetime import timedelta
 import numpy as np
 from pandas.core.common import (ABCSeries, _TD_DTYPE, _INT64_DTYPE,
-                                is_timedelta64_dtype, _maybe_box,
-                                _values_from_object, isnull, is_integer, is_float)
+                                _maybe_box,
+                                _values_from_object, isnull,
+                                is_integer, is_float)
 from pandas.core.index import Index, Int64Index
 import pandas.compat as compat
 from pandas.compat import u
-from pandas.util.decorators import cache_readonly
 from pandas.tseries.frequencies import to_offset
 import pandas.core.common as com
-from pandas.tseries import timedeltas
 from pandas.tseries.base import TimelikeOps, DatetimeIndexOpsMixin
-from pandas.tseries.timedeltas import to_timedelta, _coerce_scalar_to_timedelta_type
-import pandas.tseries.offsets as offsets
+from pandas.tseries.timedeltas import (to_timedelta,
+                                       _coerce_scalar_to_timedelta_type)
 from pandas.tseries.offsets import Tick, DateOffset
 
 import pandas.lib as lib
@@ -24,10 +23,12 @@ import pandas.index as _index
 
 Timedelta = tslib.Timedelta
 
+
 def _td_index_cmp(opname, nat_result=False):
     """
     Wrap comparison operations to convert timedelta-like to timedelta64
     """
+
     def wrapper(self, other):
         func = getattr(super(TimedeltaIndex, self), opname)
         if _is_convertible_to_td(other):
@@ -37,7 +38,8 @@ def _td_index_cmp(opname, nat_result=False):
                 result.fill(nat_result)
         else:
             if not com.is_list_like(other):
-                raise TypeError("cannot compare a TimedeltaIndex with type {0}".format(type(other)))
+                raise TypeError("cannot compare a TimedeltaIndex with type "
+                                "{0}".format(type(other)))
 
             other = TimedeltaIndex(other).values
             result = func(other)
@@ -94,8 +96,10 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
 
     _typ = 'timedeltaindex'
     _join_precedence = 10
+
     def _join_i8_wrapper(joinf, **kwargs):
-        return DatetimeIndexOpsMixin._join_i8_wrapper(joinf, dtype='m8[ns]', **kwargs)
+        return DatetimeIndexOpsMixin._join_i8_wrapper(
+            joinf, dtype='m8[ns]', **kwargs)
 
     _inner_indexer = _join_i8_wrapper(_algos.inner_join_indexer_int64)
     _outer_indexer = _join_i8_wrapper(_algos.outer_join_indexer_int64)
@@ -103,8 +107,8 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
     _left_indexer_unique = _join_i8_wrapper(
         _algos.left_join_indexer_unique_int64, with_indexers=False)
     _arrmap = None
-    _datetimelike_ops = ['days','seconds','microseconds','nanoseconds',
-                         'freq','components']
+    _datetimelike_ops = ['days', 'seconds', 'microseconds', 'nanoseconds',
+                         'freq', 'components']
 
     __eq__ = _td_index_cmp('__eq__')
     __ne__ = _td_index_cmp('__ne__', nat_result=True)
@@ -167,10 +171,10 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
                                  % repr(data))
 
         # convert if not already
-        if getattr(data,'dtype',None) != _TD_DTYPE:
-            data = to_timedelta(data,unit=unit,box=False)
+        if getattr(data, 'dtype', None) != _TD_DTYPE:
+            data = to_timedelta(data, unit=unit, box=False)
         elif copy:
-            data = np.array(data,copy=True)
+            data = np.array(data, copy=True)
 
         # check that we are matching freqs
         if verify_integrity and len(data) > 0:
@@ -178,10 +182,13 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
                 index = cls._simple_new(data, name=name)
                 inferred = index.inferred_freq
                 if inferred != freq.freqstr:
-                    on_freq = cls._generate(index[0], None, len(index), name, freq)
+                    on_freq = cls._generate(
+                        index[0], None, len(index), name, freq)
                     if not np.array_equal(index.asi8, on_freq.asi8):
-                        raise ValueError('Inferred frequency {0} from passed timedeltas does not '
-                                         'conform to passed frequency {1}'.format(inferred, freq.freqstr))
+                        raise ValueError('Inferred frequency {0} from passed '
+                                         'timedeltas does not conform to '
+                                         'passed frequency {1}'
+                                         .format(inferred, freq.freqstr))
                 index.freq = freq
                 return index
 
@@ -239,8 +246,8 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
 
     @classmethod
     def _simple_new(cls, values, name=None, freq=None, **kwargs):
-        if not getattr(values,'dtype',None):
-            values = np.array(values,copy=False)
+        if not getattr(values, 'dtype', None):
+            values = np.array(values, copy=False)
         if values.dtype == np.object_:
             values = tslib.array_to_timedelta64(values)
         if values.dtype != _TD_DTYPE:
@@ -286,7 +293,8 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
             # update name when delta is index
             name = com._maybe_match_name(self, delta)
         else:
-            raise ValueError("cannot add the type {0} to a TimedeltaIndex".format(type(delta)))
+            raise ValueError("cannot add the type {0} to a TimedeltaIndex"
+                             .format(type(delta)))
 
         result = TimedeltaIndex(new_values, freq='infer', name=name)
         return result
@@ -294,16 +302,17 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
     def _evaluate_with_timedelta_like(self, other, op, opstr):
 
         # allow division by a timedelta
-        if opstr in ['__div__','__truediv__']:
+        if opstr in ['__div__', '__truediv__']:
             if _is_convertible_to_td(other):
                 other = Timedelta(other)
                 if isnull(other):
-                    raise NotImplementedError("division by pd.NaT not implemented")
+                    raise NotImplementedError(
+                        "division by pd.NaT not implemented")
 
                 i8 = self.asi8
-                result = i8/float(other.value)
-                result = self._maybe_mask_results(result,convert='float64')
-                return Index(result,name=self.name,copy=False)
+                result = i8 / float(other.value)
+                result = self._maybe_mask_results(result, convert='float64')
+                return Index(result, name=self.name, copy=False)
 
         return NotImplemented
 
@@ -314,8 +323,8 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
         other = Timestamp(other)
         i8 = self.asi8
         result = i8 + other.value
-        result = self._maybe_mask_results(result,fill_value=tslib.iNaT)
-        return DatetimeIndex(result,name=self.name,copy=False)
+        result = self._maybe_mask_results(result, fill_value=tslib.iNaT)
+        return DatetimeIndex(result, name=self.name, copy=False)
 
     def _sub_datelike(self, other):
         raise TypeError("cannot subtract a datelike from a TimedeltaIndex")
@@ -335,10 +344,12 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
             result = np.empty(len(self), dtype='float64')
             mask = self._isnan
             imask = ~mask
-            result.flat[imask] = np.array([ getattr(Timedelta(val),m) for val in values[imask] ])
+            result.flat[imask] = np.array(
+                [getattr(Timedelta(val), m) for val in values[imask]])
             result[mask] = np.nan
         else:
-            result = np.array([ getattr(Timedelta(val),m) for val in values ],dtype='int64')
+            result = np.array([getattr(Timedelta(val), m)
+                               for val in values], dtype='int64')
         return result
 
     @property
@@ -353,12 +364,17 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
 
     @property
     def microseconds(self):
-        """ Number of microseconds (>= 0 and less than 1 second) for each element. """
+        """
+        Number of microseconds (>= 0 and less than 1 second) for each
+        element. """
         return self._get_field('microseconds')
 
     @property
     def nanoseconds(self):
-        """ Number of nanoseconds (>= 0 and less than 1 microsecond) for each element. """
+        """
+        Number of nanoseconds (>= 0 and less than 1 microsecond) for each
+        element.
+        """
         return self._get_field('nanoseconds')
 
     @property
@@ -373,18 +389,19 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
         """
         from pandas import DataFrame
 
-        columns = ['days','hours','minutes','seconds','milliseconds','microseconds','nanoseconds']
+        columns = ['days', 'hours', 'minutes', 'seconds',
+                   'milliseconds', 'microseconds', 'nanoseconds']
         hasnans = self.hasnans
         if hasnans:
             def f(x):
                 if isnull(x):
-                    return [np.nan]*len(columns)
+                    return [np.nan] * len(columns)
                 return x.components
         else:
             def f(x):
                 return x.components
 
-        result = DataFrame([ f(x) for x in self ])
+        result = DataFrame([f(x) for x in self])
         result.columns = columns
         if not hasnans:
             result = result.astype('int64')
@@ -396,7 +413,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
 
         .. versionadded:: 0.17.0
         """
-        return self._maybe_mask_results(1e-9*self.asi8)
+        return self._maybe_mask_results(1e-9 * self.asi8)
 
     def to_pytimedelta(self):
         """
@@ -422,9 +439,11 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
             # return an index (essentially this is division)
             result = self.values.astype(dtype)
             if self.hasnans:
-                return Index(self._maybe_mask_results(result,convert='float64'),name=self.name)
+                return Index(self._maybe_mask_results(result,
+                                                      convert='float64'),
+                             name=self.name)
 
-            return Index(result.astype('i8'),name=self.name)
+            return Index(result.astype('i8'), name=self.name)
 
         else:  # pragma: no cover
             raise ValueError('Cannot cast TimedeltaIndex to dtype %s' % dtype)
@@ -503,8 +522,8 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
 
     def _wrap_joined_index(self, joined, other):
         name = self.name if self.name == other.name else None
-        if (isinstance(other, TimedeltaIndex) and  self.freq == other.freq
-            and self._can_fast_union(other)):
+        if (isinstance(other, TimedeltaIndex) and self.freq == other.freq
+                and self._can_fast_union(other)):
             joined = self._shallow_copy(joined, name=name)
             return joined
         else:
@@ -550,7 +569,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
         else:
             left, right = other, self
 
-        left_start, left_end = left[0], left[-1]
+        left_end = left[-1]
         right_end = right[-1]
 
         # concatenate
@@ -624,7 +643,8 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
             return self.get_value_maybe_box(series, key)
 
         try:
-            return _maybe_box(self, Index.get_value(self, series, key), series, key)
+            return _maybe_box(self, Index.get_value(self, series, key),
+                              series, key)
         except KeyError:
             try:
                 loc = self._get_string_slice(key)
@@ -699,7 +719,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
                 return (lbound + to_offset(parsed.resolution) -
                         Timedelta(1, 'ns'))
         elif is_integer(label) or is_float(label):
-            self._invalid_indexer('slice',label)
+            self._invalid_indexer('slice', label)
 
         return label
 
@@ -707,7 +727,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
         freq = getattr(self, 'freqstr',
                        getattr(self, 'inferred_freq', None))
         if is_integer(key) or is_float(key):
-            self._invalid_indexer('slice',key)
+            self._invalid_indexer('slice', key)
         loc = self._partial_td_slice(key, freq, use_lhs=use_lhs,
                                      use_rhs=use_rhs)
         return loc
@@ -718,36 +738,44 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
         if not isinstance(key, compat.string_types):
             return key
 
-        parsed = _coerce_scalar_to_timedelta_type(key, box=True)
+        raise NotImplementedError
 
-        is_monotonic = self.is_monotonic
+        # TODO(wesm): dead code
+        # parsed = _coerce_scalar_to_timedelta_type(key, box=True)
 
-        # figure out the resolution of the passed td
-        # and round to it
-        t1 = parsed.round(reso)
-        t2 = t1 + to_offset(parsed.resolution) - Timedelta(1,'ns')
+        # is_monotonic = self.is_monotonic
 
-        stamps = self.asi8
+        # # figure out the resolution of the passed td
+        # # and round to it
 
-        if is_monotonic:
+        # # t1 = parsed.round(reso)
 
-            # we are out of range
-            if len(stamps) and (
-                (use_lhs and t1.value < stamps[0] and t2.value < stamps[0]) or (
-                (use_rhs and t1.value > stamps[-1] and t2.value > stamps[-1]))):
-                raise KeyError
+        # t2 = t1 + to_offset(parsed.resolution) - Timedelta(1, 'ns')
 
-            # a monotonic (sorted) series can be sliced
-            left = stamps.searchsorted(t1.value, side='left') if use_lhs else None
-            right = stamps.searchsorted(t2.value, side='right') if use_rhs else None
+        # stamps = self.asi8
 
-            return slice(left, right)
+        # if is_monotonic:
 
-        lhs_mask = (stamps >= t1.value) if use_lhs else True
-        rhs_mask = (stamps <= t2.value) if use_rhs else True
+        #     # we are out of range
+        #     if (len(stamps) and ((use_lhs and t1.value < stamps[0] and
+        #                           t2.value < stamps[0]) or
+        #                          ((use_rhs and t1.value > stamps[-1] and
+        #                            t2.value > stamps[-1])))):
+        #         raise KeyError
 
-        # try to find a the dates
-        return (lhs_mask & rhs_mask).nonzero()[0]
+        #     # a monotonic (sorted) series can be sliced
+        #     left = (stamps.searchsorted(t1.value, side='left')
+        #             if use_lhs else None)
+        #     right = (stamps.searchsorted(t2.value, side='right')
+        #              if use_rhs else None)
+
+        #     return slice(left, right)
+
+        # lhs_mask = (stamps >= t1.value) if use_lhs else True
+        # rhs_mask = (stamps <= t2.value) if use_rhs else True
+
+        # # try to find a the dates
+        # return (lhs_mask & rhs_mask).nonzero()[0]
 
     def searchsorted(self, key, side='left'):
         if isinstance(key, (np.ndarray, Index)):
@@ -816,7 +844,8 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
 
             # check freq can be preserved on edge cases
             if self.freq is not None:
-                if (loc == 0 or loc == -len(self)) and item + self.freq == self[0]:
+                if ((loc == 0 or loc == -len(self)) and
+                        item + self.freq == self[0]):
                     freq = self.freq
                 elif (loc == len(self)) and item - self.freq == self[-1]:
                     freq = self.freq
@@ -824,15 +853,16 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
 
         try:
             new_tds = np.concatenate((self[:loc].asi8, [item.view(np.int64)],
-                                        self[loc:].asi8))
+                                      self[loc:].asi8))
             return TimedeltaIndex(new_tds, name=self.name, freq=freq)
 
         except (AttributeError, TypeError):
 
             # fall back to object index
-            if isinstance(item,compat.string_types):
+            if isinstance(item, compat.string_types):
                 return self.asobject.insert(loc, item)
-            raise TypeError("cannot insert TimedeltaIndex with incompatible label")
+            raise TypeError(
+                "cannot insert TimedeltaIndex with incompatible label")
 
     def delete(self, loc):
         """
@@ -855,7 +885,8 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
                 freq = self.freq
         else:
             if com.is_list_like(loc):
-                loc = lib.maybe_indices_to_slice(com._ensure_int64(np.array(loc)), len(self))
+                loc = lib.maybe_indices_to_slice(
+                    com._ensure_int64(np.array(loc)), len(self))
             if isinstance(loc, slice) and loc.step in (1, None):
                 if (loc.start in (0, None) or loc.stop in (len(self), None)):
                     freq = self.freq
@@ -869,18 +900,22 @@ TimedeltaIndex._add_datetimelike_methods()
 
 
 def _is_convertible_to_index(other):
-    """ return a boolean whether I can attempt conversion to a TimedeltaIndex """
+    """
+    return a boolean whether I can attempt conversion to a TimedeltaIndex
+    """
     if isinstance(other, TimedeltaIndex):
         return True
     elif (len(other) > 0 and
-          other.inferred_type not in ('floating', 'mixed-integer','integer',
+          other.inferred_type not in ('floating', 'mixed-integer', 'integer',
                                       'mixed-integer-float', 'mixed')):
         return True
     return False
 
 
 def _is_convertible_to_td(key):
-    return isinstance(key, (DateOffset, timedelta, Timedelta, np.timedelta64, compat.string_types))
+    return isinstance(key, (DateOffset, timedelta, Timedelta,
+                            np.timedelta64, compat.string_types))
+
 
 def _to_m8(key):
     '''
@@ -893,6 +928,7 @@ def _to_m8(key):
     # return an type that can be compared
     return np.int64(key.value).view(_TD_DTYPE)
 
+
 def _generate_regular_range(start, end, periods, offset):
     stride = offset.nanos
     if periods is None:
diff --git a/pandas/tseries/tests/test_base.py b/pandas/tseries/tests/test_base.py
index 2a1e59154..2f28c55ae 100644
--- a/pandas/tseries/tests/test_base.py
+++ b/pandas/tseries/tests/test_base.py
@@ -1,80 +1,93 @@
 from __future__ import print_function
-import re
 from datetime import datetime, timedelta
 import numpy as np
 import pandas as pd
-from pandas.tseries.base import DatetimeIndexOpsMixin
-from pandas.util.testing import assertRaisesRegexp, assertIsInstance
-from pandas.tseries.common import is_datetimelike
-from pandas import (Series, Index, Int64Index, Timestamp, DatetimeIndex, PeriodIndex,
-                    TimedeltaIndex, Timedelta, timedelta_range, date_range, Float64Index)
-import pandas.tseries.offsets as offsets
+from pandas import (Series, Index, Int64Index, Timestamp, DatetimeIndex,
+                    PeriodIndex, TimedeltaIndex, Timedelta, timedelta_range,
+                    date_range, Float64Index)
 import pandas.tslib as tslib
-import nose
 
 import pandas.util.testing as tm
 
 from pandas.tests.test_base import Ops
 
+
 class TestDatetimeIndexOps(Ops):
-    tz = [None, 'UTC', 'Asia/Tokyo', 'US/Eastern',
-          'dateutil/Asia/Singapore', 'dateutil/US/Pacific']
+    tz = [None, 'UTC', 'Asia/Tokyo', 'US/Eastern', 'dateutil/Asia/Singapore',
+          'dateutil/US/Pacific']
 
     def setUp(self):
         super(TestDatetimeIndexOps, self).setUp()
-        mask = lambda x: isinstance(x, DatetimeIndex) or isinstance(x, PeriodIndex)
-        self.is_valid_objs  = [ o for o in self.objs if mask(o) ]
-        self.not_valid_objs = [ o for o in self.objs if not mask(o) ]
+        mask = lambda x: (isinstance(x, DatetimeIndex) or
+                          isinstance(x, PeriodIndex))
+        self.is_valid_objs = [o for o in self.objs if mask(o)]
+        self.not_valid_objs = [o for o in self.objs if not mask(o)]
 
     def test_ops_properties(self):
-        self.check_ops_properties(['year','month','day','hour','minute','second','weekofyear','week','dayofweek','dayofyear','quarter'])
-        self.check_ops_properties(['date','time','microsecond','nanosecond', 'is_month_start', 'is_month_end', 'is_quarter_start',
-                                   'is_quarter_end', 'is_year_start', 'is_year_end'], lambda x: isinstance(x,DatetimeIndex))
+        self.check_ops_properties(
+            ['year', 'month', 'day', 'hour', 'minute', 'second', 'weekofyear',
+             'week', 'dayofweek', 'dayofyear', 'quarter'])
+        self.check_ops_properties(['date', 'time', 'microsecond', 'nanosecond',
+                                   'is_month_start', 'is_month_end',
+                                   'is_quarter_start',
+                                   'is_quarter_end', 'is_year_start',
+                                   'is_year_end'],
+                                  lambda x: isinstance(x, DatetimeIndex))
 
     def test_ops_properties_basic(self):
 
         # sanity check that the behavior didn't change
         # GH7206
-        for op in ['year','day','second','weekday']:
-            self.assertRaises(TypeError, lambda x: getattr(self.dt_series,op))
+        for op in ['year', 'day', 'second', 'weekday']:
+            self.assertRaises(TypeError, lambda x: getattr(self.dt_series, op))
 
         # attribute access should still work!
-        s = Series(dict(year=2000,month=1,day=10))
-        self.assertEqual(s.year,2000)
-        self.assertEqual(s.month,1)
-        self.assertEqual(s.day,10)
-        self.assertRaises(AttributeError, lambda : s.weekday)
+        s = Series(dict(year=2000, month=1, day=10))
+        self.assertEqual(s.year, 2000)
+        self.assertEqual(s.month, 1)
+        self.assertEqual(s.day, 10)
+        self.assertRaises(AttributeError, lambda: s.weekday)
 
     def test_astype_str(self):
         # test astype string - #10442
-        result = date_range('2012-01-01', periods=4, name='test_name').astype(str)
-        expected = Index(['2012-01-01', '2012-01-02', '2012-01-03','2012-01-04'],
-                            name='test_name', dtype=object)
+        result = date_range('2012-01-01', periods=4,
+                            name='test_name').astype(str)
+        expected = Index(['2012-01-01', '2012-01-02', '2012-01-03',
+                          '2012-01-04'], name='test_name', dtype=object)
         tm.assert_index_equal(result, expected)
 
         # test astype string with tz and name
-        result = date_range('2012-01-01', periods=3, name='test_name', tz='US/Eastern').astype(str)
-        expected = Index(['2012-01-01 00:00:00-05:00', '2012-01-02 00:00:00-05:00',
-                          '2012-01-03 00:00:00-05:00'], name='test_name', dtype=object)
+        result = date_range('2012-01-01', periods=3, name='test_name',
+                            tz='US/Eastern').astype(str)
+        expected = Index(['2012-01-01 00:00:00-05:00',
+                          '2012-01-02 00:00:00-05:00',
+                          '2012-01-03 00:00:00-05:00'],
+                         name='test_name', dtype=object)
         tm.assert_index_equal(result, expected)
 
         # test astype string with freqH and name
-        result = date_range('1/1/2011', periods=3, freq='H', name='test_name').astype(str)
-        expected = Index(['2011-01-01 00:00:00', '2011-01-01 01:00:00', '2011-01-01 02:00:00'],
+        result = date_range('1/1/2011', periods=3, freq='H',
+                            name='test_name').astype(str)
+        expected = Index(['2011-01-01 00:00:00', '2011-01-01 01:00:00',
+                          '2011-01-01 02:00:00'],
                          name='test_name', dtype=object)
         tm.assert_index_equal(result, expected)
 
         # test astype string with freqH and timezone
         result = date_range('3/6/2012 00:00', periods=2, freq='H',
                             tz='Europe/London', name='test_name').astype(str)
-        expected = Index(['2012-03-06 00:00:00+00:00', '2012-03-06 01:00:00+00:00'],
+        expected = Index(['2012-03-06 00:00:00+00:00',
+                          '2012-03-06 01:00:00+00:00'],
                          dtype=object, name='test_name')
         tm.assert_index_equal(result, expected)
 
     def test_asobject_tolist(self):
-        idx = pd.date_range(start='2013-01-01', periods=4, freq='M', name='idx')
-        expected_list = [pd.Timestamp('2013-01-31'), pd.Timestamp('2013-02-28'),
-                         pd.Timestamp('2013-03-31'), pd.Timestamp('2013-04-30')]
+        idx = pd.date_range(start='2013-01-01', periods=4, freq='M',
+                            name='idx')
+        expected_list = [pd.Timestamp('2013-01-31'),
+                         pd.Timestamp('2013-02-28'),
+                         pd.Timestamp('2013-03-31'),
+                         pd.Timestamp('2013-04-30')]
         expected = pd.Index(expected_list, dtype=object, name='idx')
         result = idx.asobject
         self.assertTrue(isinstance(result, Index))
@@ -84,7 +97,8 @@ class TestDatetimeIndexOps(Ops):
         self.assertEqual(result.name, expected.name)
         self.assertEqual(idx.tolist(), expected_list)
 
-        idx = pd.date_range(start='2013-01-01', periods=4, freq='M', name='idx', tz='Asia/Tokyo')
+        idx = pd.date_range(start='2013-01-01', periods=4, freq='M',
+                            name='idx', tz='Asia/Tokyo')
         expected_list = [pd.Timestamp('2013-01-31', tz='Asia/Tokyo'),
                          pd.Timestamp('2013-02-28', tz='Asia/Tokyo'),
                          pd.Timestamp('2013-03-31', tz='Asia/Tokyo'),
@@ -99,8 +113,9 @@ class TestDatetimeIndexOps(Ops):
 
         idx = DatetimeIndex([datetime(2013, 1, 1), datetime(2013, 1, 2),
                              pd.NaT, datetime(2013, 1, 4)], name='idx')
-        expected_list = [pd.Timestamp('2013-01-01'), pd.Timestamp('2013-01-02'),
-                         pd.NaT, pd.Timestamp('2013-01-04')]
+        expected_list = [pd.Timestamp('2013-01-01'),
+                         pd.Timestamp('2013-01-02'), pd.NaT,
+                         pd.Timestamp('2013-01-04')]
         expected = pd.Index(expected_list, dtype=object, name='idx')
         result = idx.asobject
         self.assertTrue(isinstance(result, Index))
@@ -144,22 +159,33 @@ class TestDatetimeIndexOps(Ops):
         idx.append(DatetimeIndex([], freq='D'))
         idx.append(DatetimeIndex(['2011-01-01'], freq='D'))
         idx.append(DatetimeIndex(['2011-01-01', '2011-01-02'], freq='D'))
-        idx.append(DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03'], freq='D'))
-        idx.append(DatetimeIndex(['2011-01-01 09:00', '2011-01-01 10:00', '2011-01-01 11:00'],
-                                 freq='H', tz='Asia/Tokyo'))
-        idx.append(DatetimeIndex(['2011-01-01 09:00', '2011-01-01 10:00', pd.NaT],
-                                 tz='US/Eastern'))
-        idx.append(DatetimeIndex(['2011-01-01 09:00', '2011-01-01 10:00', pd.NaT],
-                                 tz='UTC'))
+        idx.append(DatetimeIndex(
+            ['2011-01-01', '2011-01-02', '2011-01-03'], freq='D'))
+        idx.append(DatetimeIndex(
+            ['2011-01-01 09:00', '2011-01-01 10:00', '2011-01-01 11:00'
+             ], freq='H', tz='Asia/Tokyo'))
+        idx.append(DatetimeIndex(
+            ['2011-01-01 09:00', '2011-01-01 10:00', pd.NaT], tz='US/Eastern'))
+        idx.append(DatetimeIndex(
+            ['2011-01-01 09:00', '2011-01-01 10:00', pd.NaT], tz='UTC'))
 
         exp = []
         exp.append("""DatetimeIndex([], dtype='datetime64[ns]', freq='D')""")
-        exp.append("""DatetimeIndex(['2011-01-01'], dtype='datetime64[ns]', freq='D')""")
-        exp.append("""DatetimeIndex(['2011-01-01', '2011-01-02'], dtype='datetime64[ns]', freq='D')""")
-        exp.append("""DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03'], dtype='datetime64[ns]', freq='D')""")
-        exp.append("""DatetimeIndex(['2011-01-01 09:00:00+09:00', '2011-01-01 10:00:00+09:00', '2011-01-01 11:00:00+09:00'], dtype='datetime64[ns, Asia/Tokyo]', freq='H')""")
-        exp.append("""DatetimeIndex(['2011-01-01 09:00:00-05:00', '2011-01-01 10:00:00-05:00', 'NaT'], dtype='datetime64[ns, US/Eastern]', freq=None)""")
-        exp.append("""DatetimeIndex(['2011-01-01 09:00:00+00:00', '2011-01-01 10:00:00+00:00', 'NaT'], dtype='datetime64[ns, UTC]', freq=None)""")
+        exp.append("DatetimeIndex(['2011-01-01'], dtype='datetime64[ns]', "
+                   "freq='D')")
+        exp.append("DatetimeIndex(['2011-01-01', '2011-01-02'], "
+                   "dtype='datetime64[ns]', freq='D')")
+        exp.append("DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03'], "
+                   "dtype='datetime64[ns]', freq='D')")
+        exp.append("DatetimeIndex(['2011-01-01 09:00:00+09:00', "
+                   "'2011-01-01 10:00:00+09:00', '2011-01-01 11:00:00+09:00']"
+                   ", dtype='datetime64[ns, Asia/Tokyo]', freq='H')")
+        exp.append("DatetimeIndex(['2011-01-01 09:00:00-05:00', "
+                   "'2011-01-01 10:00:00-05:00', 'NaT'], "
+                   "dtype='datetime64[ns, US/Eastern]', freq=None)")
+        exp.append("DatetimeIndex(['2011-01-01 09:00:00+00:00', "
+                   "'2011-01-01 10:00:00+00:00', 'NaT'], "
+                   "dtype='datetime64[ns, UTC]', freq=None)""")
 
         with pd.option_context('display.width', 300):
             for indx, expected in zip(idx, exp):
@@ -171,9 +197,10 @@ class TestDatetimeIndexOps(Ops):
         idx1 = DatetimeIndex([], freq='D')
         idx2 = DatetimeIndex(['2011-01-01'], freq='D')
         idx3 = DatetimeIndex(['2011-01-01', '2011-01-02'], freq='D')
-        idx4 = DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03'], freq='D')
-        idx5 = DatetimeIndex(['2011-01-01 09:00', '2011-01-01 10:00', '2011-01-01 11:00'],
-                             freq='H', tz='Asia/Tokyo')
+        idx4 = DatetimeIndex(
+            ['2011-01-01', '2011-01-02', '2011-01-03'], freq='D')
+        idx5 = DatetimeIndex(['2011-01-01 09:00', '2011-01-01 10:00',
+                              '2011-01-01 11:00'], freq='H', tz='Asia/Tokyo')
         idx6 = DatetimeIndex(['2011-01-01 09:00', '2011-01-01 10:00', pd.NaT],
                              tz='US/Eastern')
         idx7 = DatetimeIndex(['2011-01-01 09:00', '2011-01-02 10:15'])
@@ -207,8 +234,10 @@ dtype: datetime64[ns, US/Eastern]"""
 dtype: datetime64[ns]"""
 
         with pd.option_context('display.width', 300):
-            for idx, expected in zip([idx1, idx2, idx3, idx4, idx5, idx6, idx7],
-                                     [exp1, exp2, exp3, exp4, exp5, exp6, exp7]):
+            for idx, expected in zip([idx1, idx2, idx3, idx4,
+                                      idx5, idx6, idx7],
+                                     [exp1, exp2, exp3, exp4,
+                                      exp5, exp6, exp7]):
                 result = repr(Series(idx))
                 self.assertEqual(result, expected)
 
@@ -217,22 +246,30 @@ dtype: datetime64[ns]"""
         idx1 = DatetimeIndex([], freq='D')
         idx2 = DatetimeIndex(['2011-01-01'], freq='D')
         idx3 = DatetimeIndex(['2011-01-01', '2011-01-02'], freq='D')
-        idx4 = DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03'], freq='D')
-        idx5 = DatetimeIndex(['2011-01-01 09:00', '2011-01-01 10:00', '2011-01-01 11:00'],
+        idx4 = DatetimeIndex(
+            ['2011-01-01', '2011-01-02', '2011-01-03'], freq='D')
+        idx5 = DatetimeIndex(['2011-01-01 09:00', '2011-01-01 10:00',
+                              '2011-01-01 11:00'],
                              freq='H', tz='Asia/Tokyo')
         idx6 = DatetimeIndex(['2011-01-01 09:00', '2011-01-01 10:00', pd.NaT],
                              tz='US/Eastern')
 
         exp1 = """DatetimeIndex: 0 entries
 Freq: D"""
+
         exp2 = """DatetimeIndex: 1 entries, 2011-01-01 to 2011-01-01
 Freq: D"""
+
         exp3 = """DatetimeIndex: 2 entries, 2011-01-01 to 2011-01-02
 Freq: D"""
+
         exp4 = """DatetimeIndex: 3 entries, 2011-01-01 to 2011-01-03
 Freq: D"""
-        exp5 = """DatetimeIndex: 3 entries, 2011-01-01 09:00:00+09:00 to 2011-01-01 11:00:00+09:00
-Freq: H"""
+
+        exp5 = ("DatetimeIndex: 3 entries, 2011-01-01 09:00:00+09:00 "
+                "to 2011-01-01 11:00:00+09:00\n"
+                "Freq: H")
+
         exp6 = """DatetimeIndex: 3 entries, 2011-01-01 09:00:00-05:00 to NaT"""
 
         for idx, expected in zip([idx1, idx2, idx3, idx4, idx5, idx6],
@@ -241,11 +278,14 @@ Freq: H"""
             self.assertEqual(result, expected)
 
     def test_resolution(self):
-        for freq, expected in zip(['A', 'Q', 'M', 'D', 'H', 'T', 'S', 'L', 'U'],
-                                  ['day', 'day', 'day', 'day',
-                                   'hour', 'minute', 'second', 'millisecond', 'microsecond']):
+        for freq, expected in zip(['A', 'Q', 'M', 'D', 'H', 'T',
+                                   'S', 'L', 'U'],
+                                  ['day', 'day', 'day', 'day', 'hour',
+                                   'minute', 'second', 'millisecond',
+                                   'microsecond']):
             for tz in [None, 'Asia/Tokyo', 'US/Eastern']:
-                idx = pd.date_range(start='2013-04-01', periods=30, freq=freq, tz=tz)
+                idx = pd.date_range(start='2013-04-01', periods=30, freq=freq,
+                                    tz=tz)
                 self.assertEqual(idx.resolution, expected)
 
     def test_add_iadd(self):
@@ -263,7 +303,8 @@ Freq: H"""
             other3 = pd.DatetimeIndex([], tz=tz)
             expected3 = pd.date_range('1/1/2000', freq='D', periods=5, tz=tz)
 
-            for rng, other, expected in [(rng1, other1, expected1), (rng2, other2, expected2),
+            for rng, other, expected in [(rng1, other1, expected1),
+                                         (rng2, other2, expected2),
                                          (rng3, other3, expected3)]:
                 # GH9094
                 with tm.assert_produces_warning(FutureWarning):
@@ -279,20 +320,23 @@ Freq: H"""
 
             # offset
             offsets = [pd.offsets.Hour(2), timedelta(hours=2),
-                       np.timedelta64(2, 'h'),  Timedelta(hours=2)]
+                       np.timedelta64(2, 'h'), Timedelta(hours=2)]
 
             for delta in offsets:
                 rng = pd.date_range('2000-01-01', '2000-02-01', tz=tz)
                 result = rng + delta
-                expected = pd.date_range('2000-01-01 02:00', '2000-02-01 02:00', tz=tz)
+                expected = pd.date_range('2000-01-01 02:00',
+                                         '2000-02-01 02:00', tz=tz)
                 tm.assert_index_equal(result, expected)
                 rng += delta
                 tm.assert_index_equal(rng, expected)
 
             # int
-            rng = pd.date_range('2000-01-01 09:00', freq='H', periods=10, tz=tz)
+            rng = pd.date_range('2000-01-01 09:00', freq='H', periods=10,
+                                tz=tz)
             result = rng + 1
-            expected = pd.date_range('2000-01-01 10:00', freq='H', periods=10, tz=tz)
+            expected = pd.date_range('2000-01-01 10:00', freq='H', periods=10,
+                                     tz=tz)
             tm.assert_index_equal(result, expected)
             rng += 1
             tm.assert_index_equal(rng, expected)
@@ -312,28 +356,32 @@ Freq: H"""
             other3 = pd.DatetimeIndex([], tz=tz)
             expected3 = pd.date_range('1/1/2000', freq='D', periods=5, tz=tz)
 
-            for rng, other, expected in [(rng1, other1, expected1), (rng2, other2, expected2),
+            for rng, other, expected in [(rng1, other1, expected1),
+                                         (rng2, other2, expected2),
                                          (rng3, other3, expected3)]:
                 result_union = rng.difference(other)
 
                 tm.assert_index_equal(result_union, expected)
 
             # offset
-            offsets = [pd.offsets.Hour(2), timedelta(hours=2), np.timedelta64(2, 'h'),
-                       Timedelta(hours=2)]
+            offsets = [pd.offsets.Hour(2), timedelta(hours=2),
+                       np.timedelta64(2, 'h'), Timedelta(hours=2)]
 
             for delta in offsets:
                 rng = pd.date_range('2000-01-01', '2000-02-01', tz=tz)
                 result = rng - delta
-                expected = pd.date_range('1999-12-31 22:00', '2000-01-31 22:00', tz=tz)
+                expected = pd.date_range('1999-12-31 22:00',
+                                         '2000-01-31 22:00', tz=tz)
                 tm.assert_index_equal(result, expected)
                 rng -= delta
                 tm.assert_index_equal(rng, expected)
 
             # int
-            rng = pd.date_range('2000-01-01 09:00', freq='H', periods=10, tz=tz)
+            rng = pd.date_range('2000-01-01 09:00', freq='H', periods=10,
+                                tz=tz)
             result = rng - 1
-            expected = pd.date_range('2000-01-01 08:00', freq='H', periods=10, tz=tz)
+            expected = pd.date_range('2000-01-01 08:00', freq='H', periods=10,
+                                     tz=tz)
             tm.assert_index_equal(result, expected)
             rng -= 1
             tm.assert_index_equal(rng, expected)
@@ -343,23 +391,29 @@ Freq: H"""
         for tz in [None, 'UTC', 'Asia/Tokyo', 'US/Eastern']:
             idx = pd.date_range('2011-01-01 09:00', freq='H', periods=10)
             # create repeated values, 'n'th element is repeated by n+1 times
-            idx = DatetimeIndex(np.repeat(idx.values, range(1, len(idx) + 1)), tz=tz)
+            idx = DatetimeIndex(
+                np.repeat(idx.values, range(1, len(idx) + 1)), tz=tz)
 
-            exp_idx = pd.date_range('2011-01-01 18:00', freq='-1H', periods=10, tz=tz)
+            exp_idx = pd.date_range('2011-01-01 18:00', freq='-1H', periods=10,
+                                    tz=tz)
             expected = Series(range(10, 0, -1), index=exp_idx, dtype='int64')
             tm.assert_series_equal(idx.value_counts(), expected)
 
-            expected = pd.date_range('2011-01-01 09:00', freq='H', periods=10, tz=tz)
+            expected = pd.date_range('2011-01-01 09:00', freq='H', periods=10,
+                                     tz=tz)
             tm.assert_index_equal(idx.unique(), expected)
 
-            idx = DatetimeIndex(['2013-01-01 09:00', '2013-01-01 09:00', '2013-01-01 09:00',
-                                 '2013-01-01 08:00', '2013-01-01 08:00', pd.NaT], tz=tz)
+            idx = DatetimeIndex(['2013-01-01 09:00', '2013-01-01 09:00',
+                                 '2013-01-01 09:00', '2013-01-01 08:00',
+                                 '2013-01-01 08:00', pd.NaT], tz=tz)
 
-            exp_idx = DatetimeIndex(['2013-01-01 09:00', '2013-01-01 08:00'], tz=tz)
+            exp_idx = DatetimeIndex(
+                ['2013-01-01 09:00', '2013-01-01 08:00'], tz=tz)
             expected = Series([3, 2], index=exp_idx)
             tm.assert_series_equal(idx.value_counts(), expected)
 
-            exp_idx = DatetimeIndex(['2013-01-01 09:00', '2013-01-01 08:00', pd.NaT], tz=tz)
+            exp_idx = DatetimeIndex(
+                ['2013-01-01 09:00', '2013-01-01 08:00', pd.NaT], tz=tz)
             expected = Series([3, 2, 1], index=exp_idx)
             tm.assert_series_equal(idx.value_counts(dropna=False), expected)
 
@@ -367,15 +421,18 @@ Freq: H"""
 
     def test_nonunique_contains(self):
         # GH 9512
-        for idx in map(DatetimeIndex, ([0, 1, 0], [0, 0, -1], [0, -1, -1],
-                                       ['2015', '2015', '2016'], ['2015', '2015', '2014'])):
+        for idx in map(DatetimeIndex,
+                       ([0, 1, 0], [0, 0, -1], [0, -1, -1],
+                        ['2015', '2015', '2016'], ['2015', '2015', '2014'])):
             tm.assertIn(idx[0], idx)
 
     def test_order(self):
         # with freq
-        idx1 = DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03'], freq='D', name='idx')
-        idx2 = DatetimeIndex(['2011-01-01 09:00', '2011-01-01 10:00', '2011-01-01 11:00'],
-                             freq='H', tz='Asia/Tokyo', name='tzidx')
+        idx1 = DatetimeIndex(
+            ['2011-01-01', '2011-01-02', '2011-01-03'], freq='D', name='idx')
+        idx2 = DatetimeIndex(['2011-01-01 09:00', '2011-01-01 10:00',
+                              '2011-01-01 11:00'], freq='H',
+                             tz='Asia/Tokyo', name='tzidx')
 
         for idx in [idx1, idx2]:
             ordered = idx.sort_values()
@@ -393,7 +450,8 @@ Freq: H"""
             self.assert_numpy_array_equal(indexer, np.array([0, 1, 2]))
             self.assertEqual(ordered.freq, idx.freq)
 
-            ordered, indexer = idx.sort_values(return_indexer=True, ascending=False)
+            ordered, indexer = idx.sort_values(return_indexer=True,
+                                               ascending=False)
             expected = idx[::-1]
             self.assert_index_equal(ordered, expected)
             self.assert_numpy_array_equal(indexer, np.array([2, 1, 0]))
@@ -409,14 +467,17 @@ Freq: H"""
         idx2 = DatetimeIndex(['2011-01-01', '2011-01-03', '2011-01-05',
                               '2011-01-02', '2011-01-01'],
                              tz='Asia/Tokyo', name='idx2')
-        exp2 = DatetimeIndex(['2011-01-01', '2011-01-01', '2011-01-02',
-                              '2011-01-03', '2011-01-05'],
-                             tz='Asia/Tokyo', name='idx2')
 
-        idx3 = DatetimeIndex([pd.NaT, '2011-01-03', '2011-01-05',
-                              '2011-01-02', pd.NaT], name='idx3')
-        exp3 = DatetimeIndex([pd.NaT, pd.NaT, '2011-01-02', '2011-01-03',
-                              '2011-01-05'], name='idx3')
+        # TODO(wesm): unused?
+
+        # exp2 = DatetimeIndex(['2011-01-01', '2011-01-01', '2011-01-02',
+        #                       '2011-01-03', '2011-01-05'],
+        #                      tz='Asia/Tokyo', name='idx2')
+
+        # idx3 = DatetimeIndex([pd.NaT, '2011-01-03', '2011-01-05',
+        #                       '2011-01-02', pd.NaT], name='idx3')
+        # exp3 = DatetimeIndex([pd.NaT, pd.NaT, '2011-01-02', '2011-01-03',
+        #                       '2011-01-05'], name='idx3')
 
         for idx, expected in [(idx1, exp1), (idx1, exp1), (idx1, exp1)]:
             ordered = idx.sort_values()
@@ -432,14 +493,16 @@ Freq: H"""
             self.assert_numpy_array_equal(indexer, np.array([0, 4, 3, 1, 2]))
             self.assertIsNone(ordered.freq)
 
-            ordered, indexer = idx.sort_values(return_indexer=True, ascending=False)
+            ordered, indexer = idx.sort_values(return_indexer=True,
+                                               ascending=False)
             self.assert_index_equal(ordered, expected[::-1])
             self.assert_numpy_array_equal(indexer, np.array([2, 1, 3, 4, 0]))
             self.assertIsNone(ordered.freq)
 
     def test_getitem(self):
         idx1 = pd.date_range('2011-01-01', '2011-01-31', freq='D', name='idx')
-        idx2 = pd.date_range('2011-01-01', '2011-01-31', freq='D', tz='Asia/Tokyo', name='idx')
+        idx2 = pd.date_range('2011-01-01', '2011-01-31', freq='D',
+                             tz='Asia/Tokyo', name='idx')
 
         for idx in [idx1, idx2]:
             result = idx[0]
@@ -471,22 +534,23 @@ Freq: H"""
             self.assertEqual(result.freq, expected.freq)
 
     def test_drop_duplicates_metadata(self):
-        #GH 10115
+        # GH 10115
         idx = pd.date_range('2011-01-01', '2011-01-31', freq='D', name='idx')
         result = idx.drop_duplicates()
         self.assert_index_equal(idx, result)
         self.assertEqual(idx.freq, result.freq)
 
         idx_dup = idx.append(idx)
-        self.assertIsNone(idx_dup.freq)   # freq is reset
+        self.assertIsNone(idx_dup.freq)  # freq is reset
         result = idx_dup.drop_duplicates()
         self.assert_index_equal(idx, result)
         self.assertIsNone(result.freq)
 
     def test_take(self):
-        #GH 10295
+        # GH 10295
         idx1 = pd.date_range('2011-01-01', '2011-01-31', freq='D', name='idx')
-        idx2 = pd.date_range('2011-01-01', '2011-01-31', freq='D', tz='Asia/Tokyo', name='idx')
+        idx2 = pd.date_range('2011-01-01', '2011-01-31', freq='D',
+                             tz='Asia/Tokyo', name='idx')
 
         for idx in [idx1, idx2]:
             result = idx.take([0])
@@ -511,42 +575,46 @@ Freq: H"""
             self.assertEqual(result.freq, expected.freq)
 
             result = idx.take([3, 2, 5])
-            expected = DatetimeIndex(['2011-01-04', '2011-01-03', '2011-01-06'],
+            expected = DatetimeIndex(['2011-01-04', '2011-01-03',
+                                      '2011-01-06'],
                                      freq=None, tz=idx.tz, name='idx')
             self.assert_index_equal(result, expected)
             self.assertIsNone(result.freq)
 
             result = idx.take([-3, 2, 5])
-            expected = DatetimeIndex(['2011-01-29', '2011-01-03', '2011-01-06'],
+            expected = DatetimeIndex(['2011-01-29', '2011-01-03',
+                                      '2011-01-06'],
                                      freq=None, tz=idx.tz, name='idx')
             self.assert_index_equal(result, expected)
             self.assertIsNone(result.freq)
 
     def test_infer_freq(self):
         # GH 11018
-        for freq in ['A', '2A', '-2A', 'Q', '-1Q', 'M', '-1M', 'D', '3D', '-3D',
-                     'W', '-1W', 'H', '2H', '-2H', 'T', '2T', 'S', '-3S']:
+        for freq in ['A', '2A', '-2A', 'Q', '-1Q', 'M', '-1M', 'D', '3D',
+                     '-3D', 'W', '-1W', 'H', '2H', '-2H', 'T', '2T', 'S',
+                     '-3S']:
             idx = pd.date_range('2011-01-01 09:00:00', freq=freq, periods=10)
             result = pd.DatetimeIndex(idx.asi8, freq='infer')
             tm.assert_index_equal(idx, result)
             self.assertEqual(result.freq, freq)
 
-class TestTimedeltaIndexOps(Ops):
 
+class TestTimedeltaIndexOps(Ops):
     def setUp(self):
         super(TestTimedeltaIndexOps, self).setUp()
         mask = lambda x: isinstance(x, TimedeltaIndex)
-        self.is_valid_objs  = [ o for o in self.objs if mask(o) ]
-        self.not_valid_objs = [ ]
+        self.is_valid_objs = [o for o in self.objs if mask(o)]
+        self.not_valid_objs = []
 
     def test_ops_properties(self):
-        self.check_ops_properties(['days','hours','minutes','seconds','milliseconds'])
-        self.check_ops_properties(['microseconds','nanoseconds'])
+        self.check_ops_properties(['days', 'hours', 'minutes', 'seconds',
+                                   'milliseconds'])
+        self.check_ops_properties(['microseconds', 'nanoseconds'])
 
     def test_asobject_tolist(self):
         idx = timedelta_range(start='1 days', periods=4, freq='D', name='idx')
-        expected_list = [Timedelta('1 days'),Timedelta('2 days'),Timedelta('3 days'),
-                         Timedelta('4 days')]
+        expected_list = [Timedelta('1 days'), Timedelta('2 days'),
+                         Timedelta('3 days'), Timedelta('4 days')]
         expected = pd.Index(expected_list, dtype=object, name='idx')
         result = idx.asobject
         self.assertTrue(isinstance(result, Index))
@@ -556,9 +624,9 @@ class TestTimedeltaIndexOps(Ops):
         self.assertEqual(result.name, expected.name)
         self.assertEqual(idx.tolist(), expected_list)
 
-        idx = TimedeltaIndex([timedelta(days=1),timedelta(days=2),pd.NaT,
+        idx = TimedeltaIndex([timedelta(days=1), timedelta(days=2), pd.NaT,
                               timedelta(days=4)], name='idx')
-        expected_list = [Timedelta('1 days'),Timedelta('2 days'),pd.NaT,
+        expected_list = [Timedelta('1 days'), Timedelta('2 days'), pd.NaT,
                          Timedelta('4 days')]
         expected = pd.Index(expected_list, dtype=object, name='idx')
         result = idx.asobject
@@ -604,15 +672,19 @@ class TestTimedeltaIndexOps(Ops):
 
         exp1 = """TimedeltaIndex([], dtype='timedelta64[ns]', freq='D')"""
 
-        exp2 = """TimedeltaIndex(['1 days'], dtype='timedelta64[ns]', freq='D')"""
+        exp2 = ("TimedeltaIndex(['1 days'], dtype='timedelta64[ns]', "
+                "freq='D')")
 
-        exp3 = """TimedeltaIndex(['1 days', '2 days'], dtype='timedelta64[ns]', freq='D')"""
+        exp3 = ("TimedeltaIndex(['1 days', '2 days'], "
+                "dtype='timedelta64[ns]', freq='D')")
 
-        exp4 = """TimedeltaIndex(['1 days', '2 days', '3 days'], dtype='timedelta64[ns]', freq='D')"""
+        exp4 = ("TimedeltaIndex(['1 days', '2 days', '3 days'], "
+                "dtype='timedelta64[ns]', freq='D')")
 
-        exp5 = """TimedeltaIndex(['1 days 00:00:01', '2 days 00:00:00', '3 days 00:00:00'], dtype='timedelta64[ns]', freq=None)"""
+        exp5 = ("TimedeltaIndex(['1 days 00:00:01', '2 days 00:00:00', "
+                "'3 days 00:00:00'], dtype='timedelta64[ns]', freq=None)")
 
-        with pd.option_context('display.width',300):
+        with pd.option_context('display.width', 300):
             for idx, expected in zip([idx1, idx2, idx3, idx4, idx5],
                                      [exp1, exp2, exp3, exp4, exp5]):
                 for func in ['__repr__', '__unicode__', '__str__']:
@@ -645,7 +717,7 @@ dtype: timedelta64[ns]"""
 2   3 days 00:00:00
 dtype: timedelta64[ns]"""
 
-        with pd.option_context('display.width',300):
+        with pd.option_context('display.width', 300):
             for idx, expected in zip([idx1, idx2, idx3, idx4, idx5],
                                      [exp1, exp2, exp3, exp4, exp5]):
                 result = repr(pd.Series(idx))
@@ -661,13 +733,18 @@ dtype: timedelta64[ns]"""
 
         exp1 = """TimedeltaIndex: 0 entries
 Freq: D"""
+
         exp2 = """TimedeltaIndex: 1 entries, 1 days to 1 days
 Freq: D"""
+
         exp3 = """TimedeltaIndex: 2 entries, 1 days to 2 days
 Freq: D"""
+
         exp4 = """TimedeltaIndex: 3 entries, 1 days to 3 days
 Freq: D"""
-        exp5 = """TimedeltaIndex: 3 entries, 1 days 00:00:01 to 3 days 00:00:00"""
+
+        exp5 = ("TimedeltaIndex: 3 entries, 1 days 00:00:01 to 3 days "
+                "00:00:00")
 
         for idx, expected in zip([idx1, idx2, idx3, idx4, idx5],
                                  [exp1, exp2, exp3, exp4, exp5]):
@@ -680,12 +757,13 @@ Freq: D"""
 
         # offset
         offsets = [pd.offsets.Hour(2), timedelta(hours=2),
-                   np.timedelta64(2, 'h'),  Timedelta(hours=2)]
+                   np.timedelta64(2, 'h'), Timedelta(hours=2)]
 
         for delta in offsets:
-            rng = timedelta_range('1 days','10 days')
+            rng = timedelta_range('1 days', '10 days')
             result = rng + delta
-            expected = timedelta_range('1 days 02:00:00','10 days 02:00:00',freq='D')
+            expected = timedelta_range('1 days 02:00:00', '10 days 02:00:00',
+                                       freq='D')
             tm.assert_index_equal(result, expected)
             rng += delta
             tm.assert_index_equal(rng, expected)
@@ -703,11 +781,11 @@ Freq: D"""
         # only test adding/sub offsets as - is now numeric
 
         # offset
-        offsets = [pd.offsets.Hour(2), timedelta(hours=2), np.timedelta64(2, 'h'),
-                   Timedelta(hours=2)]
+        offsets = [pd.offsets.Hour(2), timedelta(hours=2),
+                   np.timedelta64(2, 'h'), Timedelta(hours=2)]
 
         for delta in offsets:
-            rng = timedelta_range('1 days','10 days')
+            rng = timedelta_range('1 days', '10 days')
             result = rng - delta
             expected = timedelta_range('0 days 22:00:00', '9 days 22:00:00')
             tm.assert_index_equal(result, expected)
@@ -724,10 +802,10 @@ Freq: D"""
 
     def test_ops_compat(self):
 
-        offsets = [pd.offsets.Hour(2), timedelta(hours=2), np.timedelta64(2, 'h'),
-                   Timedelta(hours=2)]
+        offsets = [pd.offsets.Hour(2), timedelta(hours=2),
+                   np.timedelta64(2, 'h'), Timedelta(hours=2)]
 
-        rng = timedelta_range('1 days','10 days',name='foo')
+        rng = timedelta_range('1 days', '10 days', name='foo')
 
         # multiply
         for offset in offsets:
@@ -744,10 +822,10 @@ Freq: D"""
         expected = Float64Index([12, np.nan, 24], name='foo')
         for offset in offsets:
             result = rng / offset
-            tm.assert_index_equal(result,expected)
+            tm.assert_index_equal(result, expected)
 
         # don't allow division by NaT (make could in the future)
-        self.assertRaises(TypeError, lambda : rng / pd.NaT)
+        self.assertRaises(TypeError, lambda: rng / pd.NaT)
 
     def test_subtraction_ops(self):
 
@@ -757,10 +835,10 @@ Freq: D"""
         td = Timedelta('1 days')
         dt = Timestamp('20130101')
 
-        self.assertRaises(TypeError, lambda : tdi - dt)
-        self.assertRaises(TypeError, lambda : tdi - dti)
-        self.assertRaises(TypeError, lambda : td - dt)
-        self.assertRaises(TypeError, lambda : td - dti)
+        self.assertRaises(TypeError, lambda: tdi - dt)
+        self.assertRaises(TypeError, lambda: tdi - dti)
+        self.assertRaises(TypeError, lambda: td - dt)
+        self.assertRaises(TypeError, lambda: td - dti)
 
         result = dt - dti
         expected = TimedeltaIndex(['0 days', '-1 days', '-2 days'], name='bar')
@@ -779,7 +857,8 @@ Freq: D"""
         tm.assert_index_equal(result, expected, check_names=False)
 
         result = dti - td
-        expected = DatetimeIndex(['20121231', '20130101', '20130102'], name='bar')
+        expected = DatetimeIndex(
+            ['20121231', '20130101', '20130102'], name='bar')
         tm.assert_index_equal(result, expected, check_names=False)
 
         result = dt - tdi
@@ -789,17 +868,17 @@ Freq: D"""
     def test_subtraction_ops_with_tz(self):
 
         # check that dt/dti subtraction ops with tz are validated
-        dti = date_range('20130101',periods=3)
+        dti = date_range('20130101', periods=3)
         ts = Timestamp('20130101')
         dt = ts.to_datetime()
-        dti_tz = date_range('20130101',periods=3).tz_localize('US/Eastern')
+        dti_tz = date_range('20130101', periods=3).tz_localize('US/Eastern')
         ts_tz = Timestamp('20130101').tz_localize('US/Eastern')
         ts_tz2 = Timestamp('20130101').tz_localize('CET')
         dt_tz = ts_tz.to_datetime()
         td = Timedelta('1 days')
 
         def _check(result, expected):
-            self.assertEqual(result,expected)
+            self.assertEqual(result, expected)
             self.assertIsInstance(result, Timedelta)
 
         # scalars
@@ -816,43 +895,44 @@ Freq: D"""
         _check(result, expected)
 
         # tz mismatches
-        self.assertRaises(TypeError, lambda : dt_tz - ts)
-        self.assertRaises(TypeError, lambda : dt_tz - dt)
-        self.assertRaises(TypeError, lambda : dt_tz - ts_tz2)
-        self.assertRaises(TypeError, lambda : dt - dt_tz)
-        self.assertRaises(TypeError, lambda : ts - dt_tz)
-        self.assertRaises(TypeError, lambda : ts_tz2 - ts)
-        self.assertRaises(TypeError, lambda : ts_tz2 - dt)
-        self.assertRaises(TypeError, lambda : ts_tz - ts_tz2)
+        self.assertRaises(TypeError, lambda: dt_tz - ts)
+        self.assertRaises(TypeError, lambda: dt_tz - dt)
+        self.assertRaises(TypeError, lambda: dt_tz - ts_tz2)
+        self.assertRaises(TypeError, lambda: dt - dt_tz)
+        self.assertRaises(TypeError, lambda: ts - dt_tz)
+        self.assertRaises(TypeError, lambda: ts_tz2 - ts)
+        self.assertRaises(TypeError, lambda: ts_tz2 - dt)
+        self.assertRaises(TypeError, lambda: ts_tz - ts_tz2)
 
         # with dti
-        self.assertRaises(TypeError, lambda : dti - ts_tz)
-        self.assertRaises(TypeError, lambda : dti_tz - ts)
-        self.assertRaises(TypeError, lambda : dti_tz - ts_tz2)
+        self.assertRaises(TypeError, lambda: dti - ts_tz)
+        self.assertRaises(TypeError, lambda: dti_tz - ts)
+        self.assertRaises(TypeError, lambda: dti_tz - ts_tz2)
 
-        result = dti_tz-dt_tz
-        expected = TimedeltaIndex(['0 days','1 days','2 days'])
-        tm.assert_index_equal(result,expected)
+        result = dti_tz - dt_tz
+        expected = TimedeltaIndex(['0 days', '1 days', '2 days'])
+        tm.assert_index_equal(result, expected)
 
-        result = dt_tz-dti_tz
-        expected = TimedeltaIndex(['0 days','-1 days','-2 days'])
-        tm.assert_index_equal(result,expected)
+        result = dt_tz - dti_tz
+        expected = TimedeltaIndex(['0 days', '-1 days', '-2 days'])
+        tm.assert_index_equal(result, expected)
 
-        result = dti_tz-ts_tz
-        expected = TimedeltaIndex(['0 days','1 days','2 days'])
-        tm.assert_index_equal(result,expected)
+        result = dti_tz - ts_tz
+        expected = TimedeltaIndex(['0 days', '1 days', '2 days'])
+        tm.assert_index_equal(result, expected)
 
-        result = ts_tz-dti_tz
-        expected = TimedeltaIndex(['0 days','-1 days','-2 days'])
-        tm.assert_index_equal(result,expected)
+        result = ts_tz - dti_tz
+        expected = TimedeltaIndex(['0 days', '-1 days', '-2 days'])
+        tm.assert_index_equal(result, expected)
 
         result = td - td
         expected = Timedelta('0 days')
         _check(result, expected)
 
         result = dti_tz - td
-        expected = DatetimeIndex(['20121231','20130101','20130102'],tz='US/Eastern')
-        tm.assert_index_equal(result,expected)
+        expected = DatetimeIndex(
+            ['20121231', '20130101', '20130102'], tz='US/Eastern')
+        tm.assert_index_equal(result, expected)
 
     def test_dti_dti_deprecated_ops(self):
 
@@ -860,51 +940,53 @@ Freq: D"""
         # change to return subtraction -> TimeDeltaIndex in 0.17.0
         # shoudl move to the appropriate sections above
 
-        dti = date_range('20130101',periods=3)
-        dti_tz = date_range('20130101',periods=3).tz_localize('US/Eastern')
+        dti = date_range('20130101', periods=3)
+        dti_tz = date_range('20130101', periods=3).tz_localize('US/Eastern')
 
         with tm.assert_produces_warning(FutureWarning):
-            result = dti-dti
+            result = dti - dti
             expected = Index([])
-            tm.assert_index_equal(result,expected)
+            tm.assert_index_equal(result, expected)
 
         with tm.assert_produces_warning(FutureWarning):
-            result = dti+dti
+            result = dti + dti
             expected = dti
-            tm.assert_index_equal(result,expected)
+            tm.assert_index_equal(result, expected)
 
         with tm.assert_produces_warning(FutureWarning):
-            result = dti_tz-dti_tz
+            result = dti_tz - dti_tz
             expected = Index([])
-            tm.assert_index_equal(result,expected)
+            tm.assert_index_equal(result, expected)
 
         with tm.assert_produces_warning(FutureWarning):
-            result = dti_tz+dti_tz
+            result = dti_tz + dti_tz
             expected = dti_tz
-            tm.assert_index_equal(result,expected)
+            tm.assert_index_equal(result, expected)
 
         with tm.assert_produces_warning(FutureWarning):
-            result = dti_tz-dti
+            result = dti_tz - dti
             expected = dti_tz
-            tm.assert_index_equal(result,expected)
+            tm.assert_index_equal(result, expected)
 
         with tm.assert_produces_warning(FutureWarning):
-            result = dti-dti_tz
+            result = dti - dti_tz
             expected = dti
-            tm.assert_index_equal(result,expected)
+            tm.assert_index_equal(result, expected)
 
         with tm.assert_produces_warning(FutureWarning):
-            self.assertRaises(TypeError, lambda : dti_tz+dti)
+            self.assertRaises(TypeError, lambda: dti_tz + dti)
         with tm.assert_produces_warning(FutureWarning):
-            self.assertRaises(TypeError, lambda : dti+dti_tz)
+            self.assertRaises(TypeError, lambda: dti + dti_tz)
 
     def test_dti_tdi_numeric_ops(self):
 
         # These are normally union/diff set-like ops
         tdi = TimedeltaIndex(['1 days', pd.NaT, '2 days'], name='foo')
         dti = date_range('20130101', periods=3, name='bar')
-        td = Timedelta('1 days')
-        dt = Timestamp('20130101')
+
+        # TODO(wesm): unused?
+        # td = Timedelta('1 days')
+        # dt = Timestamp('20130101')
 
         result = tdi - tdi
         expected = TimedeltaIndex(['0 days', pd.NaT, '0 days'], name='foo')
@@ -914,7 +996,7 @@ Freq: D"""
         expected = TimedeltaIndex(['2 days', pd.NaT, '4 days'], name='foo')
         tm.assert_index_equal(result, expected)
 
-        result = dti - tdi   # name will be reset
+        result = dti - tdi  # name will be reset
         expected = DatetimeIndex(['20121231', pd.NaT, '20130101'])
         tm.assert_index_equal(result, expected)
 
@@ -943,20 +1025,20 @@ Freq: D"""
         tm.assert_index_equal(result, expected)
 
         # unequal length
-        self.assertRaises(ValueError, lambda : tdi + dti[0:1])
-        self.assertRaises(ValueError, lambda : tdi[0:1] + dti)
+        self.assertRaises(ValueError, lambda: tdi + dti[0:1])
+        self.assertRaises(ValueError, lambda: tdi[0:1] + dti)
 
         # random indexes
-        self.assertRaises(TypeError, lambda : tdi + Int64Index([1,2,3]))
+        self.assertRaises(TypeError, lambda: tdi + Int64Index([1, 2, 3]))
 
         # this is a union!
-        #self.assertRaises(TypeError, lambda : Int64Index([1,2,3]) + tdi)
+        # self.assertRaises(TypeError, lambda : Int64Index([1,2,3]) + tdi)
 
-        result = tdi + dti   # name will be reset
+        result = tdi + dti  # name will be reset
         expected = DatetimeIndex(['20130102', pd.NaT, '20130105'])
         tm.assert_index_equal(result, expected)
 
-        result = dti + tdi   # name will be reset
+        result = dti + tdi  # name will be reset
         expected = DatetimeIndex(['20130102', pd.NaT, '20130105'])
         tm.assert_index_equal(result, expected)
 
@@ -982,14 +1064,16 @@ Freq: D"""
         expected = timedelta_range('1 days 09:00:00', freq='H', periods=10)
         tm.assert_index_equal(idx.unique(), expected)
 
-        idx = TimedeltaIndex(['1 days 09:00:00', '1 days 09:00:00', '1 days 09:00:00',
-                              '1 days 08:00:00', '1 days 08:00:00', pd.NaT])
+        idx = TimedeltaIndex(
+            ['1 days 09:00:00', '1 days 09:00:00', '1 days 09:00:00',
+             '1 days 08:00:00', '1 days 08:00:00', pd.NaT])
 
         exp_idx = TimedeltaIndex(['1 days 09:00:00', '1 days 08:00:00'])
         expected = Series([3, 2], index=exp_idx)
         tm.assert_series_equal(idx.value_counts(), expected)
 
-        exp_idx = TimedeltaIndex(['1 days 09:00:00', '1 days 08:00:00', pd.NaT])
+        exp_idx = TimedeltaIndex(['1 days 09:00:00', '1 days 08:00:00', pd.NaT
+                                  ])
         expected = Series([3, 2, 1], index=exp_idx)
         tm.assert_series_equal(idx.value_counts(dropna=False), expected)
 
@@ -1003,16 +1087,18 @@ Freq: D"""
             tm.assertIn(idx[0], idx)
 
     def test_unknown_attribute(self):
-        #GH 9680
-        tdi = pd.timedelta_range(start=0,periods=10,freq='1s')
-        ts = pd.Series(np.random.normal(size=10),index=tdi)
-        self.assertNotIn('foo',ts.__dict__.keys())
-        self.assertRaises(AttributeError,lambda : ts.foo)
+        # GH 9680
+        tdi = pd.timedelta_range(start=0, periods=10, freq='1s')
+        ts = pd.Series(np.random.normal(size=10), index=tdi)
+        self.assertNotIn('foo', ts.__dict__.keys())
+        self.assertRaises(AttributeError, lambda: ts.foo)
 
     def test_order(self):
-        #GH 10295
-        idx1 = TimedeltaIndex(['1 day', '2 day', '3 day'], freq='D', name='idx')
-        idx2 = TimedeltaIndex(['1 hour', '2 hour', '3 hour'], freq='H', name='idx')
+        # GH 10295
+        idx1 = TimedeltaIndex(['1 day', '2 day', '3 day'], freq='D',
+                              name='idx')
+        idx2 = TimedeltaIndex(
+            ['1 hour', '2 hour', '3 hour'], freq='H', name='idx')
 
         for idx in [idx1, idx2]:
             ordered = idx.sort_values()
@@ -1030,7 +1116,8 @@ Freq: D"""
             self.assert_numpy_array_equal(indexer, np.array([0, 1, 2]))
             self.assertEqual(ordered.freq, idx.freq)
 
-            ordered, indexer = idx.sort_values(return_indexer=True, ascending=False)
+            ordered, indexer = idx.sort_values(return_indexer=True,
+                                               ascending=False)
             self.assert_index_equal(ordered, idx[::-1])
             self.assertEqual(ordered.freq, expected.freq)
             self.assertEqual(ordered.freq.n, -1)
@@ -1042,13 +1129,15 @@ Freq: D"""
 
         idx2 = TimedeltaIndex(['1 day', '3 day', '5 day',
                                '2 day', '1 day'], name='idx2')
-        exp2 = TimedeltaIndex(['1 day', '1 day', '2 day',
-                               '3 day', '5 day'], name='idx2')
 
-        idx3 = TimedeltaIndex([pd.NaT, '3 minute', '5 minute',
-                               '2 minute', pd.NaT], name='idx3')
-        exp3 = TimedeltaIndex([pd.NaT, pd.NaT, '2 minute', '3 minute',
-                               '5 minute'], name='idx3')
+        # TODO(wesm): unused?
+        # exp2 = TimedeltaIndex(['1 day', '1 day', '2 day',
+        #                        '3 day', '5 day'], name='idx2')
+
+        # idx3 = TimedeltaIndex([pd.NaT, '3 minute', '5 minute',
+        #                        '2 minute', pd.NaT], name='idx3')
+        # exp3 = TimedeltaIndex([pd.NaT, pd.NaT, '2 minute', '3 minute',
+        #                        '5 minute'], name='idx3')
 
         for idx, expected in [(idx1, exp1), (idx1, exp1), (idx1, exp1)]:
             ordered = idx.sort_values()
@@ -1064,7 +1153,8 @@ Freq: D"""
             self.assert_numpy_array_equal(indexer, np.array([0, 4, 3, 1, 2]))
             self.assertIsNone(ordered.freq)
 
-            ordered, indexer = idx.sort_values(return_indexer=True, ascending=False)
+            ordered, indexer = idx.sort_values(return_indexer=True,
+                                               ascending=False)
             self.assert_index_equal(ordered, expected[::-1])
             self.assert_numpy_array_equal(indexer, np.array([2, 1, 3, 4, 0]))
             self.assertIsNone(ordered.freq)
@@ -1077,41 +1167,45 @@ Freq: D"""
             self.assertEqual(result, pd.Timedelta('1 day'))
 
             result = idx[0:5]
-            expected = pd.timedelta_range('1 day', '5 day', freq='D', name='idx')
+            expected = pd.timedelta_range('1 day', '5 day', freq='D',
+                                          name='idx')
             self.assert_index_equal(result, expected)
             self.assertEqual(result.freq, expected.freq)
 
             result = idx[0:10:2]
-            expected = pd.timedelta_range('1 day', '9 day', freq='2D', name='idx')
+            expected = pd.timedelta_range('1 day', '9 day', freq='2D',
+                                          name='idx')
             self.assert_index_equal(result, expected)
             self.assertEqual(result.freq, expected.freq)
 
             result = idx[-20:-5:3]
-            expected = pd.timedelta_range('12 day', '24 day', freq='3D', name='idx')
+            expected = pd.timedelta_range('12 day', '24 day', freq='3D',
+                                          name='idx')
             self.assert_index_equal(result, expected)
             self.assertEqual(result.freq, expected.freq)
 
             result = idx[4::-1]
-            expected = TimedeltaIndex(['5 day', '4 day', '3 day', '2 day', '1 day'],
+            expected = TimedeltaIndex(['5 day', '4 day', '3 day',
+                                       '2 day', '1 day'],
                                       freq='-1D', name='idx')
             self.assert_index_equal(result, expected)
             self.assertEqual(result.freq, expected.freq)
 
     def test_drop_duplicates_metadata(self):
-        #GH 10115
+        # GH 10115
         idx = pd.timedelta_range('1 day', '31 day', freq='D', name='idx')
         result = idx.drop_duplicates()
         self.assert_index_equal(idx, result)
         self.assertEqual(idx.freq, result.freq)
 
         idx_dup = idx.append(idx)
-        self.assertIsNone(idx_dup.freq)   # freq is reset
+        self.assertIsNone(idx_dup.freq)  # freq is reset
         result = idx_dup.drop_duplicates()
         self.assert_index_equal(idx, result)
         self.assertIsNone(result.freq)
 
     def test_take(self):
-        #GH 10295
+        # GH 10295
         idx1 = pd.timedelta_range('1 day', '31 day', freq='D', name='idx')
 
         for idx in [idx1]:
@@ -1122,17 +1216,20 @@ Freq: D"""
             self.assertEqual(result, pd.Timedelta('31 day'))
 
             result = idx.take([0, 1, 2])
-            expected = pd.timedelta_range('1 day', '3 day', freq='D', name='idx')
+            expected = pd.timedelta_range('1 day', '3 day', freq='D',
+                                          name='idx')
             self.assert_index_equal(result, expected)
             self.assertEqual(result.freq, expected.freq)
 
             result = idx.take([0, 2, 4])
-            expected = pd.timedelta_range('1 day', '5 day', freq='2D', name='idx')
+            expected = pd.timedelta_range('1 day', '5 day', freq='2D',
+                                          name='idx')
             self.assert_index_equal(result, expected)
             self.assertEqual(result.freq, expected.freq)
 
             result = idx.take([7, 4, 1])
-            expected = pd.timedelta_range('8 day', '2 day', freq='-3D', name='idx')
+            expected = pd.timedelta_range('8 day', '2 day', freq='-3D',
+                                          name='idx')
             self.assert_index_equal(result, expected)
             self.assertEqual(result.freq, expected.freq)
 
@@ -1148,7 +1245,8 @@ Freq: D"""
 
     def test_infer_freq(self):
         # GH 11018
-        for freq in ['D', '3D', '-3D', 'H', '2H', '-2H', 'T', '2T', 'S', '-3S']:
+        for freq in ['D', '3D', '-3D', 'H', '2H', '-2H', 'T', '2T', 'S', '-3S'
+                     ]:
             idx = pd.timedelta_range('1', freq=freq, periods=10)
             result = pd.TimedeltaIndex(idx.asi8, freq='infer')
             tm.assert_index_equal(idx, result)
@@ -1156,21 +1254,27 @@ Freq: D"""
 
 
 class TestPeriodIndexOps(Ops):
-
     def setUp(self):
         super(TestPeriodIndexOps, self).setUp()
-        mask = lambda x: isinstance(x, DatetimeIndex) or isinstance(x, PeriodIndex)
-        self.is_valid_objs  = [ o for o in self.objs if mask(o) ]
-        self.not_valid_objs = [ o for o in self.objs if not mask(o) ]
+        mask = lambda x: (isinstance(x, DatetimeIndex) or
+                          isinstance(x, PeriodIndex))
+        self.is_valid_objs = [o for o in self.objs if mask(o)]
+        self.not_valid_objs = [o for o in self.objs if not mask(o)]
 
     def test_ops_properties(self):
-        self.check_ops_properties(['year','month','day','hour','minute','second','weekofyear','week','dayofweek','dayofyear','quarter'])
-        self.check_ops_properties(['qyear'], lambda x: isinstance(x,PeriodIndex))
+        self.check_ops_properties(
+            ['year', 'month', 'day', 'hour', 'minute', 'second', 'weekofyear',
+             'week', 'dayofweek', 'dayofyear', 'quarter'])
+        self.check_ops_properties(['qyear'],
+                                  lambda x: isinstance(x, PeriodIndex))
 
     def test_asobject_tolist(self):
-        idx = pd.period_range(start='2013-01-01', periods=4, freq='M', name='idx')
-        expected_list = [pd.Period('2013-01-31', freq='M'), pd.Period('2013-02-28', freq='M'),
-                         pd.Period('2013-03-31', freq='M'), pd.Period('2013-04-30', freq='M')]
+        idx = pd.period_range(start='2013-01-01', periods=4, freq='M',
+                              name='idx')
+        expected_list = [pd.Period('2013-01-31', freq='M'),
+                         pd.Period('2013-02-28', freq='M'),
+                         pd.Period('2013-03-31', freq='M'),
+                         pd.Period('2013-04-30', freq='M')]
         expected = pd.Index(expected_list, dtype=object, name='idx')
         result = idx.asobject
         self.assertTrue(isinstance(result, Index))
@@ -1179,9 +1283,12 @@ class TestPeriodIndexOps(Ops):
         self.assertEqual(result.name, expected.name)
         self.assertEqual(idx.tolist(), expected_list)
 
-        idx = PeriodIndex(['2013-01-01', '2013-01-02', 'NaT', '2013-01-04'], freq='D', name='idx')
-        expected_list = [pd.Period('2013-01-01', freq='D'), pd.Period('2013-01-02', freq='D'),
-                         pd.Period('NaT', freq='D'), pd.Period('2013-01-04', freq='D')]
+        idx = PeriodIndex(['2013-01-01', '2013-01-02', 'NaT',
+                           '2013-01-04'], freq='D', name='idx')
+        expected_list = [pd.Period('2013-01-01', freq='D'),
+                         pd.Period('2013-01-02', freq='D'),
+                         pd.Period('NaT', freq='D'),
+                         pd.Period('2013-01-04', freq='D')]
         expected = pd.Index(expected_list, dtype=object, name='idx')
         result = idx.asobject
         self.assertTrue(isinstance(result, Index))
@@ -1207,7 +1314,7 @@ class TestPeriodIndexOps(Ops):
 
         # non-monotonic
         idx2 = pd.PeriodIndex(['2011-01-01', pd.NaT, '2011-01-03',
-                                '2011-01-02', pd.NaT], freq='D')
+                               '2011-01-02', pd.NaT], freq='D')
         self.assertFalse(idx2.is_monotonic)
 
         for idx in [idx1, idx2]:
@@ -1240,9 +1347,11 @@ class TestPeriodIndexOps(Ops):
         idx1 = PeriodIndex([], freq='D')
         idx2 = PeriodIndex(['2011-01-01'], freq='D')
         idx3 = PeriodIndex(['2011-01-01', '2011-01-02'], freq='D')
-        idx4 = PeriodIndex(['2011-01-01', '2011-01-02', '2011-01-03'], freq='D')
+        idx4 = PeriodIndex(
+            ['2011-01-01', '2011-01-02', '2011-01-03'], freq='D')
         idx5 = PeriodIndex(['2011', '2012', '2013'], freq='A')
-        idx6 = PeriodIndex(['2011-01-01 09:00', '2012-02-01 10:00', 'NaT'], freq='H')
+        idx6 = PeriodIndex(
+            ['2011-01-01 09:00', '2012-02-01 10:00', 'NaT'], freq='H')
 
         idx7 = pd.period_range('2013Q1', periods=1, freq="Q")
         idx8 = pd.period_range('2013Q1', periods=2, freq="Q")
@@ -1252,22 +1361,30 @@ class TestPeriodIndexOps(Ops):
 
         exp2 = """PeriodIndex(['2011-01-01'], dtype='int64', freq='D')"""
 
-        exp3 = """PeriodIndex(['2011-01-01', '2011-01-02'], dtype='int64', freq='D')"""
+        exp3 = ("PeriodIndex(['2011-01-01', '2011-01-02'], dtype='int64', "
+                "freq='D')")
 
-        exp4 = """PeriodIndex(['2011-01-01', '2011-01-02', '2011-01-03'], dtype='int64', freq='D')"""
+        exp4 = ("PeriodIndex(['2011-01-01', '2011-01-02', '2011-01-03'], "
+                "dtype='int64', freq='D')")
 
-        exp5 = """PeriodIndex(['2011', '2012', '2013'], dtype='int64', freq='A-DEC')"""
+        exp5 = ("PeriodIndex(['2011', '2012', '2013'], dtype='int64', "
+                "freq='A-DEC')")
 
-        exp6 = """PeriodIndex(['2011-01-01 09:00', '2012-02-01 10:00', 'NaT'], dtype='int64', freq='H')"""
+        exp6 = ("PeriodIndex(['2011-01-01 09:00', '2012-02-01 10:00', 'NaT'], "
+                "dtype='int64', freq='H')")
 
         exp7 = """PeriodIndex(['2013Q1'], dtype='int64', freq='Q-DEC')"""
 
-        exp8 = """PeriodIndex(['2013Q1', '2013Q2'], dtype='int64', freq='Q-DEC')"""
+        exp8 = ("PeriodIndex(['2013Q1', '2013Q2'], dtype='int64', "
+                "freq='Q-DEC')")
 
-        exp9 = """PeriodIndex(['2013Q1', '2013Q2', '2013Q3'], dtype='int64', freq='Q-DEC')"""
+        exp9 = ("PeriodIndex(['2013Q1', '2013Q2', '2013Q3'], dtype='int64', "
+                "freq='Q-DEC')")
 
-        for idx, expected in zip([idx1, idx2, idx3, idx4, idx5, idx6, idx7, idx8, idx9],
-                                 [exp1, exp2, exp3, exp4, exp5, exp6, exp7, exp8, exp9]):
+        for idx, expected in zip([idx1, idx2, idx3, idx4, idx5,
+                                  idx6, idx7, idx8, idx9],
+                                 [exp1, exp2, exp3, exp4, exp5,
+                                  exp6, exp7, exp8, exp9]):
             for func in ['__repr__', '__unicode__', '__str__']:
                 result = getattr(idx, func)()
                 self.assertEqual(result, expected)
@@ -1277,9 +1394,11 @@ class TestPeriodIndexOps(Ops):
         idx1 = PeriodIndex([], freq='D')
         idx2 = PeriodIndex(['2011-01-01'], freq='D')
         idx3 = PeriodIndex(['2011-01-01', '2011-01-02'], freq='D')
-        idx4 = PeriodIndex(['2011-01-01', '2011-01-02', '2011-01-03'], freq='D')
+        idx4 = PeriodIndex(
+            ['2011-01-01', '2011-01-02', '2011-01-03'], freq='D')
         idx5 = PeriodIndex(['2011', '2012', '2013'], freq='A')
-        idx6 = PeriodIndex(['2011-01-01 09:00', '2012-02-01 10:00', 'NaT'], freq='H')
+        idx6 = PeriodIndex(
+            ['2011-01-01 09:00', '2012-02-01 10:00', 'NaT'], freq='H')
 
         idx7 = pd.period_range('2013Q1', periods=1, freq="Q")
         idx8 = pd.period_range('2013Q1', periods=2, freq="Q")
@@ -1321,8 +1440,10 @@ dtype: object"""
 2   2013Q3
 dtype: object"""
 
-        for idx, expected in zip([idx1, idx2, idx3, idx4, idx5, idx6, idx7, idx8, idx9],
-                                 [exp1, exp2, exp3, exp4, exp5, exp6, exp7, exp8, exp9]):
+        for idx, expected in zip([idx1, idx2, idx3, idx4, idx5,
+                                  idx6, idx7, idx8, idx9],
+                                 [exp1, exp2, exp3, exp4, exp5,
+                                  exp6, exp7, exp8, exp9]):
             result = repr(pd.Series(idx))
             self.assertEqual(result, expected)
 
@@ -1331,9 +1452,11 @@ dtype: object"""
         idx1 = PeriodIndex([], freq='D')
         idx2 = PeriodIndex(['2011-01-01'], freq='D')
         idx3 = PeriodIndex(['2011-01-01', '2011-01-02'], freq='D')
-        idx4 = PeriodIndex(['2011-01-01', '2011-01-02', '2011-01-03'], freq='D')
+        idx4 = PeriodIndex(
+            ['2011-01-01', '2011-01-02', '2011-01-03'], freq='D')
         idx5 = PeriodIndex(['2011', '2012', '2013'], freq='A')
-        idx6 = PeriodIndex(['2011-01-01 09:00', '2012-02-01 10:00', 'NaT'], freq='H')
+        idx6 = PeriodIndex(
+            ['2011-01-01 09:00', '2012-02-01 10:00', 'NaT'], freq='H')
 
         idx7 = pd.period_range('2013Q1', periods=1, freq="Q")
         idx8 = pd.period_range('2013Q1', periods=2, freq="Q")
@@ -1341,32 +1464,44 @@ dtype: object"""
 
         exp1 = """PeriodIndex: 0 entries
 Freq: D"""
+
         exp2 = """PeriodIndex: 1 entries, 2011-01-01 to 2011-01-01
 Freq: D"""
+
         exp3 = """PeriodIndex: 2 entries, 2011-01-01 to 2011-01-02
 Freq: D"""
+
         exp4 = """PeriodIndex: 3 entries, 2011-01-01 to 2011-01-03
 Freq: D"""
+
         exp5 = """PeriodIndex: 3 entries, 2011 to 2013
 Freq: A-DEC"""
+
         exp6 = """PeriodIndex: 3 entries, 2011-01-01 09:00 to NaT
 Freq: H"""
+
         exp7 = """PeriodIndex: 1 entries, 2013Q1 to 2013Q1
 Freq: Q-DEC"""
+
         exp8 = """PeriodIndex: 2 entries, 2013Q1 to 2013Q2
 Freq: Q-DEC"""
+
         exp9 = """PeriodIndex: 3 entries, 2013Q1 to 2013Q3
 Freq: Q-DEC"""
 
-        for idx, expected in zip([idx1, idx2, idx3, idx4, idx5, idx6, idx7, idx8, idx9],
-                                 [exp1, exp2, exp3, exp4, exp5, exp6, exp7, exp8, exp9]):
+        for idx, expected in zip([idx1, idx2, idx3, idx4, idx5,
+                                  idx6, idx7, idx8, idx9],
+                                 [exp1, exp2, exp3, exp4, exp5,
+                                  exp6, exp7, exp8, exp9]):
             result = idx.summary()
             self.assertEqual(result, expected)
 
     def test_resolution(self):
-        for freq, expected in zip(['A', 'Q', 'M', 'D', 'H', 'T', 'S', 'L', 'U'],
+        for freq, expected in zip(['A', 'Q', 'M', 'D', 'H',
+                                   'T', 'S', 'L', 'U'],
                                   ['day', 'day', 'day', 'day',
-                                   'hour', 'minute', 'second', 'millisecond', 'microsecond']):
+                                   'hour', 'minute', 'second',
+                                   'millisecond', 'microsecond']):
 
             idx = pd.period_range(start='2013-04-01', periods=30, freq=freq)
             self.assertEqual(idx.resolution, expected)
@@ -1410,9 +1545,12 @@ Freq: Q-DEC"""
         other7 = pd.period_range('1998-01-01', freq='A', periods=8)
         expected7 = pd.period_range('1998-01-01', freq='A', periods=10)
 
-        for rng, other, expected in [(rng1, other1, expected1), (rng2, other2, expected2),
-                                     (rng3, other3, expected3), (rng4, other4, expected4),
-                                     (rng5, other5, expected5), (rng6, other6, expected6),
+        for rng, other, expected in [(rng1, other1, expected1),
+                                     (rng2, other2, expected2),
+                                     (rng3, other3, expected3), (rng4, other4,
+                                                                 expected4),
+                                     (rng5, other5, expected5), (rng6, other6,
+                                                                 expected6),
                                      (rng7, other7, expected7)]:
 
             # GH9094
@@ -1439,10 +1577,12 @@ Freq: Q-DEC"""
         rng += pd.offsets.YearEnd(5)
         tm.assert_index_equal(rng, expected)
 
-        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1), pd.offsets.Minute(),
-                  np.timedelta64(365, 'D'), timedelta(365), Timedelta(days=365)]:
+        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1),
+                  pd.offsets.Minute(), np.timedelta64(365, 'D'),
+                  timedelta(365), Timedelta(days=365)]:
             msg = 'Input has different freq from PeriodIndex\\(freq=A-DEC\\)'
-            with tm.assertRaisesRegexp(ValueError, 'Input has different freq from Period'):
+            with tm.assertRaisesRegexp(ValueError,
+                                       'Input has different freq from Period'):
                 rng + o
 
         rng = pd.period_range('2014-01', '2016-12', freq='M')
@@ -1452,17 +1592,19 @@ Freq: Q-DEC"""
         rng += pd.offsets.MonthEnd(5)
         tm.assert_index_equal(rng, expected)
 
-        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1), pd.offsets.Minute(),
-                  np.timedelta64(365, 'D'), timedelta(365),  Timedelta(days=365)]:
+        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1),
+                  pd.offsets.Minute(), np.timedelta64(365, 'D'),
+                  timedelta(365), Timedelta(days=365)]:
             rng = pd.period_range('2014-01', '2016-12', freq='M')
             msg = 'Input has different freq from PeriodIndex\\(freq=M\\)'
             with tm.assertRaisesRegexp(ValueError, msg):
                 rng + o
 
         # Tick
-        offsets = [pd.offsets.Day(3), timedelta(days=3), np.timedelta64(3, 'D'),
-                   pd.offsets.Hour(72), timedelta(minutes=60*24*3),
-                   np.timedelta64(72, 'h'), Timedelta('72:00:00')]
+        offsets = [pd.offsets.Day(3), timedelta(days=3),
+                   np.timedelta64(3, 'D'), pd.offsets.Hour(72),
+                   timedelta(minutes=60 * 24 * 3), np.timedelta64(72, 'h'),
+                   Timedelta('72:00:00')]
         for delta in offsets:
             rng = pd.period_range('2014-05-01', '2014-05-15', freq='D')
             result = rng + delta
@@ -1471,27 +1613,32 @@ Freq: Q-DEC"""
             rng += delta
             tm.assert_index_equal(rng, expected)
 
-        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1), pd.offsets.Minute(),
-                  np.timedelta64(4, 'h'), timedelta(hours=23), Timedelta('23:00:00')]:
+        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1),
+                  pd.offsets.Minute(), np.timedelta64(4, 'h'),
+                  timedelta(hours=23), Timedelta('23:00:00')]:
             rng = pd.period_range('2014-05-01', '2014-05-15', freq='D')
             msg = 'Input has different freq from PeriodIndex\\(freq=D\\)'
             with tm.assertRaisesRegexp(ValueError, msg):
                 rng + o
 
-        offsets = [pd.offsets.Hour(2), timedelta(hours=2), np.timedelta64(2, 'h'),
-                   pd.offsets.Minute(120), timedelta(minutes=120),
-                   np.timedelta64(120, 'm'), Timedelta(minutes=120)]
+        offsets = [pd.offsets.Hour(2), timedelta(hours=2),
+                   np.timedelta64(2, 'h'), pd.offsets.Minute(120),
+                   timedelta(minutes=120), np.timedelta64(120, 'm'),
+                   Timedelta(minutes=120)]
         for delta in offsets:
-            rng = pd.period_range('2014-01-01 10:00', '2014-01-05 10:00', freq='H')
+            rng = pd.period_range('2014-01-01 10:00', '2014-01-05 10:00',
+                                  freq='H')
             result = rng + delta
-            expected = pd.period_range('2014-01-01 12:00', '2014-01-05 12:00', freq='H')
+            expected = pd.period_range('2014-01-01 12:00', '2014-01-05 12:00',
+                                       freq='H')
             tm.assert_index_equal(result, expected)
             rng += delta
             tm.assert_index_equal(rng, expected)
 
         for delta in [pd.offsets.YearBegin(2), timedelta(minutes=30),
-                      np.timedelta64(30, 's'),  Timedelta(seconds=30)]:
-            rng = pd.period_range('2014-01-01 10:00', '2014-01-05 10:00', freq='H')
+                      np.timedelta64(30, 's'), Timedelta(seconds=30)]:
+            rng = pd.period_range('2014-01-01 10:00', '2014-01-05 10:00',
+                                  freq='H')
             msg = 'Input has different freq from PeriodIndex\\(freq=H\\)'
             with tm.assertRaisesRegexp(ValueError, msg):
                 result = rng + delta
@@ -1526,7 +1673,8 @@ Freq: Q-DEC"""
 
         rng5 = pd.PeriodIndex(['2000-01-01 09:01', '2000-01-01 09:03',
                                '2000-01-01 09:05'], freq='T')
-        other5 = pd.PeriodIndex(['2000-01-01 09:01', '2000-01-01 09:05'], freq='T')
+        other5 = pd.PeriodIndex(
+            ['2000-01-01 09:01', '2000-01-01 09:05'], freq='T')
         expected5 = pd.PeriodIndex(['2000-01-01 09:03'], freq='T')
 
         rng6 = pd.period_range('2000-01-01', freq='M', periods=7)
@@ -1537,10 +1685,13 @@ Freq: Q-DEC"""
         other7 = pd.period_range('1998-01-01', freq='A', periods=8)
         expected7 = pd.period_range('2006-01-01', freq='A', periods=2)
 
-        for rng, other, expected in [(rng1, other1, expected1), (rng2, other2, expected2),
-                                     (rng3, other3, expected3), (rng4, other4, expected4),
-                                     (rng5, other5, expected5), (rng6, other6, expected6),
-                                     (rng7, other7, expected7),]:
+        for rng, other, expected in [(rng1, other1, expected1),
+                                     (rng2, other2, expected2),
+                                     (rng3, other3, expected3),
+                                     (rng4, other4, expected4),
+                                     (rng5, other5, expected5),
+                                     (rng6, other6, expected6),
+                                     (rng7, other7, expected7), ]:
             result_union = rng.difference(other)
             tm.assert_index_equal(result_union, expected)
 
@@ -1553,8 +1704,9 @@ Freq: Q-DEC"""
         rng -= pd.offsets.YearEnd(5)
         tm.assert_index_equal(rng, expected)
 
-        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1), pd.offsets.Minute(),
-                  np.timedelta64(365, 'D'), timedelta(365)]:
+        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1),
+                  pd.offsets.Minute(), np.timedelta64(365, 'D'),
+                  timedelta(365)]:
             rng = pd.period_range('2014', '2024', freq='A')
             msg = 'Input has different freq from PeriodIndex\\(freq=A-DEC\\)'
             with tm.assertRaisesRegexp(ValueError, msg):
@@ -1567,16 +1719,18 @@ Freq: Q-DEC"""
         rng -= pd.offsets.MonthEnd(5)
         tm.assert_index_equal(rng, expected)
 
-        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1), pd.offsets.Minute(),
-                  np.timedelta64(365, 'D'), timedelta(365)]:
+        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1),
+                  pd.offsets.Minute(), np.timedelta64(365, 'D'),
+                  timedelta(365)]:
             rng = pd.period_range('2014-01', '2016-12', freq='M')
             msg = 'Input has different freq from PeriodIndex\\(freq=M\\)'
             with tm.assertRaisesRegexp(ValueError, msg):
                 rng - o
 
         # Tick
-        offsets = [pd.offsets.Day(3), timedelta(days=3), np.timedelta64(3, 'D'),
-                   pd.offsets.Hour(72), timedelta(minutes=60*24*3), np.timedelta64(72, 'h')]
+        offsets = [pd.offsets.Day(3), timedelta(days=3),
+                   np.timedelta64(3, 'D'), pd.offsets.Hour(72),
+                   timedelta(minutes=60 * 24 * 3), np.timedelta64(72, 'h')]
         for delta in offsets:
             rng = pd.period_range('2014-05-01', '2014-05-15', freq='D')
             result = rng - delta
@@ -1585,25 +1739,31 @@ Freq: Q-DEC"""
             rng -= delta
             tm.assert_index_equal(rng, expected)
 
-        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1), pd.offsets.Minute(),
-                  np.timedelta64(4, 'h'), timedelta(hours=23)]:
+        for o in [pd.offsets.YearBegin(2), pd.offsets.MonthBegin(1),
+                  pd.offsets.Minute(), np.timedelta64(4, 'h'),
+                  timedelta(hours=23)]:
             rng = pd.period_range('2014-05-01', '2014-05-15', freq='D')
             msg = 'Input has different freq from PeriodIndex\\(freq=D\\)'
             with tm.assertRaisesRegexp(ValueError, msg):
                 rng - o
 
-        offsets = [pd.offsets.Hour(2), timedelta(hours=2), np.timedelta64(2, 'h'),
-                   pd.offsets.Minute(120), timedelta(minutes=120), np.timedelta64(120, 'm')]
+        offsets = [pd.offsets.Hour(2), timedelta(hours=2),
+                   np.timedelta64(2, 'h'), pd.offsets.Minute(120),
+                   timedelta(minutes=120), np.timedelta64(120, 'm')]
         for delta in offsets:
-            rng = pd.period_range('2014-01-01 10:00', '2014-01-05 10:00', freq='H')
+            rng = pd.period_range('2014-01-01 10:00', '2014-01-05 10:00',
+                                  freq='H')
             result = rng - delta
-            expected = pd.period_range('2014-01-01 08:00', '2014-01-05 08:00', freq='H')
+            expected = pd.period_range('2014-01-01 08:00', '2014-01-05 08:00',
+                                       freq='H')
             tm.assert_index_equal(result, expected)
             rng -= delta
             tm.assert_index_equal(rng, expected)
 
-        for delta in [pd.offsets.YearBegin(2), timedelta(minutes=30), np.timedelta64(30, 's')]:
-            rng = pd.period_range('2014-01-01 10:00', '2014-01-05 10:00', freq='H')
+        for delta in [pd.offsets.YearBegin(2), timedelta(minutes=30),
+                      np.timedelta64(30, 's')]:
+            rng = pd.period_range('2014-01-01 10:00', '2014-01-05 10:00',
+                                  freq='H')
             msg = 'Input has different freq from PeriodIndex\\(freq=H\\)'
             with tm.assertRaisesRegexp(ValueError, msg):
                 result = rng + delta
@@ -1622,11 +1782,14 @@ Freq: Q-DEC"""
         # GH 7735
         idx = pd.period_range('2011-01-01 09:00', freq='H', periods=10)
         # create repeated values, 'n'th element is repeated by n+1 times
-        idx = PeriodIndex(np.repeat(idx.values, range(1, len(idx) + 1)), freq='H')
-
-        exp_idx = PeriodIndex(['2011-01-01 18:00', '2011-01-01 17:00', '2011-01-01 16:00',
-                               '2011-01-01 15:00', '2011-01-01 14:00', '2011-01-01 13:00',
-                               '2011-01-01 12:00', '2011-01-01 11:00', '2011-01-01 10:00',
+        idx = PeriodIndex(
+            np.repeat(idx.values, range(1, len(idx) + 1)), freq='H')
+
+        exp_idx = PeriodIndex(['2011-01-01 18:00', '2011-01-01 17:00',
+                               '2011-01-01 16:00', '2011-01-01 15:00',
+                               '2011-01-01 14:00', '2011-01-01 13:00',
+                               '2011-01-01 12:00', '2011-01-01 11:00',
+                               '2011-01-01 10:00',
                                '2011-01-01 09:00'], freq='H')
         expected = Series(range(10, 0, -1), index=exp_idx, dtype='int64')
         tm.assert_series_equal(idx.value_counts(), expected)
@@ -1634,33 +1797,35 @@ Freq: Q-DEC"""
         expected = pd.period_range('2011-01-01 09:00', freq='H', periods=10)
         tm.assert_index_equal(idx.unique(), expected)
 
-        idx = PeriodIndex(['2013-01-01 09:00', '2013-01-01 09:00', '2013-01-01 09:00',
-                           '2013-01-01 08:00', '2013-01-01 08:00', pd.NaT], freq='H')
+        idx = PeriodIndex(['2013-01-01 09:00', '2013-01-01 09:00',
+                           '2013-01-01 09:00', '2013-01-01 08:00',
+                           '2013-01-01 08:00', pd.NaT], freq='H')
 
-        exp_idx = PeriodIndex(['2013-01-01 09:00', '2013-01-01 08:00'], freq='H')
+        exp_idx = PeriodIndex(
+            ['2013-01-01 09:00', '2013-01-01 08:00'], freq='H')
         expected = Series([3, 2], index=exp_idx)
         tm.assert_series_equal(idx.value_counts(), expected)
 
-        exp_idx = PeriodIndex(['2013-01-01 09:00', '2013-01-01 08:00', pd.NaT], freq='H')
+        exp_idx = PeriodIndex(
+            ['2013-01-01 09:00', '2013-01-01 08:00', pd.NaT], freq='H')
         expected = Series([3, 2, 1], index=exp_idx)
         tm.assert_series_equal(idx.value_counts(dropna=False), expected)
 
         tm.assert_index_equal(idx.unique(), exp_idx)
 
     def test_drop_duplicates_metadata(self):
-        #GH 10115
+        # GH 10115
         idx = pd.period_range('2011-01-01', '2011-01-31', freq='D', name='idx')
         result = idx.drop_duplicates()
         self.assert_index_equal(idx, result)
         self.assertEqual(idx.freq, result.freq)
 
-        idx_dup = idx.append(idx) # freq will not be reset
+        idx_dup = idx.append(idx)  # freq will not be reset
         result = idx_dup.drop_duplicates()
         self.assert_index_equal(idx, result)
         self.assertEqual(idx.freq, result.freq)
 
     def test_order_compat(self):
-
         def _check_freq(index, expected_index):
             if isinstance(index, PeriodIndex):
                 self.assertEqual(index.freq, expected_index.freq)
@@ -1682,13 +1847,16 @@ Freq: Q-DEC"""
             self.assert_numpy_array_equal(indexer, np.array([0, 1, 2]))
             _check_freq(ordered, idx)
 
-            ordered, indexer = idx.sort_values(return_indexer=True, ascending=False)
+            ordered, indexer = idx.sort_values(return_indexer=True,
+                                               ascending=False)
             self.assert_index_equal(ordered, idx[::-1])
             self.assert_numpy_array_equal(indexer, np.array([2, 1, 0]))
             _check_freq(ordered, idx[::-1])
 
-        pidx = PeriodIndex(['2011', '2013', '2015', '2012', '2011'], name='pidx', freq='A')
-        pexpected = PeriodIndex(['2011', '2011', '2012', '2013', '2015'], name='pidx', freq='A')
+        pidx = PeriodIndex(['2011', '2013', '2015', '2012',
+                            '2011'], name='pidx', freq='A')
+        pexpected = PeriodIndex(
+            ['2011', '2011', '2012', '2013', '2015'], name='pidx', freq='A')
         # for compatibility check
         iidx = Index([2011, 2013, 2015, 2012, 2011], name='idx')
         iexpected = Index([2011, 2011, 2012, 2013, 2015], name='idx')
@@ -1706,20 +1874,24 @@ Freq: Q-DEC"""
             self.assert_numpy_array_equal(indexer, np.array([0, 4, 3, 1, 2]))
             _check_freq(ordered, idx)
 
-            ordered, indexer = idx.sort_values(return_indexer=True, ascending=False)
+            ordered, indexer = idx.sort_values(return_indexer=True,
+                                               ascending=False)
             self.assert_index_equal(ordered, expected[::-1])
             self.assert_numpy_array_equal(indexer, np.array([2, 1, 3, 4, 0]))
             _check_freq(ordered, idx)
 
-        pidx = PeriodIndex(['2011', '2013', 'NaT', '2011'], name='pidx', freq='D')
+        pidx = PeriodIndex(['2011', '2013', 'NaT', '2011'], name='pidx',
+                           freq='D')
 
         result = pidx.sort_values()
-        expected = PeriodIndex(['NaT', '2011', '2011', '2013'], name='pidx', freq='D')
+        expected = PeriodIndex(
+            ['NaT', '2011', '2011', '2013'], name='pidx', freq='D')
         self.assert_index_equal(result, expected)
         self.assertEqual(result.freq, 'D')
 
         result = pidx.sort_values(ascending=False)
-        expected = PeriodIndex(['2013', '2011', '2011', 'NaT'], name='pidx', freq='D')
+        expected = PeriodIndex(
+            ['2013', '2011', '2011', 'NaT'], name='pidx', freq='D')
         self.assert_index_equal(result, expected)
         self.assertEqual(result.freq, 'D')
 
@@ -1744,7 +1916,8 @@ Freq: Q-DEC"""
             self.assertEqual(ordered.freq, idx.freq)
             self.assertEqual(ordered.freq, freq)
 
-            ordered, indexer = idx.sort_values(return_indexer=True, ascending=False)
+            ordered, indexer = idx.sort_values(return_indexer=True,
+                                               ascending=False)
             expected = idx[::-1]
             self.assert_index_equal(ordered, expected)
             self.assert_numpy_array_equal(indexer, np.array([2, 1, 0]))
@@ -1756,17 +1929,18 @@ Freq: Q-DEC"""
         exp1 = PeriodIndex(['2011-01-01', '2011-01-01', '2011-01-02',
                             '2011-01-03', '2011-01-05'], freq='D', name='idx1')
 
-        idx2 = PeriodIndex(['2011-01-01', '2011-01-03', '2011-01-05',
-                            '2011-01-02', '2011-01-01'],
-                           freq='D',  name='idx2')
-        exp2 = PeriodIndex(['2011-01-01', '2011-01-01', '2011-01-02',
-                            '2011-01-03', '2011-01-05'],
-                           freq='D', name='idx2')
+        # TODO(wesm): unused?
+        # idx2 = PeriodIndex(['2011-01-01', '2011-01-03', '2011-01-05',
+        #                     '2011-01-02', '2011-01-01'],
+        #                    freq='D',  name='idx2')
+        # exp2 = PeriodIndex(['2011-01-01', '2011-01-01', '2011-01-02',
+        #                     '2011-01-03', '2011-01-05'],
+        #                    freq='D', name='idx2')
 
-        idx3 = PeriodIndex([pd.NaT, '2011-01-03', '2011-01-05',
-                            '2011-01-02', pd.NaT], freq='D', name='idx3')
-        exp3 = PeriodIndex([pd.NaT, pd.NaT, '2011-01-02', '2011-01-03',
-                            '2011-01-05'], freq='D', name='idx3')
+        # idx3 = PeriodIndex([pd.NaT, '2011-01-03', '2011-01-05',
+        #                     '2011-01-02', pd.NaT], freq='D', name='idx3')
+        # exp3 = PeriodIndex([pd.NaT, pd.NaT, '2011-01-02', '2011-01-03',
+        #                     '2011-01-05'], freq='D', name='idx3')
 
         for idx, expected in [(idx1, exp1), (idx1, exp1), (idx1, exp1)]:
             ordered = idx.sort_values()
@@ -1782,13 +1956,15 @@ Freq: Q-DEC"""
             self.assert_numpy_array_equal(indexer, np.array([0, 4, 3, 1, 2]))
             self.assertEqual(ordered.freq, 'D')
 
-            ordered, indexer = idx.sort_values(return_indexer=True, ascending=False)
+            ordered, indexer = idx.sort_values(return_indexer=True,
+                                               ascending=False)
             self.assert_index_equal(ordered, expected[::-1])
             self.assert_numpy_array_equal(indexer, np.array([2, 1, 3, 4, 0]))
             self.assertEqual(ordered.freq, 'D')
 
     def test_getitem(self):
-        idx1 = pd.period_range('2011-01-01', '2011-01-31', freq='D', name='idx')
+        idx1 = pd.period_range('2011-01-01', '2011-01-31', freq='D',
+                               name='idx')
 
         for idx in [idx1]:
             result = idx[0]
@@ -1805,7 +1981,8 @@ Freq: Q-DEC"""
             self.assertEqual(result.freq, 'D')
 
             result = idx[0:10:2]
-            expected = pd.PeriodIndex(['2011-01-01', '2011-01-03', '2011-01-05',
+            expected = pd.PeriodIndex(['2011-01-01', '2011-01-03',
+                                       '2011-01-05',
                                        '2011-01-07', '2011-01-09'],
                                       freq='D', name='idx')
             self.assert_index_equal(result, expected)
@@ -1813,7 +1990,8 @@ Freq: Q-DEC"""
             self.assertEqual(result.freq, 'D')
 
             result = idx[-20:-5:3]
-            expected = pd.PeriodIndex(['2011-01-12', '2011-01-15', '2011-01-18',
+            expected = pd.PeriodIndex(['2011-01-12', '2011-01-15',
+                                       '2011-01-18',
                                        '2011-01-21', '2011-01-24'],
                                       freq='D', name='idx')
             self.assert_index_equal(result, expected)
@@ -1822,15 +2000,16 @@ Freq: Q-DEC"""
 
             result = idx[4::-1]
             expected = PeriodIndex(['2011-01-05', '2011-01-04', '2011-01-03',
-                                   '2011-01-02', '2011-01-01'],
+                                    '2011-01-02', '2011-01-01'],
                                    freq='D', name='idx')
             self.assert_index_equal(result, expected)
             self.assertEqual(result.freq, expected.freq)
             self.assertEqual(result.freq, 'D')
 
     def test_take(self):
-        #GH 10295
-        idx1 = pd.period_range('2011-01-01', '2011-01-31', freq='D', name='idx')
+        # GH 10295
+        idx1 = pd.period_range('2011-01-01', '2011-01-31', freq='D',
+                               name='idx')
 
         for idx in [idx1]:
             result = idx.take([0])
@@ -1847,14 +2026,15 @@ Freq: Q-DEC"""
             self.assertEqual(result.freq, expected.freq)
 
             result = idx.take([0, 2, 4])
-            expected = pd.PeriodIndex(['2011-01-01', '2011-01-03', '2011-01-05'],
-                                      freq='D', name='idx')
+            expected = pd.PeriodIndex(['2011-01-01', '2011-01-03',
+                                       '2011-01-05'], freq='D', name='idx')
             self.assert_index_equal(result, expected)
             self.assertEqual(result.freq, expected.freq)
             self.assertEqual(result.freq, 'D')
 
             result = idx.take([7, 4, 1])
-            expected = pd.PeriodIndex(['2011-01-08', '2011-01-05', '2011-01-02'],
+            expected = pd.PeriodIndex(['2011-01-08', '2011-01-05',
+                                       '2011-01-02'],
                                       freq='D', name='idx')
             self.assert_index_equal(result, expected)
             self.assertEqual(result.freq, expected.freq)
@@ -1873,11 +2053,3 @@ Freq: Q-DEC"""
             self.assert_index_equal(result, expected)
             self.assertEqual(result.freq, expected.freq)
             self.assertEqual(result.freq, 'D')
-
-
-if __name__ == '__main__':
-    import nose
-
-    nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
-                   # '--with-coverage', '--cover-package=pandas.core'],
-                   exit=False)
diff --git a/pandas/tseries/tests/test_converter.py b/pandas/tseries/tests/test_converter.py
index 95c0b4466..1fe35838e 100644
--- a/pandas/tseries/tests/test_converter.py
+++ b/pandas/tseries/tests/test_converter.py
@@ -1,6 +1,4 @@
-from datetime import datetime, time, timedelta, date
-import sys
-import os
+from datetime import datetime, date
 
 import nose
 
@@ -18,11 +16,10 @@ except ImportError:
 
 
 def test_timtetonum_accepts_unicode():
-    assert(converter.time2num("00:01") == converter.time2num(u("00:01")))
+    assert (converter.time2num("00:01") == converter.time2num(u("00:01")))
 
 
 class TestDateTimeConverter(tm.TestCase):
-
     def setUp(self):
         self.dtc = converter.DatetimeConverter()
         self.tc = converter.TimeFormatter(None)
@@ -30,7 +27,7 @@ class TestDateTimeConverter(tm.TestCase):
     def test_convert_accepts_unicode(self):
         r1 = self.dtc.convert("12:22", None, None)
         r2 = self.dtc.convert(u("12:22"), None, None)
-        assert(r1 == r2), "DatetimeConverter.convert should accept unicode"
+        assert (r1 == r2), "DatetimeConverter.convert should accept unicode"
 
     def test_conversion(self):
         rs = self.dtc.convert(['2012-1-1'], None, None)[0]
@@ -56,21 +53,25 @@ class TestDateTimeConverter(tm.TestCase):
         rs = self.dtc.convert(np.datetime64('2012-01-01'), None, None)
         self.assertEqual(rs, xp)
 
-        rs = self.dtc.convert(np.datetime64('2012-01-01 00:00:00+00:00'), None, None)
+        rs = self.dtc.convert(np.datetime64(
+            '2012-01-01 00:00:00+00:00'), None, None)
         self.assertEqual(rs, xp)
 
-        rs = self.dtc.convert(np.array([np.datetime64('2012-01-01 00:00:00+00:00'),
-                                        np.datetime64('2012-01-02 00:00:00+00:00')]), None, None)
+        rs = self.dtc.convert(np.array([
+            np.datetime64('2012-01-01 00:00:00+00:00'),
+            np.datetime64('2012-01-02 00:00:00+00:00')]), None, None)
         self.assertEqual(rs[0], xp)
 
     def test_conversion_float(self):
         decimals = 9
 
-        rs = self.dtc.convert(Timestamp('2012-1-1 01:02:03', tz='UTC'), None, None)
+        rs = self.dtc.convert(
+            Timestamp('2012-1-1 01:02:03', tz='UTC'), None, None)
         xp = converter.dates.date2num(Timestamp('2012-1-1 01:02:03', tz='UTC'))
         np_assert_almost_equal(rs, xp, decimals)
 
-        rs = self.dtc.convert(Timestamp('2012-1-1 09:02:03', tz='Asia/Hong_Kong'), None, None)
+        rs = self.dtc.convert(
+            Timestamp('2012-1-1 09:02:03', tz='Asia/Hong_Kong'), None, None)
         np_assert_almost_equal(rs, xp, decimals)
 
         rs = self.dtc.convert(datetime(2012, 1, 1, 1, 2, 3), None, None)
@@ -83,7 +84,7 @@ class TestDateTimeConverter(tm.TestCase):
         decimals = 9
 
         for freq in ('B', 'L', 'S'):
-            dateindex = tm.makeDateIndex(k = 10, freq = freq)
+            dateindex = tm.makeDateIndex(k=10, freq=freq)
             rs = self.dtc.convert(dateindex, None, None)
             xp = converter.dates.date2num(dateindex._mpl_repr())
             np_assert_almost_equal(rs, xp, decimals)
@@ -93,10 +94,11 @@ class TestDateTimeConverter(tm.TestCase):
             val1 = self.dtc.convert(ts1, None, None)
             val2 = self.dtc.convert(ts2, None, None)
             if not val1 < val2:
-                raise AssertionError('{0} is not less than {1}.'.format(val1, val2))
+                raise AssertionError('{0} is not less than {1}.'.format(val1,
+                                                                        val2))
 
-        # Matplotlib's time representation using floats cannot distinguish intervals smaller
-        # than ~10 microsecond in the common range of years.
+        # Matplotlib's time representation using floats cannot distinguish
+        # intervals smaller than ~10 microsecond in the common range of years.
         ts = Timestamp('2012-1-1')
         _assert_less(ts, ts + Second())
         _assert_less(ts, ts + Milli())
@@ -104,7 +106,6 @@ class TestDateTimeConverter(tm.TestCase):
 
 
 class TestPeriodConverter(tm.TestCase):
-
     def setUp(self):
         self.pc = converter.PeriodConverter()
 
@@ -117,7 +118,8 @@ class TestPeriodConverter(tm.TestCase):
     def test_convert_accepts_unicode(self):
         r1 = self.pc.convert("2012-1-1", None, self.axis)
         r2 = self.pc.convert(u("2012-1-1"), None, self.axis)
-        self.assert_equal(r1, r2, "PeriodConverter.convert should accept unicode")
+        self.assert_equal(r1, r2,
+                          "PeriodConverter.convert should accept unicode")
 
     def test_conversion(self):
         rs = self.pc.convert(['2012-1-1'], None, self.axis)[0]
@@ -143,11 +145,13 @@ class TestPeriodConverter(tm.TestCase):
         # rs = self.pc.convert(np.datetime64('2012-01-01'), None, self.axis)
         # self.assertEqual(rs, xp)
         #
-        # rs = self.pc.convert(np.datetime64('2012-01-01 00:00:00+00:00'), None, self.axis)
+        # rs = self.pc.convert(np.datetime64('2012-01-01 00:00:00+00:00'),
+        #                      None, self.axis)
         # self.assertEqual(rs, xp)
         #
-        # rs = self.pc.convert(np.array([np.datetime64('2012-01-01 00:00:00+00:00'),
-        #                                 np.datetime64('2012-01-02 00:00:00+00:00')]), None, self.axis)
+        # rs = self.pc.convert(np.array([
+        #     np.datetime64('2012-01-01 00:00:00+00:00'),
+        #     np.datetime64('2012-01-02 00:00:00+00:00')]), None, self.axis)
         # self.assertEqual(rs[0], xp)
 
     def test_integer_passthrough(self):
diff --git a/pandas/tseries/tests/test_daterange.py b/pandas/tseries/tests/test_daterange.py
index 00336615a..5b0d9b593 100644
--- a/pandas/tseries/tests/test_daterange.py
+++ b/pandas/tseries/tests/test_daterange.py
@@ -17,7 +17,7 @@ import pandas.util.testing as tm
 
 def eq_gen_range(kwargs, expected):
     rng = generate_range(**kwargs)
-    assert(np.array_equal(list(rng), expected))
+    assert (np.array_equal(list(rng), expected))
 
 
 START, END = datetime(2009, 1, 1), datetime(2010, 1, 1)
@@ -73,41 +73,44 @@ class TestGenRangeGeneration(tm.TestCase):
 
 
 class TestDateRange(tm.TestCase):
-
     def setUp(self):
         self.rng = bdate_range(START, END)
 
     def test_constructor(self):
-        rng = bdate_range(START, END, freq=datetools.bday)
-        rng = bdate_range(START, periods=20, freq=datetools.bday)
-        rng = bdate_range(end=START, periods=20, freq=datetools.bday)
+        bdate_range(START, END, freq=datetools.bday)
+        bdate_range(START, periods=20, freq=datetools.bday)
+        bdate_range(end=START, periods=20, freq=datetools.bday)
         self.assertRaises(ValueError, date_range, '2011-1-1', '2012-1-1', 'B')
         self.assertRaises(ValueError, bdate_range, '2011-1-1', '2012-1-1', 'B')
 
     def test_naive_aware_conflicts(self):
         naive = bdate_range(START, END, freq=datetools.bday, tz=None)
-        aware = bdate_range(START, END, freq=datetools.bday, tz="Asia/Hong_Kong")
+        aware = bdate_range(START, END, freq=datetools.bday,
+                            tz="Asia/Hong_Kong")
         assertRaisesRegexp(TypeError, "tz-naive.*tz-aware", naive.join, aware)
         assertRaisesRegexp(TypeError, "tz-naive.*tz-aware", aware.join, naive)
 
     def test_cached_range(self):
-        rng = DatetimeIndex._cached_range(START, END,
-                                          offset=datetools.bday)
-        rng = DatetimeIndex._cached_range(START, periods=20,
-                                          offset=datetools.bday)
-        rng = DatetimeIndex._cached_range(end=START, periods=20,
-                                          offset=datetools.bday)
+        DatetimeIndex._cached_range(START, END, offset=datetools.bday)
+        DatetimeIndex._cached_range(START, periods=20,
+                                    offset=datetools.bday)
+        DatetimeIndex._cached_range(end=START, periods=20,
+                                    offset=datetools.bday)
 
-        assertRaisesRegexp(TypeError, "offset", DatetimeIndex._cached_range, START, END)
+        assertRaisesRegexp(TypeError, "offset", DatetimeIndex._cached_range,
+                           START, END)
 
-        assertRaisesRegexp(TypeError, "specify period", DatetimeIndex._cached_range, START,
-                          offset=datetools.bday)
+        assertRaisesRegexp(TypeError, "specify period",
+                           DatetimeIndex._cached_range, START,
+                           offset=datetools.bday)
 
-        assertRaisesRegexp(TypeError, "specify period", DatetimeIndex._cached_range, end=END,
-                          offset=datetools.bday)
+        assertRaisesRegexp(TypeError, "specify period",
+                           DatetimeIndex._cached_range, end=END,
+                           offset=datetools.bday)
 
-        assertRaisesRegexp(TypeError, "start or end", DatetimeIndex._cached_range, periods=20,
-                          offset=datetools.bday)
+        assertRaisesRegexp(TypeError, "start or end",
+                           DatetimeIndex._cached_range, periods=20,
+                           offset=datetools.bday)
 
     def test_cached_range_bug(self):
         rng = date_range('2010-09-01 05:00:00', periods=50,
@@ -124,7 +127,8 @@ class TestDateRange(tm.TestCase):
 
     def test_timezone_comparaison_assert(self):
         start = Timestamp('20130220 10:00', tz='US/Eastern')
-        self.assertRaises(AssertionError, date_range, start, periods=2, tz='Europe/Berlin')
+        self.assertRaises(AssertionError, date_range, start, periods=2,
+                          tz='Europe/Berlin')
 
     def test_comparison(self):
         d = self.rng[10]
@@ -399,17 +403,18 @@ class TestDateRange(tm.TestCase):
             dr = date_range(start, end, freq='D')
             self.assertEqual(dr[0], start)
             self.assertEqual(dr[-1], end)
-            self.assertEqual(np.all(dr.hour==0), True)
+            self.assertEqual(np.all(dr.hour == 0), True)
 
             dr = date_range(start, end, freq='D', tz='US/Eastern')
             self.assertEqual(dr[0], start)
             self.assertEqual(dr[-1], end)
-            self.assertEqual(np.all(dr.hour==0), True)
+            self.assertEqual(np.all(dr.hour == 0), True)
 
-            dr = date_range(start.replace(tzinfo=None), end.replace(tzinfo=None), freq='D', tz='US/Eastern')
+            dr = date_range(start.replace(tzinfo=None), end.replace(
+                tzinfo=None), freq='D', tz='US/Eastern')
             self.assertEqual(dr[0], start)
             self.assertEqual(dr[-1], end)
-            self.assertEqual(np.all(dr.hour==0), True)
+            self.assertEqual(np.all(dr.hour == 0), True)
 
     def test_range_tz_dateutil(self):
         # GH 2906
@@ -447,8 +452,10 @@ class TestDateRange(tm.TestCase):
         late_start = datetime(2011, 3, 1)
         late_end = datetime(2011, 5, 1)
 
-        early_dr = date_range(start=early_start, end=early_end, tz=tz, freq=datetools.monthEnd)
-        late_dr = date_range(start=late_start, end=late_end, tz=tz, freq=datetools.monthEnd)
+        early_dr = date_range(start=early_start, end=early_end, tz=tz,
+                              freq=datetools.monthEnd)
+        late_dr = date_range(start=late_start, end=late_end, tz=tz,
+                             freq=datetools.monthEnd)
 
         early_dr.union(late_dr)
 
@@ -464,8 +471,10 @@ class TestDateRange(tm.TestCase):
         late_start = datetime(2011, 3, 1)
         late_end = datetime(2011, 5, 1)
 
-        early_dr = date_range(start=early_start, end=early_end, tz=tz, freq=datetools.monthEnd)
-        late_dr = date_range(start=late_start, end=late_end, tz=tz, freq=datetools.monthEnd)
+        early_dr = date_range(start=early_start, end=early_end, tz=tz,
+                              freq=datetools.monthEnd)
+        late_dr = date_range(start=late_start, end=late_end, tz=tz,
+                             freq=datetools.monthEnd)
 
         early_dr.union(late_dr)
 
@@ -491,9 +500,12 @@ class TestDateRange(tm.TestCase):
     def test_range_closed_boundary(self):
         # GH 11804
         for closed in ['right', 'left', None]:
-            right_boundary = date_range('2015-09-12', '2015-12-01', freq='QS-MAR', closed=closed)
-            left_boundary = date_range('2015-09-01', '2015-09-12', freq='QS-MAR', closed=closed)
-            both_boundary = date_range('2015-09-01', '2015-12-01', freq='QS-MAR', closed=closed)
+            right_boundary = date_range('2015-09-12', '2015-12-01',
+                                        freq='QS-MAR', closed=closed)
+            left_boundary = date_range('2015-09-01', '2015-09-12',
+                                       freq='QS-MAR', closed=closed)
+            both_boundary = date_range('2015-09-01', '2015-12-01',
+                                       freq='QS-MAR', closed=closed)
             expected_right = expected_left = expected_both = both_boundary
 
             if closed == 'right':
@@ -520,33 +532,36 @@ class TestDateRange(tm.TestCase):
                               freq='345min')
         result_2 = date_range('2005-01-13 10:00', '2005-01-13 16:00',
                               freq='345min')
-        expected_1 = DatetimeIndex(['2005-01-12 10:00:00', '2005-01-12 15:45:00'],
-                                   dtype='datetime64[ns]', freq='345T', tz=None)
-        expected_2 = DatetimeIndex(['2005-01-13 10:00:00', '2005-01-13 15:45:00'],
-                                   dtype='datetime64[ns]', freq='345T', tz=None)
+        expected_1 = DatetimeIndex(['2005-01-12 10:00:00',
+                                    '2005-01-12 15:45:00'],
+                                   dtype='datetime64[ns]', freq='345T',
+                                   tz=None)
+        expected_2 = DatetimeIndex(['2005-01-13 10:00:00',
+                                    '2005-01-13 15:45:00'],
+                                   dtype='datetime64[ns]', freq='345T',
+                                   tz=None)
         self.assertTrue(result_1.equals(expected_1))
         self.assertTrue(result_2.equals(expected_2))
 
-class TestCustomDateRange(tm.TestCase):
 
+class TestCustomDateRange(tm.TestCase):
     def setUp(self):
         tm._skip_if_no_cday()
         self.rng = cdate_range(START, END)
 
     def test_constructor(self):
-        rng = cdate_range(START, END, freq=datetools.cday)
-        rng = cdate_range(START, periods=20, freq=datetools.cday)
-        rng = cdate_range(end=START, periods=20, freq=datetools.cday)
+        cdate_range(START, END, freq=datetools.cday)
+        cdate_range(START, periods=20, freq=datetools.cday)
+        cdate_range(end=START, periods=20, freq=datetools.cday)
         self.assertRaises(ValueError, date_range, '2011-1-1', '2012-1-1', 'C')
         self.assertRaises(ValueError, cdate_range, '2011-1-1', '2012-1-1', 'C')
 
     def test_cached_range(self):
-        rng = DatetimeIndex._cached_range(START, END,
-                                          offset=datetools.cday)
-        rng = DatetimeIndex._cached_range(START, periods=20,
-                                          offset=datetools.cday)
-        rng = DatetimeIndex._cached_range(end=START, periods=20,
-                                          offset=datetools.cday)
+        DatetimeIndex._cached_range(START, END, offset=datetools.cday)
+        DatetimeIndex._cached_range(START, periods=20,
+                                    offset=datetools.cday)
+        DatetimeIndex._cached_range(end=START, periods=20,
+                                    offset=datetools.cday)
 
         self.assertRaises(Exception, DatetimeIndex._cached_range, START, END)
 
@@ -746,8 +761,7 @@ class TestCustomDateRange(tm.TestCase):
         self.assertTrue(xp.equals(rng))
 
     def test_cdaterange_holidays(self):
-        rng = cdate_range('2013-05-01', periods=3,
-                          holidays=['2013-05-01'])
+        rng = cdate_range('2013-05-01', periods=3, holidays=['2013-05-01'])
         xp = DatetimeIndex(['2013-05-02', '2013-05-03', '2013-05-06'])
         self.assertTrue(xp.equals(rng))
 
diff --git a/pandas/tseries/tests/test_frequencies.py b/pandas/tseries/tests/test_frequencies.py
index d9bc64136..653d92a61 100644
--- a/pandas/tseries/tests/test_frequencies.py
+++ b/pandas/tseries/tests/test_frequencies.py
@@ -1,13 +1,10 @@
-from datetime import datetime, time, timedelta
+from datetime import datetime, timedelta
 from pandas.compat import range
-import sys
-import os
-
-import nose
 
 import numpy as np
 
-from pandas import Index, DatetimeIndex, Timestamp, Series, date_range, period_range
+from pandas import (Index, DatetimeIndex, Timestamp, Series,
+                    date_range, period_range)
 
 import pandas.tseries.frequencies as frequencies
 from pandas.tseries.tools import to_datetime
@@ -20,39 +17,40 @@ from pandas.compat import is_platform_windows
 import pandas.util.testing as tm
 from pandas import Timedelta
 
+
 def test_to_offset_multiple():
     freqstr = '2h30min'
     freqstr2 = '2h 30min'
 
     result = frequencies.to_offset(freqstr)
-    assert(result == frequencies.to_offset(freqstr2))
+    assert (result == frequencies.to_offset(freqstr2))
     expected = offsets.Minute(150)
-    assert(result == expected)
+    assert (result == expected)
 
     freqstr = '2h30min15s'
     result = frequencies.to_offset(freqstr)
     expected = offsets.Second(150 * 60 + 15)
-    assert(result == expected)
+    assert (result == expected)
 
     freqstr = '2h 60min'
     result = frequencies.to_offset(freqstr)
     expected = offsets.Hour(3)
-    assert(result == expected)
+    assert (result == expected)
 
     freqstr = '15l500u'
     result = frequencies.to_offset(freqstr)
     expected = offsets.Micro(15500)
-    assert(result == expected)
+    assert (result == expected)
 
     freqstr = '10s75L'
     result = frequencies.to_offset(freqstr)
     expected = offsets.Milli(10075)
-    assert(result == expected)
+    assert (result == expected)
 
     freqstr = '2800N'
     result = frequencies.to_offset(freqstr)
     expected = offsets.Nano(2800)
-    assert(result == expected)
+    assert (result == expected)
 
     # malformed
     try:
@@ -60,27 +58,27 @@ def test_to_offset_multiple():
     except ValueError:
         pass
     else:
-        assert(False)
+        assert (False)
 
 
 def test_to_offset_negative():
     freqstr = '-1S'
     result = frequencies.to_offset(freqstr)
-    assert(result.n == -1)
+    assert (result.n == -1)
 
     freqstr = '-5min10s'
     result = frequencies.to_offset(freqstr)
-    assert(result.n == -310)
+    assert (result.n == -310)
 
 
 def test_to_offset_leading_zero():
     freqstr = '00H 00T 01S'
     result = frequencies.to_offset(freqstr)
-    assert(result.n == 1)
+    assert (result.n == 1)
 
     freqstr = '-00H 03T 14S'
     result = frequencies.to_offset(freqstr)
-    assert(result.n == -194)
+    assert (result.n == -194)
 
 
 def test_to_offset_pd_timedelta():
@@ -88,37 +86,37 @@ def test_to_offset_pd_timedelta():
     td = Timedelta(days=1, seconds=1)
     result = frequencies.to_offset(td)
     expected = offsets.Second(86401)
-    assert(expected==result)
+    assert (expected == result)
 
     td = Timedelta(days=-1, seconds=1)
     result = frequencies.to_offset(td)
     expected = offsets.Second(-86399)
-    assert(expected==result)
+    assert (expected == result)
 
     td = Timedelta(hours=1, minutes=10)
     result = frequencies.to_offset(td)
     expected = offsets.Minute(70)
-    assert(expected==result)
+    assert (expected == result)
 
     td = Timedelta(hours=1, minutes=-10)
     result = frequencies.to_offset(td)
     expected = offsets.Minute(50)
-    assert(expected==result)
+    assert (expected == result)
 
     td = Timedelta(weeks=1)
     result = frequencies.to_offset(td)
     expected = offsets.Day(7)
-    assert(expected==result)
+    assert (expected == result)
 
     td1 = Timedelta(hours=1)
     result1 = frequencies.to_offset(td1)
     result2 = frequencies.to_offset('60min')
-    assert(result1 == result2)
+    assert (result1 == result2)
 
     td = Timedelta(microseconds=1)
     result = frequencies.to_offset(td)
     expected = offsets.Micro(1)
-    assert(expected == result)
+    assert (expected == result)
 
     td = Timedelta(microseconds=0)
     tm.assertRaises(ValueError, lambda: frequencies.to_offset(td))
@@ -127,53 +125,52 @@ def test_to_offset_pd_timedelta():
 def test_anchored_shortcuts():
     result = frequencies.to_offset('W')
     expected = frequencies.to_offset('W-SUN')
-    assert(result == expected)
+    assert (result == expected)
 
     result1 = frequencies.to_offset('Q')
     result2 = frequencies.to_offset('Q-DEC')
     expected = offsets.QuarterEnd(startingMonth=12)
-    assert(result1 == expected)
-    assert(result2 == expected)
+    assert (result1 == expected)
+    assert (result2 == expected)
 
     result1 = frequencies.to_offset('Q-MAY')
     expected = offsets.QuarterEnd(startingMonth=5)
-    assert(result1 == expected)
+    assert (result1 == expected)
 
 
 def test_get_rule_month():
     result = frequencies._get_rule_month('W')
-    assert(result == 'DEC')
+    assert (result == 'DEC')
     result = frequencies._get_rule_month(offsets.Week())
-    assert(result == 'DEC')
+    assert (result == 'DEC')
 
     result = frequencies._get_rule_month('D')
-    assert(result == 'DEC')
+    assert (result == 'DEC')
     result = frequencies._get_rule_month(offsets.Day())
-    assert(result == 'DEC')
+    assert (result == 'DEC')
 
     result = frequencies._get_rule_month('Q')
-    assert(result == 'DEC')
+    assert (result == 'DEC')
     result = frequencies._get_rule_month(offsets.QuarterEnd(startingMonth=12))
     print(result == 'DEC')
 
     result = frequencies._get_rule_month('Q-JAN')
-    assert(result == 'JAN')
+    assert (result == 'JAN')
     result = frequencies._get_rule_month(offsets.QuarterEnd(startingMonth=1))
-    assert(result == 'JAN')
+    assert (result == 'JAN')
 
     result = frequencies._get_rule_month('A-DEC')
-    assert(result == 'DEC')
+    assert (result == 'DEC')
     result = frequencies._get_rule_month(offsets.YearEnd())
-    assert(result == 'DEC')
+    assert (result == 'DEC')
 
     result = frequencies._get_rule_month('A-MAY')
-    assert(result == 'MAY')
+    assert (result == 'MAY')
     result = frequencies._get_rule_month(offsets.YearEnd(month=5))
-    assert(result == 'MAY')
+    assert (result == 'MAY')
 
 
 class TestFrequencyCode(tm.TestCase):
-
     def test_freq_code(self):
         self.assertEqual(frequencies.get_freq('A'), 1000)
         self.assertEqual(frequencies.get_freq('3A'), 1000)
@@ -200,15 +197,19 @@ class TestFrequencyCode(tm.TestCase):
         self.assertEqual(frequencies.get_freq_group('A-JAN'), 1000)
         self.assertEqual(frequencies.get_freq_group('A-MAY'), 1000)
         self.assertEqual(frequencies.get_freq_group(offsets.YearEnd()), 1000)
-        self.assertEqual(frequencies.get_freq_group(offsets.YearEnd(month=1)), 1000)
-        self.assertEqual(frequencies.get_freq_group(offsets.YearEnd(month=5)), 1000)
+        self.assertEqual(frequencies.get_freq_group(
+            offsets.YearEnd(month=1)), 1000)
+        self.assertEqual(frequencies.get_freq_group(
+            offsets.YearEnd(month=5)), 1000)
 
         self.assertEqual(frequencies.get_freq_group('W'), 4000)
         self.assertEqual(frequencies.get_freq_group('W-MON'), 4000)
         self.assertEqual(frequencies.get_freq_group('W-FRI'), 4000)
         self.assertEqual(frequencies.get_freq_group(offsets.Week()), 4000)
-        self.assertEqual(frequencies.get_freq_group(offsets.Week(weekday=1)), 4000)
-        self.assertEqual(frequencies.get_freq_group(offsets.Week(weekday=5)), 4000)
+        self.assertEqual(frequencies.get_freq_group(
+            offsets.Week(weekday=1)), 4000)
+        self.assertEqual(frequencies.get_freq_group(
+            offsets.Week(weekday=5)), 4000)
 
     def test_get_to_timestamp_base(self):
         tsb = frequencies.get_to_timestamp_base
@@ -227,7 +228,6 @@ class TestFrequencyCode(tm.TestCase):
         self.assertEqual(tsb(frequencies.get_freq_code('H')[0]),
                          frequencies.get_freq_code('S')[0])
 
-
     def test_freq_to_reso(self):
         Reso = frequencies.Resolution
 
@@ -297,15 +297,15 @@ class TestFrequencyCode(tm.TestCase):
                          (frequencies.get_freq('W-TUE'), 1))
         self.assertEqual(frequencies.get_freq_code(offsets.Week(3, weekday=0)),
                          (frequencies.get_freq('W-MON'), 3))
-        self.assertEqual(frequencies.get_freq_code(offsets.Week(-2, weekday=4)),
-                         (frequencies.get_freq('W-FRI'), -2))
+        self.assertEqual(
+            frequencies.get_freq_code(offsets.Week(-2, weekday=4)),
+            (frequencies.get_freq('W-FRI'), -2))
 
 
 _dti = DatetimeIndex
 
 
 class TestFrequencyInference(tm.TestCase):
-
     def test_raise_if_period_index(self):
         index = PeriodIndex(start="1/1/1990", periods=20, freq="M")
         self.assertRaises(TypeError, frequencies.infer_freq, index)
@@ -358,12 +358,12 @@ class TestFrequencyInference(tm.TestCase):
                 exp_freq = code
             self.assertEqual(frequencies.infer_freq(index), exp_freq)
 
-        index = _dti([b + base_delta * 7] +
-                     [b + base_delta * j for j in range(3)])
+        index = _dti([b + base_delta * 7] + [b + base_delta * j for j in range(
+            3)])
         self.assertIsNone(frequencies.infer_freq(index))
 
-        index = _dti([b + base_delta * j for j in range(3)] +
-                     [b + base_delta * 7])
+        index = _dti([b + base_delta * j for j in range(3)] + [b + base_delta *
+                                                               7])
 
         self.assertIsNone(frequencies.infer_freq(index))
 
@@ -391,8 +391,9 @@ class TestFrequencyInference(tm.TestCase):
         assert frequencies.infer_freq(index) is None
 
     def test_week_of_month_fake(self):
-        #All of these dates are on same day of week and are 4 or 5 weeks apart
-        index = DatetimeIndex(["2013-08-27","2013-10-01","2013-10-29","2013-11-26"])
+        # All of these dates are on same day of week and are 4 or 5 weeks apart
+        index = DatetimeIndex(["2013-08-27", "2013-10-01", "2013-10-29",
+                               "2013-11-26"])
         assert frequencies.infer_freq(index) != 'WOM-4TUE'
 
     def test_monthly(self):
@@ -433,15 +434,12 @@ class TestFrequencyInference(tm.TestCase):
             self.assertEqual(frequencies.infer_freq(index), gen.freqstr)
         else:
             inf_freq = frequencies.infer_freq(index)
-            self.assertTrue((inf_freq == 'Q-DEC' and
-                             gen.freqstr in ('Q', 'Q-DEC', 'Q-SEP', 'Q-JUN',
-                                             'Q-MAR'))
-                            or
-                            (inf_freq == 'Q-NOV' and
-                             gen.freqstr in ('Q-NOV', 'Q-AUG', 'Q-MAY', 'Q-FEB'))
-                            or
-                            (inf_freq == 'Q-OCT' and
-                             gen.freqstr in ('Q-OCT', 'Q-JUL', 'Q-APR', 'Q-JAN')))
+            self.assertTrue((inf_freq == 'Q-DEC' and gen.freqstr in (
+                'Q', 'Q-DEC', 'Q-SEP', 'Q-JUN', 'Q-MAR')) or (
+                    inf_freq == 'Q-NOV' and gen.freqstr in (
+                        'Q-NOV', 'Q-AUG', 'Q-MAY', 'Q-FEB')) or (
+                            inf_freq == 'Q-OCT' and gen.freqstr in (
+                                'Q-OCT', 'Q-JUL', 'Q-APR', 'Q-JAN')))
 
         gen = date_range(start, periods=5, freq=freq)
         index = _dti(gen.values)
@@ -449,15 +447,12 @@ class TestFrequencyInference(tm.TestCase):
             self.assertEqual(frequencies.infer_freq(index), gen.freqstr)
         else:
             inf_freq = frequencies.infer_freq(index)
-            self.assertTrue((inf_freq == 'Q-DEC' and
-                             gen.freqstr in ('Q', 'Q-DEC', 'Q-SEP', 'Q-JUN',
-                                             'Q-MAR'))
-                            or
-                            (inf_freq == 'Q-NOV' and
-                             gen.freqstr in ('Q-NOV', 'Q-AUG', 'Q-MAY', 'Q-FEB'))
-                            or
-                            (inf_freq == 'Q-OCT' and
-                             gen.freqstr in ('Q-OCT', 'Q-JUL', 'Q-APR', 'Q-JAN')))
+            self.assertTrue((inf_freq == 'Q-DEC' and gen.freqstr in (
+                'Q', 'Q-DEC', 'Q-SEP', 'Q-JUN', 'Q-MAR')) or (
+                    inf_freq == 'Q-NOV' and gen.freqstr in (
+                        'Q-NOV', 'Q-AUG', 'Q-MAY', 'Q-FEB')) or (
+                            inf_freq == 'Q-OCT' and gen.freqstr in (
+                                'Q-OCT', 'Q-JUL', 'Q-APR', 'Q-JAN')))
 
     def test_infer_freq(self):
         rng = period_range('1959Q2', '2009Q3', freq='Q')
@@ -474,13 +469,16 @@ class TestFrequencyInference(tm.TestCase):
 
     def test_infer_freq_tz(self):
 
-        freqs = {'AS-JAN': ['2009-01-01', '2010-01-01', '2011-01-01', '2012-01-01'],
-                 'Q-OCT': ['2009-01-31', '2009-04-30', '2009-07-31', '2009-10-31'],
+        freqs = {'AS-JAN':
+                 ['2009-01-01', '2010-01-01', '2011-01-01', '2012-01-01'],
+                 'Q-OCT':
+                 ['2009-01-31', '2009-04-30', '2009-07-31', '2009-10-31'],
                  'M': ['2010-11-30', '2010-12-31', '2011-01-31', '2011-02-28'],
-                 'W-SAT': ['2010-12-25', '2011-01-01', '2011-01-08', '2011-01-15'],
+                 'W-SAT':
+                 ['2010-12-25', '2011-01-01', '2011-01-08', '2011-01-15'],
                  'D': ['2011-01-01', '2011-01-02', '2011-01-03', '2011-01-04'],
-                 'H': ['2011-12-31 22:00', '2011-12-31 23:00', '2012-01-01 00:00', '2012-01-01 01:00']
-        }
+                 'H': ['2011-12-31 22:00', '2011-12-31 23:00',
+                       '2012-01-01 00:00', '2012-01-01 01:00']}
 
         # GH 7310
         for tz in [None, 'Australia/Sydney', 'Asia/Tokyo', 'Europe/Paris',
@@ -491,49 +489,55 @@ class TestFrequencyInference(tm.TestCase):
 
     def test_infer_freq_tz_transition(self):
         # Tests for #8772
-        date_pairs = [['2013-11-02', '2013-11-5'], #Fall DST
-                      ['2014-03-08', '2014-03-11'], #Spring DST
-                      ['2014-01-01', '2014-01-03']] #Regular Time
-        freqs = ['3H', '10T', '3601S', '3600001L', '3600000001U', '3600000000001N']
+        date_pairs = [['2013-11-02', '2013-11-5'],  # Fall DST
+                      ['2014-03-08', '2014-03-11'],  # Spring DST
+                      ['2014-01-01', '2014-01-03']]  # Regular Time
+        freqs = ['3H', '10T', '3601S', '3600001L', '3600000001U',
+                 '3600000000001N']
 
         for tz in [None, 'Australia/Sydney', 'Asia/Tokyo', 'Europe/Paris',
                    'US/Pacific', 'US/Eastern']:
             for date_pair in date_pairs:
                 for freq in freqs:
-                    idx = date_range(date_pair[0], date_pair[1], freq=freq, tz=tz)
+                    idx = date_range(date_pair[0], date_pair[
+                        1], freq=freq, tz=tz)
                     self.assertEqual(idx.inferred_freq, freq)
 
-        index = date_range("2013-11-03", periods=5, freq="3H").tz_localize("America/Chicago")
+        index = date_range("2013-11-03", periods=5,
+                           freq="3H").tz_localize("America/Chicago")
         self.assertIsNone(index.inferred_freq)
 
     def test_infer_freq_businesshour(self):
         # GH 7905
-        idx = DatetimeIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',
-                             '2014-07-01 12:00', '2014-07-01 13:00', '2014-07-01 14:00'])
+        idx = DatetimeIndex(
+            ['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',
+             '2014-07-01 12:00', '2014-07-01 13:00', '2014-07-01 14:00'])
         # hourly freq in a day must result in 'H'
         self.assertEqual(idx.inferred_freq, 'H')
 
-        idx = DatetimeIndex(['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',
-                             '2014-07-01 12:00', '2014-07-01 13:00', '2014-07-01 14:00',
-                             '2014-07-01 15:00', '2014-07-01 16:00',
-                             '2014-07-02 09:00', '2014-07-02 10:00', '2014-07-02 11:00'])
+        idx = DatetimeIndex(
+            ['2014-07-01 09:00', '2014-07-01 10:00', '2014-07-01 11:00',
+             '2014-07-01 12:00', '2014-07-01 13:00', '2014-07-01 14:00',
+             '2014-07-01 15:00', '2014-07-01 16:00', '2014-07-02 09:00',
+             '2014-07-02 10:00', '2014-07-02 11:00'])
         self.assertEqual(idx.inferred_freq, 'BH')
 
-        idx = DatetimeIndex(['2014-07-04 09:00', '2014-07-04 10:00', '2014-07-04 11:00',
-                             '2014-07-04 12:00', '2014-07-04 13:00', '2014-07-04 14:00',
-                             '2014-07-04 15:00', '2014-07-04 16:00',
-                             '2014-07-07 09:00', '2014-07-07 10:00', '2014-07-07 11:00'])
+        idx = DatetimeIndex(
+            ['2014-07-04 09:00', '2014-07-04 10:00', '2014-07-04 11:00',
+             '2014-07-04 12:00', '2014-07-04 13:00', '2014-07-04 14:00',
+             '2014-07-04 15:00', '2014-07-04 16:00', '2014-07-07 09:00',
+             '2014-07-07 10:00', '2014-07-07 11:00'])
         self.assertEqual(idx.inferred_freq, 'BH')
 
-        idx = DatetimeIndex(['2014-07-04 09:00', '2014-07-04 10:00', '2014-07-04 11:00',
-                             '2014-07-04 12:00', '2014-07-04 13:00', '2014-07-04 14:00',
-                             '2014-07-04 15:00', '2014-07-04 16:00',
-                             '2014-07-07 09:00', '2014-07-07 10:00', '2014-07-07 11:00',
-                             '2014-07-07 12:00', '2014-07-07 13:00', '2014-07-07 14:00',
-                             '2014-07-07 15:00', '2014-07-07 16:00',
-                             '2014-07-08 09:00', '2014-07-08 10:00', '2014-07-08 11:00',
-                             '2014-07-08 12:00', '2014-07-08 13:00', '2014-07-08 14:00',
-                             '2014-07-08 15:00', '2014-07-08 16:00'])
+        idx = DatetimeIndex(
+            ['2014-07-04 09:00', '2014-07-04 10:00', '2014-07-04 11:00',
+             '2014-07-04 12:00', '2014-07-04 13:00', '2014-07-04 14:00',
+             '2014-07-04 15:00', '2014-07-04 16:00', '2014-07-07 09:00',
+             '2014-07-07 10:00', '2014-07-07 11:00', '2014-07-07 12:00',
+             '2014-07-07 13:00', '2014-07-07 14:00', '2014-07-07 15:00',
+             '2014-07-07 16:00', '2014-07-08 09:00', '2014-07-08 10:00',
+             '2014-07-08 11:00', '2014-07-08 12:00', '2014-07-08 13:00',
+             '2014-07-08 14:00', '2014-07-08 15:00', '2014-07-08 16:00'])
         self.assertEqual(idx.inferred_freq, 'BH')
 
     def test_not_monotonic(self):
@@ -541,7 +545,7 @@ class TestFrequencyInference(tm.TestCase):
         rng = rng[::-1]
         self.assertEqual(rng.inferred_freq, '-1A-JAN')
 
-    def test_non_datetimeindex(self):
+    def test_non_datetimeindex2(self):
         rng = _dti(['1/31/2000', '1/31/2001', '1/31/2002'])
 
         vals = rng.to_pydatetime()
@@ -552,24 +556,25 @@ class TestFrequencyInference(tm.TestCase):
     def test_invalid_index_types(self):
 
         # test all index types
-        for i in [ tm.makeIntIndex(10),
-                   tm.makeFloatIndex(10),
-                   tm.makePeriodIndex(10) ]:
-            self.assertRaises(TypeError, lambda : frequencies.infer_freq(i))
+        for i in [tm.makeIntIndex(10), tm.makeFloatIndex(10),
+                  tm.makePeriodIndex(10)]:
+            self.assertRaises(TypeError, lambda: frequencies.infer_freq(i))
 
         # GH 10822
         # odd error message on conversions to datetime for unicode
         if not is_platform_windows():
-            for i in [ tm.makeStringIndex(10),
-                       tm.makeUnicodeIndex(10) ]:
-                self.assertRaises(ValueError, lambda : frequencies.infer_freq(i))
+            for i in [tm.makeStringIndex(10), tm.makeUnicodeIndex(10)]:
+                self.assertRaises(ValueError,
+                                  lambda: frequencies.infer_freq(i))
 
     def test_string_datetimelike_compat(self):
 
         # GH 6463
-        expected = frequencies.infer_freq(['2004-01', '2004-02', '2004-03', '2004-04'])
-        result = frequencies.infer_freq(Index(['2004-01', '2004-02', '2004-03', '2004-04']))
-        self.assertEqual(result,expected)
+        expected = frequencies.infer_freq(['2004-01', '2004-02', '2004-03',
+                                           '2004-04'])
+        result = frequencies.infer_freq(Index(['2004-01', '2004-02', '2004-03',
+                                               '2004-04']))
+        self.assertEqual(result, expected)
 
     def test_series(self):
 
@@ -577,31 +582,33 @@ class TestFrequencyInference(tm.TestCase):
         # inferring series
 
         # invalid type of Series
-        for s in [ Series(np.arange(10)),
-                   Series(np.arange(10.))]:
-            self.assertRaises(TypeError, lambda : frequencies.infer_freq(s))
+        for s in [Series(np.arange(10)), Series(np.arange(10.))]:
+            self.assertRaises(TypeError, lambda: frequencies.infer_freq(s))
 
         # a non-convertible string
-        self.assertRaises(ValueError, lambda : frequencies.infer_freq(Series(['foo','bar'])))
+        self.assertRaises(ValueError,
+                          lambda: frequencies.infer_freq(
+                              Series(['foo', 'bar'])))
 
         # cannot infer on PeriodIndex
         for freq in [None, 'L']:
-            s = Series(period_range('2013',periods=10,freq=freq))
-            self.assertRaises(TypeError, lambda : frequencies.infer_freq(s))
+            s = Series(period_range('2013', periods=10, freq=freq))
+            self.assertRaises(TypeError, lambda: frequencies.infer_freq(s))
         for freq in ['Y']:
-            with tm.assert_produces_warning(FutureWarning, check_stacklevel=False):
-                s = Series(period_range('2013',periods=10,freq=freq))
-            self.assertRaises(TypeError, lambda : frequencies.infer_freq(s))
+            with tm.assert_produces_warning(FutureWarning,
+                                            check_stacklevel=False):
+                s = Series(period_range('2013', periods=10, freq=freq))
+            self.assertRaises(TypeError, lambda: frequencies.infer_freq(s))
 
         # DateTimeIndex
         for freq in ['M', 'L', 'S']:
-            s = Series(date_range('20130101',periods=10,freq=freq))
+            s = Series(date_range('20130101', periods=10, freq=freq))
             inferred = frequencies.infer_freq(s)
-            self.assertEqual(inferred,freq)
+            self.assertEqual(inferred, freq)
 
-        s = Series(date_range('20130101','20130110'))
+        s = Series(date_range('20130101', '20130110'))
         inferred = frequencies.infer_freq(s)
-        self.assertEqual(inferred,'D')
+        self.assertEqual(inferred, 'D')
 
     def test_legacy_offset_warnings(self):
         for k, v in compat.iteritems(frequencies._rule_aliases):
@@ -610,34 +617,29 @@ class TestFrequencyInference(tm.TestCase):
             exp = frequencies.get_offset(v)
             self.assertEqual(result, exp)
 
-            with tm.assert_produces_warning(FutureWarning, check_stacklevel=False):
+            with tm.assert_produces_warning(FutureWarning,
+                                            check_stacklevel=False):
                 idx = date_range('2011-01-01', periods=5, freq=k)
             exp = date_range('2011-01-01', periods=5, freq=v)
             self.assert_index_equal(idx, exp)
 
 
-MONTHS = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP',
-          'OCT', 'NOV', 'DEC']
+MONTHS = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT',
+          'NOV', 'DEC']
 
 
 def test_is_superperiod_subperiod():
-    assert(frequencies.is_superperiod(offsets.YearEnd(), offsets.MonthEnd()))
-    assert(frequencies.is_subperiod(offsets.MonthEnd(), offsets.YearEnd()))
-
-    assert(frequencies.is_superperiod(offsets.Hour(), offsets.Minute()))
-    assert(frequencies.is_subperiod(offsets.Minute(), offsets.Hour()))
-
-    assert(frequencies.is_superperiod(offsets.Second(), offsets.Milli()))
-    assert(frequencies.is_subperiod(offsets.Milli(), offsets.Second()))
+    assert (frequencies.is_superperiod(offsets.YearEnd(), offsets.MonthEnd()))
+    assert (frequencies.is_subperiod(offsets.MonthEnd(), offsets.YearEnd()))
 
-    assert(frequencies.is_superperiod(offsets.Milli(), offsets.Micro()))
-    assert(frequencies.is_subperiod(offsets.Micro(), offsets.Milli()))
+    assert (frequencies.is_superperiod(offsets.Hour(), offsets.Minute()))
+    assert (frequencies.is_subperiod(offsets.Minute(), offsets.Hour()))
 
-    assert(frequencies.is_superperiod(offsets.Micro(), offsets.Nano()))
-    assert(frequencies.is_subperiod(offsets.Nano(), offsets.Micro()))
+    assert (frequencies.is_superperiod(offsets.Second(), offsets.Milli()))
+    assert (frequencies.is_subperiod(offsets.Milli(), offsets.Second()))
 
+    assert (frequencies.is_superperiod(offsets.Milli(), offsets.Micro()))
+    assert (frequencies.is_subperiod(offsets.Micro(), offsets.Milli()))
 
-if __name__ == '__main__':
-    import nose
-    nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
-                   exit=False)
+    assert (frequencies.is_superperiod(offsets.Micro(), offsets.Nano()))
+    assert (frequencies.is_subperiod(offsets.Nano(), offsets.Micro()))
diff --git a/pandas/tseries/tests/test_holiday.py b/pandas/tseries/tests/test_holiday.py
index dc07a6d45..62446e8e6 100644
--- a/pandas/tseries/tests/test_holiday.py
+++ b/pandas/tseries/tests/test_holiday.py
@@ -1,34 +1,36 @@
-
 from datetime import datetime
 import pandas.util.testing as tm
 from pandas import compat
 from pandas import DatetimeIndex
-from pandas.tseries.holiday import (
-    USFederalHolidayCalendar, USMemorialDay, USThanksgivingDay, 
-    nearest_workday, next_monday_or_tuesday, next_monday,
-    previous_friday, sunday_to_monday, Holiday, DateOffset,
-    MO, SA, Timestamp, AbstractHolidayCalendar, get_calendar,
-    HolidayCalendarFactory, next_workday, previous_workday,
-    before_nearest_workday, EasterMonday, GoodFriday,
-    after_nearest_workday, weekend_to_monday, USLaborDay,
-    USColumbusDay, USMartinLutherKingJr, USPresidentsDay)
+from pandas.tseries.holiday import (USFederalHolidayCalendar, USMemorialDay,
+                                    USThanksgivingDay, nearest_workday,
+                                    next_monday_or_tuesday, next_monday,
+                                    previous_friday, sunday_to_monday, Holiday,
+                                    DateOffset, MO, SA, Timestamp,
+                                    AbstractHolidayCalendar, get_calendar,
+                                    HolidayCalendarFactory, next_workday,
+                                    previous_workday, before_nearest_workday,
+                                    EasterMonday, GoodFriday,
+                                    after_nearest_workday, weekend_to_monday,
+                                    USLaborDay, USColumbusDay,
+                                    USMartinLutherKingJr, USPresidentsDay)
 from pytz import utc
 import nose
 
-class TestCalendar(tm.TestCase):
 
+class TestCalendar(tm.TestCase):
     def setUp(self):
         self.holiday_list = [
-                       datetime(2012, 1, 2),
-                       datetime(2012, 1, 16),
-                       datetime(2012, 2, 20),
-                       datetime(2012, 5, 28),
-                       datetime(2012, 7, 4),
-                       datetime(2012, 9, 3),
-                       datetime(2012, 10, 8),
-                       datetime(2012, 11, 12),
-                       datetime(2012, 11, 22),
-                       datetime(2012, 12, 25)]
+            datetime(2012, 1, 2),
+            datetime(2012, 1, 16),
+            datetime(2012, 2, 20),
+            datetime(2012, 5, 28),
+            datetime(2012, 7, 4),
+            datetime(2012, 9, 3),
+            datetime(2012, 10, 8),
+            datetime(2012, 11, 12),
+            datetime(2012, 11, 22),
+            datetime(2012, 12, 25)]
 
         self.start_date = datetime(2012, 1, 1)
         self.end_date = datetime(2012, 12, 31)
@@ -36,64 +38,55 @@ class TestCalendar(tm.TestCase):
     def test_calendar(self):
 
         calendar = USFederalHolidayCalendar()
-        holidays = calendar.holidays(self.start_date,
-                                     self.end_date)
+        holidays = calendar.holidays(self.start_date, self.end_date)
 
         holidays_1 = calendar.holidays(
-                        self.start_date.strftime('%Y-%m-%d'),
-                        self.end_date.strftime('%Y-%m-%d'))
+            self.start_date.strftime('%Y-%m-%d'),
+            self.end_date.strftime('%Y-%m-%d'))
         holidays_2 = calendar.holidays(
-                        Timestamp(self.start_date),
-                        Timestamp(self.end_date))
+            Timestamp(self.start_date),
+            Timestamp(self.end_date))
 
-        self.assertEqual(list(holidays.to_pydatetime()),
-                         self.holiday_list)
-        self.assertEqual(list(holidays_1.to_pydatetime()),
-                         self.holiday_list)
-        self.assertEqual(list(holidays_2.to_pydatetime()),
-                         self.holiday_list)
+        self.assertEqual(list(holidays.to_pydatetime()), self.holiday_list)
+        self.assertEqual(list(holidays_1.to_pydatetime()), self.holiday_list)
+        self.assertEqual(list(holidays_2.to_pydatetime()), self.holiday_list)
 
     def test_calendar_caching(self):
         # Test for issue #9552
 
         class TestCalendar(AbstractHolidayCalendar):
             def __init__(self, name=None, rules=None):
-                super(TestCalendar, self).__init__(
-                    name=name,
-                    rules=rules
-                )
+                super(TestCalendar, self).__init__(name=name, rules=rules)
 
         jan1 = TestCalendar(rules=[Holiday('jan1', year=2015, month=1, day=1)])
         jan2 = TestCalendar(rules=[Holiday('jan2', year=2015, month=1, day=2)])
 
-        tm.assert_index_equal(
-            jan1.holidays(),
-            DatetimeIndex(['01-Jan-2015'])
-        )
-        tm.assert_index_equal(
-            jan2.holidays(),
-            DatetimeIndex(['02-Jan-2015'])
-        )
-        
+        tm.assert_index_equal(jan1.holidays(), DatetimeIndex(['01-Jan-2015']))
+        tm.assert_index_equal(jan2.holidays(), DatetimeIndex(['02-Jan-2015']))
+
     def test_calendar_observance_dates(self):
         # Test for issue 11477
         USFedCal = get_calendar('USFederalHolidayCalendar')
-        holidays0 = USFedCal.holidays(datetime(2015,7,3), datetime(2015,7,3)) # <-- same start and end dates
-        holidays1 = USFedCal.holidays(datetime(2015,7,3), datetime(2015,7,6)) # <-- different start and end dates
-        holidays2 = USFedCal.holidays(datetime(2015,7,3), datetime(2015,7,3)) # <-- same start and end dates
-        
+        holidays0 = USFedCal.holidays(datetime(2015, 7, 3), datetime(
+            2015, 7, 3))  # <-- same start and end dates
+        holidays1 = USFedCal.holidays(datetime(2015, 7, 3), datetime(
+            2015, 7, 6))  # <-- different start and end dates
+        holidays2 = USFedCal.holidays(datetime(2015, 7, 3), datetime(
+            2015, 7, 3))  # <-- same start and end dates
+
         tm.assert_index_equal(holidays0, holidays1)
         tm.assert_index_equal(holidays0, holidays2)
-        
+
     def test_rule_from_name(self):
         USFedCal = get_calendar('USFederalHolidayCalendar')
-        self.assertEqual(USFedCal.rule_from_name('Thanksgiving'), USThanksgivingDay)
+        self.assertEqual(USFedCal.rule_from_name(
+            'Thanksgiving'), USThanksgivingDay)
 
-class TestHoliday(tm.TestCase):
 
+class TestHoliday(tm.TestCase):
     def setUp(self):
         self.start_date = datetime(2011, 1, 1)
-        self.end_date   = datetime(2020, 12, 31)
+        self.end_date = datetime(2020, 12, 31)
 
     def check_results(self, holiday, start, end, expected):
         self.assertEqual(list(holiday.dates(start, end)), expected)
@@ -109,23 +102,21 @@ class TestHoliday(tm.TestCase):
         )
 
     def test_usmemorialday(self):
-        self.check_results(
-            holiday=USMemorialDay,
-            start=self.start_date,
-            end=self.end_date,
-            expected=[
-                datetime(2011, 5, 30),
-                datetime(2012, 5, 28),
-                datetime(2013, 5, 27),
-                datetime(2014, 5, 26),
-                datetime(2015, 5, 25),
-                datetime(2016, 5, 30),
-                datetime(2017, 5, 29),
-                datetime(2018, 5, 28),
-                datetime(2019, 5, 27),
-                datetime(2020, 5, 25),
-            ],
-        )
+        self.check_results(holiday=USMemorialDay,
+                           start=self.start_date,
+                           end=self.end_date,
+                           expected=[
+                               datetime(2011, 5, 30),
+                               datetime(2012, 5, 28),
+                               datetime(2013, 5, 27),
+                               datetime(2014, 5, 26),
+                               datetime(2015, 5, 25),
+                               datetime(2016, 5, 30),
+                               datetime(2017, 5, 29),
+                               datetime(2018, 5, 28),
+                               datetime(2019, 5, 27),
+                               datetime(2020, 5, 25),
+                           ], )
 
     def test_non_observed_holiday(self):
 
@@ -154,61 +145,55 @@ class TestHoliday(tm.TestCase):
 
     def test_easter(self):
 
-        self.check_results(
-            EasterMonday,
-            start=self.start_date,
-            end=self.end_date,
-            expected=[
-                Timestamp('2011-04-25 00:00:00'),
-                Timestamp('2012-04-09 00:00:00'),
-                Timestamp('2013-04-01 00:00:00'),
-                Timestamp('2014-04-21 00:00:00'),
-                Timestamp('2015-04-06 00:00:00'),
-                Timestamp('2016-03-28 00:00:00'),
-                Timestamp('2017-04-17 00:00:00'),
-                Timestamp('2018-04-02 00:00:00'),
-                Timestamp('2019-04-22 00:00:00'),
-                Timestamp('2020-04-13 00:00:00'),
-            ],
-        )
-        self.check_results(
-            GoodFriday,
-            start=self.start_date,
-            end=self.end_date,
-            expected=[
-                Timestamp('2011-04-22 00:00:00'),
-                Timestamp('2012-04-06 00:00:00'),
-                Timestamp('2013-03-29 00:00:00'),
-                Timestamp('2014-04-18 00:00:00'),
-                Timestamp('2015-04-03 00:00:00'),
-                Timestamp('2016-03-25 00:00:00'),
-                Timestamp('2017-04-14 00:00:00'),
-                Timestamp('2018-03-30 00:00:00'),
-                Timestamp('2019-04-19 00:00:00'),
-                Timestamp('2020-04-10 00:00:00'),
-            ],
-        )
+        self.check_results(EasterMonday,
+                           start=self.start_date,
+                           end=self.end_date,
+                           expected=[
+                               Timestamp('2011-04-25 00:00:00'),
+                               Timestamp('2012-04-09 00:00:00'),
+                               Timestamp('2013-04-01 00:00:00'),
+                               Timestamp('2014-04-21 00:00:00'),
+                               Timestamp('2015-04-06 00:00:00'),
+                               Timestamp('2016-03-28 00:00:00'),
+                               Timestamp('2017-04-17 00:00:00'),
+                               Timestamp('2018-04-02 00:00:00'),
+                               Timestamp('2019-04-22 00:00:00'),
+                               Timestamp('2020-04-13 00:00:00'),
+                           ], )
+        self.check_results(GoodFriday,
+                           start=self.start_date,
+                           end=self.end_date,
+                           expected=[
+                               Timestamp('2011-04-22 00:00:00'),
+                               Timestamp('2012-04-06 00:00:00'),
+                               Timestamp('2013-03-29 00:00:00'),
+                               Timestamp('2014-04-18 00:00:00'),
+                               Timestamp('2015-04-03 00:00:00'),
+                               Timestamp('2016-03-25 00:00:00'),
+                               Timestamp('2017-04-14 00:00:00'),
+                               Timestamp('2018-03-30 00:00:00'),
+                               Timestamp('2019-04-19 00:00:00'),
+                               Timestamp('2020-04-10 00:00:00'),
+                           ], )
 
     def test_usthanksgivingday(self):
 
-        self.check_results(
-            USThanksgivingDay,
-            start=self.start_date,
-            end=self.end_date,
-            expected=[
-                datetime(2011, 11, 24),
-                datetime(2012, 11, 22),
-                datetime(2013, 11, 28),
-                datetime(2014, 11, 27),
-                datetime(2015, 11, 26),
-                datetime(2016, 11, 24),
-                datetime(2017, 11, 23),
-                datetime(2018, 11, 22),
-                datetime(2019, 11, 28),
-                datetime(2020, 11, 26),
-            ],
-        )
-        
+        self.check_results(USThanksgivingDay,
+                           start=self.start_date,
+                           end=self.end_date,
+                           expected=[
+                               datetime(2011, 11, 24),
+                               datetime(2012, 11, 22),
+                               datetime(2013, 11, 28),
+                               datetime(2014, 11, 27),
+                               datetime(2015, 11, 26),
+                               datetime(2016, 11, 24),
+                               datetime(2017, 11, 23),
+                               datetime(2018, 11, 22),
+                               datetime(2019, 11, 28),
+                               datetime(2020, 11, 26),
+                           ], )
+
     def test_holidays_within_dates(self):
         # Fix holiday behavior found in #11477
         # where holiday.dates returned dates outside start/end date
@@ -216,56 +201,55 @@ class TestHoliday(tm.TestCase):
         # was not in the original date range (e.g., 7/4/2015 -> 7/3/2015)
         start_date = datetime(2015, 7, 1)
         end_date = datetime(2015, 7, 1)
-         
+
         calendar = get_calendar('USFederalHolidayCalendar')
         new_years = calendar.rule_from_name('New Years Day')
         july_4th = calendar.rule_from_name('July 4th')
         veterans_day = calendar.rule_from_name('Veterans Day')
         christmas = calendar.rule_from_name('Christmas')
-         
+
         # Holiday: (start/end date, holiday)
-        holidays = {USMemorialDay:          ("2015-05-25", "2015-05-25"),
-                    USLaborDay:             ("2015-09-07", "2015-09-07"),
-                    USColumbusDay:          ("2015-10-12", "2015-10-12"),
-                    USThanksgivingDay:      ("2015-11-26", "2015-11-26"),
-                    USMartinLutherKingJr:   ("2015-01-19", "2015-01-19"),
-                    USPresidentsDay:        ("2015-02-16", "2015-02-16"),
-                    GoodFriday:             ("2015-04-03", "2015-04-03"),
-                    EasterMonday:           [("2015-04-06", "2015-04-06"),
-                                             ("2015-04-05", [])],
-                    new_years:              [("2015-01-01", "2015-01-01"),
-                                             ("2011-01-01", []),
-                                             ("2010-12-31", "2010-12-31")],
-                    july_4th:               [("2015-07-03", "2015-07-03"),
-                                             ("2015-07-04", [])],
-                    veterans_day:           [("2012-11-11", []),
-                                             ("2012-11-12", "2012-11-12")],
-                    christmas:              [("2011-12-25", []),
-                                             ("2011-12-26", "2011-12-26")]}
-         
+        holidays = {USMemorialDay: ("2015-05-25", "2015-05-25"),
+                    USLaborDay: ("2015-09-07", "2015-09-07"),
+                    USColumbusDay: ("2015-10-12", "2015-10-12"),
+                    USThanksgivingDay: ("2015-11-26", "2015-11-26"),
+                    USMartinLutherKingJr: ("2015-01-19", "2015-01-19"),
+                    USPresidentsDay: ("2015-02-16", "2015-02-16"),
+                    GoodFriday: ("2015-04-03", "2015-04-03"),
+                    EasterMonday: [("2015-04-06", "2015-04-06"),
+                                   ("2015-04-05", [])],
+                    new_years: [("2015-01-01", "2015-01-01"),
+                                ("2011-01-01", []),
+                                ("2010-12-31", "2010-12-31")],
+                    july_4th: [("2015-07-03", "2015-07-03"),
+                               ("2015-07-04", [])],
+                    veterans_day: [("2012-11-11", []),
+                                   ("2012-11-12", "2012-11-12")],
+                    christmas: [("2011-12-25", []),
+                                ("2011-12-26", "2011-12-26")]}
+
         for rule, dates in compat.iteritems(holidays):
             empty_dates = rule.dates(start_date, end_date)
             self.assertEqual(empty_dates.tolist(), [])
-             
+
             if isinstance(dates, tuple):
                 dates = [dates]
-                
+
             for start, expected in dates:
                 if len(expected):
                     expected = [Timestamp(expected)]
                 self.check_results(rule, start, start, expected)
 
     def test_argument_types(self):
-        holidays = USThanksgivingDay.dates(self.start_date,
-                                           self.end_date)
+        holidays = USThanksgivingDay.dates(self.start_date, self.end_date)
 
         holidays_1 = USThanksgivingDay.dates(
-                        self.start_date.strftime('%Y-%m-%d'),
-                        self.end_date.strftime('%Y-%m-%d'))
+            self.start_date.strftime('%Y-%m-%d'),
+            self.end_date.strftime('%Y-%m-%d'))
 
         holidays_2 = USThanksgivingDay.dates(
-                        Timestamp(self.start_date),
-                        Timestamp(self.end_date))
+            Timestamp(self.start_date),
+            Timestamp(self.end_date))
 
         self.assert_index_equal(holidays, holidays_1)
         self.assert_index_equal(holidays, holidays_2)
@@ -291,9 +275,11 @@ class TestHoliday(tm.TestCase):
         self.assertEqual(TestCalendar, calendar.__class__)
 
     def test_factory(self):
-        class_1 = HolidayCalendarFactory('MemorialDay', AbstractHolidayCalendar,
+        class_1 = HolidayCalendarFactory('MemorialDay',
+                                         AbstractHolidayCalendar,
                                          USMemorialDay)
-        class_2 = HolidayCalendarFactory('Thansksgiving', AbstractHolidayCalendar,
+        class_2 = HolidayCalendarFactory('Thansksgiving',
+                                         AbstractHolidayCalendar,
                                          USThanksgivingDay)
         class_3 = HolidayCalendarFactory('Combined', class_1, class_2)
 
@@ -303,15 +289,14 @@ class TestHoliday(tm.TestCase):
 
 
 class TestObservanceRules(tm.TestCase):
-
     def setUp(self):
-        self.we =   datetime(2014, 4, 9)
-        self.th =   datetime(2014, 4, 10)
-        self.fr =   datetime(2014, 4, 11)
-        self.sa =   datetime(2014, 4, 12)
-        self.su =   datetime(2014, 4, 13)
-        self.mo =   datetime(2014, 4, 14)
-        self.tu =   datetime(2014, 4, 15)
+        self.we = datetime(2014, 4, 9)
+        self.th = datetime(2014, 4, 10)
+        self.fr = datetime(2014, 4, 11)
+        self.sa = datetime(2014, 4, 12)
+        self.su = datetime(2014, 4, 13)
+        self.mo = datetime(2014, 4, 14)
+        self.tu = datetime(2014, 4, 15)
 
     def test_next_monday(self):
         self.assertEqual(next_monday(self.sa), self.mo)
@@ -353,44 +338,55 @@ class TestObservanceRules(tm.TestCase):
         self.assertEqual(before_nearest_workday(self.sa), self.th)
         self.assertEqual(before_nearest_workday(self.su), self.fr)
         self.assertEqual(before_nearest_workday(self.tu), self.mo)
-    
+
     def test_after_nearest_workday(self):
         self.assertEqual(after_nearest_workday(self.sa), self.mo)
         self.assertEqual(after_nearest_workday(self.su), self.tu)
         self.assertEqual(after_nearest_workday(self.fr), self.mo)
 
+
 class TestFederalHolidayCalendar(tm.TestCase):
 
     # Test for issue 10278
     def test_no_mlk_before_1984(self):
         class MLKCalendar(AbstractHolidayCalendar):
-            rules=[USMartinLutherKingJr]
-        holidays = MLKCalendar().holidays(start='1984', end='1988').to_pydatetime().tolist()
+            rules = [USMartinLutherKingJr]
+
+        holidays = MLKCalendar().holidays(start='1984',
+                                          end='1988').to_pydatetime().tolist()
         # Testing to make sure holiday is not incorrectly observed before 1986
-        self.assertEqual(holidays, [datetime(1986, 1, 20, 0, 0), datetime(1987, 1, 19, 0, 0)])
+        self.assertEqual(holidays, [datetime(1986, 1, 20, 0, 0), datetime(
+            1987, 1, 19, 0, 0)])
 
     def test_memorial_day(self):
         class MemorialDay(AbstractHolidayCalendar):
-            rules=[USMemorialDay]
-        holidays = MemorialDay().holidays(start='1971', end='1980').to_pydatetime().tolist()
+            rules = [USMemorialDay]
+
+        holidays = MemorialDay().holidays(start='1971',
+                                          end='1980').to_pydatetime().tolist()
         # Fixes 5/31 error and checked manually against wikipedia
-        self.assertEqual(holidays, [datetime(1971, 5, 31, 0, 0), datetime(1972, 5, 29, 0, 0),
-            datetime(1973, 5, 28, 0, 0), datetime(1974, 5, 27, 0, 0),
-            datetime(1975, 5, 26, 0, 0), datetime(1976, 5, 31, 0, 0),
-            datetime(1977, 5, 30, 0, 0), datetime(1978, 5, 29, 0, 0),
-            datetime(1979, 5, 28, 0, 0)])
+        self.assertEqual(holidays, [datetime(1971, 5, 31, 0, 0),
+                                    datetime(1972, 5, 29, 0, 0),
+                                    datetime(1973, 5, 28, 0, 0),
+                                    datetime(1974, 5, 27, 0,
+                                             0), datetime(1975, 5, 26, 0, 0),
+                                    datetime(1976, 5, 31, 0,
+                                             0), datetime(1977, 5, 30, 0, 0),
+                                    datetime(1978, 5, 29, 0,
+                                             0), datetime(1979, 5, 28, 0, 0)])
+
 
 class TestHolidayConflictingArguments(tm.TestCase):
 
     # GH 10217
 
     def test_both_offset_observance_raises(self):
+        with self.assertRaises(NotImplementedError):
+            Holiday("Cyber Monday", month=11, day=1,
+                    offset=[DateOffset(weekday=SA(4))],
+                    observance=next_monday)
 
-        with self.assertRaises(NotImplementedError) as cm:
-            h = Holiday("Cyber Monday", month=11, day=1,
-                        offset=[DateOffset(weekday=SA(4))], observance=next_monday)
 
 if __name__ == '__main__':
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
                    exit=False)
-
diff --git a/pandas/tseries/tests/test_offsets.py b/pandas/tseries/tests/test_offsets.py
index 70e0cc288..f1b5172a8 100644
--- a/pandas/tseries/tests/test_offsets.py
+++ b/pandas/tseries/tests/test_offsets.py
@@ -6,21 +6,22 @@ from pandas import compat
 import nose
 from nose.tools import assert_raises
 
-
 import numpy as np
 
-from pandas.core.datetools import (
-    bday, BDay, CDay, BQuarterEnd, BMonthEnd, BusinessHour,
-    CBMonthEnd, CBMonthBegin,
-    BYearEnd, MonthEnd, MonthBegin, BYearBegin, CustomBusinessDay,
-    QuarterBegin, BQuarterBegin, BMonthBegin, DateOffset, Week,
-    YearBegin, YearEnd, Hour, Minute, Second, Day, Micro, Milli, Nano, Easter,
-    WeekOfMonth, format, ole2datetime, QuarterEnd, to_datetime, normalize_date,
-    get_offset, get_standard_freq)
-
-from pandas import Series
-from pandas.tseries.frequencies import _offset_map, get_freq_code, _get_freq_str
-from pandas.tseries.index import _to_m8, DatetimeIndex, _daterange_cache, date_range
+from pandas.core.datetools import (bday, BDay, CDay, BQuarterEnd, BMonthEnd,
+                                   BusinessHour, CBMonthEnd, CBMonthBegin,
+                                   BYearEnd, MonthEnd, MonthBegin, BYearBegin,
+                                   QuarterBegin,
+                                   BQuarterBegin, BMonthBegin, DateOffset,
+                                   Week, YearBegin, YearEnd, Hour, Minute,
+                                   Second, Day, Micro, Milli, Nano, Easter,
+                                   WeekOfMonth, format, ole2datetime,
+                                   QuarterEnd, to_datetime, normalize_date,
+                                   get_offset, get_standard_freq)
+
+from pandas.tseries.frequencies import (_offset_map, get_freq_code,
+                                        _get_freq_str)
+from pandas.tseries.index import _to_m8, DatetimeIndex, _daterange_cache
 from pandas.tseries.tools import parse_time_string, DateParseError
 import pandas.tseries.offsets as offsets
 from pandas.io.pickle import read_pickle
@@ -41,9 +42,8 @@ def test_monthrange():
         for m in range(1, 13):
             assert tslib.monthrange(y, m) == calendar.monthrange(y, m)
 
-
 ####
-## Misc function tests
+# Misc function tests
 ####
 
 
@@ -82,15 +82,16 @@ def test_to_m8():
     tm.assertIsInstance(valu, np.datetime64)
     # assert valu == np.datetime64(datetime(2007,10,1))
 
-# def test_datetime64_box():
-#    valu = np.datetime64(datetime(2007,10,1))
-#    valb = _dt_box(valu)
-#    assert type(valb) == datetime
-#    assert valb == datetime(2007,10,1)
+    # def test_datetime64_box():
+    #    valu = np.datetime64(datetime(2007,10,1))
+    #    valb = _dt_box(valu)
+    #    assert type(valb) == datetime
+    #    assert valb == datetime(2007,10,1)
+
+    #####
+    # DateOffset Tests
+    #####
 
-#####
-### DateOffset Tests
-#####
 
 class Base(tm.TestCase):
     _offset = None
@@ -129,11 +130,12 @@ class Base(tm.TestCase):
         if self._offset is None:
             return
 
-        # try to create an out-of-bounds result timestamp; if we can't create the offset
-        # skip
+        # try to create an out-of-bounds result timestamp; if we can't create
+        # the offset skip
         try:
             if self._offset is BusinessHour:
-                # Using 10000 in BusinessHour fails in tz check because of DST difference
+                # Using 10000 in BusinessHour fails in tz check because of DST
+                # difference
                 offset = self._get_offset(self._offset, value=100000)
             else:
                 offset = self._get_offset(self._offset, value=10000)
@@ -154,11 +156,12 @@ class Base(tm.TestCase):
         except (tslib.OutOfBoundsDatetime):
             raise
         except (ValueError, KeyError) as e:
-            raise nose.SkipTest("cannot create out_of_range offset: {0} {1}".format(str(self).split('.')[-1],e))
+            raise nose.SkipTest(
+                "cannot create out_of_range offset: {0} {1}".format(
+                    str(self).split('.')[-1], e))
 
 
 class TestCommon(Base):
-
     def setUp(self):
 
         # exected value created by Base._get_offset
@@ -167,11 +170,15 @@ class TestCommon(Base):
         self.expecteds = {'Day': Timestamp('2011-01-02 09:00:00'),
                           'DateOffset': Timestamp('2011-01-02 09:00:00'),
                           'BusinessDay': Timestamp('2011-01-03 09:00:00'),
-                          'CustomBusinessDay': Timestamp('2011-01-03 09:00:00'),
-                          'CustomBusinessMonthEnd': Timestamp('2011-01-31 09:00:00'),
-                          'CustomBusinessMonthBegin': Timestamp('2011-01-03 09:00:00'),
+                          'CustomBusinessDay':
+                          Timestamp('2011-01-03 09:00:00'),
+                          'CustomBusinessMonthEnd':
+                          Timestamp('2011-01-31 09:00:00'),
+                          'CustomBusinessMonthBegin':
+                          Timestamp('2011-01-03 09:00:00'),
                           'MonthBegin': Timestamp('2011-02-01 09:00:00'),
-                          'BusinessMonthBegin': Timestamp('2011-01-03 09:00:00'),
+                          'BusinessMonthBegin':
+                          Timestamp('2011-01-03 09:00:00'),
                           'MonthEnd': Timestamp('2011-01-31 09:00:00'),
                           'BusinessMonthEnd': Timestamp('2011-01-31 09:00:00'),
                           'YearBegin': Timestamp('2012-01-01 09:00:00'),
@@ -194,7 +201,8 @@ class TestCommon(Base):
                           'Second': Timestamp('2011-01-01 09:00:01'),
                           'Milli': Timestamp('2011-01-01 09:00:00.001000'),
                           'Micro': Timestamp('2011-01-01 09:00:00.000001'),
-                          'Nano': Timestamp(np.datetime64('2011-01-01T09:00:00.000000001Z'))}
+                          'Nano': Timestamp(np.datetime64(
+                              '2011-01-01T09:00:00.000000001Z'))}
 
     def test_return_type(self):
         for offset in self.offset_types:
@@ -227,7 +235,8 @@ class TestCommon(Base):
             offset = self._get_offset(offset_klass)
 
             freqstr = offset.freqstr
-            if freqstr not in ('<Easter>', "<DateOffset: kwds={'days': 1}>",
+            if freqstr not in ('<Easter>',
+                               "<DateOffset: kwds={'days': 1}>",
                                'LWOM-SAT', ):
                 code = get_offset(freqstr)
                 self.assertEqual(offset.rule_code, code)
@@ -298,8 +307,9 @@ class TestCommon(Base):
         expecteds = self.expecteds.copy()
 
         # result will not be changed if the target is on the offset
-        no_changes = ['Day', 'MonthBegin', 'YearBegin', 'Week', 'Hour', 'Minute',
-                      'Second', 'Milli', 'Micro', 'Nano', 'DateOffset']
+        no_changes = ['Day', 'MonthBegin', 'YearBegin', 'Week', 'Hour',
+                      'Minute', 'Second', 'Milli', 'Micro', 'Nano',
+                      'DateOffset']
         for n in no_changes:
             expecteds[n] = Timestamp('2011/01/01 09:00')
 
@@ -328,16 +338,19 @@ class TestCommon(Base):
         for offset in self.offset_types:
             for dt in [sdt, ndt]:
                 expected = expecteds[offset.__name__]
-                self._check_offsetfunc_works(offset, 'rollforward', dt, expected)
+                self._check_offsetfunc_works(offset, 'rollforward', dt,
+                                             expected)
                 expected = norm_expected[offset.__name__]
-                self._check_offsetfunc_works(offset, 'rollforward', dt, expected,
-                                             normalize=True)
+                self._check_offsetfunc_works(offset, 'rollforward', dt,
+                                             expected, normalize=True)
 
     def test_rollback(self):
         expecteds = {'BusinessDay': Timestamp('2010-12-31 09:00:00'),
                      'CustomBusinessDay': Timestamp('2010-12-31 09:00:00'),
-                     'CustomBusinessMonthEnd': Timestamp('2010-12-31 09:00:00'),
-                     'CustomBusinessMonthBegin': Timestamp('2010-12-01 09:00:00'),
+                     'CustomBusinessMonthEnd':
+                     Timestamp('2010-12-31 09:00:00'),
+                     'CustomBusinessMonthBegin':
+                     Timestamp('2010-12-01 09:00:00'),
                      'BusinessMonthBegin': Timestamp('2010-12-01 09:00:00'),
                      'MonthEnd': Timestamp('2010-12-31 09:00:00'),
                      'BusinessMonthEnd': Timestamp('2010-12-31 09:00:00'),
@@ -386,8 +399,8 @@ class TestCommon(Base):
                 self._check_offsetfunc_works(offset, 'rollback', dt, expected)
 
                 expected = norm_expected[offset.__name__]
-                self._check_offsetfunc_works(offset, 'rollback',
-                                             dt, expected, normalize=True)
+                self._check_offsetfunc_works(offset, 'rollback', dt, expected,
+                                             normalize=True)
 
     def test_onOffset(self):
         for offset in self.offset_types:
@@ -455,6 +468,7 @@ class TestCommon(Base):
         #
         tm.assert_dict_equal(offsets, read_pickle(pickle_path))
 
+
 class TestDateOffset(Base):
     _multiprocess_can_split_ = True
 
@@ -474,19 +488,19 @@ class TestDateOffset(Base):
 
     def test_constructor(self):
 
-        assert((self.d + DateOffset(months=2)) == datetime(2008, 3, 2))
-        assert((self.d - DateOffset(months=2)) == datetime(2007, 11, 2))
+        assert ((self.d + DateOffset(months=2)) == datetime(2008, 3, 2))
+        assert ((self.d - DateOffset(months=2)) == datetime(2007, 11, 2))
 
-        assert((self.d + DateOffset(2)) == datetime(2008, 1, 4))
+        assert ((self.d + DateOffset(2)) == datetime(2008, 1, 4))
 
         assert not DateOffset(2).isAnchored()
         assert DateOffset(1).isAnchored()
 
         d = datetime(2008, 1, 31)
-        assert((d + DateOffset(months=1)) == datetime(2008, 2, 29))
+        assert ((d + DateOffset(months=1)) == datetime(2008, 2, 29))
 
     def test_copy(self):
-        assert(DateOffset(months=2).copy() == DateOffset(months=2))
+        assert (DateOffset(months=2).copy() == DateOffset(months=2))
 
     def test_eq(self):
         offset1 = DateOffset(days=1)
@@ -553,8 +567,7 @@ class TestBusinessDay(Base):
         self.assertEqual(self.d + 10 * self.offset, self.d + BDay(10))
 
     def testMult2(self):
-        self.assertEqual(self.d + (-5 * BDay(-10)),
-                         self.d + BDay(50))
+        self.assertEqual(self.d + (-5 * BDay(-10)), self.d + BDay(50))
 
     def testRollback1(self):
         self.assertEqual(BDay(10).rollback(self.d), self.d)
@@ -592,49 +605,44 @@ class TestBusinessDay(Base):
         tests = [(BDay(), datetime(2008, 1, 1), True),
                  (BDay(), datetime(2008, 1, 5), False)]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, d, expected in tests:
+            assertOnOffset(offset, d, expected)
 
     def test_apply(self):
         tests = []
 
-        tests.append((bday,
-                      {datetime(2008, 1, 1): datetime(2008, 1, 2),
-                       datetime(2008, 1, 4): datetime(2008, 1, 7),
-                       datetime(2008, 1, 5): datetime(2008, 1, 7),
-                       datetime(2008, 1, 6): datetime(2008, 1, 7),
-                       datetime(2008, 1, 7): datetime(2008, 1, 8)}))
-
-        tests.append((2 * bday,
-                      {datetime(2008, 1, 1): datetime(2008, 1, 3),
-                       datetime(2008, 1, 4): datetime(2008, 1, 8),
-                       datetime(2008, 1, 5): datetime(2008, 1, 8),
-                       datetime(2008, 1, 6): datetime(2008, 1, 8),
-                       datetime(2008, 1, 7): datetime(2008, 1, 9)}))
-
-        tests.append((-bday,
-                      {datetime(2008, 1, 1): datetime(2007, 12, 31),
-                       datetime(2008, 1, 4): datetime(2008, 1, 3),
-                       datetime(2008, 1, 5): datetime(2008, 1, 4),
-                       datetime(2008, 1, 6): datetime(2008, 1, 4),
-                       datetime(2008, 1, 7): datetime(2008, 1, 4),
-                       datetime(2008, 1, 8): datetime(2008, 1, 7)}))
-
-        tests.append((-2 * bday,
-                      {datetime(2008, 1, 1): datetime(2007, 12, 28),
-                       datetime(2008, 1, 4): datetime(2008, 1, 2),
-                       datetime(2008, 1, 5): datetime(2008, 1, 3),
-                       datetime(2008, 1, 6): datetime(2008, 1, 3),
-                       datetime(2008, 1, 7): datetime(2008, 1, 3),
-                       datetime(2008, 1, 8): datetime(2008, 1, 4),
-                       datetime(2008, 1, 9): datetime(2008, 1, 7)}))
-
-        tests.append((BDay(0),
-                      {datetime(2008, 1, 1): datetime(2008, 1, 1),
-                       datetime(2008, 1, 4): datetime(2008, 1, 4),
-                       datetime(2008, 1, 5): datetime(2008, 1, 7),
-                       datetime(2008, 1, 6): datetime(2008, 1, 7),
-                       datetime(2008, 1, 7): datetime(2008, 1, 7)}))
+        tests.append((bday, {datetime(2008, 1, 1): datetime(2008, 1, 2),
+                             datetime(2008, 1, 4): datetime(2008, 1, 7),
+                             datetime(2008, 1, 5): datetime(2008, 1, 7),
+                             datetime(2008, 1, 6): datetime(2008, 1, 7),
+                             datetime(2008, 1, 7): datetime(2008, 1, 8)}))
+
+        tests.append((2 * bday, {datetime(2008, 1, 1): datetime(2008, 1, 3),
+                                 datetime(2008, 1, 4): datetime(2008, 1, 8),
+                                 datetime(2008, 1, 5): datetime(2008, 1, 8),
+                                 datetime(2008, 1, 6): datetime(2008, 1, 8),
+                                 datetime(2008, 1, 7): datetime(2008, 1, 9)}))
+
+        tests.append((-bday, {datetime(2008, 1, 1): datetime(2007, 12, 31),
+                              datetime(2008, 1, 4): datetime(2008, 1, 3),
+                              datetime(2008, 1, 5): datetime(2008, 1, 4),
+                              datetime(2008, 1, 6): datetime(2008, 1, 4),
+                              datetime(2008, 1, 7): datetime(2008, 1, 4),
+                              datetime(2008, 1, 8): datetime(2008, 1, 7)}))
+
+        tests.append((-2 * bday, {datetime(2008, 1, 1): datetime(2007, 12, 28),
+                                  datetime(2008, 1, 4): datetime(2008, 1, 2),
+                                  datetime(2008, 1, 5): datetime(2008, 1, 3),
+                                  datetime(2008, 1, 6): datetime(2008, 1, 3),
+                                  datetime(2008, 1, 7): datetime(2008, 1, 3),
+                                  datetime(2008, 1, 8): datetime(2008, 1, 4),
+                                  datetime(2008, 1, 9): datetime(2008, 1, 7)}))
+
+        tests.append((BDay(0), {datetime(2008, 1, 1): datetime(2008, 1, 1),
+                                datetime(2008, 1, 4): datetime(2008, 1, 4),
+                                datetime(2008, 1, 5): datetime(2008, 1, 7),
+                                datetime(2008, 1, 6): datetime(2008, 1, 7),
+                                datetime(2008, 1, 7): datetime(2008, 1, 7)}))
 
         for offset, cases in tests:
             for base, expected in compat.iteritems(cases):
@@ -660,7 +668,7 @@ class TestBusinessDay(Base):
         self.assertEqual(rs, xp)
 
         off = BDay() * 10
-        rs = datetime(2014, 1, 5) + off # see #5890
+        rs = datetime(2014, 1, 5) + off  # see #5890
         xp = datetime(2014, 1, 17)
         self.assertEqual(rs, xp)
 
@@ -690,7 +698,8 @@ class TestBusinessHour(Base):
         from datetime import time as dt_time
         self.offset5 = BusinessHour(start=dt_time(11, 0), end=dt_time(14, 30))
         self.offset6 = BusinessHour(start='20:00', end='05:00')
-        self.offset7 = BusinessHour(n=-2, start=dt_time(21, 30), end=dt_time(6, 30))
+        self.offset7 = BusinessHour(n=-2, start=dt_time(21, 30),
+                                    end=dt_time(6, 30))
 
     def test_constructor_errors(self):
         from datetime import time as dt_time
@@ -710,13 +719,17 @@ class TestBusinessHour(Base):
 
     def test_repr(self):
         self.assertEqual(repr(self.offset1), '<BusinessHour: BH=09:00-17:00>')
-        self.assertEqual(repr(self.offset2), '<3 * BusinessHours: BH=09:00-17:00>')
-        self.assertEqual(repr(self.offset3), '<-1 * BusinessHour: BH=09:00-17:00>')
-        self.assertEqual(repr(self.offset4), '<-4 * BusinessHours: BH=09:00-17:00>')
+        self.assertEqual(repr(self.offset2),
+                         '<3 * BusinessHours: BH=09:00-17:00>')
+        self.assertEqual(repr(self.offset3),
+                         '<-1 * BusinessHour: BH=09:00-17:00>')
+        self.assertEqual(repr(self.offset4),
+                         '<-4 * BusinessHours: BH=09:00-17:00>')
 
         self.assertEqual(repr(self.offset5), '<BusinessHour: BH=11:00-14:30>')
         self.assertEqual(repr(self.offset6), '<BusinessHour: BH=20:00-05:00>')
-        self.assertEqual(repr(self.offset7), '<-2 * BusinessHours: BH=21:30-06:30>')
+        self.assertEqual(repr(self.offset7),
+                         '<-2 * BusinessHours: BH=21:30-06:30>')
 
     def test_with_offset(self):
         expected = Timestamp('2014-07-01 13:00')
@@ -730,9 +743,10 @@ class TestBusinessHour(Base):
 
         self.assertNotEqual(BusinessHour(), BusinessHour(-1))
         self.assertEqual(BusinessHour(start='09:00'), BusinessHour())
-        self.assertNotEqual(BusinessHour(start='09:00'), BusinessHour(start='09:01'))
+        self.assertNotEqual(BusinessHour(start='09:00'),
+                            BusinessHour(start='09:01'))
         self.assertNotEqual(BusinessHour(start='09:00', end='17:00'),
-                                         BusinessHour(start='17:00', end='09:01'))
+                            BusinessHour(start='17:00', end='09:01'))
 
     def test_hash(self):
         self.assertEqual(hash(self.offset2), hash(self.offset2))
@@ -768,23 +782,28 @@ class TestBusinessHour(Base):
         self.assertEqual(self.offset2.rollback(self.d), self.d)
         self.assertEqual(self.offset3.rollback(self.d), self.d)
         self.assertEqual(self.offset4.rollback(self.d), self.d)
-        self.assertEqual(self.offset5.rollback(self.d), datetime(2014, 6, 30, 14, 30))
-        self.assertEqual(self.offset6.rollback(self.d), datetime(2014, 7, 1, 5, 0))
-        self.assertEqual(self.offset7.rollback(self.d), datetime(2014, 7, 1, 6, 30))
+        self.assertEqual(self.offset5.rollback(self.d),
+                         datetime(2014, 6, 30, 14, 30))
+        self.assertEqual(self.offset6.rollback(
+            self.d), datetime(2014, 7, 1, 5, 0))
+        self.assertEqual(self.offset7.rollback(
+            self.d), datetime(2014, 7, 1, 6, 30))
 
         d = datetime(2014, 7, 1, 0)
         self.assertEqual(self.offset1.rollback(d), datetime(2014, 6, 30, 17))
         self.assertEqual(self.offset2.rollback(d), datetime(2014, 6, 30, 17))
         self.assertEqual(self.offset3.rollback(d), datetime(2014, 6, 30, 17))
         self.assertEqual(self.offset4.rollback(d), datetime(2014, 6, 30, 17))
-        self.assertEqual(self.offset5.rollback(d), datetime(2014, 6, 30, 14, 30))
+        self.assertEqual(self.offset5.rollback(
+            d), datetime(2014, 6, 30, 14, 30))
         self.assertEqual(self.offset6.rollback(d), d)
         self.assertEqual(self.offset7.rollback(d), d)
 
         self.assertEqual(self._offset(5).rollback(self.d), self.d)
 
     def testRollback2(self):
-        self.assertEqual(self._offset(-3).rollback(datetime(2014, 7, 5, 15, 0)),
+        self.assertEqual(self._offset(-3)
+                         .rollback(datetime(2014, 7, 5, 15, 0)),
                          datetime(2014, 7, 4, 17, 0))
 
     def testRollforward1(self):
@@ -792,9 +811,12 @@ class TestBusinessHour(Base):
         self.assertEqual(self.offset2.rollforward(self.d), self.d)
         self.assertEqual(self.offset3.rollforward(self.d), self.d)
         self.assertEqual(self.offset4.rollforward(self.d), self.d)
-        self.assertEqual(self.offset5.rollforward(self.d), datetime(2014, 7, 1, 11, 0))
-        self.assertEqual(self.offset6.rollforward(self.d), datetime(2014, 7, 1, 20, 0))
-        self.assertEqual(self.offset7.rollforward(self.d), datetime(2014, 7, 1, 21, 30))
+        self.assertEqual(self.offset5.rollforward(
+            self.d), datetime(2014, 7, 1, 11, 0))
+        self.assertEqual(self.offset6.rollforward(
+            self.d), datetime(2014, 7, 1, 20, 0))
+        self.assertEqual(self.offset7.rollforward(
+            self.d), datetime(2014, 7, 1, 21, 30))
 
         d = datetime(2014, 7, 1, 0)
         self.assertEqual(self.offset1.rollforward(d), datetime(2014, 7, 1, 9))
@@ -808,7 +830,8 @@ class TestBusinessHour(Base):
         self.assertEqual(self._offset(5).rollforward(self.d), self.d)
 
     def testRollforward2(self):
-        self.assertEqual(self._offset(-3).rollforward(datetime(2014, 7, 5, 16, 0)),
+        self.assertEqual(self._offset(-3)
+                         .rollforward(datetime(2014, 7, 5, 16, 0)),
                          datetime(2014, 7, 7, 9))
 
     def test_roll_date_object(self):
@@ -848,7 +871,8 @@ class TestBusinessHour(Base):
                        datetime(2014, 7, 5, 23): datetime(2014, 7, 4),
                        datetime(2014, 7, 6, 10): datetime(2014, 7, 4)}))
 
-        tests.append((BusinessHour(1, normalize=True, start='17:00', end='04:00'),
+        tests.append((BusinessHour(1, normalize=True, start='17:00',
+                                   end='04:00'),
                       {datetime(2014, 7, 1, 8): datetime(2014, 7, 1),
                        datetime(2014, 7, 1, 17): datetime(2014, 7, 1),
                        datetime(2014, 7, 1, 23): datetime(2014, 7, 2),
@@ -866,38 +890,37 @@ class TestBusinessHour(Base):
     def test_onOffset(self):
         tests = []
 
-        tests.append((BusinessHour(),
-                     {datetime(2014, 7, 1, 9): True,
-                      datetime(2014, 7, 1, 8, 59): False,
-                      datetime(2014, 7, 1, 8): False,
-                      datetime(2014, 7, 1, 17): True,
-                      datetime(2014, 7, 1, 17, 1): False,
-                      datetime(2014, 7, 1, 18): False,
-                      datetime(2014, 7, 5, 9): False,
-                      datetime(2014, 7, 6, 12): False}))
+        tests.append((BusinessHour(), {datetime(2014, 7, 1, 9): True,
+                                       datetime(2014, 7, 1, 8, 59): False,
+                                       datetime(2014, 7, 1, 8): False,
+                                       datetime(2014, 7, 1, 17): True,
+                                       datetime(2014, 7, 1, 17, 1): False,
+                                       datetime(2014, 7, 1, 18): False,
+                                       datetime(2014, 7, 5, 9): False,
+                                       datetime(2014, 7, 6, 12): False}))
 
         tests.append((BusinessHour(start='10:00', end='15:00'),
-                     {datetime(2014, 7, 1, 9): False,
-                      datetime(2014, 7, 1, 10): True,
-                      datetime(2014, 7, 1, 15): True,
-                      datetime(2014, 7, 1, 15, 1): False,
-                      datetime(2014, 7, 5, 12): False,
-                      datetime(2014, 7, 6, 12): False}))
+                      {datetime(2014, 7, 1, 9): False,
+                       datetime(2014, 7, 1, 10): True,
+                       datetime(2014, 7, 1, 15): True,
+                       datetime(2014, 7, 1, 15, 1): False,
+                       datetime(2014, 7, 5, 12): False,
+                       datetime(2014, 7, 6, 12): False}))
 
         tests.append((BusinessHour(start='19:00', end='05:00'),
-                     {datetime(2014, 7, 1, 9, 0): False,
-                      datetime(2014, 7, 1, 10, 0): False,
-                      datetime(2014, 7, 1, 15): False,
-                      datetime(2014, 7, 1, 15, 1): False,
-                      datetime(2014, 7, 5, 12, 0): False,
-                      datetime(2014, 7, 6, 12, 0): False,
-                      datetime(2014, 7, 1, 19, 0): True,
-                      datetime(2014, 7, 2, 0, 0): True,
-                      datetime(2014, 7, 4, 23): True,
-                      datetime(2014, 7, 5, 1): True,
-                      datetime(2014, 7, 5, 5, 0): True,
-                      datetime(2014, 7, 6, 23, 0): False,
-                      datetime(2014, 7, 7, 3, 0): False}))
+                      {datetime(2014, 7, 1, 9, 0): False,
+                       datetime(2014, 7, 1, 10, 0): False,
+                       datetime(2014, 7, 1, 15): False,
+                       datetime(2014, 7, 1, 15, 1): False,
+                       datetime(2014, 7, 5, 12, 0): False,
+                       datetime(2014, 7, 6, 12, 0): False,
+                       datetime(2014, 7, 1, 19, 0): True,
+                       datetime(2014, 7, 2, 0, 0): True,
+                       datetime(2014, 7, 4, 23): True,
+                       datetime(2014, 7, 5, 1): True,
+                       datetime(2014, 7, 5, 5, 0): True,
+                       datetime(2014, 7, 6, 23, 0): False,
+                       datetime(2014, 7, 7, 3, 0): False}))
 
         for offset, cases in tests:
             for dt, expected in compat.iteritems(cases):
@@ -906,94 +929,164 @@ class TestBusinessHour(Base):
     def test_opening_time(self):
         tests = []
 
-        # opening time should be affected by sign of n, not by n's value and end
-        tests.append(([BusinessHour(), BusinessHour(n=2), BusinessHour(n=4),
-                       BusinessHour(end='10:00'), BusinessHour(n=2, end='4:00'),
-                       BusinessHour(n=4, end='15:00')],
-                      {datetime(2014, 7, 1, 11): (datetime(2014, 7, 2, 9), datetime(2014, 7, 1, 9)),
-                       datetime(2014, 7, 1, 18): (datetime(2014, 7, 2, 9), datetime(2014, 7, 1, 9)),
-                       datetime(2014, 7, 1, 23): (datetime(2014, 7, 2, 9), datetime(2014, 7, 1, 9)),
-                       datetime(2014, 7, 2, 8): (datetime(2014, 7, 2, 9), datetime(2014, 7, 1, 9)),
-                       # if timestamp is on opening time, next opening time is as it is
-                       datetime(2014, 7, 2, 9): (datetime(2014, 7, 2, 9), datetime(2014, 7, 2, 9)),
-                       datetime(2014, 7, 2, 10): (datetime(2014, 7, 3, 9), datetime(2014, 7, 2, 9)),
-                       # 2014-07-05 is saturday
-                       datetime(2014, 7, 5, 10): (datetime(2014, 7, 7, 9), datetime(2014, 7, 4, 9)),
-                       datetime(2014, 7, 4, 10): (datetime(2014, 7, 7, 9), datetime(2014, 7, 4, 9)),
-                       datetime(2014, 7, 4, 23): (datetime(2014, 7, 7, 9), datetime(2014, 7, 4, 9)),
-                       datetime(2014, 7, 6, 10): (datetime(2014, 7, 7, 9), datetime(2014, 7, 4, 9)),
-                       datetime(2014, 7, 7, 5): (datetime(2014, 7, 7, 9), datetime(2014, 7, 4, 9)),
-                       datetime(2014, 7, 7, 9, 1): (datetime(2014, 7, 8, 9), datetime(2014, 7, 7, 9))}))
-
-        tests.append(([BusinessHour(start='11:15'), BusinessHour(n=2, start='11:15'),
+        # opening time should be affected by sign of n, not by n's value and
+        # end
+        tests.append((
+            [BusinessHour(), BusinessHour(n=2), BusinessHour(
+                n=4), BusinessHour(end='10:00'), BusinessHour(n=2, end='4:00'),
+             BusinessHour(n=4, end='15:00')],
+            {datetime(2014, 7, 1, 11): (datetime(2014, 7, 2, 9), datetime(
+                2014, 7, 1, 9)),
+             datetime(2014, 7, 1, 18): (datetime(2014, 7, 2, 9), datetime(
+                 2014, 7, 1, 9)),
+             datetime(2014, 7, 1, 23): (datetime(2014, 7, 2, 9), datetime(
+                 2014, 7, 1, 9)),
+             datetime(2014, 7, 2, 8): (datetime(2014, 7, 2, 9), datetime(
+                 2014, 7, 1, 9)),
+             # if timestamp is on opening time, next opening time is
+             # as it is
+             datetime(2014, 7, 2, 9): (datetime(2014, 7, 2, 9), datetime(
+                 2014, 7, 2, 9)),
+             datetime(2014, 7, 2, 10): (datetime(2014, 7, 3, 9), datetime(
+                 2014, 7, 2, 9)),
+             # 2014-07-05 is saturday
+             datetime(2014, 7, 5, 10): (datetime(2014, 7, 7, 9), datetime(
+                 2014, 7, 4, 9)),
+             datetime(2014, 7, 4, 10): (datetime(2014, 7, 7, 9), datetime(
+                 2014, 7, 4, 9)),
+             datetime(2014, 7, 4, 23): (datetime(2014, 7, 7, 9), datetime(
+                 2014, 7, 4, 9)),
+             datetime(2014, 7, 6, 10): (datetime(2014, 7, 7, 9), datetime(
+                 2014, 7, 4, 9)),
+             datetime(2014, 7, 7, 5): (datetime(2014, 7, 7, 9), datetime(
+                 2014, 7, 4, 9)),
+             datetime(2014, 7, 7, 9, 1): (datetime(2014, 7, 8, 9), datetime(
+                 2014, 7, 7, 9))}))
+
+        tests.append(([BusinessHour(start='11:15'),
+                       BusinessHour(n=2, start='11:15'),
                        BusinessHour(n=3, start='11:15'),
                        BusinessHour(start='11:15', end='10:00'),
                        BusinessHour(n=2, start='11:15', end='4:00'),
                        BusinessHour(n=3, start='11:15', end='15:00')],
-                      {datetime(2014, 7, 1, 11): (datetime(2014, 7, 1, 11, 15), datetime(2014, 6, 30, 11, 15)),
-                       datetime(2014, 7, 1, 18): (datetime(2014, 7, 2, 11, 15), datetime(2014, 7, 1, 11, 15)),
-                       datetime(2014, 7, 1, 23): (datetime(2014, 7, 2, 11, 15), datetime(2014, 7, 1, 11, 15)),
-                       datetime(2014, 7, 2, 8): (datetime(2014, 7, 2, 11, 15), datetime(2014, 7, 1, 11, 15)),
-                       datetime(2014, 7, 2, 9): (datetime(2014, 7, 2, 11, 15), datetime(2014, 7, 1, 11, 15)),
-                       datetime(2014, 7, 2, 10): (datetime(2014, 7, 2, 11, 15), datetime(2014, 7, 1, 11, 15)),
-                       datetime(2014, 7, 2, 11, 15): (datetime(2014, 7, 2, 11, 15), datetime(2014, 7, 2, 11, 15)),
-                       datetime(2014, 7, 2, 11, 15, 1): (datetime(2014, 7, 3, 11, 15), datetime(2014, 7, 2, 11, 15)),
-                       datetime(2014, 7, 5, 10): (datetime(2014, 7, 7, 11, 15), datetime(2014, 7, 4, 11, 15)),
-                       datetime(2014, 7, 4, 10): (datetime(2014, 7, 4, 11, 15), datetime(2014, 7, 3, 11, 15)),
-                       datetime(2014, 7, 4, 23): (datetime(2014, 7, 7, 11, 15), datetime(2014, 7, 4, 11, 15)),
-                       datetime(2014, 7, 6, 10): (datetime(2014, 7, 7, 11, 15), datetime(2014, 7, 4, 11, 15)),
-                       datetime(2014, 7, 7, 5): (datetime(2014, 7, 7, 11, 15), datetime(2014, 7, 4, 11, 15)),
-                       datetime(2014, 7, 7, 9, 1): (datetime(2014, 7, 7, 11, 15), datetime(2014, 7, 4, 11, 15))}))
-
-        tests.append(([BusinessHour(-1), BusinessHour(n=-2), BusinessHour(n=-4),
-                       BusinessHour(n=-1, end='10:00'), BusinessHour(n=-2, end='4:00'),
+                      {datetime(2014, 7, 1, 11): (datetime(
+                          2014, 7, 1, 11, 15), datetime(2014, 6, 30, 11, 15)),
+                       datetime(2014, 7, 1, 18): (datetime(
+                           2014, 7, 2, 11, 15), datetime(2014, 7, 1, 11, 15)),
+                       datetime(2014, 7, 1, 23): (datetime(
+                           2014, 7, 2, 11, 15), datetime(2014, 7, 1, 11, 15)),
+                       datetime(2014, 7, 2, 8): (datetime(2014, 7, 2, 11, 15),
+                                                 datetime(2014, 7, 1, 11, 15)),
+                       datetime(2014, 7, 2, 9): (datetime(2014, 7, 2, 11, 15),
+                                                 datetime(2014, 7, 1, 11, 15)),
+                       datetime(2014, 7, 2, 10): (datetime(
+                           2014, 7, 2, 11, 15), datetime(2014, 7, 1, 11, 15)),
+                       datetime(2014, 7, 2, 11, 15): (datetime(
+                           2014, 7, 2, 11, 15), datetime(2014, 7, 2, 11, 15)),
+                       datetime(2014, 7, 2, 11, 15, 1): (datetime(
+                           2014, 7, 3, 11, 15), datetime(2014, 7, 2, 11, 15)),
+                       datetime(2014, 7, 5, 10): (datetime(
+                           2014, 7, 7, 11, 15), datetime(2014, 7, 4, 11, 15)),
+                       datetime(2014, 7, 4, 10): (datetime(
+                           2014, 7, 4, 11, 15), datetime(2014, 7, 3, 11, 15)),
+                       datetime(2014, 7, 4, 23): (datetime(
+                           2014, 7, 7, 11, 15), datetime(2014, 7, 4, 11, 15)),
+                       datetime(2014, 7, 6, 10): (datetime(
+                           2014, 7, 7, 11, 15), datetime(2014, 7, 4, 11, 15)),
+                       datetime(2014, 7, 7, 5): (datetime(2014, 7, 7, 11, 15),
+                                                 datetime(2014, 7, 4, 11, 15)),
+                       datetime(2014, 7, 7, 9, 1): (
+                           datetime(2014, 7, 7, 11, 15),
+                           datetime(2014, 7, 4, 11, 15))}))
+
+        tests.append(([BusinessHour(-1), BusinessHour(n=-2),
+                       BusinessHour(n=-4),
+                       BusinessHour(n=-1, end='10:00'),
+                       BusinessHour(n=-2, end='4:00'),
                        BusinessHour(n=-4, end='15:00')],
-                      {datetime(2014, 7, 1, 11): (datetime(2014, 7, 1, 9), datetime(2014, 7, 2, 9)),
-                       datetime(2014, 7, 1, 18): (datetime(2014, 7, 1, 9), datetime(2014, 7, 2, 9)),
-                       datetime(2014, 7, 1, 23): (datetime(2014, 7, 1, 9), datetime(2014, 7, 2, 9)),
-                       datetime(2014, 7, 2, 8): (datetime(2014, 7, 1, 9), datetime(2014, 7, 2, 9)),
-                       datetime(2014, 7, 2, 9): (datetime(2014, 7, 2, 9), datetime(2014, 7, 2, 9)),
-                       datetime(2014, 7, 2, 10): (datetime(2014, 7, 2, 9), datetime(2014, 7, 3, 9)),
-                       datetime(2014, 7, 5, 10): (datetime(2014, 7, 4, 9), datetime(2014, 7, 7, 9)),
-                       datetime(2014, 7, 4, 10): (datetime(2014, 7, 4, 9), datetime(2014, 7, 7, 9)),
-                       datetime(2014, 7, 4, 23): (datetime(2014, 7, 4, 9), datetime(2014, 7, 7, 9)),
-                       datetime(2014, 7, 6, 10): (datetime(2014, 7, 4, 9), datetime(2014, 7, 7, 9)),
-                       datetime(2014, 7, 7, 5): (datetime(2014, 7, 4, 9), datetime(2014, 7, 7, 9)),
-                       datetime(2014, 7, 7, 9): (datetime(2014, 7, 7, 9), datetime(2014, 7, 7, 9)),
-                       datetime(2014, 7, 7, 9, 1): (datetime(2014, 7, 7, 9), datetime(2014, 7, 8, 9))}))
+                      {datetime(2014, 7, 1, 11): (datetime(2014, 7, 1, 9),
+                                                  datetime(2014, 7, 2, 9)),
+                       datetime(2014, 7, 1, 18): (datetime(2014, 7, 1, 9),
+                                                  datetime(2014, 7, 2, 9)),
+                       datetime(2014, 7, 1, 23): (datetime(2014, 7, 1, 9),
+                                                  datetime(2014, 7, 2, 9)),
+                       datetime(2014, 7, 2, 8): (datetime(2014, 7, 1, 9),
+                                                 datetime(2014, 7, 2, 9)),
+                       datetime(2014, 7, 2, 9): (datetime(2014, 7, 2, 9),
+                                                 datetime(2014, 7, 2, 9)),
+                       datetime(2014, 7, 2, 10): (datetime(2014, 7, 2, 9),
+                                                  datetime(2014, 7, 3, 9)),
+                       datetime(2014, 7, 5, 10): (datetime(2014, 7, 4, 9),
+                                                  datetime(2014, 7, 7, 9)),
+                       datetime(2014, 7, 4, 10): (datetime(2014, 7, 4, 9),
+                                                  datetime(2014, 7, 7, 9)),
+                       datetime(2014, 7, 4, 23): (datetime(2014, 7, 4, 9),
+                                                  datetime(2014, 7, 7, 9)),
+                       datetime(2014, 7, 6, 10): (datetime(2014, 7, 4, 9),
+                                                  datetime(2014, 7, 7, 9)),
+                       datetime(2014, 7, 7, 5): (datetime(2014, 7, 4, 9),
+                                                 datetime(2014, 7, 7, 9)),
+                       datetime(2014, 7, 7, 9): (datetime(2014, 7, 7, 9),
+                                                 datetime(2014, 7, 7, 9)),
+                       datetime(2014, 7, 7, 9, 1): (datetime(2014, 7, 7, 9),
+                                                    datetime(2014, 7, 8, 9))}))
 
         tests.append(([BusinessHour(start='17:00', end='05:00'),
                        BusinessHour(n=3, start='17:00', end='03:00')],
-                      {datetime(2014, 7, 1, 11): (datetime(2014, 7, 1, 17), datetime(2014, 6, 30, 17)),
-                       datetime(2014, 7, 1, 18): (datetime(2014, 7, 2, 17), datetime(2014, 7, 1, 17)),
-                       datetime(2014, 7, 1, 23): (datetime(2014, 7, 2, 17), datetime(2014, 7, 1, 17)),
-                       datetime(2014, 7, 2, 8): (datetime(2014, 7, 2, 17), datetime(2014, 7, 1, 17)),
-                       datetime(2014, 7, 2, 9): (datetime(2014, 7, 2, 17), datetime(2014, 7, 1, 17)),
-                       datetime(2014, 7, 4, 17): (datetime(2014, 7, 4, 17), datetime(2014, 7, 4, 17)),
-                       datetime(2014, 7, 5, 10): (datetime(2014, 7, 7, 17), datetime(2014, 7, 4, 17)),
-                       datetime(2014, 7, 4, 10): (datetime(2014, 7, 4, 17), datetime(2014, 7, 3, 17)),
-                       datetime(2014, 7, 4, 23): (datetime(2014, 7, 7, 17), datetime(2014, 7, 4, 17)),
-                       datetime(2014, 7, 6, 10): (datetime(2014, 7, 7, 17), datetime(2014, 7, 4, 17)),
-                       datetime(2014, 7, 7, 5): (datetime(2014, 7, 7, 17), datetime(2014, 7, 4, 17)),
-                       datetime(2014, 7, 7, 17, 1): (datetime(2014, 7, 8, 17), datetime(2014, 7, 7, 17)),}))
+                      {datetime(2014, 7, 1, 11): (datetime(2014, 7, 1, 17),
+                                                  datetime(2014, 6, 30, 17)),
+                       datetime(2014, 7, 1, 18): (datetime(2014, 7, 2, 17),
+                                                  datetime(2014, 7, 1, 17)),
+                       datetime(2014, 7, 1, 23): (datetime(2014, 7, 2, 17),
+                                                  datetime(2014, 7, 1, 17)),
+                       datetime(2014, 7, 2, 8): (datetime(2014, 7, 2, 17),
+                                                 datetime(2014, 7, 1, 17)),
+                       datetime(2014, 7, 2, 9): (datetime(2014, 7, 2, 17),
+                                                 datetime(2014, 7, 1, 17)),
+                       datetime(2014, 7, 4, 17): (datetime(2014, 7, 4, 17),
+                                                  datetime(2014, 7, 4, 17)),
+                       datetime(2014, 7, 5, 10): (datetime(2014, 7, 7, 17),
+                                                  datetime(2014, 7, 4, 17)),
+                       datetime(2014, 7, 4, 10): (datetime(2014, 7, 4, 17),
+                                                  datetime(2014, 7, 3, 17)),
+                       datetime(2014, 7, 4, 23): (datetime(2014, 7, 7, 17),
+                                                  datetime(2014, 7, 4, 17)),
+                       datetime(2014, 7, 6, 10): (datetime(2014, 7, 7, 17),
+                                                  datetime(2014, 7, 4, 17)),
+                       datetime(2014, 7, 7, 5): (datetime(2014, 7, 7, 17),
+                                                 datetime(2014, 7, 4, 17)),
+                       datetime(2014, 7, 7, 17, 1): (datetime(
+                           2014, 7, 8, 17), datetime(2014, 7, 7, 17)), }))
 
         tests.append(([BusinessHour(-1, start='17:00', end='05:00'),
                        BusinessHour(n=-2, start='17:00', end='03:00')],
-                      {datetime(2014, 7, 1, 11): (datetime(2014, 6, 30, 17), datetime(2014, 7, 1, 17)),
-                       datetime(2014, 7, 1, 18): (datetime(2014, 7, 1, 17), datetime(2014, 7, 2, 17)),
-                       datetime(2014, 7, 1, 23): (datetime(2014, 7, 1, 17), datetime(2014, 7, 2, 17)),
-                       datetime(2014, 7, 2, 8): (datetime(2014, 7, 1, 17), datetime(2014, 7, 2, 17)),
-                       datetime(2014, 7, 2, 9): (datetime(2014, 7, 1, 17), datetime(2014, 7, 2, 17)),
-                       datetime(2014, 7, 2, 16, 59): (datetime(2014, 7, 1, 17), datetime(2014, 7, 2, 17)),
-                       datetime(2014, 7, 5, 10): (datetime(2014, 7, 4, 17), datetime(2014, 7, 7, 17)),
-                       datetime(2014, 7, 4, 10): (datetime(2014, 7, 3, 17), datetime(2014, 7, 4, 17)),
-                       datetime(2014, 7, 4, 23): (datetime(2014, 7, 4, 17), datetime(2014, 7, 7, 17)),
-                       datetime(2014, 7, 6, 10): (datetime(2014, 7, 4, 17), datetime(2014, 7, 7, 17)),
-                       datetime(2014, 7, 7, 5): (datetime(2014, 7, 4, 17), datetime(2014, 7, 7, 17)),
-                       datetime(2014, 7, 7, 18): (datetime(2014, 7, 7, 17), datetime(2014, 7, 8, 17))}))
-
-        for offsets, cases in tests:
-            for offset in offsets:
+                      {datetime(2014, 7, 1, 11): (datetime(2014, 6, 30, 17),
+                                                  datetime(2014, 7, 1, 17)),
+                       datetime(2014, 7, 1, 18): (datetime(2014, 7, 1, 17),
+                                                  datetime(2014, 7, 2, 17)),
+                       datetime(2014, 7, 1, 23): (datetime(2014, 7, 1, 17),
+                                                  datetime(2014, 7, 2, 17)),
+                       datetime(2014, 7, 2, 8): (datetime(2014, 7, 1, 17),
+                                                 datetime(2014, 7, 2, 17)),
+                       datetime(2014, 7, 2, 9): (datetime(2014, 7, 1, 17),
+                                                 datetime(2014, 7, 2, 17)),
+                       datetime(2014, 7, 2, 16, 59): (datetime(
+                           2014, 7, 1, 17), datetime(2014, 7, 2, 17)),
+                       datetime(2014, 7, 5, 10): (datetime(2014, 7, 4, 17),
+                                                  datetime(2014, 7, 7, 17)),
+                       datetime(2014, 7, 4, 10): (datetime(2014, 7, 3, 17),
+                                                  datetime(2014, 7, 4, 17)),
+                       datetime(2014, 7, 4, 23): (datetime(2014, 7, 4, 17),
+                                                  datetime(2014, 7, 7, 17)),
+                       datetime(2014, 7, 6, 10): (datetime(2014, 7, 4, 17),
+                                                  datetime(2014, 7, 7, 17)),
+                       datetime(2014, 7, 7, 5): (datetime(2014, 7, 4, 17),
+                                                 datetime(2014, 7, 7, 17)),
+                       datetime(2014, 7, 7, 18): (datetime(2014, 7, 7, 17),
+                                                  datetime(2014, 7, 8, 17))}))
+
+        for _offsets, cases in tests:
+            for offset in _offsets:
                 for dt, (exp_next, exp_prev) in compat.iteritems(cases):
                     self.assertEqual(offset._next_opening_time(dt), exp_next)
                     self.assertEqual(offset._prev_opening_time(dt), exp_prev)
@@ -1001,79 +1094,87 @@ class TestBusinessHour(Base):
     def test_apply(self):
         tests = []
 
-        tests.append((BusinessHour(),
-                      {datetime(2014, 7, 1, 11): datetime(2014, 7, 1, 12),
-                       datetime(2014, 7, 1, 13): datetime(2014, 7, 1, 14),
-                       datetime(2014, 7, 1, 15): datetime(2014, 7, 1, 16),
-                       datetime(2014, 7, 1, 19): datetime(2014, 7, 2, 10),
-                       datetime(2014, 7, 1, 16): datetime(2014, 7, 2, 9),
-                       datetime(2014, 7, 1, 16, 30, 15): datetime(2014, 7, 2, 9, 30, 15),
-                       datetime(2014, 7, 1, 17): datetime(2014, 7, 2, 10),
-                       datetime(2014, 7, 2, 11): datetime(2014, 7, 2, 12),
-                       # out of business hours
-                       datetime(2014, 7, 2, 8): datetime(2014, 7, 2, 10),
-                       datetime(2014, 7, 2, 19): datetime(2014, 7, 3, 10),
-                       datetime(2014, 7, 2, 23): datetime(2014, 7, 3, 10),
-                       datetime(2014, 7, 3, 0): datetime(2014, 7, 3, 10),
-                       # saturday
-                       datetime(2014, 7, 5, 15): datetime(2014, 7, 7, 10),
-                       datetime(2014, 7, 4, 17): datetime(2014, 7, 7, 10),
-                       datetime(2014, 7, 4, 16, 30): datetime(2014, 7, 7, 9, 30),
-                       datetime(2014, 7, 4, 16, 30, 30): datetime(2014, 7, 7, 9, 30, 30)}))
-
-        tests.append((BusinessHour(4),
-                      {datetime(2014, 7, 1, 11): datetime(2014, 7, 1, 15),
-                       datetime(2014, 7, 1, 13): datetime(2014, 7, 2, 9),
-                       datetime(2014, 7, 1, 15): datetime(2014, 7, 2, 11),
-                       datetime(2014, 7, 1, 16): datetime(2014, 7, 2, 12),
-                       datetime(2014, 7, 1, 17): datetime(2014, 7, 2, 13),
-                       datetime(2014, 7, 2, 11): datetime(2014, 7, 2, 15),
-                       datetime(2014, 7, 2, 8): datetime(2014, 7, 2, 13),
-                       datetime(2014, 7, 2, 19): datetime(2014, 7, 3, 13),
-                       datetime(2014, 7, 2, 23): datetime(2014, 7, 3, 13),
-                       datetime(2014, 7, 3, 0): datetime(2014, 7, 3, 13),
-                       datetime(2014, 7, 5, 15): datetime(2014, 7, 7, 13),
-                       datetime(2014, 7, 4, 17): datetime(2014, 7, 7, 13),
-                       datetime(2014, 7, 4, 16, 30): datetime(2014, 7, 7, 12, 30),
-                       datetime(2014, 7, 4, 16, 30, 30): datetime(2014, 7, 7, 12, 30, 30)}))
-
-        tests.append((BusinessHour(-1),
-                      {datetime(2014, 7, 1, 11): datetime(2014, 7, 1, 10),
-                       datetime(2014, 7, 1, 13): datetime(2014, 7, 1, 12),
-                       datetime(2014, 7, 1, 15): datetime(2014, 7, 1, 14),
-                       datetime(2014, 7, 1, 16): datetime(2014, 7, 1, 15),
-                       datetime(2014, 7, 1, 10): datetime(2014, 6, 30, 17),
-                       datetime(2014, 7, 1, 16, 30, 15): datetime(2014, 7, 1, 15, 30, 15),
-                       datetime(2014, 7, 1, 9, 30, 15): datetime(2014, 6, 30, 16, 30, 15),
-                       datetime(2014, 7, 1, 17): datetime(2014, 7, 1, 16),
-                       datetime(2014, 7, 1, 5): datetime(2014, 6, 30, 16),
-                       datetime(2014, 7, 2, 11): datetime(2014, 7, 2, 10),
-                       # out of business hours
-                       datetime(2014, 7, 2, 8): datetime(2014, 7, 1, 16),
-                       datetime(2014, 7, 2, 19): datetime(2014, 7, 2, 16),
-                       datetime(2014, 7, 2, 23): datetime(2014, 7, 2, 16),
-                       datetime(2014, 7, 3, 0): datetime(2014, 7, 2, 16),
-                       # saturday
-                       datetime(2014, 7, 5, 15): datetime(2014, 7, 4, 16),
-                       datetime(2014, 7, 7, 9): datetime(2014, 7, 4, 16),
-                       datetime(2014, 7, 7, 9, 30): datetime(2014, 7, 4, 16, 30),
-                       datetime(2014, 7, 7, 9, 30, 30): datetime(2014, 7, 4, 16, 30, 30)}))
-
-        tests.append((BusinessHour(-4),
-                      {datetime(2014, 7, 1, 11): datetime(2014, 6, 30, 15),
-                       datetime(2014, 7, 1, 13): datetime(2014, 6, 30, 17),
-                       datetime(2014, 7, 1, 15): datetime(2014, 7, 1, 11),
-                       datetime(2014, 7, 1, 16): datetime(2014, 7, 1, 12),
-                       datetime(2014, 7, 1, 17): datetime(2014, 7, 1, 13),
-                       datetime(2014, 7, 2, 11): datetime(2014, 7, 1, 15),
-                       datetime(2014, 7, 2, 8): datetime(2014, 7, 1, 13),
-                       datetime(2014, 7, 2, 19): datetime(2014, 7, 2, 13),
-                       datetime(2014, 7, 2, 23): datetime(2014, 7, 2, 13),
-                       datetime(2014, 7, 3, 0): datetime(2014, 7, 2, 13),
-                       datetime(2014, 7, 5, 15): datetime(2014, 7, 4, 13),
-                       datetime(2014, 7, 4, 18): datetime(2014, 7, 4, 13),
-                       datetime(2014, 7, 7, 9, 30): datetime(2014, 7, 4, 13, 30),
-                       datetime(2014, 7, 7, 9, 30, 30): datetime(2014, 7, 4, 13, 30, 30)}))
+        tests.append((
+            BusinessHour(),
+            {datetime(2014, 7, 1, 11): datetime(2014, 7, 1, 12),
+             datetime(2014, 7, 1, 13): datetime(2014, 7, 1, 14),
+             datetime(2014, 7, 1, 15): datetime(2014, 7, 1, 16),
+             datetime(2014, 7, 1, 19): datetime(2014, 7, 2, 10),
+             datetime(2014, 7, 1, 16): datetime(2014, 7, 2, 9),
+             datetime(2014, 7, 1, 16, 30, 15): datetime(2014, 7, 2, 9, 30, 15),
+             datetime(2014, 7, 1, 17): datetime(2014, 7, 2, 10),
+             datetime(2014, 7, 2, 11): datetime(2014, 7, 2, 12),
+             # out of business hours
+             datetime(2014, 7, 2, 8): datetime(2014, 7, 2, 10),
+             datetime(2014, 7, 2, 19): datetime(2014, 7, 3, 10),
+             datetime(2014, 7, 2, 23): datetime(2014, 7, 3, 10),
+             datetime(2014, 7, 3, 0): datetime(2014, 7, 3, 10),
+             # saturday
+             datetime(2014, 7, 5, 15): datetime(2014, 7, 7, 10),
+             datetime(2014, 7, 4, 17): datetime(2014, 7, 7, 10),
+             datetime(2014, 7, 4, 16, 30): datetime(2014, 7, 7, 9, 30),
+             datetime(2014, 7, 4, 16, 30, 30): datetime(2014, 7, 7, 9, 30,
+                                                        30)}))
+
+        tests.append((BusinessHour(
+            4), {datetime(2014, 7, 1, 11): datetime(2014, 7, 1, 15),
+                 datetime(2014, 7, 1, 13): datetime(2014, 7, 2, 9),
+                 datetime(2014, 7, 1, 15): datetime(2014, 7, 2, 11),
+                 datetime(2014, 7, 1, 16): datetime(2014, 7, 2, 12),
+                 datetime(2014, 7, 1, 17): datetime(2014, 7, 2, 13),
+                 datetime(2014, 7, 2, 11): datetime(2014, 7, 2, 15),
+                 datetime(2014, 7, 2, 8): datetime(2014, 7, 2, 13),
+                 datetime(2014, 7, 2, 19): datetime(2014, 7, 3, 13),
+                 datetime(2014, 7, 2, 23): datetime(2014, 7, 3, 13),
+                 datetime(2014, 7, 3, 0): datetime(2014, 7, 3, 13),
+                 datetime(2014, 7, 5, 15): datetime(2014, 7, 7, 13),
+                 datetime(2014, 7, 4, 17): datetime(2014, 7, 7, 13),
+                 datetime(2014, 7, 4, 16, 30): datetime(2014, 7, 7, 12, 30),
+                 datetime(2014, 7, 4, 16, 30, 30): datetime(2014, 7, 7, 12, 30,
+                                                            30)}))
+
+        tests.append(
+            (BusinessHour(-1),
+             {datetime(2014, 7, 1, 11): datetime(2014, 7, 1, 10),
+              datetime(2014, 7, 1, 13): datetime(2014, 7, 1, 12),
+              datetime(2014, 7, 1, 15): datetime(2014, 7, 1, 14),
+              datetime(2014, 7, 1, 16): datetime(2014, 7, 1, 15),
+              datetime(2014, 7, 1, 10): datetime(2014, 6, 30, 17),
+              datetime(2014, 7, 1, 16, 30, 15): datetime(
+                  2014, 7, 1, 15, 30, 15),
+              datetime(2014, 7, 1, 9, 30, 15): datetime(
+                  2014, 6, 30, 16, 30, 15),
+              datetime(2014, 7, 1, 17): datetime(2014, 7, 1, 16),
+              datetime(2014, 7, 1, 5): datetime(2014, 6, 30, 16),
+              datetime(2014, 7, 2, 11): datetime(2014, 7, 2, 10),
+              # out of business hours
+              datetime(2014, 7, 2, 8): datetime(2014, 7, 1, 16),
+              datetime(2014, 7, 2, 19): datetime(2014, 7, 2, 16),
+              datetime(2014, 7, 2, 23): datetime(2014, 7, 2, 16),
+              datetime(2014, 7, 3, 0): datetime(2014, 7, 2, 16),
+              # saturday
+              datetime(2014, 7, 5, 15): datetime(2014, 7, 4, 16),
+              datetime(2014, 7, 7, 9): datetime(2014, 7, 4, 16),
+              datetime(2014, 7, 7, 9, 30): datetime(2014, 7, 4, 16, 30),
+              datetime(2014, 7, 7, 9, 30, 30): datetime(2014, 7, 4, 16, 30,
+                                                        30)}))
+
+        tests.append((BusinessHour(
+            -4), {datetime(2014, 7, 1, 11): datetime(2014, 6, 30, 15),
+                  datetime(2014, 7, 1, 13): datetime(2014, 6, 30, 17),
+                  datetime(2014, 7, 1, 15): datetime(2014, 7, 1, 11),
+                  datetime(2014, 7, 1, 16): datetime(2014, 7, 1, 12),
+                  datetime(2014, 7, 1, 17): datetime(2014, 7, 1, 13),
+                  datetime(2014, 7, 2, 11): datetime(2014, 7, 1, 15),
+                  datetime(2014, 7, 2, 8): datetime(2014, 7, 1, 13),
+                  datetime(2014, 7, 2, 19): datetime(2014, 7, 2, 13),
+                  datetime(2014, 7, 2, 23): datetime(2014, 7, 2, 13),
+                  datetime(2014, 7, 3, 0): datetime(2014, 7, 2, 13),
+                  datetime(2014, 7, 5, 15): datetime(2014, 7, 4, 13),
+                  datetime(2014, 7, 4, 18): datetime(2014, 7, 4, 13),
+                  datetime(2014, 7, 7, 9, 30): datetime(2014, 7, 4, 13, 30),
+                  datetime(2014, 7, 7, 9, 30, 30): datetime(2014, 7, 4, 13, 30,
+                                                            30)}))
 
         tests.append((BusinessHour(start='13:00', end='16:00'),
                       {datetime(2014, 7, 1, 11): datetime(2014, 7, 1, 14),
@@ -1081,21 +1182,23 @@ class TestBusinessHour(Base):
                        datetime(2014, 7, 1, 15): datetime(2014, 7, 2, 13),
                        datetime(2014, 7, 1, 19): datetime(2014, 7, 2, 14),
                        datetime(2014, 7, 1, 16): datetime(2014, 7, 2, 14),
-                       datetime(2014, 7, 1, 15, 30, 15): datetime(2014, 7, 2, 13, 30, 15),
+                       datetime(2014, 7, 1, 15, 30, 15): datetime(2014, 7, 2,
+                                                                  13, 30, 15),
                        datetime(2014, 7, 5, 15): datetime(2014, 7, 7, 14),
                        datetime(2014, 7, 4, 17): datetime(2014, 7, 7, 14)}))
 
-        tests.append((BusinessHour(n=2, start='13:00', end='16:00'),
-                      {datetime(2014, 7, 1, 17): datetime(2014, 7, 2, 15),
-                       datetime(2014, 7, 2, 14): datetime(2014, 7, 3, 13),
-                       datetime(2014, 7, 2, 8): datetime(2014, 7, 2, 15),
-                       datetime(2014, 7, 2, 19): datetime(2014, 7, 3, 15),
-                       datetime(2014, 7, 2, 14, 30): datetime(2014, 7, 3, 13, 30),
-                       datetime(2014, 7, 3, 0): datetime(2014, 7, 3, 15),
-                       datetime(2014, 7, 5, 15): datetime(2014, 7, 7, 15),
-                       datetime(2014, 7, 4, 17): datetime(2014, 7, 7, 15),
-                       datetime(2014, 7, 4, 14, 30): datetime(2014, 7, 7, 13, 30),
-                       datetime(2014, 7, 4, 14, 30, 30): datetime(2014, 7, 7, 13, 30, 30)}))
+        tests.append((BusinessHour(n=2, start='13:00', end='16:00'), {
+            datetime(2014, 7, 1, 17): datetime(2014, 7, 2, 15),
+            datetime(2014, 7, 2, 14): datetime(2014, 7, 3, 13),
+            datetime(2014, 7, 2, 8): datetime(2014, 7, 2, 15),
+            datetime(2014, 7, 2, 19): datetime(2014, 7, 3, 15),
+            datetime(2014, 7, 2, 14, 30): datetime(2014, 7, 3, 13, 30),
+            datetime(2014, 7, 3, 0): datetime(2014, 7, 3, 15),
+            datetime(2014, 7, 5, 15): datetime(2014, 7, 7, 15),
+            datetime(2014, 7, 4, 17): datetime(2014, 7, 7, 15),
+            datetime(2014, 7, 4, 14, 30): datetime(2014, 7, 7, 13, 30),
+            datetime(2014, 7, 4, 14, 30, 30): datetime(2014, 7, 7, 13, 30, 30)
+        }))
 
         tests.append((BusinessHour(n=-1, start='13:00', end='16:00'),
                       {datetime(2014, 7, 2, 11): datetime(2014, 7, 1, 15),
@@ -1104,54 +1207,58 @@ class TestBusinessHour(Base):
                        datetime(2014, 7, 2, 15): datetime(2014, 7, 2, 14),
                        datetime(2014, 7, 2, 19): datetime(2014, 7, 2, 15),
                        datetime(2014, 7, 2, 16): datetime(2014, 7, 2, 15),
-                       datetime(2014, 7, 2, 13, 30, 15): datetime(2014, 7, 1, 15, 30, 15),
+                       datetime(2014, 7, 2, 13, 30, 15): datetime(2014, 7, 1,
+                                                                  15, 30, 15),
                        datetime(2014, 7, 5, 15): datetime(2014, 7, 4, 15),
                        datetime(2014, 7, 7, 11): datetime(2014, 7, 4, 15)}))
 
-        tests.append((BusinessHour(n=-3, start='10:00', end='16:00'),
-                      {datetime(2014, 7, 1, 17): datetime(2014, 7, 1, 13),
-                       datetime(2014, 7, 2, 14): datetime(2014, 7, 2, 11),
-                       datetime(2014, 7, 2, 8): datetime(2014, 7, 1, 13),
-                       datetime(2014, 7, 2, 13): datetime(2014, 7, 1, 16),
-                       datetime(2014, 7, 2, 19): datetime(2014, 7, 2, 13),
-                       datetime(2014, 7, 2, 11, 30): datetime(2014, 7, 1, 14, 30),
-                       datetime(2014, 7, 3, 0): datetime(2014, 7, 2, 13),
-                       datetime(2014, 7, 4, 10): datetime(2014, 7, 3, 13),
-                       datetime(2014, 7, 5, 15): datetime(2014, 7, 4, 13),
-                       datetime(2014, 7, 4, 16): datetime(2014, 7, 4, 13),
-                       datetime(2014, 7, 4, 12, 30): datetime(2014, 7, 3, 15, 30),
-                       datetime(2014, 7, 4, 12, 30, 30): datetime(2014, 7, 3, 15, 30, 30)}))
-
-        tests.append((BusinessHour(start='19:00', end='05:00'),
-                      {datetime(2014, 7, 1, 17): datetime(2014, 7, 1, 20),
-                       datetime(2014, 7, 2, 14): datetime(2014, 7, 2, 20),
-                       datetime(2014, 7, 2, 8): datetime(2014, 7, 2, 20),
-                       datetime(2014, 7, 2, 13): datetime(2014, 7, 2, 20),
-                       datetime(2014, 7, 2, 19): datetime(2014, 7, 2, 20),
-                       datetime(2014, 7, 2, 4, 30): datetime(2014, 7, 2, 19, 30),
-                       datetime(2014, 7, 3, 0): datetime(2014, 7, 3, 1),
-                       datetime(2014, 7, 4, 10): datetime(2014, 7, 4, 20),
-                       datetime(2014, 7, 4, 23): datetime(2014, 7, 5, 0),
-                       datetime(2014, 7, 5, 0): datetime(2014, 7, 5, 1),
-                       datetime(2014, 7, 5, 4): datetime(2014, 7, 7, 19),
-                       datetime(2014, 7, 5, 4, 30): datetime(2014, 7, 7, 19, 30),
-                       datetime(2014, 7, 5, 4, 30, 30): datetime(2014, 7, 7, 19, 30, 30)}))
-
-        tests.append((BusinessHour(n=-1, start='19:00', end='05:00'),
-                      {datetime(2014, 7, 1, 17): datetime(2014, 7, 1, 4),
-                       datetime(2014, 7, 2, 14): datetime(2014, 7, 2, 4),
-                       datetime(2014, 7, 2, 8): datetime(2014, 7, 2, 4),
-                       datetime(2014, 7, 2, 13): datetime(2014, 7, 2, 4),
-                       datetime(2014, 7, 2, 20): datetime(2014, 7, 2, 5),
-                       datetime(2014, 7, 2, 19): datetime(2014, 7, 2, 4),
-                       datetime(2014, 7, 2, 19, 30): datetime(2014, 7, 2, 4, 30),
-                       datetime(2014, 7, 3, 0): datetime(2014, 7, 2, 23),
-                       datetime(2014, 7, 3, 6): datetime(2014, 7, 3, 4),
-                       datetime(2014, 7, 4, 23): datetime(2014, 7, 4, 22),
-                       datetime(2014, 7, 5, 0): datetime(2014, 7, 4, 23),
-                       datetime(2014, 7, 5, 4): datetime(2014, 7, 5, 3),
-                       datetime(2014, 7, 7, 19, 30): datetime(2014, 7, 5, 4, 30),
-                       datetime(2014, 7, 7, 19, 30, 30): datetime(2014, 7, 5, 4, 30, 30)}))
+        tests.append((BusinessHour(n=-3, start='10:00', end='16:00'), {
+            datetime(2014, 7, 1, 17): datetime(2014, 7, 1, 13),
+            datetime(2014, 7, 2, 14): datetime(2014, 7, 2, 11),
+            datetime(2014, 7, 2, 8): datetime(2014, 7, 1, 13),
+            datetime(2014, 7, 2, 13): datetime(2014, 7, 1, 16),
+            datetime(2014, 7, 2, 19): datetime(2014, 7, 2, 13),
+            datetime(2014, 7, 2, 11, 30): datetime(2014, 7, 1, 14, 30),
+            datetime(2014, 7, 3, 0): datetime(2014, 7, 2, 13),
+            datetime(2014, 7, 4, 10): datetime(2014, 7, 3, 13),
+            datetime(2014, 7, 5, 15): datetime(2014, 7, 4, 13),
+            datetime(2014, 7, 4, 16): datetime(2014, 7, 4, 13),
+            datetime(2014, 7, 4, 12, 30): datetime(2014, 7, 3, 15, 30),
+            datetime(2014, 7, 4, 12, 30, 30): datetime(2014, 7, 3, 15, 30, 30)
+        }))
+
+        tests.append((BusinessHour(start='19:00', end='05:00'), {
+            datetime(2014, 7, 1, 17): datetime(2014, 7, 1, 20),
+            datetime(2014, 7, 2, 14): datetime(2014, 7, 2, 20),
+            datetime(2014, 7, 2, 8): datetime(2014, 7, 2, 20),
+            datetime(2014, 7, 2, 13): datetime(2014, 7, 2, 20),
+            datetime(2014, 7, 2, 19): datetime(2014, 7, 2, 20),
+            datetime(2014, 7, 2, 4, 30): datetime(2014, 7, 2, 19, 30),
+            datetime(2014, 7, 3, 0): datetime(2014, 7, 3, 1),
+            datetime(2014, 7, 4, 10): datetime(2014, 7, 4, 20),
+            datetime(2014, 7, 4, 23): datetime(2014, 7, 5, 0),
+            datetime(2014, 7, 5, 0): datetime(2014, 7, 5, 1),
+            datetime(2014, 7, 5, 4): datetime(2014, 7, 7, 19),
+            datetime(2014, 7, 5, 4, 30): datetime(2014, 7, 7, 19, 30),
+            datetime(2014, 7, 5, 4, 30, 30): datetime(2014, 7, 7, 19, 30, 30)
+        }))
+
+        tests.append((BusinessHour(n=-1, start='19:00', end='05:00'), {
+            datetime(2014, 7, 1, 17): datetime(2014, 7, 1, 4),
+            datetime(2014, 7, 2, 14): datetime(2014, 7, 2, 4),
+            datetime(2014, 7, 2, 8): datetime(2014, 7, 2, 4),
+            datetime(2014, 7, 2, 13): datetime(2014, 7, 2, 4),
+            datetime(2014, 7, 2, 20): datetime(2014, 7, 2, 5),
+            datetime(2014, 7, 2, 19): datetime(2014, 7, 2, 4),
+            datetime(2014, 7, 2, 19, 30): datetime(2014, 7, 2, 4, 30),
+            datetime(2014, 7, 3, 0): datetime(2014, 7, 2, 23),
+            datetime(2014, 7, 3, 6): datetime(2014, 7, 3, 4),
+            datetime(2014, 7, 4, 23): datetime(2014, 7, 4, 22),
+            datetime(2014, 7, 5, 0): datetime(2014, 7, 4, 23),
+            datetime(2014, 7, 5, 4): datetime(2014, 7, 5, 3),
+            datetime(2014, 7, 7, 19, 30): datetime(2014, 7, 5, 4, 30),
+            datetime(2014, 7, 7, 19, 30, 30): datetime(2014, 7, 5, 4, 30, 30)
+        }))
 
         for offset, cases in tests:
             for base, expected in compat.iteritems(cases):
@@ -1160,38 +1267,43 @@ class TestBusinessHour(Base):
     def test_apply_large_n(self):
         tests = []
 
-        tests.append((BusinessHour(40), # A week later
-                      {datetime(2014, 7, 1, 11): datetime(2014, 7, 8, 11),
-                       datetime(2014, 7, 1, 13): datetime(2014, 7, 8, 13),
-                       datetime(2014, 7, 1, 15): datetime(2014, 7, 8, 15),
-                       datetime(2014, 7, 1, 16): datetime(2014, 7, 8, 16),
-                       datetime(2014, 7, 1, 17): datetime(2014, 7, 9, 9),
-                       datetime(2014, 7, 2, 11): datetime(2014, 7, 9, 11),
-                       datetime(2014, 7, 2, 8): datetime(2014, 7, 9, 9),
-                       datetime(2014, 7, 2, 19): datetime(2014, 7, 10, 9),
-                       datetime(2014, 7, 2, 23): datetime(2014, 7, 10, 9),
-                       datetime(2014, 7, 3, 0): datetime(2014, 7, 10, 9),
-                       datetime(2014, 7, 5, 15): datetime(2014, 7, 14, 9),
-                       datetime(2014, 7, 4, 18): datetime(2014, 7, 14, 9),
-                       datetime(2014, 7, 7, 9, 30): datetime(2014, 7, 14, 9, 30),
-                       datetime(2014, 7, 7, 9, 30, 30): datetime(2014, 7, 14, 9, 30, 30)}))
-
-        tests.append((BusinessHour(-25), # 3 days and 1 hour before
-                      {datetime(2014, 7, 1, 11): datetime(2014, 6, 26, 10),
-                       datetime(2014, 7, 1, 13): datetime(2014, 6, 26, 12),
-                       datetime(2014, 7, 1, 9): datetime(2014, 6, 25, 16),
-                       datetime(2014, 7, 1, 10): datetime(2014, 6, 25, 17),
-                       datetime(2014, 7, 3, 11): datetime(2014, 6, 30, 10),
-                       datetime(2014, 7, 3, 8): datetime(2014, 6, 27, 16),
-                       datetime(2014, 7, 3, 19): datetime(2014, 6, 30, 16),
-                       datetime(2014, 7, 3, 23): datetime(2014, 6, 30, 16),
-                       datetime(2014, 7, 4, 9): datetime(2014, 6, 30, 16),
-                       datetime(2014, 7, 5, 15): datetime(2014, 7, 1, 16),
-                       datetime(2014, 7, 6, 18): datetime(2014, 7, 1, 16),
-                       datetime(2014, 7, 7, 9, 30): datetime(2014, 7, 1, 16, 30),
-                       datetime(2014, 7, 7, 10, 30, 30): datetime(2014, 7, 2, 9, 30, 30)}))
-
-        tests.append((BusinessHour(28, start='21:00', end='02:00'), # 5 days and 3 hours later
+        tests.append(
+            (BusinessHour(40),  # A week later
+             {datetime(2014, 7, 1, 11): datetime(2014, 7, 8, 11),
+              datetime(2014, 7, 1, 13): datetime(2014, 7, 8, 13),
+              datetime(2014, 7, 1, 15): datetime(2014, 7, 8, 15),
+              datetime(2014, 7, 1, 16): datetime(2014, 7, 8, 16),
+              datetime(2014, 7, 1, 17): datetime(2014, 7, 9, 9),
+              datetime(2014, 7, 2, 11): datetime(2014, 7, 9, 11),
+              datetime(2014, 7, 2, 8): datetime(2014, 7, 9, 9),
+              datetime(2014, 7, 2, 19): datetime(2014, 7, 10, 9),
+              datetime(2014, 7, 2, 23): datetime(2014, 7, 10, 9),
+              datetime(2014, 7, 3, 0): datetime(2014, 7, 10, 9),
+              datetime(2014, 7, 5, 15): datetime(2014, 7, 14, 9),
+              datetime(2014, 7, 4, 18): datetime(2014, 7, 14, 9),
+              datetime(2014, 7, 7, 9, 30): datetime(2014, 7, 14, 9, 30),
+              datetime(2014, 7, 7, 9, 30, 30): datetime(2014, 7, 14, 9, 30,
+                                                        30)}))
+
+        tests.append(
+            (BusinessHour(-25),  # 3 days and 1 hour before
+             {datetime(2014, 7, 1, 11): datetime(2014, 6, 26, 10),
+              datetime(2014, 7, 1, 13): datetime(2014, 6, 26, 12),
+              datetime(2014, 7, 1, 9): datetime(2014, 6, 25, 16),
+              datetime(2014, 7, 1, 10): datetime(2014, 6, 25, 17),
+              datetime(2014, 7, 3, 11): datetime(2014, 6, 30, 10),
+              datetime(2014, 7, 3, 8): datetime(2014, 6, 27, 16),
+              datetime(2014, 7, 3, 19): datetime(2014, 6, 30, 16),
+              datetime(2014, 7, 3, 23): datetime(2014, 6, 30, 16),
+              datetime(2014, 7, 4, 9): datetime(2014, 6, 30, 16),
+              datetime(2014, 7, 5, 15): datetime(2014, 7, 1, 16),
+              datetime(2014, 7, 6, 18): datetime(2014, 7, 1, 16),
+              datetime(2014, 7, 7, 9, 30): datetime(2014, 7, 1, 16, 30),
+              datetime(2014, 7, 7, 10, 30, 30): datetime(2014, 7, 2, 9, 30,
+                                                         30)}))
+
+        # 5 days and 3 hours later
+        tests.append((BusinessHour(28, start='21:00', end='02:00'),
                       {datetime(2014, 7, 1, 11): datetime(2014, 7, 9, 0),
                        datetime(2014, 7, 1, 22): datetime(2014, 7, 9, 1),
                        datetime(2014, 7, 1, 23): datetime(2014, 7, 9, 21),
@@ -1204,7 +1316,8 @@ class TestBusinessHour(Base):
                        datetime(2014, 7, 5, 15): datetime(2014, 7, 15, 0),
                        datetime(2014, 7, 6, 18): datetime(2014, 7, 15, 0),
                        datetime(2014, 7, 7, 1): datetime(2014, 7, 15, 0),
-                       datetime(2014, 7, 7, 23, 30): datetime(2014, 7, 15, 21, 30)}))
+                       datetime(2014, 7, 7, 23, 30): datetime(2014, 7, 15, 21,
+                                                              30)}))
 
         for offset, cases in tests:
             for base, expected in compat.iteritems(cases):
@@ -1214,16 +1327,20 @@ class TestBusinessHour(Base):
         tests = []
 
         tests.append((BusinessHour(),
-                      {Timestamp('2014-07-04 15:00') + Nano(5): Timestamp('2014-07-04 16:00') + Nano(5),
-                       Timestamp('2014-07-04 16:00') + Nano(5): Timestamp('2014-07-07 09:00') + Nano(5),
-                       Timestamp('2014-07-04 16:00') - Nano(5): Timestamp('2014-07-04 17:00') - Nano(5)
-                       }))
+                      {Timestamp('2014-07-04 15:00') + Nano(5): Timestamp(
+                          '2014-07-04 16:00') + Nano(5),
+                       Timestamp('2014-07-04 16:00') + Nano(5): Timestamp(
+                           '2014-07-07 09:00') + Nano(5),
+                       Timestamp('2014-07-04 16:00') - Nano(5): Timestamp(
+                           '2014-07-04 17:00') - Nano(5)}))
 
         tests.append((BusinessHour(-1),
-                      {Timestamp('2014-07-04 15:00') + Nano(5): Timestamp('2014-07-04 14:00') + Nano(5),
-                       Timestamp('2014-07-04 10:00') + Nano(5): Timestamp('2014-07-04 09:00') + Nano(5),
-                       Timestamp('2014-07-04 10:00') - Nano(5): Timestamp('2014-07-03 17:00') - Nano(5),
-                       }))
+                      {Timestamp('2014-07-04 15:00') + Nano(5): Timestamp(
+                          '2014-07-04 14:00') + Nano(5),
+                       Timestamp('2014-07-04 10:00') + Nano(5): Timestamp(
+                           '2014-07-04 09:00') + Nano(5),
+                       Timestamp('2014-07-04 10:00') - Nano(5): Timestamp(
+                           '2014-07-03 17:00') - Nano(5), }))
 
         for offset, cases in tests:
             for base, expected in compat.iteritems(cases):
@@ -1236,26 +1353,36 @@ class TestBusinessHour(Base):
         self.assertFalse(offset1 != offset2)
 
     def test_datetimeindex(self):
-        idx1 = DatetimeIndex(start='2014-07-04 15:00', end='2014-07-08 10:00', freq='BH')
+        idx1 = DatetimeIndex(start='2014-07-04 15:00', end='2014-07-08 10:00',
+                             freq='BH')
         idx2 = DatetimeIndex(start='2014-07-04 15:00', periods=12, freq='BH')
         idx3 = DatetimeIndex(end='2014-07-08 10:00', periods=12, freq='BH')
-        expected = DatetimeIndex(['2014-07-04 15:00', '2014-07-04 16:00', '2014-07-07 09:00',
-                                  '2014-07-07 10:00', '2014-07-07 11:00', '2014-07-07 12:00',
-                                  '2014-07-07 13:00', '2014-07-07 14:00', '2014-07-07 15:00',
-                                  '2014-07-07 16:00', '2014-07-08 09:00', '2014-07-08 10:00'],
-                                  freq='BH')
+        expected = DatetimeIndex(['2014-07-04 15:00', '2014-07-04 16:00',
+                                  '2014-07-07 09:00',
+                                  '2014-07-07 10:00', '2014-07-07 11:00',
+                                  '2014-07-07 12:00',
+                                  '2014-07-07 13:00', '2014-07-07 14:00',
+                                  '2014-07-07 15:00',
+                                  '2014-07-07 16:00', '2014-07-08 09:00',
+                                  '2014-07-08 10:00'],
+                                 freq='BH')
         for idx in [idx1, idx2, idx3]:
             tm.assert_index_equal(idx, expected)
 
-        idx1 = DatetimeIndex(start='2014-07-04 15:45', end='2014-07-08 10:45', freq='BH')
+        idx1 = DatetimeIndex(start='2014-07-04 15:45', end='2014-07-08 10:45',
+                             freq='BH')
         idx2 = DatetimeIndex(start='2014-07-04 15:45', periods=12, freq='BH')
         idx3 = DatetimeIndex(end='2014-07-08 10:45', periods=12, freq='BH')
 
-        expected = DatetimeIndex(['2014-07-04 15:45', '2014-07-04 16:45', '2014-07-07 09:45',
-                                  '2014-07-07 10:45', '2014-07-07 11:45', '2014-07-07 12:45',
-                                  '2014-07-07 13:45', '2014-07-07 14:45', '2014-07-07 15:45',
-                                  '2014-07-07 16:45', '2014-07-08 09:45', '2014-07-08 10:45'],
-                                  freq='BH')
+        expected = DatetimeIndex(['2014-07-04 15:45', '2014-07-04 16:45',
+                                  '2014-07-07 09:45',
+                                  '2014-07-07 10:45', '2014-07-07 11:45',
+                                  '2014-07-07 12:45',
+                                  '2014-07-07 13:45', '2014-07-07 14:45',
+                                  '2014-07-07 15:45',
+                                  '2014-07-07 16:45', '2014-07-08 09:45',
+                                  '2014-07-08 10:45'],
+                                 freq='BH')
         expected = idx1
         for idx in [idx1, idx2, idx3]:
             tm.assert_index_equal(idx, expected)
@@ -1322,8 +1449,7 @@ class TestCustomBusinessDay(Base):
         self.assertEqual(self.d + 10 * self.offset, self.d + CDay(10))
 
     def testMult2(self):
-        self.assertEqual(self.d + (-5 * CDay(-10)),
-                         self.d + CDay(50))
+        self.assertEqual(self.d + (-5 * CDay(-10)), self.d + CDay(50))
 
     def testRollback1(self):
         self.assertEqual(CDay(10).rollback(self.d), self.d)
@@ -1361,50 +1487,45 @@ class TestCustomBusinessDay(Base):
         tests = [(CDay(), datetime(2008, 1, 1), True),
                  (CDay(), datetime(2008, 1, 5), False)]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, d, expected in tests:
+            assertOnOffset(offset, d, expected)
 
     def test_apply(self):
         from pandas.core.datetools import cday
         tests = []
 
-        tests.append((cday,
-                      {datetime(2008, 1, 1): datetime(2008, 1, 2),
-                       datetime(2008, 1, 4): datetime(2008, 1, 7),
-                       datetime(2008, 1, 5): datetime(2008, 1, 7),
-                       datetime(2008, 1, 6): datetime(2008, 1, 7),
-                       datetime(2008, 1, 7): datetime(2008, 1, 8)}))
-
-        tests.append((2 * cday,
-                      {datetime(2008, 1, 1): datetime(2008, 1, 3),
-                       datetime(2008, 1, 4): datetime(2008, 1, 8),
-                       datetime(2008, 1, 5): datetime(2008, 1, 8),
-                       datetime(2008, 1, 6): datetime(2008, 1, 8),
-                       datetime(2008, 1, 7): datetime(2008, 1, 9)}))
-
-        tests.append((-cday,
-                      {datetime(2008, 1, 1): datetime(2007, 12, 31),
-                       datetime(2008, 1, 4): datetime(2008, 1, 3),
-                       datetime(2008, 1, 5): datetime(2008, 1, 4),
-                       datetime(2008, 1, 6): datetime(2008, 1, 4),
-                       datetime(2008, 1, 7): datetime(2008, 1, 4),
-                       datetime(2008, 1, 8): datetime(2008, 1, 7)}))
-
-        tests.append((-2 * cday,
-                      {datetime(2008, 1, 1): datetime(2007, 12, 28),
-                       datetime(2008, 1, 4): datetime(2008, 1, 2),
-                       datetime(2008, 1, 5): datetime(2008, 1, 3),
-                       datetime(2008, 1, 6): datetime(2008, 1, 3),
-                       datetime(2008, 1, 7): datetime(2008, 1, 3),
-                       datetime(2008, 1, 8): datetime(2008, 1, 4),
-                       datetime(2008, 1, 9): datetime(2008, 1, 7)}))
-
-        tests.append((CDay(0),
-                      {datetime(2008, 1, 1): datetime(2008, 1, 1),
-                       datetime(2008, 1, 4): datetime(2008, 1, 4),
-                       datetime(2008, 1, 5): datetime(2008, 1, 7),
-                       datetime(2008, 1, 6): datetime(2008, 1, 7),
-                       datetime(2008, 1, 7): datetime(2008, 1, 7)}))
+        tests.append((cday, {datetime(2008, 1, 1): datetime(2008, 1, 2),
+                             datetime(2008, 1, 4): datetime(2008, 1, 7),
+                             datetime(2008, 1, 5): datetime(2008, 1, 7),
+                             datetime(2008, 1, 6): datetime(2008, 1, 7),
+                             datetime(2008, 1, 7): datetime(2008, 1, 8)}))
+
+        tests.append((2 * cday, {datetime(2008, 1, 1): datetime(2008, 1, 3),
+                                 datetime(2008, 1, 4): datetime(2008, 1, 8),
+                                 datetime(2008, 1, 5): datetime(2008, 1, 8),
+                                 datetime(2008, 1, 6): datetime(2008, 1, 8),
+                                 datetime(2008, 1, 7): datetime(2008, 1, 9)}))
+
+        tests.append((-cday, {datetime(2008, 1, 1): datetime(2007, 12, 31),
+                              datetime(2008, 1, 4): datetime(2008, 1, 3),
+                              datetime(2008, 1, 5): datetime(2008, 1, 4),
+                              datetime(2008, 1, 6): datetime(2008, 1, 4),
+                              datetime(2008, 1, 7): datetime(2008, 1, 4),
+                              datetime(2008, 1, 8): datetime(2008, 1, 7)}))
+
+        tests.append((-2 * cday, {datetime(2008, 1, 1): datetime(2007, 12, 28),
+                                  datetime(2008, 1, 4): datetime(2008, 1, 2),
+                                  datetime(2008, 1, 5): datetime(2008, 1, 3),
+                                  datetime(2008, 1, 6): datetime(2008, 1, 3),
+                                  datetime(2008, 1, 7): datetime(2008, 1, 3),
+                                  datetime(2008, 1, 8): datetime(2008, 1, 4),
+                                  datetime(2008, 1, 9): datetime(2008, 1, 7)}))
+
+        tests.append((CDay(0), {datetime(2008, 1, 1): datetime(2008, 1, 1),
+                                datetime(2008, 1, 4): datetime(2008, 1, 4),
+                                datetime(2008, 1, 5): datetime(2008, 1, 7),
+                                datetime(2008, 1, 6): datetime(2008, 1, 7),
+                                datetime(2008, 1, 7): datetime(2008, 1, 7)}))
 
         for offset, cases in tests:
             for base, expected in compat.iteritems(cases):
@@ -1451,8 +1572,8 @@ class TestCustomBusinessDay(Base):
 
     def test_weekmask(self):
         weekmask_saudi = 'Sat Sun Mon Tue Wed'  # Thu-Fri Weekend
-        weekmask_uae = '1111001'                # Fri-Sat Weekend
-        weekmask_egypt = [1,1,1,1,0,0,1]        # Fri-Sat Weekend
+        weekmask_uae = '1111001'  # Fri-Sat Weekend
+        weekmask_egypt = [1, 1, 1, 1, 0, 0, 1]  # Fri-Sat Weekend
         bday_saudi = CDay(weekmask=weekmask_saudi)
         bday_uae = CDay(weekmask=weekmask_uae)
         bday_egypt = CDay(weekmask=weekmask_egypt)
@@ -1486,12 +1607,13 @@ class TestCustomBusinessDay(Base):
         def _check_roundtrip(obj):
             unpickled = self.round_trip_pickle(obj)
             self.assertEqual(unpickled, obj)
+
         _check_roundtrip(self.offset)
         _check_roundtrip(self.offset2)
-        _check_roundtrip(self.offset*2)
+        _check_roundtrip(self.offset * 2)
 
     def test_pickle_compat_0_14_1(self):
-        hdays = [datetime(2013,1,1) for ele in range(4)]
+        hdays = [datetime(2013, 1, 1) for ele in range(4)]
 
         pth = tm.get_data_path()
 
@@ -1499,6 +1621,7 @@ class TestCustomBusinessDay(Base):
         cday = CDay(holidays=hdays)
         self.assertEqual(cday, cday0_14_1)
 
+
 class CustomBusinessMonthBase(object):
     _multiprocess_can_split_ = True
 
@@ -1526,15 +1649,13 @@ class CustomBusinessMonthBase(object):
         self.assertRaises(Exception, off.__sub__, self.d)
         self.assertEqual(2 * off - off, off)
 
-        self.assertEqual(self.d - self.offset2,
-                         self.d + self._object(-2))
+        self.assertEqual(self.d - self.offset2, self.d + self._object(-2))
 
     def testRSub(self):
         self.assertEqual(self.d - self.offset2, (-self.offset2).apply(self.d))
 
     def testMult1(self):
-        self.assertEqual(self.d + 10 * self.offset,
-                         self.d + self._object(10))
+        self.assertEqual(self.d + 10 * self.offset, self.d + self._object(10))
 
     def testMult2(self):
         self.assertEqual(self.d + (-5 * self._object(-10)),
@@ -1549,9 +1670,10 @@ class CustomBusinessMonthBase(object):
         def _check_roundtrip(obj):
             unpickled = self.round_trip_pickle(obj)
             self.assertEqual(unpickled, obj)
+
         _check_roundtrip(self._object())
         _check_roundtrip(self._object(2))
-        _check_roundtrip(self._object()*2)
+        _check_roundtrip(self._object() * 2)
 
 
 class TestCustomBusinessMonthEnd(CustomBusinessMonthBase, Base):
@@ -1577,10 +1699,11 @@ class TestCustomBusinessMonthEnd(CustomBusinessMonthBase, Base):
 
     def testRollback2(self):
         self.assertEqual(CBMonthEnd(10).rollback(self.d),
-                         datetime(2007,12,31))
+                         datetime(2007, 12, 31))
 
     def testRollforward1(self):
-        self.assertEqual(CBMonthEnd(10).rollforward(self.d), datetime(2008,1,31))
+        self.assertEqual(CBMonthEnd(10).rollforward(
+            self.d), datetime(2008, 1, 31))
 
     def test_roll_date_object(self):
         offset = CBMonthEnd()
@@ -1604,29 +1727,25 @@ class TestCustomBusinessMonthEnd(CustomBusinessMonthBase, Base):
         tests = [(CBMonthEnd(), datetime(2008, 1, 31), True),
                  (CBMonthEnd(), datetime(2008, 1, 1), False)]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
-
+        for offset, d, expected in tests:
+            assertOnOffset(offset, d, expected)
 
     def test_apply(self):
         cbm = CBMonthEnd()
         tests = []
 
-        tests.append((cbm,
-                      {datetime(2008, 1, 1): datetime(2008, 1, 31),
-                       datetime(2008, 2, 7): datetime(2008, 2, 29)}))
+        tests.append((cbm, {datetime(2008, 1, 1): datetime(2008, 1, 31),
+                            datetime(2008, 2, 7): datetime(2008, 2, 29)}))
 
-        tests.append((2 * cbm,
-                      {datetime(2008, 1, 1): datetime(2008, 2, 29),
-                       datetime(2008, 2, 7): datetime(2008, 3, 31)}))
+        tests.append((2 * cbm, {datetime(2008, 1, 1): datetime(2008, 2, 29),
+                                datetime(2008, 2, 7): datetime(2008, 3, 31)}))
 
-        tests.append((-cbm,
-                      {datetime(2008, 1, 1): datetime(2007, 12, 31),
-                       datetime(2008, 2, 8): datetime(2008, 1, 31)}))
+        tests.append((-cbm, {datetime(2008, 1, 1): datetime(2007, 12, 31),
+                             datetime(2008, 2, 8): datetime(2008, 1, 31)}))
 
-        tests.append((-2 * cbm,
-                      {datetime(2008, 1, 1): datetime(2007, 11, 30),
-                       datetime(2008, 2, 9): datetime(2007, 12, 31)}))
+        tests.append((-2 * cbm, {datetime(2008, 1, 1): datetime(2007, 11, 30),
+                                 datetime(2008, 2, 9): datetime(2007, 12, 31)}
+                      ))
 
         tests.append((CBMonthEnd(0),
                       {datetime(2008, 1, 1): datetime(2008, 1, 31),
@@ -1660,18 +1779,19 @@ class TestCustomBusinessMonthEnd(CustomBusinessMonthBase, Base):
         holidays = ['2012-01-31', datetime(2012, 2, 28),
                     np.datetime64('2012-02-29')]
         bm_offset = CBMonthEnd(holidays=holidays)
-        dt = datetime(2012,1,1)
-        self.assertEqual(dt + bm_offset,datetime(2012,1,30))
-        self.assertEqual(dt + 2*bm_offset,datetime(2012,2,27))
+        dt = datetime(2012, 1, 1)
+        self.assertEqual(dt + bm_offset, datetime(2012, 1, 30))
+        self.assertEqual(dt + 2 * bm_offset, datetime(2012, 2, 27))
 
     def test_datetimeindex(self):
         from pandas.tseries.holiday import USFederalHolidayCalendar
         hcal = USFederalHolidayCalendar()
         freq = CBMonthEnd(calendar=hcal)
 
-        self.assertEqual(DatetimeIndex(start='20120101',end='20130101',
+        self.assertEqual(DatetimeIndex(start='20120101', end='20130101',
                                        freq=freq).tolist()[0],
-                         datetime(2012,1,31))
+                         datetime(2012, 1, 31))
+
 
 class TestCustomBusinessMonthBegin(CustomBusinessMonthBase, Base):
     _object = CBMonthBegin
@@ -1696,10 +1816,11 @@ class TestCustomBusinessMonthBegin(CustomBusinessMonthBase, Base):
 
     def testRollback2(self):
         self.assertEqual(CBMonthBegin(10).rollback(self.d),
-                         datetime(2008,1,1))
+                         datetime(2008, 1, 1))
 
     def testRollforward1(self):
-        self.assertEqual(CBMonthBegin(10).rollforward(self.d), datetime(2008,1,1))
+        self.assertEqual(CBMonthBegin(10).rollforward(
+            self.d), datetime(2008, 1, 1))
 
     def test_roll_date_object(self):
         offset = CBMonthBegin()
@@ -1723,29 +1844,24 @@ class TestCustomBusinessMonthBegin(CustomBusinessMonthBase, Base):
         tests = [(CBMonthBegin(), datetime(2008, 1, 1), True),
                  (CBMonthBegin(), datetime(2008, 1, 31), False)]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
-
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
     def test_apply(self):
         cbm = CBMonthBegin()
         tests = []
 
-        tests.append((cbm,
-                      {datetime(2008, 1, 1): datetime(2008, 2, 1),
-                       datetime(2008, 2, 7): datetime(2008, 3, 3)}))
+        tests.append((cbm, {datetime(2008, 1, 1): datetime(2008, 2, 1),
+                            datetime(2008, 2, 7): datetime(2008, 3, 3)}))
 
-        tests.append((2 * cbm,
-                      {datetime(2008, 1, 1): datetime(2008, 3, 3),
-                       datetime(2008, 2, 7): datetime(2008, 4, 1)}))
+        tests.append((2 * cbm, {datetime(2008, 1, 1): datetime(2008, 3, 3),
+                                datetime(2008, 2, 7): datetime(2008, 4, 1)}))
 
-        tests.append((-cbm,
-                      {datetime(2008, 1, 1): datetime(2007, 12, 3),
-                       datetime(2008, 2, 8): datetime(2008, 2, 1)}))
+        tests.append((-cbm, {datetime(2008, 1, 1): datetime(2007, 12, 3),
+                             datetime(2008, 2, 8): datetime(2008, 2, 1)}))
 
-        tests.append((-2 * cbm,
-                      {datetime(2008, 1, 1): datetime(2007, 11, 1),
-                       datetime(2008, 2, 9): datetime(2008, 1, 1)}))
+        tests.append((-2 * cbm, {datetime(2008, 1, 1): datetime(2007, 11, 1),
+                                 datetime(2008, 2, 9): datetime(2008, 1, 1)}))
 
         tests.append((CBMonthBegin(0),
                       {datetime(2008, 1, 1): datetime(2008, 1, 1),
@@ -1779,16 +1895,16 @@ class TestCustomBusinessMonthBegin(CustomBusinessMonthBase, Base):
         holidays = ['2012-02-01', datetime(2012, 2, 2),
                     np.datetime64('2012-03-01')]
         bm_offset = CBMonthBegin(holidays=holidays)
-        dt = datetime(2012,1,1)
-        self.assertEqual(dt + bm_offset,datetime(2012,1,2))
-        self.assertEqual(dt + 2*bm_offset,datetime(2012,2,3))
+        dt = datetime(2012, 1, 1)
+        self.assertEqual(dt + bm_offset, datetime(2012, 1, 2))
+        self.assertEqual(dt + 2 * bm_offset, datetime(2012, 2, 3))
 
     def test_datetimeindex(self):
         hcal = USFederalHolidayCalendar()
         cbmb = CBMonthBegin(calendar=hcal)
         self.assertEqual(DatetimeIndex(start='20120101', end='20130101',
                                        freq=cbmb).tolist()[0],
-                         datetime(2012,1,3))
+                         datetime(2012, 1, 3))
 
 
 def assertOnOffset(offset, date, expected):
@@ -1804,7 +1920,8 @@ class TestWeek(Base):
     def test_repr(self):
         self.assertEqual(repr(Week(weekday=0)), "<Week: weekday=0>")
         self.assertEqual(repr(Week(n=-1, weekday=0)), "<-1 * Week: weekday=0>")
-        self.assertEqual(repr(Week(n=-2, weekday=0)), "<-2 * Weeks: weekday=0>")
+        self.assertEqual(repr(Week(n=-2, weekday=0)),
+                         "<-2 * Weeks: weekday=0>")
 
     def test_corner(self):
         self.assertRaises(ValueError, Week, weekday=7)
@@ -1873,14 +1990,20 @@ class TestWeekOfMonth(Base):
     _offset = WeekOfMonth
 
     def test_constructor(self):
-        assertRaisesRegexp(ValueError, "^N cannot be 0", WeekOfMonth, n=0, week=1, weekday=1)
-        assertRaisesRegexp(ValueError, "^Week", WeekOfMonth, n=1, week=4, weekday=0)
-        assertRaisesRegexp(ValueError, "^Week", WeekOfMonth, n=1, week=-1, weekday=0)
-        assertRaisesRegexp(ValueError, "^Day", WeekOfMonth, n=1, week=0, weekday=-1)
-        assertRaisesRegexp(ValueError, "^Day", WeekOfMonth, n=1, week=0, weekday=7)
+        assertRaisesRegexp(ValueError, "^N cannot be 0", WeekOfMonth, n=0,
+                           week=1, weekday=1)
+        assertRaisesRegexp(ValueError, "^Week", WeekOfMonth, n=1, week=4,
+                           weekday=0)
+        assertRaisesRegexp(ValueError, "^Week", WeekOfMonth, n=1, week=-1,
+                           weekday=0)
+        assertRaisesRegexp(ValueError, "^Day", WeekOfMonth, n=1, week=0,
+                           weekday=-1)
+        assertRaisesRegexp(ValueError, "^Day", WeekOfMonth, n=1, week=0,
+                           weekday=7)
 
     def test_repr(self):
-        self.assertEqual(repr(WeekOfMonth(weekday=1,week=2)), "<WeekOfMonth: week=2, weekday=1>")
+        self.assertEqual(repr(WeekOfMonth(weekday=1, week=2)),
+                         "<WeekOfMonth: week=2, weekday=1>")
 
     def test_offset(self):
         date1 = datetime(2011, 1, 4)  # 1st Tuesday of Month
@@ -1924,9 +2047,9 @@ class TestWeekOfMonth(Base):
             (2, 2, 1, date4, datetime(2011, 3, 15)),
         ]
 
-        for n, week, weekday, date, expected in test_cases:
+        for n, week, weekday, dt, expected in test_cases:
             offset = WeekOfMonth(n, week=week, weekday=weekday)
-            assertEq(offset, date, expected)
+            assertEq(offset, dt, expected)
 
         # try subtracting
         result = datetime(2011, 2, 1) - WeekOfMonth(week=1, weekday=2)
@@ -1944,24 +2067,26 @@ class TestWeekOfMonth(Base):
             (0, 1, datetime(2011, 2, 8), False),
         ]
 
-        for week, weekday, date, expected in test_cases:
+        for week, weekday, dt, expected in test_cases:
             offset = WeekOfMonth(week=week, weekday=weekday)
-            self.assertEqual(offset.onOffset(date), expected)
+            self.assertEqual(offset.onOffset(dt), expected)
+
 
 class TestLastWeekOfMonth(Base):
     _offset = LastWeekOfMonth
 
     def test_constructor(self):
-        assertRaisesRegexp(ValueError, "^N cannot be 0", \
-                           LastWeekOfMonth, n=0, weekday=1)
+        assertRaisesRegexp(ValueError, "^N cannot be 0", LastWeekOfMonth, n=0,
+                           weekday=1)
 
-        assertRaisesRegexp(ValueError, "^Day", LastWeekOfMonth, n=1, weekday=-1)
+        assertRaisesRegexp(ValueError, "^Day", LastWeekOfMonth, n=1,
+                           weekday=-1)
         assertRaisesRegexp(ValueError, "^Day", LastWeekOfMonth, n=1, weekday=7)
 
     def test_offset(self):
-        #### Saturday
-        last_sat = datetime(2013,8,31)
-        next_sat = datetime(2013,9,28)
+        # Saturday
+        last_sat = datetime(2013, 8, 31)
+        next_sat = datetime(2013, 9, 28)
         offset_sat = LastWeekOfMonth(n=1, weekday=5)
 
         one_day_before = (last_sat + timedelta(days=-1))
@@ -1970,14 +2095,14 @@ class TestLastWeekOfMonth(Base):
         one_day_after = (last_sat + timedelta(days=+1))
         self.assertEqual(one_day_after + offset_sat, next_sat)
 
-        #Test On that day
+        # Test On that day
         self.assertEqual(last_sat + offset_sat, next_sat)
 
-        #### Thursday
+        # Thursday
 
         offset_thur = LastWeekOfMonth(n=1, weekday=3)
-        last_thurs = datetime(2013,1,31)
-        next_thurs = datetime(2013,2,28)
+        last_thurs = datetime(2013, 1, 31)
+        next_thurs = datetime(2013, 2, 28)
 
         one_day_before = last_thurs + timedelta(days=-1)
         self.assertEqual(one_day_before + offset_thur, last_thurs)
@@ -1995,14 +2120,15 @@ class TestLastWeekOfMonth(Base):
         self.assertEqual(two_after + offset_thur, next_thurs)
 
         offset_sunday = LastWeekOfMonth(n=1, weekday=WeekDay.SUN)
-        self.assertEqual(datetime(2013,7,31) + offset_sunday, datetime(2013,8,25))
+        self.assertEqual(datetime(2013, 7, 31) +
+                         offset_sunday, datetime(2013, 8, 25))
 
     def test_onOffset(self):
         test_cases = [
             (WeekDay.SUN, datetime(2013, 1, 27), True),
             (WeekDay.SAT, datetime(2013, 3, 30), True),
-            (WeekDay.MON, datetime(2013, 2, 18), False), #Not the last Mon
-            (WeekDay.SUN, datetime(2013, 2, 25), False), #Not a SUN
+            (WeekDay.MON, datetime(2013, 2, 18), False),  # Not the last Mon
+            (WeekDay.SUN, datetime(2013, 2, 25), False),  # Not a SUN
             (WeekDay.MON, datetime(2013, 2, 25), True),
             (WeekDay.SAT, datetime(2013, 11, 30), True),
 
@@ -2015,9 +2141,9 @@ class TestLastWeekOfMonth(Base):
             (WeekDay.SAT, datetime(2019, 8, 31), True),
         ]
 
-        for weekday, date, expected in test_cases:
+        for weekday, dt, expected in test_cases:
             offset = LastWeekOfMonth(weekday=weekday)
-            self.assertEqual(offset.onOffset(date), expected, msg=date)
+            self.assertEqual(offset.onOffset(dt), expected, msg=date)
 
 
 class TestBMonthBegin(Base):
@@ -2027,13 +2153,13 @@ class TestBMonthBegin(Base):
         tests = []
 
         tests.append((BMonthBegin(),
-                     {datetime(2008, 1, 1): datetime(2008, 2, 1),
-                      datetime(2008, 1, 31): datetime(2008, 2, 1),
-                      datetime(2006, 12, 29): datetime(2007, 1, 1),
-                      datetime(2006, 12, 31): datetime(2007, 1, 1),
-                      datetime(2006, 9, 1): datetime(2006, 10, 2),
-                      datetime(2007, 1, 1): datetime(2007, 2, 1),
-                      datetime(2006, 12, 1): datetime(2007, 1, 1)}))
+                      {datetime(2008, 1, 1): datetime(2008, 2, 1),
+                       datetime(2008, 1, 31): datetime(2008, 2, 1),
+                       datetime(2006, 12, 29): datetime(2007, 1, 1),
+                       datetime(2006, 12, 31): datetime(2007, 1, 1),
+                       datetime(2006, 9, 1): datetime(2006, 10, 2),
+                       datetime(2007, 1, 1): datetime(2007, 2, 1),
+                       datetime(2006, 12, 1): datetime(2007, 1, 1)}))
 
         tests.append((BMonthBegin(0),
                       {datetime(2008, 1, 1): datetime(2008, 1, 1),
@@ -2044,22 +2170,22 @@ class TestBMonthBegin(Base):
                        datetime(2006, 9, 15): datetime(2006, 10, 2)}))
 
         tests.append((BMonthBegin(2),
-                     {datetime(2008, 1, 1): datetime(2008, 3, 3),
-                      datetime(2008, 1, 15): datetime(2008, 3, 3),
-                      datetime(2006, 12, 29): datetime(2007, 2, 1),
-                      datetime(2006, 12, 31): datetime(2007, 2, 1),
-                      datetime(2007, 1, 1): datetime(2007, 3, 1),
-                      datetime(2006, 11, 1): datetime(2007, 1, 1)}))
+                      {datetime(2008, 1, 1): datetime(2008, 3, 3),
+                       datetime(2008, 1, 15): datetime(2008, 3, 3),
+                       datetime(2006, 12, 29): datetime(2007, 2, 1),
+                       datetime(2006, 12, 31): datetime(2007, 2, 1),
+                       datetime(2007, 1, 1): datetime(2007, 3, 1),
+                       datetime(2006, 11, 1): datetime(2007, 1, 1)}))
 
         tests.append((BMonthBegin(-1),
-                     {datetime(2007, 1, 1): datetime(2006, 12, 1),
-                      datetime(2008, 6, 30): datetime(2008, 6, 2),
-                      datetime(2008, 6, 1): datetime(2008, 5, 1),
-                      datetime(2008, 3, 10): datetime(2008, 3, 3),
-                      datetime(2008, 12, 31): datetime(2008, 12, 1),
-                      datetime(2006, 12, 29): datetime(2006, 12, 1),
-                      datetime(2006, 12, 30): datetime(2006, 12, 1),
-                      datetime(2007, 1, 1): datetime(2006, 12, 1)}))
+                      {datetime(2007, 1, 1): datetime(2006, 12, 1),
+                       datetime(2008, 6, 30): datetime(2008, 6, 2),
+                       datetime(2008, 6, 1): datetime(2008, 5, 1),
+                       datetime(2008, 3, 10): datetime(2008, 3, 3),
+                       datetime(2008, 12, 31): datetime(2008, 12, 1),
+                       datetime(2006, 12, 29): datetime(2006, 12, 1),
+                       datetime(2006, 12, 30): datetime(2006, 12, 1),
+                       datetime(2007, 1, 1): datetime(2006, 12, 1)}))
 
         for offset, cases in tests:
             for base, expected in compat.iteritems(cases):
@@ -2072,8 +2198,8 @@ class TestBMonthBegin(Base):
                  (BMonthBegin(), datetime(2001, 4, 2), True),
                  (BMonthBegin(), datetime(2008, 3, 3), True)]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
     def test_offsets_compare_equal(self):
         # root cause of #456
@@ -2089,12 +2215,12 @@ class TestBMonthEnd(Base):
         tests = []
 
         tests.append((BMonthEnd(),
-                     {datetime(2008, 1, 1): datetime(2008, 1, 31),
-                      datetime(2008, 1, 31): datetime(2008, 2, 29),
-                      datetime(2006, 12, 29): datetime(2007, 1, 31),
-                      datetime(2006, 12, 31): datetime(2007, 1, 31),
-                      datetime(2007, 1, 1): datetime(2007, 1, 31),
-                      datetime(2006, 12, 1): datetime(2006, 12, 29)}))
+                      {datetime(2008, 1, 1): datetime(2008, 1, 31),
+                       datetime(2008, 1, 31): datetime(2008, 2, 29),
+                       datetime(2006, 12, 29): datetime(2007, 1, 31),
+                       datetime(2006, 12, 31): datetime(2007, 1, 31),
+                       datetime(2007, 1, 1): datetime(2007, 1, 31),
+                       datetime(2006, 12, 1): datetime(2006, 12, 29)}))
 
         tests.append((BMonthEnd(0),
                       {datetime(2008, 1, 1): datetime(2008, 1, 31),
@@ -2104,20 +2230,20 @@ class TestBMonthEnd(Base):
                        datetime(2007, 1, 1): datetime(2007, 1, 31)}))
 
         tests.append((BMonthEnd(2),
-                     {datetime(2008, 1, 1): datetime(2008, 2, 29),
-                      datetime(2008, 1, 31): datetime(2008, 3, 31),
-                      datetime(2006, 12, 29): datetime(2007, 2, 28),
-                      datetime(2006, 12, 31): datetime(2007, 2, 28),
-                      datetime(2007, 1, 1): datetime(2007, 2, 28),
-                      datetime(2006, 11, 1): datetime(2006, 12, 29)}))
+                      {datetime(2008, 1, 1): datetime(2008, 2, 29),
+                       datetime(2008, 1, 31): datetime(2008, 3, 31),
+                       datetime(2006, 12, 29): datetime(2007, 2, 28),
+                       datetime(2006, 12, 31): datetime(2007, 2, 28),
+                       datetime(2007, 1, 1): datetime(2007, 2, 28),
+                       datetime(2006, 11, 1): datetime(2006, 12, 29)}))
 
         tests.append((BMonthEnd(-1),
-                     {datetime(2007, 1, 1): datetime(2006, 12, 29),
-                      datetime(2008, 6, 30): datetime(2008, 5, 30),
-                      datetime(2008, 12, 31): datetime(2008, 11, 28),
-                      datetime(2006, 12, 29): datetime(2006, 11, 30),
-                      datetime(2006, 12, 30): datetime(2006, 12, 29),
-                      datetime(2007, 1, 1): datetime(2006, 12, 29)}))
+                      {datetime(2007, 1, 1): datetime(2006, 12, 29),
+                       datetime(2008, 6, 30): datetime(2008, 5, 30),
+                       datetime(2008, 12, 31): datetime(2008, 11, 28),
+                       datetime(2006, 12, 29): datetime(2006, 11, 30),
+                       datetime(2006, 12, 30): datetime(2006, 12, 29),
+                       datetime(2007, 1, 1): datetime(2006, 12, 29)}))
 
         for offset, cases in tests:
             for base, expected in compat.iteritems(cases):
@@ -2135,8 +2261,8 @@ class TestBMonthEnd(Base):
         tests = [(BMonthEnd(), datetime(2007, 12, 31), True),
                  (BMonthEnd(), datetime(2008, 1, 1), False)]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
     def test_offsets_compare_equal(self):
         # root cause of #456
@@ -2154,11 +2280,11 @@ class TestMonthBegin(Base):
         # NOTE: I'm not entirely happy with the logic here for Begin -ss
         # see thread 'offset conventions' on the ML
         tests.append((MonthBegin(),
-                     {datetime(2008, 1, 31): datetime(2008, 2, 1),
-                      datetime(2008, 2, 1): datetime(2008, 3, 1),
-                      datetime(2006, 12, 31): datetime(2007, 1, 1),
-                      datetime(2006, 12, 1): datetime(2007, 1, 1),
-                      datetime(2007, 1, 31): datetime(2007, 2, 1)}))
+                      {datetime(2008, 1, 31): datetime(2008, 2, 1),
+                       datetime(2008, 2, 1): datetime(2008, 3, 1),
+                       datetime(2006, 12, 31): datetime(2007, 1, 1),
+                       datetime(2006, 12, 1): datetime(2007, 1, 1),
+                       datetime(2007, 1, 31): datetime(2007, 2, 1)}))
 
         tests.append((MonthBegin(0),
                       {datetime(2008, 1, 31): datetime(2008, 2, 1),
@@ -2167,19 +2293,19 @@ class TestMonthBegin(Base):
                        datetime(2007, 1, 31): datetime(2007, 2, 1)}))
 
         tests.append((MonthBegin(2),
-                     {datetime(2008, 2, 29): datetime(2008, 4, 1),
-                      datetime(2008, 1, 31): datetime(2008, 3, 1),
-                      datetime(2006, 12, 31): datetime(2007, 2, 1),
-                      datetime(2007, 12, 28): datetime(2008, 2, 1),
-                      datetime(2007, 1, 1): datetime(2007, 3, 1),
-                      datetime(2006, 11, 1): datetime(2007, 1, 1)}))
+                      {datetime(2008, 2, 29): datetime(2008, 4, 1),
+                       datetime(2008, 1, 31): datetime(2008, 3, 1),
+                       datetime(2006, 12, 31): datetime(2007, 2, 1),
+                       datetime(2007, 12, 28): datetime(2008, 2, 1),
+                       datetime(2007, 1, 1): datetime(2007, 3, 1),
+                       datetime(2006, 11, 1): datetime(2007, 1, 1)}))
 
         tests.append((MonthBegin(-1),
-                     {datetime(2007, 1, 1): datetime(2006, 12, 1),
-                      datetime(2008, 5, 31): datetime(2008, 5, 1),
-                      datetime(2008, 12, 31): datetime(2008, 12, 1),
-                      datetime(2006, 12, 29): datetime(2006, 12, 1),
-                      datetime(2006, 1, 2): datetime(2006, 1, 1)}))
+                      {datetime(2007, 1, 1): datetime(2006, 12, 1),
+                       datetime(2008, 5, 31): datetime(2008, 5, 1),
+                       datetime(2008, 12, 31): datetime(2008, 12, 1),
+                       datetime(2006, 12, 29): datetime(2006, 12, 1),
+                       datetime(2006, 1, 2): datetime(2006, 1, 1)}))
 
         for offset, cases in tests:
             for base, expected in compat.iteritems(cases):
@@ -2193,12 +2319,12 @@ class TestMonthEnd(Base):
         tests = []
 
         tests.append((MonthEnd(),
-                     {datetime(2008, 1, 1): datetime(2008, 1, 31),
-                      datetime(2008, 1, 31): datetime(2008, 2, 29),
-                      datetime(2006, 12, 29): datetime(2006, 12, 31),
-                      datetime(2006, 12, 31): datetime(2007, 1, 31),
-                      datetime(2007, 1, 1): datetime(2007, 1, 31),
-                      datetime(2006, 12, 1): datetime(2006, 12, 31)}))
+                      {datetime(2008, 1, 1): datetime(2008, 1, 31),
+                       datetime(2008, 1, 31): datetime(2008, 2, 29),
+                       datetime(2006, 12, 29): datetime(2006, 12, 31),
+                       datetime(2006, 12, 31): datetime(2007, 1, 31),
+                       datetime(2007, 1, 1): datetime(2007, 1, 31),
+                       datetime(2006, 12, 1): datetime(2006, 12, 31)}))
 
         tests.append((MonthEnd(0),
                       {datetime(2008, 1, 1): datetime(2008, 1, 31),
@@ -2208,20 +2334,20 @@ class TestMonthEnd(Base):
                        datetime(2007, 1, 1): datetime(2007, 1, 31)}))
 
         tests.append((MonthEnd(2),
-                     {datetime(2008, 1, 1): datetime(2008, 2, 29),
-                      datetime(2008, 1, 31): datetime(2008, 3, 31),
-                      datetime(2006, 12, 29): datetime(2007, 1, 31),
-                      datetime(2006, 12, 31): datetime(2007, 2, 28),
-                      datetime(2007, 1, 1): datetime(2007, 2, 28),
-                      datetime(2006, 11, 1): datetime(2006, 12, 31)}))
+                      {datetime(2008, 1, 1): datetime(2008, 2, 29),
+                       datetime(2008, 1, 31): datetime(2008, 3, 31),
+                       datetime(2006, 12, 29): datetime(2007, 1, 31),
+                       datetime(2006, 12, 31): datetime(2007, 2, 28),
+                       datetime(2007, 1, 1): datetime(2007, 2, 28),
+                       datetime(2006, 11, 1): datetime(2006, 12, 31)}))
 
         tests.append((MonthEnd(-1),
-                     {datetime(2007, 1, 1): datetime(2006, 12, 31),
-                      datetime(2008, 6, 30): datetime(2008, 5, 31),
-                      datetime(2008, 12, 31): datetime(2008, 11, 30),
-                      datetime(2006, 12, 29): datetime(2006, 11, 30),
-                      datetime(2006, 12, 30): datetime(2006, 11, 30),
-                      datetime(2007, 1, 1): datetime(2006, 12, 31)}))
+                      {datetime(2007, 1, 1): datetime(2006, 12, 31),
+                       datetime(2008, 6, 30): datetime(2008, 5, 31),
+                       datetime(2008, 12, 31): datetime(2008, 11, 30),
+                       datetime(2006, 12, 29): datetime(2006, 11, 30),
+                       datetime(2006, 12, 30): datetime(2006, 11, 30),
+                       datetime(2007, 1, 1): datetime(2006, 12, 31)}))
 
         for offset, cases in tests:
             for base, expected in compat.iteritems(cases):
@@ -2250,17 +2376,20 @@ class TestMonthEnd(Base):
         tests = [(MonthEnd(), datetime(2007, 12, 31), True),
                  (MonthEnd(), datetime(2008, 1, 1), False)]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
 
 class TestBQuarterBegin(Base):
     _offset = BQuarterBegin
 
     def test_repr(self):
-        self.assertEqual(repr(BQuarterBegin()),"<BusinessQuarterBegin: startingMonth=3>")
-        self.assertEqual(repr(BQuarterBegin(startingMonth=3)), "<BusinessQuarterBegin: startingMonth=3>")
-        self.assertEqual(repr(BQuarterBegin(startingMonth=1)), "<BusinessQuarterBegin: startingMonth=1>")
+        self.assertEqual(repr(BQuarterBegin()),
+                         "<BusinessQuarterBegin: startingMonth=3>")
+        self.assertEqual(repr(BQuarterBegin(startingMonth=3)),
+                         "<BusinessQuarterBegin: startingMonth=3>")
+        self.assertEqual(repr(BQuarterBegin(startingMonth=1)),
+                         "<BusinessQuarterBegin: startingMonth=1>")
 
     def test_isAnchored(self):
         self.assertTrue(BQuarterBegin(startingMonth=1).isAnchored())
@@ -2349,9 +2478,12 @@ class TestBQuarterEnd(Base):
     _offset = BQuarterEnd
 
     def test_repr(self):
-        self.assertEqual(repr(BQuarterEnd()),"<BusinessQuarterEnd: startingMonth=3>")
-        self.assertEqual(repr(BQuarterEnd(startingMonth=3)), "<BusinessQuarterEnd: startingMonth=3>")
-        self.assertEqual(repr(BQuarterEnd(startingMonth=1)), "<BusinessQuarterEnd: startingMonth=1>")
+        self.assertEqual(repr(BQuarterEnd()),
+                         "<BusinessQuarterEnd: startingMonth=3>")
+        self.assertEqual(repr(BQuarterEnd(startingMonth=3)),
+                         "<BusinessQuarterEnd: startingMonth=3>")
+        self.assertEqual(repr(BQuarterEnd(startingMonth=1)),
+                         "<BusinessQuarterEnd: startingMonth=1>")
 
     def test_isAnchored(self):
         self.assertTrue(BQuarterEnd(startingMonth=1).isAnchored())
@@ -2450,30 +2582,37 @@ class TestBQuarterEnd(Base):
             (BQuarterEnd(1, startingMonth=3), datetime(2007, 6, 30), False),
         ]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
+
 
 def makeFY5253LastOfMonthQuarter(*args, **kwds):
     return FY5253Quarter(*args, variation="last", **kwds)
 
+
 def makeFY5253NearestEndMonthQuarter(*args, **kwds):
     return FY5253Quarter(*args, variation="nearest", **kwds)
 
+
 def makeFY5253NearestEndMonth(*args, **kwds):
     return FY5253(*args, variation="nearest", **kwds)
 
+
 def makeFY5253LastOfMonth(*args, **kwds):
     return FY5253(*args, variation="last", **kwds)
 
-class TestFY5253LastOfMonth(Base):
 
+class TestFY5253LastOfMonth(Base):
     def test_onOffset(self):
 
-        offset_lom_sat_aug = makeFY5253LastOfMonth(1, startingMonth=8, weekday=WeekDay.SAT)
-        offset_lom_sat_sep = makeFY5253LastOfMonth(1, startingMonth=9, weekday=WeekDay.SAT)
+        offset_lom_sat_aug = makeFY5253LastOfMonth(1, startingMonth=8,
+                                                   weekday=WeekDay.SAT)
+        offset_lom_sat_sep = makeFY5253LastOfMonth(1, startingMonth=9,
+                                                   weekday=WeekDay.SAT)
 
         tests = [
-            #From Wikipedia (see: http://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar#Last_Saturday_of_the_month_at_fiscal_year_end)
+            # From Wikipedia (see:
+            # http://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar#Last_Saturday_of_the_month_at_fiscal_year_end)
             (offset_lom_sat_aug, datetime(2006, 8, 26), True),
             (offset_lom_sat_aug, datetime(2007, 8, 25), True),
             (offset_lom_sat_aug, datetime(2008, 8, 30), True),
@@ -2504,19 +2643,23 @@ class TestFY5253LastOfMonth(Base):
             (offset_lom_sat_aug, datetime(2011, 8, 26), False),
             (offset_lom_sat_aug, datetime(2019, 8, 30), False),
 
-            #From GMCR (see for example: http://yahoo.brand.edgar-online.com/Default.aspx?companyid=3184&formtypeID=7)
+            # From GMCR (see for example:
+            # http://yahoo.brand.edgar-online.com/Default.aspx?
+            # companyid=3184&formtypeID=7)
             (offset_lom_sat_sep, datetime(2010, 9, 25), True),
             (offset_lom_sat_sep, datetime(2011, 9, 24), True),
             (offset_lom_sat_sep, datetime(2012, 9, 29), True),
 
         ]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
     def test_apply(self):
-        offset_lom_aug_sat = makeFY5253LastOfMonth(startingMonth=8, weekday=WeekDay.SAT)
-        offset_lom_aug_sat_1 = makeFY5253LastOfMonth(n=1, startingMonth=8, weekday=WeekDay.SAT)
+        offset_lom_aug_sat = makeFY5253LastOfMonth(startingMonth=8,
+                                                   weekday=WeekDay.SAT)
+        offset_lom_aug_sat_1 = makeFY5253LastOfMonth(n=1, startingMonth=8,
+                                                     weekday=WeekDay.SAT)
 
         date_seq_lom_aug_sat = [datetime(2006, 8, 26), datetime(2007, 8, 25),
                                 datetime(2008, 8, 30), datetime(2009, 8, 29),
@@ -2526,12 +2669,16 @@ class TestFY5253LastOfMonth(Base):
                                 datetime(2016, 8, 27)]
 
         tests = [
-                 (offset_lom_aug_sat, date_seq_lom_aug_sat),
-                 (offset_lom_aug_sat_1, date_seq_lom_aug_sat),
-                 (offset_lom_aug_sat, [datetime(2006, 8, 25)] + date_seq_lom_aug_sat),
-                 (offset_lom_aug_sat_1, [datetime(2006, 8, 27)] + date_seq_lom_aug_sat[1:]),
-                 (makeFY5253LastOfMonth(n=-1, startingMonth=8, weekday=WeekDay.SAT), list(reversed(date_seq_lom_aug_sat))),
-                ]
+            (offset_lom_aug_sat, date_seq_lom_aug_sat),
+            (offset_lom_aug_sat_1, date_seq_lom_aug_sat),
+            (offset_lom_aug_sat, [
+                datetime(2006, 8, 25)] + date_seq_lom_aug_sat),
+            (offset_lom_aug_sat_1, [
+                datetime(2006, 8, 27)] + date_seq_lom_aug_sat[1:]),
+            (makeFY5253LastOfMonth(n=-1, startingMonth=8,
+                                   weekday=WeekDay.SAT),
+             list(reversed(date_seq_lom_aug_sat))),
+        ]
         for test in tests:
             offset, data = test
             current = data[0]
@@ -2539,53 +2686,82 @@ class TestFY5253LastOfMonth(Base):
                 current = current + offset
                 self.assertEqual(current, datum)
 
-class TestFY5253NearestEndMonth(Base):
 
+class TestFY5253NearestEndMonth(Base):
     def test_get_target_month_end(self):
-        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=8, weekday=WeekDay.SAT).get_target_month_end(datetime(2013,1,1)), datetime(2013,8,31))
-        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=12, weekday=WeekDay.SAT).get_target_month_end(datetime(2013,1,1)), datetime(2013,12,31))
-        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=2, weekday=WeekDay.SAT).get_target_month_end(datetime(2013,1,1)), datetime(2013,2,28))
+        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=8,
+                                                   weekday=WeekDay.SAT)
+                         .get_target_month_end(
+            datetime(2013, 1, 1)), datetime(2013, 8, 31))
+        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=12,
+                                                   weekday=WeekDay.SAT)
+                         .get_target_month_end(datetime(2013, 1, 1)),
+                         datetime(2013, 12, 31))
+        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=2,
+                                                   weekday=WeekDay.SAT)
+                         .get_target_month_end(datetime(2013, 1, 1)),
+                         datetime(2013, 2, 28))
 
     def test_get_year_end(self):
-        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=8, weekday=WeekDay.SAT).get_year_end(datetime(2013,1,1)), datetime(2013,8,31))
-        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=8, weekday=WeekDay.SUN).get_year_end(datetime(2013,1,1)), datetime(2013,9,1))
-        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=8, weekday=WeekDay.FRI).get_year_end(datetime(2013,1,1)), datetime(2013,8,30))
+        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=8,
+                                                   weekday=WeekDay.SAT)
+                         .get_year_end(datetime(2013, 1, 1)),
+                         datetime(2013, 8, 31))
+        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=8,
+                                                   weekday=WeekDay.SUN)
+                         .get_year_end(datetime(2013, 1, 1)),
+                         datetime(2013, 9, 1))
+        self.assertEqual(makeFY5253NearestEndMonth(startingMonth=8,
+                                                   weekday=WeekDay.FRI)
+                         .get_year_end(datetime(2013, 1, 1)),
+                         datetime(2013, 8, 30))
 
         offset_n = FY5253(weekday=WeekDay.TUE, startingMonth=12,
-                      variation="nearest")
-        self.assertEqual(offset_n.get_year_end(datetime(2012,1,1)), datetime(2013,1,1))
-        self.assertEqual(offset_n.get_year_end(datetime(2012,1,10)), datetime(2013,1,1))
-
-        self.assertEqual(offset_n.get_year_end(datetime(2013,1,1)), datetime(2013,12,31))
-        self.assertEqual(offset_n.get_year_end(datetime(2013,1,2)), datetime(2013,12,31))
-        self.assertEqual(offset_n.get_year_end(datetime(2013,1,3)), datetime(2013,12,31))
-        self.assertEqual(offset_n.get_year_end(datetime(2013,1,10)), datetime(2013,12,31))
+                          variation="nearest")
+        self.assertEqual(offset_n.get_year_end(
+            datetime(2012, 1, 1)), datetime(2013, 1, 1))
+        self.assertEqual(offset_n.get_year_end(
+            datetime(2012, 1, 10)), datetime(2013, 1, 1))
+
+        self.assertEqual(offset_n.get_year_end(
+            datetime(2013, 1, 1)), datetime(2013, 12, 31))
+        self.assertEqual(offset_n.get_year_end(
+            datetime(2013, 1, 2)), datetime(2013, 12, 31))
+        self.assertEqual(offset_n.get_year_end(
+            datetime(2013, 1, 3)), datetime(2013, 12, 31))
+        self.assertEqual(offset_n.get_year_end(
+            datetime(2013, 1, 10)), datetime(2013, 12, 31))
 
         JNJ = FY5253(n=1, startingMonth=12, weekday=6, variation="nearest")
-        self.assertEqual(JNJ.get_year_end(datetime(2006, 1, 1)), datetime(2006, 12, 31))
+        self.assertEqual(JNJ.get_year_end(
+            datetime(2006, 1, 1)), datetime(2006, 12, 31))
 
     def test_onOffset(self):
-        offset_lom_aug_sat = makeFY5253NearestEndMonth(1, startingMonth=8, weekday=WeekDay.SAT)
-        offset_lom_aug_thu = makeFY5253NearestEndMonth(1, startingMonth=8, weekday=WeekDay.THU)
+        offset_lom_aug_sat = makeFY5253NearestEndMonth(1, startingMonth=8,
+                                                       weekday=WeekDay.SAT)
+        offset_lom_aug_thu = makeFY5253NearestEndMonth(1, startingMonth=8,
+                                                       weekday=WeekDay.THU)
         offset_n = FY5253(weekday=WeekDay.TUE, startingMonth=12,
-                      variation="nearest")
+                          variation="nearest")
 
         tests = [
-#             From Wikipedia (see: http://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar#Saturday_nearest_the_end_of_month)
-#             2006-09-02   2006 September 2
-#             2007-09-01   2007 September 1
-#             2008-08-30   2008 August 30    (leap year)
-#             2009-08-29   2009 August 29
-#             2010-08-28   2010 August 28
-#             2011-09-03   2011 September 3
-#             2012-09-01   2012 September 1  (leap year)
-#             2013-08-31   2013 August 31
-#             2014-08-30   2014 August 30
-#             2015-08-29   2015 August 29
-#             2016-09-03   2016 September 3  (leap year)
-#             2017-09-02   2017 September 2
-#             2018-09-01   2018 September 1
-#             2019-08-31   2019 August 31
+            #    From Wikipedia (see:
+            #    http://en.wikipedia.org/wiki/4%E2%80%934%E2%80%935_calendar
+            #    #Saturday_nearest_the_end_of_month)
+            #    2006-09-02   2006 September 2
+            #    2007-09-01   2007 September 1
+            #    2008-08-30   2008 August 30    (leap year)
+            #    2009-08-29   2009 August 29
+            #    2010-08-28   2010 August 28
+            #    2011-09-03   2011 September 3
+            #    2012-09-01   2012 September 1  (leap year)
+            #    2013-08-31   2013 August 31
+            #    2014-08-30   2014 August 30
+            #    2015-08-29   2015 August 29
+            #    2016-09-03   2016 September 3  (leap year)
+            #    2017-09-02   2017 September 2
+            #    2018-09-01   2018 September 1
+            #    2019-08-31   2019 August 31
             (offset_lom_aug_sat, datetime(2006, 9, 2), True),
             (offset_lom_aug_sat, datetime(2007, 9, 1), True),
             (offset_lom_aug_sat, datetime(2008, 8, 30), True),
@@ -2613,7 +2789,8 @@ class TestFY5253NearestEndMonth(Base):
             (offset_lom_aug_sat, datetime(2011, 8, 26), False),
             (offset_lom_aug_sat, datetime(2019, 8, 30), False),
 
-            #From Micron, see: http://google.brand.edgar-online.com/?sym=MU&formtypeID=7
+            # From Micron, see:
+            # http://google.brand.edgar-online.com/?sym=MU&formtypeID=7
             (offset_lom_aug_thu, datetime(2012, 8, 30), True),
             (offset_lom_aug_thu, datetime(2011, 9, 1), True),
 
@@ -2622,8 +2799,8 @@ class TestFY5253NearestEndMonth(Base):
             (offset_n, datetime(2013, 1, 2), False),
         ]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
     def test_apply(self):
         date_seq_nem_8_sat = [datetime(2006, 9, 2), datetime(2007, 9, 1),
@@ -2636,20 +2813,37 @@ class TestFY5253NearestEndMonth(Base):
                datetime(2011, 1, 2), datetime(2012, 1, 1),
                datetime(2012, 12, 30)]
 
-        DEC_SAT = FY5253(n=-1, startingMonth=12, weekday=5, variation="nearest")
+        DEC_SAT = FY5253(n=-1, startingMonth=12, weekday=5,
+                         variation="nearest")
 
         tests = [
-                (makeFY5253NearestEndMonth(startingMonth=8, weekday=WeekDay.SAT), date_seq_nem_8_sat),
-                (makeFY5253NearestEndMonth(n=1, startingMonth=8, weekday=WeekDay.SAT), date_seq_nem_8_sat),
-                (makeFY5253NearestEndMonth(startingMonth=8, weekday=WeekDay.SAT), [datetime(2006, 9, 1)] + date_seq_nem_8_sat),
-                (makeFY5253NearestEndMonth(n=1, startingMonth=8, weekday=WeekDay.SAT), [datetime(2006, 9, 3)] + date_seq_nem_8_sat[1:]),
-                (makeFY5253NearestEndMonth(n=-1, startingMonth=8, weekday=WeekDay.SAT), list(reversed(date_seq_nem_8_sat))),
-                (makeFY5253NearestEndMonth(n=1, startingMonth=12, weekday=WeekDay.SUN), JNJ),
-                (makeFY5253NearestEndMonth(n=-1, startingMonth=12, weekday=WeekDay.SUN), list(reversed(JNJ))),
-                (makeFY5253NearestEndMonth(n=1, startingMonth=12, weekday=WeekDay.SUN), [datetime(2005,1,2), datetime(2006, 1, 1)]),
-                (makeFY5253NearestEndMonth(n=1, startingMonth=12, weekday=WeekDay.SUN), [datetime(2006,1,2), datetime(2006, 12, 31)]),
-                (DEC_SAT, [datetime(2013,1,15), datetime(2012,12,29)])
-                ]
+            (makeFY5253NearestEndMonth(startingMonth=8,
+                                       weekday=WeekDay.SAT),
+             date_seq_nem_8_sat),
+            (makeFY5253NearestEndMonth(n=1, startingMonth=8,
+                                       weekday=WeekDay.SAT),
+             date_seq_nem_8_sat),
+            (makeFY5253NearestEndMonth(startingMonth=8, weekday=WeekDay.SAT),
+             [datetime(2006, 9, 1)] + date_seq_nem_8_sat),
+            (makeFY5253NearestEndMonth(n=1, startingMonth=8,
+                                       weekday=WeekDay.SAT),
+             [datetime(2006, 9, 3)] + date_seq_nem_8_sat[1:]),
+            (makeFY5253NearestEndMonth(n=-1, startingMonth=8,
+                                       weekday=WeekDay.SAT),
+             list(reversed(date_seq_nem_8_sat))),
+            (makeFY5253NearestEndMonth(n=1, startingMonth=12,
+                                       weekday=WeekDay.SUN), JNJ),
+            (makeFY5253NearestEndMonth(n=-1, startingMonth=12,
+                                       weekday=WeekDay.SUN),
+             list(reversed(JNJ))),
+            (makeFY5253NearestEndMonth(n=1, startingMonth=12,
+                                       weekday=WeekDay.SUN),
+             [datetime(2005, 1, 2), datetime(2006, 1, 1)]),
+            (makeFY5253NearestEndMonth(n=1, startingMonth=12,
+                                       weekday=WeekDay.SUN),
+             [datetime(2006, 1, 2), datetime(2006, 12, 31)]),
+            (DEC_SAT, [datetime(2013, 1, 15), datetime(2012, 12, 29)])
+        ]
         for test in tests:
             offset, data = test
             current = data[0]
@@ -2657,51 +2851,78 @@ class TestFY5253NearestEndMonth(Base):
                 current = current + offset
                 self.assertEqual(current, datum)
 
-class TestFY5253LastOfMonthQuarter(Base):
 
+class TestFY5253LastOfMonthQuarter(Base):
     def test_isAnchored(self):
-        self.assertTrue(makeFY5253LastOfMonthQuarter(startingMonth=1, weekday=WeekDay.SAT, qtr_with_extra_week=4).isAnchored())
-        self.assertTrue(makeFY5253LastOfMonthQuarter(weekday=WeekDay.SAT, startingMonth=3, qtr_with_extra_week=4).isAnchored())
-        self.assertFalse(makeFY5253LastOfMonthQuarter(2, startingMonth=1, weekday=WeekDay.SAT, qtr_with_extra_week=4).isAnchored())
+        self.assertTrue(
+            makeFY5253LastOfMonthQuarter(startingMonth=1, weekday=WeekDay.SAT,
+                                         qtr_with_extra_week=4).isAnchored())
+        self.assertTrue(
+            makeFY5253LastOfMonthQuarter(weekday=WeekDay.SAT, startingMonth=3,
+                                         qtr_with_extra_week=4).isAnchored())
+        self.assertFalse(makeFY5253LastOfMonthQuarter(
+            2, startingMonth=1, weekday=WeekDay.SAT,
+            qtr_with_extra_week=4).isAnchored())
 
     def test_equality(self):
-        self.assertEqual(makeFY5253LastOfMonthQuarter(startingMonth=1, weekday=WeekDay.SAT, qtr_with_extra_week=4), makeFY5253LastOfMonthQuarter(startingMonth=1, weekday=WeekDay.SAT, qtr_with_extra_week=4))
-        self.assertNotEqual(makeFY5253LastOfMonthQuarter(startingMonth=1, weekday=WeekDay.SAT, qtr_with_extra_week=4), makeFY5253LastOfMonthQuarter(startingMonth=1, weekday=WeekDay.SUN, qtr_with_extra_week=4))
-        self.assertNotEqual(makeFY5253LastOfMonthQuarter(startingMonth=1, weekday=WeekDay.SAT, qtr_with_extra_week=4), makeFY5253LastOfMonthQuarter(startingMonth=2, weekday=WeekDay.SAT, qtr_with_extra_week=4))
+        self.assertEqual(makeFY5253LastOfMonthQuarter(startingMonth=1,
+                                                      weekday=WeekDay.SAT,
+                                                      qtr_with_extra_week=4),
+                         makeFY5253LastOfMonthQuarter(startingMonth=1,
+                                                      weekday=WeekDay.SAT,
+                                                      qtr_with_extra_week=4))
+        self.assertNotEqual(
+            makeFY5253LastOfMonthQuarter(
+                startingMonth=1, weekday=WeekDay.SAT,
+                qtr_with_extra_week=4),
+            makeFY5253LastOfMonthQuarter(
+                startingMonth=1, weekday=WeekDay.SUN,
+                qtr_with_extra_week=4))
+        self.assertNotEqual(
+            makeFY5253LastOfMonthQuarter(
+                startingMonth=1, weekday=WeekDay.SAT,
+                qtr_with_extra_week=4),
+            makeFY5253LastOfMonthQuarter(
+                startingMonth=2, weekday=WeekDay.SAT,
+                qtr_with_extra_week=4))
 
     def test_offset(self):
-        offset = makeFY5253LastOfMonthQuarter(1, startingMonth=9, weekday=WeekDay.SAT, qtr_with_extra_week=4)
-        offset2 = makeFY5253LastOfMonthQuarter(2, startingMonth=9, weekday=WeekDay.SAT, qtr_with_extra_week=4)
-        offset4 = makeFY5253LastOfMonthQuarter(4, startingMonth=9, weekday=WeekDay.SAT, qtr_with_extra_week=4)
-
-        offset_neg1 = makeFY5253LastOfMonthQuarter(-1, startingMonth=9, weekday=WeekDay.SAT, qtr_with_extra_week=4)
-        offset_neg2 = makeFY5253LastOfMonthQuarter(-2, startingMonth=9, weekday=WeekDay.SAT, qtr_with_extra_week=4)
-
-        GMCR = [datetime(2010, 3, 27),
-                datetime(2010, 6, 26),
-                datetime(2010, 9, 25),
-                datetime(2010, 12, 25),
-                datetime(2011, 3, 26),
-                datetime(2011, 6, 25),
-                datetime(2011, 9, 24),
-                datetime(2011, 12, 24),
-                datetime(2012, 3, 24),
-                datetime(2012, 6, 23),
-                datetime(2012, 9, 29),
-                datetime(2012, 12, 29),
-                datetime(2013, 3, 30),
-                datetime(2013, 6, 29)]
-
+        offset = makeFY5253LastOfMonthQuarter(1, startingMonth=9,
+                                              weekday=WeekDay.SAT,
+                                              qtr_with_extra_week=4)
+        offset2 = makeFY5253LastOfMonthQuarter(2, startingMonth=9,
+                                               weekday=WeekDay.SAT,
+                                               qtr_with_extra_week=4)
+        offset4 = makeFY5253LastOfMonthQuarter(4, startingMonth=9,
+                                               weekday=WeekDay.SAT,
+                                               qtr_with_extra_week=4)
+
+        offset_neg1 = makeFY5253LastOfMonthQuarter(-1, startingMonth=9,
+                                                   weekday=WeekDay.SAT,
+                                                   qtr_with_extra_week=4)
+        offset_neg2 = makeFY5253LastOfMonthQuarter(-2, startingMonth=9,
+                                                   weekday=WeekDay.SAT,
+                                                   qtr_with_extra_week=4)
+
+        GMCR = [datetime(2010, 3, 27), datetime(2010, 6, 26),
+                datetime(2010, 9, 25), datetime(2010, 12, 25),
+                datetime(2011, 3, 26), datetime(2011, 6, 25),
+                datetime(2011, 9, 24), datetime(2011, 12, 24),
+                datetime(2012, 3, 24), datetime(2012, 6, 23),
+                datetime(2012, 9, 29), datetime(2012, 12, 29),
+                datetime(2013, 3, 30), datetime(2013, 6, 29)]
 
         assertEq(offset, base=GMCR[0], expected=GMCR[1])
-        assertEq(offset, base=GMCR[0] + relativedelta(days=-1), expected=GMCR[0])
+        assertEq(offset, base=GMCR[0] + relativedelta(days=-1),
+                 expected=GMCR[0])
         assertEq(offset, base=GMCR[1], expected=GMCR[2])
 
         assertEq(offset2, base=GMCR[0], expected=GMCR[2])
         assertEq(offset4, base=GMCR[0], expected=GMCR[4])
 
         assertEq(offset_neg1, base=GMCR[-1], expected=GMCR[-2])
-        assertEq(offset_neg1, base=GMCR[-1] + relativedelta(days=+1), expected=GMCR[-1])
+        assertEq(offset_neg1, base=GMCR[-1] + relativedelta(days=+1),
+                 expected=GMCR[-1])
         assertEq(offset_neg2, base=GMCR[-1], expected=GMCR[-3])
 
         date = GMCR[0] + relativedelta(days=-1)
@@ -2714,13 +2935,16 @@ class TestFY5253LastOfMonthQuarter(Base):
             assertEq(offset_neg1, date, expected)
             date = date + offset_neg1
 
-
     def test_onOffset(self):
-        lomq_aug_sat_4 = makeFY5253LastOfMonthQuarter(1, startingMonth=8, weekday=WeekDay.SAT, qtr_with_extra_week=4)
-        lomq_sep_sat_4 = makeFY5253LastOfMonthQuarter(1, startingMonth=9, weekday=WeekDay.SAT, qtr_with_extra_week=4)
+        lomq_aug_sat_4 = makeFY5253LastOfMonthQuarter(1, startingMonth=8,
+                                                      weekday=WeekDay.SAT,
+                                                      qtr_with_extra_week=4)
+        lomq_sep_sat_4 = makeFY5253LastOfMonthQuarter(1, startingMonth=9,
+                                                      weekday=WeekDay.SAT,
+                                                      qtr_with_extra_week=4)
 
         tests = [
-            #From Wikipedia
+            # From Wikipedia
             (lomq_aug_sat_4, datetime(2006, 8, 26), True),
             (lomq_aug_sat_4, datetime(2007, 8, 25), True),
             (lomq_aug_sat_4, datetime(2008, 8, 30), True),
@@ -2744,7 +2968,7 @@ class TestFY5253LastOfMonthQuarter(Base):
             (lomq_aug_sat_4, datetime(2011, 8, 26), False),
             (lomq_aug_sat_4, datetime(2019, 8, 30), False),
 
-            #From GMCR
+            # From GMCR
             (lomq_sep_sat_4, datetime(2010, 9, 25), True),
             (lomq_sep_sat_4, datetime(2011, 9, 24), True),
             (lomq_sep_sat_4, datetime(2012, 9, 29), True),
@@ -2759,57 +2983,111 @@ class TestFY5253LastOfMonthQuarter(Base):
             (lomq_sep_sat_4, datetime(2012, 12, 29), True),
             (lomq_sep_sat_4, datetime(2011, 12, 24), True),
 
-            #INTC (extra week in Q1)
-            #See: http://www.intc.com/releasedetail.cfm?ReleaseID=542844
-            (makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1), datetime(2011, 4, 2), True),
-
-            #see: http://google.brand.edgar-online.com/?sym=INTC&formtypeID=7
-            (makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1), datetime(2012, 12, 29), True),
-            (makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1), datetime(2011, 12, 31), True),
-            (makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1), datetime(2010, 12, 25), True),
-
+            # INTC (extra week in Q1)
+            # See: http://www.intc.com/releasedetail.cfm?ReleaseID=542844
+            (makeFY5253LastOfMonthQuarter(1, startingMonth=12,
+                                          weekday=WeekDay.SAT,
+                                          qtr_with_extra_week=1),
+             datetime(2011, 4, 2), True),
+
+            # see: http://google.brand.edgar-online.com/?sym=INTC&formtypeID=7
+            (makeFY5253LastOfMonthQuarter(1, startingMonth=12,
+                                          weekday=WeekDay.SAT,
+                                          qtr_with_extra_week=1),
+             datetime(2012, 12, 29), True),
+            (makeFY5253LastOfMonthQuarter(1, startingMonth=12,
+                                          weekday=WeekDay.SAT,
+                                          qtr_with_extra_week=1),
+             datetime(2011, 12, 31), True),
+            (makeFY5253LastOfMonthQuarter(1, startingMonth=12,
+                                          weekday=WeekDay.SAT,
+                                          qtr_with_extra_week=1),
+             datetime(2010, 12, 25), True),
         ]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
     def test_year_has_extra_week(self):
-        #End of long Q1
-        self.assertTrue(makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1).year_has_extra_week(datetime(2011, 4, 2)))
-
-        #Start of long Q1
-        self.assertTrue(makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1).year_has_extra_week(datetime(2010, 12, 26)))
-
-        #End of year before year with long Q1
-        self.assertFalse(makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1).year_has_extra_week(datetime(2010, 12, 25)))
-
-        for year in [x for x in range(1994, 2011+1) if x not in [2011, 2005, 2000, 1994]]:
-            self.assertFalse(makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1).year_has_extra_week(datetime(year, 4, 2)))
-
-        #Other long years
-        self.assertTrue(makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1).year_has_extra_week(datetime(2005, 4, 2)))
-        self.assertTrue(makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1).year_has_extra_week(datetime(2000, 4, 2)))
-        self.assertTrue(makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1).year_has_extra_week(datetime(1994, 4, 2)))
+        # End of long Q1
+        self.assertTrue(
+            makeFY5253LastOfMonthQuarter(1, startingMonth=12,
+                                         weekday=WeekDay.SAT,
+                                         qtr_with_extra_week=1)
+            .year_has_extra_week(datetime(2011, 4, 2)))
+
+        # Start of long Q1
+        self.assertTrue(
+            makeFY5253LastOfMonthQuarter(
+                1, startingMonth=12, weekday=WeekDay.SAT,
+                qtr_with_extra_week=1)
+            .year_has_extra_week(datetime(2010, 12, 26)))
+
+        # End of year before year with long Q1
+        self.assertFalse(
+            makeFY5253LastOfMonthQuarter(
+                1, startingMonth=12, weekday=WeekDay.SAT,
+                qtr_with_extra_week=1)
+            .year_has_extra_week(datetime(2010, 12, 25)))
+
+        for year in [x
+                     for x in range(1994, 2011 + 1)
+                     if x not in [2011, 2005, 2000, 1994]]:
+            self.assertFalse(
+                makeFY5253LastOfMonthQuarter(
+                    1, startingMonth=12, weekday=WeekDay.SAT,
+                    qtr_with_extra_week=1)
+                .year_has_extra_week(datetime(year, 4, 2)))
+
+        # Other long years
+        self.assertTrue(
+            makeFY5253LastOfMonthQuarter(
+                1, startingMonth=12, weekday=WeekDay.SAT,
+                qtr_with_extra_week=1)
+            .year_has_extra_week(datetime(2005, 4, 2)))
+
+        self.assertTrue(
+            makeFY5253LastOfMonthQuarter(
+                1, startingMonth=12, weekday=WeekDay.SAT,
+                qtr_with_extra_week=1)
+            .year_has_extra_week(datetime(2000, 4, 2)))
+
+        self.assertTrue(
+            makeFY5253LastOfMonthQuarter(
+                1, startingMonth=12, weekday=WeekDay.SAT,
+                qtr_with_extra_week=1)
+            .year_has_extra_week(datetime(1994, 4, 2)))
 
     def test_get_weeks(self):
-        sat_dec_1 = makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=1)
-        sat_dec_4 = makeFY5253LastOfMonthQuarter(1, startingMonth=12, weekday=WeekDay.SAT, qtr_with_extra_week=4)
+        sat_dec_1 = makeFY5253LastOfMonthQuarter(1, startingMonth=12,
+                                                 weekday=WeekDay.SAT,
+                                                 qtr_with_extra_week=1)
+        sat_dec_4 = makeFY5253LastOfMonthQuarter(1, startingMonth=12,
+                                                 weekday=WeekDay.SAT,
+                                                 qtr_with_extra_week=4)
 
-        self.assertEqual(sat_dec_1.get_weeks(datetime(2011, 4, 2)), [14, 13, 13, 13])
-        self.assertEqual(sat_dec_4.get_weeks(datetime(2011, 4, 2)), [13, 13, 13, 14])
-        self.assertEqual(sat_dec_1.get_weeks(datetime(2010, 12, 25)), [13, 13, 13, 13])
+        self.assertEqual(sat_dec_1.get_weeks(
+            datetime(2011, 4, 2)), [14, 13, 13, 13])
+        self.assertEqual(sat_dec_4.get_weeks(
+            datetime(2011, 4, 2)), [13, 13, 13, 14])
+        self.assertEqual(sat_dec_1.get_weeks(
+            datetime(2010, 12, 25)), [13, 13, 13, 13])
 
-class TestFY5253NearestEndMonthQuarter(Base):
 
+class TestFY5253NearestEndMonthQuarter(Base):
     def test_onOffset(self):
 
-        offset_nem_sat_aug_4 = makeFY5253NearestEndMonthQuarter(1, startingMonth=8, weekday=WeekDay.SAT, qtr_with_extra_week=4)
-        offset_nem_thu_aug_4 = makeFY5253NearestEndMonthQuarter(1, startingMonth=8, weekday=WeekDay.THU, qtr_with_extra_week=4)
+        offset_nem_sat_aug_4 = makeFY5253NearestEndMonthQuarter(
+            1, startingMonth=8, weekday=WeekDay.SAT,
+            qtr_with_extra_week=4)
+        offset_nem_thu_aug_4 = makeFY5253NearestEndMonthQuarter(
+            1, startingMonth=8, weekday=WeekDay.THU,
+            qtr_with_extra_week=4)
         offset_n = FY5253(weekday=WeekDay.TUE, startingMonth=12,
-                      variation="nearest", qtr_with_extra_week=4)
+                          variation="nearest", qtr_with_extra_week=4)
 
         tests = [
-            #From Wikipedia
+            # From Wikipedia
             (offset_nem_sat_aug_4, datetime(2006, 9, 2), True),
             (offset_nem_sat_aug_4, datetime(2007, 9, 1), True),
             (offset_nem_sat_aug_4, datetime(2008, 8, 30), True),
@@ -2837,11 +3115,12 @@ class TestFY5253NearestEndMonthQuarter(Base):
             (offset_nem_sat_aug_4, datetime(2011, 8, 26), False),
             (offset_nem_sat_aug_4, datetime(2019, 8, 30), False),
 
-            #From Micron, see: http://google.brand.edgar-online.com/?sym=MU&formtypeID=7
+            # From Micron, see:
+            # http://google.brand.edgar-online.com/?sym=MU&formtypeID=7
             (offset_nem_thu_aug_4, datetime(2012, 8, 30), True),
             (offset_nem_thu_aug_4, datetime(2011, 9, 1), True),
 
-            #See: http://google.brand.edgar-online.com/?sym=MU&formtypeID=13
+            # See: http://google.brand.edgar-online.com/?sym=MU&formtypeID=13
             (offset_nem_thu_aug_4, datetime(2013, 5, 30), True),
             (offset_nem_thu_aug_4, datetime(2013, 2, 28), True),
             (offset_nem_thu_aug_4, datetime(2012, 11, 29), True),
@@ -2854,13 +3133,17 @@ class TestFY5253NearestEndMonthQuarter(Base):
             (offset_n, datetime(2013, 1, 2), False)
         ]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
     def test_offset(self):
-        offset = makeFY5253NearestEndMonthQuarter(1, startingMonth=8, weekday=WeekDay.THU, qtr_with_extra_week=4)
+        offset = makeFY5253NearestEndMonthQuarter(1, startingMonth=8,
+                                                  weekday=WeekDay.THU,
+                                                  qtr_with_extra_week=4)
 
-        MU = [datetime(2012, 5, 31), datetime(2012, 8, 30), datetime(2012, 11, 29), datetime(2013, 2, 28), datetime(2013, 5, 30)]
+        MU = [datetime(2012, 5, 31), datetime(2012, 8, 30), datetime(2012, 11,
+                                                                     29),
+              datetime(2013, 2, 28), datetime(2013, 5, 30)]
 
         date = MU[0] + relativedelta(days=-1)
         for expected in MU:
@@ -2870,17 +3153,20 @@ class TestFY5253NearestEndMonthQuarter(Base):
         assertEq(offset, datetime(2012, 5, 31), datetime(2012, 8, 30))
         assertEq(offset, datetime(2012, 5, 30), datetime(2012, 5, 31))
 
-        offset2 = FY5253Quarter(weekday=5, startingMonth=12,
-                     variation="last", qtr_with_extra_week=4)
+        offset2 = FY5253Quarter(weekday=5, startingMonth=12, variation="last",
+                                qtr_with_extra_week=4)
 
-        assertEq(offset2, datetime(2013,1,15), datetime(2013, 3, 30))
+        assertEq(offset2, datetime(2013, 1, 15), datetime(2013, 3, 30))
 
-class TestQuarterBegin(Base):
 
+class TestQuarterBegin(Base):
     def test_repr(self):
-        self.assertEqual(repr(QuarterBegin()), "<QuarterBegin: startingMonth=3>")
-        self.assertEqual(repr(QuarterBegin(startingMonth=3)), "<QuarterBegin: startingMonth=3>")
-        self.assertEqual(repr(QuarterBegin(startingMonth=1)),"<QuarterBegin: startingMonth=1>")
+        self.assertEqual(repr(QuarterBegin()),
+                         "<QuarterBegin: startingMonth=3>")
+        self.assertEqual(repr(QuarterBegin(startingMonth=3)),
+                         "<QuarterBegin: startingMonth=3>")
+        self.assertEqual(repr(QuarterBegin(startingMonth=1)),
+                         "<QuarterBegin: startingMonth=1>")
 
     def test_isAnchored(self):
         self.assertTrue(QuarterBegin(startingMonth=1).isAnchored())
@@ -2955,8 +3241,10 @@ class TestQuarterEnd(Base):
 
     def test_repr(self):
         self.assertEqual(repr(QuarterEnd()), "<QuarterEnd: startingMonth=3>")
-        self.assertEqual(repr(QuarterEnd(startingMonth=3)), "<QuarterEnd: startingMonth=3>")
-        self.assertEqual(repr(QuarterEnd(startingMonth=1)), "<QuarterEnd: startingMonth=1>")
+        self.assertEqual(repr(QuarterEnd(startingMonth=3)),
+                         "<QuarterEnd: startingMonth=3>")
+        self.assertEqual(repr(QuarterEnd(startingMonth=1)),
+                         "<QuarterEnd: startingMonth=1>")
 
     def test_isAnchored(self):
         self.assertTrue(QuarterEnd(startingMonth=1).isAnchored())
@@ -3027,65 +3315,63 @@ class TestQuarterEnd(Base):
     def test_onOffset(self):
 
         tests = [(QuarterEnd(1, startingMonth=1), datetime(2008, 1, 31), True),
-                 (QuarterEnd(
-                     1, startingMonth=1), datetime(2007, 12, 31), False),
-                 (QuarterEnd(
-                     1, startingMonth=1), datetime(2008, 2, 29), False),
-                 (QuarterEnd(
-                     1, startingMonth=1), datetime(2007, 3, 30), False),
-                 (QuarterEnd(
-                     1, startingMonth=1), datetime(2007, 3, 31), False),
+                 (QuarterEnd(1, startingMonth=1), datetime(2007, 12, 31),
+                  False),
+                 (QuarterEnd(1, startingMonth=1), datetime(2008, 2, 29),
+                  False),
+                 (QuarterEnd(1, startingMonth=1), datetime(2007, 3, 30),
+                  False),
+                 (QuarterEnd(1, startingMonth=1), datetime(2007, 3, 31),
+                  False),
                  (QuarterEnd(1, startingMonth=1), datetime(2008, 4, 30), True),
-                 (QuarterEnd(
-                     1, startingMonth=1), datetime(2008, 5, 30), False),
-                 (QuarterEnd(
-                     1, startingMonth=1), datetime(2008, 5, 31), False),
-                 (QuarterEnd(
-                     1, startingMonth=1), datetime(2007, 6, 29), False),
-                 (QuarterEnd(
-                     1, startingMonth=1), datetime(2007, 6, 30), False),
-
-                 (QuarterEnd(
-                     1, startingMonth=2), datetime(2008, 1, 31), False),
-                 (QuarterEnd(
-                     1, startingMonth=2), datetime(2007, 12, 31), False),
+                 (QuarterEnd(1, startingMonth=1), datetime(2008, 5, 30),
+                  False),
+                 (QuarterEnd(1, startingMonth=1), datetime(2008, 5, 31),
+                  False),
+                 (QuarterEnd(1, startingMonth=1), datetime(2007, 6, 29),
+                  False),
+                 (QuarterEnd(1, startingMonth=1), datetime(2007, 6, 30),
+                  False),
+                 (QuarterEnd(1, startingMonth=2), datetime(2008, 1, 31),
+                  False),
+                 (QuarterEnd(1, startingMonth=2), datetime(2007, 12, 31),
+                  False),
                  (QuarterEnd(1, startingMonth=2), datetime(2008, 2, 29), True),
-                 (QuarterEnd(
-                     1, startingMonth=2), datetime(2007, 3, 30), False),
-                 (QuarterEnd(
-                     1, startingMonth=2), datetime(2007, 3, 31), False),
-                 (QuarterEnd(
-                     1, startingMonth=2), datetime(2008, 4, 30), False),
-                 (QuarterEnd(
-                     1, startingMonth=2), datetime(2008, 5, 30), False),
+                 (QuarterEnd(1, startingMonth=2), datetime(2007, 3, 30),
+                  False),
+                 (QuarterEnd(1, startingMonth=2), datetime(2007, 3, 31),
+                  False),
+                 (QuarterEnd(1, startingMonth=2), datetime(2008, 4, 30),
+                  False),
+                 (QuarterEnd(1, startingMonth=2), datetime(2008, 5, 30),
+                  False),
                  (QuarterEnd(1, startingMonth=2), datetime(2008, 5, 31), True),
-                 (QuarterEnd(
-                     1, startingMonth=2), datetime(2007, 6, 29), False),
-                 (QuarterEnd(
-                     1, startingMonth=2), datetime(2007, 6, 30), False),
-
-                 (QuarterEnd(
-                     1, startingMonth=3), datetime(2008, 1, 31), False),
-                 (QuarterEnd(
-                     1, startingMonth=3), datetime(2007, 12, 31), True),
-                 (QuarterEnd(
-                     1, startingMonth=3), datetime(2008, 2, 29), False),
-                 (QuarterEnd(
-                     1, startingMonth=3), datetime(2007, 3, 30), False),
+                 (QuarterEnd(1, startingMonth=2), datetime(2007, 6, 29),
+                  False),
+                 (QuarterEnd(1, startingMonth=2), datetime(2007, 6, 30),
+                  False),
+                 (QuarterEnd(1, startingMonth=3), datetime(2008, 1, 31),
+                  False),
+                 (QuarterEnd(1, startingMonth=3), datetime(2007, 12, 31),
+                  True),
+                 (QuarterEnd(1, startingMonth=3), datetime(2008, 2, 29),
+                  False),
+                 (QuarterEnd(1, startingMonth=3), datetime(2007, 3, 30),
+                  False),
                  (QuarterEnd(1, startingMonth=3), datetime(2007, 3, 31), True),
-                 (QuarterEnd(
-                     1, startingMonth=3), datetime(2008, 4, 30), False),
-                 (QuarterEnd(
-                     1, startingMonth=3), datetime(2008, 5, 30), False),
-                 (QuarterEnd(
-                     1, startingMonth=3), datetime(2008, 5, 31), False),
-                 (QuarterEnd(
-                     1, startingMonth=3), datetime(2007, 6, 29), False),
-                 (QuarterEnd(1, startingMonth=3), datetime(2007, 6, 30), True),
-                 ]
-
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+                 (QuarterEnd(1, startingMonth=3), datetime(2008, 4, 30),
+                  False),
+                 (QuarterEnd(1, startingMonth=3), datetime(2008, 5, 30),
+                  False),
+                 (QuarterEnd(1, startingMonth=3), datetime(2008, 5, 31),
+                  False),
+                 (QuarterEnd(1, startingMonth=3), datetime(2007, 6, 29),
+                  False),
+                 (QuarterEnd(1, startingMonth=3), datetime(2007, 6, 30),
+                  True), ]
+
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
 
 class TestBYearBegin(Base):
@@ -3105,9 +3391,7 @@ class TestBYearBegin(Base):
                        datetime(2011, 1, 1): datetime(2011, 1, 3),
                        datetime(2011, 1, 3): datetime(2012, 1, 2),
                        datetime(2005, 12, 30): datetime(2006, 1, 2),
-                       datetime(2005, 12, 31): datetime(2006, 1, 2)
-                       }
-                      ))
+                       datetime(2005, 12, 31): datetime(2006, 1, 2)}))
 
         tests.append((BYearBegin(0),
                       {datetime(2008, 1, 1): datetime(2008, 1, 1),
@@ -3225,12 +3509,11 @@ class TestYearBegin(Base):
             (YearBegin(), datetime(2006, 1, 2), False),
         ]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
 
 class TestBYearEndLagged(Base):
-
     def test_bad_month_fail(self):
         self.assertRaises(Exception, BYearEnd, month=13)
         self.assertRaises(Exception, BYearEnd, month=0)
@@ -3240,13 +3523,11 @@ class TestBYearEndLagged(Base):
 
         tests.append((BYearEnd(month=6),
                       {datetime(2008, 1, 1): datetime(2008, 6, 30),
-                      datetime(2007, 6, 30): datetime(2008, 6, 30)},
-                      ))
+                       datetime(2007, 6, 30): datetime(2008, 6, 30)}, ))
 
         tests.append((BYearEnd(n=-1, month=6),
                       {datetime(2008, 1, 1): datetime(2007, 6, 29),
-                      datetime(2007, 6, 30): datetime(2007, 6, 29)},
-                      ))
+                       datetime(2007, 6, 30): datetime(2007, 6, 29)}, ))
 
         for offset, cases in tests:
             for base, expected in compat.iteritems(cases):
@@ -3266,8 +3547,8 @@ class TestBYearEndLagged(Base):
             (BYearEnd(month=6), datetime(2007, 6, 30), False),
         ]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
 
 class TestBYearEnd(Base):
@@ -3315,8 +3596,8 @@ class TestBYearEnd(Base):
             (BYearEnd(), datetime(2006, 12, 29), True),
         ]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
 
 class TestYearEnd(Base):
@@ -3367,12 +3648,11 @@ class TestYearEnd(Base):
             (YearEnd(), datetime(2006, 12, 29), False),
         ]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
 
 class TestYearEndDiffMonth(Base):
-
     def test_offset(self):
         tests = []
 
@@ -3416,8 +3696,8 @@ class TestYearEndDiffMonth(Base):
             (YearEnd(month=3), datetime(2006, 3, 29), False),
         ]
 
-        for offset, date, expected in tests:
-            assertOnOffset(offset, date, expected)
+        for offset, dt, expected in tests:
+            assertOnOffset(offset, dt, expected)
 
 
 def assertEq(offset, base, expected):
@@ -3431,7 +3711,8 @@ def assertEq(offset, base, expected):
     except AssertionError:
         raise AssertionError("\nExpected: %s\nActual: %s\nFor Offset: %s)"
                              "\nAt Date: %s" %
-                            (expected, actual, offset, base))
+                             (expected, actual, offset, base))
+
 
 def test_Easter():
     assertEq(Easter(), datetime(2010, 1, 1), datetime(2010, 4, 4))
@@ -3481,8 +3762,10 @@ class TestTicks(tm.TestCase):
     def test_Minute(self):
         assertEq(Minute(), datetime(2010, 1, 1), datetime(2010, 1, 1, 0, 1))
         assertEq(Minute(-1), datetime(2010, 1, 1, 0, 1), datetime(2010, 1, 1))
-        assertEq(2 * Minute(), datetime(2010, 1, 1), datetime(2010, 1, 1, 0, 2))
-        assertEq(-1 * Minute(), datetime(2010, 1, 1, 0, 1), datetime(2010, 1, 1))
+        assertEq(2 * Minute(), datetime(2010, 1, 1),
+                 datetime(2010, 1, 1, 0, 2))
+        assertEq(-1 * Minute(), datetime(2010, 1, 1, 0, 1),
+                 datetime(2010, 1, 1))
 
         self.assertEqual(Minute(3) + Minute(2), Minute(5))
         self.assertEqual(Minute(3) - Minute(2), Minute())
@@ -3490,33 +3773,46 @@ class TestTicks(tm.TestCase):
 
     def test_Second(self):
         assertEq(Second(), datetime(2010, 1, 1), datetime(2010, 1, 1, 0, 0, 1))
-        assertEq(Second(-1), datetime(2010, 1, 1, 0, 0, 1), datetime(2010, 1, 1))
-        assertEq(2 * Second(), datetime(2010, 1, 1), datetime(2010, 1, 1, 0, 0, 2))
-        assertEq(
-            -1 * Second(), datetime(2010, 1, 1, 0, 0, 1), datetime(2010, 1, 1))
+        assertEq(Second(-1), datetime(2010, 1, 1,
+                                      0, 0, 1), datetime(2010, 1, 1))
+        assertEq(2 * Second(), datetime(2010, 1, 1),
+                 datetime(2010, 1, 1, 0, 0, 2))
+        assertEq(-1 * Second(), datetime(2010, 1, 1, 0, 0, 1),
+                 datetime(2010, 1, 1))
 
         self.assertEqual(Second(3) + Second(2), Second(5))
         self.assertEqual(Second(3) - Second(2), Second())
 
     def test_Millisecond(self):
-        assertEq(Milli(), datetime(2010, 1, 1), datetime(2010, 1, 1, 0, 0, 0, 1000))
-        assertEq(Milli(-1), datetime(2010, 1, 1, 0, 0, 0, 1000), datetime(2010, 1, 1))
-        assertEq(Milli(2), datetime(2010, 1, 1), datetime(2010, 1, 1, 0, 0, 0, 2000))
-        assertEq(2 * Milli(), datetime(2010, 1, 1), datetime(2010, 1, 1, 0, 0, 0, 2000))
-        assertEq(-1 * Milli(), datetime(2010, 1, 1, 0, 0, 0, 1000), datetime(2010, 1, 1))
+        assertEq(Milli(), datetime(2010, 1, 1),
+                 datetime(2010, 1, 1, 0, 0, 0, 1000))
+        assertEq(Milli(-1), datetime(2010, 1, 1, 0,
+                                     0, 0, 1000), datetime(2010, 1, 1))
+        assertEq(Milli(2), datetime(2010, 1, 1),
+                 datetime(2010, 1, 1, 0, 0, 0, 2000))
+        assertEq(2 * Milli(), datetime(2010, 1, 1),
+                 datetime(2010, 1, 1, 0, 0, 0, 2000))
+        assertEq(-1 * Milli(), datetime(2010, 1, 1, 0, 0, 0, 1000),
+                 datetime(2010, 1, 1))
 
         self.assertEqual(Milli(3) + Milli(2), Milli(5))
         self.assertEqual(Milli(3) - Milli(2), Milli())
 
     def test_MillisecondTimestampArithmetic(self):
-        assertEq(Milli(), Timestamp('2010-01-01'), Timestamp('2010-01-01 00:00:00.001'))
-        assertEq(Milli(-1), Timestamp('2010-01-01 00:00:00.001'), Timestamp('2010-01-01'))
+        assertEq(Milli(), Timestamp('2010-01-01'),
+                 Timestamp('2010-01-01 00:00:00.001'))
+        assertEq(Milli(-1), Timestamp('2010-01-01 00:00:00.001'),
+                 Timestamp('2010-01-01'))
 
     def test_Microsecond(self):
-        assertEq(Micro(), datetime(2010, 1, 1), datetime(2010, 1, 1, 0, 0, 0, 1))
-        assertEq(Micro(-1), datetime(2010, 1, 1, 0, 0, 0, 1), datetime(2010, 1, 1))
-        assertEq(2 * Micro(), datetime(2010, 1, 1), datetime(2010, 1, 1, 0, 0, 0, 2))
-        assertEq(-1 * Micro(), datetime(2010, 1, 1, 0, 0, 0, 1), datetime(2010, 1, 1))
+        assertEq(Micro(), datetime(2010, 1, 1),
+                 datetime(2010, 1, 1, 0, 0, 0, 1))
+        assertEq(Micro(-1), datetime(2010, 1, 1,
+                                     0, 0, 0, 1), datetime(2010, 1, 1))
+        assertEq(2 * Micro(), datetime(2010, 1, 1),
+                 datetime(2010, 1, 1, 0, 0, 0, 2))
+        assertEq(-1 * Micro(), datetime(2010, 1, 1, 0, 0, 0, 1),
+                 datetime(2010, 1, 1))
 
         self.assertEqual(Micro(3) + Micro(2), Micro(5))
         self.assertEqual(Micro(3) - Micro(2), Micro())
@@ -3602,32 +3898,43 @@ class TestOffsetNames(tm.TestCase):
         self.assertEqual(Week(weekday=3).freqstr, 'W-THU')
         self.assertEqual(Week(weekday=4).freqstr, 'W-FRI')
 
-        self.assertEqual(LastWeekOfMonth(weekday=WeekDay.SUN).freqstr, "LWOM-SUN")
-        self.assertEqual(makeFY5253LastOfMonthQuarter(weekday=1, startingMonth=3, qtr_with_extra_week=4).freqstr,
-                         "REQ-L-MAR-TUE-4")
-        self.assertEqual(makeFY5253NearestEndMonthQuarter(weekday=1, startingMonth=3, qtr_with_extra_week=3).freqstr,
-                         "REQ-N-MAR-TUE-3")
+        self.assertEqual(LastWeekOfMonth(
+            weekday=WeekDay.SUN).freqstr, "LWOM-SUN")
+        self.assertEqual(
+            makeFY5253LastOfMonthQuarter(weekday=1, startingMonth=3,
+                                         qtr_with_extra_week=4).freqstr,
+            "REQ-L-MAR-TUE-4")
+        self.assertEqual(
+            makeFY5253NearestEndMonthQuarter(weekday=1, startingMonth=3,
+                                             qtr_with_extra_week=3).freqstr,
+            "REQ-N-MAR-TUE-3")
+
 
 def test_get_offset():
     assertRaisesRegexp(ValueError, "rule.*GIBBERISH", get_offset, 'gibberish')
     assertRaisesRegexp(ValueError, "rule.*QS-JAN-B", get_offset, 'QS-JAN-B')
     pairs = [
-             ('B', BDay()), ('b', BDay()), ('bm', BMonthEnd()),
-             ('Bm', BMonthEnd()), ('W-MON', Week(weekday=0)),
-             ('W-TUE', Week(weekday=1)), ('W-WED', Week(weekday=2)),
-             ('W-THU', Week(weekday=3)), ('W-FRI', Week(weekday=4)),
-             ("RE-N-DEC-MON", makeFY5253NearestEndMonth(weekday=0, startingMonth=12)),
-             ("RE-L-DEC-TUE", makeFY5253LastOfMonth(weekday=1, startingMonth=12)),
-             ("REQ-L-MAR-TUE-4", makeFY5253LastOfMonthQuarter(weekday=1, startingMonth=3, qtr_with_extra_week=4)),
-             ("REQ-L-DEC-MON-3", makeFY5253LastOfMonthQuarter(weekday=0, startingMonth=12, qtr_with_extra_week=3)),
-             ("REQ-N-DEC-MON-3", makeFY5253NearestEndMonthQuarter(weekday=0, startingMonth=12, qtr_with_extra_week=3)),
-             ]
+        ('B', BDay()), ('b', BDay()), ('bm', BMonthEnd()),
+        ('Bm', BMonthEnd()), ('W-MON', Week(weekday=0)),
+        ('W-TUE', Week(weekday=1)), ('W-WED', Week(weekday=2)),
+        ('W-THU', Week(weekday=3)), ('W-FRI', Week(weekday=4)),
+        ("RE-N-DEC-MON", makeFY5253NearestEndMonth(weekday=0,
+                                                   startingMonth=12)),
+        ("RE-L-DEC-TUE", makeFY5253LastOfMonth(weekday=1, startingMonth=12)),
+        ("REQ-L-MAR-TUE-4", makeFY5253LastOfMonthQuarter(
+            weekday=1, startingMonth=3, qtr_with_extra_week=4)),
+        ("REQ-L-DEC-MON-3", makeFY5253LastOfMonthQuarter(
+            weekday=0, startingMonth=12, qtr_with_extra_week=3)),
+        ("REQ-N-DEC-MON-3", makeFY5253NearestEndMonthQuarter(
+            weekday=0, startingMonth=12, qtr_with_extra_week=3)),
+    ]
 
     for name, expected in pairs:
         offset = get_offset(name)
         assert offset == expected, ("Expected %r to yield %r (actual: %r)" %
                                     (name, expected, offset))
 
+
 def test_get_offset_legacy():
     pairs = [('w@Sat', Week(weekday=5))]
     for name, expected in pairs:
@@ -3636,8 +3943,8 @@ def test_get_offset_legacy():
         assert offset == expected, ("Expected %r to yield %r (actual: %r)" %
                                     (name, expected, offset))
 
-class TestParseTimeString(tm.TestCase):
 
+class TestParseTimeString(tm.TestCase):
     def test_parse_time_string(self):
         (date, parsed, reso) = parse_time_string('4Q1984')
         (date_lower, parsed_lower, reso_lower) = parse_time_string('4q1984')
@@ -3647,10 +3954,7 @@ class TestParseTimeString(tm.TestCase):
 
     def test_parse_time_quarter_w_dash(self):
         # https://github.com/pydata/pandas/issue/9688
-        pairs = [
-            ('1988-Q2', '1988Q2'),
-            ('2Q-1988', '2Q1988'),
-        ]
+        pairs = [('1988-Q2', '1988Q2'), ('2Q-1988', '2Q1988'), ]
 
         for dashed, normal in pairs:
             (date_dash, parsed_dash, reso_dash) = parse_time_string(dashed)
@@ -3692,11 +3996,10 @@ def test_quarterly_dont_normalize():
 
     for klass in offsets:
         result = date + klass()
-        assert(result.time() == date.time())
+        assert (result.time() == date.time())
 
 
 class TestOffsetAliases(tm.TestCase):
-
     def setUp(self):
         _offset_map.clear()
 
@@ -3737,33 +4040,34 @@ class TestOffsetAliases(tm.TestCase):
             self.assertEqual(stride, 3)
             self.assertEqual(k, _get_freq_str(code))
 
+
 def test_apply_ticks():
     result = offsets.Hour(3).apply(offsets.Hour(4))
     exp = offsets.Hour(7)
-    assert(result == exp)
+    assert (result == exp)
 
 
 def test_delta_to_tick():
     delta = timedelta(3)
 
     tick = offsets._delta_to_tick(delta)
-    assert(tick == offsets.Day(3))
+    assert (tick == offsets.Day(3))
 
 
 def test_dateoffset_misc():
     oset = offsets.DateOffset(months=2, days=4)
     # it works
-    result = oset.freqstr
+    oset.freqstr
 
-    assert(not offsets.DateOffset(months=2) == 2)
+    assert (not offsets.DateOffset(months=2) == 2)
 
 
 def test_freq_offsets():
     off = BDay(1, offset=timedelta(0, 1800))
-    assert(off.freqstr == 'B+30Min')
+    assert (off.freqstr == 'B+30Min')
 
     off = BDay(1, offset=timedelta(0, -1800))
-    assert(off.freqstr == 'B-30Min')
+    assert (off.freqstr == 'B-30Min')
 
 
 def get_all_subclasses(cls):
@@ -3774,6 +4078,7 @@ def get_all_subclasses(cls):
         ret | get_all_subclasses(this_subclass)
     return ret
 
+
 class TestCaching(tm.TestCase):
 
     # as of GH 6479 (in 0.14.0), offset caching is turned off
@@ -3791,7 +4096,8 @@ class TestCaching(tm.TestCase):
 
         self.assertTrue(inst1._should_cache(), cls)
 
-        DatetimeIndex(start=datetime(2013,1,31), end=datetime(2013,3,31), freq=inst1, normalize=True)
+        DatetimeIndex(start=datetime(2013, 1, 31), end=datetime(2013, 3, 31),
+                      freq=inst1, normalize=True)
         self.assertTrue(cls() in _daterange_cache, cls)
 
     def test_should_cache_month_end(self):
@@ -3806,35 +4112,40 @@ class TestCaching(tm.TestCase):
     def test_all_cacheableoffsets(self):
         for subclass in get_all_subclasses(CacheableOffset):
             if subclass.__name__[0] == "_" \
-                or subclass in TestCaching.no_simple_ctr:
+                    or subclass in TestCaching.no_simple_ctr:
                 continue
             self.run_X_index_creation(subclass)
 
     def test_month_end_index_creation(self):
-        DatetimeIndex(start=datetime(2013,1,31), end=datetime(2013,3,31), freq=MonthEnd(), normalize=True)
+        DatetimeIndex(start=datetime(2013, 1, 31), end=datetime(2013, 3, 31),
+                      freq=MonthEnd(), normalize=True)
         self.assertFalse(MonthEnd() in _daterange_cache)
 
     def test_bmonth_end_index_creation(self):
-        DatetimeIndex(start=datetime(2013,1,31), end=datetime(2013,3,29), freq=BusinessMonthEnd(), normalize=True)
+        DatetimeIndex(start=datetime(2013, 1, 31), end=datetime(2013, 3, 29),
+                      freq=BusinessMonthEnd(), normalize=True)
         self.assertFalse(BusinessMonthEnd() in _daterange_cache)
 
     def test_week_of_month_index_creation(self):
         inst1 = WeekOfMonth(weekday=1, week=2)
-        DatetimeIndex(start=datetime(2013,1,31), end=datetime(2013,3,29), freq=inst1, normalize=True)
+        DatetimeIndex(start=datetime(2013, 1, 31), end=datetime(2013, 3, 29),
+                      freq=inst1, normalize=True)
         inst2 = WeekOfMonth(weekday=1, week=2)
         self.assertFalse(inst2 in _daterange_cache)
 
+
 class TestReprNames(tm.TestCase):
     def test_str_for_named_is_name(self):
         # look at all the amazing combinations!
         month_prefixes = ['A', 'AS', 'BA', 'BAS', 'Q', 'BQ', 'BQS', 'QS']
-        names = [prefix + '-' + month for prefix in month_prefixes
-                    for month in ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN',
-                                  'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']]
+        names = [prefix + '-' + month
+                 for prefix in month_prefixes
+                 for month in ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL',
+                               'AUG', 'SEP', 'OCT', 'NOV', 'DEC']]
         days = ['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN']
         names += ['W-' + day for day in days]
-        names += ['WOM-' + week + day for week in ('1', '2', '3', '4')
-                                       for day in days]
+        names += ['WOM-' + week + day
+                  for week in ('1', '2', '3', '4') for day in days]
         _offset_map.clear()
         for name in names:
             offset = get_offset(name)
@@ -3857,23 +4168,19 @@ class TestDST(tm.TestCase):
 
     # test both basic names and dateutil timezones
     timezone_utc_offsets = {
-        'US/Eastern': dict(
-            utc_offset_daylight=-4,
-            utc_offset_standard=-5,
-            ),
-        'dateutil/US/Pacific': dict(
-            utc_offset_daylight=-7,
-            utc_offset_standard=-8,
-            )
-        }
+        'US/Eastern': dict(utc_offset_daylight=-4,
+                           utc_offset_standard=-5, ),
+        'dateutil/US/Pacific': dict(utc_offset_daylight=-7,
+                                    utc_offset_standard=-8, )
+    }
     valid_date_offsets_singular = [
         'weekday', 'day', 'hour', 'minute', 'second', 'microsecond'
-        ]
+    ]
     valid_date_offsets_plural = [
         'weeks', 'days',
         'hours', 'minutes', 'seconds',
         'milliseconds', 'microseconds'
-        ]
+    ]
 
     def _test_all_offsets(self, n, **kwds):
         valid_offsets = self.valid_date_offsets_plural if n > 1 \
@@ -3890,35 +4197,29 @@ class TestDST(tm.TestCase):
 
         if offset_name == 'weeks':
             # dates should match
-            self.assertTrue(
-                t.date() ==
-                timedelta(days=7 * offset.kwds['weeks']) + tstart.date()
-                )
+            self.assertTrue(t.date() == timedelta(days=7 * offset.kwds[
+                'weeks']) + tstart.date())
             # expect the same day of week, hour of day, minute, second, ...
-            self.assertTrue(
-                t.dayofweek == tstart.dayofweek and
-                t.hour == tstart.hour and
-                t.minute == tstart.minute and
-                t.second == tstart.second
-                )
+            self.assertTrue(t.dayofweek == tstart.dayofweek and t.hour ==
+                            tstart.hour and t.minute == tstart.minute and
+                            t.second == tstart.second)
         elif offset_name == 'days':
             # dates should match
-            self.assertTrue(timedelta(offset.kwds['days']) + tstart.date() == t.date())
+            self.assertTrue(timedelta(offset.kwds['days']) + tstart.date() ==
+                            t.date())
             # expect the same hour of day, minute, second, ...
-            self.assertTrue(
-                t.hour == tstart.hour and
-                t.minute == tstart.minute and
-                t.second == tstart.second
-                )
+            self.assertTrue(t.hour == tstart.hour and t.minute == tstart.minute
+                            and t.second == tstart.second)
         elif offset_name in self.valid_date_offsets_singular:
             # expect the signular offset value to match between tstart and t
-            datepart_offset = getattr(t, offset_name if offset_name != 'weekday' else 'dayofweek')
+            datepart_offset = getattr(t, offset_name
+                                      if offset_name != 'weekday' else
+                                      'dayofweek')
             self.assertTrue(datepart_offset == offset.kwds[offset_name])
         else:
             # the offset should be the same as if it was done in UTC
-            self.assertTrue(
-                t == (tstart.tz_convert('UTC') + offset).tz_convert('US/Pacific')
-                )
+            self.assertTrue(t == (tstart.tz_convert('UTC') + offset
+                                  ).tz_convert('US/Pacific'))
 
     def _make_timestamp(self, string, hrs_offset, tz):
         offset_string = '{hrs:02d}00'.format(hrs=hrs_offset) if hrs_offset >= 0 else \
@@ -3931,10 +4232,9 @@ class TestDST(tm.TestCase):
             hrs_pre = utc_offsets['utc_offset_daylight']
             hrs_post = utc_offsets['utc_offset_standard']
             self._test_all_offsets(
-                n=3,
-                tstart=self._make_timestamp(self.ts_pre_fallback, hrs_pre, tz),
-                expected_utc_offset=hrs_post
-                )
+                n=3, tstart=self._make_timestamp(self.ts_pre_fallback,
+                                                 hrs_pre, tz),
+                expected_utc_offset=hrs_post)
 
     def test_springforward_plural(self):
         """test moving from standard to daylight savings"""
@@ -3942,31 +4242,24 @@ class TestDST(tm.TestCase):
             hrs_pre = utc_offsets['utc_offset_standard']
             hrs_post = utc_offsets['utc_offset_daylight']
             self._test_all_offsets(
-                n=3,
-                tstart=self._make_timestamp(self.ts_pre_springfwd, hrs_pre, tz),
-                expected_utc_offset=hrs_post
-                )
+                n=3, tstart=self._make_timestamp(self.ts_pre_springfwd,
+                                                 hrs_pre, tz),
+                expected_utc_offset=hrs_post)
 
     def test_fallback_singular(self):
-        # in the case of signular offsets, we dont neccesarily know which utc offset
-        # the new Timestamp will wind up in (the tz for 1 month may be different from 1 second)
-        # so we don't specify an expected_utc_offset
+        # in the case of signular offsets, we dont neccesarily know which utc
+        # offset the new Timestamp will wind up in (the tz for 1 month may be
+        # different from 1 second) so we don't specify an expected_utc_offset
         for tz, utc_offsets in self.timezone_utc_offsets.items():
             hrs_pre = utc_offsets['utc_offset_standard']
-            self._test_all_offsets(
-                n=1,
-                tstart=self._make_timestamp(self.ts_pre_fallback, hrs_pre, tz),
-                expected_utc_offset=None
-                )
+            self._test_all_offsets(n=1, tstart=self._make_timestamp(
+                self.ts_pre_fallback, hrs_pre, tz), expected_utc_offset=None)
 
     def test_springforward_singular(self):
         for tz, utc_offsets in self.timezone_utc_offsets.items():
             hrs_pre = utc_offsets['utc_offset_standard']
-            self._test_all_offsets(
-                n=1,
-                tstart=self._make_timestamp(self.ts_pre_springfwd, hrs_pre, tz),
-                expected_utc_offset=None
-                )
+            self._test_all_offsets(n=1, tstart=self._make_timestamp(
+                self.ts_pre_springfwd, hrs_pre, tz), expected_utc_offset=None)
 
     def test_all_offset_classes(self):
         tests = {MonthBegin: ['11/2/2012', '12/1/2012'],
@@ -3984,14 +4277,14 @@ class TestDST(tm.TestCase):
                  QuarterEnd: ['11/2/2012', '12/31/2012'],
                  BQuarterBegin: ['11/2/2012', '12/3/2012'],
                  BQuarterEnd: ['11/2/2012', '12/31/2012'],
-                 Day: ['11/4/2012', '11/4/2012 23:00']
-                 }
+                 Day: ['11/4/2012', '11/4/2012 23:00']}
 
         for offset, test_values in iteritems(tests):
             first = Timestamp(test_values[0], tz='US/Eastern') + offset()
             second = Timestamp(test_values[1], tz='US/Eastern')
             self.assertEqual(first, second, str(offset))
 
+
 if __name__ == '__main__':
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
                    exit=False)
diff --git a/pandas/tseries/tests/test_period.py b/pandas/tseries/tests/test_period.py
index d88476628..e37ffa397 100644
--- a/pandas/tseries/tests/test_period.py
+++ b/pandas/tseries/tests/test_period.py
@@ -26,14 +26,15 @@ from pandas.compat import range, lrange, lmap, zip
 
 from pandas import Series, DataFrame, _np_version_under1p9
 from pandas import tslib
-from pandas.util.testing import(assert_series_equal, assert_almost_equal,
-                                assertRaisesRegexp)
+from pandas.util.testing import (assert_series_equal, assert_almost_equal,
+                                 assertRaisesRegexp)
 import pandas.util.testing as tm
 from pandas import compat
 
 
 class TestPeriodProperties(tm.TestCase):
     "Test properties such as year, month, weekday, etc...."
+
     #
 
     def test_quarterly_negative_ordinals(self):
@@ -132,8 +133,7 @@ class TestPeriodProperties(tm.TestCase):
         with tm.assertRaisesRegexp(ValueError, msg):
             Period('2011-01', freq='-3M')
 
-        msg = ('Frequency must be positive, because it'
-               ' represents span: 0M')
+        msg = ('Frequency must be positive, because it' ' represents span: 0M')
         with tm.assertRaisesRegexp(ValueError, msg):
             Period('2011-01', freq='0M')
 
@@ -178,13 +178,15 @@ class TestPeriodProperties(tm.TestCase):
         from pandas.tslib import maybe_get_tz
         for case in ['dateutil/Europe/Brussels', 'dateutil/Asia/Tokyo',
                      'dateutil/US/Pacific']:
-            p = Period('1/1/2005', freq='M').to_timestamp(tz=maybe_get_tz(case))
+            p = Period('1/1/2005', freq='M').to_timestamp(
+                tz=maybe_get_tz(case))
             exp = Timestamp('1/1/2005', tz='UTC').tz_convert(case)
             self.assertEqual(p, exp)
             self.assertEqual(p.tz, gettz(case.split('/', 1)[1]))
             self.assertEqual(p.tz, exp.tz)
 
-            p = Period('1/1/2005', freq='M').to_timestamp(freq='3H', tz=maybe_get_tz(case))
+            p = Period('1/1/2005',
+                       freq='M').to_timestamp(freq='3H', tz=maybe_get_tz(case))
             exp = Timestamp('1/1/2005', tz='UTC').tz_convert(case)
             self.assertEqual(p, exp)
             self.assertEqual(p.tz, gettz(case.split('/', 1)[1]))
@@ -192,7 +194,8 @@ class TestPeriodProperties(tm.TestCase):
 
     def test_timestamp_tz_arg_dateutil_from_string(self):
         from pandas.tslib import _dateutil_gettz as gettz
-        p = Period('1/1/2005', freq='M').to_timestamp(tz='dateutil/Europe/Brussels')
+        p = Period('1/1/2005',
+                   freq='M').to_timestamp(tz='dateutil/Europe/Brussels')
         self.assertEqual(p.tz, gettz('Europe/Brussels'))
 
     def test_timestamp_nat_tz(self):
@@ -352,7 +355,6 @@ class TestPeriodProperties(tm.TestCase):
 
         self.assertRaises(ValueError, Period, '2007-1-1', freq='X')
 
-
     def test_period_constructor_offsets(self):
         self.assertEqual(Period('1/1/2005', freq=offsets.MonthEnd()),
                          Period('1/1/2005', freq='M'))
@@ -374,16 +376,18 @@ class TestPeriodProperties(tm.TestCase):
 
         self.assertEqual(Period(year=2005, month=3, day=1, freq=offsets.Day()),
                          Period(year=2005, month=3, day=1, freq='D'))
-        self.assertEqual(Period(year=2012, month=3, day=10, freq=offsets.BDay()),
+        self.assertEqual(Period(year=2012, month=3, day=10,
+                                freq=offsets.BDay()),
                          Period(year=2012, month=3, day=10, freq='B'))
 
         expected = Period('2005-03-01', freq='3D')
-        self.assertEqual(Period(year=2005, month=3, day=1, freq=offsets.Day(3)),
-                         expected)
+        self.assertEqual(Period(year=2005, month=3, day=1,
+                                freq=offsets.Day(3)), expected)
         self.assertEqual(Period(year=2005, month=3, day=1, freq='3D'),
                          expected)
 
-        self.assertEqual(Period(year=2012, month=3, day=10, freq=offsets.BDay(3)),
+        self.assertEqual(Period(year=2012, month=3, day=10,
+                                freq=offsets.BDay(3)),
                          Period(year=2012, month=3, day=10, freq='3B'))
 
         self.assertEqual(Period(200701, freq=offsets.MonthEnd()),
@@ -428,7 +432,6 @@ class TestPeriodProperties(tm.TestCase):
 
         self.assertRaises(ValueError, Period, '2007-1-1', freq='X')
 
-
     def test_freq_str(self):
         i1 = Period('1982', freq='Min')
         self.assertEqual(i1.freq, offsets.Minute())
@@ -458,8 +461,8 @@ class TestPeriodProperties(tm.TestCase):
     def test_strftime(self):
         p = Period('2000-1-1 12:34:12', freq='S')
         res = p.strftime('%Y-%m-%d %H:%M:%S')
-        self.assertEqual(res,  '2000-01-01 12:34:12')
-        tm.assertIsInstance(res, compat.text_type) # GH3363
+        self.assertEqual(res, '2000-01-01 12:34:12')
+        tm.assertIsInstance(res, compat.text_type)  # GH3363
 
     def test_sub_delta(self):
         left, right = Period('2011', freq='A'), Period('2007', freq='A')
@@ -484,8 +487,7 @@ class TestPeriodProperties(tm.TestCase):
             self.assertEqual(end_ts, p.to_timestamp('D', how=a))
             self.assertEqual(end_ts, p.to_timestamp('3D', how=a))
 
-        from_lst = ['A', 'Q', 'M', 'W', 'B',
-                    'D', 'H', 'Min', 'S']
+        from_lst = ['A', 'Q', 'M', 'W', 'B', 'D', 'H', 'Min', 'S']
 
         def _ex(p):
             return Timestamp((p + 1).start_time.value - 1)
@@ -515,7 +517,6 @@ class TestPeriodProperties(tm.TestCase):
         result = p.to_timestamp('2T', how='end')
         self.assertEqual(result, expected)
 
-
         result = p.to_timestamp(how='end')
         expected = datetime(1985, 12, 31)
         self.assertEqual(result, expected)
@@ -640,7 +641,8 @@ class TestPeriodProperties(tm.TestCase):
         assert_equal(w_date.week, 1)
         assert_equal((w_date - 1).week, 52)
         assert_equal(w_date.days_in_month, 31)
-        assert_equal(Period(freq='W', year=2012, month=2, day=1).days_in_month, 29)
+        assert_equal(Period(freq='W', year=2012,
+                            month=2, day=1).days_in_month, 29)
 
     def test_properties_weekly_legacy(self):
         # Test properties on Periods with daily frequency.
@@ -668,7 +670,8 @@ class TestPeriodProperties(tm.TestCase):
         assert_equal(b_date.weekday, 0)
         assert_equal(b_date.dayofyear, 1)
         assert_equal(b_date.days_in_month, 31)
-        assert_equal(Period(freq='B', year=2012, month=2, day=1).days_in_month, 29)
+        assert_equal(Period(freq='B', year=2012,
+                            month=2, day=1).days_in_month, 29)
         #
         d_date = Period(freq='D', year=2007, month=1, day=1)
         #
@@ -717,8 +720,8 @@ class TestPeriodProperties(tm.TestCase):
 
     def test_properties_secondly(self):
         # Test properties on Periods with secondly frequency.
-        s_date = Period(freq='Min', year=2007, month=1, day=1,
-                        hour=0, minute=0, second=0)
+        s_date = Period(freq='Min', year=2007, month=1, day=1, hour=0,
+                        minute=0, second=0)
         #
         assert_equal(s_date.year, 2007)
         assert_equal(s_date.quarter, 1)
@@ -737,8 +740,8 @@ class TestPeriodProperties(tm.TestCase):
         p_nat = Period('NaT', freq='M')
         t_nat = pd.Timestamp('NaT')
         # confirm Period('NaT') work identical with Timestamp('NaT')
-        for f in ['year', 'month', 'day', 'hour', 'minute', 'second',
-                  'week', 'dayofyear', 'quarter', 'days_in_month']:
+        for f in ['year', 'month', 'day', 'hour', 'minute', 'second', 'week',
+                  'dayofyear', 'quarter', 'days_in_month']:
             self.assertTrue(np.isnan(getattr(p_nat, f)))
             self.assertTrue(np.isnan(getattr(t_nat, f)))
 
@@ -801,11 +804,14 @@ class TestPeriodProperties(tm.TestCase):
     def test_asfreq_MS(self):
         initial = Period("2013")
 
-        self.assertEqual(initial.asfreq(freq="M", how="S"), Period('2013-01', 'M'))
+        self.assertEqual(initial.asfreq(freq="M", how="S"),
+                         Period('2013-01', 'M'))
         self.assertRaises(ValueError, initial.asfreq, freq="MS", how="S")
-        tm.assertRaisesRegexp(ValueError, "Unknown freqstr: MS", pd.Period, '2013-01', 'MS')
+        tm.assertRaisesRegexp(ValueError, "Unknown freqstr: MS", pd.Period,
+                              '2013-01', 'MS')
         self.assertTrue(_period_code_map.get("MS") is None)
 
+
 def noWrap(item):
     return item
 
@@ -842,16 +848,15 @@ class TestFreqConversion(tm.TestCase):
         ival_A_to_B_end = Period(freq='B', year=2007, month=12, day=31)
         ival_A_to_D_start = Period(freq='D', year=2007, month=1, day=1)
         ival_A_to_D_end = Period(freq='D', year=2007, month=12, day=31)
-        ival_A_to_H_start = Period(freq='H', year=2007, month=1, day=1,
-                                   hour=0)
+        ival_A_to_H_start = Period(freq='H', year=2007, month=1, day=1, hour=0)
         ival_A_to_H_end = Period(freq='H', year=2007, month=12, day=31,
                                  hour=23)
         ival_A_to_T_start = Period(freq='Min', year=2007, month=1, day=1,
                                    hour=0, minute=0)
         ival_A_to_T_end = Period(freq='Min', year=2007, month=12, day=31,
                                  hour=23, minute=59)
-        ival_A_to_S_start = Period(freq='S', year=2007, month=1, day=1,
-                                   hour=0, minute=0, second=0)
+        ival_A_to_S_start = Period(freq='S', year=2007, month=1, day=1, hour=0,
+                                   minute=0, second=0)
         ival_A_to_S_end = Period(freq='S', year=2007, month=12, day=31,
                                  hour=23, minute=59, second=59)
 
@@ -910,18 +915,16 @@ class TestFreqConversion(tm.TestCase):
         ival_Q_to_B_end = Period(freq='B', year=2007, month=3, day=30)
         ival_Q_to_D_start = Period(freq='D', year=2007, month=1, day=1)
         ival_Q_to_D_end = Period(freq='D', year=2007, month=3, day=31)
-        ival_Q_to_H_start = Period(freq='H', year=2007, month=1, day=1,
-                                   hour=0)
-        ival_Q_to_H_end = Period(freq='H', year=2007, month=3, day=31,
-                                 hour=23)
+        ival_Q_to_H_start = Period(freq='H', year=2007, month=1, day=1, hour=0)
+        ival_Q_to_H_end = Period(freq='H', year=2007, month=3, day=31, hour=23)
         ival_Q_to_T_start = Period(freq='Min', year=2007, month=1, day=1,
                                    hour=0, minute=0)
         ival_Q_to_T_end = Period(freq='Min', year=2007, month=3, day=31,
                                  hour=23, minute=59)
-        ival_Q_to_S_start = Period(freq='S', year=2007, month=1, day=1,
-                                   hour=0, minute=0, second=0)
-        ival_Q_to_S_end = Period(freq='S', year=2007, month=3, day=31,
-                                 hour=23, minute=59, second=59)
+        ival_Q_to_S_start = Period(freq='S', year=2007, month=1, day=1, hour=0,
+                                   minute=0, second=0)
+        ival_Q_to_S_end = Period(freq='S', year=2007, month=3, day=31, hour=23,
+                                 minute=59, second=59)
 
         ival_QEJAN_to_D_start = Period(freq='D', year=2006, month=2, day=1)
         ival_QEJAN_to_D_end = Period(freq='D', year=2006, month=4, day=30)
@@ -968,18 +971,16 @@ class TestFreqConversion(tm.TestCase):
         ival_M_to_B_end = Period(freq='B', year=2007, month=1, day=31)
         ival_M_to_D_start = Period(freq='D', year=2007, month=1, day=1)
         ival_M_to_D_end = Period(freq='D', year=2007, month=1, day=31)
-        ival_M_to_H_start = Period(freq='H', year=2007, month=1, day=1,
-                                   hour=0)
-        ival_M_to_H_end = Period(freq='H', year=2007, month=1, day=31,
-                                 hour=23)
+        ival_M_to_H_start = Period(freq='H', year=2007, month=1, day=1, hour=0)
+        ival_M_to_H_end = Period(freq='H', year=2007, month=1, day=31, hour=23)
         ival_M_to_T_start = Period(freq='Min', year=2007, month=1, day=1,
                                    hour=0, minute=0)
         ival_M_to_T_end = Period(freq='Min', year=2007, month=1, day=31,
                                  hour=23, minute=59)
-        ival_M_to_S_start = Period(freq='S', year=2007, month=1, day=1,
-                                   hour=0, minute=0, second=0)
-        ival_M_to_S_end = Period(freq='S', year=2007, month=1, day=31,
-                                 hour=23, minute=59, second=59)
+        ival_M_to_S_start = Period(freq='S', year=2007, month=1, day=1, hour=0,
+                                   minute=0, second=0)
+        ival_M_to_S_end = Period(freq='S', year=2007, month=1, day=31, hour=23,
+                                 minute=59, second=59)
 
         assert_equal(ival_M.asfreq('A'), ival_M_to_A)
         assert_equal(ival_M_end_of_year.asfreq('A'), ival_M_to_A)
@@ -1041,11 +1042,9 @@ class TestFreqConversion(tm.TestCase):
             ival_W_to_A_end_of_year = Period(freq='A', year=2008)
 
         if Period(freq='D', year=2007, month=3, day=31).weekday == 6:
-            ival_W_to_Q_end_of_quarter = Period(freq='Q', year=2007,
-                                                quarter=1)
+            ival_W_to_Q_end_of_quarter = Period(freq='Q', year=2007, quarter=1)
         else:
-            ival_W_to_Q_end_of_quarter = Period(freq='Q', year=2007,
-                                                quarter=2)
+            ival_W_to_Q_end_of_quarter = Period(freq='Q', year=2007, quarter=2)
 
         if Period(freq='D', year=2007, month=1, day=31).weekday == 6:
             ival_W_to_M_end_of_month = Period(freq='M', year=2007, month=1)
@@ -1056,28 +1055,24 @@ class TestFreqConversion(tm.TestCase):
         ival_W_to_B_end = Period(freq='B', year=2007, month=1, day=5)
         ival_W_to_D_start = Period(freq='D', year=2007, month=1, day=1)
         ival_W_to_D_end = Period(freq='D', year=2007, month=1, day=7)
-        ival_W_to_H_start = Period(freq='H', year=2007, month=1, day=1,
-                                   hour=0)
-        ival_W_to_H_end = Period(freq='H', year=2007, month=1, day=7,
-                                 hour=23)
+        ival_W_to_H_start = Period(freq='H', year=2007, month=1, day=1, hour=0)
+        ival_W_to_H_end = Period(freq='H', year=2007, month=1, day=7, hour=23)
         ival_W_to_T_start = Period(freq='Min', year=2007, month=1, day=1,
                                    hour=0, minute=0)
         ival_W_to_T_end = Period(freq='Min', year=2007, month=1, day=7,
                                  hour=23, minute=59)
-        ival_W_to_S_start = Period(freq='S', year=2007, month=1, day=1,
-                                   hour=0, minute=0, second=0)
-        ival_W_to_S_end = Period(freq='S', year=2007, month=1, day=7,
-                                 hour=23, minute=59, second=59)
+        ival_W_to_S_start = Period(freq='S', year=2007, month=1, day=1, hour=0,
+                                   minute=0, second=0)
+        ival_W_to_S_end = Period(freq='S', year=2007, month=1, day=7, hour=23,
+                                 minute=59, second=59)
 
         assert_equal(ival_W.asfreq('A'), ival_W_to_A)
-        assert_equal(ival_W_end_of_year.asfreq('A'),
-                     ival_W_to_A_end_of_year)
+        assert_equal(ival_W_end_of_year.asfreq('A'), ival_W_to_A_end_of_year)
         assert_equal(ival_W.asfreq('Q'), ival_W_to_Q)
         assert_equal(ival_W_end_of_quarter.asfreq('Q'),
                      ival_W_to_Q_end_of_quarter)
         assert_equal(ival_W.asfreq('M'), ival_W_to_M)
-        assert_equal(ival_W_end_of_month.asfreq('M'),
-                     ival_W_to_M_end_of_month)
+        assert_equal(ival_W_end_of_month.asfreq('M'), ival_W_to_M_end_of_month)
 
         assert_equal(ival_W.asfreq('B', 'S'), ival_W_to_B_start)
         assert_equal(ival_W.asfreq('B', 'E'), ival_W_to_B_end)
@@ -1148,7 +1143,8 @@ class TestFreqConversion(tm.TestCase):
         with tm.assert_produces_warning(FutureWarning):
             ival_W_end_of_year = Period(freq='WK', year=2007, month=12, day=31)
         with tm.assert_produces_warning(FutureWarning):
-            ival_W_end_of_quarter = Period(freq='WK', year=2007, month=3, day=31)
+            ival_W_end_of_quarter = Period(freq='WK', year=2007, month=3,
+                                           day=31)
         with tm.assert_produces_warning(FutureWarning):
             ival_W_end_of_month = Period(freq='WK', year=2007, month=1, day=31)
         ival_W_to_A = Period(freq='A', year=2007)
@@ -1161,11 +1157,9 @@ class TestFreqConversion(tm.TestCase):
             ival_W_to_A_end_of_year = Period(freq='A', year=2008)
 
         if Period(freq='D', year=2007, month=3, day=31).weekday == 6:
-            ival_W_to_Q_end_of_quarter = Period(freq='Q', year=2007,
-                                                quarter=1)
+            ival_W_to_Q_end_of_quarter = Period(freq='Q', year=2007, quarter=1)
         else:
-            ival_W_to_Q_end_of_quarter = Period(freq='Q', year=2007,
-                                                quarter=2)
+            ival_W_to_Q_end_of_quarter = Period(freq='Q', year=2007, quarter=2)
 
         if Period(freq='D', year=2007, month=1, day=31).weekday == 6:
             ival_W_to_M_end_of_month = Period(freq='M', year=2007, month=1)
@@ -1176,28 +1170,24 @@ class TestFreqConversion(tm.TestCase):
         ival_W_to_B_end = Period(freq='B', year=2007, month=1, day=5)
         ival_W_to_D_start = Period(freq='D', year=2007, month=1, day=1)
         ival_W_to_D_end = Period(freq='D', year=2007, month=1, day=7)
-        ival_W_to_H_start = Period(freq='H', year=2007, month=1, day=1,
-                                   hour=0)
-        ival_W_to_H_end = Period(freq='H', year=2007, month=1, day=7,
-                                 hour=23)
+        ival_W_to_H_start = Period(freq='H', year=2007, month=1, day=1, hour=0)
+        ival_W_to_H_end = Period(freq='H', year=2007, month=1, day=7, hour=23)
         ival_W_to_T_start = Period(freq='Min', year=2007, month=1, day=1,
                                    hour=0, minute=0)
         ival_W_to_T_end = Period(freq='Min', year=2007, month=1, day=7,
                                  hour=23, minute=59)
-        ival_W_to_S_start = Period(freq='S', year=2007, month=1, day=1,
-                                   hour=0, minute=0, second=0)
-        ival_W_to_S_end = Period(freq='S', year=2007, month=1, day=7,
-                                 hour=23, minute=59, second=59)
+        ival_W_to_S_start = Period(freq='S', year=2007, month=1, day=1, hour=0,
+                                   minute=0, second=0)
+        ival_W_to_S_end = Period(freq='S', year=2007, month=1, day=7, hour=23,
+                                 minute=59, second=59)
 
         assert_equal(ival_W.asfreq('A'), ival_W_to_A)
-        assert_equal(ival_W_end_of_year.asfreq('A'),
-                     ival_W_to_A_end_of_year)
+        assert_equal(ival_W_end_of_year.asfreq('A'), ival_W_to_A_end_of_year)
         assert_equal(ival_W.asfreq('Q'), ival_W_to_Q)
         assert_equal(ival_W_end_of_quarter.asfreq('Q'),
                      ival_W_to_Q_end_of_quarter)
         assert_equal(ival_W.asfreq('M'), ival_W_to_M)
-        assert_equal(ival_W_end_of_month.asfreq('M'),
-                     ival_W_to_M_end_of_month)
+        assert_equal(ival_W_end_of_month.asfreq('M'), ival_W_to_M_end_of_month)
 
         assert_equal(ival_W.asfreq('B', 'S'), ival_W_to_B_start)
         assert_equal(ival_W.asfreq('B', 'E'), ival_W_to_B_end)
@@ -1244,18 +1234,16 @@ class TestFreqConversion(tm.TestCase):
         ival_B_to_M = Period(freq='M', year=2007, month=1)
         ival_B_to_W = Period(freq='W', year=2007, month=1, day=7)
         ival_B_to_D = Period(freq='D', year=2007, month=1, day=1)
-        ival_B_to_H_start = Period(freq='H', year=2007, month=1, day=1,
-                                   hour=0)
-        ival_B_to_H_end = Period(freq='H', year=2007, month=1, day=1,
-                                 hour=23)
+        ival_B_to_H_start = Period(freq='H', year=2007, month=1, day=1, hour=0)
+        ival_B_to_H_end = Period(freq='H', year=2007, month=1, day=1, hour=23)
         ival_B_to_T_start = Period(freq='Min', year=2007, month=1, day=1,
                                    hour=0, minute=0)
         ival_B_to_T_end = Period(freq='Min', year=2007, month=1, day=1,
                                  hour=23, minute=59)
-        ival_B_to_S_start = Period(freq='S', year=2007, month=1, day=1,
-                                   hour=0, minute=0, second=0)
-        ival_B_to_S_end = Period(freq='S', year=2007, month=1, day=1,
-                                 hour=23, minute=59, second=59)
+        ival_B_to_S_start = Period(freq='S', year=2007, month=1, day=1, hour=0,
+                                   minute=0, second=0)
+        ival_B_to_S_end = Period(freq='S', year=2007, month=1, day=1, hour=23,
+                                 minute=59, second=59)
 
         assert_equal(ival_B.asfreq('A'), ival_B_to_A)
         assert_equal(ival_B_end_of_year.asfreq('A'), ival_B_to_A)
@@ -1289,7 +1277,9 @@ class TestFreqConversion(tm.TestCase):
         ival_D_friday = Period(freq='D', year=2007, month=1, day=5)
         ival_D_saturday = Period(freq='D', year=2007, month=1, day=6)
         ival_D_sunday = Period(freq='D', year=2007, month=1, day=7)
-        ival_D_monday = Period(freq='D', year=2007, month=1, day=8)
+
+        # TODO: unused?
+        # ival_D_monday = Period(freq='D', year=2007, month=1, day=8)
 
         ival_B_friday = Period(freq='B', year=2007, month=1, day=5)
         ival_B_monday = Period(freq='B', year=2007, month=1, day=8)
@@ -1307,27 +1297,22 @@ class TestFreqConversion(tm.TestCase):
         ival_D_to_M = Period(freq='M', year=2007, month=1)
         ival_D_to_W = Period(freq='W', year=2007, month=1, day=7)
 
-        ival_D_to_H_start = Period(freq='H', year=2007, month=1, day=1,
-                                   hour=0)
-        ival_D_to_H_end = Period(freq='H', year=2007, month=1, day=1,
-                                 hour=23)
+        ival_D_to_H_start = Period(freq='H', year=2007, month=1, day=1, hour=0)
+        ival_D_to_H_end = Period(freq='H', year=2007, month=1, day=1, hour=23)
         ival_D_to_T_start = Period(freq='Min', year=2007, month=1, day=1,
                                    hour=0, minute=0)
         ival_D_to_T_end = Period(freq='Min', year=2007, month=1, day=1,
                                  hour=23, minute=59)
-        ival_D_to_S_start = Period(freq='S', year=2007, month=1, day=1,
-                                   hour=0, minute=0, second=0)
-        ival_D_to_S_end = Period(freq='S', year=2007, month=1, day=1,
-                                 hour=23, minute=59, second=59)
+        ival_D_to_S_start = Period(freq='S', year=2007, month=1, day=1, hour=0,
+                                   minute=0, second=0)
+        ival_D_to_S_end = Period(freq='S', year=2007, month=1, day=1, hour=23,
+                                 minute=59, second=59)
 
         assert_equal(ival_D.asfreq('A'), ival_D_to_A)
 
-        assert_equal(ival_D_end_of_quarter.asfreq('A-JAN'),
-                     ival_Deoq_to_AJAN)
-        assert_equal(ival_D_end_of_quarter.asfreq('A-JUN'),
-                     ival_Deoq_to_AJUN)
-        assert_equal(ival_D_end_of_quarter.asfreq('A-DEC'),
-                     ival_Deoq_to_ADEC)
+        assert_equal(ival_D_end_of_quarter.asfreq('A-JAN'), ival_Deoq_to_AJAN)
+        assert_equal(ival_D_end_of_quarter.asfreq('A-JUN'), ival_Deoq_to_AJUN)
+        assert_equal(ival_D_end_of_quarter.asfreq('A-DEC'), ival_Deoq_to_ADEC)
 
         assert_equal(ival_D_end_of_year.asfreq('A'), ival_D_to_A)
         assert_equal(ival_D_end_of_quarter.asfreq('Q'), ival_D_to_QEDEC)
@@ -1380,12 +1365,12 @@ class TestFreqConversion(tm.TestCase):
 
         ival_H_to_T_start = Period(freq='Min', year=2007, month=1, day=1,
                                    hour=0, minute=0)
-        ival_H_to_T_end = Period(freq='Min', year=2007, month=1, day=1,
-                                 hour=0, minute=59)
-        ival_H_to_S_start = Period(freq='S', year=2007, month=1, day=1,
-                                   hour=0, minute=0, second=0)
-        ival_H_to_S_end = Period(freq='S', year=2007, month=1, day=1,
-                                 hour=0, minute=59, second=59)
+        ival_H_to_T_end = Period(freq='Min', year=2007, month=1, day=1, hour=0,
+                                 minute=59)
+        ival_H_to_S_start = Period(freq='S', year=2007, month=1, day=1, hour=0,
+                                   minute=0, second=0)
+        ival_H_to_S_end = Period(freq='S', year=2007, month=1, day=1, hour=0,
+                                 minute=59, second=59)
 
         assert_equal(ival_H.asfreq('A'), ival_H_to_A)
         assert_equal(ival_H_end_of_year.asfreq('A'), ival_H_to_A)
@@ -1410,8 +1395,8 @@ class TestFreqConversion(tm.TestCase):
     def test_conv_minutely(self):
         # frequency conversion tests: from Minutely Frequency"
 
-        ival_T = Period(freq='Min', year=2007, month=1, day=1,
-                        hour=0, minute=0)
+        ival_T = Period(freq='Min', year=2007, month=1, day=1, hour=0,
+                        minute=0)
         ival_T_end_of_year = Period(freq='Min', year=2007, month=12, day=31,
                                     hour=23, minute=59)
         ival_T_end_of_quarter = Period(freq='Min', year=2007, month=3, day=31,
@@ -1435,10 +1420,10 @@ class TestFreqConversion(tm.TestCase):
         ival_T_to_B = Period(freq='B', year=2007, month=1, day=1)
         ival_T_to_H = Period(freq='H', year=2007, month=1, day=1, hour=0)
 
-        ival_T_to_S_start = Period(freq='S', year=2007, month=1, day=1,
-                                   hour=0, minute=0, second=0)
-        ival_T_to_S_end = Period(freq='S', year=2007, month=1, day=1,
-                                 hour=0, minute=0, second=59)
+        ival_T_to_S_start = Period(freq='S', year=2007, month=1, day=1, hour=0,
+                                   minute=0, second=0)
+        ival_T_to_S_end = Period(freq='S', year=2007, month=1, day=1, hour=0,
+                                 minute=0, second=59)
 
         assert_equal(ival_T.asfreq('A'), ival_T_to_A)
         assert_equal(ival_T_end_of_year.asfreq('A'), ival_T_to_A)
@@ -1463,8 +1448,8 @@ class TestFreqConversion(tm.TestCase):
     def test_conv_secondly(self):
         # frequency conversion tests: from Secondly Frequency"
 
-        ival_S = Period(freq='S', year=2007, month=1, day=1,
-                        hour=0, minute=0, second=0)
+        ival_S = Period(freq='S', year=2007, month=1, day=1, hour=0, minute=0,
+                        second=0)
         ival_S_end_of_year = Period(freq='S', year=2007, month=12, day=31,
                                     hour=23, minute=59, second=59)
         ival_S_end_of_quarter = Period(freq='S', year=2007, month=3, day=31,
@@ -1488,10 +1473,9 @@ class TestFreqConversion(tm.TestCase):
         ival_S_to_W = Period(freq='W', year=2007, month=1, day=7)
         ival_S_to_D = Period(freq='D', year=2007, month=1, day=1)
         ival_S_to_B = Period(freq='B', year=2007, month=1, day=1)
-        ival_S_to_H = Period(freq='H', year=2007, month=1, day=1,
-                             hour=0)
-        ival_S_to_T = Period(freq='Min', year=2007, month=1, day=1,
-                             hour=0, minute=0)
+        ival_S_to_H = Period(freq='H', year=2007, month=1, day=1, hour=0)
+        ival_S_to_T = Period(freq='Min', year=2007, month=1, day=1, hour=0,
+                             minute=0)
 
         assert_equal(ival_S.asfreq('A'), ival_S_to_A)
         assert_equal(ival_S_end_of_year.asfreq('A'), ival_S_to_A)
@@ -1606,14 +1590,12 @@ class TestFreqConversion(tm.TestCase):
 
 
 class TestPeriodIndex(tm.TestCase):
-
     def setUp(self):
         pass
 
     def test_hash_error(self):
         index = period_range('20010101', periods=10)
-        with tm.assertRaisesRegexp(TypeError,
-                                   "unhashable type: %r" %
+        with tm.assertRaisesRegexp(TypeError, "unhashable type: %r" %
                                    type(index).__name__):
             hash(index)
 
@@ -1745,10 +1727,10 @@ class TestPeriodIndex(tm.TestCase):
         self.assertTrue(result.equals(idx))
 
     def test_constructor_nat(self):
-        self.assertRaises(
-            ValueError, period_range, start='NaT', end='2011-01-01', freq='M')
-        self.assertRaises(
-            ValueError, period_range, start='2011-01-01', end='NaT', freq='M')
+        self.assertRaises(ValueError, period_range, start='NaT',
+                          end='2011-01-01', freq='M')
+        self.assertRaises(ValueError, period_range, start='2011-01-01',
+                          end='NaT', freq='M')
 
     def test_constructor_year_and_quarter(self):
         year = pd.Series([2001, 2002, 2003])
@@ -1764,11 +1746,13 @@ class TestPeriodIndex(tm.TestCase):
         for func in [PeriodIndex, period_range]:
             # must be the same, but for sure...
             pidx = func(start='2014-01', freq='2M', periods=4)
-            expected = PeriodIndex(['2014-01', '2014-03', '2014-05', '2014-07'], freq='M')
+            expected = PeriodIndex(
+                ['2014-01', '2014-03', '2014-05', '2014-07'], freq='M')
             tm.assert_index_equal(pidx, expected)
 
             pidx = func(start='2014-01-02', end='2014-01-15', freq='3D')
-            expected = PeriodIndex(['2014-01-02', '2014-01-05', '2014-01-08', '2014-01-11',
+            expected = PeriodIndex(['2014-01-02', '2014-01-05',
+                                    '2014-01-08', '2014-01-11',
                                     '2014-01-14'], freq='D')
             tm.assert_index_equal(pidx, expected)
 
@@ -1782,13 +1766,11 @@ class TestPeriodIndex(tm.TestCase):
         with tm.assertRaisesRegexp(ValueError, msg):
             PeriodIndex(['2011-01'], freq='-1M')
 
-        msg = ('Frequency must be positive, because it'
-               ' represents span: 0M')
+        msg = ('Frequency must be positive, because it' ' represents span: 0M')
         with tm.assertRaisesRegexp(ValueError, msg):
             PeriodIndex(['2011-01'], freq='0M')
 
-        msg = ('Frequency must be positive, because it'
-               ' represents span: 0M')
+        msg = ('Frequency must be positive, because it' ' represents span: 0M')
         with tm.assertRaisesRegexp(ValueError, msg):
             period_range('2011-01', periods=3, freq='0M')
 
@@ -1799,7 +1781,8 @@ class TestPeriodIndex(tm.TestCase):
         for mult, freq in itertools.product(mults, freqs):
             freqstr = str(mult) + freq
             pidx = PeriodIndex(start='2014-04-01', freq=freqstr, periods=10)
-            expected = date_range(start='2014-04-01', freq=freqstr, periods=10).to_period(freq)
+            expected = date_range(start='2014-04-01', freq=freqstr,
+                                  periods=10).to_period(freq)
             tm.assert_index_equal(pidx, expected)
 
     def test_is_(self):
@@ -1809,7 +1792,8 @@ class TestPeriodIndex(tm.TestCase):
         self.assertEqual(index.is_(index), True)
         self.assertEqual(index.is_(create_index()), False)
         self.assertEqual(index.is_(index.view()), True)
-        self.assertEqual(index.is_(index.view().view().view().view().view()), True)
+        self.assertEqual(
+            index.is_(index.view().view().view().view().view()), True)
         self.assertEqual(index.view().is_(index), True)
         ind2 = index.view()
         index.name = "Apple"
@@ -1863,9 +1847,10 @@ class TestPeriodIndex(tm.TestCase):
         assert_series_equal(exp, result)
 
         ts = ts[10:].append(ts[10:])
-        self.assertRaisesRegexp(
-            KeyError, "left slice bound for non-unique label: '2008'",
-            ts.__getitem__, slice('2008', '2009'))
+        self.assertRaisesRegexp(KeyError,
+                                "left slice bound for non-unique "
+                                "label: '2008'",
+                                ts.__getitem__, slice('2008', '2009'))
 
     def test_getitem_datetime(self):
         rng = period_range(start='2012-01-01', periods=10, freq='W-MON')
@@ -1894,9 +1879,12 @@ class TestPeriodIndex(tm.TestCase):
         assert_slices_equivalent(SLC[:'2014-10':-1], SLC[:8:-1])
 
         assert_slices_equivalent(SLC['2015-02':'2014-10':-1], SLC[13:8:-1])
-        assert_slices_equivalent(SLC[Period('2015-02'):Period('2014-10'):-1], SLC[13:8:-1])
-        assert_slices_equivalent(SLC['2015-02':Period('2014-10'):-1], SLC[13:8:-1])
-        assert_slices_equivalent(SLC[Period('2015-02'):'2014-10':-1], SLC[13:8:-1])
+        assert_slices_equivalent(SLC[Period('2015-02'):Period('2014-10'):-1],
+                                 SLC[13:8:-1])
+        assert_slices_equivalent(SLC['2015-02':Period('2014-10'):-1],
+                                 SLC[13:8:-1])
+        assert_slices_equivalent(SLC[Period('2015-02'):'2014-10':-1],
+                                 SLC[13:8:-1])
 
         assert_slices_equivalent(SLC['2014-10':'2015-02':-1], SLC[:0])
 
@@ -1925,8 +1913,8 @@ class TestPeriodIndex(tm.TestCase):
         self.assertTrue(result.equals(exp))
 
     def test_periods_number_check(self):
-        self.assertRaises(
-            ValueError, period_range, '2011-1-1', '2012-1-1', 'B')
+        self.assertRaises(ValueError, period_range, '2011-1-1', '2012-1-1',
+                          'B')
 
     def test_tolist(self):
         index = PeriodIndex(freq='A', start='1/1/2001', end='12/1/2009')
@@ -1996,16 +1984,17 @@ class TestPeriodIndex(tm.TestCase):
         self.assertEqual(conv.name, 'foo')
 
     def test_to_timestamp_repr_is_code(self):
-        zs=[Timestamp('99-04-17 00:00:00',tz='UTC'),
-        Timestamp('2001-04-17 00:00:00',tz='UTC'),
-        Timestamp('2001-04-17 00:00:00',tz='America/Los_Angeles'),
-        Timestamp('2001-04-17 00:00:00',tz=None)]
+        zs = [Timestamp('99-04-17 00:00:00', tz='UTC'),
+              Timestamp('2001-04-17 00:00:00', tz='UTC'),
+              Timestamp('2001-04-17 00:00:00', tz='America/Los_Angeles'),
+              Timestamp('2001-04-17 00:00:00', tz=None)]
         for z in zs:
-            self.assertEqual( eval(repr(z)), z)
+            self.assertEqual(eval(repr(z)), z)
 
     def test_to_timestamp_pi_nat(self):
         # GH 7228
-        index = PeriodIndex(['NaT', '2011-01', '2011-02'], freq='M', name='idx')
+        index = PeriodIndex(['NaT', '2011-01', '2011-02'], freq='M',
+                            name='idx')
 
         result = index.to_timestamp('D')
         expected = DatetimeIndex([pd.NaT, datetime(2011, 1, 1),
@@ -2030,10 +2019,12 @@ class TestPeriodIndex(tm.TestCase):
     def test_to_timestamp_pi_mult(self):
         idx = PeriodIndex(['2011-01', 'NaT', '2011-02'], freq='2M', name='idx')
         result = idx.to_timestamp()
-        expected = DatetimeIndex(['2011-01-01', 'NaT', '2011-02-01'], name='idx')
+        expected = DatetimeIndex(
+            ['2011-01-01', 'NaT', '2011-02-01'], name='idx')
         self.assert_index_equal(result, expected)
         result = idx.to_timestamp(how='E')
-        expected = DatetimeIndex(['2011-02-28', 'NaT', '2011-03-31'], name='idx')
+        expected = DatetimeIndex(
+            ['2011-02-28', 'NaT', '2011-03-31'], name='idx')
         self.assert_index_equal(result, expected)
 
     def test_as_frame_columns(self):
@@ -2182,8 +2173,10 @@ class TestPeriodIndex(tm.TestCase):
         self.assert_numpy_array_equal(idx.unique(), expected.values)
         self.assertEqual(idx.nunique(), 3)
 
-        idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq='A-JUN', tz='US/Eastern')
-        expected = PeriodIndex([2000, 2007, 2009], freq='A-JUN', tz='US/Eastern')
+        idx = PeriodIndex([2000, 2007, 2007, 2009, 2007], freq='A-JUN',
+                          tz='US/Eastern')
+        expected = PeriodIndex([2000, 2007, 2009], freq='A-JUN',
+                               tz='US/Eastern')
         self.assert_numpy_array_equal(idx.unique(), expected.values)
         self.assertEqual(idx.nunique(), 3)
 
@@ -2302,21 +2295,27 @@ class TestPeriodIndex(tm.TestCase):
         assert_equal(pi1.shift(-1).values, pi2.values)
 
     def test_shift_nat(self):
-        idx = PeriodIndex(['2011-01', '2011-02', 'NaT', '2011-04'], freq='M', name='idx')
+        idx = PeriodIndex(['2011-01', '2011-02', 'NaT',
+                           '2011-04'], freq='M', name='idx')
         result = idx.shift(1)
-        expected = PeriodIndex(['2011-02', '2011-03', 'NaT', '2011-05'], freq='M', name='idx')
+        expected = PeriodIndex(
+            ['2011-02', '2011-03', 'NaT', '2011-05'], freq='M', name='idx')
         self.assertTrue(result.equals(expected))
         self.assertEqual(result.name, expected.name)
 
     def test_shift_ndarray(self):
-        idx = PeriodIndex(['2011-01', '2011-02', 'NaT', '2011-04'], freq='M', name='idx')
+        idx = PeriodIndex(['2011-01', '2011-02', 'NaT',
+                           '2011-04'], freq='M', name='idx')
         result = idx.shift(np.array([1, 2, 3, 4]))
-        expected = PeriodIndex(['2011-02', '2011-04', 'NaT', '2011-08'], freq='M', name='idx')
+        expected = PeriodIndex(
+            ['2011-02', '2011-04', 'NaT', '2011-08'], freq='M', name='idx')
         self.assertTrue(result.equals(expected))
 
-        idx = PeriodIndex(['2011-01', '2011-02', 'NaT', '2011-04'], freq='M', name='idx')
+        idx = PeriodIndex(['2011-01', '2011-02', 'NaT',
+                           '2011-04'], freq='M', name='idx')
         result = idx.shift(np.array([1, -2, 3, -4]))
-        expected = PeriodIndex(['2011-02', '2010-12', 'NaT', '2010-12'], freq='M', name='idx')
+        expected = PeriodIndex(
+            ['2011-02', '2010-12', 'NaT', '2010-12'], freq='M', name='idx')
         self.assertTrue(result.equals(expected))
 
     def test_asfreq(self):
@@ -2503,12 +2502,12 @@ class TestPeriodIndex(tm.TestCase):
         # self.assertRaises(datetools.DateParseError, Period, '0', 'A')
 
     def test_negative_ordinals(self):
-        p = Period(ordinal=-1000, freq='A')
-        p = Period(ordinal=0, freq='A')
+        Period(ordinal=-1000, freq='A')
+        Period(ordinal=0, freq='A')
 
         idx1 = PeriodIndex(ordinal=[-1, 0, 1], freq='A')
         idx2 = PeriodIndex(ordinal=np.array([-1, 0, 1]), freq='A')
-        tm.assert_numpy_array_equal(idx1,idx2)
+        tm.assert_numpy_array_equal(idx1, idx2)
 
     def test_dti_to_period(self):
         dti = DatetimeIndex(start='1/1/2005', end='12/1/2005', freq='M')
@@ -2524,9 +2523,12 @@ class TestPeriodIndex(tm.TestCase):
         self.assertEqual(pi2[-1], Period('11/30/2005', freq='D'))
         self.assertEqual(pi3[-1], Period('11/30/2005', freq='3D'))
 
-        tm.assert_index_equal(pi1, period_range('1/1/2005', '11/1/2005', freq='M'))
-        tm.assert_index_equal(pi2, period_range('1/1/2005', '11/1/2005', freq='M').asfreq('D'))
-        tm.assert_index_equal(pi3, period_range('1/1/2005', '11/1/2005', freq='M').asfreq('3D'))
+        tm.assert_index_equal(pi1, period_range('1/1/2005', '11/1/2005',
+                                                freq='M'))
+        tm.assert_index_equal(pi2, period_range('1/1/2005', '11/1/2005',
+                                                freq='M').asfreq('D'))
+        tm.assert_index_equal(pi3, period_range('1/1/2005', '11/1/2005',
+                                                freq='M').asfreq('3D'))
 
     def test_pindex_slice_index(self):
         pi = PeriodIndex(start='1/1/10', end='12/31/12', freq='M')
@@ -2546,8 +2548,8 @@ class TestPeriodIndex(tm.TestCase):
 
         for idx in [didx, pidx]:
             # getitem against index should raise ValueError
-            values = ['2014', '2013/02', '2013/01/02',
-                      '2013/02/01 9H', '2013/02/01 09:00']
+            values = ['2014', '2013/02', '2013/01/02', '2013/02/01 9H',
+                      '2013/02/01 09:00']
             for v in values:
 
                 if _np_version_under1p9:
@@ -2557,7 +2559,7 @@ class TestPeriodIndex(tm.TestCase):
                     # GH7116
                     # these show deprecations as we are trying
                     # to slice with non-integer indexers
-                    #with tm.assertRaises(IndexError):
+                    # with tm.assertRaises(IndexError):
                     #    idx[v]
                     continue
 
@@ -2578,8 +2580,8 @@ class TestPeriodIndex(tm.TestCase):
 
         for idx in [didx, pidx]:
             # slices against index should raise IndexError
-            values = ['2014', '2013/02', '2013/01/02',
-                      '2013/02/01 9H', '2013/02/01 09:00']
+            values = ['2014', '2013/02', '2013/01/02', '2013/02/01 9H',
+                      '2013/02/01 09:00']
             for v in values:
                 with tm.assertRaises(IndexError):
                     idx[v:]
@@ -2598,13 +2600,14 @@ class TestPeriodIndex(tm.TestCase):
 
     def test_getitem_seconds(self):
         # GH 6716
-        didx = DatetimeIndex(start='2013/01/01 09:00:00', freq='S', periods=4000)
+        didx = DatetimeIndex(start='2013/01/01 09:00:00', freq='S',
+                             periods=4000)
         pidx = PeriodIndex(start='2013/01/01 09:00:00', freq='S', periods=4000)
 
         for idx in [didx, pidx]:
             # getitem against index should raise ValueError
-            values = ['2014', '2013/02', '2013/01/02',
-                      '2013/02/01 9H', '2013/02/01 09:00']
+            values = ['2014', '2013/02', '2013/01/02', '2013/02/01 9H',
+                      '2013/02/01 09:00']
             for v in values:
                 if _np_version_under1p9:
                     with tm.assertRaises(ValueError):
@@ -2613,7 +2616,7 @@ class TestPeriodIndex(tm.TestCase):
                     # GH7116
                     # these show deprecations as we are trying
                     # to slice with non-integer indexers
-                    #with tm.assertRaises(IndexError):
+                    # with tm.assertRaises(IndexError):
                     #    idx[v]
                     continue
 
@@ -2625,21 +2628,24 @@ class TestPeriodIndex(tm.TestCase):
 
     def test_range_slice_seconds(self):
         # GH 6716
-        didx = DatetimeIndex(start='2013/01/01 09:00:00', freq='S', periods=4000)
+        didx = DatetimeIndex(start='2013/01/01 09:00:00', freq='S',
+                             periods=4000)
         pidx = PeriodIndex(start='2013/01/01 09:00:00', freq='S', periods=4000)
 
         for idx in [didx, pidx]:
             # slices against index should raise IndexError
-            values = ['2014', '2013/02', '2013/01/02',
-                      '2013/02/01 9H', '2013/02/01 09:00']
+            values = ['2014', '2013/02', '2013/01/02', '2013/02/01 9H',
+                      '2013/02/01 09:00']
             for v in values:
                 with tm.assertRaises(IndexError):
                     idx[v:]
 
             s = Series(np.random.rand(len(idx)), index=idx)
 
-            assert_series_equal(s['2013/01/01 09:05':'2013/01/01 09:10'], s[300:660])
-            assert_series_equal(s['2013/01/01 10:00':'2013/01/01 10:05'], s[3600:3960])
+            assert_series_equal(s['2013/01/01 09:05':'2013/01/01 09:10'],
+                                s[300:660])
+            assert_series_equal(s['2013/01/01 10:00':'2013/01/01 10:05'],
+                                s[3600:3960])
             assert_series_equal(s['2013/01/01 10H':], s[3600:])
             assert_series_equal(s[:'2013/01/01 09:30'], s[:1860])
             for d in ['2013/01/01', '2013/01', '2013']:
@@ -2652,7 +2658,8 @@ class TestPeriodIndex(tm.TestCase):
 
         for idx in [didx, pidx]:
             df = DataFrame(dict(units=[100 + i for i in range(10)]), index=idx)
-            empty = DataFrame(index=idx.__class__([], freq='D'), columns=['units'])
+            empty = DataFrame(index=idx.__class__(
+                [], freq='D'), columns=['units'])
             empty['units'] = empty['units'].astype('int64')
 
             tm.assert_frame_equal(df['2013/09/01':'2013/09/30'], empty)
@@ -2664,8 +2671,10 @@ class TestPeriodIndex(tm.TestCase):
             tm.assert_frame_equal(df['2013-11':'2013-12'], empty)
 
     def test_pindex_fieldaccessor_nat(self):
-        idx = PeriodIndex(['2011-01', '2011-02', 'NaT', '2012-03', '2012-04'], freq='D')
-        self.assert_numpy_array_equal(idx.year, np.array([2011, 2011, -1, 2012, 2012]))
+        idx = PeriodIndex(['2011-01', '2011-02', 'NaT',
+                           '2012-03', '2012-04'], freq='D')
+        self.assert_numpy_array_equal(idx.year,
+                                      np.array([2011, 2011, -1, 2012, 2012]))
         self.assert_numpy_array_equal(idx.month, np.array([1, 2, -1, 3, 4]))
 
     def test_pindex_qaccess(self):
@@ -2756,10 +2765,11 @@ class TestPeriodIndex(tm.TestCase):
         self.assertEqual(result[0].freq, index.freq)
 
     def test_take(self):
-        index = PeriodIndex(start='1/1/10', end='12/31/12', freq='D', name='idx')
+        index = PeriodIndex(start='1/1/10', end='12/31/12', freq='D',
+                            name='idx')
         expected = PeriodIndex([datetime(2010, 1, 6), datetime(2010, 1, 7),
                                 datetime(2010, 1, 9), datetime(2010, 1, 13)],
-                                freq='D', name='idx')
+                               freq='D', name='idx')
 
         taken1 = index.take([5, 6, 8, 12])
         taken2 = index[[5, 6, 8, 12]]
@@ -2787,9 +2797,9 @@ class TestPeriodIndex(tm.TestCase):
             self.assertIs(index, res)
 
     def test_join_does_not_recur(self):
-        df = tm.makeCustomDataframe(3, 2, data_gen_f=lambda *args:
-                                    np.random.randint(2), c_idx_type='p',
-                                    r_idx_type='dt')
+        df = tm.makeCustomDataframe(
+            3, 2, data_gen_f=lambda *args: np.random.randint(2),
+            c_idx_type='p', r_idx_type='dt')
         s = df.iloc[:2, 0]
 
         res = s.index.join(df.columns, how='outer')
@@ -2902,9 +2912,9 @@ class TestPeriodIndex(tm.TestCase):
         self._check_all_fields(i1)
 
     def _check_all_fields(self, periodindex):
-        fields = ['year', 'month', 'day', 'hour', 'minute',
-                  'second', 'weekofyear', 'week', 'dayofweek',
-                  'weekday', 'dayofyear', 'quarter', 'qyear', 'days_in_month']
+        fields = ['year', 'month', 'day', 'hour', 'minute', 'second',
+                  'weekofyear', 'week', 'dayofweek', 'weekday', 'dayofyear',
+                  'quarter', 'qyear', 'days_in_month']
 
         periods = list(periodindex)
 
@@ -3076,14 +3086,16 @@ class TestPeriodIndex(tm.TestCase):
     def test_combine_first(self):
         # GH 3367
         didx = pd.DatetimeIndex(start='1950-01-31', end='1950-07-31', freq='M')
-        pidx = pd.PeriodIndex(start=pd.Period('1950-1'), end=pd.Period('1950-7'), freq='M')
+        pidx = pd.PeriodIndex(start=pd.Period('1950-1'),
+                              end=pd.Period('1950-7'), freq='M')
         # check to be consistent with DatetimeIndex
         for idx in [didx, pidx]:
             a = pd.Series([1, np.nan, np.nan, 4, 5, np.nan, 7], index=idx)
             b = pd.Series([9, 9, 9, 9, 9, 9, 9], index=idx)
 
             result = a.combine_first(b)
-            expected = pd.Series([1, 9, 9, 4, 5, 9, 7], index=idx, dtype=np.float64)
+            expected = pd.Series([1, 9, 9, 4, 5, 9, 7], index=idx,
+                                 dtype=np.float64)
             tm.assert_series_equal(result, expected)
 
     def test_searchsorted(self):
@@ -3105,13 +3117,13 @@ class TestPeriodIndex(tm.TestCase):
             with self.assertRaisesRegexp(ValueError, msg):
                 pidx.searchsorted(pd.Period('2014-01-01', freq='5D'))
 
-
     def test_round_trip(self):
 
         p = Period('2000Q1')
         new_p = self.round_trip_pickle(p)
         self.assertEqual(new_p, p)
 
+
 def _permute(obj):
     return obj.take(np.random.permutation(len(obj)))
 
@@ -3138,47 +3150,65 @@ class TestMethods(tm.TestCase):
             p = Period('2011', freq=freq)
             self.assertEqual(p + offsets.YearEnd(2), Period('2013', freq=freq))
 
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(365, 'D'), timedelta(365)]:
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(365, 'D'),
+                      timedelta(365)]:
                 with tm.assertRaises(ValueError):
                     p + o
 
         for freq in ['M', '2M', '3M']:
             p = Period('2011-03', freq=freq)
-            self.assertEqual(p + offsets.MonthEnd(2), Period('2011-05', freq=freq))
-            self.assertEqual(p + offsets.MonthEnd(12), Period('2012-03', freq=freq))
-
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(365, 'D'), timedelta(365)]:
+            self.assertEqual(p + offsets.MonthEnd(2),
+                             Period('2011-05', freq=freq))
+            self.assertEqual(p + offsets.MonthEnd(12),
+                             Period('2012-03', freq=freq))
+
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(365, 'D'),
+                      timedelta(365)]:
                 with tm.assertRaises(ValueError):
                     p + o
 
         # freq is Tick
         for freq in ['D', '2D', '3D']:
             p = Period('2011-04-01', freq=freq)
-            self.assertEqual(p + offsets.Day(5), Period('2011-04-06', freq=freq))
-            self.assertEqual(p + offsets.Hour(24), Period('2011-04-02', freq=freq))
-            self.assertEqual(p + np.timedelta64(2, 'D'), Period('2011-04-03', freq=freq))
-            self.assertEqual(p + np.timedelta64(3600 * 24, 's'), Period('2011-04-02', freq=freq))
-            self.assertEqual(p + timedelta(-2), Period('2011-03-30', freq=freq))
-            self.assertEqual(p + timedelta(hours=48), Period('2011-04-03', freq=freq))
-
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(4, 'h'), timedelta(hours=23)]:
+            self.assertEqual(p + offsets.Day(5),
+                             Period('2011-04-06', freq=freq))
+            self.assertEqual(p + offsets.Hour(24),
+                             Period('2011-04-02', freq=freq))
+            self.assertEqual(p + np.timedelta64(2, 'D'),
+                             Period('2011-04-03', freq=freq))
+            self.assertEqual(p + np.timedelta64(3600 * 24, 's'),
+                             Period('2011-04-02', freq=freq))
+            self.assertEqual(p + timedelta(-2),
+                             Period('2011-03-30', freq=freq))
+            self.assertEqual(p + timedelta(hours=48),
+                             Period('2011-04-03', freq=freq))
+
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(4, 'h'),
+                      timedelta(hours=23)]:
                 with tm.assertRaises(ValueError):
                     p + o
 
         for freq in ['H', '2H', '3H']:
             p = Period('2011-04-01 09:00', freq=freq)
-            self.assertEqual(p + offsets.Day(2), Period('2011-04-03 09:00', freq=freq))
-            self.assertEqual(p + offsets.Hour(3), Period('2011-04-01 12:00', freq=freq))
-            self.assertEqual(p + np.timedelta64(3, 'h'), Period('2011-04-01 12:00', freq=freq))
-            self.assertEqual(p + np.timedelta64(3600, 's'), Period('2011-04-01 10:00', freq=freq))
-            self.assertEqual(p + timedelta(minutes=120), Period('2011-04-01 11:00', freq=freq))
-            self.assertEqual(p + timedelta(days=4, minutes=180), Period('2011-04-05 12:00', freq=freq))
-
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(3200, 's'), timedelta(hours=23, minutes=30)]:
+            self.assertEqual(p + offsets.Day(2),
+                             Period('2011-04-03 09:00', freq=freq))
+            self.assertEqual(p + offsets.Hour(3),
+                             Period('2011-04-01 12:00', freq=freq))
+            self.assertEqual(p + np.timedelta64(3, 'h'),
+                             Period('2011-04-01 12:00', freq=freq))
+            self.assertEqual(p + np.timedelta64(3600, 's'),
+                             Period('2011-04-01 10:00', freq=freq))
+            self.assertEqual(p + timedelta(minutes=120),
+                             Period('2011-04-01 11:00', freq=freq))
+            self.assertEqual(p + timedelta(days=4, minutes=180),
+                             Period('2011-04-05 12:00', freq=freq))
+
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(3200, 's'),
+                      timedelta(hours=23, minutes=30)]:
                 with tm.assertRaises(ValueError):
                     p + o
 
@@ -3189,8 +3219,9 @@ class TestMethods(tm.TestCase):
             for o in [offsets.YearEnd(2)]:
                 self.assertEqual((p + o).ordinal, tslib.iNaT)
 
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(365, 'D'), timedelta(365)]:
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(365, 'D'),
+                      timedelta(365)]:
                 with tm.assertRaises(ValueError):
                     p + o
 
@@ -3199,8 +3230,9 @@ class TestMethods(tm.TestCase):
             for o in [offsets.MonthEnd(2), offsets.MonthEnd(12)]:
                 self.assertEqual((p + o).ordinal, tslib.iNaT)
 
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(365, 'D'), timedelta(365)]:
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(365, 'D'),
+                      timedelta(365)]:
                 with tm.assertRaises(ValueError):
                     p + o
 
@@ -3208,11 +3240,13 @@ class TestMethods(tm.TestCase):
         for freq in ['D', '2D', '3D']:
             p = Period('NaT', freq=freq)
             for o in [offsets.Day(5), offsets.Hour(24), np.timedelta64(2, 'D'),
-                      np.timedelta64(3600 * 24, 's'), timedelta(-2), timedelta(hours=48)]:
+                      np.timedelta64(3600 * 24, 's'), timedelta(-2),
+                      timedelta(hours=48)]:
                 self.assertEqual((p + o).ordinal, tslib.iNaT)
 
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(4, 'h'), timedelta(hours=23)]:
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(4, 'h'),
+                      timedelta(hours=23)]:
                 with tm.assertRaises(ValueError):
                     p + o
 
@@ -3223,8 +3257,9 @@ class TestMethods(tm.TestCase):
                       timedelta(days=4, minutes=180)]:
                 self.assertEqual((p + o).ordinal, tslib.iNaT)
 
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(3200, 's'), timedelta(hours=23, minutes=30)]:
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(3200, 's'),
+                      timedelta(hours=23, minutes=30)]:
                 with tm.assertRaises(ValueError):
                     p + o
 
@@ -3234,47 +3269,65 @@ class TestMethods(tm.TestCase):
             p = Period('2011', freq=freq)
             self.assertEqual(p - offsets.YearEnd(2), Period('2009', freq=freq))
 
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(365, 'D'), timedelta(365)]:
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(365, 'D'),
+                      timedelta(365)]:
                 with tm.assertRaises(ValueError):
                     p - o
 
         for freq in ['M', '2M', '3M']:
             p = Period('2011-03', freq=freq)
-            self.assertEqual(p - offsets.MonthEnd(2), Period('2011-01', freq=freq))
-            self.assertEqual(p - offsets.MonthEnd(12), Period('2010-03', freq=freq))
-
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(365, 'D'), timedelta(365)]:
+            self.assertEqual(p - offsets.MonthEnd(2),
+                             Period('2011-01', freq=freq))
+            self.assertEqual(p - offsets.MonthEnd(12),
+                             Period('2010-03', freq=freq))
+
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(365, 'D'),
+                      timedelta(365)]:
                 with tm.assertRaises(ValueError):
                     p - o
 
         # freq is Tick
         for freq in ['D', '2D', '3D']:
             p = Period('2011-04-01', freq=freq)
-            self.assertEqual(p - offsets.Day(5), Period('2011-03-27', freq=freq))
-            self.assertEqual(p - offsets.Hour(24), Period('2011-03-31', freq=freq))
-            self.assertEqual(p - np.timedelta64(2, 'D'), Period('2011-03-30', freq=freq))
-            self.assertEqual(p - np.timedelta64(3600 * 24, 's'), Period('2011-03-31', freq=freq))
-            self.assertEqual(p - timedelta(-2), Period('2011-04-03', freq=freq))
-            self.assertEqual(p - timedelta(hours=48), Period('2011-03-30', freq=freq))
-
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(4, 'h'), timedelta(hours=23)]:
+            self.assertEqual(p - offsets.Day(5),
+                             Period('2011-03-27', freq=freq))
+            self.assertEqual(p - offsets.Hour(24),
+                             Period('2011-03-31', freq=freq))
+            self.assertEqual(p - np.timedelta64(2, 'D'),
+                             Period('2011-03-30', freq=freq))
+            self.assertEqual(p - np.timedelta64(3600 * 24, 's'),
+                             Period('2011-03-31', freq=freq))
+            self.assertEqual(p - timedelta(-2),
+                             Period('2011-04-03', freq=freq))
+            self.assertEqual(p - timedelta(hours=48),
+                             Period('2011-03-30', freq=freq))
+
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(4, 'h'),
+                      timedelta(hours=23)]:
                 with tm.assertRaises(ValueError):
                     p - o
 
         for freq in ['H', '2H', '3H']:
             p = Period('2011-04-01 09:00', freq=freq)
-            self.assertEqual(p - offsets.Day(2), Period('2011-03-30 09:00', freq=freq))
-            self.assertEqual(p - offsets.Hour(3), Period('2011-04-01 06:00', freq=freq))
-            self.assertEqual(p - np.timedelta64(3, 'h'), Period('2011-04-01 06:00', freq=freq))
-            self.assertEqual(p - np.timedelta64(3600, 's'), Period('2011-04-01 08:00', freq=freq))
-            self.assertEqual(p - timedelta(minutes=120), Period('2011-04-01 07:00', freq=freq))
-            self.assertEqual(p - timedelta(days=4, minutes=180), Period('2011-03-28 06:00', freq=freq))
-
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(3200, 's'), timedelta(hours=23, minutes=30)]:
+            self.assertEqual(p - offsets.Day(2),
+                             Period('2011-03-30 09:00', freq=freq))
+            self.assertEqual(p - offsets.Hour(3),
+                             Period('2011-04-01 06:00', freq=freq))
+            self.assertEqual(p - np.timedelta64(3, 'h'),
+                             Period('2011-04-01 06:00', freq=freq))
+            self.assertEqual(p - np.timedelta64(3600, 's'),
+                             Period('2011-04-01 08:00', freq=freq))
+            self.assertEqual(p - timedelta(minutes=120),
+                             Period('2011-04-01 07:00', freq=freq))
+            self.assertEqual(p - timedelta(days=4, minutes=180),
+                             Period('2011-03-28 06:00', freq=freq))
+
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(3200, 's'),
+                      timedelta(hours=23, minutes=30)]:
                 with tm.assertRaises(ValueError):
                     p - o
 
@@ -3285,8 +3338,9 @@ class TestMethods(tm.TestCase):
             for o in [offsets.YearEnd(2)]:
                 self.assertEqual((p - o).ordinal, tslib.iNaT)
 
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(365, 'D'), timedelta(365)]:
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(365, 'D'),
+                      timedelta(365)]:
                 with tm.assertRaises(ValueError):
                     p - o
 
@@ -3295,8 +3349,9 @@ class TestMethods(tm.TestCase):
             for o in [offsets.MonthEnd(2), offsets.MonthEnd(12)]:
                 self.assertEqual((p - o).ordinal, tslib.iNaT)
 
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(365, 'D'), timedelta(365)]:
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(365, 'D'),
+                      timedelta(365)]:
                 with tm.assertRaises(ValueError):
                     p - o
 
@@ -3304,11 +3359,13 @@ class TestMethods(tm.TestCase):
         for freq in ['D', '2D', '3D']:
             p = Period('NaT', freq=freq)
             for o in [offsets.Day(5), offsets.Hour(24), np.timedelta64(2, 'D'),
-                      np.timedelta64(3600 * 24, 's'), timedelta(-2), timedelta(hours=48)]:
+                      np.timedelta64(3600 * 24, 's'), timedelta(-2),
+                      timedelta(hours=48)]:
                 self.assertEqual((p - o).ordinal, tslib.iNaT)
 
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(4, 'h'), timedelta(hours=23)]:
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(4, 'h'),
+                      timedelta(hours=23)]:
                 with tm.assertRaises(ValueError):
                     p - o
 
@@ -3319,8 +3376,9 @@ class TestMethods(tm.TestCase):
                       timedelta(days=4, minutes=180)]:
                 self.assertEqual((p - o).ordinal, tslib.iNaT)
 
-            for o in [offsets.YearBegin(2), offsets.MonthBegin(1), offsets.Minute(),
-                      np.timedelta64(3200, 's'), timedelta(hours=23, minutes=30)]:
+            for o in [offsets.YearBegin(2), offsets.MonthBegin(1),
+                      offsets.Minute(), np.timedelta64(3200, 's'),
+                      timedelta(hours=23, minutes=30)]:
                 with tm.assertRaises(ValueError):
                     p - o
 
@@ -3329,13 +3387,17 @@ class TestMethods(tm.TestCase):
             p = Period('NaT', freq=freq)
             self.assertEqual((p + 1).ordinal, tslib.iNaT)
             self.assertEqual((p - 1).ordinal, tslib.iNaT)
-            self.assertEqual((p - Period('2011-01', freq=freq)).ordinal, tslib.iNaT)
-            self.assertEqual((Period('2011-01', freq=freq) - p).ordinal, tslib.iNaT)
+            self.assertEqual(
+                (p - Period('2011-01', freq=freq)).ordinal, tslib.iNaT)
+            self.assertEqual(
+                (Period('2011-01', freq=freq) - p).ordinal, tslib.iNaT)
 
     def test_pi_ops_nat(self):
-        idx = PeriodIndex(['2011-01', '2011-02', 'NaT', '2011-04'], freq='M', name='idx')
+        idx = PeriodIndex(['2011-01', '2011-02', 'NaT',
+                           '2011-04'], freq='M', name='idx')
         result = idx + 2
-        expected = PeriodIndex(['2011-03', '2011-04', 'NaT', '2011-06'], freq='M', name='idx')
+        expected = PeriodIndex(
+            ['2011-03', '2011-04', 'NaT', '2011-06'], freq='M', name='idx')
         self.assertTrue(result.equals(expected))
 
         result2 = result - 2
@@ -3346,21 +3408,26 @@ class TestMethods(tm.TestCase):
             idx + "str"
 
     def test_pi_ops_array(self):
-        idx = PeriodIndex(['2011-01', '2011-02', 'NaT', '2011-04'], freq='M', name='idx')
+        idx = PeriodIndex(['2011-01', '2011-02', 'NaT',
+                           '2011-04'], freq='M', name='idx')
         result = idx + np.array([1, 2, 3, 4])
-        exp = PeriodIndex(['2011-02', '2011-04', 'NaT', '2011-08'], freq='M', name='idx')
+        exp = PeriodIndex(['2011-02', '2011-04', 'NaT',
+                           '2011-08'], freq='M', name='idx')
         self.assert_index_equal(result, exp)
 
         result = np.add(idx, np.array([4, -1, 1, 2]))
-        exp = PeriodIndex(['2011-05', '2011-01', 'NaT', '2011-06'], freq='M', name='idx')
+        exp = PeriodIndex(['2011-05', '2011-01', 'NaT',
+                           '2011-06'], freq='M', name='idx')
         self.assert_index_equal(result, exp)
 
         result = idx - np.array([1, 2, 3, 4])
-        exp = PeriodIndex(['2010-12', '2010-12', 'NaT', '2010-12'], freq='M', name='idx')
+        exp = PeriodIndex(['2010-12', '2010-12', 'NaT',
+                           '2010-12'], freq='M', name='idx')
         self.assert_index_equal(result, exp)
 
         result = np.subtract(idx, np.array([3, 2, 3, -2]))
-        exp = PeriodIndex(['2010-10', '2010-12', 'NaT', '2011-06'], freq='M', name='idx')
+        exp = PeriodIndex(['2010-10', '2010-12', 'NaT',
+                           '2011-06'], freq='M', name='idx')
         self.assert_index_equal(result, exp)
 
         # incompatible freq
@@ -3386,8 +3453,8 @@ class TestMethods(tm.TestCase):
 
         idx = PeriodIndex(['2011-01-01 09:00:00', '2011-01-01 10:00:00', 'NaT',
                            '2011-01-01 12:00:00'], freq='S', name='idx')
-        result = idx + np.array([np.timedelta64(1, 'h'), np.timedelta64(30, 's'),
-                                 np.timedelta64(2, 'h'), np.timedelta64(15, 'm')])
+        result = idx + np.array([np.timedelta64(1, 'h'), np.timedelta64(
+            30, 's'), np.timedelta64(2, 'h'), np.timedelta64(15, 'm')])
         exp = PeriodIndex(['2011-01-01 10:00:00', '2011-01-01 10:00:30', 'NaT',
                            '2011-01-01 12:15:00'], freq='S', name='idx')
         self.assert_index_equal(result, exp)
@@ -3527,8 +3594,8 @@ class TestComparisons(tm.TestCase):
         nat = pd.Timestamp('NaT')
         t = pd.Timestamp('2011-01-01')
         # confirm Period('NaT') work identical with Timestamp('NaT')
-        for left, right in [(p_nat, p), (p, p_nat), (p_nat, p_nat),
-                            (nat, t), (t, nat), (nat, nat)]:
+        for left, right in [(p_nat, p), (p, p_nat), (p_nat, p_nat), (nat, t),
+                            (t, nat), (nat, nat)]:
             self.assertEqual(left < right, False)
             self.assertEqual(left > right, False)
             self.assertEqual(left == right, False)
@@ -3561,7 +3628,8 @@ class TestComparisons(tm.TestCase):
             exp = np.array([True, True, False, False])
             self.assert_numpy_array_equal(base <= p, exp)
 
-            idx = PeriodIndex(['2011-02', '2011-01', '2011-03', '2011-05'], freq=freq)
+            idx = PeriodIndex(
+                ['2011-02', '2011-01', '2011-03', '2011-05'], freq=freq)
 
             exp = np.array([False, False, True, False])
             self.assert_numpy_array_equal(base == idx, exp)
@@ -3601,7 +3669,8 @@ class TestComparisons(tm.TestCase):
 
     def test_pi_nat_comp(self):
         for freq in ['M', '2M', '3M']:
-            idx1 = PeriodIndex(['2011-01', '2011-02', 'NaT', '2011-05'], freq=freq)
+            idx1 = PeriodIndex(
+                ['2011-01', '2011-02', 'NaT', '2011-05'], freq=freq)
 
             result = idx1 > Period('2011-02', freq=freq)
             exp = np.array([False, False, False, True])
@@ -3615,7 +3684,8 @@ class TestComparisons(tm.TestCase):
             exp = np.array([True, True, True, True])
             self.assert_numpy_array_equal(result, exp)
 
-            idx2 = PeriodIndex(['2011-02', '2011-01', '2011-04', 'NaT'], freq=freq)
+            idx2 = PeriodIndex(
+                ['2011-02', '2011-01', '2011-04', 'NaT'], freq=freq)
             result = idx1 < idx2
             exp = np.array([True, False, False, False])
             self.assert_numpy_array_equal(result, exp)
@@ -3636,7 +3706,8 @@ class TestComparisons(tm.TestCase):
             exp = np.array([False, False, True, False])
             self.assert_numpy_array_equal(result, exp)
 
-            diff = PeriodIndex(['2011-02', '2011-01', '2011-04', 'NaT'], freq='4M')
+            diff = PeriodIndex(
+                ['2011-02', '2011-01', '2011-04', 'NaT'], freq='4M')
             msg = "Input has different freq=4M from PeriodIndex"
             with tm.assertRaisesRegexp(ValueError, msg):
                 idx1 > diff
diff --git a/pandas/tseries/tests/test_plotting.py b/pandas/tseries/tests/test_plotting.py
index bcd1e400d..4a06a5500 100644
--- a/pandas/tseries/tests/test_plotting.py
+++ b/pandas/tseries/tests/test_plotting.py
@@ -9,7 +9,7 @@ from numpy.testing.decorators import slow
 from pandas import Index, Series, DataFrame
 
 from pandas.tseries.index import date_range, bdate_range
-from pandas.tseries.offsets import DateOffset, Week
+from pandas.tseries.offsets import DateOffset
 from pandas.tseries.period import period_range, Period, PeriodIndex
 from pandas.tseries.resample import DatetimeIndex
 
@@ -49,7 +49,7 @@ class TestTSPlot(tm.TestCase):
 
     def test_fontsize_set_correctly(self):
         # For issue #8765
-        import matplotlib.pyplot as plt
+        import matplotlib.pyplot as plt  # noqa
         df = DataFrame(np.random.randn(10, 9), index=range(10))
         ax = df.plot(fontsize=2)
         for label in (ax.get_xticklabels() + ax.get_yticklabels()):
@@ -58,7 +58,7 @@ class TestTSPlot(tm.TestCase):
     @slow
     def test_frame_inferred(self):
         # inferred freq
-        import matplotlib.pyplot as plt
+        import matplotlib.pyplot as plt  # noqa
         idx = date_range('1/1/1987', freq='MS', periods=100)
         idx = DatetimeIndex(idx.values, freq=None)
 
@@ -80,10 +80,10 @@ class TestTSPlot(tm.TestCase):
         import matplotlib.pyplot as plt
 
         idx = date_range('1/1/1987', freq='A', periods=3)
-        df = DataFrame({'A': ["x", "y", "z"], 'B': [1,2,3]}, idx)
+        df = DataFrame({'A': ["x", "y", "z"], 'B': [1, 2, 3]}, idx)
 
-        ax = df.plot() # it works
-        self.assertEqual(len(ax.get_lines()), 1) #B was plotted
+        ax = df.plot()  # it works
+        self.assertEqual(len(ax.get_lines()), 1)  # B was plotted
         plt.close(plt.gcf())
 
         self.assertRaises(TypeError, df['A'].plot)
@@ -114,7 +114,7 @@ class TestTSPlot(tm.TestCase):
         self.assertEqual((0., 0., 0.), ax.get_lines()[0].get_color())
 
     def test_both_style_and_color(self):
-        import matplotlib.pyplot as plt
+        import matplotlib.pyplot as plt  # noqa
 
         ts = tm.makeTimeSeries()
         self.assertRaises(ValueError, ts.plot, style='b-', color='#000099')
@@ -146,16 +146,21 @@ class TestTSPlot(tm.TestCase):
             first_x = first_line.get_xdata()[0].ordinal
             first_y = first_line.get_ydata()[0]
             try:
-                self.assertEqual(expected_string, ax.format_coord(first_x, first_y))
+                self.assertEqual(expected_string,
+                                 ax.format_coord(first_x, first_y))
             except (ValueError):
-                raise nose.SkipTest("skipping test because issue forming test comparison GH7664")
+                raise nose.SkipTest("skipping test because issue forming "
+                                    "test comparison GH7664")
 
-        annual = Series(1, index=date_range('2014-01-01', periods=3, freq='A-DEC'))
+        annual = Series(1, index=date_range('2014-01-01', periods=3,
+                                            freq='A-DEC'))
         check_format_of_first_point(annual.plot(), 't = 2014  y = 1.000000')
 
-        # note this is added to the annual plot already in existence, and changes its freq field
+        # note this is added to the annual plot already in existence, and
+        # changes its freq field
         daily = Series(1, index=date_range('2014-01-01', periods=3, freq='D'))
-        check_format_of_first_point(daily.plot(), 't = 2014-01-01  y = 1.000000')
+        check_format_of_first_point(daily.plot(),
+                                    't = 2014-01-01  y = 1.000000')
         tm.close()
 
         # tsplot
@@ -218,9 +223,8 @@ class TestTSPlot(tm.TestCase):
 
     @slow
     def test_plot_multiple_inferred_freq(self):
-        dr = Index([datetime(2000, 1, 1),
-                    datetime(2000, 1, 6),
-                    datetime(2000, 1, 11)])
+        dr = Index([datetime(2000, 1, 1), datetime(2000, 1, 6), datetime(
+            2000, 1, 11)])
         ser = Series(np.random.randn(len(dr)), dr)
         _check_plot_works(ser.plot)
 
@@ -261,7 +265,8 @@ class TestTSPlot(tm.TestCase):
         diffs = Series(ax.get_lines()[0].get_xydata()[:, 0]).diff()
 
         sec = 1. / 24 / 60 / 60
-        self.assertTrue((np.fabs(diffs[1:] - [sec, sec * 2, sec]) < 1e-8).all())
+        self.assertTrue((np.fabs(diffs[1:] - [sec, sec * 2, sec]) < 1e-8).all(
+        ))
 
         plt.clf()
         fig.add_subplot(111)
@@ -286,7 +291,7 @@ class TestTSPlot(tm.TestCase):
             self.assertEqual(rs, xp)
 
     def test_business_freq(self):
-        import matplotlib.pyplot as plt
+        import matplotlib.pyplot as plt  # noqa
         bts = tm.makePeriodSeries()
         ax = bts.plot()
         self.assertEqual(ax.get_lines()[0].get_xydata()[0, 0],
@@ -309,8 +314,8 @@ class TestTSPlot(tm.TestCase):
 
     def test_nonzero_base(self):
         # GH2571
-        idx = (date_range('2012-12-20', periods=24, freq='H') +
-               timedelta(minutes=30))
+        idx = (date_range('2012-12-20', periods=24, freq='H') + timedelta(
+            minutes=30))
         df = DataFrame(np.arange(24), index=idx)
         ax = df.plot()
         rs = ax.get_lines()[0].get_xdata()
@@ -601,7 +606,7 @@ class TestTSPlot(tm.TestCase):
         tm._skip_if_no_scipy()
         _skip_if_no_scipy_gaussian_kde()
 
-        import matplotlib.pyplot as plt
+        import matplotlib.pyplot as plt  # noqa
         ser = Series(np.random.randn(10))
         ax = ser.plot(secondary_y=True, kind='density')
         self.assertTrue(hasattr(ax, 'left_ax'))
@@ -616,7 +621,7 @@ class TestTSPlot(tm.TestCase):
         ax = ser.plot(secondary_y=True, kind='bar')
         fig = ax.get_figure()
         axes = fig.get_axes()
-        self.assertEqual(axes[1].get_yaxis().get_ticks_position(),  'right')
+        self.assertEqual(axes[1].get_yaxis().get_ticks_position(), 'right')
 
     @slow
     def test_secondary_frame(self):
@@ -635,10 +640,13 @@ class TestTSPlot(tm.TestCase):
         self.assertEqual(axes[2].get_yaxis().get_ticks_position(), 'right')
 
     def test_mixed_freq_regular_first(self):
-        import matplotlib.pyplot as plt
+        import matplotlib.pyplot as plt  # noqa
         s1 = tm.makeTimeSeries()
         s2 = s1[[0, 5, 10, 11, 12, 13, 14, 15]]
-        ax = s1.plot()
+
+        # it works!
+        s1.plot()
+
         ax2 = s2.plot(style='g')
         lines = ax2.get_lines()
         idx1 = PeriodIndex(lines[0].get_xdata())
@@ -652,7 +660,7 @@ class TestTSPlot(tm.TestCase):
 
     @slow
     def test_mixed_freq_irregular_first(self):
-        import matplotlib.pyplot as plt
+        import matplotlib.pyplot as plt  # noqa
         s1 = tm.makeTimeSeries()
         s2 = s1[[0, 5, 10, 11, 12, 13, 14, 15]]
         s2.plot(style='g')
@@ -666,7 +674,7 @@ class TestTSPlot(tm.TestCase):
 
     def test_mixed_freq_regular_first_df(self):
         # GH 9852
-        import matplotlib.pyplot as plt
+        import matplotlib.pyplot as plt  # noqa
         s1 = tm.makeTimeSeries().to_frame()
         s2 = s1.iloc[[0, 5, 10, 11, 12, 13, 14, 15], :]
         ax = s1.plot()
@@ -684,7 +692,7 @@ class TestTSPlot(tm.TestCase):
     @slow
     def test_mixed_freq_irregular_first_df(self):
         # GH 9852
-        import matplotlib.pyplot as plt
+        import matplotlib.pyplot as plt  # noqa
         s1 = tm.makeTimeSeries().to_frame()
         s2 = s1.iloc[[0, 5, 10, 11, 12, 13, 14, 15], :]
         ax = s2.plot(style='g')
@@ -783,12 +791,12 @@ class TestTSPlot(tm.TestCase):
         ax = high.plot()
 
         expected_h = idxh.to_period().asi8
-        expected_l = np.array([1514, 1519, 1523, 1527, 1531, 1536, 1540, 1544, 1549,
-                               1553, 1558, 1562])
+        expected_l = np.array([1514, 1519, 1523, 1527, 1531, 1536, 1540, 1544,
+                               1549, 1553, 1558, 1562])
         for l in ax.get_lines():
             self.assertTrue(PeriodIndex(data=l.get_xdata()).freq, idxh.freq)
             xdata = l.get_xdata(orig=False)
-            if len(xdata) == 12: # idxl lines
+            if len(xdata) == 12:  # idxl lines
                 self.assert_numpy_array_equal(xdata, expected_l)
             else:
                 self.assert_numpy_array_equal(xdata, expected_h)
@@ -803,7 +811,7 @@ class TestTSPlot(tm.TestCase):
         for l in lines:
             self.assertTrue(PeriodIndex(data=l.get_xdata()).freq, idxh.freq)
             xdata = l.get_xdata(orig=False)
-            if len(xdata) == 12: # idxl lines
+            if len(xdata) == 12:  # idxl lines
                 self.assert_numpy_array_equal(xdata, expected_l)
             else:
                 self.assert_numpy_array_equal(xdata, expected_h)
@@ -815,7 +823,7 @@ class TestTSPlot(tm.TestCase):
         high = DataFrame(np.random.rand(len(idxh), 3),
                          index=idxh, columns=[0, 1, 2])
         low = DataFrame(np.random.rand(len(idxl), 3),
-                     index=idxl, columns=[0, 1, 2])
+                        index=idxl, columns=[0, 1, 2])
 
         # low to high
         for kind1, kind2 in [('line', 'area'), ('area', 'line')]:
@@ -823,26 +831,31 @@ class TestTSPlot(tm.TestCase):
             ax = high.plot(kind=kind2, stacked=True, ax=ax)
 
             # check low dataframe result
-            expected_x = np.array([1514, 1519, 1523, 1527, 1531, 1536, 1540, 1544, 1549,
-                                   1553, 1558, 1562])
+            expected_x = np.array([1514, 1519, 1523, 1527, 1531, 1536, 1540,
+                                   1544, 1549, 1553, 1558, 1562])
             expected_y = np.zeros(len(expected_x))
             for i in range(3):
                 l = ax.lines[i]
                 self.assertEqual(PeriodIndex(l.get_xdata()).freq, idxh.freq)
-                self.assert_numpy_array_equal(l.get_xdata(orig=False), expected_x)
+                self.assert_numpy_array_equal(
+                    l.get_xdata(orig=False), expected_x)
                 # check stacked values are correct
                 expected_y += low[i].values
-                self.assert_numpy_array_equal(l.get_ydata(orig=False), expected_y)
+                self.assert_numpy_array_equal(
+                    l.get_ydata(orig=False), expected_y)
 
             # check high dataframe result
             expected_x = idxh.to_period().asi8
             expected_y = np.zeros(len(expected_x))
             for i in range(3):
                 l = ax.lines[3 + i]
-                self.assertEqual(PeriodIndex(data=l.get_xdata()).freq, idxh.freq)
-                self.assert_numpy_array_equal(l.get_xdata(orig=False), expected_x)
+                self.assertEqual(PeriodIndex(
+                    data=l.get_xdata()).freq, idxh.freq)
+                self.assert_numpy_array_equal(
+                    l.get_xdata(orig=False), expected_x)
                 expected_y += high[i].values
-                self.assert_numpy_array_equal(l.get_ydata(orig=False), expected_y)
+                self.assert_numpy_array_equal(
+                    l.get_ydata(orig=False), expected_y)
 
         # high to low
         for kind1, kind2 in [('line', 'area'), ('area', 'line')]:
@@ -854,21 +867,27 @@ class TestTSPlot(tm.TestCase):
             expected_y = np.zeros(len(expected_x))
             for i in range(3):
                 l = ax.lines[i]
-                self.assertEqual(PeriodIndex(data=l.get_xdata()).freq, idxh.freq)
-                self.assert_numpy_array_equal(l.get_xdata(orig=False), expected_x)
+                self.assertEqual(PeriodIndex(
+                    data=l.get_xdata()).freq, idxh.freq)
+                self.assert_numpy_array_equal(
+                    l.get_xdata(orig=False), expected_x)
                 expected_y += high[i].values
-                self.assert_numpy_array_equal(l.get_ydata(orig=False), expected_y)
+                self.assert_numpy_array_equal(
+                    l.get_ydata(orig=False), expected_y)
 
             # check low dataframe result
-            expected_x = np.array([1514, 1519, 1523, 1527, 1531, 1536, 1540, 1544, 1549,
-                                   1553, 1558, 1562])
+            expected_x = np.array([1514, 1519, 1523, 1527, 1531, 1536, 1540,
+                                   1544, 1549, 1553, 1558, 1562])
             expected_y = np.zeros(len(expected_x))
             for i in range(3):
                 l = ax.lines[3 + i]
-                self.assertEqual(PeriodIndex(data=l.get_xdata()).freq, idxh.freq)
-                self.assert_numpy_array_equal(l.get_xdata(orig=False), expected_x)
+                self.assertEqual(PeriodIndex(
+                    data=l.get_xdata()).freq, idxh.freq)
+                self.assert_numpy_array_equal(
+                    l.get_xdata(orig=False), expected_x)
                 expected_y += low[i].values
-                self.assert_numpy_array_equal(l.get_ydata(orig=False), expected_y)
+                self.assert_numpy_array_equal(
+                    l.get_ydata(orig=False), expected_y)
 
     @slow
     def test_mixed_freq_second_millisecond(self):
@@ -956,7 +975,10 @@ class TestTSPlot(tm.TestCase):
         labels = ax.get_xticklabels()
         for t, l in zip(ticks, labels):
             m, s = divmod(int(t), 60)
-            us = int((t - int(t)) * 1e6)
+
+            # TODO: unused?
+            # us = int((t - int(t)) * 1e6)
+
             h, m = divmod(m, 60)
             xp = l.get_text()
             if len(xp) > 0:
@@ -1079,8 +1101,7 @@ class TestTSPlot(tm.TestCase):
     def test_ax_plot(self):
         import matplotlib.pyplot as plt
 
-        x = DatetimeIndex(start='2012-01-02', periods=10,
-                          freq='D')
+        x = DatetimeIndex(start='2012-01-02', periods=10, freq='D')
         y = lrange(len(x))
         fig = plt.figure()
         ax = fig.add_subplot(111)
@@ -1105,9 +1126,9 @@ class TestTSPlot(tm.TestCase):
 
         line1, line2 = ax.get_lines()
         tm.assert_numpy_array_equal(np.array([x.toordinal() for x in dates]),
-                           line1.get_xydata()[:, 0])
+                                    line1.get_xydata()[:, 0])
         tm.assert_numpy_array_equal(np.array([x.toordinal() for x in dates]),
-                           line2.get_xydata()[:, 0])
+                                    line2.get_xydata()[:, 0])
 
     @slow
     def test_irregular_ts_shared_ax_xlim(self):
diff --git a/pandas/tseries/tests/test_resample.py b/pandas/tseries/tests/test_resample.py
index b48f077bd..850071e8e 100644
--- a/pandas/tseries/tests/test_resample.py
+++ b/pandas/tseries/tests/test_resample.py
@@ -6,8 +6,8 @@ from functools import partial
 from pandas.compat import range, lrange, zip, product
 import numpy as np
 
-from pandas import (Series, TimeSeries, DataFrame, Panel, Index,
-                    isnull, notnull, Timestamp)
+from pandas import (Series, DataFrame, Panel, Index, isnull,
+                    notnull, Timestamp)
 
 from pandas.core.groupby import DataError
 from pandas.tseries.index import date_range
@@ -73,7 +73,8 @@ class TestResample(tm.TestCase):
         result = g.agg(np.sum)
         assert_series_equal(result, expect)
 
-        df = DataFrame(np.random.rand(len(dti), 10), index=dti, dtype='float64')
+        df = DataFrame(np.random.rand(len(dti), 10),
+                       index=dti, dtype='float64')
         r = df.groupby(b).agg(np.sum)
 
         self.assertEqual(len(r.columns), 10)
@@ -93,8 +94,10 @@ class TestResample(tm.TestCase):
 
         result = s.resample('5min', how='mean', closed='left', label='right')
 
-        exp_idx = date_range('1/1/2000 00:05', periods=3, freq='5min', name='index')
-        expected = Series([s[:5].mean(), s[5:10].mean(), s[10:].mean()], index=exp_idx)
+        exp_idx = date_range('1/1/2000 00:05', periods=3, freq='5min',
+                             name='index')
+        expected = Series([s[:5].mean(), s[5:10].mean(),
+                           s[10:].mean()], index=exp_idx)
         assert_series_equal(result, expected)
 
         s = self.series
@@ -104,21 +107,22 @@ class TestResample(tm.TestCase):
         assert_series_equal(result, expect)
 
     def test_resample_how(self):
-        rng = date_range('1/1/2000 00:00:00', '1/1/2000 00:13:00',
-                            freq='min', name='index')
+        rng = date_range('1/1/2000 00:00:00', '1/1/2000 00:13:00', freq='min',
+                         name='index')
         s = Series(np.random.randn(14), index=rng)
         grouplist = np.ones_like(s)
         grouplist[0] = 0
         grouplist[1:6] = 1
         grouplist[6:11] = 2
         grouplist[11:] = 3
-        args = ['sum', 'mean', 'std', 'sem', 'max', 'min',
-                'median', 'first', 'last', 'ohlc']
+        args = ['sum', 'mean', 'std', 'sem', 'max', 'min', 'median', 'first',
+                'last', 'ohlc']
 
         def _ohlc(group):
             if isnull(group).all():
                 return np.repeat(np.nan, 4)
             return [group[0], group.max(), group.min(), group[-1]]
+
         inds = date_range('1/1/2000', periods=4, freq='5min', name='index')
 
         for arg in args:
@@ -127,8 +131,8 @@ class TestResample(tm.TestCase):
             else:
                 func = arg
             try:
-                result = s.resample('5min', how=arg,
-                                    closed='right', label='right')
+                result = s.resample('5min', how=arg, closed='right',
+                                    label='right')
 
                 expected = s.groupby(grouplist).agg(func)
                 self.assertEqual(result.index.name, 'index')
@@ -142,7 +146,7 @@ class TestResample(tm.TestCase):
                     assert_series_equal(result, expected)
             except BaseException as exc:
 
-                exc.args += ('how=%s' % arg,)
+                exc.args += ('how=%s' % arg, )
                 raise
 
     def test_resample_how_callables(self):
@@ -171,12 +175,13 @@ class TestResample(tm.TestCase):
 
     def test_resample_with_timedeltas(self):
 
-        expected = DataFrame({'A' : np.arange(1480)})
+        expected = DataFrame({'A': np.arange(1480)})
         expected = expected.groupby(expected.index // 30).sum()
-        expected.index = pd.timedelta_range('0 days',freq='30T',periods=50)
+        expected.index = pd.timedelta_range('0 days', freq='30T', periods=50)
 
-        df = DataFrame({'A' : np.arange(1480)},index=pd.to_timedelta(np.arange(1480),unit='T'))
-        result = df.resample('30T',how='sum')
+        df = DataFrame({'A': np.arange(1480)}, index=pd.to_timedelta(
+            np.arange(1480), unit='T'))
+        result = df.resample('30T', how='sum')
 
         assert_frame_equal(result, expected)
 
@@ -206,33 +211,43 @@ class TestResample(tm.TestCase):
 11-08-2014,00:00:21.191,1"""
 
         from pandas.compat import StringIO
-        df = pd.read_csv(StringIO(data), parse_dates={'timestamp': ['date', 'time']}, index_col='timestamp')
+        df = pd.read_csv(StringIO(data), parse_dates={'timestamp': [
+                         'date', 'time']}, index_col='timestamp')
         df.index.name = None
         result = df.resample('6s', how='sum')
-        expected = DataFrame({'value' : [4,9,4,2]},index=date_range('2014-11-08',freq='6s',periods=4))
-        assert_frame_equal(result,expected)
+        expected = DataFrame({'value': [
+            4, 9, 4, 2
+        ]}, index=date_range('2014-11-08', freq='6s', periods=4))
+        assert_frame_equal(result, expected)
 
         result = df.resample('7s', how='sum')
-        expected = DataFrame({'value' : [4,10,4,1]},index=date_range('2014-11-08',freq='7s',periods=4))
-        assert_frame_equal(result,expected)
+        expected = DataFrame({'value': [
+            4, 10, 4, 1
+        ]}, index=date_range('2014-11-08', freq='7s', periods=4))
+        assert_frame_equal(result, expected)
 
         result = df.resample('11s', how='sum')
-        expected = DataFrame({'value' : [11,8]},index=date_range('2014-11-08',freq='11s',periods=2))
-        assert_frame_equal(result,expected)
+        expected = DataFrame({'value': [
+            11, 8
+        ]}, index=date_range('2014-11-08', freq='11s', periods=2))
+        assert_frame_equal(result, expected)
 
         result = df.resample('13s', how='sum')
-        expected = DataFrame({'value' : [13,6]},index=date_range('2014-11-08',freq='13s',periods=2))
-        assert_frame_equal(result,expected)
+        expected = DataFrame({'value': [
+            13, 6
+        ]}, index=date_range('2014-11-08', freq='13s', periods=2))
+        assert_frame_equal(result, expected)
 
         result = df.resample('17s', how='sum')
-        expected = DataFrame({'value' : [16,3]},index=date_range('2014-11-08',freq='17s',periods=2))
-        assert_frame_equal(result,expected)
+        expected = DataFrame({'value': [
+            16, 3
+        ]}, index=date_range('2014-11-08', freq='17s', periods=2))
+        assert_frame_equal(result, expected)
 
     def test_resample_basic_from_daily(self):
         # from daily
-        dti = DatetimeIndex(
-            start=datetime(2005, 1, 1), end=datetime(2005, 1, 10),
-            freq='D', name='index')
+        dti = DatetimeIndex(start=datetime(2005, 1, 1),
+                            end=datetime(2005, 1, 10), freq='D', name='index')
 
         s = Series(np.random.rand(len(dti)), dti)
 
@@ -278,7 +293,9 @@ class TestResample(tm.TestCase):
         # to biz day
         result = s.resample('B', how='last')
         self.assertEqual(len(result), 7)
-        self.assertTrue((result.index.dayofweek == [4, 0, 1, 2, 3, 4, 0]).all())
+        self.assertTrue((result.index.dayofweek == [
+            4, 0, 1, 2, 3, 4, 0
+        ]).all())
         self.assertEqual(result.iloc[0], s['1/2/2005'])
         self.assertEqual(result.iloc[1], s['1/3/2005'])
         self.assertEqual(result.iloc[5], s['1/9/2005'])
@@ -287,28 +304,31 @@ class TestResample(tm.TestCase):
     def test_resample_upsampling_picked_but_not_correct(self):
 
         # Test for issue #3020
-        dates = date_range('01-Jan-2014','05-Jan-2014', freq='D')
+        dates = date_range('01-Jan-2014', '05-Jan-2014', freq='D')
         series = Series(1, index=dates)
 
         result = series.resample('D')
         self.assertEqual(result.index[0], dates[0])
 
         # GH 5955
-        # incorrect deciding to upsample when the axis frequency matches the resample frequency
+        # incorrect deciding to upsample when the axis frequency matches the
+        # resample frequency
 
         import datetime
-        s = Series(np.arange(1.,6),index=[datetime.datetime(1975, 1, i, 12, 0) for i in range(1, 6)])
-        expected = Series(np.arange(1.,6),index=date_range('19750101',periods=5,freq='D'))
+        s = Series(np.arange(1., 6), index=[datetime.datetime(
+            1975, 1, i, 12, 0) for i in range(1, 6)])
+        expected = Series(np.arange(1., 6), index=date_range(
+            '19750101', periods=5, freq='D'))
 
-        result = s.resample('D',how='count')
-        assert_series_equal(result,Series(1,index=expected.index))
+        result = s.resample('D', how='count')
+        assert_series_equal(result, Series(1, index=expected.index))
 
-        result1 = s.resample('D',how='sum')
-        result2 = s.resample('D',how='mean')
+        result1 = s.resample('D', how='sum')
+        result2 = s.resample('D', how='mean')
         result3 = s.resample('D')
-        assert_series_equal(result1,expected)
-        assert_series_equal(result2,expected)
-        assert_series_equal(result3,expected)
+        assert_series_equal(result1, expected)
+        assert_series_equal(result2, expected)
+        assert_series_equal(result3, expected)
 
     def test_resample_frame_basic(self):
         df = tm.makeTimeDataFrame()
@@ -341,22 +361,19 @@ class TestResample(tm.TestCase):
                           index=idx + timedelta(minutes=1))
         assert_series_equal(result, expected)
 
-        expected = s.resample(
-            '5min', how='mean', closed='right', label='right',
-            loffset='1min')
+        expected = s.resample('5min', how='mean', closed='right',
+                              label='right', loffset='1min')
         assert_series_equal(result, expected)
 
-        expected = s.resample(
-            '5min', how='mean', closed='right', label='right',
-            loffset=Minute(1))
+        expected = s.resample('5min', how='mean', closed='right',
+                              label='right', loffset=Minute(1))
         assert_series_equal(result, expected)
 
         self.assertEqual(result.index.freq, Minute(5))
 
-                # from daily
-        dti = DatetimeIndex(
-            start=datetime(2005, 1, 1), end=datetime(2005, 1, 10),
-            freq='D')
+        # from daily
+        dti = DatetimeIndex(start=datetime(2005, 1, 1),
+                            end=datetime(2005, 1, 10), freq='D')
         ser = Series(np.random.rand(len(dti)), dti)
 
         # to weekly
@@ -366,9 +383,8 @@ class TestResample(tm.TestCase):
 
     def test_resample_upsample(self):
         # from daily
-        dti = DatetimeIndex(
-            start=datetime(2005, 1, 1), end=datetime(2005, 1, 10),
-            freq='D', name='index')
+        dti = DatetimeIndex(start=datetime(2005, 1, 1),
+                            end=datetime(2005, 1, 10), freq='D', name='index')
 
         s = Series(np.random.rand(len(dti)), dti)
 
@@ -383,10 +399,11 @@ class TestResample(tm.TestCase):
     def test_resample_extra_index_point(self):
         # GH 9756
         index = DatetimeIndex(start='20150101', end='20150331', freq='BM')
-        expected = DataFrame({'A' : Series([21,41,63], index=index)})
+        expected = DataFrame({'A': Series([21, 41, 63], index=index)})
 
         index = DatetimeIndex(start='20150101', end='20150331', freq='B')
-        df = DataFrame({'A' : Series(range(len(index)),index=index)},dtype='int64')
+        df = DataFrame(
+            {'A': Series(range(len(index)), index=index)}, dtype='int64')
         result = df.resample('BM', how='last')
         assert_frame_equal(result, expected)
 
@@ -421,25 +438,30 @@ class TestResample(tm.TestCase):
         self.assertEqual(xs['close'], s[4])
 
     def test_resample_ohlc_dataframe(self):
-        df = (pd.DataFrame({'PRICE': {Timestamp('2011-01-06 10:59:05', tz=None): 24990,
-                                     Timestamp('2011-01-06 12:43:33', tz=None): 25499,
-                                     Timestamp('2011-01-06 12:54:09', tz=None): 25499},
-                           'VOLUME': {Timestamp('2011-01-06 10:59:05', tz=None): 1500000000,
-                                      Timestamp('2011-01-06 12:43:33', tz=None): 5000000000,
-                                      Timestamp('2011-01-06 12:54:09', tz=None): 100000000}})
-            ).reindex_axis(['VOLUME', 'PRICE'], axis=1)
+        df = (
+            pd.DataFrame({
+                'PRICE': {
+                    Timestamp('2011-01-06 10:59:05', tz=None): 24990,
+                    Timestamp('2011-01-06 12:43:33', tz=None): 25499,
+                    Timestamp('2011-01-06 12:54:09', tz=None): 25499},
+                'VOLUME': {
+                    Timestamp('2011-01-06 10:59:05', tz=None): 1500000000,
+                    Timestamp('2011-01-06 12:43:33', tz=None): 5000000000,
+                    Timestamp('2011-01-06 12:54:09', tz=None): 100000000}})
+        ).reindex_axis(['VOLUME', 'PRICE'], axis=1)
         res = df.resample('H', how='ohlc')
         exp = pd.concat([df['VOLUME'].resample('H', how='ohlc'),
-                          df['PRICE'].resample('H', how='ohlc')],
+                         df['PRICE'].resample('H', how='ohlc')],
                         axis=1,
                         keys=['VOLUME', 'PRICE'])
         assert_frame_equal(exp, res)
 
         df.columns = [['a', 'b'], ['c', 'd']]
         res = df.resample('H', how='ohlc')
-        exp.columns = pd.MultiIndex.from_tuples([('a', 'c', 'open'), ('a', 'c', 'high'),
-            ('a', 'c', 'low'), ('a', 'c', 'close'), ('b', 'd', 'open'),
-            ('b', 'd', 'high'), ('b', 'd', 'low'), ('b', 'd', 'close')])
+        exp.columns = pd.MultiIndex.from_tuples([('a', 'c', 'open'), (
+            'a', 'c', 'high'), ('a', 'c', 'low'), ('a', 'c', 'close'), (
+                'b', 'd', 'open'), ('b', 'd', 'high'), ('b', 'd', 'low'), (
+                    'b', 'd', 'close')])
         assert_frame_equal(exp, res)
 
         # dupe columns fail atm
@@ -449,17 +471,19 @@ class TestResample(tm.TestCase):
 
         # GH 4812
         # dup columns with resample raising
-        df = DataFrame(np.random.randn(4,12),index=[2000,2000,2000,2000],columns=[ Period(year=2000,month=i+1,freq='M') for i in range(12) ])
-        df.iloc[3,:] = np.nan
-        result = df.resample('Q',axis=1)
-        expected = df.groupby(lambda x: int((x.month-1)/3),axis=1).mean()
-        expected.columns = [ Period(year=2000,quarter=i+1,freq='Q') for i in range(4) ]
+        df = DataFrame(np.random.randn(4, 12), index=[2000, 2000, 2000, 2000],
+                       columns=[Period(year=2000, month=i + 1, freq='M')
+                                for i in range(12)])
+        df.iloc[3, :] = np.nan
+        result = df.resample('Q', axis=1)
+        expected = df.groupby(lambda x: int((x.month - 1) / 3), axis=1).mean()
+        expected.columns = [
+            Period(year=2000, quarter=i + 1, freq='Q') for i in range(4)]
         assert_frame_equal(result, expected)
 
     def test_resample_reresample(self):
-        dti = DatetimeIndex(
-            start=datetime(2005, 1, 1), end=datetime(2005, 1, 10),
-            freq='D')
+        dti = DatetimeIndex(start=datetime(2005, 1, 1),
+                            end=datetime(2005, 1, 10), freq='D')
         s = Series(np.random.rand(len(dti)), dti)
         bs = s.resample('B', closed='right', label='right')
         result = bs.resample('8H')
@@ -496,8 +520,7 @@ class TestResample(tm.TestCase):
                 return np.repeat(np.nan, 4)
             return [group[0], group.max(), group.min(), group[-1]]
 
-        rng = date_range('1/1/2000 00:00:00', '1/1/2000 5:59:50',
-                         freq='10s')
+        rng = date_range('1/1/2000 00:00:00', '1/1/2000 5:59:50', freq='10s')
         ts = Series(np.random.randn(len(rng)), index=rng)
 
         resampled = ts.resample('5min', how='ohlc', closed='right',
@@ -586,8 +609,8 @@ class TestResample(tm.TestCase):
     def test_resample_anchored_ticks(self):
         # If a fixed delta (5 minute, 4 hour) evenly divides a day, we should
         # "anchor" the origin at midnight so we get regular intervals rather
-        # than starting from the first timestamp which might start in the middle
-        # of a desired interval
+        # than starting from the first timestamp which might start in the
+        # middle of a desired interval
 
         rng = date_range('1/1/2000 04:00:00', periods=86400, freq='s')
         ts = Series(np.random.randn(len(rng)), index=rng)
@@ -631,14 +654,14 @@ class TestResample(tm.TestCase):
     def test_resample_base_with_timedeltaindex(self):
 
         # GH 10530
-        rng = timedelta_range(start = '0s', periods = 25, freq = 's')
-        ts = Series(np.random.randn(len(rng)), index = rng)
+        rng = timedelta_range(start='0s', periods=25, freq='s')
+        ts = Series(np.random.randn(len(rng)), index=rng)
 
-        with_base = ts.resample('2s', base = 5)
+        with_base = ts.resample('2s', base=5)
         without_base = ts.resample('2s')
 
-        exp_without_base = timedelta_range(start = '0s', end = '25s', freq = '2s')
-        exp_with_base = timedelta_range(start = '5s', end = '29s', freq = '2s')
+        exp_without_base = timedelta_range(start='0s', end='25s', freq='2s')
+        exp_with_base = timedelta_range(start='5s', end='29s', freq='2s')
 
         self.assertTrue(without_base.index.equals(exp_without_base))
         self.assertTrue(with_base.index.equals(exp_with_base))
@@ -705,7 +728,7 @@ class TestResample(tm.TestCase):
         dates = date_range('4/16/2012 20:00', periods=5000, freq='h')
         ts = Series(np.random.randn(len(dates)), index=dates)
         # it works!
-        result = ts.resample('M')
+        ts.resample('M')
 
     def test_resample_anchored_intraday(self):
         # #1471, #1458
@@ -746,7 +769,7 @@ class TestResample(tm.TestCase):
         freqs = ['MS', 'BMS', 'QS-MAR', 'AS-DEC', 'AS-JUN']
 
         for freq in freqs:
-            result = ts.resample(freq, how='mean')
+            result = ts.resample(freq, how='mean')  # noqa
 
     def test_resample_anchored_multiday(self):
         # When resampling a range spanning multiple days, ensure that the
@@ -819,10 +842,10 @@ class TestResample(tm.TestCase):
 
     def test_resample_median_bug_1688(self):
 
-        for dtype in ['int64','int32','float64','float32']:
+        for dtype in ['int64', 'int32', 'float64', 'float32']:
             df = DataFrame([1, 2], index=[datetime(2012, 1, 1, 0, 0, 0),
                                           datetime(2012, 1, 1, 0, 5, 0)],
-                           dtype = dtype)
+                           dtype=dtype)
 
             result = df.resample("T", how=lambda x: x.mean())
             exp = df.asfreq('T')
@@ -869,8 +892,8 @@ class TestResample(tm.TestCase):
         # GH 6418
         # resample with bfill / limit / reindex consistency
 
-        i30 = index=pd.date_range('2002-02-02', periods=4, freq='30T')
-        s=pd.Series(np.arange(4.), index=i30)
+        i30 = pd.date_range('2002-02-02', periods=4, freq='30T')
+        s = pd.Series(np.arange(4.), index=i30)
         s[2] = np.NaN
 
         # Upsample by factor 3 with reindex() and resample() methods:
@@ -899,15 +922,18 @@ class TestResample(tm.TestCase):
         for dates in [dates1, dates2, dates3]:
             df = DataFrame(dict(A=dates, B=np.arange(len(dates))))
             result = df.set_index('A').resample('M', how='count')
-            exp_idx = pd.DatetimeIndex(['2014-07-31', '2014-08-31', '2014-09-30',
-                                        '2014-10-31', '2014-11-30'], freq='M', name='A')
+            exp_idx = pd.DatetimeIndex(['2014-07-31', '2014-08-31',
+                                        '2014-09-30',
+                                        '2014-10-31', '2014-11-30'],
+                                       freq='M', name='A')
             expected = DataFrame({'B': [1, 0, 2, 2, 1]}, index=exp_idx)
             assert_frame_equal(result, expected)
 
             result = df.groupby(pd.Grouper(freq='M', key='A')).count()
             assert_frame_equal(result, expected)
 
-            df = DataFrame(dict(A=dates, B=np.arange(len(dates)), C=np.arange(len(dates))))
+            df = DataFrame(dict(A=dates, B=np.arange(len(dates)), C=np.arange(
+                len(dates))))
             result = df.set_index('A').resample('M', how='count')
             expected = DataFrame({'B': [1, 0, 2, 2, 1], 'C': [1, 0, 2, 2, 1]},
                                  index=exp_idx, columns=['B', 'C'])
@@ -923,8 +949,7 @@ class TestResample(tm.TestCase):
                         index=np.random.choice(dr, n))
 
             left = ts.resample('30T', how='nunique')
-            ix = date_range(start=ts.index.min(),
-                            end=ts.index.max(),
+            ix = date_range(start=ts.index.min(), end=ts.index.max(),
                             freq='30T')
 
             vals = ts.values
@@ -936,7 +961,8 @@ class TestResample(tm.TestCase):
             mask = np.r_[True, vals[1:] != vals[:-1]]
             mask |= np.r_[True, bins[1:] != bins[:-1]]
 
-            arr = np.bincount(bins[mask] - 1, minlength=len(ix)).astype('int64',copy=False)
+            arr = np.bincount(bins[mask] - 1,
+                              minlength=len(ix)).astype('int64', copy=False)
             right = Series(arr, index=ix)
 
             assert_series_equal(left, right)
@@ -950,7 +976,8 @@ class TestResample(tm.TestCase):
         ix = date_range(start=left.index.min(), end=ts.index.max(), freq='7T')
 
         bins = np.searchsorted(ix.values, ts.index.values, side='right')
-        val = np.bincount(bins, minlength=len(ix) + 1)[1:].astype('int64',copy=False)
+        val = np.bincount(bins, minlength=len(ix) + 1)[1:].astype('int64',
+                                                                  copy=False)
 
         right = Series(val, index=ix)
         assert_series_equal(left, right)
@@ -962,55 +989,66 @@ class TestResample(tm.TestCase):
         assert_frame_equal(df.resample(rule='D', how='sum'),
                            DataFrame([5], index=df.index.normalize()))
         df.resample(rule='MS', how='sum')
-        assert_frame_equal(df.resample(rule='MS', how='sum'),
-                           DataFrame([5], index=DatetimeIndex([datetime(2012, 11, 1)],
-                                                              tz='US/Eastern')))
+        assert_frame_equal(
+            df.resample(rule='MS', how='sum'),
+            DataFrame([5], index=DatetimeIndex([datetime(2012, 11, 1)],
+                                               tz='US/Eastern')))
 
-        dti = date_range('2013-09-30', '2013-11-02', freq='30Min', tz='Europe/Paris')
+        dti = date_range('2013-09-30', '2013-11-02', freq='30Min',
+                         tz='Europe/Paris')
         values = range(dti.size)
-        df = DataFrame({"a": values, "b": values, "c": values}, index=dti, dtype='int64')
+        df = DataFrame({"a": values,
+                        "b": values,
+                        "c": values}, index=dti, dtype='int64')
         how = {"a": "min", "b": "max", "c": "count"}
 
-        assert_frame_equal(df.resample("W-MON", how=how)[["a", "b", "c"]],
-                           DataFrame({"a": [0, 48, 384, 720, 1056, 1394],
-                                      "b": [47, 383, 719, 1055, 1393, 1586],
-                                      "c": [48, 336, 336, 336, 338, 193]},
-                                     index=date_range('9/30/2013', '11/4/2013',
-                                                      freq='W-MON', tz='Europe/Paris')),
-                           'W-MON Frequency')
-
-        assert_frame_equal(df.resample("2W-MON", how=how)[["a", "b", "c"]],
-                           DataFrame({"a": [0, 48, 720, 1394],
-                                      "b": [47, 719, 1393, 1586],
-                                      "c": [48, 672, 674, 193]},
-                                     index=date_range('9/30/2013', '11/11/2013',
-                                                      freq='2W-MON', tz='Europe/Paris')),
-                           '2W-MON Frequency')
-
-        assert_frame_equal(df.resample("MS", how=how)[["a", "b", "c"]],
-                           DataFrame({"a": [0, 48, 1538],
-                                      "b": [47, 1537, 1586],
-                                      "c": [48, 1490, 49]},
-                                     index=date_range('9/1/2013', '11/1/2013',
-                                                      freq='MS', tz='Europe/Paris')),
-                           'MS Frequency')
-
-        assert_frame_equal(df.resample("2MS", how=how)[["a", "b", "c"]],
-                           DataFrame({"a": [0, 1538],
-                                      "b": [1537, 1586],
-                                      "c": [1538, 49]},
-                                     index=date_range('9/1/2013', '11/1/2013',
-                                                      freq='2MS', tz='Europe/Paris')),
-                           '2MS Frequency')
+        assert_frame_equal(
+            df.resample("W-MON", how=how)[["a", "b", "c"]],
+            DataFrame({"a": [0, 48, 384, 720, 1056, 1394],
+                       "b": [47, 383, 719, 1055, 1393, 1586],
+                       "c": [48, 336, 336, 336, 338, 193]},
+                      index=date_range('9/30/2013', '11/4/2013',
+                                       freq='W-MON', tz='Europe/Paris')),
+            'W-MON Frequency')
+
+        assert_frame_equal(
+            df.resample("2W-MON", how=how)[["a", "b", "c"]],
+            DataFrame({"a": [0, 48, 720, 1394],
+                       "b": [47, 719, 1393, 1586],
+                       "c": [48, 672, 674, 193]},
+                      index=date_range('9/30/2013', '11/11/2013',
+                                       freq='2W-MON', tz='Europe/Paris')),
+            '2W-MON Frequency')
+
+        assert_frame_equal(
+            df.resample("MS", how=how)[["a", "b", "c"]],
+            DataFrame({"a": [0, 48, 1538],
+                       "b": [47, 1537, 1586],
+                       "c": [48, 1490, 49]},
+                      index=date_range('9/1/2013', '11/1/2013',
+                                       freq='MS', tz='Europe/Paris')),
+            'MS Frequency')
+
+        assert_frame_equal(
+            df.resample("2MS", how=how)[["a", "b", "c"]],
+            DataFrame({"a": [0, 1538],
+                       "b": [1537, 1586],
+                       "c": [1538, 49]},
+                      index=date_range('9/1/2013', '11/1/2013',
+                                       freq='2MS', tz='Europe/Paris')),
+            '2MS Frequency')
 
         df_daily = df['10/26/2013':'10/29/2013']
-        assert_frame_equal(df_daily.resample("D", how={"a": "min", "b": "max", "c": "count"})[["a", "b", "c"]],
-                           DataFrame({"a": [1248, 1296, 1346, 1394],
-                                      "b": [1295, 1345, 1393, 1441],
-                                      "c": [48, 50, 48, 48]},
-                                     index=date_range('10/26/2013', '10/29/2013',
-                                                      freq='D', tz='Europe/Paris')),
-                           'D Frequency')
+        assert_frame_equal(
+            df_daily.resample("D", how={"a": "min", "b": "max", "c": "count"})
+            [["a", "b", "c"]],
+            DataFrame({"a": [1248, 1296, 1346, 1394],
+                       "b": [1295, 1345, 1393, 1441],
+                       "c": [48, 50, 48, 48]},
+                      index=date_range('10/26/2013', '10/29/2013',
+                                       freq='D', tz='Europe/Paris')),
+            'D Frequency')
+
 
 def _simple_ts(start, end, freq='D'):
     rng = date_range(start, end, freq=freq)
@@ -1066,8 +1104,7 @@ class TestResamplePeriodIndex(tm.TestCase):
         for month in MONTHS:
             ts = _simple_pts('1/1/1990', end, freq='A-%s' % month)
 
-            result = ts.resample(targ, fill_method=meth,
-                                 convention=conv)
+            result = ts.resample(targ, fill_method=meth, convention=conv)
             expected = result.to_timestamp(targ, how=conv)
             expected = expected.asfreq(targ, meth).to_period()
             assert_series_equal(result, expected)
@@ -1077,8 +1114,7 @@ class TestResamplePeriodIndex(tm.TestCase):
         result = ts.resample('a-dec')
 
         expected = ts.groupby(ts.index.year).mean()
-        expected.index = period_range('1/1/1990', '6/30/1995',
-                                      freq='a-dec')
+        expected.index = period_range('1/1/1990', '6/30/1995', freq='a-dec')
         assert_series_equal(result, expected)
 
         # this is ok
@@ -1150,15 +1186,14 @@ class TestResamplePeriodIndex(tm.TestCase):
         ts = _simple_pts('1/1/1990', '12/31/1995', freq='M')
 
         for targ, conv in product(targets, ['start', 'end']):
-            result = ts.resample(targ, fill_method='ffill',
-                                 convention=conv)
+            result = ts.resample(targ, fill_method='ffill', convention=conv)
             expected = result.to_timestamp(targ, how=conv)
             expected = expected.asfreq(targ, 'ffill').to_period()
             assert_series_equal(result, expected)
 
     def test_fill_method_and_how_upsample(self):
         # GH2073
-        s = Series(np.arange(9,dtype='int64'),
+        s = Series(np.arange(9, dtype='int64'),
                    index=date_range('2010-01-01', periods=9, freq='Q'))
         last = s.resample('M', fill_method='ffill')
         both = s.resample('M', how='last', fill_method='ffill').astype('int64')
@@ -1325,12 +1360,17 @@ class TestResamplePeriodIndex(tm.TestCase):
         rng = date_range('1/1/2011', periods=20000, freq='H')
         rng = rng.tz_localize('EST')
         ts = DataFrame(index=rng)
-        ts['first']=np.random.randn(len(rng))
-        ts['second']=np.cumsum(np.random.randn(len(rng)))
-        expected = DataFrame({ 'first' : ts.resample('A',how=np.sum)['first'],
-                               'second' : ts.resample('A',how=np.mean)['second'] },columns=['first','second'])
-        result = ts.resample('A', how={'first':np.sum, 'second':np.mean}).reindex(columns=['first','second'])
-        assert_frame_equal(result,expected)
+        ts['first'] = np.random.randn(len(rng))
+        ts['second'] = np.cumsum(np.random.randn(len(rng)))
+        expected = DataFrame(
+            {
+                'first': ts.resample('A', how=np.sum)['first'],
+                'second': ts.resample('A', how=np.mean)['second']},
+            columns=['first', 'second'])
+        result = ts.resample(
+            'A', how={'first': np.sum,
+                      'second': np.mean}).reindex(columns=['first', 'second'])
+        assert_frame_equal(result, expected)
 
     def test_closed_left_corner(self):
         # #1465
@@ -1372,7 +1412,7 @@ class TestResamplePeriodIndex(tm.TestCase):
 
     def test_resample_bms_2752(self):
         # GH2753
-        foo = pd.Series(index=pd.bdate_range('20000101','20000201'))
+        foo = pd.Series(index=pd.bdate_range('20000101', '20000201'))
         res1 = foo.resample("BMS")
         res2 = foo.resample("BMS").resample("B")
         self.assertEqual(res1.index[0], Timestamp('20000103'))
@@ -1396,8 +1436,7 @@ class TestResamplePeriodIndex(tm.TestCase):
         end_types = ['M', 'A', 'Q', 'W']
 
         for from_freq, to_freq in zip(end_freq, end_types):
-            idx = DatetimeIndex(start='8/15/2012', periods=100,
-                                freq=from_freq)
+            idx = DatetimeIndex(start='8/15/2012', periods=100, freq=from_freq)
             df = DataFrame(np.random.randn(len(idx), 2), idx)
 
             resampled = df.resample(to_freq)
@@ -1409,8 +1448,7 @@ class TestResamplePeriodIndex(tm.TestCase):
         others_freq = ['D', 'Q', 'M', 'H', 'T']
 
         for from_freq, to_freq in zip(others_freq, others):
-            idx = DatetimeIndex(start='8/15/2012', periods=100,
-                                freq=from_freq)
+            idx = DatetimeIndex(start='8/15/2012', periods=100, freq=from_freq)
             df = DataFrame(np.random.randn(len(idx), 2), idx)
 
             resampled = df.resample(to_freq)
@@ -1429,11 +1467,13 @@ class TestResamplePeriodIndex(tm.TestCase):
         # 4076
         # when the frequency is evenly divisible, sometimes extra bins
 
-        df = DataFrame(np.random.randn(9, 3), index=date_range('2000-1-1', periods=9))
+        df = DataFrame(np.random.randn(9, 3),
+                       index=date_range('2000-1-1', periods=9))
         result = df.resample('5D')
-        expected = pd.concat([df.iloc[0:5].mean(),df.iloc[5:].mean()],axis=1).T
-        expected.index = [Timestamp('2000-1-1'),Timestamp('2000-1-6')]
-        assert_frame_equal(result,expected)
+        expected = pd.concat(
+            [df.iloc[0:5].mean(), df.iloc[5:].mean()], axis=1).T
+        expected.index = [Timestamp('2000-1-1'), Timestamp('2000-1-6')]
+        assert_frame_equal(result, expected)
 
         index = date_range(start='2001-5-4', periods=28)
         df = DataFrame(
@@ -1443,23 +1483,23 @@ class TestResamplePeriodIndex(tm.TestCase):
               'COOP_DLY_TRN_QT': 50, 'COOP_DLY_SLS_AMT': 20}] * 28,
             index=index.append(index)).sort_index()
 
-        index = date_range('2001-5-4',periods=4,freq='7D')
+        index = date_range('2001-5-4', periods=4, freq='7D')
         expected = DataFrame(
             [{'REST_KEY': 14, 'DLY_TRN_QT': 14, 'DLY_SLS_AMT': 14,
               'COOP_DLY_TRN_QT': 14, 'COOP_DLY_SLS_AMT': 14}] * 4,
             index=index)
         result = df.resample('7D', how='count')
-        assert_frame_equal(result,expected)
+        assert_frame_equal(result, expected)
 
         expected = DataFrame(
             [{'REST_KEY': 21, 'DLY_TRN_QT': 1050, 'DLY_SLS_AMT': 700,
               'COOP_DLY_TRN_QT': 560, 'COOP_DLY_SLS_AMT': 280}] * 4,
             index=index)
         result = df.resample('7D', how='sum')
-        assert_frame_equal(result,expected)
+        assert_frame_equal(result, expected)
 
-class TestTimeGrouper(tm.TestCase):
 
+class TestTimeGrouper(tm.TestCase):
     def setUp(self):
         self.ts = Series(np.random.randn(1000),
                          index=date_range('1/1/2000', periods=1000))
@@ -1481,7 +1521,9 @@ class TestTimeGrouper(tm.TestCase):
     def test_count(self):
         self.ts[::3] = np.nan
 
-        grouper = TimeGrouper('A', label='right', closed='right')
+        # TODO: unused?
+        grouper = TimeGrouper('A', label='right', closed='right')  # noqa
+
         result = self.ts.resample('A', how='count')
 
         expected = self.ts.groupby(lambda x: x.year).count()
@@ -1526,8 +1568,9 @@ class TestTimeGrouper(tm.TestCase):
         binagg = bingrouped.mean()
 
         def f(x):
-            assert(isinstance(x, Panel))
+            assert (isinstance(x, Panel))
             return x.mean(1)
+
         result = bingrouped.agg(f)
         tm.assert_panel_equal(result, binagg)
 
@@ -1555,8 +1598,9 @@ class TestTimeGrouper(tm.TestCase):
         normal_df['key'] = [1, 2, 3, 4, 5] * 4
 
         dt_df = DataFrame(data, columns=['A', 'B', 'C', 'D'])
-        dt_df['key'] = [datetime(2013, 1, 1), datetime(2013, 1, 2), datetime(2013, 1, 3),
-                        datetime(2013, 1, 4), datetime(2013, 1, 5)] * 4
+        dt_df['key'] = [datetime(2013, 1, 1), datetime(2013, 1, 2),
+                        datetime(2013, 1, 3), datetime(2013, 1, 4),
+                        datetime(2013, 1, 5)] * 4
 
         normal_grouped = normal_df.groupby('key')
         dt_grouped = dt_df.groupby(TimeGrouper(key='key', freq='D'))
@@ -1564,36 +1608,41 @@ class TestTimeGrouper(tm.TestCase):
         for func in ['min', 'max', 'prod', 'var', 'std', 'mean']:
             expected = getattr(normal_grouped, func)()
             dt_result = getattr(dt_grouped, func)()
-            expected.index = date_range(start='2013-01-01', freq='D', periods=5, name='key')
+            expected.index = date_range(start='2013-01-01', freq='D',
+                                        periods=5, name='key')
             assert_frame_equal(expected, dt_result)
 
         for func in ['count', 'sum']:
             expected = getattr(normal_grouped, func)()
-            expected.index = date_range(start='2013-01-01', freq='D', periods=5, name='key')
+            expected.index = date_range(start='2013-01-01', freq='D',
+                                        periods=5, name='key')
             dt_result = getattr(dt_grouped, func)()
             assert_frame_equal(expected, dt_result)
 
         # GH 7453
         for func in ['size']:
             expected = getattr(normal_grouped, func)()
-            expected.index = date_range(start='2013-01-01', freq='D', periods=5, name='key')
+            expected.index = date_range(start='2013-01-01', freq='D',
+                                        periods=5, name='key')
             dt_result = getattr(dt_grouped, func)()
             assert_series_equal(expected, dt_result)
-
         """
         for func in ['first', 'last']:
             expected = getattr(normal_grouped, func)()
-            expected.index = date_range(start='2013-01-01', freq='D', periods=5, name='key')
+            expected.index = date_range(start='2013-01-01', freq='D',
+                                        periods=5, name='key')
             dt_result = getattr(dt_grouped, func)()
             assert_frame_equal(expected, dt_result)
 
         for func in ['nth']:
             expected = getattr(normal_grouped, func)(3)
-            expected.index = date_range(start='2013-01-01', freq='D', periods=5, name='key')
+            expected.index = date_range(start='2013-01-01',
+                                        freq='D', periods=5, name='key')
             dt_result = getattr(dt_grouped, func)(3)
             assert_frame_equal(expected, dt_result)
         """
-        # if TimeGrouper is used included, 'first','last' and 'nth' doesn't work yet
+        # if TimeGrouper is used included, 'first','last' and 'nth' doesn't
+        # work yet
 
     def test_aggregate_with_nat(self):
         # check TimeGrouper's aggregation is identical as normal groupby
@@ -1613,19 +1662,22 @@ class TestTimeGrouper(tm.TestCase):
         for func in ['min', 'max', 'sum', 'prod']:
             normal_result = getattr(normal_grouped, func)()
             dt_result = getattr(dt_grouped, func)()
-            pad = DataFrame([[np.nan, np.nan, np.nan, np.nan]],
-                            index=[3], columns=['A', 'B', 'C', 'D'])
+            pad = DataFrame([[np.nan, np.nan, np.nan, np.nan]], index=[3],
+                            columns=['A', 'B', 'C', 'D'])
             expected = normal_result.append(pad)
             expected = expected.sort_index()
-            expected.index = date_range(start='2013-01-01', freq='D', periods=5, name='key')
+            expected.index = date_range(start='2013-01-01', freq='D',
+                                        periods=5, name='key')
             assert_frame_equal(expected, dt_result)
 
         for func in ['count']:
             normal_result = getattr(normal_grouped, func)()
-            pad = DataFrame([[0, 0, 0, 0]], index=[3], columns=['A', 'B', 'C', 'D'])
+            pad = DataFrame([[0, 0, 0, 0]], index=[3],
+                            columns=['A', 'B', 'C', 'D'])
             expected = normal_result.append(pad)
             expected = expected.sort_index()
-            expected.index = date_range(start='2013-01-01', freq='D', periods=5, name='key')
+            expected.index = date_range(start='2013-01-01', freq='D',
+                                        periods=5, name='key')
             dt_result = getattr(dt_grouped, func)()
             assert_frame_equal(expected, dt_result)
 
@@ -1634,13 +1686,15 @@ class TestTimeGrouper(tm.TestCase):
             pad = Series([0], index=[3])
             expected = normal_result.append(pad)
             expected = expected.sort_index()
-            expected.index = date_range(start='2013-01-01', freq='D', periods=5, name='key')
+            expected.index = date_range(start='2013-01-01', freq='D',
+                                        periods=5, name='key')
             dt_result = getattr(dt_grouped, func)()
             assert_series_equal(expected, dt_result)
             # GH 9925
             self.assertEqual(dt_result.index.name, 'key')
 
-        # if NaT is included, 'var', 'std', 'mean', 'first','last' and 'nth' doesn't work yet
+        # if NaT is included, 'var', 'std', 'mean', 'first','last' and 'nth'
+        # doesn't work yet
 
 
 if __name__ == '__main__':
diff --git a/pandas/tseries/tests/test_timedeltas.py b/pandas/tseries/tests/test_timedeltas.py
index 176b5e90b..d5a057d25 100644
--- a/pandas/tseries/tests/test_timedeltas.py
+++ b/pandas/tseries/tests/test_timedeltas.py
@@ -1,34 +1,30 @@
 # pylint: disable-msg=E1101,W0612
 
 from __future__ import division
-from datetime import datetime, timedelta, time
+from datetime import timedelta, time
 import nose
 
 from distutils.version import LooseVersion
 import numpy as np
 import pandas as pd
 
-from pandas import (Index, Series, DataFrame, Timestamp, Timedelta, TimedeltaIndex, isnull, notnull,
-                    bdate_range, date_range, timedelta_range, Int64Index)
-import pandas.core.common as com
-from pandas.compat import StringIO, lrange, range, zip, u, OrderedDict, long
+from pandas import (Index, Series, DataFrame, Timestamp, Timedelta,
+                    TimedeltaIndex, isnull, date_range,
+                    timedelta_range, Int64Index)
+from pandas.compat import range
 from pandas import compat, to_timedelta, tslib
 from pandas.tseries.timedeltas import _coerce_scalar_to_timedelta_type as ct
-from pandas.util.testing import (assert_series_equal,
-                                 assert_frame_equal,
-                                 assert_almost_equal,
-                                 assert_index_equal,
-                                 ensure_clean)
+from pandas.util.testing import (assert_series_equal, assert_frame_equal,
+                                 assert_almost_equal, assert_index_equal)
 from numpy.testing import assert_allclose
-from pandas.tseries.offsets import Day, Second, Hour
+from pandas.tseries.offsets import Day, Second
 import pandas.util.testing as tm
-from numpy.random import rand, randn
+from numpy.random import randn
 from pandas import _np_version_under1p8
-import pandas.compat as compat
-
 
 iNaT = tslib.iNaT
 
+
 class TestTimedeltas(tm.TestCase):
     _multiprocess_can_split_ = True
 
@@ -37,35 +33,46 @@ class TestTimedeltas(tm.TestCase):
 
     def test_construction(self):
 
-        expected = np.timedelta64(10,'D').astype('m8[ns]').view('i8')
-        self.assertEqual(Timedelta(10,unit='d').value, expected)
-        self.assertEqual(Timedelta(10.0,unit='d').value, expected)
+        expected = np.timedelta64(10, 'D').astype('m8[ns]').view('i8')
+        self.assertEqual(Timedelta(10, unit='d').value, expected)
+        self.assertEqual(Timedelta(10.0, unit='d').value, expected)
         self.assertEqual(Timedelta('10 days').value, expected)
         self.assertEqual(Timedelta(days=10).value, expected)
         self.assertEqual(Timedelta(days=10.0).value, expected)
 
-        expected += np.timedelta64(10,'s').astype('m8[ns]').view('i8')
+        expected += np.timedelta64(10, 's').astype('m8[ns]').view('i8')
         self.assertEqual(Timedelta('10 days 00:00:10').value, expected)
-        self.assertEqual(Timedelta(days=10,seconds=10).value, expected)
-        self.assertEqual(Timedelta(days=10,milliseconds=10*1000).value, expected)
-        self.assertEqual(Timedelta(days=10,microseconds=10*1000*1000).value, expected)
+        self.assertEqual(Timedelta(days=10, seconds=10).value, expected)
+        self.assertEqual(
+            Timedelta(days=10, milliseconds=10 * 1000).value, expected)
+        self.assertEqual(
+            Timedelta(days=10, microseconds=10 * 1000 * 1000).value, expected)
 
         # test construction with np dtypes
         # GH 8757
-        timedelta_kwargs = {'days':'D', 'seconds':'s', 'microseconds':'us',
-                            'milliseconds':'ms', 'minutes':'m', 'hours':'h', 'weeks':'W'}
-        npdtypes = [np.int64, np.int32, np.int16,
-                    np.float64, np.float32, np.float16]
+        timedelta_kwargs = {'days': 'D',
+                            'seconds': 's',
+                            'microseconds': 'us',
+                            'milliseconds': 'ms',
+                            'minutes': 'm',
+                            'hours': 'h',
+                            'weeks': 'W'}
+        npdtypes = [np.int64, np.int32, np.int16, np.float64, np.float32,
+                    np.float16]
         for npdtype in npdtypes:
             for pykwarg, npkwarg in timedelta_kwargs.items():
-                expected = np.timedelta64(1, npkwarg).astype('m8[ns]').view('i8')
-                self.assertEqual(Timedelta(**{pykwarg:npdtype(1)}).value, expected)
+                expected = np.timedelta64(1,
+                                          npkwarg).astype('m8[ns]').view('i8')
+                self.assertEqual(
+                    Timedelta(**{pykwarg: npdtype(1)}).value, expected)
 
         # rounding cases
         self.assertEqual(Timedelta(82739999850000).value, 82739999850000)
-        self.assertTrue('0 days 22:58:59.999850' in str(Timedelta(82739999850000)))
+        self.assertTrue('0 days 22:58:59.999850' in str(Timedelta(
+            82739999850000)))
         self.assertEqual(Timedelta(123072001000000).value, 123072001000000)
-        self.assertTrue('1 days 10:11:12.001' in str(Timedelta(123072001000000)))
+        self.assertTrue('1 days 10:11:12.001' in str(Timedelta(
+            123072001000000)))
 
         # string conversion with/without leading zero
         # GH 9570
@@ -94,69 +101,75 @@ class TestTimedeltas(tm.TestCase):
         self.assertEqual(Timedelta('1 us'), timedelta(microseconds=1))
         self.assertEqual(Timedelta('1 micros'), timedelta(microseconds=1))
         self.assertEqual(Timedelta('1 microsecond'), timedelta(microseconds=1))
-        self.assertEqual(Timedelta('1.5 microsecond'), Timedelta('00:00:00.000001500'))
+        self.assertEqual(Timedelta('1.5 microsecond'),
+                         Timedelta('00:00:00.000001500'))
         self.assertEqual(Timedelta('1 ns'), Timedelta('00:00:00.000000001'))
-        self.assertEqual(Timedelta('1 nano'),  Timedelta('00:00:00.000000001'))
-        self.assertEqual(Timedelta('1 nanosecond'),  Timedelta('00:00:00.000000001'))
+        self.assertEqual(Timedelta('1 nano'), Timedelta('00:00:00.000000001'))
+        self.assertEqual(Timedelta('1 nanosecond'),
+                         Timedelta('00:00:00.000000001'))
 
         # combos
-        self.assertEqual(Timedelta('10 days 1 hour'), timedelta(days=10,hours=1))
-        self.assertEqual(Timedelta('10 days 1 h'), timedelta(days=10,hours=1))
-        self.assertEqual(Timedelta('10 days 1 h 1m 1s'), timedelta(days=10,hours=1,minutes=1,seconds=1))
-        self.assertEqual(Timedelta('-10 days 1 h 1m 1s'), -timedelta(days=10,hours=1,minutes=1,seconds=1))
-        self.assertEqual(Timedelta('-10 days 1 h 1m 1s'), -timedelta(days=10,hours=1,minutes=1,seconds=1))
-        self.assertEqual(Timedelta('-10 days 1 h 1m 1s 3us'), -timedelta(days=10,hours=1,minutes=1,seconds=1,microseconds=3))
-        self.assertEqual(Timedelta('-10 days 1 h 1.5m 1s 3us'), -timedelta(days=10,hours=1,minutes=1,seconds=31,microseconds=3))
-
-        # currently invalid as it has a - on the hhmmdd part (only allowed on the days)
-        self.assertRaises(ValueError, lambda : Timedelta('-10 days -1 h 1.5m 1s 3us'))
+        self.assertEqual(Timedelta('10 days 1 hour'),
+                         timedelta(days=10, hours=1))
+        self.assertEqual(Timedelta('10 days 1 h'), timedelta(days=10, hours=1))
+        self.assertEqual(Timedelta('10 days 1 h 1m 1s'), timedelta(
+            days=10, hours=1, minutes=1, seconds=1))
+        self.assertEqual(Timedelta('-10 days 1 h 1m 1s'), -
+                         timedelta(days=10, hours=1, minutes=1, seconds=1))
+        self.assertEqual(Timedelta('-10 days 1 h 1m 1s'), -
+                         timedelta(days=10, hours=1, minutes=1, seconds=1))
+        self.assertEqual(Timedelta('-10 days 1 h 1m 1s 3us'), -
+                         timedelta(days=10, hours=1, minutes=1,
+                                   seconds=1, microseconds=3))
+        self.assertEqual(Timedelta('-10 days 1 h 1.5m 1s 3us'), -
+                         timedelta(days=10, hours=1, minutes=1,
+                                   seconds=31, microseconds=3))
+
+        # currently invalid as it has a - on the hhmmdd part (only allowed on
+        # the days)
+        self.assertRaises(ValueError,
+                          lambda: Timedelta('-10 days -1 h 1.5m 1s 3us'))
 
         # only leading neg signs are allowed
-        self.assertRaises(ValueError, lambda : Timedelta('10 days -1 h 1.5m 1s 3us'))
+        self.assertRaises(ValueError,
+                          lambda: Timedelta('10 days -1 h 1.5m 1s 3us'))
 
         # no units specified
-        self.assertRaises(ValueError, lambda : Timedelta('3.1415'))
+        self.assertRaises(ValueError, lambda: Timedelta('3.1415'))
 
         # invalid construction
+        tm.assertRaisesRegexp(ValueError, "cannot construct a TimeDelta",
+                              lambda: Timedelta())
+        tm.assertRaisesRegexp(ValueError, "unit abbreviation w/o a number",
+                              lambda: Timedelta('foo'))
         tm.assertRaisesRegexp(ValueError,
-                              "cannot construct a TimeDelta",
-                              lambda : Timedelta())
-        tm.assertRaisesRegexp(ValueError,
-                              "unit abbreviation w/o a number",
-                              lambda : Timedelta('foo'))
-        tm.assertRaisesRegexp(ValueError,
-                              "cannot construct a TimeDelta from the passed arguments, allowed keywords are ",
-                              lambda : Timedelta(day=10))
+                              "cannot construct a TimeDelta from the passed "
+                              "arguments, allowed keywords are ",
+                              lambda: Timedelta(day=10))
 
         # roundtripping both for string and value
-        for v in ['1s',
-                  '-1s',
-                  '1us',
-                  '-1us',
-                  '1 day',
-                  '-1 day',
-                  '-23:59:59.999999',
-                  '-1 days +23:59:59.999999',
-                  '-1ns',
-                  '1ns',
-                  '-23:59:59.999999999']:
+        for v in ['1s', '-1s', '1us', '-1us', '1 day', '-1 day',
+                  '-23:59:59.999999', '-1 days +23:59:59.999999', '-1ns',
+                  '1ns', '-23:59:59.999999999']:
 
             td = Timedelta(v)
-            self.assertEqual(Timedelta(td.value),td)
+            self.assertEqual(Timedelta(td.value), td)
 
             # str does not normally display nanos
             if not td.nanoseconds:
-                self.assertEqual(Timedelta(str(td)),td)
-            self.assertEqual(Timedelta(td._repr_base(format='all')),td)
+                self.assertEqual(Timedelta(str(td)), td)
+            self.assertEqual(Timedelta(td._repr_base(format='all')), td)
 
         # floats
-        expected = np.timedelta64(10,'s').astype('m8[ns]').view('i8') + np.timedelta64(500,'ms').astype('m8[ns]').view('i8')
-        self.assertEqual(Timedelta(10.5,unit='s').value, expected)
+        expected = np.timedelta64(
+            10, 's').astype('m8[ns]').view('i8') + np.timedelta64(
+                500, 'ms').astype('m8[ns]').view('i8')
+        self.assertEqual(Timedelta(10.5, unit='s').value, expected)
 
         # nat
-        self.assertEqual(Timedelta('').value,iNaT)
-        self.assertEqual(Timedelta('nat').value,iNaT)
-        self.assertEqual(Timedelta('NAT').value,iNaT)
+        self.assertEqual(Timedelta('').value, iNaT)
+        self.assertEqual(Timedelta('nat').value, iNaT)
+        self.assertEqual(Timedelta('NAT').value, iNaT)
         self.assertTrue(isnull(Timestamp('nat')))
         self.assertTrue(isnull(Timedelta('nat')))
 
@@ -184,41 +197,24 @@ class TestTimedeltas(tm.TestCase):
         t2 = Timedelta('-1 days 02:34:56.789123456')
 
         for (freq, s1, s2) in [('N', t1, t2),
-                               ('U',
-                                Timedelta('1 days 02:34:56.789123000'),
-                                Timedelta('-1 days 02:34:56.789123000')
-                                ),
-                               ('L',
-                                Timedelta('1 days 02:34:56.789000000'),
-                                Timedelta('-1 days 02:34:56.789000000')
-                                ),
-                               ('S',
-                                Timedelta('1 days 02:34:57'),
-                                Timedelta('-1 days 02:34:57')
-                                ),
-                               ('2S',
-                                Timedelta('1 days 02:34:56'),
-                                Timedelta('-1 days 02:34:56')
-                                ),
-                               ('5S',
-                                Timedelta('1 days 02:34:55'),
-                                Timedelta('-1 days 02:34:55')
-                                ),
-                               ('T',
-                                Timedelta('1 days 02:35:00'),
-                                Timedelta('-1 days 02:35:00')
-                                ),
-                               ('12T',
-                                Timedelta('1 days 02:36:00'),
+                               ('U', Timedelta('1 days 02:34:56.789123000'),
+                                Timedelta('-1 days 02:34:56.789123000')),
+                               ('L', Timedelta('1 days 02:34:56.789000000'),
+                                Timedelta('-1 days 02:34:56.789000000')),
+                               ('S', Timedelta('1 days 02:34:57'),
+                                Timedelta('-1 days 02:34:57')),
+                               ('2S', Timedelta('1 days 02:34:56'),
+                                Timedelta('-1 days 02:34:56')),
+                               ('5S', Timedelta('1 days 02:34:55'),
+                                Timedelta('-1 days 02:34:55')),
+                               ('T', Timedelta('1 days 02:35:00'),
+                                Timedelta('-1 days 02:35:00')),
+                               ('12T', Timedelta('1 days 02:36:00'),
                                 Timedelta('-1 days 02:36:00')),
-                               ('H',
-                                Timedelta('1 days 03:00:00'),
-                                Timedelta('-1 days 03:00:00')
-                                ),
-                               ('d',
-                                Timedelta('1 days'),
-                                Timedelta('-1 days')
-                                )]:
+                               ('H', Timedelta('1 days 03:00:00'),
+                                Timedelta('-1 days 03:00:00')),
+                               ('d', Timedelta('1 days'),
+                                Timedelta('-1 days'))]:
             r1 = t1.round(freq)
             self.assertEqual(r1, s1)
             r2 = t2.round(freq)
@@ -279,25 +275,30 @@ class TestTimedeltas(tm.TestCase):
 
     def test_repr(self):
 
-        self.assertEqual(repr(Timedelta(10,unit='d')),"Timedelta('10 days 00:00:00')")
-        self.assertEqual(repr(Timedelta(10,unit='s')),"Timedelta('0 days 00:00:10')")
-        self.assertEqual(repr(Timedelta(10,unit='ms')),"Timedelta('0 days 00:00:00.010000')")
-        self.assertEqual(repr(Timedelta(-10,unit='ms')),"Timedelta('-1 days +23:59:59.990000')")
+        self.assertEqual(repr(Timedelta(10, unit='d')),
+                         "Timedelta('10 days 00:00:00')")
+        self.assertEqual(repr(Timedelta(10, unit='s')),
+                         "Timedelta('0 days 00:00:10')")
+        self.assertEqual(repr(Timedelta(10, unit='ms')),
+                         "Timedelta('0 days 00:00:00.010000')")
+        self.assertEqual(repr(Timedelta(-10, unit='ms')),
+                         "Timedelta('-1 days +23:59:59.990000')")
 
     def test_identity(self):
 
-        td = Timedelta(10,unit='d')
+        td = Timedelta(10, unit='d')
         self.assertTrue(isinstance(td, Timedelta))
         self.assertTrue(isinstance(td, timedelta))
 
     def test_conversion(self):
 
-        for td in [ Timedelta(10,unit='d'), Timedelta('1 days, 10:11:12.012345') ]:
+        for td in [Timedelta(10, unit='d'),
+                   Timedelta('1 days, 10:11:12.012345')]:
             pydt = td.to_pytimedelta()
             self.assertTrue(td == Timedelta(pydt))
             self.assertEqual(td, pydt)
-            self.assertTrue(isinstance(pydt, timedelta)
-                            and not isinstance(pydt, Timedelta))
+            self.assertTrue(isinstance(pydt, timedelta) and not isinstance(
+                pydt, Timedelta))
 
             self.assertEqual(td, np.timedelta64(td.value, 'ns'))
             td64 = td.to_timedelta64()
@@ -311,36 +312,36 @@ class TestTimedeltas(tm.TestCase):
 
     def test_ops(self):
 
-        td = Timedelta(10,unit='d')
-        self.assertEqual(-td,Timedelta(-10,unit='d'))
-        self.assertEqual(+td,Timedelta(10,unit='d'))
-        self.assertEqual(td - td, Timedelta(0,unit='ns'))
+        td = Timedelta(10, unit='d')
+        self.assertEqual(-td, Timedelta(-10, unit='d'))
+        self.assertEqual(+td, Timedelta(10, unit='d'))
+        self.assertEqual(td - td, Timedelta(0, unit='ns'))
         self.assertTrue((td - pd.NaT) is pd.NaT)
-        self.assertEqual(td + td, Timedelta(20,unit='d'))
+        self.assertEqual(td + td, Timedelta(20, unit='d'))
         self.assertTrue((td + pd.NaT) is pd.NaT)
-        self.assertEqual(td * 2, Timedelta(20,unit='d'))
+        self.assertEqual(td * 2, Timedelta(20, unit='d'))
         self.assertTrue((td * pd.NaT) is pd.NaT)
-        self.assertEqual(td / 2, Timedelta(5,unit='d'))
+        self.assertEqual(td / 2, Timedelta(5, unit='d'))
         self.assertEqual(abs(td), td)
         self.assertEqual(abs(-td), td)
         self.assertEqual(td / td, 1)
         self.assertTrue((td / pd.NaT) is np.nan)
 
         # invert
-        self.assertEqual(-td,Timedelta('-10d'))
-        self.assertEqual(td * -1,Timedelta('-10d'))
-        self.assertEqual(-1 * td,Timedelta('-10d'))
-        self.assertEqual(abs(-td),Timedelta('10d'))
+        self.assertEqual(-td, Timedelta('-10d'))
+        self.assertEqual(td * -1, Timedelta('-10d'))
+        self.assertEqual(-1 * td, Timedelta('-10d'))
+        self.assertEqual(abs(-td), Timedelta('10d'))
 
         # invalid
-        self.assertRaises(TypeError, lambda : Timedelta(11,unit='d') // 2)
+        self.assertRaises(TypeError, lambda: Timedelta(11, unit='d') // 2)
 
         # invalid multiply with another timedelta
-        self.assertRaises(TypeError, lambda : td * td)
+        self.assertRaises(TypeError, lambda: td * td)
 
         # can't operate with integers
-        self.assertRaises(TypeError, lambda : td + 2)
-        self.assertRaises(TypeError, lambda : td - 2)
+        self.assertRaises(TypeError, lambda: td + 2)
+        self.assertRaises(TypeError, lambda: td - 2)
 
     def test_ops_offsets(self):
         td = Timedelta(10, unit='d')
@@ -354,11 +355,11 @@ class TestTimedeltas(tm.TestCase):
     def test_freq_conversion(self):
 
         td = Timedelta('1 days 2 hours 3 ns')
-        result = td / np.timedelta64(1,'D')
-        self.assertEqual(result, td.value/float(86400*1e9))
-        result = td / np.timedelta64(1,'s')
-        self.assertEqual(result, td.value/float(1e9))
-        result = td / np.timedelta64(1,'ns')
+        result = td / np.timedelta64(1, 'D')
+        self.assertEqual(result, td.value / float(86400 * 1e9))
+        result = td / np.timedelta64(1, 's')
+        self.assertEqual(result, td.value / float(1e9))
+        result = td / np.timedelta64(1, 'ns')
         self.assertEqual(result, td.value)
 
     def test_ops_ndarray(self):
@@ -428,6 +429,7 @@ class TestTimedeltas(tm.TestCase):
     def test_ops_notimplemented(self):
         class Other:
             pass
+
         other = Other()
 
         td = Timedelta('1 day')
@@ -438,7 +440,6 @@ class TestTimedeltas(tm.TestCase):
         self.assertTrue(td.__floordiv__(td) is NotImplemented)
 
     def test_fields(self):
-
         def check(value):
             # that we are int/long like
             self.assertTrue(isinstance(value, (int, compat.long)))
@@ -446,13 +447,13 @@ class TestTimedeltas(tm.TestCase):
         # compat to datetime.timedelta
         rng = to_timedelta('1 days, 10:11:12')
         self.assertEqual(rng.days, 1)
-        self.assertEqual(rng.seconds, 10*3600+11*60+12)
+        self.assertEqual(rng.seconds, 10 * 3600 + 11 * 60 + 12)
         self.assertEqual(rng.microseconds, 0)
         self.assertEqual(rng.nanoseconds, 0)
 
-        self.assertRaises(AttributeError, lambda : rng.hours)
-        self.assertRaises(AttributeError, lambda : rng.minutes)
-        self.assertRaises(AttributeError, lambda : rng.milliseconds)
+        self.assertRaises(AttributeError, lambda: rng.hours)
+        self.assertRaises(AttributeError, lambda: rng.minutes)
+        self.assertRaises(AttributeError, lambda: rng.milliseconds)
 
         # GH 10050
         check(rng.days)
@@ -469,12 +470,12 @@ class TestTimedeltas(tm.TestCase):
 
         rng = to_timedelta('-1 days, 10:11:12.100123456')
         self.assertEqual(rng.days, -1)
-        self.assertEqual(rng.seconds, 10*3600+11*60+12)
-        self.assertEqual(rng.microseconds, 100*1000+123)
+        self.assertEqual(rng.seconds, 10 * 3600 + 11 * 60 + 12)
+        self.assertEqual(rng.microseconds, 100 * 1000 + 123)
         self.assertEqual(rng.nanoseconds, 456)
-        self.assertRaises(AttributeError, lambda : rng.hours)
-        self.assertRaises(AttributeError, lambda : rng.minutes)
-        self.assertRaises(AttributeError, lambda : rng.milliseconds)
+        self.assertRaises(AttributeError, lambda: rng.hours)
+        self.assertRaises(AttributeError, lambda: rng.minutes)
+        self.assertRaises(AttributeError, lambda: rng.milliseconds)
 
         # components
         tup = pd.to_timedelta(-1, 'us').components
@@ -515,10 +516,11 @@ class TestTimedeltas(tm.TestCase):
         tm.assert_index_equal(result, expected)
 
         expected = to_timedelta(np.arange(5), unit='D') + Second(2) + Day()
-        result = timedelta_range('1 days, 00:00:02', '5 days, 00:00:02', freq='D')
+        result = timedelta_range('1 days, 00:00:02', '5 days, 00:00:02',
+                                 freq='D')
         tm.assert_index_equal(result, expected)
 
-        expected = to_timedelta([1,3,5,7,9], unit='D') + Second(2)
+        expected = to_timedelta([1, 3, 5, 7, 9], unit='D') + Second(2)
         result = timedelta_range('1 days, 00:00:02', periods=5, freq='2D')
         tm.assert_index_equal(result, expected)
 
@@ -537,69 +539,76 @@ class TestTimedeltas(tm.TestCase):
                     to_timedelta(arg, errors=errors)
 
         # issue10583
-        df = pd.DataFrame(np.random.normal(size=(10,4)))
+        df = pd.DataFrame(np.random.normal(size=(10, 4)))
         df.index = pd.timedelta_range(start='0s', periods=10, freq='s')
-        expected = df.loc[pd.Timedelta('0s'):,:]
-        result = df.loc['0s':,:]
+        expected = df.loc[pd.Timedelta('0s'):, :]
+        result = df.loc['0s':, :]
         assert_frame_equal(expected, result)
 
-
     def test_numeric_conversions(self):
-        self.assertEqual(ct(0), np.timedelta64(0,'ns'))
-        self.assertEqual(ct(10), np.timedelta64(10,'ns'))
-        self.assertEqual(ct(10,unit='ns'), np.timedelta64(10,'ns').astype('m8[ns]'))
-
-        self.assertEqual(ct(10,unit='us'), np.timedelta64(10,'us').astype('m8[ns]'))
-        self.assertEqual(ct(10,unit='ms'), np.timedelta64(10,'ms').astype('m8[ns]'))
-        self.assertEqual(ct(10,unit='s'), np.timedelta64(10,'s').astype('m8[ns]'))
-        self.assertEqual(ct(10,unit='d'), np.timedelta64(10,'D').astype('m8[ns]'))
+        self.assertEqual(ct(0), np.timedelta64(0, 'ns'))
+        self.assertEqual(ct(10), np.timedelta64(10, 'ns'))
+        self.assertEqual(ct(10, unit='ns'), np.timedelta64(
+            10, 'ns').astype('m8[ns]'))
+
+        self.assertEqual(ct(10, unit='us'), np.timedelta64(
+            10, 'us').astype('m8[ns]'))
+        self.assertEqual(ct(10, unit='ms'), np.timedelta64(
+            10, 'ms').astype('m8[ns]'))
+        self.assertEqual(ct(10, unit='s'), np.timedelta64(
+            10, 's').astype('m8[ns]'))
+        self.assertEqual(ct(10, unit='d'), np.timedelta64(
+            10, 'D').astype('m8[ns]'))
 
     def test_timedelta_conversions(self):
-        self.assertEqual(ct(timedelta(seconds=1)), np.timedelta64(1,'s').astype('m8[ns]'))
-        self.assertEqual(ct(timedelta(microseconds=1)), np.timedelta64(1,'us').astype('m8[ns]'))
-        self.assertEqual(ct(timedelta(days=1)), np.timedelta64(1,'D').astype('m8[ns]'))
+        self.assertEqual(ct(timedelta(seconds=1)),
+                         np.timedelta64(1, 's').astype('m8[ns]'))
+        self.assertEqual(ct(timedelta(microseconds=1)),
+                         np.timedelta64(1, 'us').astype('m8[ns]'))
+        self.assertEqual(ct(timedelta(days=1)),
+                         np.timedelta64(1, 'D').astype('m8[ns]'))
 
     def test_short_format_converters(self):
         def conv(v):
             return v.astype('m8[ns]')
 
-        self.assertEqual(ct('10'), np.timedelta64(10,'ns'))
-        self.assertEqual(ct('10ns'), np.timedelta64(10,'ns'))
-        self.assertEqual(ct('100'), np.timedelta64(100,'ns'))
-        self.assertEqual(ct('100ns'), np.timedelta64(100,'ns'))
-
-        self.assertEqual(ct('1000'), np.timedelta64(1000,'ns'))
-        self.assertEqual(ct('1000ns'), np.timedelta64(1000,'ns'))
-        self.assertEqual(ct('1000NS'), np.timedelta64(1000,'ns'))
-
-        self.assertEqual(ct('10us'), np.timedelta64(10000,'ns'))
-        self.assertEqual(ct('100us'), np.timedelta64(100000,'ns'))
-        self.assertEqual(ct('1000us'), np.timedelta64(1000000,'ns'))
-        self.assertEqual(ct('1000Us'), np.timedelta64(1000000,'ns'))
-        self.assertEqual(ct('1000uS'), np.timedelta64(1000000,'ns'))
-
-        self.assertEqual(ct('1ms'), np.timedelta64(1000000,'ns'))
-        self.assertEqual(ct('10ms'), np.timedelta64(10000000,'ns'))
-        self.assertEqual(ct('100ms'), np.timedelta64(100000000,'ns'))
-        self.assertEqual(ct('1000ms'), np.timedelta64(1000000000,'ns'))
-
-        self.assertEqual(ct('-1s'), -np.timedelta64(1000000000,'ns'))
-        self.assertEqual(ct('1s'), np.timedelta64(1000000000,'ns'))
-        self.assertEqual(ct('10s'), np.timedelta64(10000000000,'ns'))
-        self.assertEqual(ct('100s'), np.timedelta64(100000000000,'ns'))
-        self.assertEqual(ct('1000s'), np.timedelta64(1000000000000,'ns'))
-
-        self.assertEqual(ct('1d'), conv(np.timedelta64(1,'D')))
-        self.assertEqual(ct('-1d'), -conv(np.timedelta64(1,'D')))
-        self.assertEqual(ct('1D'), conv(np.timedelta64(1,'D')))
-        self.assertEqual(ct('10D'), conv(np.timedelta64(10,'D')))
-        self.assertEqual(ct('100D'), conv(np.timedelta64(100,'D')))
-        self.assertEqual(ct('1000D'), conv(np.timedelta64(1000,'D')))
-        self.assertEqual(ct('10000D'), conv(np.timedelta64(10000,'D')))
+        self.assertEqual(ct('10'), np.timedelta64(10, 'ns'))
+        self.assertEqual(ct('10ns'), np.timedelta64(10, 'ns'))
+        self.assertEqual(ct('100'), np.timedelta64(100, 'ns'))
+        self.assertEqual(ct('100ns'), np.timedelta64(100, 'ns'))
+
+        self.assertEqual(ct('1000'), np.timedelta64(1000, 'ns'))
+        self.assertEqual(ct('1000ns'), np.timedelta64(1000, 'ns'))
+        self.assertEqual(ct('1000NS'), np.timedelta64(1000, 'ns'))
+
+        self.assertEqual(ct('10us'), np.timedelta64(10000, 'ns'))
+        self.assertEqual(ct('100us'), np.timedelta64(100000, 'ns'))
+        self.assertEqual(ct('1000us'), np.timedelta64(1000000, 'ns'))
+        self.assertEqual(ct('1000Us'), np.timedelta64(1000000, 'ns'))
+        self.assertEqual(ct('1000uS'), np.timedelta64(1000000, 'ns'))
+
+        self.assertEqual(ct('1ms'), np.timedelta64(1000000, 'ns'))
+        self.assertEqual(ct('10ms'), np.timedelta64(10000000, 'ns'))
+        self.assertEqual(ct('100ms'), np.timedelta64(100000000, 'ns'))
+        self.assertEqual(ct('1000ms'), np.timedelta64(1000000000, 'ns'))
+
+        self.assertEqual(ct('-1s'), -np.timedelta64(1000000000, 'ns'))
+        self.assertEqual(ct('1s'), np.timedelta64(1000000000, 'ns'))
+        self.assertEqual(ct('10s'), np.timedelta64(10000000000, 'ns'))
+        self.assertEqual(ct('100s'), np.timedelta64(100000000000, 'ns'))
+        self.assertEqual(ct('1000s'), np.timedelta64(1000000000000, 'ns'))
+
+        self.assertEqual(ct('1d'), conv(np.timedelta64(1, 'D')))
+        self.assertEqual(ct('-1d'), -conv(np.timedelta64(1, 'D')))
+        self.assertEqual(ct('1D'), conv(np.timedelta64(1, 'D')))
+        self.assertEqual(ct('10D'), conv(np.timedelta64(10, 'D')))
+        self.assertEqual(ct('100D'), conv(np.timedelta64(100, 'D')))
+        self.assertEqual(ct('1000D'), conv(np.timedelta64(1000, 'D')))
+        self.assertEqual(ct('10000D'), conv(np.timedelta64(10000, 'D')))
 
         # space
-        self.assertEqual(ct(' 10000D '), conv(np.timedelta64(10000,'D')))
-        self.assertEqual(ct(' - 10000D '), -conv(np.timedelta64(10000,'D')))
+        self.assertEqual(ct(' 10000D '), conv(np.timedelta64(10000, 'D')))
+        self.assertEqual(ct(' - 10000D '), -conv(np.timedelta64(10000, 'D')))
 
         # invalid
         self.assertRaises(ValueError, ct, '1foo')
@@ -608,102 +617,117 @@ class TestTimedeltas(tm.TestCase):
     def test_full_format_converters(self):
         def conv(v):
             return v.astype('m8[ns]')
-        d1 = np.timedelta64(1,'D')
+
+        d1 = np.timedelta64(1, 'D')
 
         self.assertEqual(ct('1days'), conv(d1))
         self.assertEqual(ct('1days,'), conv(d1))
         self.assertEqual(ct('- 1days,'), -conv(d1))
 
-        self.assertEqual(ct('00:00:01'), conv(np.timedelta64(1,'s')))
-        self.assertEqual(ct('06:00:01'), conv(np.timedelta64(6*3600+1,'s')))
-        self.assertEqual(ct('06:00:01.0'), conv(np.timedelta64(6*3600+1,'s')))
-        self.assertEqual(ct('06:00:01.01'), conv(np.timedelta64(1000*(6*3600+1)+10,'ms')))
-
-        self.assertEqual(ct('- 1days, 00:00:01'), conv(-d1+np.timedelta64(1,'s')))
-        self.assertEqual(ct('1days, 06:00:01'), conv(d1+np.timedelta64(6*3600+1,'s')))
-        self.assertEqual(ct('1days, 06:00:01.01'), conv(d1+np.timedelta64(1000*(6*3600+1)+10,'ms')))
+        self.assertEqual(ct('00:00:01'), conv(np.timedelta64(1, 's')))
+        self.assertEqual(ct('06:00:01'), conv(
+            np.timedelta64(6 * 3600 + 1, 's')))
+        self.assertEqual(ct('06:00:01.0'), conv(
+            np.timedelta64(6 * 3600 + 1, 's')))
+        self.assertEqual(ct('06:00:01.01'), conv(
+            np.timedelta64(1000 * (6 * 3600 + 1) + 10, 'ms')))
+
+        self.assertEqual(ct('- 1days, 00:00:01'),
+                         conv(-d1 + np.timedelta64(1, 's')))
+        self.assertEqual(ct('1days, 06:00:01'), conv(
+            d1 + np.timedelta64(6 * 3600 + 1, 's')))
+        self.assertEqual(ct('1days, 06:00:01.01'), conv(
+            d1 + np.timedelta64(1000 * (6 * 3600 + 1) + 10, 'ms')))
 
         # invalid
         self.assertRaises(ValueError, ct, '- 1days, 00')
 
     def test_nat_converters(self):
-        self.assertEqual(to_timedelta('nat',box=False).astype('int64'), tslib.iNaT)
-        self.assertEqual(to_timedelta('nan',box=False).astype('int64'), tslib.iNaT)
+        self.assertEqual(to_timedelta(
+            'nat', box=False).astype('int64'), tslib.iNaT)
+        self.assertEqual(to_timedelta(
+            'nan', box=False).astype('int64'), tslib.iNaT)
 
     def test_to_timedelta(self):
         def conv(v):
             return v.astype('m8[ns]')
-        d1 = np.timedelta64(1,'D')
 
-        self.assertEqual(to_timedelta('1 days 06:05:01.00003',box=False), conv(d1+np.timedelta64(6*3600+5*60+1,'s')+np.timedelta64(30,'us')))
-        self.assertEqual(to_timedelta('15.5us',box=False), conv(np.timedelta64(15500,'ns')))
+        d1 = np.timedelta64(1, 'D')
+
+        self.assertEqual(to_timedelta('1 days 06:05:01.00003', box=False),
+                         conv(d1 + np.timedelta64(6 * 3600 +
+                                                  5 * 60 + 1, 's') +
+                              np.timedelta64(30, 'us')))
+        self.assertEqual(to_timedelta('15.5us', box=False),
+                         conv(np.timedelta64(15500, 'ns')))
 
         # empty string
-        result = to_timedelta('',box=False)
+        result = to_timedelta('', box=False)
         self.assertEqual(result.astype('int64'), tslib.iNaT)
 
         result = to_timedelta(['', ''])
         self.assertTrue(isnull(result).all())
 
         # pass thru
-        result = to_timedelta(np.array([np.timedelta64(1,'s')]))
-        expected = np.array([np.timedelta64(1,'s')])
-        tm.assert_almost_equal(result,expected)
+        result = to_timedelta(np.array([np.timedelta64(1, 's')]))
+        expected = np.array([np.timedelta64(1, 's')])
+        tm.assert_almost_equal(result, expected)
 
         # ints
-        result = np.timedelta64(0,'ns')
-        expected = to_timedelta(0,box=False)
+        result = np.timedelta64(0, 'ns')
+        expected = to_timedelta(0, box=False)
         self.assertEqual(result, expected)
 
         # Series
         expected = Series([timedelta(days=1), timedelta(days=1, seconds=1)])
-        result = to_timedelta(Series(['1d','1days 00:00:01']))
+        result = to_timedelta(Series(['1d', '1days 00:00:01']))
         tm.assert_series_equal(result, expected)
 
         # with units
-        result = TimedeltaIndex([ np.timedelta64(0,'ns'), np.timedelta64(10,'s').astype('m8[ns]') ])
-        expected = to_timedelta([0,10],unit='s')
+        result = TimedeltaIndex([np.timedelta64(0, 'ns'), np.timedelta64(
+            10, 's').astype('m8[ns]')])
+        expected = to_timedelta([0, 10], unit='s')
         tm.assert_index_equal(result, expected)
 
         # single element conversion
         v = timedelta(seconds=1)
-        result = to_timedelta(v,box=False)
+        result = to_timedelta(v, box=False)
         expected = np.timedelta64(timedelta(seconds=1))
         self.assertEqual(result, expected)
 
         v = np.timedelta64(timedelta(seconds=1))
-        result = to_timedelta(v,box=False)
+        result = to_timedelta(v, box=False)
         expected = np.timedelta64(timedelta(seconds=1))
         self.assertEqual(result, expected)
 
         # arrays of various dtypes
-        arr = np.array([1]*5,dtype='int64')
-        result = to_timedelta(arr,unit='s')
-        expected = TimedeltaIndex([ np.timedelta64(1,'s') ]*5)
+        arr = np.array([1] * 5, dtype='int64')
+        result = to_timedelta(arr, unit='s')
+        expected = TimedeltaIndex([np.timedelta64(1, 's')] * 5)
         tm.assert_index_equal(result, expected)
 
-        arr = np.array([1]*5,dtype='int64')
-        result = to_timedelta(arr,unit='m')
-        expected = TimedeltaIndex([ np.timedelta64(1,'m') ]*5)
+        arr = np.array([1] * 5, dtype='int64')
+        result = to_timedelta(arr, unit='m')
+        expected = TimedeltaIndex([np.timedelta64(1, 'm')] * 5)
         tm.assert_index_equal(result, expected)
 
-        arr = np.array([1]*5,dtype='int64')
-        result = to_timedelta(arr,unit='h')
-        expected = TimedeltaIndex([ np.timedelta64(1,'h') ]*5)
+        arr = np.array([1] * 5, dtype='int64')
+        result = to_timedelta(arr, unit='h')
+        expected = TimedeltaIndex([np.timedelta64(1, 'h')] * 5)
         tm.assert_index_equal(result, expected)
 
-        arr = np.array([1]*5,dtype='timedelta64[s]')
+        arr = np.array([1] * 5, dtype='timedelta64[s]')
         result = to_timedelta(arr)
-        expected = TimedeltaIndex([ np.timedelta64(1,'s') ]*5)
+        expected = TimedeltaIndex([np.timedelta64(1, 's')] * 5)
         tm.assert_index_equal(result, expected)
 
-        arr = np.array([1]*5,dtype='timedelta64[D]')
+        arr = np.array([1] * 5, dtype='timedelta64[D]')
         result = to_timedelta(arr)
-        expected = TimedeltaIndex([ np.timedelta64(1,'D') ]*5)
+        expected = TimedeltaIndex([np.timedelta64(1, 'D')] * 5)
         tm.assert_index_equal(result, expected)
 
         # Test with lists as input when box=false
-        expected = np.array(np.arange(3)*1000000000, dtype='timedelta64[ns]')
+        expected = np.array(np.arange(3) * 1000000000, dtype='timedelta64[ns]')
         result = to_timedelta(range(3), unit='s', box=False)
         tm.assert_numpy_array_equal(expected, result)
 
@@ -714,59 +738,65 @@ class TestTimedeltas(tm.TestCase):
         tm.assert_numpy_array_equal(expected, result)
 
         # Tests with fractional seconds as input:
-        expected = np.array([0, 500000000, 800000000, 1200000000], dtype='timedelta64[ns]')
+        expected = np.array(
+            [0, 500000000, 800000000, 1200000000], dtype='timedelta64[ns]')
         result = to_timedelta([0., 0.5, 0.8, 1.2], unit='s', box=False)
         tm.assert_numpy_array_equal(expected, result)
 
         def testit(unit, transform):
 
             # array
-            result = to_timedelta(np.arange(5),unit=unit)
-            expected = TimedeltaIndex([ np.timedelta64(i,transform(unit)) for i in np.arange(5).tolist() ])
+            result = to_timedelta(np.arange(5), unit=unit)
+            expected = TimedeltaIndex([np.timedelta64(i, transform(unit))
+                                       for i in np.arange(5).tolist()])
             tm.assert_index_equal(result, expected)
 
             # scalar
-            result = to_timedelta(2,unit=unit)
-            expected = Timedelta(np.timedelta64(2,transform(unit)).astype('timedelta64[ns]'))
+            result = to_timedelta(2, unit=unit)
+            expected = Timedelta(np.timedelta64(2, transform(unit)).astype(
+                'timedelta64[ns]'))
             self.assertEqual(result, expected)
 
         # validate all units
         # GH 6855
-        for unit in ['Y','M','W','D','y','w','d']:
-            testit(unit,lambda x: x.upper())
-        for unit in ['days','day','Day','Days']:
-            testit(unit,lambda x: 'D')
-        for unit in ['h','m','s','ms','us','ns','H','S','MS','US','NS']:
-            testit(unit,lambda x: x.lower())
+        for unit in ['Y', 'M', 'W', 'D', 'y', 'w', 'd']:
+            testit(unit, lambda x: x.upper())
+        for unit in ['days', 'day', 'Day', 'Days']:
+            testit(unit, lambda x: 'D')
+        for unit in ['h', 'm', 's', 'ms', 'us', 'ns', 'H', 'S', 'MS', 'US',
+                     'NS']:
+            testit(unit, lambda x: x.lower())
 
         # offsets
 
         # m
-        testit('T',lambda x: 'm')
+        testit('T', lambda x: 'm')
 
         # ms
-        testit('L',lambda x: 'ms')
+        testit('L', lambda x: 'ms')
 
     def test_to_timedelta_invalid(self):
 
         # these will error
-        self.assertRaises(ValueError, lambda : to_timedelta([1,2],unit='foo'))
-        self.assertRaises(ValueError, lambda : to_timedelta(1,unit='foo'))
+        self.assertRaises(ValueError, lambda: to_timedelta([1, 2], unit='foo'))
+        self.assertRaises(ValueError, lambda: to_timedelta(1, unit='foo'))
 
         # time not supported ATM
-        self.assertRaises(ValueError, lambda :to_timedelta(time(second=1)))
-        self.assertTrue(to_timedelta(time(second=1), errors='coerce') is pd.NaT)
+        self.assertRaises(ValueError, lambda: to_timedelta(time(second=1)))
+        self.assertTrue(to_timedelta(
+            time(second=1), errors='coerce') is pd.NaT)
 
-        self.assertRaises(ValueError, lambda : to_timedelta(['foo','bar']))
-        tm.assert_index_equal(TimedeltaIndex([pd.NaT,pd.NaT]),
-                              to_timedelta(['foo','bar'], errors='coerce'))
+        self.assertRaises(ValueError, lambda: to_timedelta(['foo', 'bar']))
+        tm.assert_index_equal(TimedeltaIndex([pd.NaT, pd.NaT]),
+                              to_timedelta(['foo', 'bar'], errors='coerce'))
 
         tm.assert_index_equal(TimedeltaIndex(['1 day', pd.NaT, '1 min']),
-                              to_timedelta(['1 day','bar','1 min'], errors='coerce'))
+                              to_timedelta(['1 day', 'bar', '1 min'],
+                                           errors='coerce'))
 
     def test_to_timedelta_via_apply(self):
         # GH 5458
-        expected = Series([np.timedelta64(1,'s')])
+        expected = Series([np.timedelta64(1, 's')])
         result = Series(['00:00:01']).apply(to_timedelta)
         tm.assert_series_equal(result, expected)
 
@@ -776,7 +806,8 @@ class TestTimedeltas(tm.TestCase):
     def test_timedelta_ops(self):
         # GH4984
         # make sure ops return Timedelta
-        s = Series([Timestamp('20130101') + timedelta(seconds=i*i) for i in range(10) ])
+        s = Series([Timestamp('20130101') + timedelta(seconds=i * i)
+                    for i in range(10)])
         td = s.diff()
 
         result = td.mean()
@@ -787,7 +818,7 @@ class TestTimedeltas(tm.TestCase):
         self.assertEqual(result[0], expected)
 
         result = td.quantile(.1)
-        expected = Timedelta(np.timedelta64(2600,'ms'))
+        expected = Timedelta(np.timedelta64(2600, 'ms'))
         self.assertEqual(result, expected)
 
         result = td.median()
@@ -815,35 +846,39 @@ class TestTimedeltas(tm.TestCase):
         self.assertEqual(result[0], expected)
 
         # invalid ops
-        for op in ['skew','kurt','sem','prod']:
-            self.assertRaises(TypeError, getattr(td,op))
+        for op in ['skew', 'kurt', 'sem', 'prod']:
+            self.assertRaises(TypeError, getattr(td, op))
 
         # GH 10040
         # make sure NaT is properly handled by median()
         s = Series([Timestamp('2015-02-03'), Timestamp('2015-02-07')])
         self.assertEqual(s.diff().median(), timedelta(days=4))
 
-        s = Series([Timestamp('2015-02-03'), Timestamp('2015-02-07'), Timestamp('2015-02-15')])
+        s = Series([Timestamp('2015-02-03'), Timestamp('2015-02-07'),
+                    Timestamp('2015-02-15')])
         self.assertEqual(s.diff().median(), timedelta(days=6))
 
     def test_overflow(self):
         # GH 9442
-        s = Series(pd.date_range('20130101',periods=100000,freq='H'))
+        s = Series(pd.date_range('20130101', periods=100000, freq='H'))
         s[0] += pd.Timedelta('1s 1ms')
 
         # mean
-        result = (s-s.min()).mean()
-        expected = pd.Timedelta((pd.DatetimeIndex((s-s.min())).asi8/len(s)).sum())
+        result = (s - s.min()).mean()
+        expected = pd.Timedelta((pd.DatetimeIndex((s - s.min())).asi8 / len(s)
+                                 ).sum())
 
-        # the computation is converted to float so might be some loss of precision
-        self.assertTrue(np.allclose(result.value/1000, expected.value/1000))
+        # the computation is converted to float so might be some loss of
+        # precision
+        self.assertTrue(np.allclose(result.value / 1000, expected.value /
+                                    1000))
 
         # sum
-        self.assertRaises(ValueError, lambda : (s-s.min()).sum())
+        self.assertRaises(ValueError, lambda: (s - s.min()).sum())
         s1 = s[0:10000]
-        self.assertRaises(ValueError, lambda : (s1-s1.min()).sum())
+        self.assertRaises(ValueError, lambda: (s1 - s1.min()).sum())
         s2 = s[0:1000]
-        result = (s2-s2.min()).sum()
+        result = (s2 - s2.min()).sum()
 
     def test_timedelta_ops_scalar(self):
         # GH 6808
@@ -851,10 +886,9 @@ class TestTimedeltas(tm.TestCase):
         expected_add = pd.to_datetime('20130101 09:01:22.123456')
         expected_sub = pd.to_datetime('20130101 09:01:02.123456')
 
-        for offset in [pd.to_timedelta(10,unit='s'),
-                       timedelta(seconds=10),
-                       np.timedelta64(10,'s'),
-                       np.timedelta64(10000000000,'ns'),
+        for offset in [pd.to_timedelta(10, unit='s'), timedelta(seconds=10),
+                       np.timedelta64(10, 's'),
+                       np.timedelta64(10000000000, 'ns'),
                        pd.offsets.Second(10)]:
             result = base + offset
             self.assertEqual(result, expected_add)
@@ -868,9 +902,9 @@ class TestTimedeltas(tm.TestCase):
 
         for offset in [pd.to_timedelta('1 day, 00:00:10'),
                        pd.to_timedelta('1 days, 00:00:10'),
-                       timedelta(days=1,seconds=10),
-                       np.timedelta64(1,'D')+np.timedelta64(10,'s'),
-                       pd.offsets.Day()+pd.offsets.Second(10)]:
+                       timedelta(days=1, seconds=10),
+                       np.timedelta64(1, 'D') + np.timedelta64(10, 's'),
+                       pd.offsets.Day() + pd.offsets.Second(10)]:
             result = base + offset
             self.assertEqual(result, expected_add)
 
@@ -882,7 +916,8 @@ class TestTimedeltas(tm.TestCase):
         timedelta_NaT = np.timedelta64('NaT')
 
         actual = pd.to_timedelta(Series(['00:00:01', np.nan]))
-        expected = Series([np.timedelta64(1000000000, 'ns'), timedelta_NaT], dtype='<m8[ns]')
+        expected = Series([np.timedelta64(1000000000, 'ns'),
+                           timedelta_NaT], dtype='<m8[ns]')
         assert_series_equal(actual, expected)
 
         actual = pd.to_timedelta(Series(['00:00:01', pd.NaT]))
@@ -900,7 +935,8 @@ class TestTimedeltas(tm.TestCase):
         expected = Timedelta('100ns')
         self.assertEqual(result, expected)
 
-        result = Timedelta(days=1,hours=1,minutes=1,weeks=1,seconds=1,milliseconds=1,microseconds=1,nanoseconds=1)
+        result = Timedelta(days=1, hours=1, minutes=1, weeks=1, seconds=1,
+                           milliseconds=1, microseconds=1, nanoseconds=1)
         expected = Timedelta(694861001001001)
         self.assertEqual(result, expected)
 
@@ -912,7 +948,7 @@ class TestTimedeltas(tm.TestCase):
         expected = Timedelta('999ns')
         self.assertEqual(result, expected)
 
-        result = Timedelta(microseconds=1) + 5*Timedelta(nanoseconds=-2)
+        result = Timedelta(microseconds=1) + 5 * Timedelta(nanoseconds=-2)
         expected = Timedelta('990ns')
         self.assertEqual(result, expected)
 
@@ -1017,8 +1053,10 @@ class TestTimedeltas(tm.TestCase):
         # assert_series_equal(a, b)
 
         list_of_strings = ['00:00:01', np.nan, pd.NaT, timedelta_NaT]
-        a = pd.to_timedelta(list_of_strings)
-        b = Series(list_of_strings).apply(pd.to_timedelta)
+
+        # TODO: unused?
+        a = pd.to_timedelta(list_of_strings)  # noqa
+        b = Series(list_of_strings).apply(pd.to_timedelta)  # noqa
         # Can't compare until apply on a Series gives the correct dtype
         # assert_series_equal(a, b)
 
@@ -1026,10 +1064,10 @@ class TestTimedeltas(tm.TestCase):
 
         v = Timedelta('1 days 10:11:12.0123456')
         v_p = self.round_trip_pickle(v)
-        self.assertEqual(v,v_p)
+        self.assertEqual(v, v_p)
 
     def test_timedelta_hash_equality(self):
-        #GH 11129
+        # GH 11129
         v = Timedelta(1, 'D')
         td = timedelta(days=1)
         self.assertEqual(hash(v), hash(td))
@@ -1038,8 +1076,8 @@ class TestTimedeltas(tm.TestCase):
         self.assertEqual(d[v], 2)
 
         tds = timedelta_range('1 second', periods=20)
-        self.assertTrue(
-            all(hash(td) == hash(td.to_pytimedelta()) for td in tds))
+        self.assertTrue(all(hash(td) == hash(td.to_pytimedelta()) for td in
+                            tds))
 
         # python timedeltas drop ns resolution
         ns_td = Timedelta(1, 'ns')
@@ -1051,7 +1089,7 @@ class TestTimedeltaIndex(tm.TestCase):
 
     def test_pass_TimedeltaIndex_to_index(self):
 
-        rng = timedelta_range('1 days','10 days')
+        rng = timedelta_range('1 days', '10 days')
         idx = Index(rng, dtype=object)
 
         expected = Index(rng.to_pytimedelta(), dtype=object)
@@ -1062,12 +1100,11 @@ class TestTimedeltaIndex(tm.TestCase):
 
         rng = timedelta_range('1 days', periods=10)
         rng_p = self.round_trip_pickle(rng)
-        tm.assert_index_equal(rng,rng_p)
+        tm.assert_index_equal(rng, rng_p)
 
     def test_hash_error(self):
         index = timedelta_range('1 days', periods=10)
-        with tm.assertRaisesRegexp(TypeError,
-                                   "unhashable type: %r" %
+        with tm.assertRaisesRegexp(TypeError, "unhashable type: %r" %
                                    type(index).__name__):
             hash(index)
 
@@ -1083,7 +1120,7 @@ class TestTimedeltaIndex(tm.TestCase):
 
     def test_append_numpy_bug_1681(self):
 
-        td = timedelta_range('1 days','10 days',freq='2D')
+        td = timedelta_range('1 days', '10 days', freq='2D')
         a = DataFrame()
         c = DataFrame({'A': 'foo', 'B': td}, index=td)
         str(c)
@@ -1098,48 +1135,60 @@ class TestTimedeltaIndex(tm.TestCase):
         self.assert_numpy_array_equal(result, rng.asi8)
 
     def test_fields(self):
-        rng = timedelta_range('1 days, 10:11:12.100123456', periods=2, freq='s')
-        self.assert_numpy_array_equal(rng.days, np.array([1,1],dtype='int64'))
-        self.assert_numpy_array_equal(rng.seconds, np.array([10*3600+11*60+12,10*3600+11*60+13],dtype='int64'))
-        self.assert_numpy_array_equal(rng.microseconds, np.array([100*1000+123,100*1000+123],dtype='int64'))
-        self.assert_numpy_array_equal(rng.nanoseconds, np.array([456,456],dtype='int64'))
-
-        self.assertRaises(AttributeError, lambda : rng.hours)
-        self.assertRaises(AttributeError, lambda : rng.minutes)
-        self.assertRaises(AttributeError, lambda : rng.milliseconds)
+        rng = timedelta_range('1 days, 10:11:12.100123456', periods=2,
+                              freq='s')
+        self.assert_numpy_array_equal(rng.days, np.array(
+            [1, 1], dtype='int64'))
+        self.assert_numpy_array_equal(
+            rng.seconds,
+            np.array([10 * 3600 + 11 * 60 + 12, 10 * 3600 + 11 * 60 + 13],
+                     dtype='int64'))
+        self.assert_numpy_array_equal(rng.microseconds, np.array(
+            [100 * 1000 + 123, 100 * 1000 + 123], dtype='int64'))
+        self.assert_numpy_array_equal(rng.nanoseconds, np.array(
+            [456, 456], dtype='int64'))
+
+        self.assertRaises(AttributeError, lambda: rng.hours)
+        self.assertRaises(AttributeError, lambda: rng.minutes)
+        self.assertRaises(AttributeError, lambda: rng.milliseconds)
 
         # with nat
         s = Series(rng)
         s[1] = np.nan
 
-        tm.assert_series_equal(s.dt.days,Series([1,np.nan],index=[0,1]))
-        tm.assert_series_equal(s.dt.seconds,Series([10*3600+11*60+12,np.nan],index=[0,1]))
+        tm.assert_series_equal(s.dt.days, Series([1, np.nan], index=[0, 1]))
+        tm.assert_series_equal(s.dt.seconds, Series(
+            [10 * 3600 + 11 * 60 + 12, np.nan], index=[0, 1]))
 
     def test_total_seconds(self):
         # GH 10939
         # test index
-        rng = timedelta_range('1 days, 10:11:12.100123456', periods=2, freq='s')
-        expt = [1*86400+10*3600+11*60+12+100123456./1e9,1*86400+10*3600+11*60+13+100123456./1e9]
+        rng = timedelta_range('1 days, 10:11:12.100123456', periods=2,
+                              freq='s')
+        expt = [1 * 86400 + 10 * 3600 + 11 * 60 + 12 + 100123456. / 1e9,
+                1 * 86400 + 10 * 3600 + 11 * 60 + 13 + 100123456. / 1e9]
         assert_allclose(rng.total_seconds(), expt, atol=1e-10, rtol=0)
 
         # test Series
         s = Series(rng)
-        s_expt = Series(expt,index=[0,1])
-        tm.assert_series_equal(s.dt.total_seconds(),s_expt)
+        s_expt = Series(expt, index=[0, 1])
+        tm.assert_series_equal(s.dt.total_seconds(), s_expt)
 
         # with nat
         s[1] = np.nan
-        s_expt = Series([1*86400+10*3600+11*60+12+100123456./1e9,np.nan],index=[0,1])
-        tm.assert_series_equal(s.dt.total_seconds(),s_expt)
+        s_expt = Series([1 * 86400 + 10 * 3600 + 11 * 60 +
+                         12 + 100123456. / 1e9, np.nan], index=[0, 1])
+        tm.assert_series_equal(s.dt.total_seconds(), s_expt)
 
         # with both nat
-        s = Series([np.nan,np.nan], dtype='timedelta64[ns]')
-        tm.assert_series_equal(s.dt.total_seconds(),Series([np.nan,np.nan],index=[0,1]))
+        s = Series([np.nan, np.nan], dtype='timedelta64[ns]')
+        tm.assert_series_equal(s.dt.total_seconds(), Series(
+            [np.nan, np.nan], index=[0, 1]))
 
     def test_total_seconds_scalar(self):
         # GH 10939
         rng = Timedelta('1 days, 10:11:12.100123456')
-        expt = 1*86400+10*3600+11*60+12+100123456./1e9
+        expt = 1 * 86400 + 10 * 3600 + 11 * 60 + 12 + 100123456. / 1e9
         assert_allclose(rng.total_seconds(), expt, atol=1e-10, rtol=0)
 
         rng = Timedelta(np.nan)
@@ -1158,20 +1207,15 @@ class TestTimedeltaIndex(tm.TestCase):
         self.assertTrue(result.iloc[1].isnull().all())
 
     def test_constructor(self):
-        expected = TimedeltaIndex(['1 days', '1 days 00:00:05',
-                                   '2 days', '2 days 00:00:02',
-                                   '0 days 00:00:03'])
-        result = TimedeltaIndex(['1 days', '1 days, 00:00:05',
-                                 np.timedelta64(2, 'D'),
-                                 timedelta(days=2, seconds=2),
-                                 pd.offsets.Second(3)])
+        expected = TimedeltaIndex(['1 days', '1 days 00:00:05', '2 days',
+                                   '2 days 00:00:02', '0 days 00:00:03'])
+        result = TimedeltaIndex(['1 days', '1 days, 00:00:05', np.timedelta64(
+            2, 'D'), timedelta(days=2, seconds=2), pd.offsets.Second(3)])
         tm.assert_index_equal(result, expected)
 
         # unicode
-        result = TimedeltaIndex([u'1 days', '1 days, 00:00:05',
-                                 np.timedelta64(2, 'D'),
-                                 timedelta(days=2, seconds=2),
-                                 pd.offsets.Second(3)])
+        result = TimedeltaIndex([u'1 days', '1 days, 00:00:05', np.timedelta64(
+            2, 'D'), timedelta(days=2, seconds=2), pd.offsets.Second(3)])
 
         expected = TimedeltaIndex(['0 days 00:00:00', '0 days 00:00:01',
                                    '0 days 00:00:02'])
@@ -1179,9 +1223,9 @@ class TestTimedeltaIndex(tm.TestCase):
         expected = TimedeltaIndex(['0 days 00:00:00', '0 days 00:00:05',
                                    '0 days 00:00:09'])
         tm.assert_index_equal(TimedeltaIndex([0, 5, 9], unit='s'), expected)
-        expected = TimedeltaIndex(['0 days 00:00:00.400',
-                                   '0 days 00:00:00.450',
-                                   '0 days 00:00:01.200'])
+        expected = TimedeltaIndex(
+            ['0 days 00:00:00.400', '0 days 00:00:00.450',
+             '0 days 00:00:01.200'])
         tm.assert_index_equal(TimedeltaIndex([400, 450, 1200], unit='ms'),
                               expected)
 
@@ -1207,7 +1251,7 @@ class TestTimedeltaIndex(tm.TestCase):
         # NumPy string array
         strings = np.array(['1 days', '2 days', '3 days'])
         result = TimedeltaIndex(strings)
-        expected = to_timedelta([1,2,3],unit='d')
+        expected = to_timedelta([1, 2, 3], unit='d')
         self.assertTrue(result.equals(expected))
 
         from_ints = TimedeltaIndex(expected.asi8)
@@ -1215,14 +1259,12 @@ class TestTimedeltaIndex(tm.TestCase):
 
         # non-conforming freq
         self.assertRaises(ValueError, TimedeltaIndex,
-                          ['1 days', '2 days', '4 days'],
-                          freq='D')
+                          ['1 days', '2 days', '4 days'], freq='D')
 
         self.assertRaises(ValueError, TimedeltaIndex, periods=10, freq='D')
 
     def test_constructor_name(self):
-        idx = TimedeltaIndex(start='1 days', periods=1, freq='D',
-                            name='TEST')
+        idx = TimedeltaIndex(start='1 days', periods=1, freq='D', name='TEST')
         self.assertEqual(idx.name, 'TEST')
 
         # GH10025
@@ -1234,49 +1276,52 @@ class TestTimedeltaIndex(tm.TestCase):
         # doc example
 
         # series
-        td = Series(date_range('20130101',periods=4)) - \
-             Series(date_range('20121201',periods=4))
-        td[2] += timedelta(minutes=5,seconds=3)
+        td = Series(date_range('20130101', periods=4)) - \
+            Series(date_range('20121201', periods=4))
+        td[2] += timedelta(minutes=5, seconds=3)
         td[3] = np.nan
 
-        result = td / np.timedelta64(1,'D')
-        expected = Series([31,31,(31*86400+5*60+3)/86400.0,np.nan])
-        assert_series_equal(result,expected)
+        result = td / np.timedelta64(1, 'D')
+        expected = Series([31, 31, (31 * 86400 + 5 * 60 + 3) / 86400.0, np.nan
+                           ])
+        assert_series_equal(result, expected)
 
         result = td.astype('timedelta64[D]')
-        expected = Series([31,31,31,np.nan])
-        assert_series_equal(result,expected)
+        expected = Series([31, 31, 31, np.nan])
+        assert_series_equal(result, expected)
 
-        result = td / np.timedelta64(1,'s')
-        expected = Series([31*86400,31*86400,31*86400+5*60+3,np.nan])
-        assert_series_equal(result,expected)
+        result = td / np.timedelta64(1, 's')
+        expected = Series([31 * 86400, 31 * 86400, 31 * 86400 + 5 * 60 + 3,
+                           np.nan])
+        assert_series_equal(result, expected)
 
         result = td.astype('timedelta64[s]')
-        assert_series_equal(result,expected)
+        assert_series_equal(result, expected)
 
         # tdi
         td = TimedeltaIndex(td)
 
-        result = td / np.timedelta64(1,'D')
-        expected = Index([31,31,(31*86400+5*60+3)/86400.0,np.nan])
-        assert_index_equal(result,expected)
+        result = td / np.timedelta64(1, 'D')
+        expected = Index([31, 31, (31 * 86400 + 5 * 60 + 3) / 86400.0, np.nan])
+        assert_index_equal(result, expected)
 
         result = td.astype('timedelta64[D]')
-        expected = Index([31,31,31,np.nan])
-        assert_index_equal(result,expected)
+        expected = Index([31, 31, 31, np.nan])
+        assert_index_equal(result, expected)
 
-        result = td / np.timedelta64(1,'s')
-        expected = Index([31*86400,31*86400,31*86400+5*60+3,np.nan])
-        assert_index_equal(result,expected)
+        result = td / np.timedelta64(1, 's')
+        expected = Index([31 * 86400, 31 * 86400, 31 * 86400 + 5 * 60 + 3,
+                          np.nan])
+        assert_index_equal(result, expected)
 
         result = td.astype('timedelta64[s]')
-        assert_index_equal(result,expected)
+        assert_index_equal(result, expected)
 
     def test_comparisons_coverage(self):
         rng = timedelta_range('1 days', periods=10)
 
         result = rng < rng[3]
-        exp = np.array([True, True, True]+[False]*7)
+        exp = np.array([True, True, True] + [False] * 7)
         self.assert_numpy_array_equal(result, exp)
 
         # raise TypeError for now
@@ -1292,11 +1337,11 @@ class TestTimedeltaIndex(tm.TestCase):
                                     '1 day 00:00:01', '5 day 00:00:03'])
         tdidx2 = pd.TimedeltaIndex(['2 day', '2 day', pd.NaT, pd.NaT,
                                     '1 day 00:00:02', '5 days 00:00:03'])
-        tdarr = np.array([np.timedelta64(2,'D'),
-                          np.timedelta64(2,'D'),
-                          np.timedelta64('nat'), np.timedelta64('nat'),
-                          np.timedelta64(1,'D') + np.timedelta64(2,'s'),
-                          np.timedelta64(5,'D') + np.timedelta64(3,'s')])
+        tdarr = np.array([np.timedelta64(2, 'D'),
+                          np.timedelta64(2, 'D'), np.timedelta64('nat'),
+                          np.timedelta64('nat'),
+                          np.timedelta64(1, 'D') + np.timedelta64(2, 's'),
+                          np.timedelta64(5, 'D') + np.timedelta64(3, 's')])
 
         if _np_version_under1p8:
             # cannot test array because np.datetime('nat') returns today's date
@@ -1346,7 +1391,7 @@ class TestTimedeltaIndex(tm.TestCase):
         result = rng.groupby(rng.days)
         tm.assertIsInstance(list(result.values())[0][0], Timedelta)
 
-        idx = TimedeltaIndex(['3d','1d','2d'])
+        idx = TimedeltaIndex(['3d', '1d', '2d'])
         self.assertTrue(idx.equals(list(idx)))
 
         non_td = Index(list('abc'))
@@ -1354,10 +1399,10 @@ class TestTimedeltaIndex(tm.TestCase):
 
     def test_union(self):
 
-        i1 = timedelta_range('1day',periods=5)
-        i2 = timedelta_range('3day',periods=5)
+        i1 = timedelta_range('1day', periods=5)
+        i2 = timedelta_range('3day', periods=5)
         result = i1.union(i2)
-        expected = timedelta_range('1day',periods=7)
+        expected = timedelta_range('1day', periods=7)
         self.assert_numpy_array_equal(result, expected)
 
         i1 = Int64Index(np.arange(0, 20, 2))
@@ -1367,7 +1412,7 @@ class TestTimedeltaIndex(tm.TestCase):
 
     def test_union_coverage(self):
 
-        idx = TimedeltaIndex(['3d','1d','2d'])
+        idx = TimedeltaIndex(['3d', '1d', '2d'])
         ordered = TimedeltaIndex(idx.sort_values(), freq='infer')
         result = ordered.union(idx)
         self.assertTrue(result.equals(ordered))
@@ -1388,9 +1433,9 @@ class TestTimedeltaIndex(tm.TestCase):
     def test_union_bug_1745(self):
 
         left = TimedeltaIndex(['1 day 15:19:49.695000'])
-        right = TimedeltaIndex(['2 day 13:04:21.322000',
-                               '1 day 15:27:24.873000',
-                               '1 day 15:31:05.350000'])
+        right = TimedeltaIndex(
+            ['2 day 13:04:21.322000', '1 day 15:27:24.873000',
+             '1 day 15:31:05.350000'])
 
         result = left.union(right)
         exp = TimedeltaIndex(sorted(set(list(left)) | set(list(right))))
@@ -1398,7 +1443,7 @@ class TestTimedeltaIndex(tm.TestCase):
 
     def test_union_bug_4564(self):
 
-        left = timedelta_range("1 day","30d")
+        left = timedelta_range("1 day", "30d")
         right = left + pd.offsets.Minute(15)
 
         result = left.union(right)
@@ -1416,24 +1461,26 @@ class TestTimedeltaIndex(tm.TestCase):
         index_2 = index_1 + pd.offsets.Hour(1)
 
         result = index_1 & index_2
-        expected = timedelta_range('1 day 01:00:00',periods=3,freq='h')
-        tm.assert_index_equal(result,expected)
+        expected = timedelta_range('1 day 01:00:00', periods=3, freq='h')
+        tm.assert_index_equal(result, expected)
 
     def test_get_duplicates(self):
-        idx = TimedeltaIndex(['1 day','2 day','2 day','3 day','3day', '4day'])
+        idx = TimedeltaIndex(['1 day', '2 day', '2 day', '3 day', '3day',
+                              '4day'])
 
         result = idx.get_duplicates()
-        ex = TimedeltaIndex(['2 day','3day'])
+        ex = TimedeltaIndex(['2 day', '3day'])
         self.assertTrue(result.equals(ex))
 
     def test_argmin_argmax(self):
-        idx = TimedeltaIndex(['1 day 00:00:05','1 day 00:00:01','1 day 00:00:02'])
+        idx = TimedeltaIndex(['1 day 00:00:05', '1 day 00:00:01',
+                              '1 day 00:00:02'])
         self.assertEqual(idx.argmin(), 1)
         self.assertEqual(idx.argmax(), 0)
 
     def test_sort_values(self):
 
-        idx = TimedeltaIndex(['4d','1d','2d'])
+        idx = TimedeltaIndex(['4d', '1d', '2d'])
 
         ordered = idx.sort_values()
         self.assertTrue(ordered.is_monotonic)
@@ -1451,10 +1498,10 @@ class TestTimedeltaIndex(tm.TestCase):
 
     def test_insert(self):
 
-        idx = TimedeltaIndex(['4day','1day','2day'], name='idx')
+        idx = TimedeltaIndex(['4day', '1day', '2day'], name='idx')
 
         result = idx.insert(2, timedelta(days=5))
-        exp = TimedeltaIndex(['4day','1day','5day','2day'],name='idx')
+        exp = TimedeltaIndex(['4day', '1day', '5day', '2day'], name='idx')
         self.assertTrue(result.equals(exp))
 
         # insertion of non-datetime should coerce to object index
@@ -1468,15 +1515,19 @@ class TestTimedeltaIndex(tm.TestCase):
         idx = timedelta_range('1day 00:00:01', periods=3, freq='s', name='idx')
 
         # preserve freq
-        expected_0 = TimedeltaIndex(['1day','1day 00:00:01','1day 00:00:02','1day 00:00:03'],
+        expected_0 = TimedeltaIndex(['1day', '1day 00:00:01', '1day 00:00:02',
+                                     '1day 00:00:03'],
                                     name='idx', freq='s')
-        expected_3 = TimedeltaIndex(['1day 00:00:01','1day 00:00:02','1day 00:00:03','1day 00:00:04'],
+        expected_3 = TimedeltaIndex(['1day 00:00:01', '1day 00:00:02',
+                                     '1day 00:00:03', '1day 00:00:04'],
                                     name='idx', freq='s')
 
         # reset freq to None
-        expected_1_nofreq = TimedeltaIndex(['1day 00:00:01','1day 00:00:01','1day 00:00:02','1day 00:00:03'],
+        expected_1_nofreq = TimedeltaIndex(['1day 00:00:01', '1day 00:00:01',
+                                            '1day 00:00:02', '1day 00:00:03'],
                                            name='idx', freq=None)
-        expected_3_nofreq = TimedeltaIndex(['1day 00:00:01','1day 00:00:02','1day 00:00:03','1day 00:00:05'],
+        expected_3_nofreq = TimedeltaIndex(['1day 00:00:01', '1day 00:00:02',
+                                            '1day 00:00:03', '1day 00:00:05'],
                                            name='idx', freq=None)
 
         cases = [(0, Timedelta('1day'), expected_0),
@@ -1495,15 +1546,20 @@ class TestTimedeltaIndex(tm.TestCase):
         idx = timedelta_range(start='1 Days', periods=5, freq='D', name='idx')
 
         # prserve freq
-        expected_0 = timedelta_range(start='2 Days', periods=4, freq='D', name='idx')
-        expected_4 = timedelta_range(start='1 Days', periods=4, freq='D', name='idx')
+        expected_0 = timedelta_range(start='2 Days', periods=4, freq='D',
+                                     name='idx')
+        expected_4 = timedelta_range(start='1 Days', periods=4, freq='D',
+                                     name='idx')
 
         # reset freq to None
-        expected_1 = TimedeltaIndex(['1 day','3 day','4 day', '5 day'],freq=None,name='idx')
-
-        cases ={0: expected_0, -5: expected_0,
-                -1: expected_4, 4: expected_4,
-                1: expected_1}
+        expected_1 = TimedeltaIndex(
+            ['1 day', '3 day', '4 day', '5 day'], freq=None, name='idx')
+
+        cases = {0: expected_0,
+                 -5: expected_0,
+                 -1: expected_4,
+                 4: expected_4,
+                 1: expected_1}
         for n, expected in compat.iteritems(cases):
             result = idx.delete(n)
             self.assertTrue(result.equals(expected))
@@ -1518,16 +1574,19 @@ class TestTimedeltaIndex(tm.TestCase):
         idx = timedelta_range(start='1 days', periods=10, freq='D', name='idx')
 
         # prserve freq
-        expected_0_2 = timedelta_range(start='4 days', periods=7, freq='D', name='idx')
-        expected_7_9 = timedelta_range(start='1 days', periods=7, freq='D', name='idx')
+        expected_0_2 = timedelta_range(start='4 days', periods=7, freq='D',
+                                       name='idx')
+        expected_7_9 = timedelta_range(start='1 days', periods=7, freq='D',
+                                       name='idx')
 
         # reset freq to None
-        expected_3_5 = TimedeltaIndex(['1 d','2 d','3 d',
-                                       '7 d','8 d','9 d','10d'], freq=None, name='idx')
+        expected_3_5 = TimedeltaIndex(['1 d', '2 d', '3 d',
+                                       '7 d', '8 d', '9 d', '10d'],
+                                      freq=None, name='idx')
 
-        cases ={(0, 1, 2): expected_0_2,
-                (7, 8, 9): expected_7_9,
-                (3, 4, 5): expected_3_5}
+        cases = {(0, 1, 2): expected_0_2,
+                 (7, 8, 9): expected_7_9,
+                 (3, 4, 5): expected_3_5}
         for n, expected in compat.iteritems(cases):
             result = idx.delete(n)
             self.assertTrue(result.equals(expected))
@@ -1541,12 +1600,12 @@ class TestTimedeltaIndex(tm.TestCase):
 
     def test_take(self):
 
-        tds = ['1day 02:00:00','1 day 04:00:00','1 day 10:00:00']
-        idx = TimedeltaIndex(start='1d',end='2d',freq='H',name='idx')
+        tds = ['1day 02:00:00', '1 day 04:00:00', '1 day 10:00:00']
+        idx = TimedeltaIndex(start='1d', end='2d', freq='H', name='idx')
         expected = TimedeltaIndex(tds, freq=None, name='idx')
 
         taken1 = idx.take([2, 4, 10])
-        taken2 = idx[[2,4,10]]
+        taken2 = idx[[2, 4, 10]]
 
         for taken in [taken1, taken2]:
             self.assertTrue(taken.equals(expected))
@@ -1567,8 +1626,9 @@ class TestTimedeltaIndex(tm.TestCase):
                             [False, False, True, False])
 
     def test_does_not_convert_mixed_integer(self):
-        df = tm.makeCustomDataframe(10, 10, data_gen_f=lambda *args, **kwargs:
-                                    randn(), r_idx_type='i', c_idx_type='td')
+        df = tm.makeCustomDataframe(10, 10,
+                                    data_gen_f=lambda *args, **kwargs: randn(),
+                                    r_idx_type='i', c_idx_type='td')
         str(df)
 
         cols = df.columns.join(df.index, how='outer')
@@ -1580,7 +1640,7 @@ class TestTimedeltaIndex(tm.TestCase):
     def test_slice_keeps_name(self):
 
         # GH4226
-        dr = pd.timedelta_range('1d','5d', freq='H', name='timebucket')
+        dr = pd.timedelta_range('1d', '5d', freq='H', name='timebucket')
         self.assertEqual(dr[1:].name, dr.name)
 
     def test_join_self(self):
@@ -1592,11 +1652,11 @@ class TestTimedeltaIndex(tm.TestCase):
             self.assertIs(index, joined)
 
     def test_factorize(self):
-        idx1 = TimedeltaIndex(['1 day','1 day','2 day',
-                               '2 day','3 day','3 day'])
+        idx1 = TimedeltaIndex(['1 day', '1 day', '2 day', '2 day', '3 day',
+                               '3 day'])
 
         exp_arr = np.array([0, 0, 1, 1, 2, 2])
-        exp_idx = TimedeltaIndex(['1 day','2 day','3 day'])
+        exp_idx = TimedeltaIndex(['1 day', '2 day', '3 day'])
 
         arr, idx = idx1.factorize()
         self.assert_numpy_array_equal(arr, exp_arr)
@@ -1613,10 +1673,10 @@ class TestTimedeltaIndex(tm.TestCase):
         self.assert_numpy_array_equal(arr, exp_arr)
         self.assertTrue(idx.equals(idx3))
 
-class TestSlicing(tm.TestCase):
 
+class TestSlicing(tm.TestCase):
     def test_partial_slice(self):
-        rng = timedelta_range('1 day 10:11:12', freq='h',periods=500)
+        rng = timedelta_range('1 day 10:11:12', freq='h', periods=500)
         s = Series(np.arange(len(rng)), index=rng)
 
         result = s['5 day':'6 day']
@@ -1639,7 +1699,7 @@ class TestSlicing(tm.TestCase):
     def test_partial_slice_high_reso(self):
 
         # higher reso
-        rng = timedelta_range('1 day 10:11:12', freq='us',periods=2000)
+        rng = timedelta_range('1 day 10:11:12', freq='us', periods=2000)
         s = Series(np.arange(len(rng)), index=rng)
 
         result = s['1 day 10:11:12':]
@@ -1654,8 +1714,7 @@ class TestSlicing(tm.TestCase):
         self.assertEqual(result, s.iloc[1001])
 
     def test_slice_with_negative_step(self):
-        ts = Series(np.arange(20),
-                    timedelta_range('0', periods=20, freq='H'))
+        ts = Series(np.arange(20), timedelta_range('0', periods=20, freq='H'))
         SLC = pd.IndexSlice
 
         def assert_slices_equivalent(l_slc, i_slc):
@@ -1670,15 +1729,17 @@ class TestSlicing(tm.TestCase):
         assert_slices_equivalent(SLC[:'7 hours':-1], SLC[:6:-1])
 
         assert_slices_equivalent(SLC['15 hours':'7 hours':-1], SLC[15:6:-1])
-        assert_slices_equivalent(SLC[Timedelta(hours=15):Timedelta(hours=7):-1], SLC[15:6:-1])
-        assert_slices_equivalent(SLC['15 hours':Timedelta(hours=7):-1], SLC[15:6:-1])
-        assert_slices_equivalent(SLC[Timedelta(hours=15):'7 hours':-1], SLC[15:6:-1])
+        assert_slices_equivalent(SLC[Timedelta(hours=15):Timedelta(hours=7):-
+                                     1], SLC[15:6:-1])
+        assert_slices_equivalent(SLC['15 hours':Timedelta(hours=7):-1],
+                                 SLC[15:6:-1])
+        assert_slices_equivalent(SLC[Timedelta(hours=15):'7 hours':-1],
+                                 SLC[15:6:-1])
 
         assert_slices_equivalent(SLC['7 hours':'15 hours':-1], SLC[:0])
 
     def test_slice_with_zero_step_raises(self):
-        ts = Series(np.arange(20),
-                    timedelta_range('0', periods=20, freq='H'))
+        ts = Series(np.arange(20), timedelta_range('0', periods=20, freq='H'))
         self.assertRaisesRegexp(ValueError, 'slice step cannot be zero',
                                 lambda: ts[::0])
         self.assertRaisesRegexp(ValueError, 'slice step cannot be zero',
@@ -1694,7 +1755,7 @@ class TestSlicing(tm.TestCase):
         tm.assert_index_equal(result, exp)
         self.assertEqual(result.freq, '2D')
 
-        result = rng -2
+        result = rng - 2
         exp = timedelta_range('-2 days', periods=5, freq='2D', name='x')
         tm.assert_index_equal(result, exp)
         self.assertEqual(result.freq, '2D')
@@ -1709,7 +1770,7 @@ class TestSlicing(tm.TestCase):
         tm.assert_index_equal(result, exp)
         self.assertEqual(result.freq, 'D')
 
-        result = - rng
+        result = -rng
         exp = timedelta_range('-2 days', periods=5, freq='-2D', name='x')
         tm.assert_index_equal(result, exp)
         self.assertEqual(result.freq, '-2D')
diff --git a/pandas/tseries/tests/test_timeseries.py b/pandas/tseries/tests/test_timeseries.py
index e81df6198..84065c034 100644
--- a/pandas/tseries/tests/test_timeseries.py
+++ b/pandas/tseries/tests/test_timeseries.py
@@ -11,10 +11,9 @@ import pandas.lib as lib
 import pandas.tslib as tslib
 import pandas.index as _index
 import pandas as pd
-from pandas import (Index, Series, DataFrame,
-                    isnull, date_range, Timestamp, Period, DatetimeIndex,
-                    Int64Index, to_datetime, bdate_range, Float64Index,
-                    NaT, timedelta_range, Timedelta)
+from pandas import (Index, Series, DataFrame, isnull, date_range, Timestamp,
+                    Period, DatetimeIndex, Int64Index, to_datetime,
+                    bdate_range, Float64Index, NaT, timedelta_range, Timedelta)
 
 import pandas.core.datetools as datetools
 import pandas.tseries.offsets as offsets
@@ -80,20 +79,19 @@ class TestTimeSeriesDuplicates(tm.TestCase):
         self.assertTrue(result.equals(expected))
 
         # NaT, note this is excluded
-        arr = [ 1370745748 + t for t in range(20) ] + [iNaT]
+        arr = [1370745748 + t for t in range(20)] + [iNaT]
         idx = DatetimeIndex(arr * 3)
         self.assertTrue(idx.unique().equals(DatetimeIndex(arr)))
         self.assertEqual(idx.nunique(), 20)
         self.assertEqual(idx.nunique(dropna=False), 21)
 
-        arr = [Timestamp('2013-06-09 02:42:28') + timedelta(seconds=t) for
-               t in range(20)] + [NaT]
+        arr = [Timestamp('2013-06-09 02:42:28') + timedelta(seconds=t)
+               for t in range(20)] + [NaT]
         idx = DatetimeIndex(arr * 3)
         self.assertTrue(idx.unique().equals(DatetimeIndex(arr)))
         self.assertEqual(idx.nunique(), 20)
         self.assertEqual(idx.nunique(dropna=False), 21)
 
-
     def test_index_dupes_contains(self):
         d = datetime(2011, 12, 5, 20, 30)
         ix = DatetimeIndex([d, d])
@@ -122,8 +120,8 @@ class TestTimeSeriesDuplicates(tm.TestCase):
         self.assertRaises(KeyError, ts.__getitem__, datetime(2000, 1, 6))
 
         # new index
-        ts[datetime(2000,1,6)] = 0
-        self.assertEqual(ts[datetime(2000,1,6)], 0)
+        ts[datetime(2000, 1, 6)] = 0
+        self.assertEqual(ts[datetime(2000, 1, 6)], 0)
 
     def test_range_slice(self):
         idx = DatetimeIndex(['1/1/2000', '1/2/2000', '1/2/2000', '1/3/2000',
@@ -187,11 +185,13 @@ class TestTimeSeriesDuplicates(tm.TestCase):
     def test_indexing_unordered(self):
         # GH 2437
         rng = date_range(start='2011-01-01', end='2011-01-15')
-        ts  = Series(randn(len(rng)), index=rng)
-        ts2 = concat([ts[0:4],ts[-4:],ts[4:-4]])
+        ts = Series(randn(len(rng)), index=rng)
+        ts2 = concat([ts[0:4], ts[-4:], ts[4:-4]])
 
         for t in ts.index:
-            s = str(t)
+            # TODO: unused?
+            s = str(t)  # noqa
+
             expected = ts[t]
             result = ts2[t]
             self.assertTrue(expected == result)
@@ -201,21 +201,21 @@ class TestTimeSeriesDuplicates(tm.TestCase):
             result = ts2[slobj].copy()
             result = result.sort_index()
             expected = ts[slobj]
-            assert_series_equal(result,expected)
+            assert_series_equal(result, expected)
 
-        compare(slice('2011-01-01','2011-01-15'))
-        compare(slice('2010-12-30','2011-01-15'))
-        compare(slice('2011-01-01','2011-01-16'))
+        compare(slice('2011-01-01', '2011-01-15'))
+        compare(slice('2010-12-30', '2011-01-15'))
+        compare(slice('2011-01-01', '2011-01-16'))
 
         # partial ranges
-        compare(slice('2011-01-01','2011-01-6'))
-        compare(slice('2011-01-06','2011-01-8'))
-        compare(slice('2011-01-06','2011-01-12'))
+        compare(slice('2011-01-01', '2011-01-6'))
+        compare(slice('2011-01-06', '2011-01-8'))
+        compare(slice('2011-01-06', '2011-01-12'))
 
         # single values
         result = ts2['2011'].sort_index()
         expected = ts['2011']
-        assert_series_equal(result,expected)
+        assert_series_equal(result, expected)
 
         # diff freq
         rng = date_range(datetime(2005, 1, 1), periods=20, freq='M')
@@ -229,7 +229,7 @@ class TestTimeSeriesDuplicates(tm.TestCase):
     def test_indexing(self):
 
         idx = date_range("2001-1-1", periods=20, freq='M')
-        ts = Series(np.random.rand(len(idx)),index=idx)
+        ts = Series(np.random.rand(len(idx)), index=idx)
 
         # getting
 
@@ -237,7 +237,7 @@ class TestTimeSeriesDuplicates(tm.TestCase):
         expected = ts['2001']
         expected.name = 'A'
 
-        df = DataFrame(dict(A = ts))
+        df = DataFrame(dict(A=ts))
         result = df['2001']['A']
         assert_series_equal(expected, result)
 
@@ -280,11 +280,11 @@ class TestTimeSeriesDuplicates(tm.TestCase):
         assert_frame_equal(result, expected)
 
         # this is a single date, so will raise
-        self.assertRaises(KeyError, df.__getitem__, df.index[2],)
+        self.assertRaises(KeyError, df.__getitem__, df.index[2], )
 
     def test_recreate_from_data(self):
-        freqs = ['M', 'Q', 'A', 'D', 'B', 'BH', 'T',
-                 'S', 'L', 'U', 'H', 'N', 'C']
+        freqs = ['M', 'Q', 'A', 'D', 'B', 'BH', 'T', 'S', 'L', 'U', 'H', 'N',
+                 'C']
 
         for f in freqs:
             org = DatetimeIndex(start='2001/02/01 09:00', freq=f, periods=1)
@@ -298,9 +298,9 @@ class TestTimeSeriesDuplicates(tm.TestCase):
 
 
 def assert_range_equal(left, right):
-    assert(left.equals(right))
-    assert(left.freq == right.freq)
-    assert(left.tz == right.tz)
+    assert (left.equals(right))
+    assert (left.freq == right.freq)
+    assert (left.tz == right.tz)
 
 
 class TestTimeSeries(tm.TestCase):
@@ -373,7 +373,7 @@ class TestTimeSeries(tm.TestCase):
         tm.assertIsInstance(s.iat[5], Timestamp)
 
     def test_series_box_timedelta(self):
-        rng = timedelta_range('1 day 1 s',periods=5,freq='h')
+        rng = timedelta_range('1 day 1 s', periods=5, freq='h')
         s = Series(rng)
         tm.assertIsInstance(s[1], Timedelta)
         tm.assertIsInstance(s.iat[2], Timedelta)
@@ -383,13 +383,12 @@ class TestTimeSeries(tm.TestCase):
         start = datetime(2011, 1, 1, 5, 3, 40)
         end = datetime(2011, 1, 1, 8, 9, 40)
 
-        self.assertRaises(ValueError, date_range, start, end,
-                          freq='s', periods=10)
+        self.assertRaises(ValueError, date_range, start, end, freq='s',
+                          periods=10)
 
     def test_timestamp_to_datetime(self):
         tm._skip_if_no_pytz()
-        rng = date_range('20090415', '20090519',
-                         tz='US/Eastern')
+        rng = date_range('20090415', '20090519', tz='US/Eastern')
 
         stamp = rng[0]
         dtval = stamp.to_pydatetime()
@@ -398,8 +397,7 @@ class TestTimeSeries(tm.TestCase):
 
     def test_timestamp_to_datetime_dateutil(self):
         tm._skip_if_no_pytz()
-        rng = date_range('20090415', '20090519',
-                         tz='dateutil/US/Eastern')
+        rng = date_range('20090415', '20090519', tz='dateutil/US/Eastern')
 
         stamp = rng[0]
         dtval = stamp.to_pydatetime()
@@ -421,8 +419,7 @@ class TestTimeSeries(tm.TestCase):
         tm._skip_if_windows_python_3()
         tm._skip_if_no_dateutil()
         from pandas.tslib import _dateutil_gettz as gettz
-        rng = date_range('20090415', '20090519',
-                         tz=gettz('US/Eastern'))
+        rng = date_range('20090415', '20090519', tz=gettz('US/Eastern'))
 
         stamp = rng[0]
         dtval = stamp.to_pydatetime()
@@ -668,20 +665,17 @@ class TestTimeSeries(tm.TestCase):
         # neither monotonic increasing or decreasing
         rng2 = rng[[1, 0, 2]]
 
-        self.assertRaises(ValueError, rng2.get_indexer, rng,
-                          method='pad')
+        self.assertRaises(ValueError, rng2.get_indexer, rng, method='pad')
 
     def test_frame_ctor_datetime64_column(self):
-        rng = date_range('1/1/2000 00:00:00', '1/1/2000 1:59:50',
-                         freq='10s')
+        rng = date_range('1/1/2000 00:00:00', '1/1/2000 1:59:50', freq='10s')
         dates = np.asarray(rng)
 
         df = DataFrame({'A': np.random.randn(len(rng)), 'B': dates})
         self.assertTrue(np.issubdtype(df['B'].dtype, np.dtype('M8[ns]')))
 
     def test_frame_add_datetime64_column(self):
-        rng = date_range('1/1/2000 00:00:00', '1/1/2000 1:59:50',
-                         freq='10s')
+        rng = date_range('1/1/2000 00:00:00', '1/1/2000 1:59:50', freq='10s')
         df = DataFrame(index=np.arange(len(rng)))
 
         df['A'] = rng
@@ -730,34 +724,40 @@ class TestTimeSeries(tm.TestCase):
     def test_to_datetime_unit(self):
 
         epoch = 1370745748
-        s = Series([ epoch + t for t in range(20) ])
-        result = to_datetime(s,unit='s')
-        expected = Series([ Timestamp('2013-06-09 02:42:28') + timedelta(seconds=t) for t in range(20) ])
-        assert_series_equal(result,expected)
-
-        s = Series([ epoch + t for t in range(20) ]).astype(float)
-        result = to_datetime(s,unit='s')
-        expected = Series([ Timestamp('2013-06-09 02:42:28') + timedelta(seconds=t) for t in range(20) ])
-        assert_series_equal(result,expected)
-
-        s = Series([ epoch + t for t in range(20) ] + [iNaT])
-        result = to_datetime(s,unit='s')
-        expected = Series([ Timestamp('2013-06-09 02:42:28') + timedelta(seconds=t) for t in range(20) ] + [NaT])
-        assert_series_equal(result,expected)
-
-        s = Series([ epoch + t for t in range(20) ] + [iNaT]).astype(float)
-        result = to_datetime(s,unit='s')
-        expected = Series([ Timestamp('2013-06-09 02:42:28') + timedelta(seconds=t) for t in range(20) ] + [NaT])
-        assert_series_equal(result,expected)
-
-        s = concat([Series([ epoch + t for t in range(20) ]).astype(float),Series([np.nan])],ignore_index=True)
-        result = to_datetime(s,unit='s')
-        expected = Series([ Timestamp('2013-06-09 02:42:28') + timedelta(seconds=t) for t in range(20) ] + [NaT])
-        assert_series_equal(result,expected)
+        s = Series([epoch + t for t in range(20)])
+        result = to_datetime(s, unit='s')
+        expected = Series([Timestamp('2013-06-09 02:42:28') + timedelta(
+            seconds=t) for t in range(20)])
+        assert_series_equal(result, expected)
+
+        s = Series([epoch + t for t in range(20)]).astype(float)
+        result = to_datetime(s, unit='s')
+        expected = Series([Timestamp('2013-06-09 02:42:28') + timedelta(
+            seconds=t) for t in range(20)])
+        assert_series_equal(result, expected)
+
+        s = Series([epoch + t for t in range(20)] + [iNaT])
+        result = to_datetime(s, unit='s')
+        expected = Series([Timestamp('2013-06-09 02:42:28') + timedelta(
+            seconds=t) for t in range(20)] + [NaT])
+        assert_series_equal(result, expected)
+
+        s = Series([epoch + t for t in range(20)] + [iNaT]).astype(float)
+        result = to_datetime(s, unit='s')
+        expected = Series([Timestamp('2013-06-09 02:42:28') + timedelta(
+            seconds=t) for t in range(20)] + [NaT])
+        assert_series_equal(result, expected)
+
+        s = concat([Series([epoch + t for t in range(20)]
+                           ).astype(float), Series([np.nan])],
+                   ignore_index=True)
+        result = to_datetime(s, unit='s')
+        expected = Series([Timestamp('2013-06-09 02:42:28') + timedelta(
+            seconds=t) for t in range(20)] + [NaT])
+        assert_series_equal(result, expected)
 
     def test_series_ctor_datetime64(self):
-        rng = date_range('1/1/2000 00:00:00', '1/1/2000 1:59:50',
-                         freq='10s')
+        rng = date_range('1/1/2000 00:00:00', '1/1/2000 1:59:50', freq='10s')
         dates = np.asarray(rng)
 
         series = Series(dates)
@@ -865,13 +865,13 @@ class TestTimeSeries(tm.TestCase):
         malformed = np.array(['1/100/2000', np.nan], dtype=object)
 
         # GH 10636, default is now 'raise'
-        self.assertRaises(ValueError, lambda : to_datetime(malformed, errors='raise'))
+        self.assertRaises(ValueError,
+                          lambda: to_datetime(malformed, errors='raise'))
 
         result = to_datetime(malformed, errors='ignore')
         tm.assert_numpy_array_equal(result, malformed)
 
-        self.assertRaises(ValueError, to_datetime, malformed,
-                          errors='raise')
+        self.assertRaises(ValueError, to_datetime, malformed, errors='raise')
 
         idx = ['a', 'b', 'c', 'd', 'e']
         series = Series(['1/1/2000', np.nan, '1/3/2000', np.nan,
@@ -911,9 +911,11 @@ class TestTimeSeries(tm.TestCase):
         xp = datetime(2001, 1, 1)
         self.assertTrue(rs, xp)
 
-        #### dayfirst is essentially broken
-        #### to_datetime('01-13-2012', dayfirst=True)
-        #### self.assertRaises(ValueError, to_datetime('01-13-2012', dayfirst=True))
+        # dayfirst is essentially broken
+
+        # to_datetime('01-13-2012', dayfirst=True)
+        # self.assertRaises(ValueError, to_datetime('01-13-2012',
+        #                   dayfirst=True))
 
     def test_to_datetime_on_datetime64_series(self):
         # #2699
@@ -928,25 +930,30 @@ class TestTimeSeries(tm.TestCase):
 
         # GH 5195
         # with a format and coerce a single item to_datetime fails
-        td = Series(['May 04', 'Jun 02', 'Dec 11'], index=[1,2,3])
+        td = Series(['May 04', 'Jun 02', 'Dec 11'], index=[1, 2, 3])
         expected = pd.to_datetime(td, format='%b %y')
         result = td.apply(pd.to_datetime, format='%b %y')
         assert_series_equal(result, expected)
 
-        td = pd.Series(['May 04', 'Jun 02', ''], index=[1,2,3])
-        self.assertRaises(ValueError, lambda : pd.to_datetime(td,format='%b %y', errors='raise'))
-        self.assertRaises(ValueError, lambda : td.apply(pd.to_datetime, format='%b %y', errors='raise'))
+        td = pd.Series(['May 04', 'Jun 02', ''], index=[1, 2, 3])
+        self.assertRaises(ValueError,
+                          lambda: pd.to_datetime(td, format='%b %y',
+                                                 errors='raise'))
+        self.assertRaises(ValueError,
+                          lambda: td.apply(pd.to_datetime, format='%b %y',
+                                           errors='raise'))
         expected = pd.to_datetime(td, format='%b %y', errors='coerce')
 
-        result = td.apply(lambda x: pd.to_datetime(x, format='%b %y', errors='coerce'))
+        result = td.apply(
+            lambda x: pd.to_datetime(x, format='%b %y', errors='coerce'))
         assert_series_equal(result, expected)
 
     def test_nat_vector_field_access(self):
         idx = DatetimeIndex(['1/1/2000', None, None, '1/4/2000'])
 
-        fields = ['year', 'quarter', 'month', 'day', 'hour',
-                  'minute', 'second', 'microsecond', 'nanosecond',
-                  'week', 'dayofyear', 'days_in_month']
+        fields = ['year', 'quarter', 'month', 'day', 'hour', 'minute',
+                  'second', 'microsecond', 'nanosecond', 'week', 'dayofyear',
+                  'days_in_month']
         for field in fields:
             result = getattr(idx, field)
             expected = [getattr(x, field) if x is not NaT else np.nan
@@ -954,22 +961,21 @@ class TestTimeSeries(tm.TestCase):
             self.assert_numpy_array_equal(result, np.array(expected))
 
     def test_nat_scalar_field_access(self):
-        fields = ['year', 'quarter', 'month', 'day', 'hour',
-                  'minute', 'second', 'microsecond', 'nanosecond',
-                  'week', 'dayofyear', 'days_in_month', 'daysinmonth',
-                  'dayofweek']
+        fields = ['year', 'quarter', 'month', 'day', 'hour', 'minute',
+                  'second', 'microsecond', 'nanosecond', 'week', 'dayofyear',
+                  'days_in_month', 'daysinmonth', 'dayofweek']
         for field in fields:
             result = getattr(NaT, field)
             self.assertTrue(np.isnan(result))
 
     def test_NaT_methods(self):
         # GH 9513
-        raise_methods = ['astimezone', 'combine', 'ctime', 'dst', 'fromordinal',
-                         'fromtimestamp', 'isocalendar', 'isoformat',
-                         'strftime', 'strptime',
-                         'time', 'timestamp', 'timetuple', 'timetz',
-                         'toordinal', 'tzname', 'utcfromtimestamp',
-                         'utcnow', 'utcoffset', 'utctimetuple']
+        raise_methods = ['astimezone', 'combine', 'ctime', 'dst',
+                         'fromordinal', 'fromtimestamp', 'isocalendar',
+                         'isoformat', 'strftime', 'strptime', 'time',
+                         'timestamp', 'timetuple', 'timetz', 'toordinal',
+                         'tzname', 'utcfromtimestamp', 'utcnow', 'utcoffset',
+                         'utctimetuple']
         nat_methods = ['date', 'now', 'replace', 'to_datetime', 'today']
         nan_methods = ['weekday', 'isoweekday']
 
@@ -1004,16 +1010,16 @@ class TestTimeSeries(tm.TestCase):
         result = to_datetime('2012')
         self.assertEqual(result, expected)
 
-        ### array = ['2012','20120101','20120101 12:01:01']
-        array = ['20120101','20120101 12:01:01']
+        # array = ['2012','20120101','20120101 12:01:01']
+        array = ['20120101', '20120101 12:01:01']
         expected = list(to_datetime(array))
-        result = lmap(Timestamp,array)
-        tm.assert_almost_equal(result,expected)
+        result = lmap(Timestamp, array)
+        tm.assert_almost_equal(result, expected)
 
-        ### currently fails ###
-        ### result = Timestamp('2012')
-        ### expected = to_datetime('2012')
-        ### self.assertEqual(result, expected)
+        # currently fails ###
+        # result = Timestamp('2012')
+        # expected = to_datetime('2012')
+        # self.assertEqual(result, expected)
 
     def test_to_datetime_unprocessable_input(self):
         # GH 4928
@@ -1051,15 +1057,9 @@ class TestTimeSeries(tm.TestCase):
         ]
 
         for dt in in_bound_dts:
-            self.assertEqual(
-                pd.to_datetime(dt),
-                Timestamp(dt)
-            )
+            self.assertEqual(pd.to_datetime(dt), Timestamp(dt))
 
-        oob_dts = [
-            np.datetime64('1000-01-01'),
-            np.datetime64('5000-01-02'),
-        ]
+        oob_dts = [np.datetime64('1000-01-01'), np.datetime64('5000-01-02'), ]
 
         for dt in oob_dts:
             self.assertRaises(ValueError, pd.to_datetime, dt, errors='raise')
@@ -1067,10 +1067,7 @@ class TestTimeSeries(tm.TestCase):
             self.assertIs(pd.to_datetime(dt, errors='coerce'), NaT)
 
     def test_to_datetime_array_of_dt64s(self):
-        dts = [
-            np.datetime64('2000-01-01'),
-            np.datetime64('2000-01-02'),
-        ]
+        dts = [np.datetime64('2000-01-01'), np.datetime64('2000-01-02'), ]
 
         # Assuming all datetimes are in bounds, to_datetime() returns
         # an array that is equal to Timestamp() parsing
@@ -1082,22 +1079,18 @@ class TestTimeSeries(tm.TestCase):
         # A list of datetimes where the last one is out of bounds
         dts_with_oob = dts + [np.datetime64('9999-01-01')]
 
-        self.assertRaises(
-            ValueError,
-            pd.to_datetime,
-            dts_with_oob,
-            errors='raise'
-        )
+        self.assertRaises(ValueError, pd.to_datetime, dts_with_oob,
+                          errors='raise')
 
         self.assert_numpy_array_equal(
             pd.to_datetime(dts_with_oob, box=False, errors='coerce'),
             np.array(
-                    [
-                        Timestamp(dts_with_oob[0]).asm8,
-                        Timestamp(dts_with_oob[1]).asm8,
-                        iNaT,
-                    ],
-                    dtype='M8'
+                [
+                    Timestamp(dts_with_oob[0]).asm8,
+                    Timestamp(dts_with_oob[1]).asm8,
+                    iNaT,
+                ],
+                dtype='M8'
             )
         )
 
@@ -1107,8 +1100,8 @@ class TestTimeSeries(tm.TestCase):
         self.assert_numpy_array_equal(
             pd.to_datetime(dts_with_oob, box=False, errors='ignore'),
             np.array(
-                    [dt.item() for dt in dts_with_oob],
-                    dtype='O'
+                [dt.item() for dt in dts_with_oob],
+                dtype='O'
             )
         )
 
@@ -1116,14 +1109,17 @@ class TestTimeSeries(tm.TestCase):
 
         # xref 8260
         # uniform returns a DatetimeIndex
-        arr = [pd.Timestamp('2013-01-01 13:00:00-0800', tz='US/Pacific'),pd.Timestamp('2013-01-02 14:00:00-0800', tz='US/Pacific')]
+        arr = [pd.Timestamp('2013-01-01 13:00:00-0800', tz='US/Pacific'),
+               pd.Timestamp('2013-01-02 14:00:00-0800', tz='US/Pacific')]
         result = pd.to_datetime(arr)
-        expected = DatetimeIndex(['2013-01-01 13:00:00','2013-01-02 14:00:00'],tz='US/Pacific')
+        expected = DatetimeIndex(
+            ['2013-01-01 13:00:00', '2013-01-02 14:00:00'], tz='US/Pacific')
         tm.assert_index_equal(result, expected)
 
         # mixed tzs will raise
-        arr = [pd.Timestamp('2013-01-01 13:00:00', tz='US/Pacific'),pd.Timestamp('2013-01-02 14:00:00', tz='US/Eastern')]
-        self.assertRaises(ValueError, lambda : pd.to_datetime(arr))
+        arr = [pd.Timestamp('2013-01-01 13:00:00', tz='US/Pacific'),
+               pd.Timestamp('2013-01-02 14:00:00', tz='US/Eastern')]
+        self.assertRaises(ValueError, lambda: pd.to_datetime(arr))
 
     def test_to_datetime_tz_pytz(self):
 
@@ -1132,10 +1128,15 @@ class TestTimeSeries(tm.TestCase):
         import pytz
 
         us_eastern = pytz.timezone('US/Eastern')
-        arr = np.array([us_eastern.localize(datetime(year=2000, month=1, day=1, hour=3, minute=0)),
-                        us_eastern.localize(datetime(year=2000, month=6, day=1, hour=3, minute=0))],dtype=object)
+        arr = np.array([us_eastern.localize(datetime(year=2000, month=1, day=1,
+                                                     hour=3, minute=0)),
+                        us_eastern.localize(datetime(year=2000, month=6, day=1,
+                                                     hour=3, minute=0))],
+                       dtype=object)
         result = pd.to_datetime(arr, utc=True)
-        expected = DatetimeIndex(['2000-01-01 08:00:00+00:00', '2000-06-01 07:00:00+00:00'], dtype='datetime64[ns, UTC]', freq=None)
+        expected = DatetimeIndex(['2000-01-01 08:00:00+00:00',
+                                  '2000-06-01 07:00:00+00:00'],
+                                 dtype='datetime64[ns, UTC]', freq=None)
         tm.assert_index_equal(result, expected)
 
     def test_to_datetime_tz_psycopg2(self):
@@ -1147,15 +1148,22 @@ class TestTimeSeries(tm.TestCase):
             raise nose.SkipTest("no psycopg2 installed")
 
         # misc cases
-        arr = np.array([ datetime(2000, 1, 1, 3, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=-300, name=None)),
-                         datetime(2000, 6, 1, 3, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=-240, name=None))], dtype=object)
+        tz1 = psycopg2.tz.FixedOffsetTimezone(offset=-300, name=None)
+        tz2 = psycopg2.tz.FixedOffsetTimezone(offset=-240, name=None)
+        arr = np.array([datetime(2000, 1, 1, 3, 0, tzinfo=tz1),
+                        datetime(2000, 6, 1, 3, 0, tzinfo=tz2)],
+                       dtype=object)
 
         result = pd.to_datetime(arr, errors='coerce', utc=True)
-        expected = DatetimeIndex(['2000-01-01 08:00:00+00:00', '2000-06-01 07:00:00+00:00'], dtype='datetime64[ns, UTC]', freq=None)
+        expected = DatetimeIndex(['2000-01-01 08:00:00+00:00',
+                                  '2000-06-01 07:00:00+00:00'],
+                                 dtype='datetime64[ns, UTC]', freq=None)
         tm.assert_index_equal(result, expected)
 
         # dtype coercion
-        i = pd.DatetimeIndex(['2000-01-01 08:00:00+00:00'],tz=psycopg2.tz.FixedOffsetTimezone(offset=-300, name=None))
+        i = pd.DatetimeIndex([
+            '2000-01-01 08:00:00+00:00'
+        ], tz=psycopg2.tz.FixedOffsetTimezone(offset=-300, name=None))
         self.assertFalse(com.is_datetime64_ns_dtype(i))
 
         # tz coerceion
@@ -1218,8 +1226,8 @@ class TestTimeSeries(tm.TestCase):
     def test_asfreq_keep_index_name(self):
         # GH #9854
         index_name = 'bar'
-        index = pd.date_range('20130101',periods=20,name=index_name)
-        df = pd.DataFrame([x for x in range(20)],columns=['foo'],index=index)
+        index = pd.date_range('20130101', periods=20, name=index_name)
+        df = pd.DataFrame([x for x in range(20)], columns=['foo'], index=index)
 
         tm.assert_equal(index_name, df.index.name)
         tm.assert_equal(index_name, df.asfreq('10D').index.name)
@@ -1291,12 +1299,14 @@ class TestTimeSeries(tm.TestCase):
     def test_date_range_negative_freq(self):
         # GH 11018
         rng = date_range('2011-12-31', freq='-2A', periods=3)
-        exp = pd.DatetimeIndex(['2011-12-31', '2009-12-31', '2007-12-31'], freq='-2A')
+        exp = pd.DatetimeIndex(
+            ['2011-12-31', '2009-12-31', '2007-12-31'], freq='-2A')
         self.assert_index_equal(rng, exp)
         self.assertEqual(rng.freq, '-2A')
 
         rng = date_range('2011-01-31', freq='-2M', periods=3)
-        exp = pd.DatetimeIndex(['2011-01-31', '2010-11-30', '2010-09-30'], freq='-2M')
+        exp = pd.DatetimeIndex(
+            ['2011-01-31', '2010-11-30', '2010-09-30'], freq='-2M')
         self.assert_index_equal(rng, exp)
         self.assertEqual(rng.freq, '-2M')
 
@@ -1566,10 +1576,10 @@ class TestTimeSeries(tm.TestCase):
         rng = date_range('1/1/2000', '1/5/2000', freq='5min')
         ts = DataFrame(np.random.randn(len(rng), 2), index=rng)
 
-        strings = [("2:00", "2:30"), ("0200", "0230"),
-                   ("2:00am", "2:30am"), ("0200am", "0230am"),
-                   ("2:00:00", "2:30:00"), ("020000", "023000"),
-                   ("2:00:00am", "2:30:00am"), ("020000am", "023000am")]
+        strings = [("2:00", "2:30"), ("0200", "0230"), ("2:00am", "2:30am"),
+                   ("0200am", "0230am"), ("2:00:00", "2:30:00"),
+                   ("020000", "023000"), ("2:00:00am", "2:30:00am"),
+                   ("020000am", "023000am")]
         expected_length = 28
 
         for time_string in strings:
@@ -1590,13 +1600,15 @@ class TestTimeSeries(tm.TestCase):
             expected1 = date_range('2014-01-31', '2014-12-31', freq='M', tz=tz)
 
             rng2 = date_range('2014', '2015', freq='MS', tz=tz)
-            expected2 = date_range('2014-01-01', '2015-01-01', freq='MS', tz=tz)
+            expected2 = date_range('2014-01-01', '2015-01-01', freq='MS',
+                                   tz=tz)
 
             rng3 = date_range('2014', '2020', freq='A', tz=tz)
             expected3 = date_range('2014-12-31', '2019-12-31', freq='A', tz=tz)
 
             rng4 = date_range('2014', '2020', freq='AS', tz=tz)
-            expected4 = date_range('2014-01-01', '2020-01-01', freq='AS', tz=tz)
+            expected4 = date_range('2014-01-01', '2020-01-01', freq='AS',
+                                   tz=tz)
 
             for rng, expected in [(rng1, expected1), (rng2, expected2),
                                   (rng3, expected3), (rng4, expected4)]:
@@ -1609,9 +1621,13 @@ class TestTimeSeries(tm.TestCase):
         expected = date_range('1/1/2000', periods=10, freq='D')
         self.assertTrue(result.equals(expected))
 
-        rng_ns = pd.DatetimeIndex(np.array([1380585623454345752, 1380585612343234312]).astype("datetime64[ns]"))
+        rng_ns = pd.DatetimeIndex(np.array([1380585623454345752,
+                                            1380585612343234312]).astype(
+                                                "datetime64[ns]"))
         rng_ns_normalized = rng_ns.normalize()
-        expected = pd.DatetimeIndex(np.array([1380585600000000000, 1380585600000000000]).astype("datetime64[ns]"))
+        expected = pd.DatetimeIndex(np.array([1380585600000000000,
+                                              1380585600000000000]).astype(
+                                                  "datetime64[ns]"))
         self.assertTrue(rng_ns_normalized.equals(expected))
 
         self.assertTrue(result.is_normalized)
@@ -1633,7 +1649,8 @@ class TestTimeSeries(tm.TestCase):
         assert_series_equal(pts, exp)
 
         # GH 7606 without freq
-        idx = DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03', '2011-01-04'])
+        idx = DatetimeIndex(['2011-01-01', '2011-01-02', '2011-01-03',
+                             '2011-01-04'])
         exp_idx = pd.PeriodIndex(['2011-01-01', '2011-01-02', '2011-01-03',
                                   '2011-01-04'], freq='D')
 
@@ -1798,7 +1815,10 @@ class TestTimeSeries(tm.TestCase):
         # extra fields from DatetimeIndex like quarter and week
         idx = tm.makeDateIndex(100)
 
-        fields = ['dayofweek', 'dayofyear', 'week', 'weekofyear', 'quarter', 'days_in_month', 'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end', 'is_year_start', 'is_year_end']
+        fields = ['dayofweek', 'dayofyear', 'week', 'weekofyear', 'quarter',
+                  'days_in_month', 'is_month_start', 'is_month_end',
+                  'is_quarter_start', 'is_quarter_end', 'is_year_start',
+                  'is_year_end']
         for f in fields:
             expected = getattr(idx, f)[-1]
             result = getattr(Timestamp(idx[-1]), f)
@@ -1809,33 +1829,34 @@ class TestTimeSeries(tm.TestCase):
 
     def test_woy_boundary(self):
         # make sure weeks at year boundaries are correct
-        d = datetime(2013,12,31)
+        d = datetime(2013, 12, 31)
         result = Timestamp(d).week
-        expected = 1 # ISO standard
+        expected = 1  # ISO standard
         self.assertEqual(result, expected)
 
-        d = datetime(2008,12,28)
+        d = datetime(2008, 12, 28)
         result = Timestamp(d).week
-        expected = 52 # ISO standard
+        expected = 52  # ISO standard
         self.assertEqual(result, expected)
 
-        d = datetime(2009,12,31)
+        d = datetime(2009, 12, 31)
         result = Timestamp(d).week
-        expected = 53 # ISO standard
+        expected = 53  # ISO standard
         self.assertEqual(result, expected)
 
-        d = datetime(2010,1,1)
+        d = datetime(2010, 1, 1)
         result = Timestamp(d).week
-        expected = 53 # ISO standard
+        expected = 53  # ISO standard
         self.assertEqual(result, expected)
 
-        d = datetime(2010,1,3)
+        d = datetime(2010, 1, 3)
         result = Timestamp(d).week
-        expected = 53 # ISO standard
+        expected = 53  # ISO standard
         self.assertEqual(result, expected)
 
-        result = np.array([Timestamp(datetime(*args)).week for args in
-                           [(2000,1,1),(2000,1,2),(2005,1,1),(2005,1,2)]])
+        result = np.array([Timestamp(datetime(*args)).week
+                           for args in [(2000, 1, 1), (2000, 1, 2), (
+                               2005, 1, 1), (2005, 1, 2)]])
         self.assertTrue((result == [52, 52, 53, 53]).all())
 
     def test_timestamp_date_out_of_range(self):
@@ -1866,7 +1887,7 @@ class TestTimeSeries(tm.TestCase):
         # with a tzinfo
         stamp = Timestamp('2011-4-16', tz='US/Eastern')
         dt_tz = stamp.to_pydatetime()
-        ts = Timestamp.fromordinal(dt_tz.toordinal(),tz='US/Eastern')
+        ts = Timestamp.fromordinal(dt_tz.toordinal(), tz='US/Eastern')
         self.assertEqual(ts.to_pydatetime(), dt_tz)
 
     def test_datetimeindex_integers_shift(self):
@@ -1922,15 +1943,15 @@ class TestTimeSeries(tm.TestCase):
         self.assertIsNone(rng1.append(rng2).name)
 
     def test_append_concat_tz(self):
-        #GH 2938
+        # GH 2938
         tm._skip_if_no_pytz()
 
         rng = date_range('5/8/2012 1:45', periods=10, freq='5T',
                          tz='US/Eastern')
         rng2 = date_range('5/8/2012 2:35', periods=10, freq='5T',
-                         tz='US/Eastern')
+                          tz='US/Eastern')
         rng3 = date_range('5/8/2012 1:45', periods=20, freq='5T',
-                         tz='US/Eastern')
+                          tz='US/Eastern')
         ts = Series(np.random.randn(len(rng)), rng)
         df = DataFrame(np.random.randn(len(rng), 4), index=rng)
         ts2 = Series(np.random.randn(len(rng2)), rng2)
@@ -1952,9 +1973,9 @@ class TestTimeSeries(tm.TestCase):
         rng = date_range('5/8/2012 1:45', periods=10, freq='5T',
                          tz=timezone('US/Eastern'))
         rng2 = date_range('5/8/2012 2:35', periods=10, freq='5T',
-                         tz=timezone('US/Eastern'))
+                          tz=timezone('US/Eastern'))
         rng3 = date_range('5/8/2012 1:45', periods=20, freq='5T',
-                         tz=timezone('US/Eastern'))
+                          tz=timezone('US/Eastern'))
         ts = Series(np.random.randn(len(rng)), rng)
         df = DataFrame(np.random.randn(len(rng), 4), index=rng)
         ts2 = Series(np.random.randn(len(rng2)), rng2)
@@ -1971,14 +1992,12 @@ class TestTimeSeries(tm.TestCase):
     def test_append_concat_tz_dateutil(self):
         # GH 2938
         tm._skip_if_no_dateutil()
-        from pandas.tslib import _dateutil_gettz as timezone
-
         rng = date_range('5/8/2012 1:45', periods=10, freq='5T',
                          tz='dateutil/US/Eastern')
         rng2 = date_range('5/8/2012 2:35', periods=10, freq='5T',
-                         tz='dateutil/US/Eastern')
+                          tz='dateutil/US/Eastern')
         rng3 = date_range('5/8/2012 1:45', periods=20, freq='5T',
-                         tz='dateutil/US/Eastern')
+                          tz='dateutil/US/Eastern')
         ts = Series(np.random.randn(len(rng)), rng)
         df = DataFrame(np.random.randn(len(rng), 4), index=rng)
         ts2 = Series(np.random.randn(len(rng2)), rng2)
@@ -2148,10 +2167,11 @@ class TestTimeSeries(tm.TestCase):
 
     def test_series_map_box_timedelta(self):
         # GH 11349
-        s = Series(timedelta_range('1 day 1 s',periods=5,freq='h'))
+        s = Series(timedelta_range('1 day 1 s', periods=5, freq='h'))
 
         def f(x):
             return x.total_seconds()
+
         s.map(f)
         s.apply(f)
         DataFrame(s).applymap(f)
@@ -2165,16 +2185,18 @@ class TestTimeSeries(tm.TestCase):
         df2_obj = DataFrame.from_records(rows, columns=['date', 'test'])
 
         ind = date_range(start="2000/1/1", freq="D", periods=10)
-        df1 = DataFrame({'date': ind, 'test':lrange(10)})
+        df1 = DataFrame({'date': ind, 'test': lrange(10)})
 
         # it works!
         pd.concat([df1, df2_obj])
 
     def test_period_resample(self):
         # GH3609
-        s = Series(range(100),index=date_range('20130101', freq='s', periods=100), dtype='float')
+        s = Series(range(100), index=date_range(
+            '20130101', freq='s', periods=100), dtype='float')
         s[10:30] = np.nan
-        expected = Series([34.5, 79.5], index=[Period('2013-01-01 00:00', 'T'), Period('2013-01-01 00:01', 'T')])
+        expected = Series([34.5, 79.5], index=[Period(
+            '2013-01-01 00:00', 'T'), Period('2013-01-01 00:01', 'T')])
         result = s.to_period().resample('T', kind='period')
         assert_series_equal(result, expected)
         result2 = s.resample('T', kind='period')
@@ -2187,9 +2209,11 @@ class TestTimeSeries(tm.TestCase):
 
         local_timezone = pytz.timezone('America/Los_Angeles')
 
-        start = datetime(year=2013, month=11, day=1, hour=0, minute=0, tzinfo=pytz.utc)
+        start = datetime(year=2013, month=11, day=1, hour=0, minute=0,
+                         tzinfo=pytz.utc)
         # 1 day later
-        end = datetime(year=2013, month=11, day=2, hour=0, minute=0, tzinfo=pytz.utc)
+        end = datetime(year=2013, month=11, day=2, hour=0, minute=0,
+                       tzinfo=pytz.utc)
 
         index = pd.date_range(start, end, freq='H')
 
@@ -2197,7 +2221,9 @@ class TestTimeSeries(tm.TestCase):
         series = series.tz_convert(local_timezone)
         result = series.resample('D', kind='period')
         # Create the expected series
-        expected_index = (pd.period_range(start=start, end=end, freq='D') - 1)  # Index is moved back a day with the timezone conversion from UTC to Pacific
+        # Index is moved back a day with the timezone conversion from UTC to
+        # Pacific
+        expected_index = (pd.period_range(start=start, end=end, freq='D') - 1)
         expected = pd.Series(1, index=expected_index)
         assert_series_equal(result, expected)
 
@@ -2208,9 +2234,11 @@ class TestTimeSeries(tm.TestCase):
 
         local_timezone = 'dateutil/America/Los_Angeles'
 
-        start = datetime(year=2013, month=11, day=1, hour=0, minute=0, tzinfo=dateutil.tz.tzutc())
+        start = datetime(year=2013, month=11, day=1, hour=0, minute=0,
+                         tzinfo=dateutil.tz.tzutc())
         # 1 day later
-        end = datetime(year=2013, month=11, day=2, hour=0, minute=0, tzinfo=dateutil.tz.tzutc())
+        end = datetime(year=2013, month=11, day=2, hour=0, minute=0,
+                       tzinfo=dateutil.tz.tzutc())
 
         index = pd.date_range(start, end, freq='H')
 
@@ -2218,7 +2246,9 @@ class TestTimeSeries(tm.TestCase):
         series = series.tz_convert(local_timezone)
         result = series.resample('D', kind='period')
         # Create the expected series
-        expected_index = (pd.period_range(start=start, end=end, freq='D') - 1)  # Index is moved back a day with the timezone conversion from UTC to Pacific
+        # Index is moved back a day with the timezone conversion from UTC to
+        # Pacific
+        expected_index = (pd.period_range(start=start, end=end, freq='D') - 1)
         expected = pd.Series(1, index=expected_index)
         assert_series_equal(result, expected)
 
@@ -2243,21 +2273,20 @@ class TestTimeSeries(tm.TestCase):
     def test_timestamp_equality(self):
 
         # GH 11034
-        s = Series([Timestamp('2000-01-29 01:59:00'),'NaT'])
+        s = Series([Timestamp('2000-01-29 01:59:00'), 'NaT'])
         result = s != s
-        assert_series_equal(result, Series([False,True]))
+        assert_series_equal(result, Series([False, True]))
         result = s != s[0]
-        assert_series_equal(result, Series([False,True]))
+        assert_series_equal(result, Series([False, True]))
         result = s != s[1]
-        assert_series_equal(result, Series([True,True]))
+        assert_series_equal(result, Series([True, True]))
 
         result = s == s
-        assert_series_equal(result, Series([True,False]))
+        assert_series_equal(result, Series([True, False]))
         result = s == s[0]
-        assert_series_equal(result, Series([True,False]))
+        assert_series_equal(result, Series([True, False]))
         result = s == s[1]
-        assert_series_equal(result, Series([False,False]))
-
+        assert_series_equal(result, Series([False, False]))
 
 
 def _simple_ts(start, end, freq='D'):
@@ -2270,18 +2299,17 @@ class TestDatetimeIndex(tm.TestCase):
 
     def test_hash_error(self):
         index = date_range('20010101', periods=10)
-        with tm.assertRaisesRegexp(TypeError,
-                                   "unhashable type: %r" %
+        with tm.assertRaisesRegexp(TypeError, "unhashable type: %r" %
                                    type(index).__name__):
             hash(index)
 
     def test_stringified_slice_with_tz(self):
-        #GH2658
+        # GH2658
         import datetime
-        start=datetime.datetime.now()
-        idx=DatetimeIndex(start=start,freq="1d",periods=10)
-        df=DataFrame(lrange(10),index=idx)
-        df["2013-01-14 23:44:34.437768-05:00":] # no exception here
+        start = datetime.datetime.now()
+        idx = DatetimeIndex(start=start, freq="1d", periods=10)
+        df = DataFrame(lrange(10), index=idx)
+        df["2013-01-14 23:44:34.437768-05:00":]  # no exception here
 
     def test_append_join_nondatetimeindex(self):
         rng = date_range('1/1/2000', periods=10)
@@ -2293,7 +2321,6 @@ class TestDatetimeIndex(tm.TestCase):
         # it works
         rng.join(idx, how='outer')
 
-
     def test_astype(self):
         rng = date_range('1/1/2000', periods=10)
 
@@ -2303,20 +2330,25 @@ class TestDatetimeIndex(tm.TestCase):
         # with tz
         rng = date_range('1/1/2000', periods=10, tz='US/Eastern')
         result = rng.astype('datetime64[ns]')
-        expected = date_range('1/1/2000', periods=10, tz='US/Eastern').tz_convert('UTC').tz_localize(None)
+        expected = (date_range('1/1/2000', periods=10,
+                               tz='US/Eastern')
+                    .tz_convert('UTC').tz_localize(None))
         tm.assert_index_equal(result, expected)
 
         # BUG#10442 : testing astype(str) is correct for Series/DatetimeIndex
         result = pd.Series(pd.date_range('2012-01-01', periods=3)).astype(str)
-        expected = pd.Series(['2012-01-01', '2012-01-02', '2012-01-03'], dtype=object)
+        expected = pd.Series(
+            ['2012-01-01', '2012-01-02', '2012-01-03'], dtype=object)
         tm.assert_series_equal(result, expected)
 
-        result = Series(pd.date_range('2012-01-01', periods=3, tz='US/Eastern')).astype(str)
-        expected = Series(['2012-01-01 00:00:00-05:00', '2012-01-02 00:00:00-05:00', '2012-01-03 00:00:00-05:00'],
+        result = Series(pd.date_range('2012-01-01', periods=3,
+                                      tz='US/Eastern')).astype(str)
+        expected = Series(['2012-01-01 00:00:00-05:00',
+                           '2012-01-02 00:00:00-05:00',
+                           '2012-01-03 00:00:00-05:00'],
                           dtype=object)
         tm.assert_series_equal(result, expected)
 
-
     def test_to_period_nofreq(self):
         idx = DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-04'])
         self.assertRaises(ValueError, idx.to_period)
@@ -2324,7 +2356,8 @@ class TestDatetimeIndex(tm.TestCase):
         idx = DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-03'],
                             freq='infer')
         self.assertEqual(idx.freqstr, 'D')
-        expected = pd.PeriodIndex(['2000-01-01', '2000-01-02', '2000-01-03'], freq='D')
+        expected = pd.PeriodIndex(
+            ['2000-01-01', '2000-01-02', '2000-01-03'], freq='D')
         self.assertTrue(idx.to_period().equals(expected))
 
         # GH 7606
@@ -2379,13 +2412,12 @@ class TestDatetimeIndex(tm.TestCase):
 
         # non-conforming
         self.assertRaises(ValueError, DatetimeIndex,
-                          ['2000-01-01', '2000-01-02', '2000-01-04'],
-                          freq='D')
+                          ['2000-01-01', '2000-01-02', '2000-01-04'], freq='D')
 
-        self.assertRaises(ValueError, DatetimeIndex,
-                          start='2011-01-01', freq='b')
-        self.assertRaises(ValueError, DatetimeIndex,
-                          end='2011-01-01', freq='B')
+        self.assertRaises(ValueError, DatetimeIndex, start='2011-01-01',
+                          freq='b')
+        self.assertRaises(ValueError, DatetimeIndex, end='2011-01-01',
+                          freq='B')
         self.assertRaises(ValueError, DatetimeIndex, periods=10, freq='D')
 
     def test_constructor_datetime64_tzformat(self):
@@ -2394,42 +2426,50 @@ class TestDatetimeIndex(tm.TestCase):
         import pytz
         # ISO 8601 format results in pytz.FixedOffset
         for freq in ['AS', 'W-SUN']:
-            idx = date_range('2013-01-01T00:00:00-05:00', '2016-01-01T23:59:59-05:00', freq=freq)
+            idx = date_range('2013-01-01T00:00:00-05:00',
+                             '2016-01-01T23:59:59-05:00', freq=freq)
             expected = date_range('2013-01-01T00:00:00', '2016-01-01T23:59:59',
                                   freq=freq, tz=pytz.FixedOffset(-300))
             tm.assert_index_equal(idx, expected)
             # Unable to use `US/Eastern` because of DST
-            expected_i8 = date_range('2013-01-01T00:00:00', '2016-01-01T23:59:59',
-                                     freq=freq, tz='America/Lima')
+            expected_i8 = date_range('2013-01-01T00:00:00',
+                                     '2016-01-01T23:59:59', freq=freq,
+                                     tz='America/Lima')
             self.assert_numpy_array_equal(idx.asi8, expected_i8.asi8)
 
-            idx = date_range('2013-01-01T00:00:00+09:00', '2016-01-01T23:59:59+09:00', freq=freq)
+            idx = date_range('2013-01-01T00:00:00+09:00',
+                             '2016-01-01T23:59:59+09:00', freq=freq)
             expected = date_range('2013-01-01T00:00:00', '2016-01-01T23:59:59',
                                   freq=freq, tz=pytz.FixedOffset(540))
             tm.assert_index_equal(idx, expected)
-            expected_i8 = date_range('2013-01-01T00:00:00', '2016-01-01T23:59:59',
-                                     freq=freq, tz='Asia/Tokyo')
+            expected_i8 = date_range('2013-01-01T00:00:00',
+                                     '2016-01-01T23:59:59', freq=freq,
+                                     tz='Asia/Tokyo')
             self.assert_numpy_array_equal(idx.asi8, expected_i8.asi8)
 
         tm._skip_if_no_dateutil()
         from dateutil.tz import tzoffset
         # Non ISO 8601 format results in dateutil.tz.tzoffset
         for freq in ['AS', 'W-SUN']:
-            idx = date_range('2013/1/1 0:00:00-5:00', '2016/1/1 23:59:59-5:00', freq=freq)
+            idx = date_range('2013/1/1 0:00:00-5:00', '2016/1/1 23:59:59-5:00',
+                             freq=freq)
             expected = date_range('2013-01-01T00:00:00', '2016-01-01T23:59:59',
                                   freq=freq, tz=tzoffset(None, -18000))
             tm.assert_index_equal(idx, expected)
             # Unable to use `US/Eastern` because of DST
-            expected_i8 = date_range('2013-01-01T00:00:00', '2016-01-01T23:59:59',
-                                     freq=freq, tz='America/Lima')
+            expected_i8 = date_range('2013-01-01T00:00:00',
+                                     '2016-01-01T23:59:59', freq=freq,
+                                     tz='America/Lima')
             self.assert_numpy_array_equal(idx.asi8, expected_i8.asi8)
 
-            idx = date_range('2013/1/1 0:00:00+9:00', '2016/1/1 23:59:59+09:00', freq=freq)
+            idx = date_range('2013/1/1 0:00:00+9:00',
+                             '2016/1/1 23:59:59+09:00', freq=freq)
             expected = date_range('2013-01-01T00:00:00', '2016-01-01T23:59:59',
                                   freq=freq, tz=tzoffset(None, 32400))
             tm.assert_index_equal(idx, expected)
-            expected_i8 = date_range('2013-01-01T00:00:00', '2016-01-01T23:59:59',
-                                     freq=freq, tz='Asia/Tokyo')
+            expected_i8 = date_range('2013-01-01T00:00:00',
+                                     '2016-01-01T23:59:59', freq=freq,
+                                     tz='Asia/Tokyo')
             self.assert_numpy_array_equal(idx.asi8, expected_i8.asi8)
 
     def test_constructor_name(self):
@@ -2546,7 +2586,6 @@ class TestDatetimeIndex(tm.TestCase):
         exp = [f(x) for x in rng]
         tm.assert_almost_equal(result, exp)
 
-
     def test_iteration_preserves_tz(self):
 
         tm._skip_if_no_dateutil()
@@ -2560,7 +2599,8 @@ class TestDatetimeIndex(tm.TestCase):
             expected = index[i]
             self.assertEqual(result, expected)
 
-        index = date_range("2012-01-01", periods=3, freq='H', tz=dateutil.tz.tzoffset(None, -28800))
+        index = date_range("2012-01-01", periods=3, freq='H',
+                           tz=dateutil.tz.tzoffset(None, -28800))
 
         for i, ts in enumerate(index):
             result = ts
@@ -2569,14 +2609,14 @@ class TestDatetimeIndex(tm.TestCase):
             self.assertEqual(result, expected)
 
         # 9100
-        index = pd.DatetimeIndex(['2014-12-01 03:32:39.987000-08:00','2014-12-01 04:12:34.987000-08:00'])
+        index = pd.DatetimeIndex(['2014-12-01 03:32:39.987000-08:00',
+                                  '2014-12-01 04:12:34.987000-08:00'])
         for i, ts in enumerate(index):
             result = ts
             expected = index[i]
             self.assertEqual(result._repr_base, expected._repr_base)
             self.assertEqual(result, expected)
 
-
     def test_misc_coverage(self):
         rng = date_range('1/1/2000', periods=5)
         result = rng.groupby(rng.day)
@@ -2608,9 +2648,9 @@ class TestDatetimeIndex(tm.TestCase):
 
     def test_union_bug_1745(self):
         left = DatetimeIndex(['2012-05-11 15:19:49.695000'])
-        right = DatetimeIndex(['2012-05-29 13:04:21.322000',
-                               '2012-05-11 15:27:24.873000',
-                               '2012-05-11 15:31:05.350000'])
+        right = DatetimeIndex(
+            ['2012-05-29 13:04:21.322000', '2012-05-11 15:27:24.873000',
+             '2012-05-11 15:31:05.350000'])
 
         result = left.union(right)
         exp = DatetimeIndex(sorted(set(list(left)) | set(list(right))))
@@ -2634,7 +2674,7 @@ class TestDatetimeIndex(tm.TestCase):
         self.assertEqual(len(result), 0)
 
     def test_union_freq_both_none(self):
-        #GH11086
+        # GH11086
         expected = bdate_range('20150101', periods=10)
         expected.freq = None
 
@@ -2681,8 +2721,9 @@ class TestDatetimeIndex(tm.TestCase):
                 with tm.assert_produces_warning(PerformanceWarning):
                     s = klass([Timestamp('2000-1-1'), Timestamp('2000-2-1')])
                     result = s + Series([pd.offsets.DateOffset(years=1),
-                                        pd.offsets.MonthEnd()])
-                    exp = klass([Timestamp('2001-1-1'), Timestamp('2000-2-29')])
+                                         pd.offsets.MonthEnd()])
+                    exp = klass([Timestamp('2001-1-1'), Timestamp('2000-2-29')
+                                 ])
                     assert_func(result, exp)
 
                     # same offset
@@ -2691,36 +2732,45 @@ class TestDatetimeIndex(tm.TestCase):
                     exp = klass([Timestamp('2001-1-1'), Timestamp('2001-2-1')])
                     assert_func(result, exp)
 
-            s = klass([Timestamp('2000-01-05 00:15:00'), Timestamp('2000-01-31 00:23:00'),
-                       Timestamp('2000-01-01'), Timestamp('2000-03-31'),
-                       Timestamp('2000-02-29'), Timestamp('2000-12-31')])
+            s = klass([Timestamp('2000-01-05 00:15:00'), Timestamp(
+                '2000-01-31 00:23:00'), Timestamp('2000-01-01'), Timestamp(
+                    '2000-03-31'), Timestamp('2000-02-29'), Timestamp(
+                        '2000-12-31')])
 
-            #DateOffset relativedelta fastpath
+            # DateOffset relativedelta fastpath
             relative_kwargs = [('years', 2), ('months', 5), ('days', 3),
-                            ('hours', 5), ('minutes', 10), ('seconds', 2),
-                            ('microseconds', 5)]
+                               ('hours', 5), ('minutes', 10), ('seconds', 2),
+                               ('microseconds', 5)]
             for i, kwd in enumerate(relative_kwargs):
                 op = pd.DateOffset(**dict([kwd]))
                 assert_func(klass([x + op for x in s]), s + op)
                 assert_func(klass([x - op for x in s]), s - op)
-                op = pd.DateOffset(**dict(relative_kwargs[:i+1]))
+                op = pd.DateOffset(**dict(relative_kwargs[:i + 1]))
                 assert_func(klass([x + op for x in s]), s + op)
                 assert_func(klass([x - op for x in s]), s - op)
 
-
             # assert these are equal on a piecewise basis
-            offsets = ['YearBegin', ('YearBegin', {'month': 5}),
-                       'YearEnd', ('YearEnd', {'month': 5}),
-                       'MonthBegin', 'MonthEnd', 'Week', ('Week', {'weekday': 3}),
-                       'BusinessDay', 'BDay', 'QuarterEnd', 'QuarterBegin',
-                       'CustomBusinessDay', 'CDay', 'CBMonthEnd','CBMonthBegin',
-                       'BMonthBegin', 'BMonthEnd', 'BusinessHour', 'BYearBegin',
-                       'BYearEnd','BQuarterBegin', ('LastWeekOfMonth', {'weekday':2}),
-                       ('FY5253Quarter', {'qtr_with_extra_week': 1, 'startingMonth': 1,
-                                          'weekday': 2, 'variation': 'nearest'}),
-                       ('FY5253',{'weekday': 0, 'startingMonth': 2, 'variation': 'nearest'}),
-                       ('WeekOfMonth', {'weekday': 2, 'week': 2}), 'Easter',
-                       ('DateOffset', {'day': 4}), ('DateOffset', {'month': 5})]
+            offsets = ['YearBegin', ('YearBegin', {'month': 5}), 'YearEnd',
+                       ('YearEnd', {'month': 5}), 'MonthBegin', 'MonthEnd',
+                       'Week', ('Week', {
+                           'weekday': 3
+                       }), 'BusinessDay', 'BDay', 'QuarterEnd', 'QuarterBegin',
+                       'CustomBusinessDay', 'CDay', 'CBMonthEnd',
+                       'CBMonthBegin', 'BMonthBegin', 'BMonthEnd',
+                       'BusinessHour', 'BYearBegin', 'BYearEnd',
+                       'BQuarterBegin', ('LastWeekOfMonth', {
+                           'weekday': 2
+                       }), ('FY5253Quarter', {'qtr_with_extra_week': 1,
+                                              'startingMonth': 1,
+                                              'weekday': 2,
+                                              'variation': 'nearest'}),
+                       ('FY5253', {'weekday': 0,
+                                   'startingMonth': 2,
+                                   'variation':
+                                   'nearest'}), ('WeekOfMonth', {'weekday': 2,
+                                                                 'week': 2}),
+                       'Easter', ('DateOffset', {'day': 4}),
+                       ('DateOffset', {'month': 5})]
 
             with warnings.catch_warnings(record=True):
                 for normalize in (True, False):
@@ -2732,10 +2782,12 @@ class TestDatetimeIndex(tm.TestCase):
                             kwargs = {}
 
                         for n in [0, 5]:
-                            if (do in ['WeekOfMonth','LastWeekOfMonth',
-                                       'FY5253Quarter','FY5253'] and n == 0):
+                            if (do in ['WeekOfMonth', 'LastWeekOfMonth',
+                                       'FY5253Quarter', 'FY5253'] and n == 0):
                                 continue
-                            op = getattr(pd.offsets,do)(n, normalize=normalize, **kwargs)
+                            op = getattr(pd.offsets, do)(n,
+                                                         normalize=normalize,
+                                                         **kwargs)
                             assert_func(klass([x + op for x in s]), s + op)
                             assert_func(klass([x - op for x in s]), s - op)
                             assert_func(klass([op + x for x in s]), op + s)
@@ -2832,20 +2884,22 @@ class TestDatetimeIndex(tm.TestCase):
         result = dt.round('s')
         self.assertEqual(result, dt)
 
-        dti = date_range('20130101 09:10:11',periods=5).tz_localize('UTC').tz_convert('US/Eastern')
+        dti = date_range('20130101 09:10:11',
+                         periods=5).tz_localize('UTC').tz_convert('US/Eastern')
         result = dti.round('D')
-        expected = date_range('20130101',periods=5).tz_localize('US/Eastern')
+        expected = date_range('20130101', periods=5).tz_localize('US/Eastern')
         tm.assert_index_equal(result, expected)
 
         result = dti.round('s')
         tm.assert_index_equal(result, dti)
 
         # invalid
-        for freq in ['Y','M','foobar']:
-            self.assertRaises(ValueError, lambda : dti.round(freq))
+        for freq in ['Y', 'M', 'foobar']:
+            self.assertRaises(ValueError, lambda: dti.round(freq))
 
     def test_insert(self):
-        idx = DatetimeIndex(['2000-01-04', '2000-01-01', '2000-01-02'], name='idx')
+        idx = DatetimeIndex(
+            ['2000-01-04', '2000-01-01', '2000-01-02'], name='idx')
 
         result = idx.insert(2, datetime(2000, 1, 5))
         exp = DatetimeIndex(['2000-01-04', '2000-01-01', '2000-01-05',
@@ -2854,7 +2908,8 @@ class TestDatetimeIndex(tm.TestCase):
 
         # insertion of non-datetime should coerce to object index
         result = idx.insert(1, 'inserted')
-        expected = Index([datetime(2000, 1, 4), 'inserted', datetime(2000, 1, 1),
+        expected = Index([datetime(2000, 1, 4), 'inserted',
+                          datetime(2000, 1, 1),
                           datetime(2000, 1, 2)], name='idx')
         self.assertNotIsInstance(result, DatetimeIndex)
         tm.assert_index_equal(result, expected)
@@ -2869,10 +2924,14 @@ class TestDatetimeIndex(tm.TestCase):
                                     '2000-04-30'], name='idx', freq='M')
 
         # reset freq to None
-        expected_1_nofreq = DatetimeIndex(['2000-01-31', '2000-01-31', '2000-02-29',
-                                           '2000-03-31'], name='idx', freq=None)
-        expected_3_nofreq = DatetimeIndex(['2000-01-31', '2000-02-29', '2000-03-31',
-                                           '2000-01-02'], name='idx', freq=None)
+        expected_1_nofreq = DatetimeIndex(['2000-01-31', '2000-01-31',
+                                           '2000-02-29',
+                                           '2000-03-31'], name='idx',
+                                          freq=None)
+        expected_3_nofreq = DatetimeIndex(['2000-01-31', '2000-02-29',
+                                           '2000-03-31',
+                                           '2000-01-02'], name='idx',
+                                          freq=None)
 
         cases = [(0, datetime(1999, 12, 31), expected_0),
                  (-3, datetime(1999, 12, 31), expected_0),
@@ -2898,7 +2957,8 @@ class TestDatetimeIndex(tm.TestCase):
         tm._skip_if_no_pytz()
         import pytz
 
-        idx = date_range('1/1/2000', periods=3, freq='D', tz='Asia/Tokyo', name='idx')
+        idx = date_range('1/1/2000', periods=3, freq='D', tz='Asia/Tokyo',
+                         name='idx')
         with tm.assertRaises(ValueError):
             result = idx.insert(3, pd.Timestamp('2000-01-04'))
         with tm.assertRaises(ValueError):
@@ -2906,12 +2966,16 @@ class TestDatetimeIndex(tm.TestCase):
         with tm.assertRaises(ValueError):
             result = idx.insert(3, pd.Timestamp('2000-01-04', tz='US/Eastern'))
         with tm.assertRaises(ValueError):
-            result = idx.insert(3, datetime(2000, 1, 4, tzinfo=pytz.timezone('US/Eastern')))
+            result = idx.insert(3,
+                                datetime(2000, 1, 4,
+                                         tzinfo=pytz.timezone('US/Eastern')))
 
         for tz in ['US/Pacific', 'Asia/Singapore']:
-            idx = date_range('1/1/2000 09:00', periods=6, freq='H', tz=tz, name='idx')
+            idx = date_range('1/1/2000 09:00', periods=6, freq='H', tz=tz,
+                             name='idx')
             # preserve freq
-            expected = date_range('1/1/2000 09:00', periods=7, freq='H', tz=tz, name='idx')
+            expected = date_range('1/1/2000 09:00', periods=7, freq='H', tz=tz,
+                                  name='idx')
             for d in [pd.Timestamp('2000-01-01 15:00', tz=tz),
                       pytz.timezone(tz).localize(datetime(2000, 1, 1, 15))]:
 
@@ -2921,10 +2985,12 @@ class TestDatetimeIndex(tm.TestCase):
                 self.assertEqual(result.freq, expected.freq)
                 self.assertEqual(result.tz, expected.tz)
 
-            expected = DatetimeIndex(['2000-01-01 09:00', '2000-01-01 10:00', '2000-01-01 11:00',
-                                      '2000-01-01 12:00', '2000-01-01 13:00', '2000-01-01 14:00',
+            expected = DatetimeIndex(['2000-01-01 09:00', '2000-01-01 10:00',
+                                      '2000-01-01 11:00',
+                                      '2000-01-01 12:00', '2000-01-01 13:00',
+                                      '2000-01-01 14:00',
                                       '2000-01-01 10:00'], name='idx',
-                                      tz=tz, freq=None)
+                                     tz=tz, freq=None)
             # reset freq to None
             for d in [pd.Timestamp('2000-01-01 10:00', tz=tz),
                       pytz.timezone(tz).localize(datetime(2000, 1, 1, 10))]:
@@ -2938,16 +3004,20 @@ class TestDatetimeIndex(tm.TestCase):
         idx = date_range(start='2000-01-01', periods=5, freq='M', name='idx')
 
         # prserve freq
-        expected_0 = date_range(start='2000-02-01', periods=4, freq='M', name='idx')
-        expected_4 = date_range(start='2000-01-01', periods=4, freq='M', name='idx')
+        expected_0 = date_range(start='2000-02-01', periods=4, freq='M',
+                                name='idx')
+        expected_4 = date_range(start='2000-01-01', periods=4, freq='M',
+                                name='idx')
 
         # reset freq to None
         expected_1 = DatetimeIndex(['2000-01-31', '2000-03-31', '2000-04-30',
                                     '2000-05-31'], freq=None, name='idx')
 
-        cases ={0: expected_0, -5: expected_0,
-                -1: expected_4, 4: expected_4,
-                1: expected_1}
+        cases = {0: expected_0,
+                 -5: expected_0,
+                 -1: expected_4,
+                 4: expected_4,
+                 1: expected_1}
         for n, expected in compat.iteritems(cases):
             result = idx.delete(n)
             self.assertTrue(result.equals(expected))
@@ -2959,8 +3029,8 @@ class TestDatetimeIndex(tm.TestCase):
             result = idx.delete(5)
 
         for tz in [None, 'Asia/Tokyo', 'US/Pacific']:
-            idx = date_range(start='2000-01-01 09:00', periods=10,
-                             freq='H', name='idx', tz=tz)
+            idx = date_range(start='2000-01-01 09:00', periods=10, freq='H',
+                             name='idx', tz=tz)
 
             expected = date_range(start='2000-01-01 10:00', periods=9,
                                   freq='H', name='idx', tz=tz)
@@ -2982,17 +3052,19 @@ class TestDatetimeIndex(tm.TestCase):
         idx = date_range(start='2000-01-01', periods=10, freq='D', name='idx')
 
         # prserve freq
-        expected_0_2 = date_range(start='2000-01-04', periods=7, freq='D', name='idx')
-        expected_7_9 = date_range(start='2000-01-01', periods=7, freq='D', name='idx')
+        expected_0_2 = date_range(start='2000-01-04', periods=7, freq='D',
+                                  name='idx')
+        expected_7_9 = date_range(start='2000-01-01', periods=7, freq='D',
+                                  name='idx')
 
         # reset freq to None
         expected_3_5 = DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-03',
-                                    '2000-01-07', '2000-01-08', '2000-01-09',
-                                    '2000-01-10'], freq=None, name='idx')
+                                      '2000-01-07', '2000-01-08', '2000-01-09',
+                                      '2000-01-10'], freq=None, name='idx')
 
-        cases ={(0, 1, 2): expected_0_2,
-                (7, 8, 9): expected_7_9,
-                (3, 4, 5): expected_3_5}
+        cases = {(0, 1, 2): expected_0_2,
+                 (7, 8, 9): expected_7_9,
+                 (3, 4, 5): expected_3_5}
         for n, expected in compat.iteritems(cases):
             result = idx.delete(n)
             self.assertTrue(result.equals(expected))
@@ -3005,11 +3077,12 @@ class TestDatetimeIndex(tm.TestCase):
             self.assertEqual(result.freq, expected.freq)
 
         for tz in [None, 'Asia/Tokyo', 'US/Pacific']:
-            ts = pd.Series(1, index=pd.date_range('2000-01-01 09:00', periods=10,
-                                                  freq='H', name='idx', tz=tz))
+            ts = pd.Series(1, index=pd.date_range(
+                '2000-01-01 09:00', periods=10, freq='H', name='idx', tz=tz))
             # preserve freq
             result = ts.drop(ts.index[:5]).index
-            expected = pd.date_range('2000-01-01 14:00', periods=5, freq='H', name='idx', tz=tz)
+            expected = pd.date_range('2000-01-01 14:00', periods=5, freq='H',
+                                     name='idx', tz=tz)
             self.assertTrue(result.equals(expected))
             self.assertEqual(result.name, expected.name)
             self.assertEqual(result.freq, expected.freq)
@@ -3017,9 +3090,10 @@ class TestDatetimeIndex(tm.TestCase):
 
             # reset freq to None
             result = ts.drop(ts.index[[1, 3, 5, 7, 9]]).index
-            expected = DatetimeIndex(['2000-01-01 09:00', '2000-01-01 11:00', '2000-01-01 13:00',
+            expected = DatetimeIndex(['2000-01-01 09:00', '2000-01-01 11:00',
+                                      '2000-01-01 13:00',
                                       '2000-01-01 15:00', '2000-01-01 17:00'],
-                                      freq=None, name='idx', tz=tz)
+                                     freq=None, name='idx', tz=tz)
             self.assertTrue(result.equals(expected))
             self.assertEqual(result.name, expected.name)
             self.assertEqual(result.freq, expected.freq)
@@ -3030,8 +3104,9 @@ class TestDatetimeIndex(tm.TestCase):
                  datetime(2010, 1, 1, 17), datetime(2010, 1, 1, 21)]
 
         for tz in [None, 'US/Eastern', 'Asia/Tokyo']:
-            idx = DatetimeIndex(start='2010-01-01 09:00', end='2010-02-01 09:00',
-                                freq='H', tz=tz, name='idx')
+            idx = DatetimeIndex(start='2010-01-01 09:00',
+                                end='2010-02-01 09:00', freq='H', tz=tz,
+                                name='idx')
             expected = DatetimeIndex(dates, freq=None, name='idx', tz=tz)
 
             taken1 = idx.take([5, 6, 8, 12])
@@ -3106,8 +3181,9 @@ class TestDatetimeIndex(tm.TestCase):
         self.assertTrue((result == expected).all())
 
     def test_does_not_convert_mixed_integer(self):
-        df = tm.makeCustomDataframe(10, 10, data_gen_f=lambda *args, **kwargs:
-                                    randn(), r_idx_type='i', c_idx_type='dt')
+        df = tm.makeCustomDataframe(10, 10,
+                                    data_gen_f=lambda *args, **kwargs: randn(),
+                                    r_idx_type='i', c_idx_type='dt')
         cols = df.columns.join(df.index, how='outer')
         joined = cols.join(df.columns)
         self.assertEqual(cols.dtype, np.dtype('O'))
@@ -3142,13 +3218,14 @@ class TestDatetimeIndex(tm.TestCase):
         index = pd.DatetimeIndex(dt, freq=freq, name='time')
         self.assert_index_parameters(index)
 
-        new_index = pd.DatetimeIndex(start=index[0], end=index[-1], freq=index.freq)
+        new_index = pd.DatetimeIndex(start=index[0], end=index[-1],
+                                     freq=index.freq)
         self.assert_index_parameters(new_index)
 
     def test_join_with_period_index(self):
-        df = tm.makeCustomDataframe(10, 10, data_gen_f=lambda *args:
-                                    np.random.randint(2), c_idx_type='p',
-                                    r_idx_type='dt')
+        df = tm.makeCustomDataframe(
+            10, 10, data_gen_f=lambda *args: np.random.randint(2),
+            c_idx_type='p', r_idx_type='dt')
         s = df.iloc[:5, 0]
         joins = 'left', 'right', 'inner', 'outer'
 
@@ -3158,8 +3235,8 @@ class TestDatetimeIndex(tm.TestCase):
                 df.columns.join(s.index, how=join)
 
     def test_factorize(self):
-        idx1 = DatetimeIndex(['2014-01', '2014-01', '2014-02',
-                              '2014-02', '2014-03', '2014-03'])
+        idx1 = DatetimeIndex(['2014-01', '2014-01', '2014-02', '2014-02',
+                              '2014-03', '2014-03'])
 
         exp_arr = np.array([0, 0, 1, 1, 2, 2])
         exp_idx = DatetimeIndex(['2014-01', '2014-02', '2014-03'])
@@ -3181,7 +3258,7 @@ class TestDatetimeIndex(tm.TestCase):
         self.assertTrue(idx.equals(exp_idx))
 
         idx2 = pd.DatetimeIndex(['2014-03', '2014-03', '2014-02', '2014-01',
-                               '2014-03', '2014-01'])
+                                 '2014-03', '2014-01'])
 
         exp_arr = np.array([2, 2, 1, 0, 2, 0])
         exp_idx = DatetimeIndex(['2014-01', '2014-02', '2014-03'])
@@ -3202,7 +3279,6 @@ class TestDatetimeIndex(tm.TestCase):
         self.assert_numpy_array_equal(arr, exp_arr)
         self.assertTrue(idx.equals(idx3))
 
-
     def test_slice_with_negative_step(self):
         ts = Series(np.arange(20),
                     date_range('2014-01-01', periods=20, freq='MS'))
@@ -3219,10 +3295,14 @@ class TestDatetimeIndex(tm.TestCase):
         assert_slices_equivalent(SLC[:Timestamp('2014-10-01'):-1], SLC[:8:-1])
         assert_slices_equivalent(SLC[:'2014-10-01':-1], SLC[:8:-1])
 
-        assert_slices_equivalent(SLC['2015-02-01':'2014-10-01':-1], SLC[13:8:-1])
-        assert_slices_equivalent(SLC[Timestamp('2015-02-01'):Timestamp('2014-10-01'):-1], SLC[13:8:-1])
-        assert_slices_equivalent(SLC['2015-02-01':Timestamp('2014-10-01'):-1], SLC[13:8:-1])
-        assert_slices_equivalent(SLC[Timestamp('2015-02-01'):'2014-10-01':-1], SLC[13:8:-1])
+        assert_slices_equivalent(SLC['2015-02-01':'2014-10-01':-1],
+                                 SLC[13:8:-1])
+        assert_slices_equivalent(SLC[Timestamp('2015-02-01'):Timestamp(
+            '2014-10-01'):-1], SLC[13:8:-1])
+        assert_slices_equivalent(SLC['2015-02-01':Timestamp('2014-10-01'):-1],
+                                 SLC[13:8:-1])
+        assert_slices_equivalent(SLC[Timestamp('2015-02-01'):'2014-10-01':-1],
+                                 SLC[13:8:-1])
 
         assert_slices_equivalent(SLC['2014-10-01':'2015-02-01':-1], SLC[:0])
 
@@ -3237,7 +3317,6 @@ class TestDatetimeIndex(tm.TestCase):
                                 lambda: ts.ix[::0])
 
 
-
 class TestDatetime64(tm.TestCase):
     """
     Also test support for datetime64[ns] in Series / DataFrame
@@ -3249,8 +3328,7 @@ class TestDatetime64(tm.TestCase):
         self.series = Series(rand(len(dti)), dti)
 
     def test_datetimeindex_accessors(self):
-        dti = DatetimeIndex(
-            freq='D', start=datetime(1998, 1, 1), periods=365)
+        dti = DatetimeIndex(freq='D', start=datetime(1998, 1, 1), periods=365)
 
         self.assertEqual(dti.year[0], 1998)
         self.assertEqual(dti.month[0], 1)
@@ -3309,15 +3387,16 @@ class TestDatetime64(tm.TestCase):
         self.assertEqual(len(dti.is_year_start), 365)
         self.assertEqual(len(dti.is_year_end), 365)
 
-        dti = DatetimeIndex(
-            freq='BQ-FEB', start=datetime(1998, 1, 1), periods=4)
+        dti = DatetimeIndex(freq='BQ-FEB', start=datetime(1998, 1, 1),
+                            periods=4)
 
         self.assertEqual(sum(dti.is_quarter_start), 0)
         self.assertEqual(sum(dti.is_quarter_end), 4)
         self.assertEqual(sum(dti.is_year_start), 0)
         self.assertEqual(sum(dti.is_year_end), 1)
 
-        # Ensure is_start/end accessors throw ValueError for CustomBusinessDay, CBD requires np >= 1.7
+        # Ensure is_start/end accessors throw ValueError for CustomBusinessDay,
+        # CBD requires np >= 1.7
         bday_egypt = offsets.CustomBusinessDay(weekmask='Sun Mon Tue Wed Thu')
         dti = date_range(datetime(2013, 4, 30), periods=5, freq=bday_egypt)
         self.assertRaises(ValueError, lambda: dti.is_month_start)
@@ -3363,7 +3442,6 @@ class TestDatetime64(tm.TestCase):
         for ts, value in tests:
             self.assertEqual(ts, value)
 
-
     def test_nanosecond_field(self):
         dti = DatetimeIndex(np.arange(10))
 
@@ -3425,8 +3503,8 @@ class TestDatetime64(tm.TestCase):
         arr = to_datetime(['1/1/2005', '1/2/2005', '1/3/2005', '2005-01-04'])
         idx5 = DatetimeIndex(arr)
 
-        arr = to_datetime(
-            ['1/1/2005', '1/2/2005', 'Jan 3, 2005', '2005-01-04'])
+        arr = to_datetime(['1/1/2005', '1/2/2005', 'Jan 3, 2005', '2005-01-04'
+                           ])
         idx6 = DatetimeIndex(arr)
 
         idx7 = DatetimeIndex(['12/05/2007', '25/01/2008'], dayfirst=True)
@@ -3470,8 +3548,7 @@ class TestDatetime64(tm.TestCase):
     def test_dayfirst(self):
         # GH 5917
         arr = ['10/02/2014', '11/02/2014', '12/02/2014']
-        expected = DatetimeIndex([datetime(2014, 2, 10),
-                                  datetime(2014, 2, 11),
+        expected = DatetimeIndex([datetime(2014, 2, 10), datetime(2014, 2, 11),
                                   datetime(2014, 2, 12)])
         idx1 = DatetimeIndex(arr, dayfirst=True)
         idx2 = DatetimeIndex(np.array(arr), dayfirst=True)
@@ -3530,11 +3607,17 @@ class TestDatetime64(tm.TestCase):
 
         # 11314
         # with tz
-        index = date_range(datetime(2015, 10, 1), datetime(2015,10,1,23), freq='H', tz='US/Eastern')
+        index = date_range(datetime(2015, 10, 1), datetime(
+            2015, 10, 1, 23), freq='H', tz='US/Eastern')
         df = DataFrame(np.random.randn(24, 1), columns=['a'], index=index)
-        new_index = date_range(datetime(2015, 10, 2), datetime(2015,10,2,23), freq='H', tz='US/Eastern')
-        result = df.set_index(new_index)
-        self.assertEqual(new_index.freq,index.freq)
+        new_index = date_range(datetime(2015, 10, 2),
+                               datetime(2015, 10, 2, 23),
+                               freq='H', tz='US/Eastern')
+
+        # TODO: unused?
+        result = df.set_index(new_index)  # noqa
+
+        self.assertEqual(new_index.freq, index.freq)
 
     def test_datetimeindex_union_join_empty(self):
         dti = DatetimeIndex(start='1/1/2001', end='2/1/2001', freq='D')
@@ -3576,40 +3659,42 @@ class TestDatetime64(tm.TestCase):
         # GH 7523
 
         # unique
-        df = DataFrame(np.arange(4.,dtype='float64'),
-                       index=[datetime(2001, 1, i, 10, 00) for i in [1,2,3,4]])
-        result = df.ix[datetime(2001,1,1,10):]
-        assert_frame_equal(result,df)
-        result = df.ix[:datetime(2001,1,4,10)]
-        assert_frame_equal(result,df)
-        result = df.ix[datetime(2001,1,1,10):datetime(2001,1,4,10)]
-        assert_frame_equal(result,df)
-
-        result = df.ix[datetime(2001,1,1,11):]
+        df = DataFrame(np.arange(4., dtype='float64'),
+                       index=[datetime(2001, 1, i, 10, 00)
+                              for i in [1, 2, 3, 4]])
+        result = df.ix[datetime(2001, 1, 1, 10):]
+        assert_frame_equal(result, df)
+        result = df.ix[:datetime(2001, 1, 4, 10)]
+        assert_frame_equal(result, df)
+        result = df.ix[datetime(2001, 1, 1, 10):datetime(2001, 1, 4, 10)]
+        assert_frame_equal(result, df)
+
+        result = df.ix[datetime(2001, 1, 1, 11):]
         expected = df.iloc[1:]
-        assert_frame_equal(result,expected)
+        assert_frame_equal(result, expected)
         result = df.ix['20010101 11':]
-        assert_frame_equal(result,expected)
+        assert_frame_equal(result, expected)
 
         # duplicates
-        df = pd.DataFrame(np.arange(5.,dtype='float64'),
-                          index=[datetime(2001, 1, i, 10, 00) for i in [1,2,2,3,4]])
-
-        result = df.ix[datetime(2001,1,1,10):]
-        assert_frame_equal(result,df)
-        result = df.ix[:datetime(2001,1,4,10)]
-        assert_frame_equal(result,df)
-        result = df.ix[datetime(2001,1,1,10):datetime(2001,1,4,10)]
-        assert_frame_equal(result,df)
-
-        result = df.ix[datetime(2001,1,1,11):]
+        df = pd.DataFrame(np.arange(5., dtype='float64'),
+                          index=[datetime(2001, 1, i, 10, 00)
+                                 for i in [1, 2, 2, 3, 4]])
+
+        result = df.ix[datetime(2001, 1, 1, 10):]
+        assert_frame_equal(result, df)
+        result = df.ix[:datetime(2001, 1, 4, 10)]
+        assert_frame_equal(result, df)
+        result = df.ix[datetime(2001, 1, 1, 10):datetime(2001, 1, 4, 10)]
+        assert_frame_equal(result, df)
+
+        result = df.ix[datetime(2001, 1, 1, 11):]
         expected = df.iloc[1:]
-        assert_frame_equal(result,expected)
+        assert_frame_equal(result, expected)
         result = df.ix['20010101 11':]
-        assert_frame_equal(result,expected)
+        assert_frame_equal(result, expected)
 
-class TestSeriesDatetime64(tm.TestCase):
 
+class TestSeriesDatetime64(tm.TestCase):
     def setUp(self):
         self.series = Series(date_range('1/1/2000', periods=10))
 
@@ -3639,7 +3724,7 @@ class TestSeriesDatetime64(tm.TestCase):
         expected = (self.series >= left) & (self.series <= right)
         assert_series_equal(result, expected)
 
-    #----------------------------------------------------------------------
+    # ---------------------------------------------------------------------
     # NaT support
 
     def test_NaT_scalar(self):
@@ -3672,7 +3757,8 @@ class TestSeriesDatetime64(tm.TestCase):
 
     def test_intercept_astype_object(self):
 
-        # this test no longer makes sense as series is by default already M8[ns]
+        # this test no longer makes sense as series is by default already
+        # M8[ns]
         expected = self.series.astype('object')
 
         df = DataFrame({'a': self.series,
@@ -3681,8 +3767,7 @@ class TestSeriesDatetime64(tm.TestCase):
         result = df.values.squeeze()
         self.assertTrue((result[:, 0] == expected.values).all())
 
-        df = DataFrame({'a': self.series,
-                        'b': ['foo'] * len(self.series)})
+        df = DataFrame({'a': self.series, 'b': ['foo'] * len(self.series)})
 
         result = df.values.squeeze()
         self.assertTrue((result[:, 0] == expected.values).all())
@@ -3703,16 +3788,19 @@ class TestSeriesDatetime64(tm.TestCase):
 
             # if target has the same name, it is preserved
             rng2 = date_range('5/15/2000', '6/20/2000', freq='D', name='idx')
-            expected2 = date_range('6/1/2000', '6/20/2000', freq='D', name='idx')
+            expected2 = date_range('6/1/2000', '6/20/2000', freq='D',
+                                   name='idx')
 
             # if target name is different, it will be reset
             rng3 = date_range('5/15/2000', '6/20/2000', freq='D', name='other')
-            expected3 = date_range('6/1/2000', '6/20/2000', freq='D', name=None)
+            expected3 = date_range('6/1/2000', '6/20/2000', freq='D',
+                                   name=None)
 
             rng4 = date_range('7/1/2000', '7/31/2000', freq='D', name='idx')
             expected4 = DatetimeIndex([], name='idx')
 
-            for (rng, expected) in [(rng2, expected2), (rng3, expected3), (rng4, expected4)]:
+            for (rng, expected) in [(rng2, expected2), (rng3, expected3),
+                                    (rng4, expected4)]:
                 result = base.intersection(rng)
                 self.assertTrue(result.equals(expected))
                 self.assertEqual(result.name, expected.name)
@@ -3720,22 +3808,29 @@ class TestSeriesDatetime64(tm.TestCase):
                 self.assertEqual(result.tz, expected.tz)
 
             # non-monotonic
-            base = DatetimeIndex(['2011-01-05', '2011-01-04', '2011-01-02', '2011-01-03'],
-                                tz=tz, name='idx')
+            base = DatetimeIndex(['2011-01-05', '2011-01-04',
+                                  '2011-01-02', '2011-01-03'],
+                                 tz=tz, name='idx')
 
-            rng2 = DatetimeIndex(['2011-01-04', '2011-01-02', '2011-02-02', '2011-02-03'],
+            rng2 = DatetimeIndex(['2011-01-04', '2011-01-02',
+                                  '2011-02-02', '2011-02-03'],
                                  tz=tz, name='idx')
-            expected2 = DatetimeIndex(['2011-01-04', '2011-01-02'], tz=tz, name='idx')
+            expected2 = DatetimeIndex(
+                ['2011-01-04', '2011-01-02'], tz=tz, name='idx')
 
-            rng3 = DatetimeIndex(['2011-01-04', '2011-01-02', '2011-02-02', '2011-02-03'],
+            rng3 = DatetimeIndex(['2011-01-04', '2011-01-02',
+                                  '2011-02-02', '2011-02-03'],
                                  tz=tz, name='other')
-            expected3 = DatetimeIndex(['2011-01-04', '2011-01-02'], tz=tz, name=None)
+            expected3 = DatetimeIndex(
+                ['2011-01-04', '2011-01-02'], tz=tz, name=None)
 
             # GH 7880
-            rng4 = date_range('7/1/2000', '7/31/2000', freq='D', tz=tz, name='idx')
+            rng4 = date_range('7/1/2000', '7/31/2000', freq='D', tz=tz,
+                              name='idx')
             expected4 = DatetimeIndex([], tz=tz, name='idx')
 
-            for (rng, expected) in [(rng2, expected2), (rng3, expected3), (rng4, expected4)]:
+            for (rng, expected) in [(rng2, expected2), (rng3, expected3),
+                                    (rng4, expected4)]:
                 result = base.intersection(rng)
                 self.assertTrue(result.equals(expected))
                 self.assertEqual(result.name, expected.name)
@@ -3758,25 +3853,36 @@ class TestSeriesDatetime64(tm.TestCase):
         self.assertEqual(rng[0], ex_first)
 
     def test_date_range_businesshour(self):
-        idx = DatetimeIndex(['2014-07-04 09:00', '2014-07-04 10:00', '2014-07-04 11:00',
-                             '2014-07-04 12:00', '2014-07-04 13:00', '2014-07-04 14:00',
-                             '2014-07-04 15:00', '2014-07-04 16:00'], freq='BH')
+        idx = DatetimeIndex(['2014-07-04 09:00', '2014-07-04 10:00',
+                             '2014-07-04 11:00',
+                             '2014-07-04 12:00', '2014-07-04 13:00',
+                             '2014-07-04 14:00',
+                             '2014-07-04 15:00', '2014-07-04 16:00'],
+                            freq='BH')
         rng = date_range('2014-07-04 09:00', '2014-07-04 16:00', freq='BH')
         tm.assert_index_equal(idx, rng)
 
-        idx = DatetimeIndex(['2014-07-04 16:00', '2014-07-07 09:00'], freq='BH')
+        idx = DatetimeIndex(
+            ['2014-07-04 16:00', '2014-07-07 09:00'], freq='BH')
         rng = date_range('2014-07-04 16:00', '2014-07-07 09:00', freq='BH')
         tm.assert_index_equal(idx, rng)
 
-        idx = DatetimeIndex(['2014-07-04 09:00', '2014-07-04 10:00', '2014-07-04 11:00',
-                             '2014-07-04 12:00', '2014-07-04 13:00', '2014-07-04 14:00',
+        idx = DatetimeIndex(['2014-07-04 09:00', '2014-07-04 10:00',
+                             '2014-07-04 11:00',
+                             '2014-07-04 12:00', '2014-07-04 13:00',
+                             '2014-07-04 14:00',
                              '2014-07-04 15:00', '2014-07-04 16:00',
-                             '2014-07-07 09:00', '2014-07-07 10:00', '2014-07-07 11:00',
-                             '2014-07-07 12:00', '2014-07-07 13:00', '2014-07-07 14:00',
+                             '2014-07-07 09:00', '2014-07-07 10:00',
+                             '2014-07-07 11:00',
+                             '2014-07-07 12:00', '2014-07-07 13:00',
+                             '2014-07-07 14:00',
                              '2014-07-07 15:00', '2014-07-07 16:00',
-                             '2014-07-08 09:00', '2014-07-08 10:00', '2014-07-08 11:00',
-                             '2014-07-08 12:00', '2014-07-08 13:00', '2014-07-08 14:00',
-                             '2014-07-08 15:00', '2014-07-08 16:00'], freq='BH')
+                             '2014-07-08 09:00', '2014-07-08 10:00',
+                             '2014-07-08 11:00',
+                             '2014-07-08 12:00', '2014-07-08 13:00',
+                             '2014-07-08 14:00',
+                             '2014-07-08 15:00', '2014-07-08 16:00'],
+                            freq='BH')
         rng = date_range('2014-07-04 09:00', '2014-07-08 16:00', freq='BH')
         tm.assert_index_equal(idx, rng)
 
@@ -3793,13 +3899,13 @@ class TestSeriesDatetime64(tm.TestCase):
 
 
 class TestTimestamp(tm.TestCase):
-
     def test_class_ops_pytz(self):
         tm._skip_if_no_pytz()
         from pytz import timezone
 
         def compare(x, y):
-            self.assertEqual(int(Timestamp(x).value / 1e9), int(Timestamp(y).value / 1e9))
+            self.assertEqual(int(Timestamp(x).value / 1e9),
+                             int(Timestamp(y).value / 1e9))
 
         compare(Timestamp.now(), datetime.now())
         compare(Timestamp.now('UTC'), datetime.now(timezone('UTC')))
@@ -3820,13 +3926,14 @@ class TestTimestamp(tm.TestCase):
         tm._skip_if_no_dateutil()
         from dateutil.tz import tzutc
 
-        def compare(x,y):
-            self.assertEqual(int(np.round(Timestamp(x).value/1e9)), int(np.round(Timestamp(y).value/1e9)))
+        def compare(x, y):
+            self.assertEqual(int(np.round(Timestamp(x).value / 1e9)),
+                             int(np.round(Timestamp(y).value / 1e9)))
 
-        compare(Timestamp.now(),datetime.now())
+        compare(Timestamp.now(), datetime.now())
         compare(Timestamp.now('UTC'), datetime.now(tzutc()))
-        compare(Timestamp.utcnow(),datetime.utcnow())
-        compare(Timestamp.today(),datetime.today())
+        compare(Timestamp.utcnow(), datetime.utcnow())
+        compare(Timestamp.today(), datetime.today())
         current_time = calendar.timegm(datetime.now().utctimetuple())
         compare(Timestamp.utcfromtimestamp(current_time),
                 datetime.utcfromtimestamp(current_time))
@@ -3847,7 +3954,7 @@ class TestTimestamp(tm.TestCase):
         self.assertEqual(stamp.nanosecond, 500)
 
     def test_unit(self):
-        def check(val,unit=None,h=1,s=1,us=0):
+        def check(val, unit=None, h=1, s=1, us=0):
             stamp = Timestamp(val, unit=unit)
             self.assertEqual(stamp.year, 2000)
             self.assertEqual(stamp.month, 1)
@@ -3868,34 +3975,34 @@ class TestTimestamp(tm.TestCase):
         days = (ts - Timestamp('1970-01-01')).days
 
         check(val)
-        check(val/long(1000),unit='us')
-        check(val/long(1000000),unit='ms')
-        check(val/long(1000000000),unit='s')
-        check(days,unit='D',h=0)
+        check(val / long(1000), unit='us')
+        check(val / long(1000000), unit='ms')
+        check(val / long(1000000000), unit='s')
+        check(days, unit='D', h=0)
 
         # using truediv, so these are like floats
         if compat.PY3:
-            check((val+500000)/long(1000000000),unit='s',us=500)
-            check((val+500000000)/long(1000000000),unit='s',us=500000)
-            check((val+500000)/long(1000000),unit='ms',us=500)
+            check((val + 500000) / long(1000000000), unit='s', us=500)
+            check((val + 500000000) / long(1000000000), unit='s', us=500000)
+            check((val + 500000) / long(1000000), unit='ms', us=500)
 
         # get chopped in py2
         else:
-            check((val+500000)/long(1000000000),unit='s')
-            check((val+500000000)/long(1000000000),unit='s')
-            check((val+500000)/long(1000000),unit='ms')
+            check((val + 500000) / long(1000000000), unit='s')
+            check((val + 500000000) / long(1000000000), unit='s')
+            check((val + 500000) / long(1000000), unit='ms')
 
         # ok
-        check((val+500000)/long(1000),unit='us',us=500)
-        check((val+500000000)/long(1000000),unit='ms',us=500000)
+        check((val + 500000) / long(1000), unit='us', us=500)
+        check((val + 500000000) / long(1000000), unit='ms', us=500000)
 
         # floats
-        check(val/1000.0 + 5,unit='us',us=5)
-        check(val/1000.0 + 5000,unit='us',us=5000)
-        check(val/1000000.0 + 0.5,unit='ms',us=500)
-        check(val/1000000.0 + 0.005,unit='ms',us=5)
-        check(val/1000000000.0 + 0.5,unit='s',us=500000)
-        check(days + 0.5,unit='D',h=12)
+        check(val / 1000.0 + 5, unit='us', us=5)
+        check(val / 1000.0 + 5000, unit='us', us=5000)
+        check(val / 1000000.0 + 0.5, unit='ms', us=500)
+        check(val / 1000000.0 + 0.005, unit='ms', us=5)
+        check(val / 1000000000.0 + 0.5, unit='s', us=500000)
+        check(days + 0.5, unit='D', h=12)
 
         # nan
         result = Timestamp(np.nan)
@@ -3920,25 +4027,25 @@ class TestTimestamp(tm.TestCase):
         base = Timestamp('20140101 00:00:00')
 
         result = Timestamp(base.value + pd.Timedelta('5ms').value)
-        self.assertEqual(result,Timestamp(str(base) + ".005000"))
-        self.assertEqual(result.microsecond,5000)
+        self.assertEqual(result, Timestamp(str(base) + ".005000"))
+        self.assertEqual(result.microsecond, 5000)
 
         result = Timestamp(base.value + pd.Timedelta('5us').value)
-        self.assertEqual(result,Timestamp(str(base) + ".000005"))
-        self.assertEqual(result.microsecond,5)
+        self.assertEqual(result, Timestamp(str(base) + ".000005"))
+        self.assertEqual(result.microsecond, 5)
 
         result = Timestamp(base.value + pd.Timedelta('5ns').value)
-        self.assertEqual(result,Timestamp(str(base) + ".000000005"))
-        self.assertEqual(result.nanosecond,5)
-        self.assertEqual(result.microsecond,0)
+        self.assertEqual(result, Timestamp(str(base) + ".000000005"))
+        self.assertEqual(result.nanosecond, 5)
+        self.assertEqual(result.microsecond, 0)
 
         result = Timestamp(base.value + pd.Timedelta('6ms 5us').value)
-        self.assertEqual(result,Timestamp(str(base) + ".006005"))
-        self.assertEqual(result.microsecond,5+6*1000)
+        self.assertEqual(result, Timestamp(str(base) + ".006005"))
+        self.assertEqual(result.microsecond, 5 + 6 * 1000)
 
         result = Timestamp(base.value + pd.Timedelta('200ms 5us').value)
-        self.assertEqual(result,Timestamp(str(base) + ".200005"))
-        self.assertEqual(result.microsecond,5+200*1000)
+        self.assertEqual(result, Timestamp(str(base) + ".200005"))
+        self.assertEqual(result.microsecond, 5 + 200 * 1000)
 
     def test_comparison(self):
         # 5-18-2012 00:00:00.000
@@ -3979,7 +4086,7 @@ class TestTimestamp(tm.TestCase):
         self.assertFalse(val == 1)
         self.assertFalse(val == long(1))
         self.assertFalse(val == [])
-        self.assertFalse(val == {'foo' : 1})
+        self.assertFalse(val == {'foo': 1})
         self.assertFalse(val == np.float64(1))
         self.assertFalse(val == np.int64(1))
 
@@ -3988,12 +4095,12 @@ class TestTimestamp(tm.TestCase):
         self.assertTrue(val != 1)
         self.assertTrue(val != long(1))
         self.assertTrue(val != [])
-        self.assertTrue(val != {'foo' : 1})
+        self.assertTrue(val != {'foo': 1})
         self.assertTrue(val != np.float64(1))
         self.assertTrue(val != np.int64(1))
 
         # ops testing
-        df = DataFrame(randn(5,2))
+        df = DataFrame(randn(5, 2))
         a = df[0]
         b = Series(randn(5))
         b.name = Timestamp('2000-01-01')
@@ -4075,7 +4182,7 @@ class TestTimestamp(tm.TestCase):
 
     def test_frequency_misc(self):
         self.assertEqual(frequencies.get_freq_group('T'),
-                          frequencies.FreqGroup.FR_MIN)
+                         frequencies.FreqGroup.FR_MIN)
 
         code, stride = frequencies.get_freq_code(offsets.Hour())
         self.assertEqual(code, frequencies.FreqGroup.FR_HR)
@@ -4112,8 +4219,12 @@ class TestTimestamp(tm.TestCase):
         rhs = Timestamp('now')
         nat = Timestamp('nat')
 
-        ops = {'gt': 'lt', 'lt': 'gt', 'ge': 'le', 'le': 'ge', 'eq': 'eq',
-            'ne': 'ne'}
+        ops = {'gt': 'lt',
+               'lt': 'gt',
+               'ge': 'le',
+               'le': 'ge',
+               'eq': 'eq',
+               'ne': 'ne'}
 
         for left, right in ops.items():
             left_f = getattr(operator, left)
@@ -4164,7 +4275,6 @@ class TestTimestamp(tm.TestCase):
 
 
 class TestSlicing(tm.TestCase):
-
     def test_slice_year(self):
         dti = DatetimeIndex(freq='B', start=datetime(2005, 1, 1), periods=500)
 
@@ -4281,28 +4391,35 @@ class TestSlicing(tm.TestCase):
 
         # GH 4758
         # partial string indexing with a multi-index buggy
-        df = DataFrame({'ACCOUNT':["ACCT1", "ACCT1", "ACCT1", "ACCT2"],
-                        'TICKER':["ABC", "MNP", "XYZ", "XYZ"],
-                        'val':[1,2,3,4]},
-                       index=date_range("2013-06-19 09:30:00", periods=4, freq='5T'))
+        df = DataFrame({'ACCOUNT': ["ACCT1", "ACCT1", "ACCT1", "ACCT2"],
+                        'TICKER': ["ABC", "MNP", "XYZ", "XYZ"],
+                        'val': [1, 2, 3, 4]},
+                       index=date_range("2013-06-19 09:30:00",
+                                        periods=4, freq='5T'))
         df_multi = df.set_index(['ACCOUNT', 'TICKER'], append=True)
 
-        expected = DataFrame([[1]],index=Index(['ABC'],name='TICKER'),columns=['val'])
+        expected = DataFrame([
+            [1]
+        ], index=Index(['ABC'], name='TICKER'), columns=['val'])
         result = df_multi.loc[('2013-06-19 09:30:00', 'ACCT1')]
         assert_frame_equal(result, expected)
 
-        expected = df_multi.loc[(pd.Timestamp('2013-06-19 09:30:00', tz=None), 'ACCT1', 'ABC')]
+        expected = df_multi.loc[
+            (pd.Timestamp('2013-06-19 09:30:00', tz=None), 'ACCT1', 'ABC')]
         result = df_multi.loc[('2013-06-19 09:30:00', 'ACCT1', 'ABC')]
         assert_series_equal(result, expected)
 
-        # this is a KeyError as we don't do partial string selection on multi-levels
+        # this is a KeyError as we don't do partial string selection on
+        # multi-levels
         def f():
             df_multi.loc[('2013-06-19', 'ACCT1', 'ABC')]
+
         self.assertRaises(KeyError, f)
 
         # GH 4294
         # partial slice on a series mi
-        s = pd.DataFrame(randn(1000, 1000), index=pd.date_range('2000-1-1', periods=1000)).stack()
+        s = pd.DataFrame(randn(1000, 1000), index=pd.date_range(
+            '2000-1-1', periods=1000)).stack()
 
         s2 = s[:-1].copy()
         expected = s2['2000-1-4']
@@ -4330,8 +4447,8 @@ class TestSlicing(tm.TestCase):
 
         self.assert_numpy_array_equal(rng, values)
 
-        rng = date_range(
-            '1/1/2000 08:15', periods=n, normalize=False, freq='B')
+        rng = date_range('1/1/2000 08:15', periods=n, normalize=False,
+                         freq='B')
         the_time = time(8, 15)
         for val in rng:
             self.assertEqual(val.time(), the_time)
@@ -4427,8 +4544,7 @@ class TestSlicing(tm.TestCase):
     def test_min_max_series(self):
         rng = date_range('1/1/2000', periods=10, freq='4h')
         lvls = ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C']
-        df = DataFrame({'TS': rng, 'V': np.random.randn(len(rng)),
-                        'L': lvls})
+        df = DataFrame({'TS': rng, 'V': np.random.randn(len(rng)), 'L': lvls})
 
         result = df.TS.max()
         exp = Timestamp(df.TS.iat[-1])
@@ -4441,8 +4557,7 @@ class TestSlicing(tm.TestCase):
         self.assertEqual(result, exp)
 
     def test_from_M8_structured(self):
-        dates = [(datetime(2012, 9, 9, 0, 0),
-                 datetime(2012, 9, 8, 15, 10))]
+        dates = [(datetime(2012, 9, 9, 0, 0), datetime(2012, 9, 8, 15, 10))]
         arr = np.array(dates,
                        dtype=[('Date', 'M8[us]'), ('Forecasting', 'M8[us]')])
         df = DataFrame(arr)
@@ -4462,8 +4577,7 @@ class TestSlicing(tm.TestCase):
 
         dates = date_range('1/1/2000', periods=4)
         levels = [dates, [0, 1]]
-        labels = [[0, 0, 1, 1, 2, 2, 3, 3],
-                  [0, 1, 0, 1, 0, 1, 0, 1]]
+        labels = [[0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 0, 1, 0, 1, 0, 1]]
 
         index = MultiIndex(levels=levels, labels=labels)
 
@@ -4479,18 +4593,14 @@ class TestSlicing(tm.TestCase):
         self.assertTrue(df.x1.dtype == 'M8[ns]')
 
     def test_date_range_fy5252(self):
-        dr = date_range(start="2013-01-01",
-                           periods=2,
-                           freq=offsets.FY5253(startingMonth=1,
-                                               weekday=3,
-                                               variation="nearest"))
+        dr = date_range(start="2013-01-01", periods=2, freq=offsets.FY5253(
+            startingMonth=1, weekday=3, variation="nearest"))
         self.assertEqual(dr[0], Timestamp('2013-01-31'))
         self.assertEqual(dr[1], Timestamp('2014-01-30'))
 
     def test_partial_slice_doesnt_require_monotonicity(self):
         # For historical reasons.
-        s = pd.Series(np.arange(10),
-                      pd.date_range('2014-01-01', periods=10))
+        s = pd.Series(np.arange(10), pd.date_range('2014-01-01', periods=10))
 
         nonmonotonic = s[[3, 5, 4]]
         expected = nonmonotonic.iloc[:0]
@@ -4509,15 +4619,16 @@ class TimeConversionFormats(tm.TestCase):
     def test_to_datetime_format(self):
         values = ['1/1/2000', '1/2/2000', '1/3/2000']
 
-        results1 = [ Timestamp('20000101'), Timestamp('20000201'),
-                     Timestamp('20000301') ]
-        results2 = [ Timestamp('20000101'), Timestamp('20000102'),
-                     Timestamp('20000103') ]
-        for vals, expecteds in [ (values, (Index(results1), Index(results2))),
-                                 (Series(values),(Series(results1), Series(results2))),
-                                 (values[0], (results1[0], results2[0])),
-                                 (values[1], (results1[1], results2[1])),
-                                 (values[2], (results1[2], results2[2])) ]:
+        results1 = [Timestamp('20000101'), Timestamp('20000201'),
+                    Timestamp('20000301')]
+        results2 = [Timestamp('20000101'), Timestamp('20000102'),
+                    Timestamp('20000103')]
+        for vals, expecteds in [(values, (Index(results1), Index(results2))),
+                                (Series(values),
+                                 (Series(results1), Series(results2))),
+                                (values[0], (results1[0], results2[0])),
+                                (values[1], (results1[1], results2[1])),
+                                (values[2], (results1[2], results2[2]))]:
 
             for i, fmt in enumerate(['%d/%m/%Y', '%m/%d/%Y']):
                 result = to_datetime(vals, format=fmt)
@@ -4531,52 +4642,55 @@ class TimeConversionFormats(tm.TestCase):
                     self.assertTrue(result.equals(expected))
 
     def test_to_datetime_format_YYYYMMDD(self):
-        s = Series([19801222,19801222] + [19810105]*5)
-        expected = Series([ Timestamp(x) for x in s.apply(str) ])
+        s = Series([19801222, 19801222] + [19810105] * 5)
+        expected = Series([Timestamp(x) for x in s.apply(str)])
 
-        result = to_datetime(s,format='%Y%m%d')
+        result = to_datetime(s, format='%Y%m%d')
         assert_series_equal(result, expected)
 
-        result = to_datetime(s.apply(str),format='%Y%m%d')
+        result = to_datetime(s.apply(str), format='%Y%m%d')
         assert_series_equal(result, expected)
 
         # with NaT
-        expected = Series([Timestamp("19801222"),Timestamp("19801222")] + [Timestamp("19810105")]*5)
+        expected = Series([Timestamp("19801222"), Timestamp("19801222")] +
+                          [Timestamp("19810105")] * 5)
         expected[2] = np.nan
         s[2] = np.nan
 
-        result = to_datetime(s,format='%Y%m%d')
+        result = to_datetime(s, format='%Y%m%d')
         assert_series_equal(result, expected)
 
         # string with NaT
         s = s.apply(str)
         s[2] = 'nat'
-        result = to_datetime(s,format='%Y%m%d')
+        result = to_datetime(s, format='%Y%m%d')
         assert_series_equal(result, expected)
 
         # coercion
         # GH 7930
         s = Series([20121231, 20141231, 99991231])
-        result = pd.to_datetime(s,format='%Y%m%d',errors='ignore')
-        expected = np.array([ datetime(2012,12,31), datetime(2014,12,31), datetime(9999,12,31) ], dtype=object)
+        result = pd.to_datetime(s, format='%Y%m%d', errors='ignore')
+        expected = np.array([datetime(2012, 12, 31), datetime(
+            2014, 12, 31), datetime(9999, 12, 31)], dtype=object)
         self.assert_numpy_array_equal(result, expected)
 
-        result = pd.to_datetime(s,format='%Y%m%d', errors='coerce')
-        expected = Series(['20121231','20141231','NaT'],dtype='M8[ns]')
+        result = pd.to_datetime(s, format='%Y%m%d', errors='coerce')
+        expected = Series(['20121231', '20141231', 'NaT'], dtype='M8[ns]')
         assert_series_equal(result, expected)
 
     # GH 10178
     def test_to_datetime_format_integer(self):
         s = Series([2000, 2001, 2002])
-        expected = Series([ Timestamp(x) for x in s.apply(str) ])
+        expected = Series([Timestamp(x) for x in s.apply(str)])
 
-        result = to_datetime(s,format='%Y')
+        result = to_datetime(s, format='%Y')
         assert_series_equal(result, expected)
 
         s = Series([200001, 200105, 200206])
-        expected = Series([ Timestamp(x[:4] + '-' + x[4:]) for x in s.apply(str) ])
+        expected = Series([Timestamp(x[:4] + '-' + x[4:]) for x in s.apply(str)
+                           ])
 
-        result = to_datetime(s,format='%Y%m')
+        result = to_datetime(s, format='%Y%m')
         assert_series_equal(result, expected)
 
     def test_to_datetime_format_microsecond(self):
@@ -4588,13 +4702,19 @@ class TimeConversionFormats(tm.TestCase):
 
     def test_to_datetime_format_time(self):
         data = [
-               ['01/10/2010 15:20', '%m/%d/%Y %H:%M', Timestamp('2010-01-10 15:20')],
-             ['01/10/2010 05:43', '%m/%d/%Y %I:%M', Timestamp('2010-01-10 05:43')],
-             ['01/10/2010 13:56:01', '%m/%d/%Y %H:%M:%S', Timestamp('2010-01-10 13:56:01')]#,
-             #['01/10/2010 08:14 PM', '%m/%d/%Y %I:%M %p', Timestamp('2010-01-10 20:14')],
-             #['01/10/2010 07:40 AM', '%m/%d/%Y %I:%M %p', Timestamp('2010-01-10 07:40')],
-             #['01/10/2010 09:12:56 AM', '%m/%d/%Y %I:%M:%S %p', Timestamp('2010-01-10 09:12:56')]
-            ]
+            ['01/10/2010 15:20', '%m/%d/%Y %H:%M',
+             Timestamp('2010-01-10 15:20')],
+            ['01/10/2010 05:43', '%m/%d/%Y %I:%M',
+             Timestamp('2010-01-10 05:43')],
+            ['01/10/2010 13:56:01', '%m/%d/%Y %H:%M:%S',
+             Timestamp('2010-01-10 13:56:01')]  # ,
+            # ['01/10/2010 08:14 PM', '%m/%d/%Y %I:%M %p',
+            #  Timestamp('2010-01-10 20:14')],
+            # ['01/10/2010 07:40 AM', '%m/%d/%Y %I:%M %p',
+            #  Timestamp('2010-01-10 07:40')],
+            # ['01/10/2010 09:12:56 AM', '%m/%d/%Y %I:%M:%S %p',
+            #  Timestamp('2010-01-10 09:12:56')]
+        ]
         for s, format, dt in data:
             self.assertEqual(to_datetime(s, format=format), dt)
 
@@ -4607,9 +4727,10 @@ class TimeConversionFormats(tm.TestCase):
         if sys.version_info < (2, 7):
             raise nose.SkipTest('on python version < 2.7')
 
-        s = Series(['19MAY11','foobar19MAY11','19MAY11:00:00:00','19MAY11 00:00:00Z'])
-        result = to_datetime(s,format='%d%b%y',exact=False)
-        expected = to_datetime(s.str.extract('(\d+\w+\d+)'),format='%d%b%y')
+        s = Series(['19MAY11', 'foobar19MAY11', '19MAY11:00:00:00',
+                    '19MAY11 00:00:00Z'])
+        result = to_datetime(s, format='%d%b%y', exact=False)
+        expected = to_datetime(s.str.extract('(\d+\w+\d+)'), format='%d%b%y')
         assert_series_equal(result, expected)
 
     def test_parse_nanoseconds_with_formula(self):
@@ -4620,25 +4741,24 @@ class TimeConversionFormats(tm.TestCase):
                   "2012-01-01 09:00:00.000001",
                   "2012-01-01 09:00:00.001",
                   "2012-01-01 09:00:00.001000",
-                  "2012-01-01 09:00:00.001000000",
-                  ]:
+                  "2012-01-01 09:00:00.001000000", ]:
             expected = pd.to_datetime(v)
-            result =  pd.to_datetime(v, format="%Y-%m-%d %H:%M:%S.%f")
-            self.assertEqual(result,expected)
+            result = pd.to_datetime(v, format="%Y-%m-%d %H:%M:%S.%f")
+            self.assertEqual(result, expected)
 
     def test_to_datetime_format_weeks(self):
         data = [
-                ['2009324', '%Y%W%w', Timestamp('2009-08-13')],
-                ['2013020', '%Y%U%w', Timestamp('2013-01-13')]
-            ]
+            ['2009324', '%Y%W%w', Timestamp('2009-08-13')],
+            ['2013020', '%Y%U%w', Timestamp('2013-01-13')]
+        ]
         for s, format, dt in data:
             self.assertEqual(to_datetime(s, format=format), dt)
 
+
 class TestToDatetimeInferFormat(tm.TestCase):
     def test_to_datetime_infer_datetime_format_consistent_format(self):
-        time_series = pd.Series(
-            pd.date_range('20000101', periods=50, freq='H')
-        )
+        time_series = pd.Series(pd.date_range('20000101', periods=50,
+                                              freq='H'))
 
         test_formats = [
             '%m-%d-%Y',
@@ -4648,16 +4768,13 @@ class TestToDatetimeInferFormat(tm.TestCase):
 
         for test_format in test_formats:
             s_as_dt_strings = time_series.apply(
-                lambda x: x.strftime(test_format)
-            )
+                lambda x: x.strftime(test_format))
 
             with_format = pd.to_datetime(s_as_dt_strings, format=test_format)
-            no_infer = pd.to_datetime(
-                s_as_dt_strings, infer_datetime_format=False
-            )
-            yes_infer = pd.to_datetime(
-                s_as_dt_strings, infer_datetime_format=True
-            )
+            no_infer = pd.to_datetime(s_as_dt_strings,
+                                      infer_datetime_format=False)
+            yes_infer = pd.to_datetime(s_as_dt_strings,
+                                       infer_datetime_format=True)
 
             # Whether the format is explicitly passed, it is inferred, or
             # it is not inferred, the results should all be the same
@@ -4665,11 +4782,10 @@ class TestToDatetimeInferFormat(tm.TestCase):
             self.assert_numpy_array_equal(no_infer, yes_infer)
 
     def test_to_datetime_infer_datetime_format_inconsistent_format(self):
-        test_series = pd.Series(
-            np.array([
-                '01/01/2011 00:00:00',
-                '01-02-2011 00:00:00',
-                '2011-01-03T00:00:00',
+        test_series = pd.Series(np.array([
+            '01/01/2011 00:00:00',
+            '01-02-2011 00:00:00',
+            '2011-01-03T00:00:00',
         ]))
 
         # When the format is inconsistent, infer_datetime_format should just
@@ -4679,11 +4795,10 @@ class TestToDatetimeInferFormat(tm.TestCase):
             pd.to_datetime(test_series, infer_datetime_format=True)
         )
 
-        test_series = pd.Series(
-            np.array([
-                'Jan/01/2011',
-                'Feb/01/2011',
-                'Mar/01/2011',
+        test_series = pd.Series(np.array([
+            'Jan/01/2011',
+            'Feb/01/2011',
+            'Mar/01/2011',
         ]))
 
         self.assert_numpy_array_equal(
@@ -4692,12 +4807,11 @@ class TestToDatetimeInferFormat(tm.TestCase):
         )
 
     def test_to_datetime_infer_datetime_format_series_with_nans(self):
-        test_series = pd.Series(
-            np.array([
-                '01/01/2011 00:00:00',
-                np.nan,
-                '01/03/2011 00:00:00',
-                np.nan,
+        test_series = pd.Series(np.array([
+            '01/01/2011 00:00:00',
+            np.nan,
+            '01/03/2011 00:00:00',
+            np.nan,
         ]))
 
         self.assert_numpy_array_equal(
@@ -4706,13 +4820,12 @@ class TestToDatetimeInferFormat(tm.TestCase):
         )
 
     def test_to_datetime_infer_datetime_format_series_starting_with_nans(self):
-        test_series = pd.Series(
-            np.array([
-                np.nan,
-                np.nan,
-                '01/01/2011 00:00:00',
-                '01/02/2011 00:00:00',
-                '01/03/2011 00:00:00',
+        test_series = pd.Series(np.array([
+            np.nan,
+            np.nan,
+            '01/01/2011 00:00:00',
+            '01/02/2011 00:00:00',
+            '01/03/2011 00:00:00',
         ]))
 
         self.assert_numpy_array_equal(
@@ -4723,14 +4836,13 @@ class TestToDatetimeInferFormat(tm.TestCase):
 
 class TestGuessDatetimeFormat(tm.TestCase):
     def test_guess_datetime_format_with_parseable_formats(self):
-        dt_string_to_format = (
-            ('20111230', '%Y%m%d'),
-            ('2011-12-30', '%Y-%m-%d'),
-            ('30-12-2011', '%d-%m-%Y'),
-            ('2011-12-30 00:00:00', '%Y-%m-%d %H:%M:%S'),
-            ('2011-12-30T00:00:00', '%Y-%m-%dT%H:%M:%S'),
-            ('2011-12-30 00:00:00.000000', '%Y-%m-%d %H:%M:%S.%f'),
-        )
+        dt_string_to_format = (('20111230', '%Y%m%d'),
+                               ('2011-12-30', '%Y-%m-%d'),
+                               ('30-12-2011', '%d-%m-%Y'),
+                               ('2011-12-30 00:00:00', '%Y-%m-%d %H:%M:%S'),
+                               ('2011-12-30T00:00:00', '%Y-%m-%dT%H:%M:%S'),
+                               ('2011-12-30 00:00:00.000000',
+                                '%Y-%m-%d %H:%M:%S.%f'), )
 
         for dt_string, dt_format in dt_string_to_format:
             self.assertEqual(
@@ -4754,11 +4866,9 @@ class TestGuessDatetimeFormat(tm.TestCase):
         # case these wont be parsed properly (dateutil can't parse them)
         _skip_if_has_locale()
 
-        dt_string_to_format = (
-            ('30/Dec/2011', '%d/%b/%Y'),
-            ('30/December/2011', '%d/%B/%Y'),
-            ('30/Dec/2011 00:00:00', '%d/%b/%Y %H:%M:%S'),
-        )
+        dt_string_to_format = (('30/Dec/2011', '%d/%b/%Y'),
+                               ('30/December/2011', '%d/%B/%Y'),
+                               ('30/Dec/2011 00:00:00', '%d/%b/%Y %H:%M:%S'), )
 
         for dt_string, dt_format in dt_string_to_format:
             self.assertEqual(
@@ -4786,14 +4896,12 @@ class TestGuessDatetimeFormat(tm.TestCase):
 
     def test_guess_datetime_format_nopadding(self):
         # GH 11142
-        dt_string_to_format = (
-            ('2011-1-1', '%Y-%m-%d'),
-            ('30-1-2011', '%d-%m-%Y'),
-            ('1/1/2011', '%m/%d/%Y'),
-            ('2011-1-1 00:00:00', '%Y-%m-%d %H:%M:%S'),
-            ('2011-1-1 0:0:0', '%Y-%m-%d %H:%M:%S'),
-            ('2011-1-3T00:00:0', '%Y-%m-%dT%H:%M:%S')
-        )
+        dt_string_to_format = (('2011-1-1', '%Y-%m-%d'),
+                               ('30-1-2011', '%d-%m-%Y'),
+                               ('1/1/2011', '%m/%d/%Y'),
+                               ('2011-1-1 00:00:00', '%Y-%m-%d %H:%M:%S'),
+                               ('2011-1-1 0:0:0', '%Y-%m-%d %H:%M:%S'),
+                               ('2011-1-3T00:00:0', '%Y-%m-%dT%H:%M:%S'))
 
         for dt_string, dt_format in dt_string_to_format:
             self.assertEqual(
@@ -4801,7 +4909,6 @@ class TestGuessDatetimeFormat(tm.TestCase):
                 dt_format
             )
 
-
     def test_guess_datetime_format_for_array(self):
         expected_format = '%Y-%m-%d %H:%M:%S.%f'
         dt_string = datetime(2011, 12, 30, 0, 0, 0).strftime(expected_format)
@@ -4819,13 +4926,12 @@ class TestGuessDatetimeFormat(tm.TestCase):
             )
 
         format_for_string_of_nans = tools._guess_datetime_format_for_array(
-            np.array([np.nan, np.nan, np.nan], dtype='O')
-        )
+            np.array(
+                [np.nan, np.nan, np.nan], dtype='O'))
         self.assertTrue(format_for_string_of_nans is None)
 
 
 class TestTimestampToJulianDate(tm.TestCase):
-
     def test_compare_1700(self):
         r = Timestamp('1700-06-23').to_julian_date()
         self.assertEqual(r, 2342145.5)
@@ -4849,98 +4955,96 @@ class TestTimestampToJulianDate(tm.TestCase):
 
 class TestDateTimeIndexToJulianDate(tm.TestCase):
     def test_1700(self):
-        r1 = Float64Index([2345897.5,
-                           2345898.5,
-                           2345899.5,
-                           2345900.5,
+        r1 = Float64Index([2345897.5, 2345898.5, 2345899.5, 2345900.5,
                            2345901.5])
-        r2 = date_range(start=Timestamp('1710-10-01'),
-                        periods=5,
+        r2 = date_range(start=Timestamp('1710-10-01'), periods=5,
                         freq='D').to_julian_date()
         self.assertIsInstance(r2, Float64Index)
         tm.assert_index_equal(r1, r2)
 
     def test_2000(self):
-        r1 = Float64Index([2451601.5,
-                           2451602.5,
-                           2451603.5,
-                           2451604.5,
+        r1 = Float64Index([2451601.5, 2451602.5, 2451603.5, 2451604.5,
                            2451605.5])
-        r2 = date_range(start=Timestamp('2000-02-27'),
-                        periods=5,
+        r2 = date_range(start=Timestamp('2000-02-27'), periods=5,
                         freq='D').to_julian_date()
         self.assertIsInstance(r2, Float64Index)
         tm.assert_index_equal(r1, r2)
 
     def test_hour(self):
-        r1 = Float64Index([2451601.5,
-                           2451601.5416666666666666,
-                           2451601.5833333333333333,
-                           2451601.625,
-                           2451601.6666666666666666])
-        r2 = date_range(start=Timestamp('2000-02-27'),
-                        periods=5,
+        r1 = Float64Index(
+            [2451601.5, 2451601.5416666666666666, 2451601.5833333333333333,
+             2451601.625, 2451601.6666666666666666])
+        r2 = date_range(start=Timestamp('2000-02-27'), periods=5,
                         freq='H').to_julian_date()
         self.assertIsInstance(r2, Float64Index)
         tm.assert_index_equal(r1, r2)
 
     def test_minute(self):
-        r1 = Float64Index([2451601.5,
-                           2451601.5006944444444444,
-                           2451601.5013888888888888,
-                           2451601.5020833333333333,
-                           2451601.5027777777777777])
-        r2 = date_range(start=Timestamp('2000-02-27'),
-                        periods=5,
+        r1 = Float64Index(
+            [2451601.5, 2451601.5006944444444444, 2451601.5013888888888888,
+             2451601.5020833333333333, 2451601.5027777777777777])
+        r2 = date_range(start=Timestamp('2000-02-27'), periods=5,
                         freq='T').to_julian_date()
         self.assertIsInstance(r2, Float64Index)
         tm.assert_index_equal(r1, r2)
 
     def test_second(self):
-        r1 = Float64Index([2451601.5,
-                           2451601.500011574074074,
-                           2451601.5000231481481481,
-                           2451601.5000347222222222,
-                           2451601.5000462962962962])
-        r2 = date_range(start=Timestamp('2000-02-27'),
-                        periods=5,
+        r1 = Float64Index(
+            [2451601.5, 2451601.500011574074074, 2451601.5000231481481481,
+             2451601.5000347222222222, 2451601.5000462962962962])
+        r2 = date_range(start=Timestamp('2000-02-27'), periods=5,
                         freq='S').to_julian_date()
         self.assertIsInstance(r2, Float64Index)
         tm.assert_index_equal(r1, r2)
 
-class TestDaysInMonth(tm.TestCase):
 
+class TestDaysInMonth(tm.TestCase):
     def test_coerce_deprecation(self):
 
         # deprecation of coerce
         with tm.assert_produces_warning(FutureWarning):
             to_datetime('2015-02-29', coerce=True)
         with tm.assert_produces_warning(FutureWarning):
-            self.assertRaises(ValueError, lambda : to_datetime('2015-02-29', coerce=False))
+            self.assertRaises(ValueError,
+                              lambda: to_datetime('2015-02-29', coerce=False))
 
         # multiple arguments
-        for e, c in zip(['raise','ignore','coerce'],[True,False]):
+        for e, c in zip(['raise', 'ignore', 'coerce'], [True, False]):
             with tm.assert_produces_warning(FutureWarning):
-                self.assertRaises(TypeError, lambda : to_datetime('2015-02-29', errors=e, coerce=c))
+                self.assertRaises(TypeError,
+                                  lambda: to_datetime('2015-02-29', errors=e,
+                                                      coerce=c))
 
     # tests for issue #10154
     def test_day_not_in_month_coerce(self):
         self.assertTrue(isnull(to_datetime('2015-02-29', errors='coerce')))
-        self.assertTrue(isnull(to_datetime('2015-02-29', format="%Y-%m-%d", errors='coerce')))
-        self.assertTrue(isnull(to_datetime('2015-02-32', format="%Y-%m-%d", errors='coerce')))
-        self.assertTrue(isnull(to_datetime('2015-04-31', format="%Y-%m-%d", errors='coerce')))
+        self.assertTrue(isnull(to_datetime('2015-02-29', format="%Y-%m-%d",
+                                           errors='coerce')))
+        self.assertTrue(isnull(to_datetime('2015-02-32', format="%Y-%m-%d",
+                                           errors='coerce')))
+        self.assertTrue(isnull(to_datetime('2015-04-31', format="%Y-%m-%d",
+                                           errors='coerce')))
 
     def test_day_not_in_month_raise(self):
-        self.assertRaises(ValueError, to_datetime, '2015-02-29', errors='raise')
-        self.assertRaises(ValueError, to_datetime, '2015-02-29', errors='raise', format="%Y-%m-%d")
-        self.assertRaises(ValueError, to_datetime, '2015-02-32', errors='raise', format="%Y-%m-%d")
-        self.assertRaises(ValueError, to_datetime, '2015-04-31', errors='raise', format="%Y-%m-%d")
+        self.assertRaises(ValueError, to_datetime, '2015-02-29',
+                          errors='raise')
+        self.assertRaises(ValueError, to_datetime, '2015-02-29',
+                          errors='raise', format="%Y-%m-%d")
+        self.assertRaises(ValueError, to_datetime, '2015-02-32',
+                          errors='raise', format="%Y-%m-%d")
+        self.assertRaises(ValueError, to_datetime, '2015-04-31',
+                          errors='raise', format="%Y-%m-%d")
 
     def test_day_not_in_month_ignore(self):
-        self.assertEqual(to_datetime('2015-02-29', errors='ignore'), '2015-02-29')
-        self.assertEqual(to_datetime('2015-02-29', errors='ignore', format="%Y-%m-%d"), '2015-02-29')
-        self.assertEqual(to_datetime('2015-02-32', errors='ignore', format="%Y-%m-%d"), '2015-02-32')
-        self.assertEqual(to_datetime('2015-04-31', errors='ignore', format="%Y-%m-%d"), '2015-04-31')
+        self.assertEqual(to_datetime(
+            '2015-02-29', errors='ignore'), '2015-02-29')
+        self.assertEqual(to_datetime(
+            '2015-02-29', errors='ignore', format="%Y-%m-%d"), '2015-02-29')
+        self.assertEqual(to_datetime(
+            '2015-02-32', errors='ignore', format="%Y-%m-%d"), '2015-02-32')
+        self.assertEqual(to_datetime(
+            '2015-04-31', errors='ignore', format="%Y-%m-%d"), '2015-04-31')
+
 
 if __name__ == '__main__':
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
diff --git a/pandas/tseries/tests/test_timeseries_legacy.py b/pandas/tseries/tests/test_timeseries_legacy.py
index 4cbc17136..96a9fd677 100644
--- a/pandas/tseries/tests/test_timeseries_legacy.py
+++ b/pandas/tseries/tests/test_timeseries_legacy.py
@@ -1,5 +1,5 @@
 # pylint: disable-msg=E1101,W0612
-from datetime import datetime, time, timedelta
+from datetime import datetime
 import sys
 import os
 
@@ -8,9 +8,8 @@ import nose
 import numpy as np
 randn = np.random.randn
 
-from pandas import (Index, Series, DataFrame,
-                    isnull, date_range, Timestamp, DatetimeIndex,
-                    Int64Index, to_datetime, bdate_range)
+from pandas import (Index, Series, date_range, Timestamp,
+                    DatetimeIndex, Int64Index, to_datetime)
 
 import pandas.core.datetools as datetools
 import pandas.tseries.offsets as offsets
@@ -19,9 +18,7 @@ import pandas as pd
 from pandas.util.testing import assert_series_equal, assert_almost_equal
 import pandas.util.testing as tm
 
-from pandas.compat import(
-    range, long, StringIO, lrange, lmap, map, zip, cPickle as pickle, product
-)
+from pandas.compat import StringIO, cPickle as pickle
 from pandas import read_pickle
 from numpy.random import rand
 import pandas.compat as compat
@@ -182,7 +179,7 @@ class LegacySupport(object):
         tm.assertIsInstance(result[0], Timestamp)
 
     def test_object_convert_fail(self):
-        idx = DatetimeIndex([NaT])
+        idx = DatetimeIndex([np.NaT])
         self.assertRaises(ValueError, idx.astype, 'O')
 
     def test_setops_conversion_fail(self):
@@ -199,17 +196,16 @@ class LegacySupport(object):
         self.assertTrue(result.equals(expected))
 
     def test_legacy_time_rules(self):
-        rules = [('WEEKDAY', 'B'),
-                 ('EOM', 'BM'),
-                 ('W@MON', 'W-MON'), ('W@TUE', 'W-TUE'), ('W@WED', 'W-WED'),
-                 ('W@THU', 'W-THU'), ('W@FRI', 'W-FRI'),
-                 ('Q@JAN', 'BQ-JAN'), ('Q@FEB', 'BQ-FEB'), ('Q@MAR', 'BQ-MAR'),
-                 ('A@JAN', 'BA-JAN'), ('A@FEB', 'BA-FEB'), ('A@MAR', 'BA-MAR'),
-                 ('A@APR', 'BA-APR'), ('A@MAY', 'BA-MAY'), ('A@JUN', 'BA-JUN'),
-                 ('A@JUL', 'BA-JUL'), ('A@AUG', 'BA-AUG'), ('A@SEP', 'BA-SEP'),
-                 ('A@OCT', 'BA-OCT'), ('A@NOV', 'BA-NOV'), ('A@DEC', 'BA-DEC'),
-                 ('WOM@1FRI', 'WOM-1FRI'), ('WOM@2FRI', 'WOM-2FRI'),
-                 ('WOM@3FRI', 'WOM-3FRI'), ('WOM@4FRI', 'WOM-4FRI')]
+        rules = [('WEEKDAY', 'B'), ('EOM', 'BM'), ('W@MON', 'W-MON'),
+                 ('W@TUE', 'W-TUE'), ('W@WED', 'W-WED'), ('W@THU', 'W-THU'),
+                 ('W@FRI', 'W-FRI'), ('Q@JAN', 'BQ-JAN'), ('Q@FEB', 'BQ-FEB'),
+                 ('Q@MAR', 'BQ-MAR'), ('A@JAN', 'BA-JAN'), ('A@FEB', 'BA-FEB'),
+                 ('A@MAR', 'BA-MAR'), ('A@APR', 'BA-APR'), ('A@MAY', 'BA-MAY'),
+                 ('A@JUN', 'BA-JUN'), ('A@JUL', 'BA-JUL'), ('A@AUG', 'BA-AUG'),
+                 ('A@SEP', 'BA-SEP'), ('A@OCT', 'BA-OCT'), ('A@NOV', 'BA-NOV'),
+                 ('A@DEC', 'BA-DEC'), ('WOM@1FRI', 'WOM-1FRI'),
+                 ('WOM@2FRI', 'WOM-2FRI'), ('WOM@3FRI', 'WOM-3FRI'),
+                 ('WOM@4FRI', 'WOM-4FRI')]
 
         start, end = '1/1/2000', '1/1/2010'
 
@@ -233,6 +229,7 @@ class LegacySupport(object):
         rule = datetools.to_offset('10us')
         self.assertEqual(rule, datetools.Micro(10))
 
+
 if __name__ == '__main__':
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
                    exit=False)
diff --git a/pandas/tseries/tests/test_timezones.py b/pandas/tseries/tests/test_timezones.py
index 37c40dd48..7a951683a 100644
--- a/pandas/tseries/tests/test_timezones.py
+++ b/pandas/tseries/tests/test_timezones.py
@@ -21,9 +21,8 @@ from pandas.core.dtypes import DatetimeTZDtype
 from pandas.util.testing import assert_frame_equal
 from pandas.compat import lrange, zip
 
-
 try:
-    import pytz
+    import pytz  # noqa
 except ImportError:
     pass
 
@@ -49,6 +48,7 @@ class FixedOffset(tzinfo):
     def dst(self, dt):
         return timedelta(0)
 
+
 fixed_off = FixedOffset(-420, '-07:00')
 fixed_off_no_name = FixedOffset(-330, None)
 
@@ -60,18 +60,21 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         tm._skip_if_no_pytz()
 
     def tz(self, tz):
-        ''' Construct a timezone object from a string. Overridden in subclass to parameterize tests. '''
+        # Construct a timezone object from a string. Overridden in subclass to
+        # parameterize tests.
         return pytz.timezone(tz)
 
     def tzstr(self, tz):
-        ''' Construct a timezone string from a string. Overridden in subclass to parameterize tests. '''
+        # Construct a timezone string from a string. Overridden in subclass to
+        # parameterize tests.
         return tz
 
     def localize(self, tz, x):
         return tz.localize(x)
 
     def cmptz(self, tz1, tz2):
-        ''' Compare two timezones. Overridden in subclass to parameterize tests. '''
+        # Compare two timezones. Overridden in subclass to parameterize
+        # tests.
         return tz1.zone == tz2.zone
 
     def test_utc_to_local_no_modify(self):
@@ -92,7 +95,6 @@ class TestTimeZoneSupportPytz(tm.TestCase):
 
         self.assertEqual(rng_eastern.tz, self.tz('US/Eastern'))
 
-
     def test_localize_utc_conversion(self):
         # Localizing to time zone should:
         #  1) check for DST ambiguities
@@ -107,7 +109,8 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         # DST ambiguity, this should fail
         rng = date_range('3/11/2012', '3/12/2012', freq='30T')
         # Is this really how it should fail??
-        self.assertRaises(NonExistentTimeError, rng.tz_localize, self.tzstr('US/Eastern'))
+        self.assertRaises(NonExistentTimeError, rng.tz_localize,
+                          self.tzstr('US/Eastern'))
 
     def test_localize_utc_conversion_explicit(self):
         # Localizing to time zone should:
@@ -122,7 +125,8 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         # DST ambiguity, this should fail
         rng = date_range('3/11/2012', '3/12/2012', freq='30T')
         # Is this really how it should fail??
-        self.assertRaises(NonExistentTimeError, rng.tz_localize, self.tz('US/Eastern'))
+        self.assertRaises(NonExistentTimeError, rng.tz_localize,
+                          self.tz('US/Eastern'))
 
     def test_timestamp_tz_localize(self):
         stamp = Timestamp('3/11/2012 04:00')
@@ -195,30 +199,27 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         self.assertEqual(result, expected)
 
     def test_tz_localize_dti(self):
-        from pandas.tseries.offsets import Hour
-
         dti = DatetimeIndex(start='1/1/2005', end='1/1/2005 0:00:30.256',
                             freq='L')
         dti2 = dti.tz_localize(self.tzstr('US/Eastern'))
 
         dti_utc = DatetimeIndex(start='1/1/2005 05:00',
-                                end='1/1/2005 5:00:30.256', freq='L',
-                                tz='utc')
+                                end='1/1/2005 5:00:30.256', freq='L', tz='utc')
 
         self.assert_numpy_array_equal(dti2.values, dti_utc.values)
 
         dti3 = dti2.tz_convert(self.tzstr('US/Pacific'))
         self.assert_numpy_array_equal(dti3.values, dti_utc.values)
 
-        dti = DatetimeIndex(start='11/6/2011 1:59',
-                            end='11/6/2011 2:00', freq='L')
+        dti = DatetimeIndex(start='11/6/2011 1:59', end='11/6/2011 2:00',
+                            freq='L')
         self.assertRaises(pytz.AmbiguousTimeError, dti.tz_localize,
                           self.tzstr('US/Eastern'))
 
         dti = DatetimeIndex(start='3/13/2011 1:59', end='3/13/2011 2:00',
                             freq='L')
-        self.assertRaises(
-            pytz.NonExistentTimeError, dti.tz_localize, self.tzstr('US/Eastern'))
+        self.assertRaises(pytz.NonExistentTimeError, dti.tz_localize,
+                          self.tzstr('US/Eastern'))
 
     def test_tz_localize_empty_series(self):
         # #2248
@@ -242,8 +243,8 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         stamp = Timestamp('3/11/2012 05:00', tz=self.tzstr('US/Eastern'))
         self.assertEqual(stamp.hour, 5)
 
-        rng = date_range(
-            '3/11/2012 04:00', periods=10, freq='H', tz=self.tzstr('US/Eastern'))
+        rng = date_range('3/11/2012 04:00', periods=10, freq='H',
+                         tz=self.tzstr('US/Eastern'))
 
         self.assertEqual(stamp, rng[1])
 
@@ -264,8 +265,8 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         rng2 = date_range(start, periods=len(rng), tz=off)
         self.assertTrue(rng.equals(rng2))
 
-        rng3 = date_range(
-            '3/11/2012 05:00:00+07:00', '6/11/2012 05:00:00+07:00')
+        rng3 = date_range('3/11/2012 05:00:00+07:00',
+                          '6/11/2012 05:00:00+07:00')
         self.assertTrue((rng.values == rng3.values).all())
 
     def test_create_with_fixedoffset_noname(self):
@@ -279,8 +280,8 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         self.assertEqual(off, idx.tz)
 
     def test_date_range_localize(self):
-        rng = date_range(
-            '3/11/2012 03:00', periods=15, freq='H', tz='US/Eastern')
+        rng = date_range('3/11/2012 03:00', periods=15, freq='H',
+                         tz='US/Eastern')
         rng2 = DatetimeIndex(['3/11/2012 03:00', '3/11/2012 04:00'],
                              tz='US/Eastern')
         rng3 = date_range('3/11/2012 03:00', periods=15, freq='H')
@@ -298,8 +299,8 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         self.assertTrue(rng[:2].equals(rng2))
 
         # Right before the DST transition
-        rng = date_range(
-            '3/11/2012 00:00', periods=2, freq='H', tz='US/Eastern')
+        rng = date_range('3/11/2012 00:00', periods=2, freq='H',
+                         tz='US/Eastern')
         rng2 = DatetimeIndex(['3/11/2012 00:00', '3/11/2012 01:00'],
                              tz='US/Eastern')
         self.assertTrue(rng.equals(rng2))
@@ -330,7 +331,8 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         rng_eastern = rng.tz_convert(self.tzstr('US/Eastern'))
         # test not valid for dateutil timezones.
         # self.assertIn('EDT', repr(rng_eastern[0].tzinfo))
-        self.assertTrue('EDT' in repr(rng_eastern[0].tzinfo) or 'tzfile' in repr(rng_eastern[0].tzinfo))
+        self.assertTrue('EDT' in repr(rng_eastern[0].tzinfo) or 'tzfile' in
+                        repr(rng_eastern[0].tzinfo))
 
     def test_timestamp_tz_convert(self):
         strdates = ['1/1/2012', '3/1/2012', '4/1/2012']
@@ -379,11 +381,13 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         # normalized
         central = dr.tz_convert(tz)
         self.assertIs(central.tz, tz)
-        comp = self.localize(tz, central[0].to_pydatetime().replace(tzinfo=None)).tzinfo
+        comp = self.localize(tz, central[0].to_pydatetime().replace(
+            tzinfo=None)).tzinfo
         self.assertIs(central[0].tz, comp)
 
         # compare vs a localized tz
-        comp = self.localize(tz, dr[0].to_pydatetime().replace(tzinfo=None)).tzinfo
+        comp = self.localize(tz,
+                             dr[0].to_pydatetime().replace(tzinfo=None)).tzinfo
         self.assertIs(central[0].tz, comp)
 
         # datetimes with tzinfo set
@@ -391,8 +395,8 @@ class TestTimeZoneSupportPytz(tm.TestCase):
                          '1/1/2009', tz=pytz.utc)
 
         self.assertRaises(Exception, bdate_range,
-                          datetime(2005, 1, 1, tzinfo=pytz.utc),
-                          '1/1/2009', tz=tz)
+                          datetime(2005, 1, 1, tzinfo=pytz.utc), '1/1/2009',
+                          tz=tz)
 
     def test_tz_localize(self):
         dr = bdate_range('1/1/2009', '1/1/2010')
@@ -432,16 +436,16 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         # With repeated hours, we can infer the transition
         dr = date_range(datetime(2011, 11, 6, 0), periods=5,
                         freq=datetools.Hour(), tz=tz)
-        times = ['11/06/2011 00:00', '11/06/2011 01:00',
-                 '11/06/2011 01:00', '11/06/2011 02:00',
-                 '11/06/2011 03:00']
+        times = ['11/06/2011 00:00', '11/06/2011 01:00', '11/06/2011 01:00',
+                 '11/06/2011 02:00', '11/06/2011 03:00']
         di = DatetimeIndex(times)
         localized = di.tz_localize(tz, ambiguous='infer')
         self.assert_numpy_array_equal(dr, localized)
         with tm.assert_produces_warning(FutureWarning):
             localized_old = di.tz_localize(tz, infer_dst=True)
         self.assert_numpy_array_equal(dr, localized_old)
-        self.assert_numpy_array_equal(dr, DatetimeIndex(times, tz=tz, ambiguous='infer'))
+        self.assert_numpy_array_equal(dr, DatetimeIndex(times, tz=tz,
+                                                        ambiguous='infer'))
 
         # When there is no dst transition, nothing special happens
         dr = date_range(datetime(2011, 6, 1, 0), periods=10,
@@ -460,21 +464,22 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         # Pass in flags to determine right dst transition
         dr = date_range(datetime(2011, 11, 6, 0), periods=5,
                         freq=datetools.Hour(), tz=tz)
-        times = ['11/06/2011 00:00', '11/06/2011 01:00',
-                 '11/06/2011 01:00', '11/06/2011 02:00',
-                 '11/06/2011 03:00']
+        times = ['11/06/2011 00:00', '11/06/2011 01:00', '11/06/2011 01:00',
+                 '11/06/2011 02:00', '11/06/2011 03:00']
 
         # Test tz_localize
         di = DatetimeIndex(times)
         is_dst = [1, 1, 0, 0, 0]
         localized = di.tz_localize(tz, ambiguous=is_dst)
         self.assert_numpy_array_equal(dr, localized)
-        self.assert_numpy_array_equal(dr, DatetimeIndex(times, tz=tz, ambiguous=is_dst))
+        self.assert_numpy_array_equal(dr, DatetimeIndex(times, tz=tz,
+                                                        ambiguous=is_dst))
 
         localized = di.tz_localize(tz, ambiguous=np.array(is_dst))
         self.assert_numpy_array_equal(dr, localized)
 
-        localized = di.tz_localize(tz, ambiguous=np.array(is_dst).astype('bool'))
+        localized = di.tz_localize(tz,
+                                   ambiguous=np.array(is_dst).astype('bool'))
         self.assert_numpy_array_equal(dr, localized)
 
         # Test constructor
@@ -504,30 +509,26 @@ class TestTimeZoneSupportPytz(tm.TestCase):
 
         # construction with an ambiguous end-point
         # GH 11626
-        tz=self.tzstr("Europe/London")
+        tz = self.tzstr("Europe/London")
 
         def f():
             date_range("2013-10-26 23:00", "2013-10-27 01:00",
-                       tz="Europe/London",
-                       freq="H")
+                       tz="Europe/London", freq="H")
             self.assertRaises(pytz.AmbiguousTimeError, f)
-        times = date_range("2013-10-26 23:00", "2013-10-27 01:00",
-                              freq="H",
-                              tz=tz,
-                              ambiguous='infer')
-        self.assertEqual(times[0],Timestamp('2013-10-26 23:00',tz=tz))
-        self.assertEqual(times[-1],Timestamp('2013-10-27 01:00',tz=tz))
+
+        times = date_range("2013-10-26 23:00", "2013-10-27 01:00", freq="H",
+                           tz=tz, ambiguous='infer')
+        self.assertEqual(times[0], Timestamp('2013-10-26 23:00', tz=tz))
+        self.assertEqual(times[-1], Timestamp('2013-10-27 01:00', tz=tz))
 
     def test_ambiguous_nat(self):
         tz = self.tz('US/Eastern')
-        times = ['11/06/2011 00:00', '11/06/2011 01:00',
-                 '11/06/2011 01:00', '11/06/2011 02:00',
-                 '11/06/2011 03:00']
+        times = ['11/06/2011 00:00', '11/06/2011 01:00', '11/06/2011 01:00',
+                 '11/06/2011 02:00', '11/06/2011 03:00']
         di = DatetimeIndex(times)
         localized = di.tz_localize(tz, ambiguous='NaT')
 
-        times = ['11/06/2011 00:00', np.NaN,
-                 np.NaN, '11/06/2011 02:00',
+        times = ['11/06/2011 00:00', np.NaN, np.NaN, '11/06/2011 02:00',
                  '11/06/2011 03:00']
         di_test = DatetimeIndex(times, tz='US/Eastern')
         self.assert_numpy_array_equal(di_test, localized)
@@ -542,22 +543,25 @@ class TestTimeZoneSupportPytz(tm.TestCase):
 
         start = self.localize(eastern, _start)
         end = self.localize(eastern, _end)
-        assert(tools._infer_tzinfo(start, end) is self.localize(eastern, _start).tzinfo)
-        assert(tools._infer_tzinfo(start, None) is self.localize(eastern, _start).tzinfo)
-        assert(tools._infer_tzinfo(None, end) is self.localize(eastern, _end).tzinfo)
+        assert (tools._infer_tzinfo(start, end) is self.localize(
+            eastern, _start).tzinfo)
+        assert (tools._infer_tzinfo(start, None) is self.localize(
+            eastern, _start).tzinfo)
+        assert (tools._infer_tzinfo(None, end) is self.localize(eastern,
+                                                                _end).tzinfo)
 
         start = utc.localize(_start)
         end = utc.localize(_end)
-        assert(tools._infer_tzinfo(start, end) is utc)
+        assert (tools._infer_tzinfo(start, end) is utc)
 
         end = self.localize(eastern, _end)
         self.assertRaises(Exception, tools._infer_tzinfo, start, end)
         self.assertRaises(Exception, tools._infer_tzinfo, end, start)
 
     def test_tz_string(self):
-        result = date_range('1/1/2000', periods=10, tz=self.tzstr('US/Eastern'))
-        expected = date_range('1/1/2000', periods=10,
-                              tz=self.tz('US/Eastern'))
+        result = date_range('1/1/2000', periods=10,
+                            tz=self.tzstr('US/Eastern'))
+        expected = date_range('1/1/2000', periods=10, tz=self.tz('US/Eastern'))
 
         self.assertTrue(result.equals(expected))
 
@@ -604,13 +608,15 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         ts_local = ts.tz_localize(self.tzstr('US/Eastern'))
 
         result = ts_local.at_time(time(10, 0))
-        expected = ts.at_time(time(10, 0)).tz_localize(self.tzstr('US/Eastern'))
+        expected = ts.at_time(time(10, 0)).tz_localize(self.tzstr(
+            'US/Eastern'))
         tm.assert_series_equal(result, expected)
         self.assertTrue(self.cmptz(result.index.tz, self.tz('US/Eastern')))
 
         t1, t2 = time(10, 0), time(11, 0)
         result = ts_local.between_time(t1, t2)
-        expected = ts.between_time(t1, t2).tz_localize(self.tzstr('US/Eastern'))
+        expected = ts.between_time(t1,
+                                   t2).tz_localize(self.tzstr('US/Eastern'))
         tm.assert_series_equal(result, expected)
         self.assertTrue(self.cmptz(result.index.tz, self.tz('US/Eastern')))
 
@@ -685,23 +691,24 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         dr = date_range('2011/1/1', '2012/1/1', freq='W-FRI')
         dr_tz = dr.tz_localize(self.tzstr('US/Eastern'))
         e = DataFrame({'A': 'foo', 'B': dr_tz}, index=dr)
-        tz_expected = DatetimeTZDtype('ns',dr_tz.tzinfo)
+        tz_expected = DatetimeTZDtype('ns', dr_tz.tzinfo)
         self.assertEqual(e['B'].dtype, tz_expected)
 
         # GH 2810 (with timezones)
-        datetimes_naive   = [ ts.to_pydatetime() for ts in dr ]
-        datetimes_with_tz = [ ts.to_pydatetime() for ts in dr_tz ]
-        df = DataFrame({'dr' : dr, 'dr_tz' : dr_tz,
+        datetimes_naive = [ts.to_pydatetime() for ts in dr]
+        datetimes_with_tz = [ts.to_pydatetime() for ts in dr_tz]
+        df = DataFrame({'dr': dr,
+                        'dr_tz': dr_tz,
                         'datetimes_naive': datetimes_naive,
-                        'datetimes_with_tz' : datetimes_with_tz })
+                        'datetimes_with_tz': datetimes_with_tz})
         result = df.get_dtype_counts().sort_index()
-        expected = Series({ 'datetime64[ns]' : 2, str(tz_expected) : 2 }).sort_index()
+        expected = Series({'datetime64[ns]': 2,
+                           str(tz_expected): 2}).sort_index()
         tm.assert_series_equal(result, expected)
 
     def test_hongkong_tz_convert(self):
         # #1673
-        dr = date_range(
-            '2012-01-01', '2012-01-10', freq='D', tz='Hongkong')
+        dr = date_range('2012-01-01', '2012-01-10', freq='D', tz='Hongkong')
 
         # it works!
         dr.hour
@@ -722,8 +729,8 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         self.assertEqual(result.tz, dr_tz.tz)
 
     def test_tz_aware_asfreq(self):
-        dr = date_range(
-            '2011-12-01', '2012-07-20', freq='D', tz=self.tzstr('US/Eastern'))
+        dr = date_range('2011-12-01', '2012-07-20', freq='D',
+                        tz=self.tzstr('US/Eastern'))
 
         s = Series(np.random.randn(len(dr)), index=dr)
 
@@ -791,12 +798,13 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         repr(series.index[0])
 
     def test_getitem_pydatetime_tz(self):
-        index = date_range(start='2012-12-24 16:00',
-                           end='2012-12-24 18:00', freq='H',
-                           tz=self.tzstr('Europe/Berlin'))
+        index = date_range(start='2012-12-24 16:00', end='2012-12-24 18:00',
+                           freq='H', tz=self.tzstr('Europe/Berlin'))
         ts = Series(index=index, data=index.hour)
-        time_pandas = Timestamp('2012-12-24 17:00', tz=self.tzstr('Europe/Berlin'))
-        time_datetime = self.localize(self.tz('Europe/Berlin'), datetime(2012, 12, 24, 17, 0))
+        time_pandas = Timestamp('2012-12-24 17:00',
+                                tz=self.tzstr('Europe/Berlin'))
+        time_datetime = self.localize(
+            self.tz('Europe/Berlin'), datetime(2012, 12, 24, 17, 0))
         self.assertEqual(ts[time_pandas], ts[time_datetime])
 
     def test_index_drop_dont_lose_tz(self):
@@ -814,7 +822,8 @@ class TestTimeZoneSupportPytz(tm.TestCase):
         arr = ['11/10/2005 08:00:00', '11/10/2005 09:00:00']
 
         idx1 = to_datetime(arr).tz_localize(self.tzstr('US/Eastern'))
-        idx2 = DatetimeIndex(start="2005-11-10 08:00:00", freq='H', periods=2, tz=self.tzstr('US/Eastern'))
+        idx2 = DatetimeIndex(start="2005-11-10 08:00:00", freq='H', periods=2,
+                             tz=self.tzstr('US/Eastern'))
         idx3 = DatetimeIndex(arr, tz=self.tzstr('US/Eastern'))
         idx4 = DatetimeIndex(np.array(arr), tz=self.tzstr('US/Eastern'))
 
@@ -822,7 +831,8 @@ class TestTimeZoneSupportPytz(tm.TestCase):
             self.assertTrue(idx1.equals(other))
 
     def test_datetimeindex_tz_nat(self):
-        idx = to_datetime([Timestamp("2013-1-1", tz=self.tzstr('US/Eastern')), NaT])
+        idx = to_datetime([Timestamp("2013-1-1", tz=self.tzstr('US/Eastern')),
+                           NaT])
 
         self.assertTrue(isnull(idx[1]))
         self.assertTrue(idx[0].tzinfo is not None)
@@ -843,11 +853,13 @@ class TestTimeZoneSupportDateutil(TestTimeZoneSupportPytz):
         return tslib.maybe_get_tz('dateutil/' + tz)
 
     def tzstr(self, tz):
-        ''' Construct a timezone string from a string. Overridden in subclass to parameterize tests. '''
+        ''' Construct a timezone string from a string. Overridden in subclass
+        to parameterize tests. '''
         return 'dateutil/' + tz
 
     def cmptz(self, tz1, tz2):
-        ''' Compare two timezones. Overridden in subclass to parameterize tests. '''
+        ''' Compare two timezones. Overridden in subclass to parameterize
+        tests. '''
         return tz1 == tz2
 
     def localize(self, tz, x):
@@ -873,7 +885,8 @@ class TestTimeZoneSupportDateutil(TestTimeZoneSupportPytz):
         # Regression test for tslib.tz_convert(vals, tz1, tz2).
         # See https://github.com/pydata/pandas/issues/4496 for details.
         for freq, n in [('H', 1), ('T', 60), ('S', 3600)]:
-            idx = date_range(datetime(2011, 3, 26, 23), datetime(2011, 3, 27, 1), freq=freq)
+            idx = date_range(datetime(2011, 3, 26, 23),
+                             datetime(2011, 3, 27, 1), freq=freq)
             idx = idx.tz_localize('UTC')
             idx = idx.tz_convert('Europe/Moscow')
 
@@ -883,47 +896,59 @@ class TestTimeZoneSupportDateutil(TestTimeZoneSupportPytz):
     def test_tslib_tz_convert_dst(self):
         for freq, n in [('H', 1), ('T', 60), ('S', 3600)]:
             # Start DST
-            idx = date_range('2014-03-08 23:00', '2014-03-09 09:00', freq=freq, tz='UTC')
+            idx = date_range('2014-03-08 23:00', '2014-03-09 09:00', freq=freq,
+                             tz='UTC')
             idx = idx.tz_convert('US/Eastern')
-            expected = np.repeat(np.array([18, 19, 20, 21, 22, 23, 0, 1, 3, 4, 5]),
+            expected = np.repeat(np.array([18, 19, 20, 21, 22, 23,
+                                           0, 1, 3, 4, 5]),
                                  np.array([n, n, n, n, n, n, n, n, n, n, 1]))
             self.assert_numpy_array_equal(idx.hour, expected)
 
-            idx = date_range('2014-03-08 18:00', '2014-03-09 05:00', freq=freq, tz='US/Eastern')
+            idx = date_range('2014-03-08 18:00', '2014-03-09 05:00', freq=freq,
+                             tz='US/Eastern')
             idx = idx.tz_convert('UTC')
             expected = np.repeat(np.array([23, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),
                                  np.array([n, n, n, n, n, n, n, n, n, n, 1]))
             self.assert_numpy_array_equal(idx.hour, expected)
 
             # End DST
-            idx = date_range('2014-11-01 23:00', '2014-11-02 09:00', freq=freq, tz='UTC')
+            idx = date_range('2014-11-01 23:00', '2014-11-02 09:00', freq=freq,
+                             tz='UTC')
             idx = idx.tz_convert('US/Eastern')
-            expected = np.repeat(np.array([19, 20, 21, 22, 23, 0, 1, 1, 2, 3, 4]),
+            expected = np.repeat(np.array([19, 20, 21, 22, 23,
+                                           0, 1, 1, 2, 3, 4]),
                                  np.array([n, n, n, n, n, n, n, n, n, n, 1]))
             self.assert_numpy_array_equal(idx.hour, expected)
 
-            idx = date_range('2014-11-01 18:00', '2014-11-02 05:00', freq=freq, tz='US/Eastern')
+            idx = date_range('2014-11-01 18:00', '2014-11-02 05:00', freq=freq,
+                             tz='US/Eastern')
             idx = idx.tz_convert('UTC')
-            expected = np.repeat(np.array([22, 23, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]),
-                                 np.array([n, n, n, n, n, n, n, n, n, n, n, n, 1]))
+            expected = np.repeat(np.array([22, 23, 0, 1, 2, 3, 4, 5, 6,
+                                           7, 8, 9, 10]),
+                                 np.array([n, n, n, n, n, n, n, n, n,
+                                           n, n, n, 1]))
             self.assert_numpy_array_equal(idx.hour, expected)
 
         # daily
         # Start DST
-        idx = date_range('2014-03-08 00:00', '2014-03-09 00:00', freq='D', tz='UTC')
+        idx = date_range('2014-03-08 00:00', '2014-03-09 00:00', freq='D',
+                         tz='UTC')
         idx = idx.tz_convert('US/Eastern')
         self.assert_numpy_array_equal(idx.hour, np.array([19, 19]))
 
-        idx = date_range('2014-03-08 00:00', '2014-03-09 00:00', freq='D', tz='US/Eastern')
+        idx = date_range('2014-03-08 00:00', '2014-03-09 00:00', freq='D',
+                         tz='US/Eastern')
         idx = idx.tz_convert('UTC')
         self.assert_numpy_array_equal(idx.hour, np.array([5, 5]))
 
         # End DST
-        idx = date_range('2014-11-01 00:00', '2014-11-02 00:00', freq='D', tz='UTC')
+        idx = date_range('2014-11-01 00:00', '2014-11-02 00:00', freq='D',
+                         tz='UTC')
         idx = idx.tz_convert('US/Eastern')
         self.assert_numpy_array_equal(idx.hour, np.array([20, 20]))
 
-        idx = date_range('2014-11-01 00:00', '2014-11-02 000:00', freq='D', tz='US/Eastern')
+        idx = date_range('2014-11-01 00:00', '2014-11-02 000:00', freq='D',
+                         tz='US/Eastern')
         idx = idx.tz_convert('UTC')
         self.assert_numpy_array_equal(idx.hour, np.array([4, 4]))
 
@@ -940,7 +965,8 @@ class TestTimeZoneCacheKey(tm.TestCase):
             if tz_d is None:
                 # skip timezones that dateutil doesn't know about.
                 continue
-            self.assertNotEqual(tslib._p_tz_cache_key(tz_p), tslib._p_tz_cache_key(tz_d))
+            self.assertNotEqual(tslib._p_tz_cache_key(
+                tz_p), tslib._p_tz_cache_key(tz_d))
 
 
 class TestTimeZones(tm.TestCase):
@@ -952,8 +978,7 @@ class TestTimeZones(tm.TestCase):
 
     def test_index_equals_with_tz(self):
         left = date_range('1/1/2011', periods=100, freq='H', tz='utc')
-        right = date_range('1/1/2011', periods=100, freq='H',
-                           tz='US/Eastern')
+        right = date_range('1/1/2011', periods=100, freq='H', tz='US/Eastern')
 
         self.assertFalse(left.equals(right))
 
@@ -973,7 +998,8 @@ class TestTimeZones(tm.TestCase):
             idx4 = date_range(start='2014-08-01', end='2014-10-31', freq='T')
             for idx in [idx1, idx2, idx3, idx4]:
                 localized = idx.tz_localize(tz)
-                expected = date_range(start=idx[0], end=idx[-1], freq=idx.freq, tz=tz)
+                expected = date_range(start=idx[0], end=idx[-1], freq=idx.freq,
+                                      tz=tz)
                 tm.assert_index_equal(localized, expected)
 
                 with tm.assertRaises(TypeError):
@@ -1005,11 +1031,11 @@ class TestTimeZones(tm.TestCase):
         # Can't localize if already tz-aware
         rng = date_range('1/1/2011', periods=100, freq='H', tz='utc')
         ts = Series(1, index=rng)
-        tm.assertRaisesRegexp(TypeError, 'Already tz-aware', ts.tz_localize, 'US/Eastern')
+        tm.assertRaisesRegexp(TypeError, 'Already tz-aware', ts.tz_localize,
+                              'US/Eastern')
 
     def test_series_frame_tz_convert(self):
-        rng = date_range('1/1/2011', periods=200, freq='D',
-                         tz='US/Eastern')
+        rng = date_range('1/1/2011', periods=200, freq='D', tz='US/Eastern')
         ts = Series(1, index=rng)
 
         result = ts.tz_convert('Europe/Berlin')
@@ -1029,30 +1055,35 @@ class TestTimeZones(tm.TestCase):
         # can't convert tz-naive
         rng = date_range('1/1/2011', periods=200, freq='D')
         ts = Series(1, index=rng)
-        tm.assertRaisesRegexp(TypeError, "Cannot convert tz-naive", ts.tz_convert, 'US/Eastern')
+        tm.assertRaisesRegexp(TypeError, "Cannot convert tz-naive",
+                              ts.tz_convert, 'US/Eastern')
 
     def test_tz_convert_roundtrip(self):
         for tz in self.timezones:
-            idx1 = date_range(start='2014-01-01', end='2014-12-31', freq='M', tz='UTC')
+            idx1 = date_range(start='2014-01-01', end='2014-12-31', freq='M',
+                              tz='UTC')
             exp1 = date_range(start='2014-01-01', end='2014-12-31', freq='M')
 
-            idx2 = date_range(start='2014-01-01', end='2014-12-31', freq='D', tz='UTC')
+            idx2 = date_range(start='2014-01-01', end='2014-12-31', freq='D',
+                              tz='UTC')
             exp2 = date_range(start='2014-01-01', end='2014-12-31', freq='D')
 
-            idx3 = date_range(start='2014-01-01', end='2014-03-01', freq='H', tz='UTC')
+            idx3 = date_range(start='2014-01-01', end='2014-03-01', freq='H',
+                              tz='UTC')
             exp3 = date_range(start='2014-01-01', end='2014-03-01', freq='H')
 
-            idx4 = date_range(start='2014-08-01', end='2014-10-31', freq='T', tz='UTC')
+            idx4 = date_range(start='2014-08-01', end='2014-10-31', freq='T',
+                              tz='UTC')
             exp4 = date_range(start='2014-08-01', end='2014-10-31', freq='T')
 
-
-            for idx, expected in [(idx1, exp1), (idx2, exp2), (idx3, exp3), (idx4, exp4)]:
+            for idx, expected in [(idx1, exp1), (idx2, exp2), (idx3, exp3),
+                                  (idx4, exp4)]:
                 converted = idx.tz_convert(tz)
                 reset = converted.tz_convert(None)
                 tm.assert_index_equal(reset, expected)
                 self.assertTrue(reset.tzinfo is None)
-                tm.assert_index_equal(reset, converted.tz_convert('UTC').tz_localize(None))
-
+                tm.assert_index_equal(reset, converted.tz_convert(
+                    'UTC').tz_localize(None))
 
     def test_join_utc_convert(self):
         rng = date_range('1/1/2011', periods=100, freq='H', tz='utc')
@@ -1093,11 +1124,11 @@ class TestTimeZones(tm.TestCase):
         self.assertTrue(result.index.tz.zone == 'US/Central')
 
         # non-overlapping
-        rng = date_range("2012-11-15 00:00:00", periods=6,
-                         freq="H", tz="US/Central")
+        rng = date_range("2012-11-15 00:00:00", periods=6, freq="H",
+                         tz="US/Central")
 
-        rng2 = date_range("2012-11-15 12:00:00", periods=6,
-                          freq="H", tz="US/Eastern")
+        rng2 = date_range("2012-11-15 12:00:00", periods=6, freq="H",
+                          tz="US/Eastern")
 
         result = rng.union(rng2)
         self.assertTrue(result.tz.zone == 'UTC')
@@ -1121,10 +1152,8 @@ class TestTimeZones(tm.TestCase):
         ts_result = ts1.append(ts2)
         self.assertEqual(ts_result.index.tz, rng1.tz)
 
-        rng1 = date_range('1/1/2011 01:00', periods=1, freq='H',
-                          tz='UTC')
-        rng2 = date_range('1/1/2011 02:00', periods=1, freq='H',
-                          tz='UTC')
+        rng1 = date_range('1/1/2011 01:00', periods=1, freq='H', tz='UTC')
+        rng2 = date_range('1/1/2011 02:00', periods=1, freq='H', tz='UTC')
         ts1 = Series(np.random.randn(len(rng1)), index=rng1)
         ts2 = Series(np.random.randn(len(rng2)), index=rng2)
         ts_result = ts1.append(ts2)
@@ -1147,8 +1176,8 @@ class TestTimeZones(tm.TestCase):
         ts1 = Series(np.random.randn(len(rng1)), index=rng1)
         ts2 = Series(np.random.randn(len(rng2)), index=rng2)
         ts_result = ts1.append(ts2)
-        self.assertTrue(ts_result.index.equals(
-            ts1.index.asobject.append(ts2.index.asobject)))
+        self.assertTrue(ts_result.index.equals(ts1.index.asobject.append(
+            ts2.index.asobject)))
 
         # mixed
 
@@ -1157,8 +1186,8 @@ class TestTimeZones(tm.TestCase):
         ts1 = Series(np.random.randn(len(rng1)), index=rng1)
         ts2 = Series(np.random.randn(len(rng2)), index=rng2)
         ts_result = ts1.append(ts2)
-        self.assertTrue(ts_result.index.equals(
-            ts1.index.asobject.append(ts2.index)))
+        self.assertTrue(ts_result.index.equals(ts1.index.asobject.append(
+            ts2.index)))
 
     def test_equal_join_ensure_utc(self):
         rng = date_range('1/1/2011', periods=10, freq='H', tz='US/Eastern')
@@ -1242,23 +1271,19 @@ class TestTimeZones(tm.TestCase):
         self.assertTrue(result.is_normalized)
         self.assertFalse(rng.is_normalized)
 
-        rng = date_range('1/1/2000 9:30', periods=10, freq='D',
-                         tz='UTC')
+        rng = date_range('1/1/2000 9:30', periods=10, freq='D', tz='UTC')
 
         result = rng.normalize()
-        expected = date_range('1/1/2000', periods=10, freq='D',
-                              tz='UTC')
+        expected = date_range('1/1/2000', periods=10, freq='D', tz='UTC')
         self.assertTrue(result.equals(expected))
 
         self.assertTrue(result.is_normalized)
         self.assertFalse(rng.is_normalized)
 
         from dateutil.tz import tzlocal
-        rng = date_range('1/1/2000 9:30', periods=10, freq='D',
-                         tz=tzlocal())
+        rng = date_range('1/1/2000 9:30', periods=10, freq='D', tz=tzlocal())
         result = rng.normalize()
-        expected = date_range('1/1/2000', periods=10, freq='D',
-                              tz=tzlocal())
+        expected = date_range('1/1/2000', periods=10, freq='D', tz=tzlocal())
         self.assertTrue(result.equals(expected))
 
         self.assertTrue(result.is_normalized)
diff --git a/pandas/tseries/tests/test_tslib.py b/pandas/tseries/tests/test_tslib.py
index 55a6bf6f1..123b91d8b 100644
--- a/pandas/tseries/tests/test_tslib.py
+++ b/pandas/tseries/tests/test_tslib.py
@@ -19,7 +19,6 @@ from pandas.util.testing import assert_series_equal, _skip_if_has_locale
 
 
 class TestTimestamp(tm.TestCase):
-
     def test_constructor(self):
         base_str = '2014-07-01 09:00'
         base_dt = datetime.datetime(2014, 7, 1, 9)
@@ -27,23 +26,27 @@ class TestTimestamp(tm.TestCase):
 
         # confirm base representation is correct
         import calendar
-        self.assertEqual(calendar.timegm(base_dt.timetuple()) * 1000000000, base_expected)
+        self.assertEqual(calendar.timegm(base_dt.timetuple())
+                         * 1000000000, base_expected)
 
         tests = [(base_str, base_dt, base_expected),
                  ('2014-07-01 10:00', datetime.datetime(2014, 7, 1, 10),
                   base_expected + 3600 * 1000000000),
                  ('2014-07-01 09:00:00.000008000',
-                  datetime.datetime(2014, 7, 1, 9, 0, 0, 8), base_expected + 8000),
+                  datetime.datetime(2014, 7, 1, 9, 0, 0, 8),
+                  base_expected + 8000),
                  ('2014-07-01 09:00:00.000000005',
-                  Timestamp('2014-07-01 09:00:00.000000005'), base_expected + 5)]
+                  Timestamp('2014-07-01 09:00:00.000000005'),
+                  base_expected + 5)]
 
         tm._skip_if_no_pytz()
         tm._skip_if_no_dateutil()
         import pytz
         import dateutil
-        timezones = [(None, 0), ('UTC', 0), (pytz.utc, 0),
-                     ('Asia/Tokyo', 9), ('US/Eastern', -4), ('dateutil/US/Pacific', -7),
-                     (pytz.FixedOffset(-180), -3), (dateutil.tz.tzoffset(None, 18000), 5)]
+        timezones = [(None, 0), ('UTC', 0), (pytz.utc, 0), ('Asia/Tokyo', 9),
+                     ('US/Eastern', -4), ('dateutil/US/Pacific', -7),
+                     (pytz.FixedOffset(-180), -3),
+                     (dateutil.tz.tzoffset(None, 18000), 5)]
 
         for date_str, date, expected in tests:
             for result in [Timestamp(date_str), Timestamp(date)]:
@@ -58,7 +61,8 @@ class TestTimestamp(tm.TestCase):
 
             # with timezone
             for tz, offset in timezones:
-                for result in [Timestamp(date_str, tz=tz), Timestamp(date, tz=tz)]:
+                for result in [Timestamp(date_str, tz=tz), Timestamp(date,
+                                                                     tz=tz)]:
                     expected_tz = expected - offset * 3600 * 1000000000
                     self.assertEqual(result.value, expected_tz)
                     self.assertEqual(tslib.pydt_to_i8(result), expected_tz)
@@ -82,10 +86,12 @@ class TestTimestamp(tm.TestCase):
 
         # confirm base representation is correct
         import calendar
-        self.assertEqual(calendar.timegm(base_dt.timetuple()) * 1000000000, base_expected)
+        self.assertEqual(calendar.timegm(base_dt.timetuple())
+                         * 1000000000, base_expected)
 
         tests = [(base_str, base_expected),
-                 ('2014-07-01 12:00:00+02:00', base_expected + 3600 * 1000000000),
+                 ('2014-07-01 12:00:00+02:00',
+                  base_expected + 3600 * 1000000000),
                  ('2014-07-01 11:00:00.000008000+02:00', base_expected + 8000),
                  ('2014-07-01 11:00:00.000000005+02:00', base_expected + 5)]
 
@@ -93,10 +99,10 @@ class TestTimestamp(tm.TestCase):
         tm._skip_if_no_dateutil()
         import pytz
         import dateutil
-        timezones = [(None, 0), ('UTC', 0), (pytz.utc, 0),
-                     ('Asia/Tokyo', 9), ('US/Eastern', -4),
-                     ('dateutil/US/Pacific', -7),
-                     (pytz.FixedOffset(-180), -3), (dateutil.tz.tzoffset(None, 18000), 5)]
+        timezones = [(None, 0), ('UTC', 0), (pytz.utc, 0), ('Asia/Tokyo', 9),
+                     ('US/Eastern', -4), ('dateutil/US/Pacific', -7),
+                     (pytz.FixedOffset(-180), -3),
+                     (dateutil.tz.tzoffset(None, 18000), 5)]
 
         for date_str, expected in tests:
             for result in [Timestamp(date_str)]:
@@ -185,14 +191,18 @@ class TestTimestamp(tm.TestCase):
         tm._skip_if_no_pytz()
         tm._skip_if_no_dateutil()
 
-        dates = ['2014-03-07', '2014-01-01 09:00', '2014-01-01 00:00:00.000000001']
+        dates = ['2014-03-07', '2014-01-01 09:00',
+                 '2014-01-01 00:00:00.000000001']
 
         # dateutil zone change (only matters for repr)
         import dateutil
-        if dateutil.__version__ >= LooseVersion('2.3') and dateutil.__version__ <= LooseVersion('2.4.0'):
-            timezones = ['UTC', 'Asia/Tokyo', 'US/Eastern', 'dateutil/US/Pacific']
+        if dateutil.__version__ >= LooseVersion(
+                '2.3') and dateutil.__version__ <= LooseVersion('2.4.0'):
+            timezones = ['UTC', 'Asia/Tokyo', 'US/Eastern',
+                         'dateutil/US/Pacific']
         else:
-            timezones = ['UTC', 'Asia/Tokyo', 'US/Eastern', 'dateutil/America/Los_Angeles']
+            timezones = ['UTC', 'Asia/Tokyo', 'US/Eastern',
+                         'dateutil/America/Los_Angeles']
 
         freqs = ['D', 'M', 'S', 'N']
 
@@ -231,43 +241,33 @@ class TestTimestamp(tm.TestCase):
                     self.assertIn(freq_repr, repr(date_tz_freq))
                     self.assertEqual(date_tz_freq, eval(repr(date_tz_freq)))
 
-        # this can cause the tz field to be populated, but it's redundant to information in the datestring
+        # this can cause the tz field to be populated, but it's redundant to
+        # information in the datestring
         tm._skip_if_no_pytz()
-        import pytz
+        import pytz  # noqa
         date_with_utc_offset = Timestamp('2014-03-13 00:00:00-0400', tz=None)
         self.assertIn('2014-03-13 00:00:00-0400', repr(date_with_utc_offset))
         self.assertNotIn('tzoffset', repr(date_with_utc_offset))
         self.assertIn('pytz.FixedOffset(-240)', repr(date_with_utc_offset))
         expr = repr(date_with_utc_offset).replace("'pytz.FixedOffset(-240)'",
-                    'pytz.FixedOffset(-240)')
+                                                  'pytz.FixedOffset(-240)')
         self.assertEqual(date_with_utc_offset, eval(expr))
 
     def test_bounds_with_different_units(self):
-        out_of_bounds_dates = (
-            '1677-09-21',
-            '2262-04-12',
-        )
+        out_of_bounds_dates = ('1677-09-21', '2262-04-12', )
 
         time_units = ('D', 'h', 'm', 's', 'ms', 'us')
 
         for date_string in out_of_bounds_dates:
             for unit in time_units:
-                self.assertRaises(
-                    ValueError,
-                    Timestamp,
-                    np.datetime64(date_string, dtype='M8[%s]' % unit)
-                )
-
-        in_bounds_dates = (
-            '1677-09-23',
-            '2262-04-11',
-        )
+                self.assertRaises(ValueError, Timestamp, np.datetime64(
+                    date_string, dtype='M8[%s]' % unit))
+
+        in_bounds_dates = ('1677-09-23', '2262-04-11', )
 
         for date_string in in_bounds_dates:
             for unit in time_units:
-                Timestamp(
-                    np.datetime64(date_string, dtype='M8[%s]' % unit)
-                )
+                Timestamp(np.datetime64(date_string, dtype='M8[%s]' % unit))
 
     def test_tz(self):
         t = '2014-02-01 09:00'
@@ -276,8 +276,7 @@ class TestTimestamp(tm.TestCase):
         self.assertEqual(local.hour, 9)
         self.assertEqual(local, Timestamp(t, tz='Asia/Tokyo'))
         conv = local.tz_convert('US/Eastern')
-        self.assertEqual(conv,
-                         Timestamp('2014-01-31 19:00', tz='US/Eastern'))
+        self.assertEqual(conv, Timestamp('2014-01-31 19:00', tz='US/Eastern'))
         self.assertEqual(conv.hour, 19)
 
         # preserves nanosecond
@@ -298,21 +297,24 @@ class TestTimestamp(tm.TestCase):
         rng = date_range('2014-11-02', periods=3, freq='H', tz='US/Eastern')
         self.assertEqual(rng[1], ts_dst)
         self.assertEqual(rng[2], ts_no_dst)
-        self.assertRaises(ValueError, ts.tz_localize, 'US/Eastern', ambiguous='infer')
+        self.assertRaises(ValueError, ts.tz_localize, 'US/Eastern',
+                          ambiguous='infer')
 
         # GH 8025
-        with tm.assertRaisesRegexp(TypeError, 'Cannot localize tz-aware Timestamp, use '
+        with tm.assertRaisesRegexp(TypeError,
+                                   'Cannot localize tz-aware Timestamp, use '
                                    'tz_convert for conversions'):
-            Timestamp('2011-01-01' ,tz='US/Eastern').tz_localize('Asia/Tokyo')
+            Timestamp('2011-01-01', tz='US/Eastern').tz_localize('Asia/Tokyo')
 
-        with tm.assertRaisesRegexp(TypeError, 'Cannot convert tz-naive Timestamp, use '
-                            'tz_localize to localize'):
+        with tm.assertRaisesRegexp(TypeError,
+                                   'Cannot convert tz-naive Timestamp, use '
+                                   'tz_localize to localize'):
             Timestamp('2011-01-01').tz_convert('Asia/Tokyo')
 
     def test_tz_localize_roundtrip(self):
         for tz in ['UTC', 'Asia/Tokyo', 'US/Eastern', 'dateutil/US/Pacific']:
-            for t in ['2014-02-01 09:00', '2014-07-08 09:00', '2014-11-01 17:00',
-                      '2014-11-05 00:00']:
+            for t in ['2014-02-01 09:00', '2014-07-08 09:00',
+                      '2014-11-01 17:00', '2014-11-05 00:00']:
                 ts = Timestamp(t)
                 localized = ts.tz_localize(tz)
                 self.assertEqual(localized, Timestamp(t, tz=tz))
@@ -326,15 +328,16 @@ class TestTimestamp(tm.TestCase):
 
     def test_tz_convert_roundtrip(self):
         for tz in ['UTC', 'Asia/Tokyo', 'US/Eastern', 'dateutil/US/Pacific']:
-            for t in ['2014-02-01 09:00', '2014-07-08 09:00', '2014-11-01 17:00',
-                      '2014-11-05 00:00']:
+            for t in ['2014-02-01 09:00', '2014-07-08 09:00',
+                      '2014-11-01 17:00', '2014-11-05 00:00']:
                 ts = Timestamp(t, tz='UTC')
                 converted = ts.tz_convert(tz)
 
                 reset = converted.tz_convert(None)
                 self.assertEqual(reset, Timestamp(t))
                 self.assertTrue(reset.tzinfo is None)
-                self.assertEqual(reset, converted.tz_convert('UTC').tz_localize(None))
+                self.assertEqual(reset,
+                                 converted.tz_convert('UTC').tz_localize(None))
 
     def test_barely_oob_dts(self):
         one_us = np.timedelta64(1).astype('timedelta64[us]')
@@ -355,7 +358,8 @@ class TestTimestamp(tm.TestCase):
         self.assertRaises(ValueError, Timestamp, max_ts_us + one_us)
 
     def test_utc_z_designator(self):
-        self.assertEqual(get_timezone(Timestamp('2014-11-02 01:00Z').tzinfo), 'UTC')
+        self.assertEqual(get_timezone(
+            Timestamp('2014-11-02 01:00Z').tzinfo), 'UTC')
 
     def test_now(self):
         # #9000
@@ -366,13 +370,14 @@ class TestTimestamp(tm.TestCase):
         ts_from_string_tz = Timestamp('now', tz='US/Eastern')
         ts_from_method_tz = Timestamp.now(tz='US/Eastern')
 
-        # Check that the delta between the times is less than 1s (arbitrarily small)
+        # Check that the delta between the times is less than 1s (arbitrarily
+        # small)
         delta = Timedelta(seconds=1)
         self.assertTrue(abs(ts_from_method - ts_from_string) < delta)
         self.assertTrue(abs(ts_datetime - ts_from_method) < delta)
         self.assertTrue(abs(ts_from_method_tz - ts_from_string_tz) < delta)
-        self.assertTrue(abs(ts_from_string_tz.tz_localize(None)
-                            - ts_from_method_tz.tz_localize(None)) < delta)
+        self.assertTrue(abs(ts_from_string_tz.tz_localize(None) -
+                            ts_from_method_tz.tz_localize(None)) < delta)
 
     def test_today(self):
 
@@ -383,21 +388,18 @@ class TestTimestamp(tm.TestCase):
         ts_from_string_tz = Timestamp('today', tz='US/Eastern')
         ts_from_method_tz = Timestamp.today(tz='US/Eastern')
 
-        # Check that the delta between the times is less than 1s (arbitrarily small)
+        # Check that the delta between the times is less than 1s (arbitrarily
+        # small)
         delta = Timedelta(seconds=1)
         self.assertTrue(abs(ts_from_method - ts_from_string) < delta)
         self.assertTrue(abs(ts_datetime - ts_from_method) < delta)
         self.assertTrue(abs(ts_from_method_tz - ts_from_string_tz) < delta)
-        self.assertTrue(abs(ts_from_string_tz.tz_localize(None)
-                            - ts_from_method_tz.tz_localize(None)) < delta)
+        self.assertTrue(abs(ts_from_string_tz.tz_localize(None) -
+                            ts_from_method_tz.tz_localize(None)) < delta)
 
     def test_asm8(self):
         np.random.seed(7960929)
-        ns = [
-            Timestamp.min.value,
-            Timestamp.max.value,
-            1000,
-        ]
+        ns = [Timestamp.min.value, Timestamp.max.value, 1000, ]
         for n in ns:
             self.assertEqual(Timestamp(n).asm8.view('i8'),
                              np.datetime64(n, 'ns').view('i8'), n)
@@ -405,7 +407,6 @@ class TestTimestamp(tm.TestCase):
                          np.datetime64('nat', 'ns').view('i8'))
 
     def test_fields(self):
-
         def check(value, equal):
             # that we are int/long like
             self.assertTrue(isinstance(value, (int, compat.long)))
@@ -419,7 +420,7 @@ class TestTimestamp(tm.TestCase):
         check(ts.hour, 9)
         check(ts.minute, 6)
         check(ts.second, 3)
-        self.assertRaises(AttributeError, lambda : ts.millisecond)
+        self.assertRaises(AttributeError, lambda: ts.millisecond)
         check(ts.microsecond, 100)
         check(ts.nanosecond, 1)
         check(ts.dayofweek, 6)
@@ -449,34 +450,23 @@ class TestTimestamp(tm.TestCase):
 
 
 class TestDatetimeParsingWrappers(tm.TestCase):
-
     def test_does_not_convert_mixed_integer(self):
-        bad_date_strings = (
-            '-50000',
-            '999',
-            '123.1234',
-            'm',
-            'T'
-        )
+        bad_date_strings = ('-50000', '999', '123.1234', 'm', 'T')
 
         for bad_date_string in bad_date_strings:
-            self.assertFalse(
-                tslib._does_string_look_like_datetime(bad_date_string)
-            )
+            self.assertFalse(tslib._does_string_look_like_datetime(
+                bad_date_string))
 
-        good_date_strings = (
-            '2012-01-01',
-            '01/01/2012',
-            'Mon Sep 16, 2013',
-            '01012012',
-            '0101',
-            '1-1',
-        )
+        good_date_strings = ('2012-01-01',
+                             '01/01/2012',
+                             'Mon Sep 16, 2013',
+                             '01012012',
+                             '0101',
+                             '1-1', )
 
         for good_date_string in good_date_strings:
-            self.assertTrue(
-                tslib._does_string_look_like_datetime(good_date_string)
-            )
+            self.assertTrue(tslib._does_string_look_like_datetime(
+                good_date_string))
 
     def test_parsers(self):
         cases = {'2011-01-01': datetime.datetime(2011, 1, 1),
@@ -495,15 +485,12 @@ class TestDatetimeParsingWrappers(tm.TestCase):
                  '4Q2000': datetime.datetime(2000, 10, 1),
                  '4Q00': datetime.datetime(2000, 10, 1),
                  '2000q4': datetime.datetime(2000, 10, 1),
-
                  '2000-Q4': datetime.datetime(2000, 10, 1),
                  '00-Q4': datetime.datetime(2000, 10, 1),
                  '4Q-2000': datetime.datetime(2000, 10, 1),
                  '4Q-00': datetime.datetime(2000, 10, 1),
-
                  '2000q4': datetime.datetime(2000, 10, 1),
                  '00q4': datetime.datetime(2000, 10, 1),
-
                  '2005': datetime.datetime(2005, 1, 1),
                  '2005-11': datetime.datetime(2005, 11, 1),
                  '2005 11': datetime.datetime(2005, 11, 1),
@@ -511,16 +498,14 @@ class TestDatetimeParsingWrappers(tm.TestCase):
                  '11 2005': datetime.datetime(2005, 11, 1),
                  '200511': datetime.datetime(2020, 5, 11),
                  '20051109': datetime.datetime(2005, 11, 9),
-
                  '20051109 10:15': datetime.datetime(2005, 11, 9, 10, 15),
                  '20051109 08H': datetime.datetime(2005, 11, 9, 8, 0),
-
                  '2005-11-09 10:15': datetime.datetime(2005, 11, 9, 10, 15),
                  '2005-11-09 08H': datetime.datetime(2005, 11, 9, 8, 0),
                  '2005/11/09 10:15': datetime.datetime(2005, 11, 9, 10, 15),
                  '2005/11/09 08H': datetime.datetime(2005, 11, 9, 8, 0),
-
-                 "Thu Sep 25 10:36:28 2003": datetime.datetime(2003, 9, 25, 10, 36, 28),
+                 "Thu Sep 25 10:36:28 2003": datetime.datetime(2003, 9, 25, 10,
+                                                               36, 28),
                  "Thu Sep 25 2003": datetime.datetime(2003, 9, 25),
                  "Sep 25 2003": datetime.datetime(2003, 9, 25),
                  "January 1 2014": datetime.datetime(2014, 1, 1),
@@ -529,8 +514,7 @@ class TestDatetimeParsingWrappers(tm.TestCase):
                  '2014-06': datetime.datetime(2014, 6, 1),
                  '06-2014': datetime.datetime(2014, 6, 1),
                  '2014-6': datetime.datetime(2014, 6, 1),
-                 '6-2014': datetime.datetime(2014, 6, 1),
-                 }
+                 '6-2014': datetime.datetime(2014, 6, 1), }
 
         for date_str, expected in compat.iteritems(cases):
             result1, _, _ = tools.parse_time_string(date_str)
@@ -560,8 +544,7 @@ class TestDatetimeParsingWrappers(tm.TestCase):
 
     def test_parsers_quarter_invalid(self):
 
-        cases = ['2Q 2005', '2Q-200A', '2Q-200',
-                 '22Q2005', '6Q-20', '2Q200.']
+        cases = ['2Q 2005', '2Q-200A', '2Q-200', '22Q2005', '6Q-20', '2Q200.']
         for case in cases:
             self.assertRaises(ValueError, tools.parse_time_string, case)
 
@@ -579,8 +562,9 @@ class TestDatetimeParsingWrappers(tm.TestCase):
         tm._skip_if_no_dateutil()
         from dateutil.parser import parse
         for date_str, values in compat.iteritems(cases):
-            for dayfirst, yearfirst ,expected in values:
-                result1, _, _ = tools.parse_time_string(date_str, dayfirst=dayfirst,
+            for dayfirst, yearfirst, expected in values:
+                result1, _, _ = tools.parse_time_string(date_str,
+                                                        dayfirst=dayfirst,
                                                         yearfirst=yearfirst)
 
                 result2 = to_datetime(date_str, dayfirst=dayfirst,
@@ -596,7 +580,8 @@ class TestDatetimeParsingWrappers(tm.TestCase):
                 self.assertEqual(result3, expected)
 
                 # compare with dateutil result
-                dateutil_result = parse(date_str, dayfirst=dayfirst, yearfirst=yearfirst)
+                dateutil_result = parse(date_str, dayfirst=dayfirst,
+                                        yearfirst=yearfirst)
                 self.assertEqual(dateutil_result, expected)
 
     def test_parsers_timestring(self):
@@ -605,7 +590,7 @@ class TestDatetimeParsingWrappers(tm.TestCase):
 
         # must be the same as dateutil result
         cases = {'10:15': (parse('10:15'), datetime.datetime(1, 1, 1, 10, 15)),
-                 '9:05': (parse('9:05'), datetime.datetime(1, 1, 1, 9, 5)) }
+                 '9:05': (parse('9:05'), datetime.datetime(1, 1, 1, 9, 5))}
 
         for date_str, (exp_now, exp_def) in compat.iteritems(cases):
             result1, _, _ = tools.parse_time_string(date_str)
@@ -647,9 +632,9 @@ class TestDatetimeParsingWrappers(tm.TestCase):
         self.assert_numpy_array_equal(tools.to_time(arg, format="%I:%M%p",
                                                     errors="ignore"),
                                       np.array(arg))
-        self.assertRaises(ValueError, lambda: tools.to_time(arg,
-                                                            format="%I:%M%p",
-                                                            errors="raise"))
+        self.assertRaises(ValueError,
+                          lambda: tools.to_time(arg, format="%I:%M%p",
+                                                errors="raise"))
         self.assert_series_equal(tools.to_time(Series(arg, name="test")),
                                  Series(expected_arr, name="test"))
         self.assert_numpy_array_equal(tools.to_time(np.array(arg)),
@@ -666,13 +651,14 @@ class TestDatetimeParsingWrappers(tm.TestCase):
             self.assertEqual(result2, expected)
 
     def test_parsers_quarterly_with_freq(self):
-
-        msg = 'Incorrect quarterly string is given, quarter must be between 1 and 4: 2013Q5'
+        msg = ('Incorrect quarterly string is given, quarter '
+               'must be between 1 and 4: 2013Q5')
         with tm.assertRaisesRegexp(tslib.DateParseError, msg):
             tools.parse_time_string('2013Q5')
 
         # GH 5418
-        msg = 'Unable to retrieve month information from given freq: INVLD-L-DEC-SAT'
+        msg = ('Unable to retrieve month information from given freq: '
+               'INVLD-L-DEC-SAT')
         with tm.assertRaisesRegexp(tslib.DateParseError, msg):
             tools.parse_time_string('2013Q1', freq='INVLD-L-DEC-SAT')
 
@@ -702,17 +688,18 @@ class TestDatetimeParsingWrappers(tm.TestCase):
             converted_time = dt_time.tz_localize('UTC').tz_convert(tz)
             self.assertEqual(dt_string_repr, repr(converted_time))
 
+
 class TestArrayToDatetime(tm.TestCase):
     def test_parsing_valid_dates(self):
         arr = np.array(['01-01-2013', '01-02-2013'], dtype=object)
         self.assert_numpy_array_equal(
             tslib.array_to_datetime(arr),
             np.array(
-                    [
-                        '2013-01-01T00:00:00.000000000-0000',
-                        '2013-01-02T00:00:00.000000000-0000'
-                    ],
-                    dtype='M8[ns]'
+                [
+                    '2013-01-01T00:00:00.000000000-0000',
+                    '2013-01-02T00:00:00.000000000-0000'
+                ],
+                dtype='M8[ns]'
             )
         )
 
@@ -720,11 +707,11 @@ class TestArrayToDatetime(tm.TestCase):
         self.assert_numpy_array_equal(
             tslib.array_to_datetime(arr),
             np.array(
-                    [
-                        '2013-09-16T00:00:00.000000000-0000',
-                        '2013-09-17T00:00:00.000000000-0000'
-                    ],
-                    dtype='M8[ns]'
+                [
+                    '2013-09-16T00:00:00.000000000-0000',
+                    '2013-09-17T00:00:00.000000000-0000'
+                ],
+                dtype='M8[ns]'
             )
         )
 
@@ -733,10 +720,12 @@ class TestArrayToDatetime(tm.TestCase):
         # These strings don't look like datetimes so they shouldn't be
         # attempted to be converted
         arr = np.array(['-352.737091', '183.575577'], dtype=object)
-        self.assert_numpy_array_equal(tslib.array_to_datetime(arr, errors='ignore'), arr)
+        self.assert_numpy_array_equal(
+            tslib.array_to_datetime(arr, errors='ignore'), arr)
 
         arr = np.array(['1', '2', '3', '4', '5'], dtype=object)
-        self.assert_numpy_array_equal(tslib.array_to_datetime(arr, errors='ignore'), arr)
+        self.assert_numpy_array_equal(
+            tslib.array_to_datetime(arr, errors='ignore'), arr)
 
     def test_coercing_dates_outside_of_datetime64_ns_bounds(self):
         invalid_dates = [
@@ -748,12 +737,11 @@ class TestArrayToDatetime(tm.TestCase):
         ]
 
         for invalid_date in invalid_dates:
-            self.assertRaises(
-                ValueError,
-                tslib.array_to_datetime,
-                np.array([invalid_date], dtype='object'),
-                errors='raise',
-            )
+            self.assertRaises(ValueError,
+                              tslib.array_to_datetime,
+                              np.array(
+                                  [invalid_date], dtype='object'),
+                              errors='raise', )
             self.assert_numpy_array_equal(
                 tslib.array_to_datetime(
                     np.array([invalid_date], dtype='object'),
@@ -765,11 +753,11 @@ class TestArrayToDatetime(tm.TestCase):
         self.assert_numpy_array_equal(
             tslib.array_to_datetime(arr, errors='coerce'),
             np.array(
-                    [
-                        tslib.iNaT,
-                        '2000-01-01T00:00:00.000000000-0000'
-                    ],
-                    dtype='M8[ns]'
+                [
+                    tslib.iNaT,
+                    '2000-01-01T00:00:00.000000000-0000'
+                ],
+                dtype='M8[ns]'
             )
         )
 
@@ -778,18 +766,19 @@ class TestArrayToDatetime(tm.TestCase):
 
         # Without coercing, the presence of any invalid dates prevents
         # any values from being converted
-        self.assert_numpy_array_equal(tslib.array_to_datetime(arr,errors='ignore'), arr)
+        self.assert_numpy_array_equal(
+            tslib.array_to_datetime(arr, errors='ignore'), arr)
 
         # With coercing, the invalid dates becomes iNaT
         self.assert_numpy_array_equal(
             tslib.array_to_datetime(arr, errors='coerce'),
             np.array(
-                    [
-                        '2013-01-01T00:00:00.000000000-0000',
-                        tslib.iNaT,
-                        tslib.iNaT
-                    ],
-                    dtype='M8[ns]'
+                [
+                    '2013-01-01T00:00:00.000000000-0000',
+                    tslib.iNaT,
+                    tslib.iNaT
+                ],
+                dtype='M8[ns]'
             )
         )
 
@@ -803,9 +792,8 @@ class TestArrayToDatetime(tm.TestCase):
             '12-31-2012 23:00:00-01:00'
         ]
 
-        expected_output = tslib.array_to_datetime(
-            np.array(['01-01-2013 00:00:00'], dtype=object)
-        )
+        expected_output = tslib.array_to_datetime(np.array(
+            ['01-01-2013 00:00:00'], dtype=object))
 
         for dt_string in dt_strings:
             self.assert_numpy_array_equal(
@@ -815,6 +803,7 @@ class TestArrayToDatetime(tm.TestCase):
                 expected_output
             )
 
+
 class TestTimestampNsOperations(tm.TestCase):
     def setUp(self):
         self.timestamp = Timestamp(datetime.datetime.utcnow())
@@ -826,13 +815,16 @@ class TestTimestampNsOperations(tm.TestCase):
         self.assertEqual(modified_value - value, expected_value)
 
     def test_timedelta_ns_arithmetic(self):
-        self.assert_ns_timedelta(self.timestamp + np.timedelta64(-123, 'ns'), -123)
+        self.assert_ns_timedelta(self.timestamp + np.timedelta64(-123, 'ns'),
+                                 -123)
 
     def test_timedelta_ns_based_arithmetic(self):
-        self.assert_ns_timedelta(self.timestamp + np.timedelta64(1234567898, 'ns'), 1234567898)
+        self.assert_ns_timedelta(self.timestamp + np.timedelta64(
+            1234567898, 'ns'), 1234567898)
 
     def test_timedelta_us_arithmetic(self):
-        self.assert_ns_timedelta(self.timestamp + np.timedelta64(-123, 'us'), -123000)
+        self.assert_ns_timedelta(self.timestamp + np.timedelta64(-123, 'us'),
+                                 -123000)
 
     def test_timedelta_ms_arithmetic(self):
         time = self.timestamp + np.timedelta64(-123, 'ms')
@@ -927,65 +919,99 @@ class TestTimestampNsOperations(tm.TestCase):
             self.assertTrue((left - right) is nat)
 
 
-
 class TestTslib(tm.TestCase):
-
     def test_intraday_conversion_factors(self):
-        self.assertEqual(period_asfreq(1, get_freq('D'), get_freq('H'), False), 24)
-        self.assertEqual(period_asfreq(1, get_freq('D'), get_freq('T'), False), 1440)
-        self.assertEqual(period_asfreq(1, get_freq('D'), get_freq('S'), False), 86400)
-        self.assertEqual(period_asfreq(1, get_freq('D'), get_freq('L'), False), 86400000)
-        self.assertEqual(period_asfreq(1, get_freq('D'), get_freq('U'), False), 86400000000)
-        self.assertEqual(period_asfreq(1, get_freq('D'), get_freq('N'), False), 86400000000000)
-
-        self.assertEqual(period_asfreq(1, get_freq('H'), get_freq('T'), False), 60)
-        self.assertEqual(period_asfreq(1, get_freq('H'), get_freq('S'), False), 3600)
-        self.assertEqual(period_asfreq(1, get_freq('H'), get_freq('L'), False), 3600000)
-        self.assertEqual(period_asfreq(1, get_freq('H'), get_freq('U'), False), 3600000000)
-        self.assertEqual(period_asfreq(1, get_freq('H'), get_freq('N'), False), 3600000000000)
-
-        self.assertEqual(period_asfreq(1, get_freq('T'), get_freq('S'), False), 60)
-        self.assertEqual(period_asfreq(1, get_freq('T'), get_freq('L'), False), 60000)
-        self.assertEqual(period_asfreq(1, get_freq('T'), get_freq('U'), False), 60000000)
-        self.assertEqual(period_asfreq(1, get_freq('T'), get_freq('N'), False), 60000000000)
-
-        self.assertEqual(period_asfreq(1, get_freq('S'), get_freq('L'), False), 1000)
-        self.assertEqual(period_asfreq(1, get_freq('S'), get_freq('U'), False), 1000000)
-        self.assertEqual(period_asfreq(1, get_freq('S'), get_freq('N'), False), 1000000000)
-
-        self.assertEqual(period_asfreq(1, get_freq('L'), get_freq('U'), False), 1000)
-        self.assertEqual(period_asfreq(1, get_freq('L'), get_freq('N'), False), 1000000)
-
-        self.assertEqual(period_asfreq(1, get_freq('U'), get_freq('N'), False), 1000)
+        self.assertEqual(period_asfreq(
+            1, get_freq('D'), get_freq('H'), False), 24)
+        self.assertEqual(period_asfreq(
+            1, get_freq('D'), get_freq('T'), False), 1440)
+        self.assertEqual(period_asfreq(
+            1, get_freq('D'), get_freq('S'), False), 86400)
+        self.assertEqual(period_asfreq(1, get_freq(
+            'D'), get_freq('L'), False), 86400000)
+        self.assertEqual(period_asfreq(1, get_freq(
+            'D'), get_freq('U'), False), 86400000000)
+        self.assertEqual(period_asfreq(1, get_freq(
+            'D'), get_freq('N'), False), 86400000000000)
+
+        self.assertEqual(period_asfreq(
+            1, get_freq('H'), get_freq('T'), False), 60)
+        self.assertEqual(period_asfreq(
+            1, get_freq('H'), get_freq('S'), False), 3600)
+        self.assertEqual(period_asfreq(1, get_freq('H'),
+                                       get_freq('L'), False), 3600000)
+        self.assertEqual(period_asfreq(1, get_freq(
+            'H'), get_freq('U'), False), 3600000000)
+        self.assertEqual(period_asfreq(1, get_freq(
+            'H'), get_freq('N'), False), 3600000000000)
+
+        self.assertEqual(period_asfreq(
+            1, get_freq('T'), get_freq('S'), False), 60)
+        self.assertEqual(period_asfreq(
+            1, get_freq('T'), get_freq('L'), False), 60000)
+        self.assertEqual(period_asfreq(1, get_freq(
+            'T'), get_freq('U'), False), 60000000)
+        self.assertEqual(period_asfreq(1, get_freq(
+            'T'), get_freq('N'), False), 60000000000)
+
+        self.assertEqual(period_asfreq(
+            1, get_freq('S'), get_freq('L'), False), 1000)
+        self.assertEqual(period_asfreq(1, get_freq('S'),
+                                       get_freq('U'), False), 1000000)
+        self.assertEqual(period_asfreq(1, get_freq(
+            'S'), get_freq('N'), False), 1000000000)
+
+        self.assertEqual(period_asfreq(
+            1, get_freq('L'), get_freq('U'), False), 1000)
+        self.assertEqual(period_asfreq(1, get_freq('L'),
+                                       get_freq('N'), False), 1000000)
+
+        self.assertEqual(period_asfreq(
+            1, get_freq('U'), get_freq('N'), False), 1000)
 
     def test_period_ordinal_start_values(self):
         # information for 1.1.1970
-        self.assertEqual(0, period_ordinal(1970, 1, 1, 0, 0, 0, 0, 0, get_freq('A')))
-        self.assertEqual(0, period_ordinal(1970, 1, 1, 0, 0, 0, 0, 0, get_freq('M')))
-        self.assertEqual(1, period_ordinal(1970, 1, 1, 0, 0, 0, 0, 0, get_freq('W')))
-        self.assertEqual(0, period_ordinal(1970, 1, 1, 0, 0, 0, 0, 0, get_freq('D')))
-        self.assertEqual(0, period_ordinal(1970, 1, 1, 0, 0, 0, 0, 0, get_freq('B')))
+        self.assertEqual(0, period_ordinal(1970, 1, 1, 0, 0, 0, 0, 0,
+                                           get_freq('A')))
+        self.assertEqual(0, period_ordinal(1970, 1, 1, 0, 0, 0, 0, 0,
+                                           get_freq('M')))
+        self.assertEqual(1, period_ordinal(1970, 1, 1, 0, 0, 0, 0, 0,
+                                           get_freq('W')))
+        self.assertEqual(0, period_ordinal(1970, 1, 1, 0, 0, 0, 0, 0,
+                                           get_freq('D')))
+        self.assertEqual(0, period_ordinal(1970, 1, 1, 0, 0, 0, 0, 0,
+                                           get_freq('B')))
 
     def test_period_ordinal_week(self):
-        self.assertEqual(1, period_ordinal(1970, 1, 4, 0, 0, 0, 0, 0, get_freq('W')))
-        self.assertEqual(2, period_ordinal(1970, 1, 5, 0, 0, 0, 0, 0, get_freq('W')))
+        self.assertEqual(1, period_ordinal(1970, 1, 4, 0, 0, 0, 0, 0,
+                                           get_freq('W')))
+        self.assertEqual(2, period_ordinal(1970, 1, 5, 0, 0, 0, 0, 0,
+                                           get_freq('W')))
 
-        self.assertEqual(2284, period_ordinal(2013, 10, 6, 0, 0, 0, 0, 0, get_freq('W')))
-        self.assertEqual(2285, period_ordinal(2013, 10, 7, 0, 0, 0, 0, 0, get_freq('W')))
+        self.assertEqual(2284, period_ordinal(2013, 10, 6, 0, 0, 0, 0, 0,
+                                              get_freq('W')))
+        self.assertEqual(2285, period_ordinal(2013, 10, 7, 0, 0, 0, 0, 0,
+                                              get_freq('W')))
 
     def test_period_ordinal_business_day(self):
         # Thursday
-        self.assertEqual(11415, period_ordinal(2013, 10, 3, 0, 0, 0, 0, 0, get_freq('B')))
+        self.assertEqual(11415, period_ordinal(2013, 10, 3, 0, 0, 0, 0, 0,
+                                               get_freq('B')))
         # Friday
-        self.assertEqual(11416, period_ordinal(2013, 10, 4, 0, 0, 0, 0, 0, get_freq('B')))
+        self.assertEqual(11416, period_ordinal(2013, 10, 4, 0, 0, 0, 0, 0,
+                                               get_freq('B')))
         # Saturday
-        self.assertEqual(11417, period_ordinal(2013, 10, 5, 0, 0, 0, 0, 0, get_freq('B')))
+        self.assertEqual(11417, period_ordinal(2013, 10, 5, 0, 0, 0, 0, 0,
+                                               get_freq('B')))
         # Sunday
-        self.assertEqual(11417, period_ordinal(2013, 10, 6, 0, 0, 0, 0, 0, get_freq('B')))
+        self.assertEqual(11417, period_ordinal(2013, 10, 6, 0, 0, 0, 0, 0,
+                                               get_freq('B')))
         # Monday
-        self.assertEqual(11417, period_ordinal(2013, 10, 7, 0, 0, 0, 0, 0, get_freq('B')))
+        self.assertEqual(11417, period_ordinal(2013, 10, 7, 0, 0, 0, 0, 0,
+                                               get_freq('B')))
         # Tuesday
-        self.assertEqual(11418, period_ordinal(2013, 10, 8, 0, 0, 0, 0, 0, get_freq('B')))
+        self.assertEqual(11418, period_ordinal(2013, 10, 8, 0, 0, 0, 0, 0,
+                                               get_freq('B')))
 
     def test_tslib_tz_convert(self):
         def compare_utc_to_local(tz_didx, utc_didx):
@@ -1006,7 +1032,8 @@ class TestTslib(tm.TestCase):
             tz_didx = date_range('2014-03-01', '2015-01-10', freq='H', tz=tz)
             utc_didx = date_range('2014-03-01', '2015-01-10', freq='H')
             compare_utc_to_local(tz_didx, utc_didx)
-            # local tz to UTC can be differ in hourly (or higher) freqs because of DST
+            # local tz to UTC can be differ in hourly (or higher) freqs because
+            # of DST
             compare_local_to_utc(tz_didx, utc_didx)
 
             tz_didx = date_range('2000-01-01', '2020-01-01', freq='D', tz=tz)
@@ -1029,26 +1056,32 @@ class TestTslib(tm.TestCase):
         result = tslib.tz_convert(np.array([tslib.iNaT], dtype=np.int64),
                                   tslib.maybe_get_tz('US/Eastern'),
                                   tslib.maybe_get_tz('Asia/Tokyo'))
-        self.assert_numpy_array_equal(result, np.array([tslib.iNaT], dtype=np.int64))
+        self.assert_numpy_array_equal(result, np.array(
+            [tslib.iNaT], dtype=np.int64))
 
     def test_shift_months(self):
-        s = DatetimeIndex([Timestamp('2000-01-05 00:15:00'), Timestamp('2000-01-31 00:23:00'),
-                           Timestamp('2000-01-01'), Timestamp('2000-02-29'), Timestamp('2000-12-31')])
+        s = DatetimeIndex([Timestamp('2000-01-05 00:15:00'), Timestamp(
+            '2000-01-31 00:23:00'), Timestamp('2000-01-01'), Timestamp(
+                '2000-02-29'), Timestamp('2000-12-31')])
         for years in [-1, 0, 1]:
             for months in [-2, 0, 2]:
-                actual = DatetimeIndex(tslib.shift_months(s.asi8, years * 12 + months))
-                expected = DatetimeIndex([x + offsets.DateOffset(years=years, months=months) for x in s])
+                actual = DatetimeIndex(tslib.shift_months(s.asi8, years * 12 +
+                                                          months))
+                expected = DatetimeIndex([x + offsets.DateOffset(
+                    years=years, months=months) for x in s])
                 tm.assert_index_equal(actual, expected)
 
 
-
 class TestTimestampOps(tm.TestCase):
     def test_timestamp_and_datetime(self):
-        self.assertEqual((Timestamp(datetime.datetime(2013, 10, 13)) - datetime.datetime(2013, 10, 12)).days, 1)
-        self.assertEqual((datetime.datetime(2013, 10, 12) - Timestamp(datetime.datetime(2013, 10, 13))).days, -1)
+        self.assertEqual((Timestamp(datetime.datetime(
+            2013, 10, 13)) - datetime.datetime(2013, 10, 12)).days, 1)
+        self.assertEqual((datetime.datetime(2013, 10, 12) -
+                          Timestamp(datetime.datetime(2013, 10, 13))).days, -1)
 
     def test_timestamp_and_series(self):
-        timestamp_series = Series(date_range('2014-03-17', periods=2, freq='D', tz='US/Eastern'))
+        timestamp_series = Series(date_range('2014-03-17', periods=2, freq='D',
+                                             tz='US/Eastern'))
         first_timestamp = timestamp_series[0]
 
         delta_series = Series([np.timedelta64(0, 'D'), np.timedelta64(1, 'D')])
@@ -1056,25 +1089,34 @@ class TestTimestampOps(tm.TestCase):
         assert_series_equal(first_timestamp - timestamp_series, -delta_series)
 
     def test_addition_subtraction_types(self):
-        # Assert on the types resulting from Timestamp +/- various date/time objects
+        # Assert on the types resulting from Timestamp +/- various date/time
+        # objects
         datetime_instance = datetime.datetime(2014, 3, 4)
         timedelta_instance = datetime.timedelta(seconds=1)
-        # build a timestamp with a frequency, since then it supports addition/subtraction of integers
-        timestamp_instance = date_range(datetime_instance, periods=1, freq='D')[0]
+        # build a timestamp with a frequency, since then it supports
+        # addition/subtraction of integers
+        timestamp_instance = date_range(datetime_instance, periods=1,
+                                        freq='D')[0]
 
         self.assertEqual(type(timestamp_instance + 1), Timestamp)
         self.assertEqual(type(timestamp_instance - 1), Timestamp)
 
-        # Timestamp + datetime not supported, though subtraction is supported and yields timedelta
-        # more tests in tseries/base/tests/test_base.py
-        self.assertEqual(type(timestamp_instance - datetime_instance), Timedelta)
-        self.assertEqual(type(timestamp_instance + timedelta_instance), Timestamp)
-        self.assertEqual(type(timestamp_instance - timedelta_instance), Timestamp)
-
-        # Timestamp +/- datetime64 not supported, so not tested (could possibly assert error raised?)
+        # Timestamp + datetime not supported, though subtraction is supported
+        # and yields timedelta more tests in tseries/base/tests/test_base.py
+        self.assertEqual(
+            type(timestamp_instance - datetime_instance), Timedelta)
+        self.assertEqual(
+            type(timestamp_instance + timedelta_instance), Timestamp)
+        self.assertEqual(
+            type(timestamp_instance - timedelta_instance), Timestamp)
+
+        # Timestamp +/- datetime64 not supported, so not tested (could possibly
+        # assert error raised?)
         timedelta64_instance = np.timedelta64(1, 'D')
-        self.assertEqual(type(timestamp_instance + timedelta64_instance), Timestamp)
-        self.assertEqual(type(timestamp_instance - timedelta64_instance), Timestamp)
+        self.assertEqual(
+            type(timestamp_instance + timedelta64_instance), Timestamp)
+        self.assertEqual(
+            type(timestamp_instance - timedelta64_instance), Timestamp)
 
     def test_addition_subtraction_preserve_frequency(self):
         timestamp_instance = date_range('2014-03-05', periods=1, freq='D')[0]
@@ -1082,20 +1124,30 @@ class TestTimestampOps(tm.TestCase):
         original_freq = timestamp_instance.freq
         self.assertEqual((timestamp_instance + 1).freq, original_freq)
         self.assertEqual((timestamp_instance - 1).freq, original_freq)
-        self.assertEqual((timestamp_instance + timedelta_instance).freq, original_freq)
-        self.assertEqual((timestamp_instance - timedelta_instance).freq, original_freq)
+        self.assertEqual(
+            (timestamp_instance + timedelta_instance).freq, original_freq)
+        self.assertEqual(
+            (timestamp_instance - timedelta_instance).freq, original_freq)
 
         timedelta64_instance = np.timedelta64(1, 'D')
-        self.assertEqual((timestamp_instance + timedelta64_instance).freq, original_freq)
-        self.assertEqual((timestamp_instance - timedelta64_instance).freq, original_freq)
+        self.assertEqual(
+            (timestamp_instance + timedelta64_instance).freq, original_freq)
+        self.assertEqual(
+            (timestamp_instance - timedelta64_instance).freq, original_freq)
 
     def test_resolution(self):
 
-        for freq, expected in zip(['A', 'Q', 'M', 'D', 'H', 'T', 'S', 'L', 'U'],
-                                  [period.D_RESO, period.D_RESO, period.D_RESO, period.D_RESO,
-                                   period.H_RESO, period.T_RESO, period.S_RESO, period.MS_RESO, period.US_RESO]):
-            for tz in [None, 'Asia/Tokyo', 'US/Eastern', 'dateutil/US/Eastern']:
-                idx = date_range(start='2013-04-01', periods=30, freq=freq, tz=tz)
+        for freq, expected in zip(['A', 'Q', 'M', 'D', 'H', 'T',
+                                   'S', 'L', 'U'],
+                                  [period.D_RESO, period.D_RESO,
+                                   period.D_RESO, period.D_RESO,
+                                   period.H_RESO, period.T_RESO,
+                                   period.S_RESO, period.MS_RESO,
+                                   period.US_RESO]):
+            for tz in [None, 'Asia/Tokyo', 'US/Eastern', 'dateutil/US/Eastern'
+                       ]:
+                idx = date_range(start='2013-04-01', periods=30, freq=freq,
+                                 tz=tz)
                 result = period.resolution(idx.asi8, idx.tz)
                 self.assertEqual(result, expected)
 
diff --git a/pandas/tseries/tests/test_util.py b/pandas/tseries/tests/test_util.py
index c75fcbdac..9c5c9b7a0 100644
--- a/pandas/tseries/tests/test_util.py
+++ b/pandas/tseries/tests/test_util.py
@@ -2,7 +2,6 @@ from pandas.compat import range
 import nose
 
 import numpy as np
-from numpy.testing.decorators import slow
 
 from pandas import Series, date_range
 import pandas.util.testing as tm
@@ -17,6 +16,7 @@ class TestPivotAnnual(tm.TestCase):
     """
     New pandas of scikits.timeseries pivot_annual
     """
+
     def test_daily(self):
         rng = date_range('1/1/2000', '12/31/2004', freq='D')
         ts = Series(np.random.randn(len(rng)), index=rng)
@@ -42,8 +42,8 @@ class TestPivotAnnual(tm.TestCase):
         tm.assert_series_equal(annual[day].dropna(), leaps)
 
     def test_hourly(self):
-        rng_hourly = date_range(
-            '1/1/1994', periods=(18 * 8760 + 4 * 24), freq='H')
+        rng_hourly = date_range('1/1/1994', periods=(18 * 8760 + 4 * 24),
+                                freq='H')
         data_hourly = np.random.randint(100, 350, rng_hourly.size)
         ts_hourly = Series(data_hourly, index=rng_hourly)
 
@@ -64,15 +64,13 @@ class TestPivotAnnual(tm.TestCase):
             tm.assert_series_equal(result, subset, check_names=False)
             self.assertEqual(result.name, i)
 
-        leaps = ts_hourly[(ts_hourly.index.month == 2) &
-                          (ts_hourly.index.day == 29) &
-                          (ts_hourly.index.hour == 0)]
+        leaps = ts_hourly[(ts_hourly.index.month == 2) & (
+            ts_hourly.index.day == 29) & (ts_hourly.index.hour == 0)]
         hour = leaps.index.dayofyear[0] * 24 - 23
         leaps.index = leaps.index.year
         leaps.name = 1417
         tm.assert_series_equal(annual[hour].dropna(), leaps)
 
-
     def test_weekly(self):
         pass
 
@@ -104,12 +102,13 @@ def test_normalize_date():
     value = date(2012, 9, 7)
 
     result = normalize_date(value)
-    assert(result == datetime(2012, 9, 7))
+    assert (result == datetime(2012, 9, 7))
 
     value = datetime(2012, 9, 7, 12)
 
     result = normalize_date(value)
-    assert(result == datetime(2012, 9, 7))
+    assert (result == datetime(2012, 9, 7))
+
 
 if __name__ == '__main__':
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
diff --git a/pandas/tseries/timedeltas.py b/pandas/tseries/timedeltas.py
index b769eb240..7ff5d7adc 100644
--- a/pandas/tseries/timedeltas.py
+++ b/pandas/tseries/timedeltas.py
@@ -2,15 +2,14 @@
 timedelta support tools
 """
 
-import re
 import numpy as np
 import pandas.tslib as tslib
-from pandas import compat
 from pandas.core.common import (ABCSeries, is_integer_dtype,
                                 is_timedelta64_dtype, is_list_like,
-                                isnull, _ensure_object, ABCIndexClass)
+                                _ensure_object, ABCIndexClass)
 from pandas.util.decorators import deprecate_kwarg
 
+
 @deprecate_kwarg(old_arg_name='coerce', new_arg_name='errors',
                  mapping={True: 'coerce', False: 'raise'})
 def to_timedelta(arg, unit='ns', box=True, errors='raise', coerce=None):
@@ -20,10 +19,12 @@ def to_timedelta(arg, unit='ns', box=True, errors='raise', coerce=None):
     Parameters
     ----------
     arg : string, timedelta, list, tuple, 1-d array, or Series
-    unit : unit of the arg (D,h,m,s,ms,us,ns) denote the unit, which is an integer/float number
+    unit : unit of the arg (D,h,m,s,ms,us,ns) denote the unit, which is an
+        integer/float number
     box : boolean, default True
         - If True returns a Timedelta/TimedeltaIndex of the results
-        - if False returns a np.timedelta64 or ndarray of values of dtype timedelta64[ns]
+        - if False returns a np.timedelta64 or ndarray of values of dtype
+          timedelta64[ns]
     errors : {'ignore', 'raise', 'coerce'}, default 'raise'
         - If 'raise', then invalid parsing will raise an exception
         - If 'coerce', then invalid parsing will be set as NaT
@@ -46,14 +47,18 @@ def to_timedelta(arg, unit='ns', box=True, errors='raise', coerce=None):
     Parsing a list or array of strings:
 
     >>> pd.to_timedelta(['1 days 06:05:01.00003', '15.5us', 'nan'])
-    TimedeltaIndex(['1 days 06:05:01.000030', '0 days 00:00:00.000015', NaT], dtype='timedelta64[ns]', freq=None)
+    TimedeltaIndex(['1 days 06:05:01.000030', '0 days 00:00:00.000015', NaT],
+                   dtype='timedelta64[ns]', freq=None)
 
     Converting numbers by specifying the `unit` keyword argument:
 
     >>> pd.to_timedelta(np.arange(5), unit='s')
-    TimedeltaIndex(['00:00:00', '00:00:01', '00:00:02', '00:00:03', '00:00:04'], dtype='timedelta64[ns]', freq=None)
+    TimedeltaIndex(['00:00:00', '00:00:01', '00:00:02',
+                    '00:00:03', '00:00:04'],
+                   dtype='timedelta64[ns]', freq=None)
     >>> pd.to_timedelta(np.arange(5), unit='d')
-    TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'], dtype='timedelta64[ns]', freq=None)
+    TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'],
+                   dtype='timedelta64[ns]', freq=None)
     """
     unit = _validate_timedelta_unit(unit)
 
@@ -66,14 +71,16 @@ def to_timedelta(arg, unit='ns', box=True, errors='raise', coerce=None):
         if is_timedelta64_dtype(arg):
             value = arg.astype('timedelta64[ns]')
         elif is_integer_dtype(arg):
-            value = arg.astype('timedelta64[{0}]'.format(unit)).astype('timedelta64[ns]', copy=False)
+            value = arg.astype('timedelta64[{0}]'.format(
+                unit)).astype('timedelta64[ns]', copy=False)
         else:
-            value = tslib.array_to_timedelta64(_ensure_object(arg), unit=unit, errors=errors)
+            value = tslib.array_to_timedelta64(
+                _ensure_object(arg), unit=unit, errors=errors)
             value = value.astype('timedelta64[ns]', copy=False)
 
         if box:
             from pandas import TimedeltaIndex
-            value = TimedeltaIndex(value,unit='ns', name=name)
+            value = TimedeltaIndex(value, unit='ns', name=name)
         return value
 
     if arg is None:
@@ -87,37 +94,40 @@ def to_timedelta(arg, unit='ns', box=True, errors='raise', coerce=None):
     elif is_list_like(arg) and getattr(arg, 'ndim', 1) == 1:
         return _convert_listlike(arg, box=box, unit=unit)
     elif getattr(arg, 'ndim', 1) > 1:
-        raise TypeError('arg must be a string, timedelta, list, tuple, 1-d array, or Series')
+        raise TypeError('arg must be a string, timedelta, list, tuple, '
+                        '1-d array, or Series')
 
     # ...so it must be a scalar value. Return scalar.
-    return _coerce_scalar_to_timedelta_type(arg, unit=unit, box=box, errors=errors)
+    return _coerce_scalar_to_timedelta_type(arg, unit=unit,
+                                            box=box, errors=errors)
 
 _unit_map = {
-    'Y' : 'Y',
-    'y' : 'Y',
-    'W' : 'W',
-    'w' : 'W',
-    'D' : 'D',
-    'd' : 'D',
-    'days' : 'D',
-    'Days' : 'D',
-    'day'  : 'D',
-    'Day'  : 'D',
-    'M'    : 'M',
-    'H'  : 'h',
-    'h'  : 'h',
-    'm'  : 'm',
-    'T'  : 'm',
-    'S'  : 's',
-    's'  : 's',
-    'L'  : 'ms',
-    'MS' : 'ms',
-    'ms' : 'ms',
-    'US' : 'us',
-    'us' : 'us',
-    'NS' : 'ns',
-    'ns' : 'ns',
-    }
+    'Y': 'Y',
+    'y': 'Y',
+    'W': 'W',
+    'w': 'W',
+    'D': 'D',
+    'd': 'D',
+    'days': 'D',
+    'Days': 'D',
+    'day': 'D',
+    'Day': 'D',
+    'M': 'M',
+    'H': 'h',
+    'h': 'h',
+    'm': 'm',
+    'T': 'm',
+    'S': 's',
+    's': 's',
+    'L': 'ms',
+    'MS': 'ms',
+    'ms': 'ms',
+    'US': 'us',
+    'us': 'us',
+    'NS': 'ns',
+    'ns': 'ns',
+}
+
 
 def _validate_timedelta_unit(arg):
     """ provide validation / translation for timedelta short units """
@@ -128,10 +138,14 @@ def _validate_timedelta_unit(arg):
             return 'ns'
         raise ValueError("invalid timedelta unit {0} provided".format(arg))
 
+
 def _coerce_scalar_to_timedelta_type(r, unit='ns', box=True, errors='raise'):
-    """ convert strings to timedelta; coerce to Timedelta (if box), else np.timedelta64"""
+    """
+    convert strings to timedelta; coerce to Timedelta (if box), else
+    np.timedelta64
+    """
 
-    result = tslib.convert_to_timedelta(r,unit,errors)
+    result = tslib.convert_to_timedelta(r, unit, errors)
     if box:
         result = tslib.Timedelta(result)
 
diff --git a/pandas/tseries/tools.py b/pandas/tseries/tools.py
index 795e125da..734857c6d 100644
--- a/pandas/tseries/tools.py
+++ b/pandas/tseries/tools.py
@@ -37,6 +37,7 @@ try:
 except (ImportError, AttributeError):
     pass
 
+
 def _infer_tzinfo(start, end):
     def _infer(a, b):
         tz = a.tzinfo
@@ -169,6 +170,7 @@ def _guess_datetime_format(dt_str, dayfirst=False,
     if parsed_datetime.strftime(guessed_format) == dt_str:
         return guessed_format
 
+
 def _guess_datetime_format_for_array(arr, **kwargs):
     # Try to guess the format based on the first non-NaN element
     non_nan_elements = com.notnull(arr).nonzero()[0]
@@ -193,13 +195,16 @@ def to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False,
         - If 'ignore', then invalid parsing will return the input
     dayfirst : boolean, default False
         Specify a date parse order if `arg` is str or its list-likes.
-        If True, parses dates with the day first, eg 10/11/12 is parsed as 2012-11-10.
+        If True, parses dates with the day first, eg 10/11/12 is parsed as
+        2012-11-10.
         Warning: dayfirst=True is not strict, but will prefer to parse
         with day first (this is a known bug, based on dateutil behavior).
     yearfirst : boolean, default False
         Specify a date parse order if `arg` is str or its list-likes.
-        - If True parses dates with the year first, eg 10/11/12 is parsed as 2010-11-12.
-        - If both dayfirst and yearfirst are True, yearfirst is preceded (same as dateutil).
+        - If True parses dates with the year first, eg 10/11/12 is parsed as
+          2010-11-12.
+        - If both dayfirst and yearfirst are True, yearfirst is preceded (same
+          as dateutil).
         Warning: yearfirst=True is not strict, but will prefer to parse
         with year first (this is a known bug, based on dateutil beahavior).
 
@@ -269,7 +274,8 @@ def to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False,
     >>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')
     NaT
     """
-    return _to_datetime(arg, errors=errors, dayfirst=dayfirst, yearfirst=yearfirst,
+    return _to_datetime(arg, errors=errors, dayfirst=dayfirst,
+                        yearfirst=yearfirst,
                         utc=utc, box=box, format=format, exact=exact,
                         unit=unit, infer_datetime_format=infer_datetime_format)
 
@@ -293,7 +299,8 @@ def _to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False,
         if com.is_datetime64_ns_dtype(arg):
             if box and not isinstance(arg, DatetimeIndex):
                 try:
-                    return DatetimeIndex(arg, tz='utc' if utc else None, name=name)
+                    return DatetimeIndex(arg, tz='utc' if utc else None,
+                                         name=name)
                 except ValueError:
                     pass
 
@@ -306,13 +313,15 @@ def _to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False,
                 arg = arg.tz_convert(None)
             return arg
 
-        elif format is None and com.is_integer_dtype(arg) and unit=='ns':
+        elif format is None and com.is_integer_dtype(arg) and unit == 'ns':
             result = arg.astype('datetime64[ns]')
             if box:
-                return DatetimeIndex(result, tz='utc' if utc else None, name=name)
+                return DatetimeIndex(result, tz='utc' if utc else None,
+                                     name=name)
             return result
         elif getattr(arg, 'ndim', 1) > 1:
-            raise TypeError('arg must be a string, datetime, list, tuple, 1-d array, or Series')
+            raise TypeError('arg must be a string, datetime, list, tuple, '
+                            '1-d array, or Series')
 
         arg = com._ensure_object(arg)
         require_iso8601 = False
@@ -400,7 +409,7 @@ def _to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False,
     elif com.is_list_like(arg):
         return _convert_listlike(arg, box, format)
 
-    return _convert_listlike(np.array([ arg ]), box, format)[0]
+    return _convert_listlike(np.array([arg]), box, format)[0]
 
 
 def _attempt_YYYYMMDD(arg, errors):
@@ -417,8 +426,8 @@ def _attempt_YYYYMMDD(arg, errors):
     def calc(carg):
         # calculate the actual result
         carg = carg.astype(object)
-        parsed = lib.try_parse_year_month_day(carg/10000,
-                                              carg/100 % 100,
+        parsed = lib.try_parse_year_month_day(carg / 10000,
+                                              carg / 100 % 100,
                                               carg % 100)
         return tslib.array_to_datetime(parsed, errors=errors)
 
@@ -439,14 +448,14 @@ def _attempt_YYYYMMDD(arg, errors):
     # a float with actual np.nan
     try:
         carg = arg.astype(np.float64)
-        return calc_with_mask(carg,com.notnull(carg))
+        return calc_with_mask(carg, com.notnull(carg))
     except:
         pass
 
     # string with NaN-like
     try:
         mask = ~lib.ismember(arg, tslib._nat_strings)
-        return calc_with_mask(arg,mask)
+        return calc_with_mask(arg, mask)
     except:
         pass
 
diff --git a/pandas/tseries/util.py b/pandas/tseries/util.py
index 4f29b2bf3..7e314657c 100644
--- a/pandas/tseries/util.py
+++ b/pandas/tseries/util.py
@@ -1,4 +1,4 @@
-from pandas.compat import range, lrange
+from pandas.compat import lrange
 import numpy as np
 import pandas.core.common as com
 from pandas.core.frame import DataFrame
