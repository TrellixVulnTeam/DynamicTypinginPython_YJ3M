commit 410ad372f747fd536b7aac3d828b6e7353b60654
Author: Matthew Roeschke <emailformattr@gmail.com>
Date:   Sun Nov 19 07:05:34 2017 -0800

    CLN: Lint for lists instead of generators in built-in Python functions (#18335)

diff --git a/asv_bench/benchmarks/frame_ctor.py b/asv_bench/benchmarks/frame_ctor.py
index dec4fcba0..7f95e8d06 100644
--- a/asv_bench/benchmarks/frame_ctor.py
+++ b/asv_bench/benchmarks/frame_ctor.py
@@ -132,7 +132,7 @@ class FrameConstructorDTIndexFromOffsets(object):
         offset = getattr(offsets, offset)
         self.idx = get_index_for_offset(offset(n_steps, **kwargs))
         self.df = DataFrame(np.random.randn(len(self.idx), 10), index=self.idx)
-        self.d = dict([(col, self.df[col]) for col in self.df.columns])
+        self.d = dict(self.df.items())
 
     def time_frame_ctor(self, offset, n_steps):
         DataFrame(self.d)
diff --git a/asv_bench/benchmarks/io_bench.py b/asv_bench/benchmarks/io_bench.py
index 93273955a..d5eedf63d 100644
--- a/asv_bench/benchmarks/io_bench.py
+++ b/asv_bench/benchmarks/io_bench.py
@@ -202,7 +202,7 @@ class read_json_lines(object):
     def setup(self):
         self.N = 100000
         self.C = 5
-        self.df = DataFrame(dict([('float{0}'.format(i), randn(self.N)) for i in range(self.C)]))
+        self.df = DataFrame({('float{0}'.format(i), randn(self.N)) for i in range(self.C)})
         self.df.to_json(self.fname,orient="records",lines=True)
 
     def teardown(self):
diff --git a/asv_bench/benchmarks/packers.py b/asv_bench/benchmarks/packers.py
index 24f80cc83..e3d95aa35 100644
--- a/asv_bench/benchmarks/packers.py
+++ b/asv_bench/benchmarks/packers.py
@@ -17,7 +17,7 @@ class _Packers(object):
         self.N = 100000
         self.C = 5
         self.index = date_range('20000101', periods=self.N, freq='H')
-        self.df = DataFrame(dict([('float{0}'.format(i), randn(self.N)) for i in range(self.C)]), index=self.index)
+        self.df = DataFrame(dict(('float{0}'.format(i), randn(self.N)) for i in range(self.C)), index=self.index)
         self.df2 = self.df.copy()
         self.df2['object'] = [('%08x' % randrange((16 ** 8))) for _ in range(self.N)]
         self.remove(self.f)
diff --git a/asv_bench/vbench_to_asv.py b/asv_bench/vbench_to_asv.py
index 2a4ce5d18..b1179387e 100644
--- a/asv_bench/vbench_to_asv.py
+++ b/asv_bench/vbench_to_asv.py
@@ -69,7 +69,7 @@ class AssignToSelf(ast.NodeTransformer):
         return node
 
     def visit_TryExcept(self, node):
-        if any([isinstance(x, (ast.Import, ast.ImportFrom)) for x in node.body]):
+        if any(isinstance(x, (ast.Import, ast.ImportFrom)) for x in node.body):
             self.imports.append(node)
         else:
             self.generic_visit(node)
diff --git a/ci/lint.sh b/ci/lint.sh
index 71d8c5c7e..402773790 100755
--- a/ci/lint.sh
+++ b/ci/lint.sh
@@ -84,6 +84,19 @@ if [ "$LINT" ]; then
     fi
     echo "Check for invalid testing DONE"
 
+    echo "Check for use of lists instead of generators in built-in Python functions"
+
+    # Example: Avoid `any([i for i in some_iterator])` in favor of `any(i for i in some_iterator)`
+    #
+    # Check the following functions:
+    # any(), all(), sum(), max(), min(), list(), dict(), set(), frozenset(), tuple(), str.join()
+    grep -R --include="*.py*" -E "[^_](any|all|sum|max|min|list|dict|set|frozenset|tuple|join)\(\[.* for .* in .*\]\)"
+
+    if [ $? = "0" ]; then
+        RET=1
+    fi
+    echo "Check for use of lists instead of generators in built-in Python functions DONE"
+
 else
     echo "NOT Linting"
 fi
diff --git a/doc/source/conf.py b/doc/source/conf.py
index c8189b86b..bcb83d569 100644
--- a/doc/source/conf.py
+++ b/doc/source/conf.py
@@ -78,7 +78,7 @@ with open("index.rst") as f:
 # JP: added from sphinxdocs
 autosummary_generate = False
 
-if any([re.match("\s*api\s*", l) for l in index_rst_lines]):
+if any(re.match("\s*api\s*", l) for l in index_rst_lines):
     autosummary_generate = True
 
 files_to_delete = []
@@ -89,7 +89,7 @@ for f in os.listdir(os.path.dirname(__file__)):
 
     _file_basename = os.path.splitext(f)[0]
     _regex_to_match = "\s*{}\s*$".format(_file_basename)
-    if not any([re.match(_regex_to_match, line) for line in index_rst_lines]):
+    if not any(re.match(_regex_to_match, line) for line in index_rst_lines):
         files_to_delete.append(f)
 
 if files_to_delete:
diff --git a/doc/sphinxext/ipython_sphinxext/ipython_directive.py b/doc/sphinxext/ipython_sphinxext/ipython_directive.py
index 922767a8e..4f7b32840 100644
--- a/doc/sphinxext/ipython_sphinxext/ipython_directive.py
+++ b/doc/sphinxext/ipython_sphinxext/ipython_directive.py
@@ -522,7 +522,7 @@ class EmbeddedSphinxShell(object):
                 source = self.directive.state.document.current_source
                 content = self.directive.content
                 # Add tabs and join into a single string.
-                content = '\n'.join([TAB + line for line in content])
+                content = '\n'.join(TAB + line for line in content)
 
             # Make sure the output contains the output prompt.
             ind = found.find(output_prompt)
diff --git a/doc/sphinxext/numpydoc/compiler_unparse.py b/doc/sphinxext/numpydoc/compiler_unparse.py
index 8933a83db..eabb5934c 100755
--- a/doc/sphinxext/numpydoc/compiler_unparse.py
+++ b/doc/sphinxext/numpydoc/compiler_unparse.py
@@ -399,7 +399,7 @@ class UnparseCompilerAst:
         self._fill("return ")
         if t.value:
             if isinstance(t.value, Tuple):
-                text = ', '.join([ name.name for name in t.value.asList() ])
+                text = ', '.join(name.name for name in t.value.asList())
                 self._write(text)
             else:
                 self._dispatch(t.value)
diff --git a/doc/sphinxext/numpydoc/docscrape.py b/doc/sphinxext/numpydoc/docscrape.py
index 2c49ed84a..38cb62581 100755
--- a/doc/sphinxext/numpydoc/docscrape.py
+++ b/doc/sphinxext/numpydoc/docscrape.py
@@ -270,7 +270,7 @@ class NumpyDocString(object):
         # If several signatures present, take the last one
         while True:
             summary = self._doc.read_to_next_empty_line()
-            summary_str = " ".join([s.strip() for s in summary]).strip()
+            summary_str = " ".join(s.strip() for s in summary).strip()
             if re.compile('^([\w., ]+=)?\s*[\w\.]+\(.*\)$').match(summary_str):
                 self['Signature'] = summary_str
                 if not self._is_at_section():
@@ -289,7 +289,7 @@ class NumpyDocString(object):
 
         for (section,content) in self._read_sections():
             if not section.startswith('..'):
-                section = ' '.join([s.capitalize() for s in section.split(' ')])
+                section = ' '.join(s.capitalize() for s in section.split(' '))
             if section in ('Parameters', 'Returns', 'Raises', 'Warns',
                            'Other Parameters', 'Attributes', 'Methods'):
                 self[section] = self._parse_param_list(content)
diff --git a/doc/sphinxext/numpydoc/docscrape_sphinx.py b/doc/sphinxext/numpydoc/docscrape_sphinx.py
index 5a582b4d0..9017480c9 100755
--- a/doc/sphinxext/numpydoc/docscrape_sphinx.py
+++ b/doc/sphinxext/numpydoc/docscrape_sphinx.py
@@ -130,7 +130,7 @@ class SphinxDocString(NumpyDocString):
                 out += [''] + autosum
 
             if others:
-                maxlen_0 = max(3, max([len(x[0]) for x in others]))
+                maxlen_0 = max(3, max(len(x[0]) for x in others))
                 hdr = sixu("=")*maxlen_0 + sixu("  ") + sixu("=")*10
                 fmt = sixu('%%%ds  %%s  ') % (maxlen_0,)
                 out += ['', hdr]
@@ -203,7 +203,7 @@ class SphinxDocString(NumpyDocString):
                 m = re.match(r'.. \[([a-z0-9._-]+)\]', line, re.I)
                 if m:
                     items.append(m.group(1))
-            out += ['   ' + ", ".join(["[%s]_" % item for item in items]), '']
+            out += ['   ' + ", ".join("[%s]_" % item for item in items), '']
         return out
 
     def _str_examples(self):
diff --git a/doc/sphinxext/numpydoc/phantom_import.py b/doc/sphinxext/numpydoc/phantom_import.py
index 4b4fec863..e0bd645f5 100755
--- a/doc/sphinxext/numpydoc/phantom_import.py
+++ b/doc/sphinxext/numpydoc/phantom_import.py
@@ -60,7 +60,7 @@ def import_phantom_module(xml_file):
     # Sort items so that
     # - Base classes come before classes inherited from them
     # - Modules come before their contents
-    all_nodes = dict([(n.attrib['id'], n) for n in root])
+    all_nodes = dict((n.attrib['id'], n) for n in root)
     
     def _get_bases(node, recurse=False):
         bases = [x.attrib['ref'] for x in node.findall('base')]
diff --git a/pandas/_libs/parsers.pyx b/pandas/_libs/parsers.pyx
index 85857c158..546f08d65 100644
--- a/pandas/_libs/parsers.pyx
+++ b/pandas/_libs/parsers.pyx
@@ -770,7 +770,7 @@ cdef class TextReader:
                     msg = self.orig_header
                     if isinstance(msg, list):
                         msg = "[%s], len of %d," % (
-                            ','.join([ str(m) for m in msg ]), len(msg))
+                            ','.join(str(m) for m in msg), len(msg))
                     raise ParserError(
                         'Passed header=%s but only %d lines in file'
                         % (msg, self.parser.lines))
@@ -2227,7 +2227,7 @@ def _concatenate_chunks(list chunks):
     for name in names:
         arrs = [chunk.pop(name) for chunk in chunks]
         # Check each arr for consistent types.
-        dtypes = set([a.dtype for a in arrs])
+        dtypes = set(a.dtype for a in arrs)
         if len(dtypes) > 1:
             common_type = np.find_common_type(dtypes, [])
             if common_type == np.object:
diff --git a/pandas/_libs/src/inference.pyx b/pandas/_libs/src/inference.pyx
index c432c40c8..ad2defc7b 100644
--- a/pandas/_libs/src/inference.pyx
+++ b/pandas/_libs/src/inference.pyx
@@ -1309,7 +1309,7 @@ def maybe_convert_objects(ndarray[object] objects, bint try_float=0,
 
     # we try to coerce datetime w/tz but must all have the same tz
     if seen.datetimetz_:
-        if len(set([getattr(val, 'tzinfo', None) for val in objects])) == 1:
+        if len({getattr(val, 'tzinfo', None) for val in objects}) == 1:
             from pandas import DatetimeIndex
             return DatetimeIndex(objects)
         seen.object_ = 1
diff --git a/pandas/_libs/tslibs/resolution.pyx b/pandas/_libs/tslibs/resolution.pyx
index b590121b9..388075903 100644
--- a/pandas/_libs/tslibs/resolution.pyx
+++ b/pandas/_libs/tslibs/resolution.pyx
@@ -218,7 +218,7 @@ class Resolution(object):
         'U': 'N',
         'N': None}
 
-    _str_reso_map = dict([(v, k) for k, v in _reso_str_map.items()])
+    _str_reso_map = {v: k for k, v in _reso_str_map.items()}
 
     _reso_freq_map = {
         'year': 'A',
@@ -232,8 +232,7 @@ class Resolution(object):
         'microsecond': 'U',
         'nanosecond': 'N'}
 
-    _freq_reso_map = dict([(v, k)
-                           for k, v in _reso_freq_map.items()])
+    _freq_reso_map = {v: k for k, v in _reso_freq_map.items()}
 
     @classmethod
     def get_str(cls, reso):
diff --git a/pandas/_libs/tslibs/strptime.pyx b/pandas/_libs/tslibs/strptime.pyx
index 64a972dac..439cc21a3 100644
--- a/pandas/_libs/tslibs/strptime.pyx
+++ b/pandas/_libs/tslibs/strptime.pyx
@@ -568,7 +568,7 @@ class TimeRE(dict):
                 break
         else:
             return ''
-        regex = '|'.join([re.escape(stuff) for stuff in to_convert])
+        regex = '|'.join(re.escape(stuff) for stuff in to_convert)
         regex = '(?P<%s>%s' % (directive, regex)
         return '%s)' % regex
 
diff --git a/pandas/_version.py b/pandas/_version.py
index 0fdb0efde..4a469ebb8 100644
--- a/pandas/_version.py
+++ b/pandas/_version.py
@@ -141,11 +141,11 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         if verbose:
             print("keywords are unexpanded, not using")
         raise NotThisMethod("unexpanded keywords, not a git-archive tarball")
-    refs = set([r.strip() for r in refnames.strip("()").split(",")])
+    refs = set(r.strip() for r in refnames.strip("()").split(","))
     # starting in git-1.8.3, tags are listed as "tag: foo-1.0" instead of
     # just "foo-1.0". If we see a "tag: " prefix, prefer those.
     TAG = "tag: "
-    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])
+    tags = set(r[len(TAG):] for r in refs if r.startswith(TAG))
     if not tags:
         # Either we're using git < 1.8.3, or there really are no tags. We use
         # a heuristic: assume all version tags have a digit. The old git %d
@@ -154,7 +154,7 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         # between branches and tags. By ignoring refnames without digits, we
         # filter out many common branch names like "release" and
         # "stabilization", as well as "HEAD" and "master".
-        tags = set([r for r in refs if re.search(r'\d', r)])
+        tags = set(r for r in refs if re.search(r'\d', r))
         if verbose:
             print("discarding '{}', no digits".format(",".join(refs - tags)))
     if verbose:
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 29d278b6e..8e12ce364 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -347,7 +347,7 @@ def map_indices_py(arr):
     Returns a dictionary with (element, index) pairs for each element in the
     given array/list
     """
-    return dict([(x, i) for i, x in enumerate(arr)])
+    return dict((x, i) for i, x in enumerate(arr))
 
 
 def union(*seqs):
diff --git a/pandas/core/dtypes/concat.py b/pandas/core/dtypes/concat.py
index 23884869a..fe306b51d 100644
--- a/pandas/core/dtypes/concat.py
+++ b/pandas/core/dtypes/concat.py
@@ -459,7 +459,7 @@ def _concat_datetimetz(to_concat, name=None):
     it is used in DatetimeIndex.append also
     """
     # do not pass tz to set because tzlocal cannot be hashed
-    if len(set([str(x.dtype) for x in to_concat])) != 1:
+    if len(set(str(x.dtype) for x in to_concat)) != 1:
         raise ValueError('to_concat must have the same tz')
     tz = to_concat[0].tz
     # no need to localize because internal repr will not be changed
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 4d8fb9d03..7145fa709 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -3895,7 +3895,7 @@ class DataFrame(NDFrame):
                     return self._constructor_sliced(r, index=new_index,
                                                     dtype=r.dtype)
 
-                result = dict([(col, f(col)) for col in this])
+                result = dict((col, f(col)) for col in this)
 
             # non-unique
             else:
@@ -3906,9 +3906,7 @@ class DataFrame(NDFrame):
                     return self._constructor_sliced(r, index=new_index,
                                                     dtype=r.dtype)
 
-                result = dict([
-                    (i, f(i)) for i, col in enumerate(this.columns)
-                ])
+                result = dict((i, f(i)) for i, col in enumerate(this.columns))
                 result = self._constructor(result, index=new_index, copy=False)
                 result.columns = new_columns
                 return result
@@ -3986,7 +3984,7 @@ class DataFrame(NDFrame):
         if self.columns.is_unique:
 
             def _compare(a, b):
-                return dict([(col, func(a[col], b[col])) for col in a.columns])
+                return dict((col, func(a[col], b[col])) for col in a.columns)
 
             new_data = expressions.evaluate(_compare, str_rep, self, other)
             return self._constructor(data=new_data, index=self.index,
@@ -3995,8 +3993,8 @@ class DataFrame(NDFrame):
         else:
 
             def _compare(a, b):
-                return dict([(i, func(a.iloc[:, i], b.iloc[:, i]))
-                             for i, col in enumerate(a.columns)])
+                return dict((i, func(a.iloc[:, i], b.iloc[:, i]))
+                            for i, col in enumerate(a.columns))
 
             new_data = expressions.evaluate(_compare, str_rep, self, other)
             result = self._constructor(data=new_data, index=self.index,
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 5f0630feb..d93fe52d5 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -279,21 +279,21 @@ class NDFrame(PandasObject, SelectionMixin):
 
     def _construct_axes_dict(self, axes=None, **kwargs):
         """Return an axes dictionary for myself."""
-        d = dict([(a, self._get_axis(a)) for a in (axes or self._AXIS_ORDERS)])
+        d = dict((a, self._get_axis(a)) for a in (axes or self._AXIS_ORDERS))
         d.update(kwargs)
         return d
 
     @staticmethod
     def _construct_axes_dict_from(self, axes, **kwargs):
         """Return an axes dictionary for the passed axes."""
-        d = dict([(a, ax) for a, ax in zip(self._AXIS_ORDERS, axes)])
+        d = dict((a, ax) for a, ax in zip(self._AXIS_ORDERS, axes))
         d.update(kwargs)
         return d
 
     def _construct_axes_dict_for_slice(self, axes=None, **kwargs):
         """Return an axes dictionary for myself."""
-        d = dict([(self._AXIS_SLICEMAP[a], self._get_axis(a))
-                  for a in (axes or self._AXIS_ORDERS)])
+        d = dict((self._AXIS_SLICEMAP[a], self._get_axis(a))
+                 for a in (axes or self._AXIS_ORDERS))
         d.update(kwargs)
         return d
 
@@ -329,7 +329,7 @@ class NDFrame(PandasObject, SelectionMixin):
                         raise TypeError("not enough/duplicate arguments "
                                         "specified!")
 
-        axes = dict([(a, kwargs.pop(a, None)) for a in self._AXIS_ORDERS])
+        axes = dict((a, kwargs.pop(a, None)) for a in self._AXIS_ORDERS)
         return axes, kwargs
 
     @classmethod
@@ -586,10 +586,10 @@ class NDFrame(PandasObject, SelectionMixin):
         # construct the args
         axes, kwargs = self._construct_axes_from_arguments(args, kwargs,
                                                            require_all=True)
-        axes_names = tuple([self._get_axis_name(axes[a])
-                            for a in self._AXIS_ORDERS])
-        axes_numbers = tuple([self._get_axis_number(axes[a])
-                              for a in self._AXIS_ORDERS])
+        axes_names = tuple(self._get_axis_name(axes[a])
+                           for a in self._AXIS_ORDERS)
+        axes_numbers = tuple(self._get_axis_number(axes[a])
+                             for a in self._AXIS_ORDERS)
 
         # we must have unique axes
         if len(axes) != len(set(axes)):
@@ -699,8 +699,8 @@ class NDFrame(PandasObject, SelectionMixin):
                 (self._get_axis_number(axis),))
         try:
             return self.iloc[
-                tuple([0 if i in axis and len(a) == 1 else slice(None)
-                       for i, a in enumerate(self.axes)])]
+                tuple(0 if i in axis and len(a) == 1 else slice(None)
+                      for i, a in enumerate(self.axes))]
         except Exception:
             return self
 
@@ -4277,8 +4277,8 @@ class NDFrame(PandasObject, SelectionMixin):
             elif self.ndim == 3:
 
                 # fill in 2d chunks
-                result = dict([(col, s.fillna(method=method, value=value))
-                               for col, s in self.iteritems()])
+                result = dict((col, s.fillna(method=method, value=value))
+                              for col, s in self.iteritems())
                 new_obj = self._constructor.\
                     from_dict(result).__finalize__(self)
                 new_data = new_obj._data
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 8bd9b822e..8338df33f 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -471,7 +471,7 @@ class _GroupBy(PandasObject, SelectionMixin):
                     raise ValueError(msg)
 
             converters = [get_converter(s) for s in index_sample]
-            names = [tuple([f(n) for f, n in zip(converters, name)])
+            names = [tuple(f(n) for f, n in zip(converters, name))
                      for name in names]
 
         else:
diff --git a/pandas/core/indexes/api.py b/pandas/core/indexes/api.py
index 08cda8a06..b7af533f9 100644
--- a/pandas/core/indexes/api.py
+++ b/pandas/core/indexes/api.py
@@ -101,7 +101,7 @@ def _union_indexes(indexes):
 
 
 def _sanitize_and_check(indexes):
-    kinds = list(set([type(index) for index in indexes]))
+    kinds = list({type(index) for index in indexes})
 
     if list in kinds:
         if len(kinds) > 1:
@@ -122,8 +122,8 @@ def _get_consensus_names(indexes):
 
     # find the non-none names, need to tupleify to make
     # the set hashable, then reverse on return
-    consensus_names = set([tuple(i.names) for i in indexes
-                           if com._any_not_none(*i.names)])
+    consensus_names = set(tuple(i.names) for i in indexes
+                          if com._any_not_none(*i.names))
     if len(consensus_names) == 1:
         return list(list(consensus_names)[0])
     return [None] * indexes[0].nlevels
diff --git a/pandas/core/indexes/base.py b/pandas/core/indexes/base.py
index 57454e6fc..121bf6a66 100644
--- a/pandas/core/indexes/base.py
+++ b/pandas/core/indexes/base.py
@@ -732,7 +732,7 @@ class Index(IndexOpsMixin, PandasObject):
 
     def _get_attributes_dict(self):
         """ return an attributes dict for my class """
-        return dict([(k, getattr(self, k, None)) for k in self._attributes])
+        return dict((k, getattr(self, k, None)) for k in self._attributes)
 
     def view(self, cls=None):
 
@@ -838,7 +838,7 @@ class Index(IndexOpsMixin, PandasObject):
         space = self._format_space()
 
         prepr = (u(",%s") %
-                 space).join([u("%s=%s") % (k, v) for k, v in attrs])
+                 space).join(u("%s=%s") % (k, v) for k, v in attrs)
 
         # no data provided, just attributes
         if data is None:
@@ -1781,7 +1781,7 @@ class Index(IndexOpsMixin, PandasObject):
             if not isinstance(obj, Index):
                 raise TypeError('all inputs must be Index')
 
-        names = set([obj.name for obj in to_concat])
+        names = set(obj.name for obj in to_concat)
         name = None if len(names) > 1 else self.name
 
         return self._concat(to_concat, name)
diff --git a/pandas/core/indexes/interval.py b/pandas/core/indexes/interval.py
index 6ae55b063..2461355df 100644
--- a/pandas/core/indexes/interval.py
+++ b/pandas/core/indexes/interval.py
@@ -1002,7 +1002,7 @@ class IntervalIndex(IntervalMixin, Index):
         assert that we all have the same .closed
         we allow a 0-len index here as well
         """
-        if not len(set([i.closed for i in to_concat if len(i)])) == 1:
+        if not len(set(i.closed for i in to_concat if len(i))) == 1:
             msg = ('can only append two IntervalIndex objects '
                    'that are closed on the same side')
             raise ValueError(msg)
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index ae799afdb..90733fa6d 100755
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -2055,7 +2055,7 @@ def convert_from_missing_indexer_tuple(indexer, axes):
         return (axes[_i].get_loc(_idx['key']) if isinstance(_idx, dict) else
                 _idx)
 
-    return tuple([get_indexer(_i, _idx) for _i, _idx in enumerate(indexer)])
+    return tuple(get_indexer(_i, _idx) for _i, _idx in enumerate(indexer))
 
 
 def maybe_convert_indices(indices, n):
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 07d0f0ffe..5a19e4c38 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -241,7 +241,7 @@ class Block(PandasObject):
 
         else:
 
-            shape = ' x '.join([pprint_thing(s) for s in self.shape])
+            shape = ' x '.join(pprint_thing(s) for s in self.shape)
             result = '{name}: {index}, {shape}, dtype: {dtype}'.format(
                 name=name, index=pprint_thing(self.mgr_locs.indexer),
                 shape=shape, dtype=self.dtype)
@@ -3376,7 +3376,7 @@ class BlockManager(PandasObject):
             blocks.append(block)
 
         # note that some DatetimeTZ, Categorical are always ndim==1
-        ndim = set([b.ndim for b in blocks])
+        ndim = set(b.ndim for b in blocks)
 
         if 2 in ndim:
 
@@ -4870,7 +4870,7 @@ def _merge_blocks(blocks, dtype=None, _can_consolidate=True):
     if _can_consolidate:
 
         if dtype is None:
-            if len(set([b.dtype for b in blocks])) != 1:
+            if len(set(b.dtype for b in blocks)) != 1:
                 raise AssertionError("_merge_blocks are invalid!")
             dtype = blocks[0].dtype
 
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 327180b6a..0a5e70507 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -1080,7 +1080,7 @@ class Panel(NDFrame):
         for i in range(np.prod(shape)):
 
             # construct the object
-            pts = tuple([p[i] for p in points])
+            pts = tuple(p[i] for p in points)
             indexer.put(indlist, slice_indexer)
 
             obj = Series(values[tuple(indexer)], index=slice_axis, name=pts)
@@ -1417,10 +1417,10 @@ class Panel(NDFrame):
     @staticmethod
     def _extract_axes_for_slice(self, axes):
         """ return the slice dictionary for these axes """
-        return dict([(self._AXIS_SLICEMAP[i], a)
-                     for i, a in zip(
-                         self._AXIS_ORDERS[self._AXIS_LEN - len(axes):],
-                         axes)])
+        return dict((self._AXIS_SLICEMAP[i], a)
+                    for i, a in zip(
+                        self._AXIS_ORDERS[self._AXIS_LEN - len(axes):],
+                        axes))
 
     @staticmethod
     def _prep_ndarray(self, values, copy=True):
@@ -1468,8 +1468,8 @@ class Panel(NDFrame):
                 adj_frames[k] = v
 
         axes = self._AXIS_ORDERS[1:]
-        axes_dict = dict([(a, ax) for a, ax in zip(axes, self._extract_axes(
-            self, adj_frames, axes, intersect=intersect))])
+        axes_dict = dict((a, ax) for a, ax in zip(axes, self._extract_axes(
+            self, adj_frames, axes, intersect=intersect)))
 
         reindex_dict = dict(
             [(self._AXIS_SLICEMAP[a], axes_dict[a]) for a in axes])
diff --git a/pandas/core/panelnd.py b/pandas/core/panelnd.py
index 7a5cb63cd..691787125 100644
--- a/pandas/core/panelnd.py
+++ b/pandas/core/panelnd.py
@@ -105,7 +105,7 @@ def create_nd_panel_factory(klass_name, orders, slices, slicer, aliases=None,
             new_axes.append(getattr(self, a).union(getattr(other, a)))
 
         # reindex: could check that everything's the same size, but forget it
-        d = dict([(a, ax) for a, ax in zip(self._AXIS_ORDERS, new_axes)])
+        d = dict((a, ax) for a, ax in zip(self._AXIS_ORDERS, new_axes))
         d['copy'] = False
         this = self.reindex(**d)
         other = other.reindex(**d)
diff --git a/pandas/core/reshape/concat.py b/pandas/core/reshape/concat.py
index 6b07054ed..6139f0932 100644
--- a/pandas/core/reshape/concat.py
+++ b/pandas/core/reshape/concat.py
@@ -568,7 +568,7 @@ def _make_concat_multiindex(indexes, keys, levels=None, names=None):
             names = list(names)
         else:
             # make sure that all of the passed indices have the same nlevels
-            if not len(set([idx.nlevels for idx in indexes])) == 1:
+            if not len(set(idx.nlevels for idx in indexes)) == 1:
                 raise AssertionError("Cannot concat indices that do"
                                      " not have the same number of levels")
 
diff --git a/pandas/core/sparse/frame.py b/pandas/core/sparse/frame.py
index 22a88264c..0c9a55e0c 100644
--- a/pandas/core/sparse/frame.py
+++ b/pandas/core/sparse/frame.py
@@ -173,7 +173,7 @@ class SparseDataFrame(DataFrame):
         """ Init self from ndarray or list of lists """
         data = _prep_ndarray(data, copy=False)
         index, columns = self._prep_index(data, index, columns)
-        data = dict([(idx, data[:, i]) for i, idx in enumerate(columns)])
+        data = dict((idx, data[:, i]) for i, idx in enumerate(columns))
         return self._init_dict(data, index, columns, dtype)
 
     def _init_spmatrix(self, data, index, columns, dtype=None,
diff --git a/pandas/io/clipboards.py b/pandas/io/clipboards.py
index 6252a02b0..117c96d00 100644
--- a/pandas/io/clipboards.py
+++ b/pandas/io/clipboards.py
@@ -53,7 +53,7 @@ def read_clipboard(sep='\s+', **kwargs):  # pragma: no cover
     # 0  1  2
     # 1  3  4
 
-    counts = set([x.lstrip().count('\t') for x in lines])
+    counts = set(x.lstrip().count('\t') for x in lines)
     if len(lines) > 1 and len(counts) == 1 and counts.pop() != 0:
         sep = '\t'
 
diff --git a/pandas/io/html.py b/pandas/io/html.py
index f29062968..d0861f1aa 100644
--- a/pandas/io/html.py
+++ b/pandas/io/html.py
@@ -699,7 +699,7 @@ def _parser_dispatch(flavor):
 
 
 def _print_as_set(s):
-    return '{{arg}}'.format(arg=', '.join([pprint_thing(el) for el in s]))
+    return '{{arg}}'.format(arg=', '.join(pprint_thing(el) for el in s))
 
 
 def _validate_flavor(flavor):
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index ee336dff0..38d9baee8 100755
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -1133,8 +1133,8 @@ def _evaluate_usecols(usecols, names):
     If not a callable, returns 'usecols'.
     """
     if callable(usecols):
-        return set([i for i, name in enumerate(names)
-                    if usecols(name)])
+        return set(i for i, name in enumerate(names)
+                   if usecols(name))
     return usecols
 
 
@@ -1356,7 +1356,7 @@ class ParserBase(object):
         field_count = len(header[0])
 
         def extract(r):
-            return tuple([r[i] for i in range(field_count) if i not in sic])
+            return tuple(r[i] for i in range(field_count) if i not in sic)
 
         columns = lzip(*[extract(r) for r in header])
         names = ic + columns
@@ -1371,7 +1371,7 @@ class ParserBase(object):
                 raise ParserError(
                     "Passed header=[%s] are too many rows for this "
                     "multi_index of columns"
-                    % ','.join([str(x) for x in self.header])
+                    % ','.join(str(x) for x in self.header)
                 )
 
         # clean the column names (if we have an index_col)
@@ -3133,7 +3133,7 @@ def _try_convert_dates(parser, colspec, data_dict, columns):
         else:
             colnames.append(c)
 
-    new_name = '_'.join([str(x) for x in colnames])
+    new_name = '_'.join(str(x) for x in colnames)
     to_parse = [data_dict[c] for c in colnames if c in data_dict]
 
     new_col = parser(*to_parse)
@@ -3156,9 +3156,9 @@ def _clean_na_values(na_values, keep_default_na=True):
                     v = [v]
                 v = set(v) | _NA_VALUES
                 na_values[k] = v
-        na_fvalues = dict([
+        na_fvalues = dict(
             (k, _floatify_na_values(v)) for k, v in na_values.items()  # noqa
-        ])
+        )
     else:
         if not is_list_like(na_values):
             na_values = [na_values]
@@ -3310,7 +3310,7 @@ def _concat_date_cols(date_cols):
                 for x in date_cols[0]
             ], dtype=object)
 
-    rs = np.array([' '.join([compat.text_type(y) for y in x])
+    rs = np.array([' '.join(compat.text_type(y) for y in x)
                    for x in zip(*date_cols)], dtype=object)
     return rs
 
@@ -3381,7 +3381,7 @@ class FixedWidthReader(BaseIterator):
 
     def detect_colspecs(self, n=100, skiprows=None):
         # Regex escape the delimiters
-        delimiters = ''.join([r'\%s' % x for x in self.delimiter])
+        delimiters = ''.join(r'\%s' % x for x in self.delimiter)
         pattern = re.compile('([^%s]+)' % delimiters)
         rows = self.get_rows(n, skiprows)
         if not rows:
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 5d8299ff1..b9cddce55 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -815,7 +815,7 @@ class HDFStore(StringMixin):
                     "all tables must have exactly the same nrows!")
 
         # axis is the concentation axes
-        axis = list(set([t.non_index_axes[0][0] for t in tbls]))[0]
+        axis = list(set(t.non_index_axes[0][0] for t in tbls))[0]
 
         def func(_start, _stop, _where):
 
@@ -2238,7 +2238,7 @@ class Fixed(StringMixin):
         version = _ensure_decoded(
             getattr(self.group._v_attrs, 'pandas_version', None))
         try:
-            self.version = tuple([int(x) for x in version.split('.')])
+            self.version = tuple(int(x) for x in version.split('.'))
             if len(self.version) == 2:
                 self.version = self.version + (0,)
         except:
@@ -2259,7 +2259,7 @@ class Fixed(StringMixin):
         s = self.shape
         if s is not None:
             if isinstance(s, (list, tuple)):
-                s = "[%s]" % ','.join([pprint_thing(x) for x in s])
+                s = "[%s]" % ','.join(pprint_thing(x) for x in s)
             return "%-12.12s (shape->%s)" % (self.pandas_type, s)
         return self.pandas_type
 
@@ -2374,8 +2374,8 @@ class GenericFixed(Fixed):
 
     """ a generified fixed version """
     _index_type_map = {DatetimeIndex: 'datetime', PeriodIndex: 'period'}
-    _reverse_index_map = dict([(v, k)
-                               for k, v in compat.iteritems(_index_type_map)])
+    _reverse_index_map = dict((v, k)
+                              for k, v in compat.iteritems(_index_type_map))
     attributes = []
 
     # indexer helpders
@@ -2997,11 +2997,11 @@ class Table(Fixed):
 
         ver = ''
         if self.is_old_version:
-            ver = "[%s]" % '.'.join([str(x) for x in self.version])
+            ver = "[%s]" % '.'.join(str(x) for x in self.version)
 
         return "%-12.12s%s (typ->%s,nrows->%s,ncols->%s,indexers->[%s]%s)" % (
             self.pandas_type, ver, self.table_type_short, self.nrows,
-            self.ncols, ','.join([a.name for a in self.index_axes]), dc
+            self.ncols, ','.join(a.name for a in self.index_axes), dc
         )
 
     def __getitem__(self, c):
@@ -3510,8 +3510,8 @@ class Table(Fixed):
 
         # reorder the blocks in the same order as the existing_table if we can
         if existing_table is not None:
-            by_items = dict([(tuple(b_items.tolist()), (b, b_items))
-                             for b, b_items in zip(blocks, blk_items)])
+            by_items = dict((tuple(b_items.tolist()), (b, b_items))
+                            for b, b_items in zip(blocks, blk_items))
             new_blocks = []
             new_blk_items = []
             for ea in existing_table.values_axes:
@@ -3659,7 +3659,7 @@ class Table(Fixed):
         d = dict(name='table', expectedrows=expectedrows)
 
         # description from the axes & values
-        d['description'] = dict([(a.cname, a.typ) for a in self.axes])
+        d['description'] = dict((a.cname, a.typ) for a in self.axes)
 
         if complib:
             if complevel is None:
diff --git a/pandas/io/sql.py b/pandas/io/sql.py
index c42c19e13..82b1bff75 100644
--- a/pandas/io/sql.py
+++ b/pandas/io/sql.py
@@ -1322,7 +1322,7 @@ class SQLiteTable(SQLTable):
                 keys = [self.keys]
             else:
                 keys = self.keys
-            cnames_br = ", ".join([escape(c) for c in keys])
+            cnames_br = ", ".join(escape(c) for c in keys)
             create_tbl_stmts.append(
                 "CONSTRAINT {tbl}_pk PRIMARY KEY ({cnames_br})".format(
                     tbl=self.name, cnames_br=cnames_br))
@@ -1334,7 +1334,7 @@ class SQLiteTable(SQLTable):
                    if is_index]
         if len(ix_cols):
             cnames = "_".join(ix_cols)
-            cnames_br = ",".join([escape(c) for c in ix_cols])
+            cnames_br = ",".join(escape(c) for c in ix_cols)
             create_stmts.append(
                 "CREATE INDEX " + escape("ix_" + self.name + "_" + cnames) +
                 "ON " + escape(self.name) + " (" + cnames_br + ")")
diff --git a/pandas/plotting/_converter.py b/pandas/plotting/_converter.py
index aadd5a1be..0f06d8772 100644
--- a/pandas/plotting/_converter.py
+++ b/pandas/plotting/_converter.py
@@ -994,7 +994,7 @@ class TimeSeries_DateFormatter(Formatter):
                                  info)
         else:
             format = np.compress(info['maj'], info)
-        self.formatdict = dict([(x, f) for (x, _, _, f) in format])
+        self.formatdict = dict((x, f) for (x, _, _, f) in format)
         return self.formatdict
 
     def set_locs(self, locs):
diff --git a/pandas/plotting/_core.py b/pandas/plotting/_core.py
index c934648a1..c18e17c69 100644
--- a/pandas/plotting/_core.py
+++ b/pandas/plotting/_core.py
@@ -608,7 +608,7 @@ class MPLPlot(object):
         if isinstance(self.data.index, MultiIndex):
             name = self.data.index.names
             if _any_not_none(*name):
-                name = ','.join([pprint_thing(x) for x in name])
+                name = ','.join(pprint_thing(x) for x in name)
             else:
                 name = None
         else:
diff --git a/pandas/stats/moments.py b/pandas/stats/moments.py
index 4e9e1b51e..a0e94aa0c 100644
--- a/pandas/stats/moments.py
+++ b/pandas/stats/moments.py
@@ -219,8 +219,8 @@ def ensure_compat(dispatch, name, arg, func_kw=None, *args, **kwargs):
 
         # give a helpful deprecation message
         # with copy-pastable arguments
-        pargs = ','.join(["{a}={b}".format(a=a, b=b)
-                          for a, b in kwargs.items() if b is not None])
+        pargs = ','.join("{a}={b}".format(a=a, b=b)
+                         for a, b in kwargs.items() if b is not None)
         aargs = ','.join(args)
         if len(aargs):
             aargs += ','
@@ -229,7 +229,7 @@ def ensure_compat(dispatch, name, arg, func_kw=None, *args, **kwargs):
             if is_scalar(b):
                 return "{a}={b}".format(a=a, b=b)
             return "{a}=<{b}>".format(a=a, b=type(b).__name__)
-        aargs = ','.join([f(a, b) for a, b in kwds.items() if b is not None])
+        aargs = ','.join(f(a, b) for a, b in kwds.items() if b is not None)
         warnings.warn("pd.{dispatch}_{name} is deprecated for {klass} "
                       "and will be removed in a future version, replace with "
                       "\n\t{klass}.{dispatch}({pargs}).{name}({aargs})"
diff --git a/pandas/tests/frame/common.py b/pandas/tests/frame/common.py
index b475d25eb..3786facdd 100644
--- a/pandas/tests/frame/common.py
+++ b/pandas/tests/frame/common.py
@@ -32,8 +32,8 @@ class TestData(object):
     @cache_readonly
     def intframe(self):
         # force these all to int64 to avoid platform testing issues
-        return pd.DataFrame(dict([(c, s) for c, s in
-                                  compat.iteritems(_intframe)]),
+        return pd.DataFrame(dict((c, s) for c, s in
+                                 compat.iteritems(_intframe)),
                             dtype=np.int64)
 
     @cache_readonly
@@ -112,7 +112,7 @@ def _check_mixed_float(df, dtype=None):
     # float16 are most likely to be upcasted to float32
     dtypes = dict(A='float32', B='float32', C='float16', D='float64')
     if isinstance(dtype, compat.string_types):
-        dtypes = dict([(k, dtype) for k, v in dtypes.items()])
+        dtypes = dict((k, dtype) for k, v in dtypes.items())
     elif isinstance(dtype, dict):
         dtypes.update(dtype)
     if dtypes.get('A'):
@@ -128,7 +128,7 @@ def _check_mixed_float(df, dtype=None):
 def _check_mixed_int(df, dtype=None):
     dtypes = dict(A='int32', B='uint64', C='uint8', D='int64')
     if isinstance(dtype, compat.string_types):
-        dtypes = dict([(k, dtype) for k, v in dtypes.items()])
+        dtypes = dict((k, dtype) for k, v in dtypes.items())
     elif isinstance(dtype, dict):
         dtypes.update(dtype)
     if dtypes.get('A'):
diff --git a/pandas/tests/frame/test_constructors.py b/pandas/tests/frame/test_constructors.py
index 8291e9d45..6ca90d715 100644
--- a/pandas/tests/frame/test_constructors.py
+++ b/pandas/tests/frame/test_constructors.py
@@ -120,7 +120,7 @@ class TestDataFrameConstructors(TestData):
                 assert(a.dtype == d)
             if ad is None:
                 ad = dict()
-            ad.update(dict([(d, a) for d, a in zipper]))
+            ad.update(dict((d, a) for d, a in zipper))
             return DataFrame(ad)
 
         def _check_mixed_dtypes(df, dtypes=None):
@@ -696,8 +696,8 @@ class TestDataFrameConstructors(TestData):
             mrecs = mrecords.fromarrays(data, names=names)
 
             # fill the comb
-            comb = dict([(k, v.filled()) if hasattr(
-                v, 'filled') else (k, v) for k, v in comb])
+            comb = dict((k, v.filled()) if hasattr(
+                v, 'filled') else (k, v) for k, v in comb)
 
             expected = DataFrame(comb, columns=names)
             result = DataFrame(mrecs)
diff --git a/pandas/tests/frame/test_dtypes.py b/pandas/tests/frame/test_dtypes.py
index 5adcd3b68..7591f1f14 100644
--- a/pandas/tests/frame/test_dtypes.py
+++ b/pandas/tests/frame/test_dtypes.py
@@ -420,8 +420,8 @@ class TestDataFrameDataTypes(TestData):
 
         # mixed casting
         def _check_cast(df, v):
-            assert (list(set([s.dtype.name for
-                              _, s in compat.iteritems(df)]))[0] == v)
+            assert (list(set(s.dtype.name for
+                             _, s in compat.iteritems(df)))[0] == v)
 
         mn = self.all_mixed._get_numeric_data().copy()
         mn['little_float'] = np.array(12345., dtype='float16')
diff --git a/pandas/tests/frame/test_indexing.py b/pandas/tests/frame/test_indexing.py
index 78554d98a..d35b67b52 100644
--- a/pandas/tests/frame/test_indexing.py
+++ b/pandas/tests/frame/test_indexing.py
@@ -269,8 +269,8 @@ class TestDataFrameIndexing(TestData):
 
             data = df._get_numeric_data()
             bif = df[df > 0]
-            bifw = DataFrame(dict([(c, np.where(data[c] > 0, data[c], np.nan))
-                                   for c in data.columns]),
+            bifw = DataFrame(dict((c, np.where(data[c] > 0, data[c], np.nan))
+                                  for c in data.columns),
                              index=data.index, columns=data.columns)
 
             # add back other columns to compare
@@ -2375,8 +2375,8 @@ class TestDataFrameIndexing(TestData):
                 return (issubclass(s.dtype.type, (np.integer, np.floating)) and
                         s.dtype != 'uint8')
 
-            return DataFrame(dict([(c, s + 1) if is_ok(s) else (c, s)
-                                   for c, s in compat.iteritems(df)]))
+            return DataFrame(dict((c, s + 1) if is_ok(s) else (c, s)
+                                  for c, s in compat.iteritems(df)))
 
         def _check_get(df, cond, check_dtypes=True):
             other1 = _safe_add(df)
@@ -2399,9 +2399,9 @@ class TestDataFrameIndexing(TestData):
             _check_get(df, cond)
 
         # upcasting case (GH # 2794)
-        df = DataFrame(dict([(c, Series([1] * 3, dtype=c))
-                             for c in ['int64', 'int32',
-                                       'float32', 'float64']]))
+        df = DataFrame(dict((c, Series([1] * 3, dtype=c))
+                            for c in ['int64', 'int32',
+                                      'float32', 'float64']))
         df.iloc[1, :] = 0
         result = df.where(df >= 0).get_dtype_counts()
 
@@ -2453,8 +2453,8 @@ class TestDataFrameIndexing(TestData):
 
             # integers are upcast, so don't check the dtypes
             cond = df > 0
-            check_dtypes = all([not issubclass(s.type, np.integer)
-                                for s in df.dtypes])
+            check_dtypes = all(not issubclass(s.type, np.integer)
+                               for s in df.dtypes)
             _check_align(df, cond, np.nan, check_dtypes=check_dtypes)
 
         # invalid conditions
diff --git a/pandas/tests/groupby/test_groupby.py b/pandas/tests/groupby/test_groupby.py
index 03f780957..91a5569b3 100644
--- a/pandas/tests/groupby/test_groupby.py
+++ b/pandas/tests/groupby/test_groupby.py
@@ -257,7 +257,7 @@ class TestGroupBy(MixIn):
         assert len(grouped) == len(df)
 
         grouped = df.groupby([lambda x: x.year, lambda x: x.month])
-        expected = len(set([(x.year, x.month) for x in df.index]))
+        expected = len(set((x.year, x.month) for x in df.index))
         assert len(grouped) == expected
 
         # issue 11016
diff --git a/pandas/tests/groupby/test_whitelist.py b/pandas/tests/groupby/test_whitelist.py
index e8e215055..977c639d7 100644
--- a/pandas/tests/groupby/test_whitelist.py
+++ b/pandas/tests/groupby/test_whitelist.py
@@ -238,7 +238,7 @@ def test_groupby_blacklist(df_letters):
 
 def test_tab_completion(mframe):
     grp = mframe.groupby(level='second')
-    results = set([v for v in dir(grp) if not v.startswith('_')])
+    results = set(v for v in dir(grp) if not v.startswith('_'))
     expected = {
         'A', 'B', 'C', 'agg', 'aggregate', 'apply', 'boxplot', 'filter',
         'first', 'get_group', 'groups', 'hist', 'indices', 'last', 'max',
diff --git a/pandas/tests/indexing/test_panel.py b/pandas/tests/indexing/test_panel.py
index 2d4ffd6a4..4d7768c9e 100644
--- a/pandas/tests/indexing/test_panel.py
+++ b/pandas/tests/indexing/test_panel.py
@@ -119,7 +119,7 @@ class TestPanel(object):
             df = DataFrame(
                 np.random.randn(
                     len(ind), 5), index=ind, columns=list('ABCDE'))
-            panel = Panel(dict([('frame_' + c, df) for c in list('ABC')]))
+            panel = Panel(dict(('frame_' + c, df) for c in list('ABC')))
 
             test2 = panel.loc[:, "2002":"2002-12-31"]
             test1 = panel.loc[:, "2002"]
diff --git a/pandas/tests/io/formats/test_format.py b/pandas/tests/io/formats/test_format.py
index 8d2745689..bfaa47bf3 100644
--- a/pandas/tests/io/formats/test_format.py
+++ b/pandas/tests/io/formats/test_format.py
@@ -1158,7 +1158,7 @@ class TestDataFrameFormatting(object):
                                   float_format='%.5f'.__mod__)
         lines = result.split('\n')
         header = lines[0].strip().split()
-        joined = '\n'.join([re.sub(r'\s+', ' ', x).strip() for x in lines[1:]])
+        joined = '\n'.join(re.sub(r'\s+', ' ', x).strip() for x in lines[1:])
         recons = read_table(StringIO(joined), names=header,
                             header=None, sep=' ')
         tm.assert_series_equal(recons['B'], biggie['B'])
diff --git a/pandas/tests/io/formats/test_style.py b/pandas/tests/io/formats/test_style.py
index 7335e1ce0..eb3db24d3 100644
--- a/pandas/tests/io/formats/test_style.py
+++ b/pandas/tests/io/formats/test_style.py
@@ -675,9 +675,10 @@ class TestStyler(object):
         df = pd.DataFrame(np.random.random(size=(2, 2)))
         ctx = df.style.format("{:0.1f}")._translate()
 
-        assert all(['display_value' in c for c in row] for row in ctx['body'])
-        assert (all([len(c['display_value']) <= 3 for c in row[1:]]
-                    for row in ctx['body']))
+        assert all(['display_value' in c for c in row]
+                   for row in ctx['body'])
+        assert all([len(c['display_value']) <= 3 for c in row[1:]]
+                   for row in ctx['body'])
         assert len(ctx['body'][0][1]['display_value'].lstrip('-')) <= 3
 
     def test_display_format_raises(self):
diff --git a/pandas/tests/io/msgpack/test_case.py b/pandas/tests/io/msgpack/test_case.py
index 3927693a9..9bb34a70e 100644
--- a/pandas/tests/io/msgpack/test_case.py
+++ b/pandas/tests/io/msgpack/test_case.py
@@ -98,10 +98,10 @@ def test_match():
         (tuple(range(16)), (b"\xdc\x00\x10\x00\x01\x02\x03\x04\x05\x06\x07"
                             b"\x08\x09\x0a\x0b\x0c\x0d\x0e\x0f")),
         ({}, b'\x80'),
-        (dict([(x, x) for x in range(15)]),
+        (dict((x, x) for x in range(15)),
          (b'\x8f\x00\x00\x01\x01\x02\x02\x03\x03\x04\x04\x05\x05\x06\x06\x07'
           b'\x07\x08\x08\t\t\n\n\x0b\x0b\x0c\x0c\r\r\x0e\x0e')),
-        (dict([(x, x) for x in range(16)]),
+        (dict((x, x) for x in range(16)),
          (b'\xde\x00\x10\x00\x00\x01\x01\x02\x02\x03\x03\x04\x04\x05\x05\x06'
           b'\x06\x07\x07\x08\x08\t\t\n\n\x0b\x0b\x0c\x0c\r\r\x0e\x0e'
           b'\x0f\x0f')),
diff --git a/pandas/tests/io/parser/na_values.py b/pandas/tests/io/parser/na_values.py
index 8dc599b42..f8906d5a1 100644
--- a/pandas/tests/io/parser/na_values.py
+++ b/pandas/tests/io/parser/na_values.py
@@ -88,7 +88,7 @@ NaN,nan
 
             return buf
 
-        data = StringIO('\n'.join([f(i, v) for i, v in enumerate(_NA_VALUES)]))
+        data = StringIO('\n'.join(f(i, v) for i, v in enumerate(_NA_VALUES)))
         expected = DataFrame(np.nan, columns=range(nv), index=range(nv))
         df = self.read_csv(data, header=None)
         tm.assert_frame_equal(df, expected)
diff --git a/pandas/tests/io/test_pytables.py b/pandas/tests/io/test_pytables.py
index 13bf81889..ca20d089e 100644
--- a/pandas/tests/io/test_pytables.py
+++ b/pandas/tests/io/test_pytables.py
@@ -1391,7 +1391,7 @@ class TestHDFStore(Base):
             with catch_warnings(record=True):
                 wp = tm.makePanel()
                 wp2 = wp.rename_axis(
-                    dict([(x, "%s_extra" % x) for x in wp.minor_axis]), axis=2)
+                    dict((x, "%s_extra" % x) for x in wp.minor_axis), axis=2)
 
                 def check_col(key, name, size):
                     assert getattr(store.get_storer(key)
@@ -2143,9 +2143,9 @@ class TestHDFStore(Base):
             assert df1.dtypes[0] == 'float32'
 
             # check with mixed dtypes
-            df1 = DataFrame(dict([(c, Series(np.random.randn(5), dtype=c))
-                                  for c in ['float32', 'float64', 'int32',
-                                            'int64', 'int16', 'int8']]))
+            df1 = DataFrame(dict((c, Series(np.random.randn(5), dtype=c))
+                                 for c in ['float32', 'float64', 'int32',
+                                           'int64', 'int16', 'int8']))
             df1['string'] = 'foo'
             df1['float322'] = 1.
             df1['float322'] = df1['float322'].astype('float32')
diff --git a/pandas/tests/io/test_sql.py b/pandas/tests/io/test_sql.py
index 2df43158b..00a30940c 100644
--- a/pandas/tests/io/test_sql.py
+++ b/pandas/tests/io/test_sql.py
@@ -2243,8 +2243,8 @@ class TestXSQLite(SQLiteMixIn):
         sql.to_sql(mono_df, con=self.conn, name='mono_df', index=False)
         # computing the sum via sql
         con_x = self.conn
-        the_sum = sum([my_c0[0]
-                       for my_c0 in con_x.execute("select * from mono_df")])
+        the_sum = sum(my_c0[0]
+                      for my_c0 in con_x.execute("select * from mono_df"))
         # it should not fail, and gives 3 ( Issue #3628 )
         assert the_sum == 3
 
diff --git a/pandas/tests/plotting/test_frame.py b/pandas/tests/plotting/test_frame.py
index 11dca1abc..3887271ed 100644
--- a/pandas/tests/plotting/test_frame.py
+++ b/pandas/tests/plotting/test_frame.py
@@ -1162,14 +1162,13 @@ class TestDataFramePlots(TestPlotBase):
             if kind == 'bar':
                 axis = ax.xaxis
                 ax_min, ax_max = ax.get_xlim()
-                min_edge = min([p.get_x() for p in ax.patches])
-                max_edge = max([p.get_x() + p.get_width() for p in ax.patches])
+                min_edge = min(p.get_x() for p in ax.patches)
+                max_edge = max(p.get_x() + p.get_width() for p in ax.patches)
             elif kind == 'barh':
                 axis = ax.yaxis
                 ax_min, ax_max = ax.get_ylim()
-                min_edge = min([p.get_y() for p in ax.patches])
-                max_edge = max([p.get_y() + p.get_height() for p in ax.patches
-                                ])
+                min_edge = min(p.get_y() for p in ax.patches)
+                max_edge = max(p.get_y() + p.get_height() for p in ax.patches)
             else:
                 raise ValueError
 
diff --git a/pandas/tests/reshape/test_concat.py b/pandas/tests/reshape/test_concat.py
index fd5b4611e..ae41502f2 100644
--- a/pandas/tests/reshape/test_concat.py
+++ b/pandas/tests/reshape/test_concat.py
@@ -1385,14 +1385,14 @@ class TestConcatenate(ConcatenateBase):
                     return DataFrame(np.random.randn(index, cols),
                                      index=["I%s" % i for i in range(index)],
                                      columns=["C%s" % i for i in range(cols)])
-                return Panel(dict([("Item%s" % x, df())
-                                   for x in ['A', 'B', 'C']]))
+                return Panel(dict(("Item%s" % x, df())
+                                  for x in ['A', 'B', 'C']))
 
             panel1 = make_panel()
             panel2 = make_panel()
 
-            panel2 = panel2.rename_axis(dict([(x, "%s_1" % x)
-                                              for x in panel2.major_axis]),
+            panel2 = panel2.rename_axis(dict((x, "%s_1" % x)
+                                             for x in panel2.major_axis),
                                         axis=1)
 
             panel3 = panel2.rename_axis(lambda x: '%s_1' % x, axis=1)
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index 42df2e26b..0e783d675 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -1350,18 +1350,18 @@ class TestPanel(PanelTests, CheckIndexing, SafeForLongAndSparse,
 
             # make sure that we don't trigger any warnings
             result = self.panel.apply(f, axis=['items', 'major_axis'])
-            expected = Panel(dict([(ax, f(self.panel.loc[:, :, ax]))
-                                   for ax in self.panel.minor_axis]))
+            expected = Panel(dict((ax, f(self.panel.loc[:, :, ax]))
+                                  for ax in self.panel.minor_axis))
             assert_panel_equal(result, expected)
 
             result = self.panel.apply(f, axis=['major_axis', 'minor_axis'])
-            expected = Panel(dict([(ax, f(self.panel.loc[ax]))
-                                   for ax in self.panel.items]))
+            expected = Panel(dict((ax, f(self.panel.loc[ax]))
+                                  for ax in self.panel.items))
             assert_panel_equal(result, expected)
 
             result = self.panel.apply(f, axis=['minor_axis', 'items'])
-            expected = Panel(dict([(ax, f(self.panel.loc[:, ax]))
-                                   for ax in self.panel.major_axis]))
+            expected = Panel(dict((ax, f(self.panel.loc[:, ax]))
+                                  for ax in self.panel.major_axis))
             assert_panel_equal(result, expected)
 
             # with multi-indexes
diff --git a/pandas/tests/test_window.py b/pandas/tests/test_window.py
index 742b8a5ac..2427bcea4 100644
--- a/pandas/tests/test_window.py
+++ b/pandas/tests/test_window.py
@@ -2505,14 +2505,14 @@ class TestMomentsConsistency(Base):
              [0.84780328, 0.33394331], [0.78369152, 0.63919667]]))
 
         res = df[0].rolling(5, center=True).corr(df[1])
-        assert all([np.abs(np.nan_to_num(x)) <= 1 for x in res])
+        assert all(np.abs(np.nan_to_num(x)) <= 1 for x in res)
 
         # and some fuzzing
         for _ in range(10):
             df = DataFrame(np.random.rand(30, 2))
             res = df[0].rolling(5, center=True).corr(df[1])
             try:
-                assert all([np.abs(np.nan_to_num(x)) <= 1 for x in res])
+                assert all(np.abs(np.nan_to_num(x)) <= 1 for x in res)
             except AssertionError:
                 print(res)
 
diff --git a/pandas/tseries/holiday.py b/pandas/tseries/holiday.py
index d8bfa3013..957352d9f 100644
--- a/pandas/tseries/holiday.py
+++ b/pandas/tseries/holiday.py
@@ -439,7 +439,7 @@ class AbstractHolidayCalendar(object):
 
         if not isinstance(base, list):
             base = [base]
-        base_holidays = dict([(holiday.name, holiday) for holiday in base])
+        base_holidays = dict((holiday.name, holiday) for holiday in base)
 
         other_holidays.update(base_holidays)
         return list(other_holidays.values())
diff --git a/scripts/api_rst_coverage.py b/scripts/api_rst_coverage.py
index 6bb538350..45340ba09 100644
--- a/scripts/api_rst_coverage.py
+++ b/scripts/api_rst_coverage.py
@@ -22,7 +22,7 @@ def main():
     api_rst_members = set()
     file_name = '../doc/source/api.rst'
     with open(file_name, 'r') as f:
-        pattern = re.compile('({})\.(\w+)'.format('|'.join([cls.__name__ for cls in classes])))
+        pattern = re.compile('({})\.(\w+)'.format('|'.join(cls.__name__ for cls in classes)))
         for line in f:
             match = pattern.search(line)
             if match:
diff --git a/scripts/find_commits_touching_func.py b/scripts/find_commits_touching_func.py
index 74ea120bf..f9440f6f8 100755
--- a/scripts/find_commits_touching_func.py
+++ b/scripts/find_commits_touching_func.py
@@ -88,7 +88,7 @@ def get_hits(defname,files=()):
         # remove comment lines
         lines = [x for x in lines if not re.search("^\w+\s*\(.+\)\s*#",x)]
         hits = set(map(lambda x: x.split(" ")[0],lines))
-        cs.update(set([Hit(commit=c,path=f) for c in hits]))
+        cs.update(set(Hit(commit=c,path=f) for c in hits))
 
     return cs
 
@@ -101,12 +101,12 @@ def get_commit_vitals(c,hlen=HASH_LEN):
     return h[:hlen],s,parse_date(d)
 
 def file_filter(state,dirname,fnames):
-    if args.dir_masks and not any([re.search(x,dirname) for x in args.dir_masks]):
+    if args.dir_masks and not any(re.search(x,dirname) for x in args.dir_masks):
         return
     for f in fnames:
         p = os.path.abspath(os.path.join(os.path.realpath(dirname),f))
-        if  any([re.search(x,f) for x in args.file_masks])\
-            or any([re.search(x,p) for x in args.path_masks]):
+        if  any(re.search(x,f) for x in args.file_masks)\
+            or any(re.search(x,p) for x in args.path_masks):
             if os.path.isfile(p):
                 state['files'].append(p)
 
diff --git a/scripts/merge-pr.py b/scripts/merge-pr.py
index 1fc4eef3d..11cc96609 100755
--- a/scripts/merge-pr.py
+++ b/scripts/merge-pr.py
@@ -160,7 +160,7 @@ def merge_pr(pr_num, target_ref):
     if body is not None:
         merge_message_flags += ["-m", '\n'.join(textwrap.wrap(body))]
 
-    authors = "\n".join(["Author: %s" % a for a in distinct_authors])
+    authors = "\n".join("Author: %s" % a for a in distinct_authorsS)
 
     merge_message_flags += ["-m", authors]
 
diff --git a/versioneer.py b/versioneer.py
index 104e8e97c..59228ec63 100644
--- a/versioneer.py
+++ b/versioneer.py
@@ -606,11 +606,11 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         if verbose:
             print("keywords are unexpanded, not using")
         raise NotThisMethod("unexpanded keywords, not a git-archive tarball")
-    refs = set([r.strip() for r in refnames.strip("()").split(",")])
+    refs = set(r.strip() for r in refnames.strip("()").split(","))
     # starting in git-1.8.3, tags are listed as "tag: foo-1.0" instead of
     # just "foo-1.0". If we see a "tag: " prefix, prefer those.
     TAG = "tag: "
-    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])
+    tags = set(r[len(TAG):] for r in refs if r.startswith(TAG))
     if not tags:
         # Either we're using git < 1.8.3, or there really are no tags. We use
         # a heuristic: assume all version tags have a digit. The old git %%d
@@ -619,7 +619,7 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         # between branches and tags. By ignoring refnames without digits, we
         # filter out many common branch names like "release" and
         # "stabilization", as well as "HEAD" and "master".
-        tags = set([r for r in refs if re.search(r'\d', r)])
+        tags = set(r for r in refs if re.search(r'\d', r))
         if verbose:
             print("discarding '%%s', no digits" %% ",".join(refs-tags))
     if verbose:
@@ -960,11 +960,11 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         if verbose:
             print("keywords are unexpanded, not using")
         raise NotThisMethod("unexpanded keywords, not a git-archive tarball")
-    refs = set([r.strip() for r in refnames.strip("()").split(",")])
+    refs = set(r.strip() for r in refnames.strip("()").split(","))
     # starting in git-1.8.3, tags are listed as "tag: foo-1.0" instead of
     # just "foo-1.0". If we see a "tag: " prefix, prefer those.
     TAG = "tag: "
-    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])
+    tags = set(r[len(TAG):] for r in refs if r.startswith(TAG))
     if not tags:
         # Either we're using git < 1.8.3, or there really are no tags. We use
         # a heuristic: assume all version tags have a digit. The old git %d
@@ -973,7 +973,7 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         # between branches and tags. By ignoring refnames without digits, we
         # filter out many common branch names like "release" and
         # "stabilization", as well as "HEAD" and "master".
-        tags = set([r for r in refs if re.search(r'\d', r)])
+        tags = set(r for r in refs if re.search(r'\d', r))
         if verbose:
             print("discarding '%s', no digits" % ",".join(refs-tags))
     if verbose:
