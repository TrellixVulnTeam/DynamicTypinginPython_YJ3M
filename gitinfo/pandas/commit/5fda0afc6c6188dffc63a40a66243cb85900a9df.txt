commit 5fda0afc6c6188dffc63a40a66243cb85900a9df
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Wed Apr 4 14:24:09 2012 -0400

    ENH: non-unique index support. much more testing needed

diff --git a/pandas/core/common.py b/pandas/core/common.py
index dde82a19c..5c6389330 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -596,6 +596,13 @@ def _clean_fill_method(method):
         method = 'backfill'
     return method
 
+def _all_none(*args):
+    for arg in args:
+        if arg is not None:
+            return False
+    return True
+
+
 def save(obj, path):
     """
     Pickle (serialize) object to input file path
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 557290c7c..cc83e4678 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -562,15 +562,7 @@ class Index(np.ndarray):
         -------
         loc : int
         """
-        # TODO: push all of this into Cython
-        if self.is_unique:
-            return self._engine.get_loc(key)
-        elif self.is_monotonic:
-            left = self.searchsorted(key, side='left')
-            right = self.searchsorted(key, side='right')
-            return slice(left, right)
-        else:
-            return self.values == key
+        return self._engine.get_loc(key)
 
     def get_value(self, series, key):
         """
@@ -1109,7 +1101,11 @@ def _dt_index_cmp(opname):
         if isinstance(other, datetime):
             func = getattr(self, opname)
             result = func(_dt_unbox(other))
+        elif isinstance(other, np.ndarray):
+            func = getattr(super(DatetimeIndex, self), opname)
+            result = func(other)
         else:
+            other = _ensure_datetime64(other)
             func = getattr(super(DatetimeIndex, self), opname)
             result = func(other)
         try:
@@ -1118,6 +1114,14 @@ def _dt_index_cmp(opname):
             return result
     return wrapper
 
+def _ensure_datetime64(other):
+    if isinstance(other, np.datetime64):
+        return other
+    elif com.is_integer(other):
+        return np.datetime64(other)
+    else:
+        raise TypeError(other)
+
 def _dt_index_op(opname):
     """
     Wrap arithmetic operations to unbox a timedelta to a timedelta64.
diff --git a/pandas/core/nanops.py b/pandas/core/nanops.py
index 7a7274ca3..bf1aad67a 100644
--- a/pandas/core/nanops.py
+++ b/pandas/core/nanops.py
@@ -360,20 +360,20 @@ def unique1d(values):
     """
     Hash table-based unique
     """
-    if issubclass(values.dtype.type, np.floating):
-        if values.dtype != np.float64:
-            values = values.astype(np.float64)
+    if np.issubdtype(values.dtype, np.floating):
         table = lib.Float64HashTable(len(values))
-        uniques = np.array(table.unique(values), dtype=np.float64)
-    elif issubclass(values.dtype.type, np.integer):
-        if values.dtype != np.int64:
-            values = values.astype(np.int64)
+        uniques = np.array(table.unique(com._ensure_float64(values)),
+                           dtype=np.float64)
+    elif np.issubdtype(values.dtype, np.integer):
         table = lib.Int64HashTable(len(values))
-        uniques = np.array(table.unique(values), dtype=np.int64)
+        uniques = np.array(table.unique(com._ensure_int64(values)),
+                           dtype=np.int64)
+
+        if values.dtype == np.datetime64:
+            uniques = uniques.view('M8[us]')
     else:
-        if not values.dtype == np.object_:
-            values = values.astype(np.object_)
         table = lib.PyObjectHashTable(len(values))
-        uniques = lib.list_to_object_array(table.unique(values))
+        uniques = table.unique(com._ensure_object(values))
+        uniques = lib.list_to_object_array(uniques)
     return uniques
 
diff --git a/pandas/sparse/panel.py b/pandas/sparse/panel.py
index 701c3d904..46c818d27 100644
--- a/pandas/sparse/panel.py
+++ b/pandas/sparse/panel.py
@@ -7,15 +7,14 @@ float64 data
 
 import numpy as np
 
-from pandas.core.common import _pickle_array, _unpickle_array, _mut_exclusive
 from pandas.core.index import Index, MultiIndex, _ensure_index
 from pandas.core.frame import DataFrame
 from pandas.core.panel import Panel
-
 from pandas.sparse.frame import SparseDataFrame
-
 from pandas.util.decorators import deprecate
 
+import pandas.core.common as com
+
 class SparsePanelAxis(object):
 
     def __init__(self, cache_field, frame_attr):
@@ -209,8 +208,9 @@ class SparsePanel(Panel):
 
     def __getstate__(self):
         # pickling
-        return (self._frames, _pickle_array(self.items),
-                _pickle_array(self.major_axis), _pickle_array(self.minor_axis),
+        return (self._frames, com._pickle_array(self.items),
+                com._pickle_array(self.major_axis),
+                com._pickle_array(self.minor_axis),
                 self.default_fill_value, self.default_kind)
 
     def __setstate__(self, state):
@@ -218,9 +218,9 @@ class SparsePanel(Panel):
 
         self.default_fill_value = fv
         self.default_kind = kind
-        self._items = _unpickle_array(items)
-        self._major_axis = _unpickle_array(major)
-        self._minor_axis = _unpickle_array(minor)
+        self._items = com._unpickle_array(items)
+        self._major_axis = com._unpickle_array(major)
+        self._minor_axis = com._unpickle_array(minor)
         self._frames = frames
 
     def copy(self):
@@ -307,10 +307,10 @@ class SparsePanel(Panel):
         -------
         reindexed : SparsePanel
         """
-        major = _mut_exclusive(major, major_axis)
-        minor = _mut_exclusive(minor, minor_axis)
+        major = com._mut_exclusive(major, major_axis)
+        minor = com._mut_exclusive(minor, minor_axis)
 
-        if None == major == items == minor:
+        if com._all_none(items, major, minor):
             raise ValueError('Must specify at least one axis')
 
         major = self.major_axis if major is None else major
diff --git a/pandas/src/engines.pyx b/pandas/src/engines.pyx
index b3d9856ff..9595e0014 100644
--- a/pandas/src/engines.pyx
+++ b/pandas/src/engines.pyx
@@ -67,22 +67,84 @@ cdef class IndexEngine:
         arr : 1-dimensional ndarray
         '''
         cdef:
-            Py_ssize_t loc
+            object loc
             void* data_ptr
 
         loc = self.get_loc(key)
-        return util.get_value_at(arr, loc)
+        if PySlice_Check(loc) or cnp.PyArray_Check(loc):
+            return arr[loc]
+        else:
+            return util.get_value_at(arr, loc)
 
     cpdef set_value(self, ndarray arr, object key, object value):
         '''
         arr : 1-dimensional ndarray
         '''
         cdef:
-            Py_ssize_t loc
+            object loc
             void* data_ptr
 
         loc = self.get_loc(key)
-        util.set_value_at(arr, loc, value)
+        if PySlice_Check(loc) or cnp.PyArray_Check(loc):
+            arr[loc] = value
+        else:
+            util.set_value_at(arr, loc, value)
+
+    cpdef get_loc(self, object val):
+        if is_definitely_invalid_key(val):
+            raise TypeError
+
+        self._ensure_mapping_populated()
+        if not self.unique:
+            return self._get_loc_duplicates(val)
+
+        try:
+            return self.mapping.get_item(val)
+        except TypeError:
+            self._check_type(val)
+            raise KeyError(val)
+
+    cdef inline _get_loc_duplicates(self, object val):
+        cdef:
+            Py_ssize_t diff
+
+        if self.is_monotonic:
+            values = self._get_index_values()
+            left = values.searchsorted(val, side='left')
+            right = values.searchsorted(val, side='right')
+            diff = right - left
+            if diff == 0:
+                raise KeyError(val)
+            elif diff == 1:
+                return left
+            else:
+                return slice(left, right)
+        else:
+            return self._get_bool_indexer(val)
+
+    cdef _get_bool_indexer(self, object val):
+        cdef:
+            ndarray[uint8_t, cast=True] indexer
+            ndarray[object] values
+            int count = 0
+            Py_ssize_t i, n
+
+        values = self._get_index_values()
+        n = len(values)
+
+        indexer = np.empty(n, dtype=bool)
+
+        for i in range(n):
+            if values[i] == val:
+                count += 1
+                indexer[i] = 1
+            else:
+                indexer[i] = 0
+
+        if count == 0:
+            raise KeyError(val)
+
+        return indexer
 
     property is_unique:
 
@@ -125,20 +187,6 @@ cdef class IndexEngine:
     cdef _make_hash_table(self, n):
         raise NotImplementedError
 
-    cpdef get_loc(self, object val):
-        if is_definitely_invalid_key(val):
-            raise TypeError
-
-        self._ensure_mapping_populated()
-        if not self.unique:
-            raise Exception('Index values are not unique')
-
-        try:
-            return self.mapping.get_item(val)
-        except TypeError:
-            self._check_type(val)
-            raise KeyError(val)
-
     cdef inline _check_type(self, object val):
         hash(val)
 
@@ -195,6 +243,36 @@ cdef class Int64Engine(IndexEngine):
     def get_backfill_indexer(self, other):
         return _tseries.backfill_int64(self._get_index_values(), other)
 
+    cdef _get_bool_indexer(self, object val):
+        cdef:
+            ndarray[uint8_t, cast=True] indexer
+            ndarray[int64_t] values
+            int count = 0
+            Py_ssize_t i, n
+            int64_t ival
+
+        if not util.is_integer_object(val):
+            raise KeyError(val)
+
+        ival = val
+
+        values = self._get_index_values()
+        n = len(values)
+
+        indexer = np.empty(n, dtype=bool)
+
+        for i in range(n):
+            if values[i] == val:
+                count += 1
+                indexer[i] = 1
+            else:
+                indexer[i] = 0
+
+        if count == 0:
+            raise KeyError(val)
+
+        return indexer
+
 cdef class Float64Engine(IndexEngine):
 
     # cdef Float64HashTable mapping
@@ -229,7 +307,7 @@ cdef class ObjectEngine(IndexEngine):
         return _tseries.backfill_object(self._get_index_values(), other)
 
 
-cdef class DatetimeEngine(IndexEngine):
+cdef class DatetimeEngine(Int64Engine):
 
     # cdef Int64HashTable mapping
 
@@ -245,9 +323,6 @@ cdef class DatetimeEngine(IndexEngine):
 
         return val in self.mapping
 
-    cdef _make_hash_table(self, n):
-        return Int64HashTable(n)
-
     cdef _get_index_values(self):
         return self.index_weakref().values.view('i8')
 
@@ -258,16 +333,16 @@ cdef class DatetimeEngine(IndexEngine):
         if is_definitely_invalid_key(val):
             raise TypeError
 
-        self._ensure_mapping_populated()
-        if not self.unique:
-            raise Exception('Index values are not unique')
-
         if util.is_datetime64_object(val):
             val = val.view('i8')
         elif PyDateTime_Check(val):
             val = np.datetime64(val)
             val = val.view('i8')
 
+        self._ensure_mapping_populated()
+        if not self.unique:
+            return self._get_loc_duplicates(val)
+
         try:
             return self.mapping.get_item(val)
         except TypeError:
@@ -298,6 +373,7 @@ cdef class DatetimeEngine(IndexEngine):
         other = np.asarray(other).view('i8')
         return _tseries.backfill_int64(self._get_index_values(), other)
 
+
 # ctypedef fused idxvalue_t:
 #     object
 #     int
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index e6b16f5e6..18fa62209 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -2287,6 +2287,65 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         # it works!
         result = np.unique(self.ts)
 
+class TestSeriesNonUnique(unittest.TestCase):
+
+    def setUp(self):
+        pass
+
+    def test_basic_indexing(self):
+        s = Series(np.random.randn(5), index=['a', 'b', 'a', 'a', 'b'])
+
+        self.assertRaises(IndexError, s.__getitem__, 5)
+        self.assertRaises(IndexError, s.__setitem__, 5, 0)
+
+        self.assertRaises(KeyError, s.__getitem__, 'c')
+        self.assertRaises(KeyError, s.__setitem__, 'c', 0)
+
+        s = s.sort_index()
+
+        self.assertRaises(IndexError, s.__getitem__, 5)
+        self.assertRaises(IndexError, s.__setitem__, 5, 0)
+
+        self.assertRaises(KeyError, s.__getitem__, 'c')
+        self.assertRaises(KeyError, s.__setitem__, 'c', 0)
+
+    def test_int_indexing(self):
+        s = Series(np.random.randn(6), index=[0, 0, 1, 1, 2, 2])
+
+        self.assertRaises(KeyError, s.__getitem__, 5)
+        self.assertRaises(KeyError, s.__setitem__, 5, 0)
+
+        self.assertRaises(KeyError, s.__getitem__, 'c')
+        self.assertRaises(KeyError, s.__setitem__, 'c', 0)
+
+        # not monotonic
+        s = Series(np.random.randn(6), index=[2, 2, 0, 0, 1, 1])
+
+        self.assertRaises(KeyError, s.__getitem__, 5)
+        self.assertRaises(KeyError, s.__setitem__, 5, 0)
+
+        self.assertRaises(KeyError, s.__getitem__, 'c')
+        self.assertRaises(KeyError, s.__setitem__, 'c', 0)
+
+    def test_datetime_indexing(self):
+        from pandas import date_range
+        from pandas.core.datetools import to_timestamp
+
+        index = date_range('1/1/2000', '1/7/2000')
+        index = index.repeat(3)
+
+        s = Series(len(index), index=index)
+        stamp = to_timestamp('1/8/2000')
+
+        self.assertRaises(KeyError, s.__getitem__, stamp)
+        self.assertRaises(KeyError, s.__setitem__, stamp, 0)
+
+        # not monotonic
+        s = s[::-1]
+
+        self.assertRaises(KeyError, s.__getitem__, stamp)
+        self.assertRaises(KeyError, s.__setitem__, stamp, 0)
+
 if __name__ == '__main__':
     nose.runmodule(argv=[__file__,'-vvs','-x','--pdb', '--pdb-failure'],
                    exit=False)
diff --git a/pandas/tests/test_timeseries.py b/pandas/tests/test_timeseries.py
index 150dba32f..455166f37 100644
--- a/pandas/tests/test_timeseries.py
+++ b/pandas/tests/test_timeseries.py
@@ -44,11 +44,16 @@ class TestTimeSeriesDuplicates(unittest.TestCase):
     def test_is_unique_monotonic(self):
         self.assert_(not self.dups.index.is_unique)
 
+    def test_index_unique(self):
+        uniques = self.dups.index.unique()
+        self.assert_(uniques.dtype == 'M8') # sanity
 
     def test_duplicate_dates_indexing(self):
         ts = self.dups
 
-        for date in ts.index.unique():
+        uniques = ts.index.unique()
+
+        for date in uniques:
             result = ts[date]
 
             mask = ts.index == date
@@ -61,7 +66,7 @@ class TestTimeSeriesDuplicates(unittest.TestCase):
 
             cp = ts.copy()
             cp[date] = 0
-            expected = np.where(ts.index == date, 0, ts)
+            expected = Series(np.where(mask, 0, ts), index=ts.index)
             assert_series_equal(cp, expected)
 
         self.assertRaises(KeyError, ts.__getitem__, datetime(2000, 1, 6))
