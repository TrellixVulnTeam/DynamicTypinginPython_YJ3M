commit b1e68cb7eb7e31e618b524a568e9ffb59d44a008
Author: jbrockmendel <jbrockmendel@gmail.com>
Date:   Sun Dec 1 15:20:36 2019 -0800

    CLN: explicit signature for to_hdf (#29939)

diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 42b8214e0..48500a9a4 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -2403,7 +2403,19 @@ class NDFrame(PandasObject, SelectionMixin):
             indent=indent,
         )
 
-    def to_hdf(self, path_or_buf, key, **kwargs):
+    def to_hdf(
+        self,
+        path_or_buf,
+        key: str,
+        mode: str = "a",
+        complevel: Optional[int] = None,
+        complib: Optional[str] = None,
+        append: bool_t = False,
+        format: Optional[str] = None,
+        errors: str = "strict",
+        encoding: str = "UTF-8",
+        **kwargs,
+    ):
         """
         Write the contained data to an HDF5 file using HDFStore.
 
@@ -2431,7 +2443,20 @@ class NDFrame(PandasObject, SelectionMixin):
             - 'a': append, an existing file is opened for reading and
               writing, and if the file does not exist it is created.
             - 'r+': similar to 'a', but the file must already exist.
-        format : {'fixed', 'table'}, default 'fixed'
+        complevel : {0-9}, optional
+            Specifies a compression level for data.
+            A value of 0 disables compression.
+        complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'
+            Specifies the compression library to be used.
+            As of v0.20.2 these additional compressors for Blosc are supported
+            (default if no compressor specified: 'blosc:blosclz'):
+            {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',
+            'blosc:zlib', 'blosc:zstd'}.
+            Specifying a compression library which is not available issues
+            a ValueError.
+        append : bool, default False
+            For Table formats, append the input data to the existing.
+        format : {'fixed', 'table', None}, default 'fixed'
             Possible values:
 
             - 'fixed': Fixed format. Fast writing/reading. Not-appendable,
@@ -2439,32 +2464,22 @@ class NDFrame(PandasObject, SelectionMixin):
             - 'table': Table format. Write as a PyTables Table structure
               which may perform worse but allow more flexible operations
               like searching / selecting subsets of the data.
-        append : bool, default False
-            For Table formats, append the input data to the existing.
+            - If None, pd.get_option('io.hdf.default_format') is checked,
+              followed by fallback to "fixed"
+        errors : str, default 'strict'
+            Specifies how encoding and decoding errors are to be handled.
+            See the errors argument for :func:`open` for a full list
+            of options.
+        encoding : str, default "UTF-8"
         data_columns : list of columns or True, optional
             List of columns to create as indexed data columns for on-disk
             queries, or True to use all columns. By default only the axes
             of the object are indexed. See :ref:`io.hdf5-query-data-columns`.
             Applicable only to format='table'.
-        complevel : {0-9}, optional
-            Specifies a compression level for data.
-            A value of 0 disables compression.
-        complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'
-            Specifies the compression library to be used.
-            As of v0.20.2 these additional compressors for Blosc are supported
-            (default if no compressor specified: 'blosc:blosclz'):
-            {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',
-            'blosc:zlib', 'blosc:zstd'}.
-            Specifying a compression library which is not available issues
-            a ValueError.
         fletcher32 : bool, default False
             If applying compression use the fletcher32 checksum.
         dropna : bool, default False
             If true, ALL nan rows will not be written to store.
-        errors : str, default 'strict'
-            Specifies how encoding and decoding errors are to be handled.
-            See the errors argument for :func:`open` for a full list
-            of options.
 
         See Also
         --------
@@ -2506,7 +2521,19 @@ class NDFrame(PandasObject, SelectionMixin):
         """
         from pandas.io import pytables
 
-        pytables.to_hdf(path_or_buf, key, self, **kwargs)
+        pytables.to_hdf(
+            path_or_buf,
+            key,
+            self,
+            mode=mode,
+            complevel=complevel,
+            complib=complib,
+            append=append,
+            format=format,
+            errors=errors,
+            encoding=encoding,
+            **kwargs,
+        )
 
     def to_msgpack(self, path_or_buf=None, encoding="utf-8", **kwargs):
         """
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 05bde5a94..6ef821fc5 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -53,6 +53,7 @@ from pandas import (
     concat,
     isna,
 )
+from pandas._typing import FrameOrSeries
 from pandas.core.arrays.categorical import Categorical
 import pandas.core.common as com
 from pandas.core.computation.pytables import PyTablesExpr, maybe_expression
@@ -251,20 +252,27 @@ def _tables():
 
 def to_hdf(
     path_or_buf,
-    key,
-    value,
-    mode=None,
+    key: str,
+    value: FrameOrSeries,
+    mode: str = "a",
     complevel: Optional[int] = None,
-    complib=None,
-    append=None,
+    complib: Optional[str] = None,
+    append: bool = False,
+    format: Optional[str] = None,
+    errors: str = "strict",
+    encoding: str = "UTF-8",
     **kwargs,
 ):
     """ store this object, close it if we opened it """
 
     if append:
-        f = lambda store: store.append(key, value, **kwargs)
+        f = lambda store: store.append(
+            key, value, format=format, errors=errors, encoding=encoding, **kwargs
+        )
     else:
-        f = lambda store: store.put(key, value, **kwargs)
+        f = lambda store: store.put(
+            key, value, format=format, errors=errors, encoding=encoding, **kwargs
+        )
 
     path_or_buf = _stringify_path(path_or_buf)
     if isinstance(path_or_buf, str):
@@ -1042,7 +1050,7 @@ class HDFStore:
         format=None,
         append=True,
         columns=None,
-        dropna=None,
+        dropna: Optional[bool] = None,
         **kwargs,
     ):
         """
@@ -1070,7 +1078,7 @@ class HDFStore:
         chunksize    : size to chunk the writing
         expectedrows : expected TOTAL row size of this table
         encoding     : default None, provide an encoding for strings
-        dropna       : bool, default False
+        dropna : bool, default False
             Do not write an ALL nan row to the store settable
             by the option 'io.hdf.dropna_table'.
 
