commit 793020293ee1e5fa023f45c12943a4ac51cc23d0
Author: Jeff Reback <jeff@reback.net>
Date:   Tue Jul 25 06:18:23 2017 -0400

    COMPAT: rename isnull -> isna, notnull -> notna (#16972)
    
    closes #15001

diff --git a/doc/source/10min.rst b/doc/source/10min.rst
index 8482eef55..def49a641 100644
--- a/doc/source/10min.rst
+++ b/doc/source/10min.rst
@@ -373,7 +373,7 @@ To get the boolean mask where values are ``nan``
 
 .. ipython:: python
 
-   pd.isnull(df1)
+   pd.isna(df1)
 
 
 Operations
diff --git a/doc/source/api.rst b/doc/source/api.rst
index f22591dba..1a4ee68ef 100644
--- a/doc/source/api.rst
+++ b/doc/source/api.rst
@@ -187,7 +187,9 @@ Top-level missing data
 .. autosummary::
    :toctree: generated/
 
+   isna
    isnull
+   notna
    notnull
 
 Top-level conversions
@@ -272,8 +274,8 @@ Conversion
    Series.astype
    Series.infer_objects
    Series.copy
-   Series.isnull
-   Series.notnull
+   Series.isna
+   Series.notna
 
 Indexing, iteration
 ~~~~~~~~~~~~~~~~~~~
@@ -781,8 +783,8 @@ Conversion
    DataFrame.convert_objects
    DataFrame.infer_objects
    DataFrame.copy
-   DataFrame.isnull
-   DataFrame.notnull
+   DataFrame.isna
+   DataFrame.notna
 
 Indexing, iteration
 ~~~~~~~~~~~~~~~~~~~
@@ -1099,8 +1101,8 @@ Conversion
 
    Panel.astype
    Panel.copy
-   Panel.isnull
-   Panel.notnull
+   Panel.isna
+   Panel.notna
 
 Getting and setting
 ~~~~~~~~~~~~~~~~~~~
@@ -1343,8 +1345,8 @@ Missing Values
 
    Index.fillna
    Index.dropna
-   Index.isnull
-   Index.notnull
+   Index.isna
+   Index.notna
 
 Conversion
 ~~~~~~~~~~
diff --git a/doc/source/basics.rst b/doc/source/basics.rst
index aae1fffb7..c8138d795 100644
--- a/doc/source/basics.rst
+++ b/doc/source/basics.rst
@@ -444,7 +444,7 @@ So, for instance, to reproduce :meth:`~DataFrame.combine_first` as above:
 
 .. ipython:: python
 
-   combiner = lambda x, y: np.where(pd.isnull(x), y, x)
+   combiner = lambda x, y: np.where(pd.isna(x), y, x)
    df1.combine(df2, combiner)
 
 .. _basics.stats:
@@ -511,7 +511,7 @@ optional ``level`` parameter which applies only if the object has a
     :header: "Function", "Description"
     :widths: 20, 80
 
-    ``count``, Number of non-null observations
+    ``count``, Number of non-na observations
     ``sum``, Sum of values
     ``mean``, Mean of values
     ``mad``, Mean absolute deviation
@@ -541,7 +541,7 @@ will exclude NAs on Series input by default:
    np.mean(df['one'].values)
 
 ``Series`` also has a method :meth:`~Series.nunique` which will return the
-number of unique non-null values:
+number of unique non-na values:
 
 .. ipython:: python
 
diff --git a/doc/source/categorical.rst b/doc/source/categorical.rst
index ef558381c..02d7920bc 100644
--- a/doc/source/categorical.rst
+++ b/doc/source/categorical.rst
@@ -863,14 +863,14 @@ a code of ``-1``.
     s.cat.codes
 
 
-Methods for working with missing data, e.g. :meth:`~Series.isnull`, :meth:`~Series.fillna`,
+Methods for working with missing data, e.g. :meth:`~Series.isna`, :meth:`~Series.fillna`,
 :meth:`~Series.dropna`, all work normally:
 
 .. ipython:: python
 
     s = pd.Series(["a", "b", np.nan], dtype="category")
     s
-    pd.isnull(s)
+    pd.isna(s)
     s.fillna("a")
 
 Differences to R's `factor`
diff --git a/doc/source/comparison_with_sas.rst b/doc/source/comparison_with_sas.rst
index 875358521..33a347de0 100644
--- a/doc/source/comparison_with_sas.rst
+++ b/doc/source/comparison_with_sas.rst
@@ -444,13 +444,13 @@ For example, in SAS you could do this to filter missing values.
        if value_x ^= .;
    run;
 
-Which doesn't work in in pandas.  Instead, the ``pd.isnull`` or ``pd.notnull`` functions
+Which doesn't work in in pandas.  Instead, the ``pd.isna`` or ``pd.notna`` functions
 should be used for comparisons.
 
 .. ipython:: python
 
-   outer_join[pd.isnull(outer_join['value_x'])]
-   outer_join[pd.notnull(outer_join['value_x'])]
+   outer_join[pd.isna(outer_join['value_x'])]
+   outer_join[pd.notna(outer_join['value_x'])]
 
 pandas also provides a variety of methods to work with missing data - some of
 which would be challenging to express in SAS. For example, there are methods to
@@ -570,7 +570,7 @@ machine's memory, but also that the operations on that data may be faster.
 
 If out of core processing is needed, one possibility is the
 `dask.dataframe <http://dask.pydata.org/en/latest/dataframe.html>`_
-library (currently in development) which 
+library (currently in development) which
 provides a subset of pandas functionality for an on-disk ``DataFrame``
 
 Data Interop
@@ -578,7 +578,7 @@ Data Interop
 
 pandas provides a :func:`read_sas` method that can read SAS data saved in
 the XPORT or SAS7BDAT binary format.
- 
+
 .. code-block:: none
 
    libname xportout xport 'transport-file.xpt';
@@ -613,4 +613,3 @@ to interop data between SAS and pandas is to serialize to csv.
 
    In [9]: %time df = pd.read_csv('big.csv')
    Wall time: 4.86 s
- 
diff --git a/doc/source/comparison_with_sql.rst b/doc/source/comparison_with_sql.rst
index 7962e0e69..2112c7de8 100644
--- a/doc/source/comparison_with_sql.rst
+++ b/doc/source/comparison_with_sql.rst
@@ -101,7 +101,7 @@ Just like SQL's OR and AND, multiple conditions can be passed to a DataFrame usi
     # tips by parties of at least 5 diners OR bill total was more than $45
     tips[(tips['size'] >= 5) | (tips['total_bill'] > 45)]
 
-NULL checking is done using the :meth:`~pandas.Series.notnull` and :meth:`~pandas.Series.isnull`
+NULL checking is done using the :meth:`~pandas.Series.notna` and :meth:`~pandas.Series.isna`
 methods.
 
 .. ipython:: python
@@ -121,9 +121,9 @@ where ``col2`` IS NULL with the following query:
 
 .. ipython:: python
 
-    frame[frame['col2'].isnull()]
+    frame[frame['col2'].isna()]
 
-Getting items where ``col1`` IS NOT NULL can be done with :meth:`~pandas.Series.notnull`.
+Getting items where ``col1`` IS NOT NULL can be done with :meth:`~pandas.Series.notna`.
 
 .. code-block:: sql
 
@@ -133,7 +133,7 @@ Getting items where ``col1`` IS NOT NULL can be done with :meth:`~pandas.Series.
 
 .. ipython:: python
 
-    frame[frame['col1'].notnull()]
+    frame[frame['col1'].notna()]
 
 
 GROUP BY
diff --git a/doc/source/conf.py b/doc/source/conf.py
index cb3063d59..6eb12324e 100644
--- a/doc/source/conf.py
+++ b/doc/source/conf.py
@@ -238,8 +238,8 @@ html_static_path = ['_static']
 # https://github.com/pandas-dev/pandas/issues/16186
 
 moved_api_pages = [
-    ('pandas.core.common.isnull', 'pandas.isnull'),
-    ('pandas.core.common.notnull', 'pandas.notnull'),
+    ('pandas.core.common.isnull', 'pandas.isna'),
+    ('pandas.core.common.notnull', 'pandas.notna'),
     ('pandas.core.reshape.get_dummies', 'pandas.get_dummies'),
     ('pandas.tools.merge.concat', 'pandas.concat'),
     ('pandas.tools.merge.merge', 'pandas.merge'),
diff --git a/doc/source/gotchas.rst b/doc/source/gotchas.rst
index 11827fe27..a3a90f514 100644
--- a/doc/source/gotchas.rst
+++ b/doc/source/gotchas.rst
@@ -202,7 +202,7 @@ For many reasons we chose the latter. After years of production use it has
 proven, at least in my opinion, to be the best decision given the state of
 affairs in NumPy and Python in general. The special value ``NaN``
 (Not-A-Number) is used everywhere as the ``NA`` value, and there are API
-functions ``isnull`` and ``notnull`` which can be used across the dtypes to
+functions ``isna`` and ``notna`` which can be used across the dtypes to
 detect NA values.
 
 However, it comes with it a couple of trade-offs which I most certainly have
diff --git a/doc/source/missing_data.rst b/doc/source/missing_data.rst
index 379307758..e40b7d460 100644
--- a/doc/source/missing_data.rst
+++ b/doc/source/missing_data.rst
@@ -36,7 +36,7 @@ When / why does data become missing?
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 Some might quibble over our usage of *missing*. By "missing" we simply mean
-**null** or "not present for whatever reason". Many data sets simply arrive with
+**na** or "not present for whatever reason". Many data sets simply arrive with
 missing data, either because it exists and was not collected or it never
 existed. For example, in a collection of financial time series, some of the time
 series might start on different dates. Thus, values prior to the start date
@@ -63,27 +63,27 @@ to handling missing data. While ``NaN`` is the default missing value marker for
 reasons of computational speed and convenience, we need to be able to easily
 detect this value with data of different types: floating point, integer,
 boolean, and general object. In many cases, however, the Python ``None`` will
-arise and we wish to also consider that "missing" or "null".
+arise and we wish to also consider that "missing" or "na".
 
 .. note::
 
    Prior to version v0.10.0 ``inf`` and ``-inf`` were also
-   considered to be "null" in computations. This is no longer the case by
-   default; use the ``mode.use_inf_as_null`` option to recover it.
+   considered to be "na" in computations. This is no longer the case by
+   default; use the ``mode.use_inf_as_na`` option to recover it.
 
-.. _missing.isnull:
+.. _missing.isna:
 
 To make detecting missing values easier (and across different array dtypes),
-pandas provides the :func:`~pandas.core.common.isnull` and
-:func:`~pandas.core.common.notnull` functions, which are also methods on
+pandas provides the :func:`isna` and
+:func:`notna` functions, which are also methods on
 ``Series`` and ``DataFrame`` objects:
 
 .. ipython:: python
 
    df2['one']
-   pd.isnull(df2['one'])
-   df2['four'].notnull()
-   df2.isnull()
+   pd.isna(df2['one'])
+   df2['four'].notna()
+   df2.isna()
 
 .. warning::
 
@@ -206,7 +206,7 @@ with missing data.
 Filling missing values: fillna
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-The **fillna** function can "fill in" NA values with non-null data in a couple
+The **fillna** function can "fill in" NA values with non-na data in a couple
 of ways, which we illustrate:
 
 **Replace NA with a scalar value**
@@ -220,7 +220,7 @@ of ways, which we illustrate:
 **Fill gaps forward or backward**
 
 Using the same filling arguments as :ref:`reindexing <basics.reindexing>`, we
-can propagate non-null values forward or backward:
+can propagate non-na values forward or backward:
 
 .. ipython:: python
 
@@ -288,7 +288,7 @@ a Series in this case.
 
 .. ipython:: python
 
-        dff.where(pd.notnull(dff), dff.mean(), axis='columns')
+        dff.where(pd.notna(dff), dff.mean(), axis='columns')
 
 
 .. _missing_data.dropna:
diff --git a/doc/source/options.rst b/doc/source/options.rst
index c585da64e..83b08acac 100644
--- a/doc/source/options.rst
+++ b/doc/source/options.rst
@@ -419,10 +419,10 @@ mode.chained_assignment             warn         Raise an exception, warn, or no
                                                  assignment, The default is warn
 mode.sim_interactive                False        Whether to simulate interactive mode
                                                  for purposes of testing.
-mode.use_inf_as_null                False        True means treat None, NaN, -INF,
-                                                 INF as null (old way), False means
+mode.use_inf_as_na                  False        True means treat None, NaN, -INF,
+                                                 INF as NA (old way), False means
                                                  None and NaN are null, but INF, -INF
-                                                 are not null (new way).
+                                                 are not NA (new way).
 compute.use_bottleneck              True         Use the bottleneck library to accelerate
                                                  computation if it is installed.
 compute.use_numexpr                 True         Use the numexpr library to accelerate
diff --git a/doc/source/whatsnew/v0.21.0.txt b/doc/source/whatsnew/v0.21.0.txt
index e6764178d..5a5ea827e 100644
--- a/doc/source/whatsnew/v0.21.0.txt
+++ b/doc/source/whatsnew/v0.21.0.txt
@@ -128,8 +128,6 @@ the target. Now, a ``ValueError`` will be raised when such an input is passed in
    ...
    ValueError: Cannot operate inplace if there is no assignment
 
-.. _whatsnew_0210.dtype_conversions:
-
 Dtype Conversions
 ^^^^^^^^^^^^^^^^^
 
@@ -187,6 +185,20 @@ Dtype Conversions
   - Inconsistent behavior in ``.where()`` with datetimelikes which would raise rather than coerce to ``object`` (:issue:`16402`)
    - Bug in assignment against ``int64`` data with ``np.ndarray`` with ``float64`` dtype may keep ``int64`` dtype (:issue:`14001`)
 
+.. _whatsnew_0210.api.na_changes:
+
+NA naming Changes
+^^^^^^^^^^^^^^^^^
+
+In orde to promote more consistency among the pandas API, we have added additional top-level
+functions :func:`isna` and :func:`notna` that are aliases for :func:`isnull` and :func:`notnull`.
+The naming scheme is now more consistent with methods like ``.dropna()`` and ``.fillna()``. Furthermore
+in all cases where ``.isnull()`` and ``.notnull()`` methods are defined, these have additional methods
+named ``.isna()`` and ``.notna()``, these are included for classes ``Categorical``,
+``Index``, ``Series``, and ``DataFrame``. (:issue:`15001`).
+
+The configuration option ``mode.use_inf_as_null``is deprecated, and ``mode.use_inf_as_na`` is added as a replacement.
+
 .. _whatsnew_0210.api:
 
 Other API Changes
diff --git a/pandas/_libs/algos_rank_helper.pxi.in b/pandas/_libs/algos_rank_helper.pxi.in
index aafffbf60..0945aec63 100644
--- a/pandas/_libs/algos_rank_helper.pxi.in
+++ b/pandas/_libs/algos_rank_helper.pxi.in
@@ -83,7 +83,7 @@ def rank_1d_{{dtype}}(object in_arr, ties_method='average', ascending=True,
         nan_value = {{neg_nan_value}}
 
     {{if dtype == 'object'}}
-    mask = lib.isnullobj(values)
+    mask = lib.isnaobj(values)
     {{elif dtype == 'float64'}}
     mask = np.isnan(values)
     {{elif dtype == 'int64'}}
@@ -259,7 +259,7 @@ def rank_2d_{{dtype}}(object in_arr, axis=0, ties_method='average',
         nan_value = {{neg_nan_value}}
 
     {{if dtype == 'object'}}
-    mask = lib.isnullobj2d(values)
+    mask = lib.isnaobj2d(values)
     {{elif dtype == 'float64'}}
     mask = np.isnan(values)
     {{elif dtype == 'int64'}}
diff --git a/pandas/_libs/lib.pyx b/pandas/_libs/lib.pyx
index f6e574b66..0458d4ae9 100644
--- a/pandas/_libs/lib.pyx
+++ b/pandas/_libs/lib.pyx
@@ -286,7 +286,7 @@ def item_from_zerodim(object val):
 
 @cython.wraparound(False)
 @cython.boundscheck(False)
-def isnullobj(ndarray arr):
+def isnaobj(ndarray arr):
     cdef Py_ssize_t i, n
     cdef object val
     cdef ndarray[uint8_t] result
@@ -303,7 +303,7 @@ def isnullobj(ndarray arr):
 
 @cython.wraparound(False)
 @cython.boundscheck(False)
-def isnullobj_old(ndarray arr):
+def isnaobj_old(ndarray arr):
     cdef Py_ssize_t i, n
     cdef object val
     cdef ndarray[uint8_t] result
@@ -320,7 +320,7 @@ def isnullobj_old(ndarray arr):
 
 @cython.wraparound(False)
 @cython.boundscheck(False)
-def isnullobj2d(ndarray arr):
+def isnaobj2d(ndarray arr):
     cdef Py_ssize_t i, j, n, m
     cdef object val
     cdef ndarray[uint8_t, ndim=2] result
@@ -339,7 +339,7 @@ def isnullobj2d(ndarray arr):
 
 @cython.wraparound(False)
 @cython.boundscheck(False)
-def isnullobj2d_old(ndarray arr):
+def isnaobj2d_old(ndarray arr):
     cdef Py_ssize_t i, j, n, m
     cdef object val
     cdef ndarray[uint8_t, ndim=2] result
diff --git a/pandas/_libs/testing.pyx b/pandas/_libs/testing.pyx
index 9495af87f..ab7f3c3de 100644
--- a/pandas/_libs/testing.pyx
+++ b/pandas/_libs/testing.pyx
@@ -1,7 +1,7 @@
 import numpy as np
 
 from pandas import compat
-from pandas.core.dtypes.missing import isnull, array_equivalent
+from pandas.core.dtypes.missing import isna, array_equivalent
 from pandas.core.dtypes.common import is_dtype_equal
 
 cdef NUMERIC_TYPES = (
@@ -182,7 +182,7 @@ cpdef assert_almost_equal(a, b,
     if a == b:
         # object comparison
         return True
-    if isnull(a) and isnull(b):
+    if isna(a) and isna(b):
         # nan / None comparison
         return True
     if is_comparable_as_number(a) and is_comparable_as_number(b):
diff --git a/pandas/core/algorithms.py b/pandas/core/algorithms.py
index 133e9d7dc..4ca658b35 100644
--- a/pandas/core/algorithms.py
+++ b/pandas/core/algorithms.py
@@ -27,7 +27,7 @@ from pandas.core.dtypes.common import (
     _ensure_float64, _ensure_uint64,
     _ensure_int64)
 from pandas.compat.numpy import _np_version_under1p10
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna
 
 from pandas.core import common as com
 from pandas._libs import algos, lib, hashtable as htable
@@ -427,7 +427,7 @@ def isin(comps, values):
         try:
             values = values.astype('float64', copy=False)
             comps = comps.astype('float64', copy=False)
-            checknull = isnull(values).any()
+            checknull = isna(values).any()
             f = lambda x, y: htable.ismember_float64(x, y, checknull)
         except (TypeError, ValueError):
             values = values.astype(object)
@@ -529,7 +529,7 @@ def value_counts(values, sort=True, ascending=False, normalize=False,
 
         # count, remove nulls (from the index), and but the bins
         result = ii.value_counts(dropna=dropna)
-        result = result[result.index.notnull()]
+        result = result[result.index.notna()]
         result.index = result.index.astype('interval')
         result = result.sort_index()
 
@@ -597,9 +597,9 @@ def _value_counts_arraylike(values, dropna):
         f = getattr(htable, "value_count_{dtype}".format(dtype=ndtype))
         keys, counts = f(values, dropna)
 
-        mask = isnull(values)
+        mask = isna(values)
         if not dropna and mask.any():
-            if not isnull(keys).any():
+            if not isna(keys).any():
                 keys = np.insert(keys, 0, np.NaN)
                 counts = np.insert(counts, 0, mask.sum())
 
@@ -860,7 +860,7 @@ def quantile(x, q, interpolation_method='fraction'):
 
     """
     x = np.asarray(x)
-    mask = isnull(x)
+    mask = isna(x)
 
     x = x[~mask]
 
diff --git a/pandas/core/api.py b/pandas/core/api.py
index 265fb4004..086fedd7d 100644
--- a/pandas/core/api.py
+++ b/pandas/core/api.py
@@ -5,7 +5,7 @@
 import numpy as np
 
 from pandas.core.algorithms import factorize, unique, value_counts
-from pandas.core.dtypes.missing import isnull, notnull
+from pandas.core.dtypes.missing import isna, isnull, notna, notnull
 from pandas.core.categorical import Categorical
 from pandas.core.groupby import Grouper
 from pandas.io.formats.format import set_eng_float_format
diff --git a/pandas/core/base.py b/pandas/core/base.py
index 97c4c8626..eb785b18b 100644
--- a/pandas/core/base.py
+++ b/pandas/core/base.py
@@ -6,7 +6,7 @@ from pandas import compat
 from pandas.compat import builtins
 import numpy as np
 
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna
 from pandas.core.dtypes.generic import ABCDataFrame, ABCSeries, ABCIndexClass
 from pandas.core.dtypes.common import is_object_dtype, is_list_like, is_scalar
 from pandas.util._validators import validate_bool_kwarg
@@ -894,7 +894,7 @@ class IndexOpsMixin(object):
     @cache_readonly
     def hasnans(self):
         """ return if I have any nans; enables various perf speedups """
-        return isnull(self).any()
+        return isna(self).any()
 
     def _reduce(self, op, name, axis=0, skipna=True, numeric_only=None,
                 filter_type=None, **kwds):
@@ -990,7 +990,7 @@ class IndexOpsMixin(object):
         """
         uniqs = self.unique()
         n = len(uniqs)
-        if dropna and isnull(uniqs).any():
+        if dropna and isna(uniqs).any():
             n -= 1
         return n
 
diff --git a/pandas/core/categorical.py b/pandas/core/categorical.py
index afae11163..1392ad2f0 100644
--- a/pandas/core/categorical.py
+++ b/pandas/core/categorical.py
@@ -10,7 +10,7 @@ from pandas._libs import lib, algos as libalgos
 
 from pandas.core.dtypes.generic import (
     ABCSeries, ABCIndexClass, ABCCategoricalIndex)
-from pandas.core.dtypes.missing import isnull, notnull
+from pandas.core.dtypes.missing import isna, notna
 from pandas.core.dtypes.cast import (
     maybe_infer_to_datetimelike,
     coerce_indexer_dtype)
@@ -34,8 +34,8 @@ from pandas.core.base import (PandasObject, PandasDelegate,
 import pandas.core.common as com
 from pandas.core.missing import interpolate_2d
 from pandas.compat.numpy import function as nv
-from pandas.util._decorators import (Appender, cache_readonly,
-                                     deprecate_kwarg, Substitution)
+from pandas.util._decorators import (
+    Appender, cache_readonly, deprecate_kwarg, Substitution)
 
 from pandas.io.formats.terminal import get_terminal_size
 from pandas.util._validators import validate_bool_kwarg
@@ -290,7 +290,7 @@ class Categorical(PandasObject):
                 # On list with NaNs, int values will be converted to float. Use
                 # "object" dtype to prevent this. In the end objects will be
                 # casted to int/... in the category assignment step.
-                dtype = 'object' if isnull(values).any() else None
+                dtype = 'object' if isna(values).any() else None
                 values = _sanitize_array(values, None, dtype=dtype)
 
         if categories is None:
@@ -561,9 +561,9 @@ class Categorical(PandasObject):
                 categories = _convert_to_list_like(categories)
                 # On categories with NaNs, int values would be converted to
                 # float. Use "object" dtype to prevent this.
-                if isnull(categories).any():
+                if isna(categories).any():
                     without_na = np.array([x for x in categories
-                                           if notnull(x)])
+                                           if notna(x)])
                     with_na = np.array(categories)
                     if with_na.dtype != without_na.dtype:
                         dtype = "object"
@@ -941,9 +941,9 @@ class Categorical(PandasObject):
         new_categories = [c for c in self._categories if c not in removal_set]
 
         # GH 10156
-        if any(isnull(removals)):
-            not_included = [x for x in not_included if notnull(x)]
-            new_categories = [x for x in new_categories if notnull(x)]
+        if any(isna(removals)):
+            not_included = [x for x in not_included if notna(x)]
+            new_categories = [x for x in new_categories if notna(x)]
 
         if len(not_included) != 0:
             raise ValueError("removals must all be in old categories: %s" %
@@ -1153,7 +1153,7 @@ class Categorical(PandasObject):
         return self.codes.searchsorted(values_as_codes, side=side,
                                        sorter=sorter)
 
-    def isnull(self):
+    def isna(self):
         """
         Detect missing values
 
@@ -1165,8 +1165,9 @@ class Categorical(PandasObject):
 
         See also
         --------
-        isnull : pandas version
-        Categorical.notnull : boolean inverse of Categorical.isnull
+        isna : top-level isna
+        isnull : alias of isna
+        Categorical.notna : boolean inverse of Categorical.isna
 
         """
 
@@ -1175,14 +1176,15 @@ class Categorical(PandasObject):
         # String/object and float categories can hold np.nan
         if self.categories.dtype.kind in ['S', 'O', 'f']:
             if np.nan in self.categories:
-                nan_pos = np.where(isnull(self.categories))[0]
+                nan_pos = np.where(isna(self.categories))[0]
                 # we only have one NA in categories
                 ret = np.logical_or(ret, self._codes == nan_pos)
         return ret
+    isnull = isna
 
-    def notnull(self):
+    def notna(self):
         """
-        Reverse of isnull
+        Inverse of isna
 
         Both missing values (-1 in .codes) and NA as a category are detected as
         null.
@@ -1193,11 +1195,13 @@ class Categorical(PandasObject):
 
         See also
         --------
-        notnull : pandas version
-        Categorical.isnull : boolean inverse of Categorical.notnull
+        notna : top-level notna
+        notnull : alias of notna
+        Categorical.isna : boolean inverse of Categorical.notna
 
         """
-        return ~self.isnull()
+        return ~self.isna()
+    notnull = notna
 
     def put(self, *args, **kwargs):
         """
@@ -1217,8 +1221,8 @@ class Categorical(PandasObject):
         -------
         valid : Categorical
         """
-        result = self[self.notnull()]
-        if isnull(result.categories).any():
+        result = self[self.notna()]
+        if isna(result.categories).any():
             result = result.remove_categories([np.nan])
         return result
 
@@ -1243,12 +1247,10 @@ class Categorical(PandasObject):
 
         """
         from numpy import bincount
-        from pandas.core.dtypes.missing import isnull
-        from pandas.core.series import Series
-        from pandas.core.index import CategoricalIndex
+        from pandas import isna, Series, CategoricalIndex
 
         obj = (self.remove_categories([np.nan]) if dropna and
-               isnull(self.categories).any() else self)
+               isna(self.categories).any() else self)
         code, cat = obj._codes, obj.categories
         ncat, mask = len(cat), 0 <= code
         ix, clean = np.arange(ncat), mask.all()
@@ -1520,7 +1522,7 @@ class Categorical(PandasObject):
         if self.categories.dtype.kind in ['S', 'O', 'f']:
             if np.nan in self.categories:
                 values = values.copy()
-                nan_pos = np.where(isnull(self.categories))[0]
+                nan_pos = np.where(isna(self.categories))[0]
                 # we only have one NA in categories
                 values[values == nan_pos] = -1
 
@@ -1534,13 +1536,13 @@ class Categorical(PandasObject):
 
         else:
 
-            if not isnull(value) and value not in self.categories:
+            if not isna(value) and value not in self.categories:
                 raise ValueError("fill value must be in categories")
 
             mask = values == -1
             if mask.any():
                 values = values.copy()
-                if isnull(value):
+                if isna(value):
                     values[mask] = -1
                 else:
                     values[mask] = self.categories.get_loc(value)
@@ -1556,7 +1558,7 @@ class Categorical(PandasObject):
 
         # filling must always be None/nan here
         # but is passed thru internally
-        assert isnull(fill_value)
+        assert isna(fill_value)
 
         codes = take_1d(self._codes, indexer, allow_fill=True, fill_value=-1)
         result = self._constructor(codes, categories=self.categories,
@@ -1720,7 +1722,7 @@ class Categorical(PandasObject):
 
         # no assignments of values not in categories, but it's always ok to set
         # something to np.nan
-        if len(to_add) and not isnull(to_add).all():
+        if len(to_add) and not isna(to_add).all():
             raise ValueError("Cannot setitem on a Categorical with a new "
                              "category, set the categories first")
 
@@ -1763,8 +1765,8 @@ class Categorical(PandasObject):
         # https://github.com/pandas-dev/pandas/issues/7820
         # float categories do currently return -1 for np.nan, even if np.nan is
         # included in the index -> "repair" this here
-        if isnull(rvalue).any() and isnull(self.categories).any():
-            nan_pos = np.where(isnull(self.categories))[0]
+        if isna(rvalue).any() and isna(self.categories).any():
+            nan_pos = np.where(isna(self.categories))[0]
             lindexer[lindexer == -1] = nan_pos
 
         lindexer = self._maybe_coerce_indexer(lindexer)
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 3b09e68c6..44cb36b8a 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -18,7 +18,7 @@ from pandas.core.config import get_option
 from pandas.core.dtypes.generic import ABCSeries
 from pandas.core.dtypes.common import _NS_DTYPE
 from pandas.core.dtypes.inference import _iterable_not_string
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna, isnull, notnull  # noqa
 from pandas.api import types
 from pandas.core.dtypes import common
 
@@ -187,7 +187,7 @@ def is_bool_indexer(key):
             key = np.asarray(_values_from_object(key))
 
             if not lib.is_bool_array(key):
-                if isnull(key).any():
+                if isna(key).any():
                     raise ValueError('cannot index with vector containing '
                                      'NA / NaN values')
                 return False
diff --git a/pandas/core/config_init.py b/pandas/core/config_init.py
index 06ce81170..76e30a6fb 100644
--- a/pandas/core/config_init.py
+++ b/pandas/core/config_init.py
@@ -392,9 +392,14 @@ with cf.config_prefix('mode'):
     cf.register_option('sim_interactive', False, tc_sim_interactive_doc)
 
 use_inf_as_null_doc = """
+use_inf_as_null had been deprecated and will be removed in a future version.
+Use `use_inf_as_na` instead.
+"""
+
+use_inf_as_na_doc = """
 : boolean
-    True means treat None, NaN, INF, -INF as null (old way),
-    False means None and NaN are null, but INF, -INF are not null
+    True means treat None, NaN, INF, -INF as na (old way),
+    False means None and NaN are null, but INF, -INF are not na
     (new way).
 """
 
@@ -402,14 +407,17 @@ use_inf_as_null_doc = """
 # or we'll hit circular deps.
 
 
-def use_inf_as_null_cb(key):
-    from pandas.core.dtypes.missing import _use_inf_as_null
-    _use_inf_as_null(key)
+def use_inf_as_na_cb(key):
+    from pandas.core.dtypes.missing import _use_inf_as_na
+    _use_inf_as_na(key)
 
 
-with cf.config_prefix('mode'):
-    cf.register_option('use_inf_as_null', False, use_inf_as_null_doc,
-                       cb=use_inf_as_null_cb)
+cf.register_option('mode.use_inf_as_na', False, use_inf_as_na_doc,
+                   cb=use_inf_as_na_cb)
+
+cf.deprecate_option('mode.use_inf_as_null', msg=use_inf_as_null_doc,
+                    rkey='mode.use_inf_as_na')
+
 
 # user warnings
 chained_assignment = """
diff --git a/pandas/core/dtypes/cast.py b/pandas/core/dtypes/cast.py
index 22d98a89d..723e4f70d 100644
--- a/pandas/core/dtypes/cast.py
+++ b/pandas/core/dtypes/cast.py
@@ -27,7 +27,7 @@ from .common import (_ensure_object, is_bool, is_integer, is_float,
 from .dtypes import ExtensionDtype, DatetimeTZDtype, PeriodDtype
 from .generic import (ABCDatetimeIndex, ABCPeriodIndex,
                       ABCSeries)
-from .missing import isnull, notnull
+from .missing import isna, notna
 from .inference import is_list_like
 
 _int8_max = np.iinfo(np.int8).max
@@ -121,7 +121,7 @@ def maybe_downcast_to_dtype(result, dtype):
             arr = np.array([r[0]])
 
             # if we have any nulls, then we are done
-            if (isnull(arr).any() or
+            if (isna(arr).any() or
                     not np.allclose(arr, trans(arr).astype(dtype), rtol=0)):
                 return result
 
@@ -131,7 +131,7 @@ def maybe_downcast_to_dtype(result, dtype):
                 return result
 
             if (issubclass(result.dtype.type, (np.object_, np.number)) and
-                    notnull(result).all()):
+                    notna(result).all()):
                 new_result = trans(result).astype(dtype)
                 try:
                     if np.allclose(new_result, result, rtol=0):
@@ -191,7 +191,7 @@ def maybe_upcast_putmask(result, mask, other):
         #   integer or integer array -> date-like array
         if is_datetimelike(result.dtype):
             if is_scalar(other):
-                if isnull(other):
+                if isna(other):
                     other = result.dtype.type('nat')
                 elif is_integer(other):
                     other = np.array(other, dtype=result.dtype)
@@ -232,13 +232,13 @@ def maybe_upcast_putmask(result, mask, other):
             # and its nan and we are changing some values
             if (is_scalar(other) or
                     (isinstance(other, np.ndarray) and other.ndim < 1)):
-                if isnull(other):
+                if isna(other):
                     return changeit()
 
             # we have an ndarray and the masking has nans in it
             else:
 
-                if isnull(other[mask]).any():
+                if isna(other[mask]).any():
                     return changeit()
 
         try:
@@ -268,7 +268,7 @@ def maybe_promote(dtype, fill_value=np.nan):
         # for now: refuse to upcast datetime64
         # (this is because datetime64 will not implicitly upconvert
         #  to object correctly as of numpy 1.6.1)
-        if isnull(fill_value):
+        if isna(fill_value):
             fill_value = iNaT
         else:
             if issubclass(dtype.type, np.datetime64):
@@ -287,7 +287,7 @@ def maybe_promote(dtype, fill_value=np.nan):
             else:
                 fill_value = iNaT
     elif is_datetimetz(dtype):
-        if isnull(fill_value):
+        if isna(fill_value):
             fill_value = iNaT
     elif is_float(fill_value):
         if issubclass(dtype.type, np.bool_):
@@ -580,7 +580,7 @@ def coerce_to_dtypes(result, dtypes):
 
     def conv(r, dtype):
         try:
-            if isnull(r):
+            if isna(r):
                 pass
             elif dtype == _NS_DTYPE:
                 r = tslib.Timestamp(r)
@@ -635,7 +635,7 @@ def astype_nansafe(arr, dtype, copy=True):
 
             # allow frequency conversions
             if dtype.kind == 'm':
-                mask = isnull(arr)
+                mask = isna(arr)
                 result = arr.astype(dtype).astype(np.float64)
                 result[mask] = np.nan
                 return result
@@ -687,7 +687,7 @@ def maybe_convert_objects(values, convert_dates=True, convert_numeric=True,
                 values, 'M8[ns]', errors='coerce')
 
             # if we are all nans then leave me alone
-            if not isnull(new_values).all():
+            if not isna(new_values).all():
                 values = new_values
 
         else:
@@ -702,7 +702,7 @@ def maybe_convert_objects(values, convert_dates=True, convert_numeric=True,
             new_values = to_timedelta(values, errors='coerce')
 
             # if we are all nans then leave me alone
-            if not isnull(new_values).all():
+            if not isna(new_values).all():
                 values = new_values
 
         else:
@@ -717,7 +717,7 @@ def maybe_convert_objects(values, convert_dates=True, convert_numeric=True,
                                                        coerce_numeric=True)
 
                 # if we are all nans then leave me alone
-                if not isnull(new_values).all():
+                if not isna(new_values).all():
                     values = new_values
 
             except:
@@ -779,7 +779,7 @@ def soft_convert_objects(values, datetime=True, numeric=True, timedelta=True,
             converted = lib.maybe_convert_numeric(values, set(),
                                                   coerce_numeric=True)
             # If all NaNs, then do not-alter
-            values = converted if not isnull(converted).all() else values
+            values = converted if not isna(converted).all() else values
             values = values.copy() if copy else values
         except:
             pass
@@ -881,7 +881,7 @@ def maybe_infer_to_datetimelike(value, convert_dates=False):
     elif inferred_type == 'nat':
 
         # if all NaT, return as datetime
-        if isnull(v).all():
+        if isna(v).all():
             value = try_datetime(v)
         else:
 
@@ -932,7 +932,7 @@ def maybe_cast_to_datetime(value, dtype, errors='raise'):
                 # our NaT doesn't support tz's
                 # this will coerce to DatetimeIndex with
                 # a matching dtype below
-                if is_scalar(value) and isnull(value):
+                if is_scalar(value) and isna(value):
                     value = [value]
 
             elif is_timedelta64 and not is_dtype_equal(dtype, _TD_DTYPE):
@@ -946,7 +946,7 @@ def maybe_cast_to_datetime(value, dtype, errors='raise'):
                                     "dtype [%s]" % dtype)
 
             if is_scalar(value):
-                if value == iNaT or isnull(value):
+                if value == iNaT or isna(value):
                     value = iNaT
             else:
                 value = np.array(value, copy=False)
diff --git a/pandas/core/dtypes/missing.py b/pandas/core/dtypes/missing.py
index 9913923cb..101612893 100644
--- a/pandas/core/dtypes/missing.py
+++ b/pandas/core/dtypes/missing.py
@@ -23,7 +23,7 @@ from .common import (is_string_dtype, is_datetimelike,
 from .inference import is_list_like
 
 
-def isnull(obj):
+def isna(obj):
     """Detect missing values (NaN in numeric arrays, None/NaN in object arrays)
 
     Parameters
@@ -33,34 +33,38 @@ def isnull(obj):
 
     Returns
     -------
-    isnulled : array-like of bool or bool
+    isna : array-like of bool or bool
         Array or bool indicating whether an object is null or if an array is
         given which of the element is null.
 
     See also
     --------
-    pandas.notnull: boolean inverse of pandas.isnull
+    pandas.notna: boolean inverse of pandas.isna
+    pandas.isnull: alias of isna
     """
-    return _isnull(obj)
+    return _isna(obj)
 
 
-def _isnull_new(obj):
+isnull = isna
+
+
+def _isna_new(obj):
     if is_scalar(obj):
         return lib.checknull(obj)
     # hack (for now) because MI registers as ndarray
     elif isinstance(obj, ABCMultiIndex):
-        raise NotImplementedError("isnull is not defined for MultiIndex")
+        raise NotImplementedError("isna is not defined for MultiIndex")
     elif isinstance(obj, (ABCSeries, np.ndarray, ABCIndexClass)):
-        return _isnull_ndarraylike(obj)
+        return _isna_ndarraylike(obj)
     elif isinstance(obj, ABCGeneric):
-        return obj._constructor(obj._data.isnull(func=isnull))
+        return obj._constructor(obj._data.isna(func=isna))
     elif isinstance(obj, list) or hasattr(obj, '__array__'):
-        return _isnull_ndarraylike(np.asarray(obj))
+        return _isna_ndarraylike(np.asarray(obj))
     else:
         return obj is None
 
 
-def _isnull_old(obj):
+def _isna_old(obj):
     """Detect missing values. Treat None, NaN, INF, -INF as null.
 
     Parameters
@@ -75,22 +79,22 @@ def _isnull_old(obj):
         return lib.checknull_old(obj)
     # hack (for now) because MI registers as ndarray
     elif isinstance(obj, ABCMultiIndex):
-        raise NotImplementedError("isnull is not defined for MultiIndex")
+        raise NotImplementedError("isna is not defined for MultiIndex")
     elif isinstance(obj, (ABCSeries, np.ndarray, ABCIndexClass)):
-        return _isnull_ndarraylike_old(obj)
+        return _isna_ndarraylike_old(obj)
     elif isinstance(obj, ABCGeneric):
-        return obj._constructor(obj._data.isnull(func=_isnull_old))
+        return obj._constructor(obj._data.isna(func=_isna_old))
     elif isinstance(obj, list) or hasattr(obj, '__array__'):
-        return _isnull_ndarraylike_old(np.asarray(obj))
+        return _isna_ndarraylike_old(np.asarray(obj))
     else:
         return obj is None
 
 
-_isnull = _isnull_new
+_isna = _isna_new
 
 
-def _use_inf_as_null(key):
-    """Option change callback for null/inf behaviour
+def _use_inf_as_na(key):
+    """Option change callback for na/inf behaviour
     Choose which replacement for numpy.isnan / -numpy.isfinite is used.
 
     Parameters
@@ -111,12 +115,12 @@ def _use_inf_as_null(key):
     from pandas.core.config import get_option
     flag = get_option(key)
     if flag:
-        globals()['_isnull'] = _isnull_old
+        globals()['_isna'] = _isna_old
     else:
-        globals()['_isnull'] = _isnull_new
+        globals()['_isna'] = _isna_new
 
 
-def _isnull_ndarraylike(obj):
+def _isna_ndarraylike(obj):
 
     values = getattr(obj, 'values', obj)
     dtype = values.dtype
@@ -126,10 +130,10 @@ def _isnull_ndarraylike(obj):
             from pandas import Categorical
             if not isinstance(values, Categorical):
                 values = values.values
-            result = values.isnull()
+            result = values.isna()
         elif is_interval_dtype(values):
             from pandas import IntervalIndex
-            result = IntervalIndex(obj).isnull()
+            result = IntervalIndex(obj).isna()
         else:
 
             # Working around NumPy ticket 1542
@@ -139,7 +143,7 @@ def _isnull_ndarraylike(obj):
                 result = np.zeros(values.shape, dtype=bool)
             else:
                 result = np.empty(shape, dtype=bool)
-                vec = lib.isnullobj(values.ravel())
+                vec = lib.isnaobj(values.ravel())
                 result[...] = vec.reshape(shape)
 
     elif needs_i8_conversion(obj):
@@ -156,7 +160,7 @@ def _isnull_ndarraylike(obj):
     return result
 
 
-def _isnull_ndarraylike_old(obj):
+def _isna_ndarraylike_old(obj):
     values = getattr(obj, 'values', obj)
     dtype = values.dtype
 
@@ -168,7 +172,7 @@ def _isnull_ndarraylike_old(obj):
             result = np.zeros(values.shape, dtype=bool)
         else:
             result = np.empty(shape, dtype=bool)
-            vec = lib.isnullobj_old(values.ravel())
+            vec = lib.isnaobj_old(values.ravel())
             result[:] = vec.reshape(shape)
 
     elif is_datetime64_dtype(dtype):
@@ -185,7 +189,7 @@ def _isnull_ndarraylike_old(obj):
     return result
 
 
-def notnull(obj):
+def notna(obj):
     """Replacement for numpy.isfinite / -numpy.isnan which is suitable for use
     on object arrays.
 
@@ -196,20 +200,24 @@ def notnull(obj):
 
     Returns
     -------
-    isnulled : array-like of bool or bool
+    notisna : array-like of bool or bool
         Array or bool indicating whether an object is *not* null or if an array
         is given which of the element is *not* null.
 
     See also
     --------
-    pandas.isnull : boolean inverse of pandas.notnull
+    pandas.isna : boolean inverse of pandas.notna
+    pandas.notnull : alias of notna
     """
-    res = isnull(obj)
+    res = isna(obj)
     if is_scalar(res):
         return not res
     return ~res
 
 
+notnull = notna
+
+
 def is_null_datelike_scalar(other):
     """ test whether the object is a null datelike, e.g. Nat
     but guard against passing a non-scalar """
@@ -222,11 +230,11 @@ def is_null_datelike_scalar(other):
             return other.view('i8') == iNaT
         elif is_integer(other) and other == iNaT:
             return True
-        return isnull(other)
+        return isna(other)
     return False
 
 
-def _is_na_compat(arr, fill_value=np.nan):
+def _isna_compat(arr, fill_value=np.nan):
     """
     Parameters
     ----------
@@ -238,7 +246,7 @@ def _is_na_compat(arr, fill_value=np.nan):
     True if we can fill using this fill_value
     """
     dtype = arr.dtype
-    if isnull(fill_value):
+    if isna(fill_value):
         return not (is_bool_dtype(dtype) or
                     is_integer_dtype(dtype))
     return True
@@ -286,7 +294,7 @@ def array_equivalent(left, right, strict_nan=False):
     if is_string_dtype(left) or is_string_dtype(right):
 
         if not strict_nan:
-            # isnull considers NaN and None to be equivalent.
+            # isna considers NaN and None to be equivalent.
             return lib.array_equivalent_object(
                 _ensure_object(left.ravel()), _ensure_object(right.ravel()))
 
@@ -305,7 +313,7 @@ def array_equivalent(left, right, strict_nan=False):
 
     # NaNs can occur in float and complex arrays.
     if is_float_dtype(left) or is_complex_dtype(left):
-        return ((left == right) | (isnull(left) & isnull(right))).all()
+        return ((left == right) | (isna(left) & isna(right))).all()
 
     # numpy will will not allow this type of datetimelike vs integer comparison
     elif is_datetimelike_v_numeric(left, right):
@@ -365,7 +373,7 @@ def _maybe_fill(arr, fill_value=np.nan):
     """
     if we have a compatiable fill_value and arr dtype, then fill
     """
-    if _is_na_compat(arr, fill_value):
+    if _isna_compat(arr, fill_value):
         arr.fill(fill_value)
     return arr
 
@@ -400,4 +408,4 @@ def remove_na_arraylike(arr):
     """
     Return array-like containing only true/non-NaN values, possibly empty.
     """
-    return arr[notnull(lib.values_from_object(arr))]
+    return arr[notna(lib.values_from_object(arr))]
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 2ceb62dc7..6c72fa648 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -58,7 +58,7 @@ from pandas.core.dtypes.common import (
     is_iterator,
     is_sequence,
     is_named_tuple)
-from pandas.core.dtypes.missing import isnull, notnull
+from pandas.core.dtypes.missing import isna, notna
 
 
 from pandas.core.common import (_try_sort,
@@ -3205,6 +3205,22 @@ it is assumed to be aliases for the column names')
     # ----------------------------------------------------------------------
     # Reindex-based selection methods
 
+    @Appender(_shared_docs['isna'] % _shared_doc_kwargs)
+    def isna(self):
+        return super(DataFrame, self).isna()
+
+    @Appender(_shared_docs['isna'] % _shared_doc_kwargs)
+    def isnull(self):
+        return super(DataFrame, self).isnull()
+
+    @Appender(_shared_docs['isna'] % _shared_doc_kwargs)
+    def notna(self):
+        return super(DataFrame, self).notna()
+
+    @Appender(_shared_docs['notna'] % _shared_doc_kwargs)
+    def notnull(self):
+        return super(DataFrame, self).notnull()
+
     def dropna(self, axis=0, how='any', thresh=None, subset=None,
                inplace=False):
         """
@@ -3689,8 +3705,8 @@ it is assumed to be aliases for the column names')
 
         def _arith_op(left, right):
             if fill_value is not None:
-                left_mask = isnull(left)
-                right_mask = isnull(right)
+                left_mask = isna(left)
+                right_mask = isna(right)
                 left = left.copy()
                 right = right.copy()
 
@@ -3874,8 +3890,8 @@ it is assumed to be aliases for the column names')
             this_dtype = series.dtype
             other_dtype = otherSeries.dtype
 
-            this_mask = isnull(series)
-            other_mask = isnull(otherSeries)
+            this_mask = isna(series)
+            other_mask = isna(otherSeries)
 
             # don't overwrite columns unecessarily
             # DO propagate if this column is not in the intersection
@@ -3954,11 +3970,11 @@ it is assumed to be aliases for the column names')
             x_values = x.values if hasattr(x, 'values') else x
             y_values = y.values if hasattr(y, 'values') else y
             if needs_i8_conversion:
-                mask = isnull(x)
+                mask = isna(x)
                 x_values = x_values.view('i8')
                 y_values = y_values.view('i8')
             else:
-                mask = isnull(x_values)
+                mask = isna(x_values)
 
             return expressions.where(mask, y_values, x_values,
                                      raise_on_error=True)
@@ -3998,18 +4014,18 @@ it is assumed to be aliases for the column names')
             that = other[col].values
             if filter_func is not None:
                 with np.errstate(all='ignore'):
-                    mask = ~filter_func(this) | isnull(that)
+                    mask = ~filter_func(this) | isna(that)
             else:
                 if raise_conflict:
-                    mask_this = notnull(that)
-                    mask_that = notnull(this)
+                    mask_this = notna(that)
+                    mask_that = notna(this)
                     if any(mask_this & mask_that):
                         raise ValueError("Data overlaps.")
 
                 if overwrite:
-                    mask = isnull(that)
+                    mask = isna(that)
                 else:
-                    mask = notnull(this)
+                    mask = notna(this)
 
             # don't overwrite columns unecessarily
             if mask.all():
@@ -5181,7 +5197,7 @@ it is assumed to be aliases for the column names')
         idx = cols.copy()
         mat = numeric_df.values
 
-        if notnull(mat).all():
+        if notna(mat).all():
             if min_periods is not None and min_periods > len(mat):
                 baseCov = np.empty((mat.shape[1], mat.shape[1]))
                 baseCov.fill(np.nan)
@@ -5281,9 +5297,9 @@ it is assumed to be aliases for the column names')
             result = Series(0, index=frame._get_agg_axis(axis))
         else:
             if frame._is_mixed_type:
-                result = notnull(frame).sum(axis=axis)
+                result = notna(frame).sum(axis=axis)
             else:
-                counts = notnull(frame.values).sum(axis=axis)
+                counts = notna(frame.values).sum(axis=axis)
                 result = Series(counts, index=frame._get_agg_axis(axis))
 
         return result.astype('int64')
@@ -5302,12 +5318,12 @@ it is assumed to be aliases for the column names')
                             self._get_axis_name(axis))
 
         if frame._is_mixed_type:
-            # Since we have mixed types, calling notnull(frame.values) might
+            # Since we have mixed types, calling notna(frame.values) might
             # upcast everything to object
-            mask = notnull(frame).values
+            mask = notna(frame).values
         else:
             # But use the speedup when we have homogeneous dtypes
-            mask = notnull(frame.values)
+            mask = notna(frame.values)
 
         if axis == 1:
             # We're transposing the mask rather than frame to avoid potential
@@ -5400,7 +5416,7 @@ it is assumed to be aliases for the column names')
             try:
                 if filter_type is None or filter_type == 'numeric':
                     result = result.astype(np.float64)
-                elif filter_type == 'bool' and notnull(result).all():
+                elif filter_type == 'bool' and notna(result).all():
                     result = result.astype(np.bool_)
             except (ValueError, TypeError):
 
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index f3b7b3155..abccd76b2 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -25,9 +25,8 @@ from pandas.core.dtypes.common import (
     is_dict_like,
     is_re_compilable,
     pandas_dtype)
-from pandas.core.dtypes.cast import (
-    maybe_promote, maybe_upcast_putmask)
-from pandas.core.dtypes.missing import isnull, notnull
+from pandas.core.dtypes.cast import maybe_promote, maybe_upcast_putmask
+from pandas.core.dtypes.missing import isna, notna
 from pandas.core.dtypes.generic import ABCSeries, ABCPanel
 
 from pandas.core.common import (_values_from_object,
@@ -54,7 +53,8 @@ from pandas.compat import (map, zip, lzip, lrange, string_types,
                            isidentifier, set_function_name, cPickle as pkl)
 from pandas.core.ops import _align_method_FRAME
 import pandas.core.nanops as nanops
-from pandas.util._decorators import Appender, Substitution, deprecate_kwarg
+from pandas.util._decorators import (Appender, Substitution,
+                                     deprecate_kwarg)
 from pandas.util._validators import validate_bool_kwarg
 from pandas.core import config
 
@@ -4000,7 +4000,7 @@ it is assumed to be aliases for the column names.')
                                              inplace=inplace,
                                              downcast=downcast)
             elif isinstance(value, DataFrame) and self.ndim == 2:
-                new_data = self.where(self.notnull(), value)
+                new_data = self.where(self.notna(), value)
             else:
                 raise ValueError("invalid fill value with a %s" % type(value))
 
@@ -4398,7 +4398,7 @@ it is assumed to be aliases for the column names.')
         else:
             index = _maybe_transposed_self._get_axis(alt_ax)
 
-        if pd.isnull(index).any():
+        if isna(index).any():
             raise NotImplementedError("Interpolation with NaNs in the index "
                                       "has not been implemented. Try filling "
                                       "those NaNs before interpolating.")
@@ -4503,14 +4503,14 @@ it is assumed to be aliases for the column names.')
                     loc -= 1
 
                 values = self._values
-                while loc > 0 and isnull(values[loc]):
+                while loc > 0 and isna(values[loc]):
                     loc -= 1
                 return values[loc]
 
         if not isinstance(where, Index):
             where = Index(where) if is_list else Index([where])
 
-        nulls = self.isnull() if is_series else self[subset].isnull().any(1)
+        nulls = self.isna() if is_series else self[subset].isna().any(1)
         if nulls.all():
             if is_series:
                 return self._constructor(np.nan, index=where, name=self.name)
@@ -4533,38 +4533,50 @@ it is assumed to be aliases for the column names.')
     # ----------------------------------------------------------------------
     # Action Methods
 
-    _shared_docs['isnull'] = """
-        Return a boolean same-sized object indicating if the values are null.
+    _shared_docs['isna'] = """
+        Return a boolean same-sized object indicating if the values are na.
 
         See Also
         --------
-        notnull : boolean inverse of isnull
+        %(klass)s.notna : boolean inverse of isna
+        %(klass)s.isnull : alias of isna
+        isna : top-level isna
         """
 
-    @Appender(_shared_docs['isnull'])
+    @Appender(_shared_docs['isna'] % _shared_doc_kwargs)
+    def isna(self):
+        return isna(self).__finalize__(self)
+
+    @Appender(_shared_docs['isna'] % _shared_doc_kwargs)
     def isnull(self):
-        return isnull(self).__finalize__(self)
+        return isna(self).__finalize__(self)
 
-    _shared_docs['isnotnull'] = """
+    _shared_docs['notna'] = """
         Return a boolean same-sized object indicating if the values are
-        not null.
+        not na.
 
         See Also
         --------
-        isnull : boolean inverse of notnull
+        %(klass)s.isna : boolean inverse of notna
+        %(klass)s.notnull : alias of notna
+        notna : top-level notna
         """
 
-    @Appender(_shared_docs['isnotnull'])
+    @Appender(_shared_docs['notna'] % _shared_doc_kwargs)
+    def notna(self):
+        return notna(self).__finalize__(self)
+
+    @Appender(_shared_docs['notna'] % _shared_doc_kwargs)
     def notnull(self):
-        return notnull(self).__finalize__(self)
+        return notna(self).__finalize__(self)
 
     def _clip_with_scalar(self, lower, upper, inplace=False):
-        if ((lower is not None and np.any(isnull(lower))) or
-                (upper is not None and np.any(isnull(upper)))):
+        if ((lower is not None and np.any(isna(lower))) or
+                (upper is not None and np.any(isna(upper)))):
             raise ValueError("Cannot use an NA value as a clip threshold")
 
         result = self.values
-        mask = isnull(result)
+        mask = isna(result)
 
         with np.errstate(all='ignore'):
             if upper is not None:
@@ -4588,7 +4600,7 @@ it is assumed to be aliases for the column names.')
         if axis is not None:
             axis = self._get_axis_number(axis)
 
-        if np.any(isnull(threshold)):
+        if np.any(isna(threshold)):
             raise ValueError("Cannot use an NA value as a clip threshold")
 
         # method is self.le for upper bound and self.ge for lower bound
@@ -4597,7 +4609,7 @@ it is assumed to be aliases for the column names.')
                 return self._clip_with_scalar(None, threshold, inplace=inplace)
             return self._clip_with_scalar(threshold, None, inplace=inplace)
 
-        subset = method(threshold, axis=axis) | isnull(self)
+        subset = method(threshold, axis=axis) | isna(self)
 
         # GH #15390
         # In order for where method to work, the threshold must
@@ -5472,7 +5484,7 @@ it is assumed to be aliases for the column names.')
                 right = other.reindex(join_index, level=level)
 
         # fill
-        fill_na = notnull(fill_value) or (method is not None)
+        fill_na = notna(fill_value) or (method is not None)
         if fill_na:
             left = left.fillna(fill_value, method=method, limit=limit,
                                axis=fill_axis)
@@ -6405,7 +6417,7 @@ it is assumed to be aliases for the column names.')
         rs = (data.div(data.shift(periods=periods, freq=freq, axis=axis,
                                   **kwargs)) - 1)
         if freq is None:
-            mask = isnull(_values_from_object(self))
+            mask = isna(_values_from_object(self))
             np.putmask(rs.values, mask, np.nan)
         return rs
 
@@ -6767,10 +6779,10 @@ def _make_cum_function(cls, name, name1, name2, axis_descr, desc,
         if (skipna and
                 issubclass(y.dtype.type, (np.datetime64, np.timedelta64))):
             result = accum_func(y, axis)
-            mask = isnull(self)
+            mask = isna(self)
             np.putmask(result, mask, tslib.iNaT)
         elif skipna and not issubclass(y.dtype.type, (np.integer, np.bool_)):
-            mask = isnull(self)
+            mask = isna(self)
             np.putmask(y, mask, mask_a)
             result = accum_func(y, axis)
             np.putmask(result, mask, mask_b)
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index c8a7ee752..a388892e9 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -36,7 +36,7 @@ from pandas.core.dtypes.common import (
     _ensure_categorical,
     _ensure_float)
 from pandas.core.dtypes.cast import maybe_downcast_to_dtype
-from pandas.core.dtypes.missing import isnull, notnull, _maybe_fill
+from pandas.core.dtypes.missing import isna, notna, _maybe_fill
 
 from pandas.core.common import (_values_from_object, AbstractMethodError,
                                 _default_index)
@@ -1168,7 +1168,7 @@ class GroupBy(_GroupBy):
             def first(x):
 
                 x = np.asarray(x)
-                x = x[notnull(x)]
+                x = x[notna(x)]
                 if len(x) == 0:
                     return np.nan
                 return x[0]
@@ -1183,7 +1183,7 @@ class GroupBy(_GroupBy):
             def last(x):
 
                 x = np.asarray(x)
-                x = x[notnull(x)]
+                x = x[notna(x)]
                 if len(x) == 0:
                     return np.nan
                 return x[-1]
@@ -2357,7 +2357,7 @@ class BinGrouper(BaseGrouper):
 
     @cache_readonly
     def result_index(self):
-        if len(self.binlabels) != 0 and isnull(self.binlabels[0]):
+        if len(self.binlabels) != 0 and isna(self.binlabels[0]):
             return self.binlabels[1:]
 
         return self.binlabels
@@ -3114,13 +3114,13 @@ class SeriesGroupBy(GroupBy):
             wrapper = lambda x: func(x, *args, **kwargs)
 
         # Interpret np.nan as False.
-        def true_and_notnull(x, *args, **kwargs):
+        def true_and_notna(x, *args, **kwargs):
             b = wrapper(x, *args, **kwargs)
-            return b and notnull(b)
+            return b and notna(b)
 
         try:
             indices = [self._get_index(name) for name, group in self
-                       if true_and_notnull(group)]
+                       if true_and_notna(group)]
         except ValueError:
             raise TypeError("the filter must return a boolean result")
         except TypeError:
@@ -3142,9 +3142,9 @@ class SeriesGroupBy(GroupBy):
                 'val.dtype must be object, got %s' % val.dtype
             val, _ = algorithms.factorize(val, sort=False)
             sorter = np.lexsort((val, ids))
-            _isnull = lambda a: a == -1
+            _isna = lambda a: a == -1
         else:
-            _isnull = isnull
+            _isna = isna
 
         ids, val = ids[sorter], val[sorter]
 
@@ -3154,7 +3154,7 @@ class SeriesGroupBy(GroupBy):
         inc = np.r_[1, val[1:] != val[:-1]]
 
         # 1st item of each group is a new unique observation
-        mask = _isnull(val)
+        mask = _isna(val)
         if dropna:
             inc[idx] = 1
             inc[mask] = 0
@@ -3316,7 +3316,7 @@ class SeriesGroupBy(GroupBy):
         ids, _, ngroups = self.grouper.group_info
         val = self.obj.get_values()
 
-        mask = (ids != -1) & ~isnull(val)
+        mask = (ids != -1) & ~isna(val)
         ids = _ensure_platform_int(ids)
         out = np.bincount(ids[mask], minlength=ngroups or None)
 
@@ -3870,7 +3870,7 @@ class NDFrameGroupBy(GroupBy):
             if res.shape == res_fast.shape:
                 res_r = res.values.ravel()
                 res_fast_r = res_fast.values.ravel()
-                mask = notnull(res_r)
+                mask = notna(res_r)
             if (res_r[mask] == res_fast_r[mask]).all():
                 path = fast_path
 
@@ -3950,8 +3950,8 @@ class NDFrameGroupBy(GroupBy):
                 pass
 
             # interpret the result of the filter
-            if is_bool(res) or (is_scalar(res) and isnull(res)):
-                if res and notnull(res):
+            if is_bool(res) or (is_scalar(res) and isna(res)):
+                if res and notna(res):
                     indices.append(self._get_index(name))
             else:
                 # non scalars aren't allowed
@@ -4204,13 +4204,13 @@ class DataFrameGroupBy(NDFrameGroupBy):
     def count(self):
         """ Compute count of group, excluding missing values """
         from functools import partial
-        from pandas.core.dtypes.missing import _isnull_ndarraylike as isnull
+        from pandas.core.dtypes.missing import _isna_ndarraylike as isna
 
         data, _ = self._get_data_to_aggregate()
         ids, _, ngroups = self.grouper.group_info
         mask = ids != -1
 
-        val = ((mask & ~isnull(blk.get_values())) for blk in data.blocks)
+        val = ((mask & ~isna(blk.get_values())) for blk in data.blocks)
         loc = (blk.mgr_locs for blk in data.blocks)
 
         counter = partial(count_level_2d, labels=ids, max_bin=ngroups, axis=1)
diff --git a/pandas/core/indexes/base.py b/pandas/core/indexes/base.py
index 714b95221..fd9abcfb7 100644
--- a/pandas/core/indexes/base.py
+++ b/pandas/core/indexes/base.py
@@ -14,7 +14,7 @@ from pandas import compat
 
 
 from pandas.core.dtypes.generic import ABCSeries, ABCMultiIndex, ABCPeriodIndex
-from pandas.core.dtypes.missing import isnull, array_equivalent
+from pandas.core.dtypes.missing import isna, array_equivalent
 from pandas.core.dtypes.common import (
     _ensure_int64,
     _ensure_object,
@@ -42,8 +42,8 @@ from pandas.core.common import (is_bool_indexer,
 
 from pandas.core.base import PandasObject, IndexOpsMixin
 import pandas.core.base as base
-from pandas.util._decorators import (Appender, Substitution,
-                                     cache_readonly, deprecate_kwarg)
+from pandas.util._decorators import (
+    Appender, Substitution, cache_readonly, deprecate_kwarg)
 from pandas.core.indexes.frozen import FrozenList
 import pandas.core.common as com
 import pandas.core.dtypes.concat as _concat
@@ -216,7 +216,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
                         if inferred == 'integer':
                             data = np.array(data, copy=copy, dtype=dtype)
                         elif inferred in ['floating', 'mixed-integer-float']:
-                            if isnull(data).any():
+                            if isna(data).any():
                                 raise ValueError('cannot convert float '
                                                  'NaN to integer')
 
@@ -624,7 +624,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
 
         values = np.where(cond, values, other)
 
-        if self._is_numeric_dtype and np.any(isnull(values)):
+        if self._is_numeric_dtype and np.any(isna(values)):
             # We can't coerce to the numeric dtype of "self" (unless
             # it's float) if there are NaN values in our output.
             dtype = None
@@ -735,7 +735,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
         """
         dtype = self.dtype
 
-        if self._is_numeric_dtype and isnull(item):
+        if self._is_numeric_dtype and isna(item):
             # We can't coerce to the numeric dtype of "self" (unless
             # it's float) if there are NaN values in our output.
             dtype = None
@@ -1821,7 +1821,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
     def _isnan(self):
         """ return if each value is nan"""
         if self._can_hold_na:
-            return isnull(self)
+            return isna(self)
         else:
             # shouldn't reach to this condition by checking hasnans beforehand
             values = np.empty(len(self), dtype=np.bool_)
@@ -1844,7 +1844,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
         else:
             return False
 
-    def isnull(self):
+    def isna(self):
         """
         Detect missing values
 
@@ -1852,29 +1852,33 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
 
         Returns
         -------
-        a boolean array of whether my values are null
+        a boolean array of whether my values are na
 
         See also
         --------
-        pandas.isnull : pandas version
+        isnull : alias of isna
+        pandas.isna : top-level isna
         """
         return self._isnan
+    isnull = isna
 
-    def notnull(self):
+    def notna(self):
         """
-        Reverse of isnull
+        Inverse of isna
 
         .. versionadded:: 0.20.0
 
         Returns
         -------
-        a boolean array of whether my values are not null
+        a boolean array of whether my values are not na
 
         See also
         --------
-        pandas.notnull : pandas version
+        notnull : alias of notna
+        pandas.notna : top-level notna
         """
-        return ~self.isnull()
+        return ~self.isna()
+    notnull = notna
 
     def putmask(self, mask, value):
         """
@@ -1922,7 +1926,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
                       for x in values]
 
             # could have nans
-            mask = isnull(values)
+            mask = isna(values)
             if mask.any():
                 result = np.array(result)
                 result[mask] = na_rep
@@ -1960,7 +1964,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
 
     def _format_native_types(self, na_rep='', quoting=None, **kwargs):
         """ actually format my specific types """
-        mask = isnull(self)
+        mask = isna(self)
         if not self.is_object() and not quoting:
             values = np.asarray(self).astype(str)
         else:
@@ -2411,7 +2415,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
         if dropna:
             try:
                 if self.hasnans:
-                    values = values[~isnull(values)]
+                    values = values[~isna(values)]
             except NotImplementedError:
                 pass
 
diff --git a/pandas/core/indexes/datetimelike.py b/pandas/core/indexes/datetimelike.py
index cd8559bcc..845c71b6c 100644
--- a/pandas/core/indexes/datetimelike.py
+++ b/pandas/core/indexes/datetimelike.py
@@ -17,7 +17,7 @@ from pandas.core.dtypes.common import (
 from pandas.core.dtypes.generic import (
     ABCIndex, ABCSeries,
     ABCPeriodIndex, ABCIndexClass)
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna
 from pandas.core import common as com, algorithms
 from pandas.core.algorithms import checked_add_with_arr
 from pandas.core.common import AbstractMethodError
@@ -857,7 +857,7 @@ class DatetimeIndexOpsMixin(object):
 
 def _ensure_datetimelike_to_i8(other):
     """ helper for coercing an input scalar or array to i8 """
-    if lib.isscalar(other) and isnull(other):
+    if lib.isscalar(other) and isna(other):
         other = iNaT
     elif isinstance(other, ABCIndexClass):
         # convert tz if needed
diff --git a/pandas/core/indexes/datetimes.py b/pandas/core/indexes/datetimes.py
index e6bc1790f..5a04c550f 100644
--- a/pandas/core/indexes/datetimes.py
+++ b/pandas/core/indexes/datetimes.py
@@ -23,7 +23,7 @@ from pandas.core.dtypes.common import (
     _ensure_int64)
 from pandas.core.dtypes.generic import ABCSeries
 from pandas.core.dtypes.dtypes import DatetimeTZDtype
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna
 
 import pandas.core.dtypes.concat as _concat
 from pandas.errors import PerformanceWarning
@@ -109,7 +109,7 @@ def _dt_index_cmp(opname, nat_result=False):
                 isinstance(other, compat.string_types)):
             other = _to_m8(other, tz=self.tz)
             result = func(other)
-            if isnull(other):
+            if isna(other):
                 result.fill(nat_result)
         else:
             if isinstance(other, list):
diff --git a/pandas/core/indexes/interval.py b/pandas/core/indexes/interval.py
index e6b2bc095..aa2ad21ae 100644
--- a/pandas/core/indexes/interval.py
+++ b/pandas/core/indexes/interval.py
@@ -2,7 +2,7 @@
 
 import numpy as np
 
-from pandas.core.dtypes.missing import notnull, isnull
+from pandas.core.dtypes.missing import notna, isna
 from pandas.core.dtypes.generic import ABCPeriodIndex
 from pandas.core.dtypes.dtypes import IntervalDtype
 from pandas.core.dtypes.common import (
@@ -222,8 +222,8 @@ class IntervalIndex(IntervalMixin, Index):
             raise ValueError("invalid options for 'closed': %s" % self.closed)
         if len(self.left) != len(self.right):
             raise ValueError('left and right must have the same length')
-        left_mask = notnull(self.left)
-        right_mask = notnull(self.right)
+        left_mask = notna(self.left)
+        right_mask = notna(self.right)
         if not (left_mask == right_mask).all():
             raise ValueError('missing values must be missing in the same '
                              'location both left and right sides')
@@ -240,7 +240,7 @@ class IntervalIndex(IntervalMixin, Index):
     def _isnan(self):
         """ return if each value is nan"""
         if self._mask is None:
-            self._mask = isnull(self.left)
+            self._mask = isna(self.left)
         return self._mask
 
     @cache_readonly
@@ -415,7 +415,7 @@ class IntervalIndex(IntervalMixin, Index):
         right = []
         for d in data:
 
-            if isnull(d):
+            if isna(d):
                 left.append(np.nan)
                 right.append(np.nan)
                 continue
diff --git a/pandas/core/indexes/multi.py b/pandas/core/indexes/multi.py
index ed7ca079a..420788f90 100644
--- a/pandas/core/indexes/multi.py
+++ b/pandas/core/indexes/multi.py
@@ -19,7 +19,7 @@ from pandas.core.dtypes.common import (
     is_iterator,
     is_list_like,
     is_scalar)
-from pandas.core.dtypes.missing import isnull, array_equivalent
+from pandas.core.dtypes.missing import isna, array_equivalent
 from pandas.errors import PerformanceWarning, UnsortedIndexError
 from pandas.core.common import (_values_from_object,
                                 is_bool_indexer,
@@ -783,8 +783,8 @@ class MultiIndex(Index):
 
     @Appender(ibase._index_shared_docs['fillna'])
     def fillna(self, value=None, downcast=None):
-        # isnull is not implemented for MultiIndex
-        raise NotImplementedError('isnull is not defined for MultiIndex')
+        # isna is not implemented for MultiIndex
+        raise NotImplementedError('isna is not defined for MultiIndex')
 
     @Appender(_index_shared_docs['dropna'])
     def dropna(self, how='any'):
@@ -920,7 +920,7 @@ class MultiIndex(Index):
 
             else:
                 # weird all NA case
-                formatted = [pprint_thing(na if isnull(x) else x,
+                formatted = [pprint_thing(na if isna(x) else x,
                                           escape_chars=('\t', '\r', '\n'))
                              for x in algos.take_1d(lev._values, lab)]
             stringified_levels.append(formatted)
diff --git a/pandas/core/indexes/timedeltas.py b/pandas/core/indexes/timedeltas.py
index 68713743d..2823951c0 100644
--- a/pandas/core/indexes/timedeltas.py
+++ b/pandas/core/indexes/timedeltas.py
@@ -13,7 +13,7 @@ from pandas.core.dtypes.common import (
     is_timedelta64_dtype,
     is_timedelta64_ns_dtype,
     _ensure_int64)
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna
 from pandas.core.dtypes.generic import ABCSeries
 from pandas.core.common import _maybe_box, _values_from_object
 
@@ -51,7 +51,7 @@ def _td_index_cmp(opname, nat_result=False):
                 # failed to parse as timedelta
                 raise TypeError(msg.format(type(other)))
             result = func(other)
-            if isnull(other):
+            if isna(other):
                 result.fill(nat_result)
         else:
             if not is_list_like(other):
@@ -331,7 +331,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
         if opstr in ['__div__', '__truediv__', '__floordiv__']:
             if _is_convertible_to_td(other):
                 other = Timedelta(other)
-                if isnull(other):
+                if isna(other):
                     raise NotImplementedError(
                         "division by pd.NaT not implemented")
 
@@ -430,7 +430,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
         hasnans = self.hasnans
         if hasnans:
             def f(x):
-                if isnull(x):
+                if isna(x):
                     return [np.nan] * len(columns)
                 return x.components
         else:
@@ -685,7 +685,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
         if is_list_like(key):
             raise TypeError
 
-        if isnull(key):
+        if isna(key):
             key = NaT
 
         if tolerance is not None:
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index 38cc5431a..8f6b00fd2 100755
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -15,7 +15,7 @@ from pandas.core.dtypes.common import (
     is_sparse,
     _is_unorderable_exception,
     _ensure_platform_int)
-from pandas.core.dtypes.missing import isnull, _infer_fill_value
+from pandas.core.dtypes.missing import isna, _infer_fill_value
 
 from pandas.core.index import Index, MultiIndex
 
@@ -1428,7 +1428,7 @@ class _LocIndexer(_LocationIndexer):
         else:
 
             def error():
-                if isnull(key):
+                if isna(key):
                     raise TypeError("cannot use label indexing with a null "
                                     "key")
                 raise KeyError("the label [%s] is not in the [%s]" %
@@ -1940,7 +1940,7 @@ def check_bool_indexer(ax, key):
     result = key
     if isinstance(key, ABCSeries) and not key.index.equals(ax):
         result = result.reindex(ax)
-        mask = isnull(result._values)
+        mask = isna(result._values)
         if mask.any():
             raise IndexingError('Unalignable boolean Series provided as '
                                 'indexer (index of the boolean Series and of '
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 8f3667edf..25c367fcb 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -44,8 +44,8 @@ from pandas.core.dtypes.cast import (
     astype_nansafe,
     find_common_type)
 from pandas.core.dtypes.missing import (
-    isnull, notnull, array_equivalent,
-    _is_na_compat,
+    isna, notna, array_equivalent,
+    _isna_compat,
     is_null_datelike_scalar)
 import pandas.core.dtypes.concat as _concat
 
@@ -371,7 +371,7 @@ class Block(PandasObject):
             else:
                 return self.copy()
 
-        mask = isnull(self.values)
+        mask = isna(self.values)
         if limit is not None:
             if not is_integer(limit):
                 raise ValueError('Limit must be an integer')
@@ -633,7 +633,7 @@ class Block(PandasObject):
                 dtype = dtype.type
             if issubclass(dtype, (np.bool_, np.object_)):
                 if issubclass(dtype, np.bool_):
-                    if isnull(result).all():
+                    if isna(result).all():
                         return result.astype(np.bool_)
                     else:
                         result = result.astype(np.object_)
@@ -651,7 +651,7 @@ class Block(PandasObject):
     def _try_coerce_args(self, values, other):
         """ provide coercion to our input arguments """
 
-        if np.any(notnull(other)) and not self._can_hold_element(other):
+        if np.any(notna(other)) and not self._can_hold_element(other):
             # coercion issues
             # let higher levels handle
             raise TypeError("cannot convert {} to an {}".format(
@@ -676,7 +676,7 @@ class Block(PandasObject):
         values = self.values
         if slicer is not None:
             values = values[:, slicer]
-        mask = isnull(values)
+        mask = isna(values)
 
         if not self.is_object and not quoting:
             values = values.astype(str)
@@ -764,7 +764,7 @@ class Block(PandasObject):
                 find_dtype = True
 
             elif is_scalar(value):
-                if isnull(value):
+                if isna(value):
                     # NaN promotion is handled in latter path
                     dtype = False
                 else:
@@ -894,7 +894,7 @@ class Block(PandasObject):
             mask = mask.values
 
         # if we are passed a scalar None, convert it here
-        if not is_list_like(new) and isnull(new) and not self.is_object:
+        if not is_list_like(new) and isna(new) and not self.is_object:
             new = self.fill_value
 
         if self._can_hold_element(new):
@@ -1504,7 +1504,7 @@ class Block(PandasObject):
 
         def _nanpercentile(values, q, axis, **kw):
 
-            mask = isnull(self.values)
+            mask = isna(self.values)
             if not is_scalar(mask) and mask.any():
                 if self.ndim == 1:
                     return _nanpercentile1D(values, mask, q, **kw)
@@ -1750,7 +1750,7 @@ class FloatBlock(FloatOrComplexBlock):
         # output (important for appropriate 'quoting' behaviour),
         # so do not pass it through the FloatArrayFormatter
         if float_format is None and decimal == '.':
-            mask = isnull(values)
+            mask = isna(values)
 
             if not quoting:
                 values = values.astype(str)
@@ -1869,7 +1869,7 @@ class TimeDeltaBlock(DatetimeLikeBlockMixin, IntBlock):
         base-type values, values mask, base-type other, other mask
         """
 
-        values_mask = isnull(values)
+        values_mask = isna(values)
         values = values.view('i8')
         other_mask = False
 
@@ -1879,15 +1879,15 @@ class TimeDeltaBlock(DatetimeLikeBlockMixin, IntBlock):
             other = tslib.iNaT
             other_mask = True
         elif isinstance(other, Timedelta):
-            other_mask = isnull(other)
+            other_mask = isna(other)
             other = other.value
         elif isinstance(other, timedelta):
             other = Timedelta(other).value
         elif isinstance(other, np.timedelta64):
-            other_mask = isnull(other)
+            other_mask = isna(other)
             other = Timedelta(other).value
         elif hasattr(other, 'dtype') and is_timedelta64_dtype(other):
-            other_mask = isnull(other)
+            other_mask = isna(other)
             other = other.astype('i8', copy=False).view('i8')
         else:
             # coercion issues
@@ -1899,7 +1899,7 @@ class TimeDeltaBlock(DatetimeLikeBlockMixin, IntBlock):
     def _try_coerce_result(self, result):
         """ reverse of try_coerce_args / try_operate """
         if isinstance(result, np.ndarray):
-            mask = isnull(result)
+            mask = isna(result)
             if result.dtype.kind in ['i', 'f', 'O']:
                 result = result.astype('m8[ns]')
             result[mask] = tslib.iNaT
@@ -1917,7 +1917,7 @@ class TimeDeltaBlock(DatetimeLikeBlockMixin, IntBlock):
         values = self.values
         if slicer is not None:
             values = values[:, slicer]
-        mask = isnull(values)
+        mask = isna(values)
 
         rvalues = np.empty(values.shape, dtype=object)
         if na_rep is None:
@@ -2178,7 +2178,7 @@ class ObjectBlock(Block):
 
         # deal with replacing values with objects (strings) that match but
         # whose replacement is not a string (numeric, nan, object)
-        if isnull(value) or not isinstance(value, compat.string_types):
+        if isna(value) or not isinstance(value, compat.string_types):
 
             def re_replacer(s):
                 try:
@@ -2333,7 +2333,7 @@ class CategoricalBlock(NonConsolidatableMixIn, ObjectBlock):
         if slicer is not None:
             # Categorical is always one dimension
             values = values[slicer]
-        mask = isnull(values)
+        mask = isna(values)
         values = np.array(values, dtype='object')
         values[mask] = na_rep
 
@@ -2377,7 +2377,7 @@ class DatetimeBlock(DatetimeLikeBlockMixin, Block):
             element = np.array(element)
             return element.dtype == _NS_DTYPE or element.dtype == np.int64
         return (is_integer(element) or isinstance(element, datetime) or
-                isnull(element))
+                isna(element))
 
     def _try_coerce_args(self, values, other):
         """
@@ -2396,7 +2396,7 @@ class DatetimeBlock(DatetimeLikeBlockMixin, Block):
         base-type values, values mask, base-type other, other mask
         """
 
-        values_mask = isnull(values)
+        values_mask = isna(values)
         values = values.view('i8')
         other_mask = False
 
@@ -2410,10 +2410,10 @@ class DatetimeBlock(DatetimeLikeBlockMixin, Block):
             if getattr(other, 'tz') is not None:
                 raise TypeError("cannot coerce a Timestamp with a tz on a "
                                 "naive Block")
-            other_mask = isnull(other)
+            other_mask = isna(other)
             other = other.asm8.view('i8')
         elif hasattr(other, 'dtype') and is_datetime64_dtype(other):
-            other_mask = isnull(other)
+            other_mask = isna(other)
             other = other.astype('i8', copy=False).view('i8')
         else:
             # coercion issues
@@ -2540,26 +2540,26 @@ class DatetimeTZBlock(NonConsolidatableMixIn, DatetimeBlock):
         -------
         base-type values, values mask, base-type other, other mask
         """
-        values_mask = _block_shape(isnull(values), ndim=self.ndim)
+        values_mask = _block_shape(isna(values), ndim=self.ndim)
         # asi8 is a view, needs copy
         values = _block_shape(values.asi8, ndim=self.ndim)
         other_mask = False
 
         if isinstance(other, ABCSeries):
             other = self._holder(other)
-            other_mask = isnull(other)
+            other_mask = isna(other)
 
         if isinstance(other, bool):
             raise TypeError
         elif (is_null_datelike_scalar(other) or
-              (is_scalar(other) and isnull(other))):
+              (is_scalar(other) and isna(other))):
             other = tslib.iNaT
             other_mask = True
         elif isinstance(other, self._holder):
             if other.tz != self.values.tz:
                 raise ValueError("incompatible or non tz-aware value")
             other = other.asi8
-            other_mask = isnull(other)
+            other_mask = isna(other)
         elif isinstance(other, (np.datetime64, datetime, date)):
             other = lib.Timestamp(other)
             tz = getattr(other, 'tz', None)
@@ -2567,7 +2567,7 @@ class DatetimeTZBlock(NonConsolidatableMixIn, DatetimeBlock):
             # test we can have an equal time zone
             if tz is None or str(tz) != str(self.values.tz):
                 raise ValueError("incompatible or non tz-aware value")
-            other_mask = isnull(other)
+            other_mask = isna(other)
             other = other.value
         else:
             raise TypeError
@@ -3292,7 +3292,7 @@ class BlockManager(PandasObject):
                         placement=np.arange(len(values)))],
             axes[0])
 
-    def isnull(self, **kwargs):
+    def isna(self, **kwargs):
         return self.apply('apply', **kwargs)
 
     def where(self, **kwargs):
@@ -3347,8 +3347,8 @@ class BlockManager(PandasObject):
         values = self.as_matrix()
 
         def comp(s):
-            if isnull(s):
-                return isnull(values)
+            if isna(s):
+                return isna(values)
             return _maybe_compare(values, getattr(s, 'asm8', s), operator.eq)
 
         masks = [comp(s) for i, s in enumerate(src_list)]
@@ -3681,10 +3681,10 @@ class BlockManager(PandasObject):
         """
         if self.items.is_unique:
 
-            if not isnull(item):
+            if not isna(item):
                 loc = self.items.get_loc(item)
             else:
-                indexer = np.arange(len(self.items))[isnull(self.items)]
+                indexer = np.arange(len(self.items))[isna(self.items)]
 
                 # allow a single nan location indexer
                 if not is_scalar(indexer):
@@ -3696,7 +3696,7 @@ class BlockManager(PandasObject):
             return self.iget(loc, fastpath=fastpath)
         else:
 
-            if isnull(item):
+            if isna(item):
                 raise TypeError("cannot label index with a null key")
 
             indexer = self.items.get_indexer_for([item])
@@ -4886,7 +4886,7 @@ def _putmask_smart(v, m, n):
 
         # make sure that we have a nullable type
         # if we have nulls
-        if not _is_na_compat(v, nn[0]):
+        if not _isna_compat(v, nn[0]):
             raise ValueError
 
         # we ignore ComplexWarning here
@@ -5010,7 +5010,7 @@ def get_empty_dtype_and_na(join_units):
         # Null blocks should not influence upcast class selection, unless there
         # are only null blocks, when same upcasting rules must be applied to
         # null upcast classes.
-        if unit.is_null:
+        if unit.is_na:
             null_upcast_classes[upcast_cls].append(dtype)
         else:
             upcast_classes[upcast_cls].append(dtype)
@@ -5280,7 +5280,7 @@ class JoinUnit(object):
                                             self.block.fill_value)[0])
 
     @cache_readonly
-    def is_null(self):
+    def is_na(self):
         if self.block is None:
             return True
 
@@ -5303,7 +5303,7 @@ class JoinUnit(object):
         total_len = values_flat.shape[0]
         chunk_len = max(total_len // 40, 1000)
         for i in range(0, total_len, chunk_len):
-            if not isnull(values_flat[i:i + chunk_len]).all():
+            if not isna(values_flat[i:i + chunk_len]).all():
                 return False
 
         return True
@@ -5316,7 +5316,7 @@ class JoinUnit(object):
         else:
             fill_value = upcasted_na
 
-            if self.is_null:
+            if self.is_na:
                 if getattr(self.block, 'is_object', False):
                     # we want to avoid filling with np.nan if we are
                     # using None; we already know that we are all
diff --git a/pandas/core/missing.py b/pandas/core/missing.py
index 5aabc9d87..93281e20a 100644
--- a/pandas/core/missing.py
+++ b/pandas/core/missing.py
@@ -20,7 +20,7 @@ from pandas.core.dtypes.common import (
     _ensure_float64)
 
 from pandas.core.dtypes.cast import infer_dtype_from_array
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna
 
 
 def mask_missing(arr, values_to_mask):
@@ -36,7 +36,7 @@ def mask_missing(arr, values_to_mask):
     except Exception:
         values_to_mask = np.array(values_to_mask, dtype=object)
 
-    na_mask = isnull(values_to_mask)
+    na_mask = isna(values_to_mask)
     nonna = values_to_mask[~na_mask]
 
     mask = None
@@ -63,9 +63,9 @@ def mask_missing(arr, values_to_mask):
 
     if na_mask.any():
         if mask is None:
-            mask = isnull(arr)
+            mask = isna(arr)
         else:
-            mask |= isnull(arr)
+            mask |= isna(arr)
 
     return mask
 
@@ -122,7 +122,7 @@ def interpolate_1d(xvalues, yvalues, method='linear', limit=None,
     """
     # Treat the original, non-scipy methods first.
 
-    invalid = isnull(yvalues)
+    invalid = isna(yvalues)
     valid = ~invalid
 
     if not valid.any():
@@ -479,7 +479,7 @@ def pad_1d(values, limit=None, mask=None, dtype=None):
         raise ValueError('Invalid dtype for pad_1d [%s]' % dtype.name)
 
     if mask is None:
-        mask = isnull(values)
+        mask = isna(values)
     mask = mask.view(np.uint8)
     _method(values, mask, limit=limit)
     return values
@@ -503,7 +503,7 @@ def backfill_1d(values, limit=None, mask=None, dtype=None):
         raise ValueError('Invalid dtype for backfill_1d [%s]' % dtype.name)
 
     if mask is None:
-        mask = isnull(values)
+        mask = isna(values)
     mask = mask.view(np.uint8)
 
     _method(values, mask, limit=limit)
@@ -528,7 +528,7 @@ def pad_2d(values, limit=None, mask=None, dtype=None):
         raise ValueError('Invalid dtype for pad_2d [%s]' % dtype.name)
 
     if mask is None:
-        mask = isnull(values)
+        mask = isna(values)
     mask = mask.view(np.uint8)
 
     if np.all(values.shape):
@@ -557,7 +557,7 @@ def backfill_2d(values, limit=None, mask=None, dtype=None):
         raise ValueError('Invalid dtype for backfill_2d [%s]' % dtype.name)
 
     if mask is None:
-        mask = isnull(values)
+        mask = isna(values)
     mask = mask.view(np.uint8)
 
     if np.all(values.shape):
diff --git a/pandas/core/nanops.py b/pandas/core/nanops.py
index 1d64f87b1..5bebb8eb6 100644
--- a/pandas/core/nanops.py
+++ b/pandas/core/nanops.py
@@ -16,7 +16,7 @@ from pandas.core.dtypes.common import (
     is_datetime_or_timedelta_dtype,
     is_int_or_datetime_dtype, is_any_int_dtype)
 from pandas.core.dtypes.cast import _int64_max, maybe_upcast_putmask
-from pandas.core.dtypes.missing import isnull, notnull
+from pandas.core.dtypes.missing import isna, notna
 from pandas.core.config import get_option
 from pandas.core.common import _values_from_object
 
@@ -195,7 +195,7 @@ def _get_values(values, skipna, fill_value=None, fill_value_typ=None,
     if isfinite:
         mask = _isfinite(values)
     else:
-        mask = isnull(values)
+        mask = isna(values)
 
     dtype = values.dtype
     dtype_ok = _na_ok_dtype(dtype)
@@ -232,7 +232,7 @@ def _get_values(values, skipna, fill_value=None, fill_value_typ=None,
 
 def _isfinite(values):
     if is_datetime_or_timedelta_dtype(values):
-        return isnull(values)
+        return isna(values)
     if (is_complex_dtype(values) or is_float_dtype(values) or
             is_integer_dtype(values) or is_bool_dtype(values)):
         return ~np.isfinite(values)
@@ -329,7 +329,7 @@ def nanmedian(values, axis=None, skipna=True):
     values, mask, dtype, dtype_max = _get_values(values, skipna)
 
     def get_median(x):
-        mask = notnull(x)
+        mask = notna(x)
         if not skipna and not mask.all():
             return np.nan
         return algos.median(_values_from_object(x[mask]))
@@ -395,7 +395,7 @@ def nanvar(values, axis=None, skipna=True, ddof=1):
 
     values = _values_from_object(values)
     dtype = values.dtype
-    mask = isnull(values)
+    mask = isna(values)
     if is_any_int_dtype(values):
         values = values.astype('f8')
         values[mask] = np.nan
@@ -434,7 +434,7 @@ def nanvar(values, axis=None, skipna=True, ddof=1):
 def nansem(values, axis=None, skipna=True, ddof=1):
     var = nanvar(values, axis, skipna, ddof=ddof)
 
-    mask = isnull(values)
+    mask = isna(values)
     if not is_float_dtype(values.dtype):
         values = values.astype('f8')
     count, _ = _get_counts_nanvar(mask, axis, ddof, values.dtype)
@@ -503,7 +503,7 @@ def nanskew(values, axis=None, skipna=True):
     """
 
     values = _values_from_object(values)
-    mask = isnull(values)
+    mask = isna(values)
     if not is_float_dtype(values.dtype):
         values = values.astype('f8')
         count = _get_counts(mask, axis)
@@ -558,7 +558,7 @@ def nankurt(values, axis=None, skipna=True):
 
     """
     values = _values_from_object(values)
-    mask = isnull(values)
+    mask = isna(values)
     if not is_float_dtype(values.dtype):
         values = values.astype('f8')
         count = _get_counts(mask, axis)
@@ -615,7 +615,7 @@ def nankurt(values, axis=None, skipna=True):
 
 @disallow('M8', 'm8')
 def nanprod(values, axis=None, skipna=True):
-    mask = isnull(values)
+    mask = isna(values)
     if skipna and not is_any_int_dtype(values):
         values = values.copy()
         values[mask] = 1
@@ -696,7 +696,7 @@ def nancorr(a, b, method='pearson', min_periods=None):
     if min_periods is None:
         min_periods = 1
 
-    valid = notnull(a) & notnull(b)
+    valid = notna(a) & notna(b)
     if not valid.all():
         a = a[valid]
         b = b[valid]
@@ -740,7 +740,7 @@ def nancov(a, b, min_periods=None):
     if min_periods is None:
         min_periods = 1
 
-    valid = notnull(a) & notnull(b)
+    valid = notna(a) & notna(b)
     if not valid.all():
         a = a[valid]
         b = b[valid]
@@ -778,8 +778,8 @@ def _ensure_numeric(x):
 
 def make_nancomp(op):
     def f(x, y):
-        xmask = isnull(x)
-        ymask = isnull(y)
+        xmask = isna(x)
+        ymask = isna(y)
         mask = xmask | ymask
 
         with np.errstate(all='ignore'):
diff --git a/pandas/core/ops.py b/pandas/core/ops.py
index bc201be26..4e08e1483 100644
--- a/pandas/core/ops.py
+++ b/pandas/core/ops.py
@@ -23,7 +23,7 @@ import pandas.core.missing as missing
 
 from pandas.errors import PerformanceWarning
 from pandas.core.common import _values_from_object, _maybe_match_name
-from pandas.core.dtypes.missing import notnull, isnull
+from pandas.core.dtypes.missing import notna, isna
 from pandas.core.dtypes.common import (
     needs_i8_conversion,
     is_datetimelike_v_numeric,
@@ -465,7 +465,7 @@ class _TimeOp(_Op):
             # we are in the wrong path
             if (supplied_dtype is None and other is not None and
                 (other.dtype in ('timedelta64[ns]', 'datetime64[ns]')) and
-                    isnull(values).all()):
+                    isna(values).all()):
                 values = np.empty(values.shape, dtype='timedelta64[ns]')
                 values[:] = iNaT
 
@@ -496,7 +496,7 @@ class _TimeOp(_Op):
                 raise TypeError("incompatible type for a datetime/timedelta "
                                 "operation [{0}]".format(name))
         elif inferred_type == 'floating':
-            if (isnull(values).all() and
+            if (isna(values).all() and
                     name in ('__add__', '__radd__', '__sub__', '__rsub__')):
                 values = np.empty(values.shape, dtype=other.dtype)
                 values[:] = iNaT
@@ -512,7 +512,7 @@ class _TimeOp(_Op):
     def _convert_for_datetime(self, lvalues, rvalues):
         from pandas.core.tools.timedeltas import to_timedelta
 
-        mask = isnull(lvalues) | isnull(rvalues)
+        mask = isna(lvalues) | isna(rvalues)
 
         # datetimes require views
         if self.is_datetime_lhs or self.is_datetime_rhs:
@@ -662,11 +662,11 @@ def _arith_method_SERIES(op, name, str_rep, fill_zeros=None, default_axis=None,
             if isinstance(y, (np.ndarray, ABCSeries, pd.Index)):
                 dtype = find_common_type([x.dtype, y.dtype])
                 result = np.empty(x.size, dtype=dtype)
-                mask = notnull(x) & notnull(y)
+                mask = notna(x) & notna(y)
                 result[mask] = op(x[mask], _values_from_object(y[mask]))
             elif isinstance(x, np.ndarray):
                 result = np.empty(len(x), dtype=x.dtype)
-                mask = notnull(x)
+                mask = notna(x)
                 result[mask] = op(x[mask], y)
             else:
                 raise TypeError("{typ} cannot perform the operation "
@@ -776,7 +776,7 @@ def _comp_method_SERIES(op, name, str_rep, masker=False):
                 raise TypeError("invalid type comparison")
 
             # numpy does not like comparisons vs None
-            if is_scalar(y) and isnull(y):
+            if is_scalar(y) and isna(y):
                 if name == '__ne__':
                     return np.ones(len(x), dtype=bool)
                 else:
@@ -788,10 +788,10 @@ def _comp_method_SERIES(op, name, str_rep, masker=False):
                     (not is_scalar(y) and needs_i8_conversion(y))):
 
                 if is_scalar(y):
-                    mask = isnull(x)
+                    mask = isna(x)
                     y = libindex.convert_scalar(x, _values_from_object(y))
                 else:
-                    mask = isnull(x) | isnull(y)
+                    mask = isna(x) | isna(y)
                     y = y.view('i8')
                 x = x.view('i8')
 
@@ -898,7 +898,7 @@ def _bool_method_SERIES(op, name, str_rep):
                 try:
 
                     # let null fall thru
-                    if not isnull(y):
+                    if not isna(y):
                         y = bool(y)
                     result = lib.scalar_binop(x, y, op)
                 except:
@@ -1182,7 +1182,7 @@ def _arith_method_FRAME(op, name, str_rep=None, default_axis='columns',
                 dtype = np.find_common_type([x.dtype, y.dtype], [])
                 result = np.empty(x.size, dtype=dtype)
                 yrav = y.ravel()
-                mask = notnull(xrav) & notnull(yrav)
+                mask = notna(xrav) & notna(yrav)
                 xrav = xrav[mask]
 
                 # we may need to manually
@@ -1197,7 +1197,7 @@ def _arith_method_FRAME(op, name, str_rep=None, default_axis='columns',
                         result[mask] = op(xrav, yrav)
             elif hasattr(x, 'size'):
                 result = np.empty(x.size, dtype=x.dtype)
-                mask = notnull(xrav)
+                mask = notna(xrav)
                 xrav = xrav[mask]
                 if np.prod(xrav.shape):
                     with np.errstate(all='ignore'):
@@ -1259,11 +1259,11 @@ def _flex_comp_method_FRAME(op, name, str_rep=None, default_axis='columns',
             result = np.empty(x.size, dtype=bool)
             if isinstance(y, (np.ndarray, ABCSeries)):
                 yrav = y.ravel()
-                mask = notnull(xrav) & notnull(yrav)
+                mask = notna(xrav) & notna(yrav)
                 result[mask] = op(np.array(list(xrav[mask])),
                                   np.array(list(yrav[mask])))
             else:
-                mask = notnull(xrav)
+                mask = notna(xrav)
                 result[mask] = op(np.array(list(xrav[mask])), y)
 
             if op == operator.ne:  # pragma: no cover
@@ -1335,7 +1335,7 @@ def _arith_method_PANEL(op, name, str_rep=None, fill_zeros=None,
 
             # TODO: might need to find_common_type here?
             result = np.empty(len(x), dtype=x.dtype)
-            mask = notnull(x)
+            mask = notna(x)
             result[mask] = op(x[mask], y)
             result, changed = maybe_upcast_putmask(result, ~mask, np.nan)
 
@@ -1365,11 +1365,11 @@ def _comp_method_PANEL(op, name, str_rep=None, masker=False):
             result = np.empty(x.size, dtype=bool)
             if isinstance(y, np.ndarray):
                 yrav = y.ravel()
-                mask = notnull(xrav) & notnull(yrav)
+                mask = notna(xrav) & notna(yrav)
                 result[mask] = op(np.array(list(xrav[mask])),
                                   np.array(list(yrav[mask])))
             else:
-                mask = notnull(xrav)
+                mask = notna(xrav)
                 result[mask] = op(np.array(list(xrav[mask])), y)
 
             if op == operator.ne:  # pragma: no cover
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 609bf3186..e4515efe1 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -13,7 +13,7 @@ from pandas.core.dtypes.cast import (
 from pandas.core.dtypes.common import (
     is_integer, is_list_like,
     is_string_like, is_scalar)
-from pandas.core.dtypes.missing import notnull
+from pandas.core.dtypes.missing import notna
 
 import pandas.core.computation.expressions as expressions
 import pandas.core.common as com
@@ -685,7 +685,7 @@ class Panel(NDFrame):
         axis = self._get_axis_number(axis)
 
         values = self.values
-        mask = notnull(values)
+        mask = notna(values)
 
         for ax in reversed(sorted(set(range(self._AXIS_LEN)) - set([axis]))):
             mask = mask.sum(ax)
@@ -907,7 +907,7 @@ class Panel(NDFrame):
 
         if filter_observations:
             # shaped like the return DataFrame
-            mask = notnull(self.values).all(axis=0)
+            mask = notna(self.values).all(axis=0)
             # size = mask.sum()
             selector = mask.ravel()
         else:
diff --git a/pandas/core/reshape/pivot.py b/pandas/core/reshape/pivot.py
index 890555477..c2fb81178 100644
--- a/pandas/core/reshape/pivot.py
+++ b/pandas/core/reshape/pivot.py
@@ -175,7 +175,7 @@ def pivot_table(data, values=None, index=None, columns=None, aggfunc='mean',
 
     if margins:
         if dropna:
-            data = data[data.notnull().all(axis=1)]
+            data = data[data.notna().all(axis=1)]
         table = _add_margins(table, data, values, rows=index,
                              cols=columns, aggfunc=aggfunc,
                              margins_name=margins_name)
diff --git a/pandas/core/reshape/reshape.py b/pandas/core/reshape/reshape.py
index dcb83d225..b7638471f 100644
--- a/pandas/core/reshape/reshape.py
+++ b/pandas/core/reshape/reshape.py
@@ -12,7 +12,7 @@ from pandas.core.dtypes.common import (
     is_list_like, is_bool_dtype,
     needs_i8_conversion)
 from pandas.core.dtypes.cast import maybe_promote
-from pandas.core.dtypes.missing import notnull
+from pandas.core.dtypes.missing import notna
 import pandas.core.dtypes.concat as _concat
 
 from pandas.core.series import Series
@@ -547,7 +547,7 @@ def stack(frame, level=-1, dropna=True):
 
     new_values = frame.values.ravel()
     if dropna:
-        mask = notnull(new_values)
+        mask = notna(new_values)
         new_values = new_values[mask]
         new_index = new_index[mask]
     return Series(new_values, index=new_index)
@@ -835,7 +835,7 @@ def lreshape(data, groups, dropna=True, label=None):
     if dropna:
         mask = np.ones(len(mdata[pivot_cols[0]]), dtype=bool)
         for c in pivot_cols:
-            mask &= notnull(mdata[c])
+            mask &= notna(mdata[c])
         if not mask.all():
             mdata = dict((k, v[mask]) for k, v in compat.iteritems(mdata))
 
diff --git a/pandas/core/reshape/tile.py b/pandas/core/reshape/tile.py
index d8398023a..1cb39faa2 100644
--- a/pandas/core/reshape/tile.py
+++ b/pandas/core/reshape/tile.py
@@ -2,7 +2,7 @@
 Quantilization functions and related stuff
 """
 
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna
 from pandas.core.dtypes.common import (
     is_integer,
     is_scalar,
@@ -241,7 +241,7 @@ def _bins_to_cuts(x, bins, right=True, labels=None,
     if include_lowest:
         ids[x == bins[0]] = 1
 
-    na_mask = isnull(x) | (ids == len(bins)) | (ids == 0)
+    na_mask = isna(x) | (ids == len(bins)) | (ids == 0)
     has_nas = na_mask.any()
 
     if labels is not False:
diff --git a/pandas/core/series.py b/pandas/core/series.py
index c7ead292c..fb5819b27 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -36,7 +36,8 @@ from pandas.core.dtypes.cast import (
     maybe_upcast, infer_dtype_from_scalar,
     maybe_convert_platform,
     maybe_cast_to_datetime, maybe_castable)
-from pandas.core.dtypes.missing import isnull, notnull, remove_na_arraylike
+from pandas.core.dtypes.missing import isna, notna, remove_na_arraylike
+
 from pandas.core.common import (is_bool_indexer,
                                 _default_index,
                                 _asarray_tuplesafe,
@@ -745,7 +746,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
                     pass
                 elif is_timedelta64_dtype(self.dtype):
                     # reassign a null value to iNaT
-                    if isnull(value):
+                    if isna(value):
                         value = iNaT
 
                         try:
@@ -1226,7 +1227,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         from pandas.core.index import _get_na_value
 
         if level is None:
-            return notnull(_values_from_object(self)).sum()
+            return notna(_values_from_object(self)).sum()
 
         if isinstance(level, compat.string_types):
             level = self.index._get_level_number(level)
@@ -1239,7 +1240,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
             lab[mask] = cnt = len(lev)
             lev = lev.insert(cnt, _get_na_value(lev.dtype.type))
 
-        obs = lab[notnull(self.values)]
+        obs = lab[notna(self.values)]
         out = np.bincount(obs, minlength=len(lev) or None)
         return self._constructor(out, index=lev,
                                  dtype='int64').__finalize__(self)
@@ -1665,8 +1666,8 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         other_vals = other.values
 
         if fill_value is not None:
-            this_mask = isnull(this_vals)
-            other_mask = isnull(other_vals)
+            this_mask = isna(this_vals)
+            other_mask = isna(other_vals)
             this_vals = this_vals.copy()
             other_vals = other_vals.copy()
 
@@ -1735,7 +1736,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         other = other.reindex(new_index, copy=False)
         # TODO: do we need name?
         name = _maybe_match_name(self, other)  # noqa
-        rs_vals = com._where_compat(isnull(this), other._values, this._values)
+        rs_vals = com._where_compat(isna(this), other._values, this._values)
         return self._constructor(rs_vals, index=new_index).__finalize__(self)
 
     def update(self, other):
@@ -1748,7 +1749,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         other : Series
         """
         other = other.reindex_like(self)
-        mask = notnull(other)
+        mask = notna(other)
 
         self._data = self._data.putmask(mask=mask, new=other, inplace=True)
         self._maybe_update_cacher()
@@ -1781,7 +1782,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         arr = self._values
         sortedIdx = np.empty(len(self), dtype=np.int32)
 
-        bad = isnull(arr)
+        bad = isna(arr)
 
         good = ~bad
         idx = _default_index(len(self))
@@ -1886,7 +1887,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         numpy.ndarray.argsort
         """
         values = self._values
-        mask = isnull(values)
+        mask = isna(values)
 
         if mask.any():
             result = Series(-1, index=self.index, name=self.name,
@@ -2215,7 +2216,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
             if na_action == 'ignore':
                 def map_f(values, f):
                     return lib.map_infer_mask(values, f,
-                                              isnull(values).view(np.uint8))
+                                              isna(values).view(np.uint8))
             else:
                 map_f = lib.map_infer
 
@@ -2783,6 +2784,22 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
                     merge_cells=merge_cells, encoding=encoding,
                     inf_rep=inf_rep, verbose=verbose)
 
+    @Appender(generic._shared_docs['isna'] % _shared_doc_kwargs)
+    def isna(self):
+        return super(Series, self).isna()
+
+    @Appender(generic._shared_docs['isna'] % _shared_doc_kwargs)
+    def isnull(self):
+        return super(Series, self).isnull()
+
+    @Appender(generic._shared_docs['isna'] % _shared_doc_kwargs)
+    def notna(self):
+        return super(Series, self).notna()
+
+    @Appender(generic._shared_docs['notna'] % _shared_doc_kwargs)
+    def notnull(self):
+        return super(Series, self).notnull()
+
     def dropna(self, axis=0, inplace=False, **kwargs):
         """
         Return Series without null values
@@ -2824,7 +2841,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         if len(self) == 0:
             return None
 
-        mask = isnull(self._values)
+        mask = isna(self._values)
         i = mask.argmin()
         if mask[i]:
             return None
@@ -2838,7 +2855,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         if len(self) == 0:
             return None
 
-        mask = isnull(self._values[::-1])
+        mask = isna(self._values[::-1])
         i = mask.argmin()
         if mask[i]:
             return None
@@ -3010,7 +3027,7 @@ def _sanitize_array(data, index, dtype=None, copy=False,
 
             # possibility of nan -> garbage
             if is_float_dtype(data.dtype) and is_integer_dtype(dtype):
-                if not isnull(data).any():
+                if not isna(data).any():
                     subarr = _try_cast(data, True)
                 elif copy:
                     subarr = data.copy()
diff --git a/pandas/core/sorting.py b/pandas/core/sorting.py
index 44a27bb5c..12e8d8aba 100644
--- a/pandas/core/sorting.py
+++ b/pandas/core/sorting.py
@@ -9,7 +9,7 @@ from pandas.core.dtypes.common import (
     is_list_like,
     is_categorical_dtype)
 from pandas.core.dtypes.cast import infer_dtype_from_array
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna
 import pandas.core.algorithms as algorithms
 from pandas._libs import lib, algos, hashtable
 from pandas._libs.hashtable import unique_label_indices
@@ -239,7 +239,7 @@ def nargsort(items, kind='quicksort', ascending=True, na_position='last'):
 
     items = np.asanyarray(items)
     idx = np.arange(len(items))
-    mask = isnull(items)
+    mask = isna(items)
     non_nans = items[~mask]
     non_nan_idx = idx[~mask]
     nan_idx = np.nonzero(mask)[0]
diff --git a/pandas/core/sparse/array.py b/pandas/core/sparse/array.py
index 42fc5189e..4a12dd1af 100644
--- a/pandas/core/sparse/array.py
+++ b/pandas/core/sparse/array.py
@@ -27,7 +27,7 @@ from pandas.core.dtypes.common import (
 from pandas.core.dtypes.cast import (
     maybe_convert_platform, maybe_promote,
     astype_nansafe, find_common_type)
-from pandas.core.dtypes.missing import isnull, notnull, na_value_for_dtype
+from pandas.core.dtypes.missing import isna, notna, na_value_for_dtype
 
 import pandas._libs.sparse as splib
 from pandas._libs.sparse import SparseIndex, BlockIndex, IntIndex
@@ -579,12 +579,12 @@ class SparseArray(PandasObject, np.ndarray):
 
     @property
     def _null_fill_value(self):
-        return isnull(self.fill_value)
+        return isna(self.fill_value)
 
     @property
     def _valid_sp_values(self):
         sp_vals = self.sp_values
-        mask = notnull(sp_vals)
+        mask = notna(sp_vals)
         return sp_vals[mask]
 
     @Appender(_index_shared_docs['fillna'] % _sparray_doc_kwargs)
@@ -595,7 +595,7 @@ class SparseArray(PandasObject, np.ndarray):
         if issubclass(self.dtype.type, np.floating):
             value = float(value)
 
-        new_values = np.where(isnull(self.sp_values), value, self.sp_values)
+        new_values = np.where(isna(self.sp_values), value, self.sp_values)
         fill_value = value if self._null_fill_value else self.fill_value
 
         return self._simple_new(new_values, self.sp_index,
@@ -687,7 +687,7 @@ class SparseArray(PandasObject, np.ndarray):
                 pass
             else:
                 if self._null_fill_value:
-                    mask = pd.isnull(keys)
+                    mask = pd.isna(keys)
                 else:
                     mask = keys == self.fill_value
 
@@ -767,8 +767,8 @@ def make_sparse(arr, kind='block', fill_value=None):
     if fill_value is None:
         fill_value = na_value_for_dtype(arr.dtype)
 
-    if isnull(fill_value):
-        mask = notnull(arr)
+    if isna(fill_value):
+        mask = notna(arr)
     else:
         # For str arrays in NumPy 1.12.0, operator!= below isn't
         # element-wise but just returns False if fill_value is not str,
diff --git a/pandas/core/sparse/frame.py b/pandas/core/sparse/frame.py
index 462fb1861..d8c0aa41e 100644
--- a/pandas/core/sparse/frame.py
+++ b/pandas/core/sparse/frame.py
@@ -10,7 +10,7 @@ from pandas.compat import lmap
 from pandas import compat
 import numpy as np
 
-from pandas.core.dtypes.missing import isnull, notnull
+from pandas.core.dtypes.missing import isna, notna
 from pandas.core.dtypes.cast import maybe_upcast, find_common_type
 from pandas.core.dtypes.common import _ensure_platform_int, is_scipy_sparse
 
@@ -565,7 +565,7 @@ class SparseDataFrame(DataFrame):
             new_data[col] = func(series.values, other.values)
 
         # fill_value is a function of our operator
-        if isnull(other.fill_value) or isnull(self.default_fill_value):
+        if isna(other.fill_value) or isna(self.default_fill_value):
             fill_value = np.nan
         else:
             fill_value = func(np.float64(self.default_fill_value),
@@ -651,7 +651,7 @@ class SparseDataFrame(DataFrame):
         if level is not None:
             raise TypeError('Reindex by level not supported for sparse')
 
-        if notnull(fill_value):
+        if notna(fill_value):
             raise NotImplementedError("'fill_value' argument is not supported")
 
         if limit:
@@ -785,13 +785,15 @@ class SparseDataFrame(DataFrame):
 
         return self.apply(lambda x: x.cumsum(), axis=axis)
 
-    @Appender(generic._shared_docs['isnull'])
-    def isnull(self):
-        return self._apply_columns(lambda x: x.isnull())
+    @Appender(generic._shared_docs['isna'])
+    def isna(self):
+        return self._apply_columns(lambda x: x.isna())
+    isnull = isna
 
-    @Appender(generic._shared_docs['isnotnull'])
-    def isnotnull(self):
-        return self._apply_columns(lambda x: x.isnotnull())
+    @Appender(generic._shared_docs['notna'])
+    def notna(self):
+        return self._apply_columns(lambda x: x.notna())
+    notnull = notna
 
     def apply(self, func, axis=0, broadcast=False, reduce=False):
         """
diff --git a/pandas/core/sparse/series.py b/pandas/core/sparse/series.py
index 1bc9cf537..62d20e73d 100644
--- a/pandas/core/sparse/series.py
+++ b/pandas/core/sparse/series.py
@@ -8,7 +8,7 @@ with float64 data
 import numpy as np
 import warnings
 
-from pandas.core.dtypes.missing import isnull, notnull
+from pandas.core.dtypes.missing import isna, notna
 from pandas.core.dtypes.common import is_scalar
 from pandas.core.common import _values_from_object, _maybe_match_name
 
@@ -172,7 +172,7 @@ class SparseSeries(Series):
             else:
                 length = len(index)
 
-                if data == fill_value or (isnull(data) and isnull(fill_value)):
+                if data == fill_value or (isna(data) and isna(fill_value)):
                     if kind == 'block':
                         sparse_index = BlockIndex(length, [], [])
                     else:
@@ -641,19 +641,21 @@ class SparseSeries(Series):
             new_array, index=self.index,
             sparse_index=new_array.sp_index).__finalize__(self)
 
-    @Appender(generic._shared_docs['isnull'])
-    def isnull(self):
-        arr = SparseArray(isnull(self.values.sp_values),
+    @Appender(generic._shared_docs['isna'])
+    def isna(self):
+        arr = SparseArray(isna(self.values.sp_values),
                           sparse_index=self.values.sp_index,
-                          fill_value=isnull(self.fill_value))
+                          fill_value=isna(self.fill_value))
         return self._constructor(arr, index=self.index).__finalize__(self)
+    isnull = isna
 
-    @Appender(generic._shared_docs['isnotnull'])
-    def isnotnull(self):
-        arr = SparseArray(notnull(self.values.sp_values),
+    @Appender(generic._shared_docs['notna'])
+    def notna(self):
+        arr = SparseArray(notna(self.values.sp_values),
                           sparse_index=self.values.sp_index,
-                          fill_value=notnull(self.fill_value))
+                          fill_value=notna(self.fill_value))
         return self._constructor(arr, index=self.index).__finalize__(self)
+    notnull = notna
 
     def dropna(self, axis=0, inplace=False, **kwargs):
         """
@@ -665,7 +667,7 @@ class SparseSeries(Series):
         if inplace:
             raise NotImplementedError("Cannot perform inplace dropna"
                                       " operations on a SparseSeries")
-        if isnull(self.fill_value):
+        if isna(self.fill_value):
             return dense_valid
         else:
             dense_valid = dense_valid[dense_valid != self.fill_value]
@@ -677,7 +679,7 @@ class SparseSeries(Series):
             return self.copy()
 
         # no special handling of fill values yet
-        if not isnull(self.fill_value):
+        if not isna(self.fill_value):
             shifted = self.to_dense().shift(periods, freq=freq,
                                             axis=axis)
             return shifted.to_sparse(fill_value=self.fill_value,
diff --git a/pandas/core/strings.py b/pandas/core/strings.py
index cd7e313b1..30465561a 100644
--- a/pandas/core/strings.py
+++ b/pandas/core/strings.py
@@ -2,7 +2,7 @@ import numpy as np
 
 from pandas.compat import zip
 from pandas.core.dtypes.generic import ABCSeries, ABCIndex
-from pandas.core.dtypes.missing import isnull, notnull
+from pandas.core.dtypes.missing import isna, notna
 from pandas.core.dtypes.common import (
     is_bool_dtype,
     is_categorical_dtype,
@@ -101,7 +101,7 @@ def str_cat(arr, others=None, sep=None, na_rep=None):
         arrays = _get_array_list(arr, others)
 
         n = _length_check(arrays)
-        masks = np.array([isnull(x) for x in arrays])
+        masks = np.array([isna(x) for x in arrays])
         cats = None
 
         if na_rep is None:
@@ -129,12 +129,12 @@ def str_cat(arr, others=None, sep=None, na_rep=None):
         return result
     else:
         arr = np.asarray(arr, dtype=object)
-        mask = isnull(arr)
+        mask = isna(arr)
         if na_rep is None and mask.any():
             if sep == '':
                 na_rep = ''
             else:
-                return sep.join(arr[notnull(arr)])
+                return sep.join(arr[notna(arr)])
         return sep.join(np.where(mask, na_rep, arr))
 
 
@@ -165,7 +165,7 @@ def _map(f, arr, na_mask=False, na_value=np.nan, dtype=object):
     if not isinstance(arr, np.ndarray):
         arr = np.asarray(arr, dtype=object)
     if na_mask:
-        mask = isnull(arr)
+        mask = isna(arr)
         try:
             convert = not all(mask)
             result = lib.map_infer_mask(arr, f, mask.view(np.uint8), convert)
@@ -1391,7 +1391,7 @@ class StringMethods(NoNewAttributesMixin):
     def __iter__(self):
         i = 0
         g = self.get(i)
-        while g.notnull().any():
+        while g.notna().any():
             yield g
             i += 1
             g = self.get(i)
diff --git a/pandas/core/tools/datetimes.py b/pandas/core/tools/datetimes.py
index 9c02a6212..a1f323aff 100644
--- a/pandas/core/tools/datetimes.py
+++ b/pandas/core/tools/datetimes.py
@@ -18,7 +18,7 @@ from pandas.core.dtypes.common import (
 from pandas.core.dtypes.generic import (
     ABCIndexClass, ABCSeries,
     ABCDataFrame)
-from pandas.core.dtypes.missing import notnull
+from pandas.core.dtypes.missing import notna
 from pandas.core import algorithms
 
 import pandas.compat as compat
@@ -176,7 +176,7 @@ def _guess_datetime_format(dt_str, dayfirst=False,
 
 def _guess_datetime_format_for_array(arr, **kwargs):
     # Try to guess the format based on the first non-NaN element
-    non_nan_elements = notnull(arr).nonzero()[0]
+    non_nan_elements = notna(arr).nonzero()[0]
     if len(non_nan_elements):
         return _guess_datetime_format(arr[non_nan_elements[0]], **kwargs)
 
@@ -665,7 +665,7 @@ def _attempt_YYYYMMDD(arg, errors):
     # a float with actual np.nan
     try:
         carg = arg.astype(np.float64)
-        return calc_with_mask(carg, notnull(carg))
+        return calc_with_mask(carg, notna(carg))
     except:
         pass
 
@@ -744,7 +744,7 @@ _time_formats = ["%H:%M", "%H%M", "%I:%M%p", "%I%M%p",
 
 def _guess_time_format_for_array(arr):
     # Try to guess the format based on the first non-NaN element
-    non_nan_elements = notnull(arr).nonzero()[0]
+    non_nan_elements = notna(arr).nonzero()[0]
     if len(non_nan_elements):
         element = arr[non_nan_elements[0]]
         for time_format in _time_formats:
diff --git a/pandas/core/util/hashing.py b/pandas/core/util/hashing.py
index e41ffae9d..07e993d7e 100644
--- a/pandas/core/util/hashing.py
+++ b/pandas/core/util/hashing.py
@@ -12,7 +12,7 @@ from pandas.core.dtypes.generic import (
     ABCDataFrame)
 from pandas.core.dtypes.common import (
     is_categorical_dtype, is_list_like)
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna
 from pandas.core.dtypes.cast import infer_dtype_from_scalar
 
 
@@ -215,7 +215,7 @@ def _hash_categorical(c, encoding, hash_key):
     #
     # TODO: GH 15362
 
-    mask = c.isnull()
+    mask = c.isna()
     if len(hashed):
         result = hashed.take(c.codes)
     else:
@@ -313,7 +313,7 @@ def _hash_scalar(val, encoding='utf8', hash_key=None):
     1d uint64 numpy array of hash value, of length 1
     """
 
-    if isnull(val):
+    if isna(val):
         # this is to be consistent with the _hash_categorical implementation
         return np.array([np.iinfo(np.uint64).max], dtype='u8')
 
diff --git a/pandas/core/window.py b/pandas/core/window.py
index 57611794c..5866f1e8a 100644
--- a/pandas/core/window.py
+++ b/pandas/core/window.py
@@ -828,7 +828,7 @@ class _Rolling_and_Expanding(_Rolling):
 
         results = []
         for b in blocks:
-            result = b.notnull().astype(int)
+            result = b.notna().astype(int)
             result = self._constructor(result, window=window, min_periods=0,
                                        center=self.center,
                                        closed=self.closed).sum()
diff --git a/pandas/io/formats/format.py b/pandas/io/formats/format.py
index 23eb3bb05..2b322431b 100644
--- a/pandas/io/formats/format.py
+++ b/pandas/io/formats/format.py
@@ -10,7 +10,7 @@ from distutils.version import LooseVersion
 
 from textwrap import dedent
 
-from pandas.core.dtypes.missing import isnull, notnull
+from pandas.core.dtypes.missing import isna, notna
 from pandas.core.dtypes.common import (
     is_categorical_dtype,
     is_float_dtype,
@@ -1562,7 +1562,7 @@ class CSVFormatter(object):
         self.data_index = obj.index
         if (isinstance(self.data_index, (DatetimeIndex, PeriodIndex)) and
                 date_format is not None):
-            self.data_index = Index([x.strftime(date_format) if notnull(x) else
+            self.data_index = Index([x.strftime(date_format) if notna(x) else
                                      '' for x in self.data_index])
 
         self.nlevels = getattr(self.data_index, 'nlevels', 1)
@@ -1816,7 +1816,7 @@ class GenericArrayFormatter(object):
         elif isinstance(vals, ABCSparseArray):
             vals = vals.values
 
-        is_float_type = lib.map_infer(vals, is_float) & notnull(vals)
+        is_float_type = lib.map_infer(vals, is_float) & notna(vals)
         leading_space = is_float_type.any()
 
         fmt_values = []
@@ -1862,10 +1862,10 @@ class FloatArrayFormatter(GenericArrayFormatter):
         # because str(0.0) = '0.0' while '%g' % 0.0 = '0'
         if float_format:
             def base_formatter(v):
-                return (float_format % v) if notnull(v) else self.na_rep
+                return (float_format % v) if notna(v) else self.na_rep
         else:
             def base_formatter(v):
-                return str(v) if notnull(v) else self.na_rep
+                return str(v) if notna(v) else self.na_rep
 
         if self.decimal != '.':
             def decimal_formatter(v):
@@ -1877,7 +1877,7 @@ class FloatArrayFormatter(GenericArrayFormatter):
             return decimal_formatter
 
         def formatter(value):
-            if notnull(value):
+            if notna(value):
                 if abs(value) > threshold:
                     return decimal_formatter(value)
                 else:
@@ -1907,7 +1907,7 @@ class FloatArrayFormatter(GenericArrayFormatter):
 
             # separate the wheat from the chaff
             values = self.values
-            mask = isnull(values)
+            mask = isna(values)
             if hasattr(values, 'to_dense'):  # sparse numpy ndarray
                 values = values.to_dense()
             values = np.array(values, dtype='object')
diff --git a/pandas/io/formats/style.py b/pandas/io/formats/style.py
index d88a230b4..445fceb4b 100644
--- a/pandas/io/formats/style.py
+++ b/pandas/io/formats/style.py
@@ -771,7 +771,7 @@ class Styler(object):
 
     @staticmethod
     def _highlight_null(v, null_color):
-        return 'background-color: %s' % null_color if pd.isnull(v) else ''
+        return 'background-color: %s' % null_color if pd.isna(v) else ''
 
     def highlight_null(self, null_color='red'):
         """
diff --git a/pandas/io/json/json.py b/pandas/io/json/json.py
index 31907ad58..a1d48719b 100644
--- a/pandas/io/json/json.py
+++ b/pandas/io/json/json.py
@@ -5,7 +5,7 @@ import numpy as np
 import pandas._libs.json as json
 from pandas._libs.tslib import iNaT
 from pandas.compat import StringIO, long, u
-from pandas import compat, isnull
+from pandas import compat, isna
 from pandas import Series, DataFrame, to_datetime, MultiIndex
 from pandas.io.common import (get_filepath_or_buffer, _get_handle,
                               _stringify_path)
@@ -535,7 +535,7 @@ class Parser(object):
 
         # ignore numbers that are out of range
         if issubclass(new_data.dtype.type, np.number):
-            in_range = (isnull(new_data.values) | (new_data > self.min_stamp) |
+            in_range = (isna(new_data.values) | (new_data > self.min_stamp) |
                         (new_data.values == iNaT))
             if not in_range.all():
                 return data, False
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 1e7d9d420..9cf0a11a6 100755
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -21,7 +21,7 @@ from pandas.core.dtypes.common import (
     is_float, is_dtype_equal,
     is_object_dtype, is_string_dtype,
     is_scalar, is_categorical_dtype)
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna
 from pandas.core.dtypes.cast import astype_nansafe
 from pandas.core.index import Index, MultiIndex, RangeIndex
 from pandas.core.series import Series
@@ -1532,7 +1532,7 @@ class ParserBase(object):
         if try_num_bool:
             try:
                 result = lib.maybe_convert_numeric(values, na_values, False)
-                na_count = isnull(result).sum()
+                na_count = isna(result).sum()
             except Exception:
                 result = values
                 if values.dtype == np.object_:
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 4e343556c..82c80a133 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -25,7 +25,7 @@ from pandas.core.dtypes.missing import array_equivalent
 
 import numpy as np
 from pandas import (Series, DataFrame, Panel, Panel4D, Index,
-                    MultiIndex, Int64Index, isnull, concat,
+                    MultiIndex, Int64Index, isna, concat,
                     SparseSeries, SparseDataFrame, PeriodIndex,
                     DatetimeIndex, TimedeltaIndex)
 from pandas.core import config
@@ -2136,7 +2136,7 @@ class DataCol(IndexCol):
                 # if we have stored a NaN in the categories
                 # then strip it; in theory we could have BOTH
                 # -1s in the codes and nulls :<
-                mask = isnull(categories)
+                mask = isna(categories)
                 if mask.any():
                     categories = categories[~mask]
                     codes[codes != -1] -= mask.astype(int).cumsum().values
@@ -3941,7 +3941,7 @@ class AppendableTable(LegacyTable):
 
                 # figure the mask: only do if we can successfully process this
                 # column, otherwise ignore the mask
-                mask = isnull(a.data).all(axis=0)
+                mask = isna(a.data).all(axis=0)
                 if isinstance(mask, np.ndarray):
                     masks.append(mask.astype('u1', copy=False))
 
diff --git a/pandas/io/sql.py b/pandas/io/sql.py
index 0dbef6661..9aa47e5c6 100644
--- a/pandas/io/sql.py
+++ b/pandas/io/sql.py
@@ -12,7 +12,7 @@ import re
 import numpy as np
 
 import pandas._libs.lib as lib
-from pandas.core.dtypes.missing import isnull
+from pandas.core.dtypes.missing import isna
 from pandas.core.dtypes.dtypes import DatetimeTZDtype
 from pandas.core.dtypes.common import (
     is_list_like, is_dict_like,
@@ -632,7 +632,7 @@ class SQLTable(PandasObject):
 
             # replace NaN with None
             if b._can_hold_na:
-                mask = isnull(d)
+                mask = isna(d)
                 d[mask] = None
 
             for col_loc, col in zip(b.mgr_locs, d):
@@ -845,7 +845,7 @@ class SQLTable(PandasObject):
             except KeyError:
                 pass  # this column not in results
 
-    def _get_notnull_col_dtype(self, col):
+    def _get_notna_col_dtype(self, col):
         """
         Infer datatype of the Series col.  In case the dtype of col is 'object'
         and it contains NA values, this infers the datatype of the not-NA
@@ -853,9 +853,9 @@ class SQLTable(PandasObject):
         """
         col_for_inference = col
         if col.dtype == 'object':
-            notnulldata = col[~isnull(col)]
-            if len(notnulldata):
-                col_for_inference = notnulldata
+            notnadata = col[~isna(col)]
+            if len(notnadata):
+                col_for_inference = notnadata
 
         return lib.infer_dtype(col_for_inference)
 
@@ -865,7 +865,7 @@ class SQLTable(PandasObject):
         if col.name in dtype:
             return self.dtype[col.name]
 
-        col_type = self._get_notnull_col_dtype(col)
+        col_type = self._get_notna_col_dtype(col)
 
         from sqlalchemy.types import (BigInteger, Integer, Float,
                                       Text, Boolean,
@@ -1345,7 +1345,7 @@ class SQLiteTable(SQLTable):
         if col.name in dtype:
             return dtype[col.name]
 
-        col_type = self._get_notnull_col_dtype(col)
+        col_type = self._get_notna_col_dtype(col)
         if col_type == 'timedelta64':
             warnings.warn("the 'timedelta' type is not supported, and will be "
                           "written as integer values (ns frequency) to the "
diff --git a/pandas/io/stata.py b/pandas/io/stata.py
index 30991d8a2..253ed03c2 100644
--- a/pandas/io/stata.py
+++ b/pandas/io/stata.py
@@ -24,7 +24,7 @@ from pandas.core.categorical import Categorical
 from pandas.core.frame import DataFrame
 from pandas.core.series import Series
 import datetime
-from pandas import compat, to_timedelta, to_datetime, isnull, DatetimeIndex
+from pandas import compat, to_timedelta, to_datetime, isna, DatetimeIndex
 from pandas.compat import lrange, lmap, lzip, text_type, string_types, range, \
     zip, BytesIO
 from pandas.util._decorators import Appender
@@ -402,7 +402,7 @@ def _datetime_to_stata_elapsed_vec(dates, fmt):
 
         return DataFrame(d, index=index)
 
-    bad_loc = isnull(dates)
+    bad_loc = isna(dates)
     index = dates.index
     if bad_loc.any():
         dates = Series(dates)
diff --git a/pandas/plotting/_core.py b/pandas/plotting/_core.py
index de96d17da..b8d7cebe8 100644
--- a/pandas/plotting/_core.py
+++ b/pandas/plotting/_core.py
@@ -11,14 +11,14 @@ import numpy as np
 
 from pandas.util._decorators import cache_readonly
 from pandas.core.base import PandasObject
-from pandas.core.dtypes.missing import notnull, remove_na_arraylike
+from pandas.core.dtypes.missing import isna, notna, remove_na_arraylike
 from pandas.core.dtypes.common import (
     is_list_like,
     is_integer,
     is_number,
     is_hashable,
     is_iterator)
-from pandas.core.common import AbstractMethodError, isnull, _try_sort
+from pandas.core.common import AbstractMethodError, _try_sort
 from pandas.core.generic import _shared_docs, _shared_doc_kwargs
 from pandas.core.index import Index, MultiIndex
 from pandas.core.series import Series
@@ -554,7 +554,7 @@ class MPLPlot(object):
                 """
                 x = index._mpl_repr()
             elif is_datetype:
-                self.data = self.data[notnull(self.data.index)]
+                self.data = self.data[notna(self.data.index)]
                 self.data = self.data.sort_index()
                 x = self.data.index._mpl_repr()
             else:
@@ -567,7 +567,7 @@ class MPLPlot(object):
 
     @classmethod
     def _plot(cls, ax, x, y, style=None, is_errorbar=False, **kwds):
-        mask = isnull(y)
+        mask = isna(y)
         if mask.any():
             y = np.ma.array(y)
             y = np.ma.masked_where(mask, y)
@@ -1290,7 +1290,7 @@ class HistPlot(LinePlot):
             # create common bin edge
             values = (self.data._convert(datetime=True)._get_numeric_data())
             values = np.ravel(values)
-            values = values[~isnull(values)]
+            values = values[~isna(values)]
 
             hist, self.bins = np.histogram(
                 values, bins=self.bins,
@@ -1305,7 +1305,7 @@ class HistPlot(LinePlot):
               stacking_id=None, **kwds):
         if column_num == 0:
             cls._initialize_stacker(ax, stacking_id, len(bins) - 1)
-        y = y[~isnull(y)]
+        y = y[~isna(y)]
 
         base = np.zeros(len(bins) - 1)
         bottom = bottom + \
diff --git a/pandas/plotting/_misc.py b/pandas/plotting/_misc.py
index 20ada033c..db2211fb5 100644
--- a/pandas/plotting/_misc.py
+++ b/pandas/plotting/_misc.py
@@ -5,7 +5,7 @@ from __future__ import division
 import numpy as np
 
 from pandas.util._decorators import deprecate_kwarg
-from pandas.core.dtypes.missing import notnull
+from pandas.core.dtypes.missing import notna
 from pandas.compat import range, lrange, lmap, zip
 from pandas.io.formats.printing import pprint_thing
 
@@ -62,7 +62,7 @@ def scatter_matrix(frame, alpha=0.5, figsize=None, ax=None, grid=False,
     # no gaps between subplots
     fig.subplots_adjust(wspace=0, hspace=0)
 
-    mask = notnull(df)
+    mask = notna(df)
 
     marker = _get_marker_compat(marker)
 
diff --git a/pandas/tests/api/test_api.py b/pandas/tests/api/test_api.py
index b1652cf6e..433ed7e51 100644
--- a/pandas/tests/api/test_api.py
+++ b/pandas/tests/api/test_api.py
@@ -64,8 +64,8 @@ class TestPDApi(Base):
     funcs = ['bdate_range', 'concat', 'crosstab', 'cut',
              'date_range', 'interval_range', 'eval',
              'factorize', 'get_dummies',
-             'infer_freq', 'isnull', 'lreshape',
-             'melt', 'notnull', 'offsets',
+             'infer_freq', 'isna', 'isnull', 'lreshape',
+             'melt', 'notna', 'notnull', 'offsets',
              'merge', 'merge_ordered', 'merge_asof',
              'period_range',
              'pivot', 'pivot_table', 'qcut',
@@ -88,6 +88,9 @@ class TestPDApi(Base):
     funcs_to = ['to_datetime', 'to_msgpack',
                 'to_numeric', 'to_pickle', 'to_timedelta']
 
+    # top-level to deprecate in the future
+    deprecated_funcs_in_future = []
+
     # these are already deprecated; awaiting removal
     deprecated_funcs = ['ewma', 'ewmcorr', 'ewmcov', 'ewmstd', 'ewmvar',
                         'ewmvol', 'expanding_apply', 'expanding_corr',
@@ -113,6 +116,7 @@ class TestPDApi(Base):
                    self.deprecated_classes_in_future +
                    self.funcs + self.funcs_option +
                    self.funcs_read + self.funcs_to +
+                   self.deprecated_funcs_in_future +
                    self.deprecated_funcs,
                    self.ignored)
 
diff --git a/pandas/tests/dtypes/test_inference.py b/pandas/tests/dtypes/test_inference.py
index ec5fe45d7..d26ea047b 100644
--- a/pandas/tests/dtypes/test_inference.py
+++ b/pandas/tests/dtypes/test_inference.py
@@ -18,7 +18,7 @@ import pandas as pd
 from pandas._libs import tslib, lib
 from pandas import (Series, Index, DataFrame, Timedelta,
                     DatetimeIndex, TimedeltaIndex, Timestamp,
-                    Panel, Period, Categorical)
+                    Panel, Period, Categorical, isna)
 from pandas.compat import u, PY2, PY3, StringIO, lrange
 from pandas.core.dtypes import inference
 from pandas.core.dtypes.common import (
@@ -36,7 +36,6 @@ from pandas.core.dtypes.common import (
     is_scipy_sparse,
     _ensure_int32,
     _ensure_categorical)
-from pandas.core.dtypes.missing import isnull
 from pandas.util import testing as tm
 
 
@@ -1014,7 +1013,7 @@ def test_nan_to_nat_conversions():
 
     s = df['B'].copy()
     s._data = s._data.setitem(indexer=tuple([slice(8, 9)]), value=np.nan)
-    assert (isnull(s[8]))
+    assert (isna(s[8]))
 
     # numpy < 1.7.0 is wrong
     from distutils.version import LooseVersion
diff --git a/pandas/tests/dtypes/test_missing.py b/pandas/tests/dtypes/test_missing.py
index ea4f5da04..d3c9ca51a 100644
--- a/pandas/tests/dtypes/test_missing.py
+++ b/pandas/tests/dtypes/test_missing.py
@@ -15,151 +15,153 @@ from pandas import (NaT, Float64Index, Series,
 from pandas.core.dtypes.common import is_scalar
 from pandas.core.dtypes.dtypes import DatetimeTZDtype
 from pandas.core.dtypes.missing import (
-    array_equivalent, isnull, notnull,
+    array_equivalent, isna, notna, isnull, notnull,
     na_value_for_dtype)
 
 
-def test_notnull():
-    assert notnull(1.)
-    assert not notnull(None)
-    assert not notnull(np.NaN)
+@pytest.mark.parametrize('notna_f', [notna, notnull])
+def test_notna_notnull(notna_f):
+    assert notna_f(1.)
+    assert not notna_f(None)
+    assert not notna_f(np.NaN)
 
-    with cf.option_context("mode.use_inf_as_null", False):
-        assert notnull(np.inf)
-        assert notnull(-np.inf)
+    with cf.option_context("mode.use_inf_as_na", False):
+        assert notna_f(np.inf)
+        assert notna_f(-np.inf)
 
         arr = np.array([1.5, np.inf, 3.5, -np.inf])
-        result = notnull(arr)
+        result = notna_f(arr)
         assert result.all()
 
-    with cf.option_context("mode.use_inf_as_null", True):
-        assert not notnull(np.inf)
-        assert not notnull(-np.inf)
+    with cf.option_context("mode.use_inf_as_na", True):
+        assert not notna_f(np.inf)
+        assert not notna_f(-np.inf)
 
         arr = np.array([1.5, np.inf, 3.5, -np.inf])
-        result = notnull(arr)
+        result = notna_f(arr)
         assert result.sum() == 2
 
-    with cf.option_context("mode.use_inf_as_null", False):
+    with cf.option_context("mode.use_inf_as_na", False):
         for s in [tm.makeFloatSeries(), tm.makeStringSeries(),
                   tm.makeObjectSeries(), tm.makeTimeSeries(),
                   tm.makePeriodSeries()]:
-            assert (isinstance(isnull(s), Series))
+            assert (isinstance(notna_f(s), Series))
 
 
-class TestIsNull(object):
+class TestIsNA(object):
 
     def test_0d_array(self):
-        assert isnull(np.array(np.nan))
-        assert not isnull(np.array(0.0))
-        assert not isnull(np.array(0))
+        assert isna(np.array(np.nan))
+        assert not isna(np.array(0.0))
+        assert not isna(np.array(0))
         # test object dtype
-        assert isnull(np.array(np.nan, dtype=object))
-        assert not isnull(np.array(0.0, dtype=object))
-        assert not isnull(np.array(0, dtype=object))
+        assert isna(np.array(np.nan, dtype=object))
+        assert not isna(np.array(0.0, dtype=object))
+        assert not isna(np.array(0, dtype=object))
 
     def test_empty_object(self):
 
         for shape in [(4, 0), (4,)]:
             arr = np.empty(shape=shape, dtype=object)
-            result = isnull(arr)
+            result = isna(arr)
             expected = np.ones(shape=shape, dtype=bool)
             tm.assert_numpy_array_equal(result, expected)
 
-    def test_isnull(self):
-        assert not isnull(1.)
-        assert isnull(None)
-        assert isnull(np.NaN)
+    @pytest.mark.parametrize('isna_f', [isna, isnull])
+    def test_isna_isnull(self, isna_f):
+        assert not isna_f(1.)
+        assert isna_f(None)
+        assert isna_f(np.NaN)
         assert float('nan')
-        assert not isnull(np.inf)
-        assert not isnull(-np.inf)
+        assert not isna_f(np.inf)
+        assert not isna_f(-np.inf)
 
         # series
         for s in [tm.makeFloatSeries(), tm.makeStringSeries(),
                   tm.makeObjectSeries(), tm.makeTimeSeries(),
                   tm.makePeriodSeries()]:
-            assert isinstance(isnull(s), Series)
+            assert isinstance(isna_f(s), Series)
 
         # frame
         for df in [tm.makeTimeDataFrame(), tm.makePeriodFrame(),
                    tm.makeMixedDataFrame()]:
-            result = isnull(df)
-            expected = df.apply(isnull)
+            result = isna_f(df)
+            expected = df.apply(isna_f)
             tm.assert_frame_equal(result, expected)
 
         # panel
         with catch_warnings(record=True):
             for p in [tm.makePanel(), tm.makePeriodPanel(),
                       tm.add_nans(tm.makePanel())]:
-                result = isnull(p)
-                expected = p.apply(isnull)
+                result = isna_f(p)
+                expected = p.apply(isna_f)
                 tm.assert_panel_equal(result, expected)
 
         # panel 4d
         with catch_warnings(record=True):
             for p in [tm.makePanel4D(), tm.add_nans_panel4d(tm.makePanel4D())]:
-                result = isnull(p)
-                expected = p.apply(isnull)
+                result = isna_f(p)
+                expected = p.apply(isna_f)
                 tm.assert_panel4d_equal(result, expected)
 
-    def test_isnull_lists(self):
-        result = isnull([[False]])
+    def test_isna_lists(self):
+        result = isna([[False]])
         exp = np.array([[False]])
         tm.assert_numpy_array_equal(result, exp)
 
-        result = isnull([[1], [2]])
+        result = isna([[1], [2]])
         exp = np.array([[False], [False]])
         tm.assert_numpy_array_equal(result, exp)
 
         # list of strings / unicode
-        result = isnull(['foo', 'bar'])
+        result = isna(['foo', 'bar'])
         exp = np.array([False, False])
         tm.assert_numpy_array_equal(result, exp)
 
-        result = isnull([u('foo'), u('bar')])
+        result = isna([u('foo'), u('bar')])
         exp = np.array([False, False])
         tm.assert_numpy_array_equal(result, exp)
 
-    def test_isnull_nat(self):
-        result = isnull([NaT])
+    def test_isna_nat(self):
+        result = isna([NaT])
         exp = np.array([True])
         tm.assert_numpy_array_equal(result, exp)
 
-        result = isnull(np.array([NaT], dtype=object))
+        result = isna(np.array([NaT], dtype=object))
         exp = np.array([True])
         tm.assert_numpy_array_equal(result, exp)
 
-    def test_isnull_numpy_nat(self):
+    def test_isna_numpy_nat(self):
         arr = np.array([NaT, np.datetime64('NaT'), np.timedelta64('NaT'),
                         np.datetime64('NaT', 's')])
-        result = isnull(arr)
+        result = isna(arr)
         expected = np.array([True] * 4)
         tm.assert_numpy_array_equal(result, expected)
 
-    def test_isnull_datetime(self):
-        assert not isnull(datetime.now())
-        assert notnull(datetime.now())
+    def test_isna_datetime(self):
+        assert not isna(datetime.now())
+        assert notna(datetime.now())
 
         idx = date_range('1/1/1990', periods=20)
         exp = np.ones(len(idx), dtype=bool)
-        tm.assert_numpy_array_equal(notnull(idx), exp)
+        tm.assert_numpy_array_equal(notna(idx), exp)
 
         idx = np.asarray(idx)
         idx[0] = iNaT
         idx = DatetimeIndex(idx)
-        mask = isnull(idx)
+        mask = isna(idx)
         assert mask[0]
         exp = np.array([True] + [False] * (len(idx) - 1), dtype=bool)
         tm.assert_numpy_array_equal(mask, exp)
 
         # GH 9129
         pidx = idx.to_period(freq='M')
-        mask = isnull(pidx)
+        mask = isna(pidx)
         assert mask[0]
         exp = np.array([True] + [False] * (len(idx) - 1), dtype=bool)
         tm.assert_numpy_array_equal(mask, exp)
 
-        mask = isnull(pidx[1:])
+        mask = isna(pidx[1:])
         exp = np.zeros(len(mask), dtype=bool)
         tm.assert_numpy_array_equal(mask, exp)
 
@@ -174,7 +176,7 @@ class TestIsNull(object):
          (np.array([1, 1 + 0j, np.nan, 3]).astype(object),
           np.array([False, False, True, False]))])
     def test_complex(self, value, expected):
-        result = isnull(value)
+        result = isna(value)
         if is_scalar(result):
             assert result is expected
         else:
@@ -183,10 +185,10 @@ class TestIsNull(object):
     def test_datetime_other_units(self):
         idx = pd.DatetimeIndex(['2011-01-01', 'NaT', '2011-01-02'])
         exp = np.array([False, True, False])
-        tm.assert_numpy_array_equal(isnull(idx), exp)
-        tm.assert_numpy_array_equal(notnull(idx), ~exp)
-        tm.assert_numpy_array_equal(isnull(idx.values), exp)
-        tm.assert_numpy_array_equal(notnull(idx.values), ~exp)
+        tm.assert_numpy_array_equal(isna(idx), exp)
+        tm.assert_numpy_array_equal(notna(idx), ~exp)
+        tm.assert_numpy_array_equal(isna(idx.values), exp)
+        tm.assert_numpy_array_equal(notna(idx.values), ~exp)
 
         for dtype in ['datetime64[D]', 'datetime64[h]', 'datetime64[m]',
                       'datetime64[s]', 'datetime64[ms]', 'datetime64[us]',
@@ -194,24 +196,24 @@ class TestIsNull(object):
             values = idx.values.astype(dtype)
 
             exp = np.array([False, True, False])
-            tm.assert_numpy_array_equal(isnull(values), exp)
-            tm.assert_numpy_array_equal(notnull(values), ~exp)
+            tm.assert_numpy_array_equal(isna(values), exp)
+            tm.assert_numpy_array_equal(notna(values), ~exp)
 
             exp = pd.Series([False, True, False])
             s = pd.Series(values)
-            tm.assert_series_equal(isnull(s), exp)
-            tm.assert_series_equal(notnull(s), ~exp)
+            tm.assert_series_equal(isna(s), exp)
+            tm.assert_series_equal(notna(s), ~exp)
             s = pd.Series(values, dtype=object)
-            tm.assert_series_equal(isnull(s), exp)
-            tm.assert_series_equal(notnull(s), ~exp)
+            tm.assert_series_equal(isna(s), exp)
+            tm.assert_series_equal(notna(s), ~exp)
 
     def test_timedelta_other_units(self):
         idx = pd.TimedeltaIndex(['1 days', 'NaT', '2 days'])
         exp = np.array([False, True, False])
-        tm.assert_numpy_array_equal(isnull(idx), exp)
-        tm.assert_numpy_array_equal(notnull(idx), ~exp)
-        tm.assert_numpy_array_equal(isnull(idx.values), exp)
-        tm.assert_numpy_array_equal(notnull(idx.values), ~exp)
+        tm.assert_numpy_array_equal(isna(idx), exp)
+        tm.assert_numpy_array_equal(notna(idx), ~exp)
+        tm.assert_numpy_array_equal(isna(idx.values), exp)
+        tm.assert_numpy_array_equal(notna(idx.values), ~exp)
 
         for dtype in ['timedelta64[D]', 'timedelta64[h]', 'timedelta64[m]',
                       'timedelta64[s]', 'timedelta64[ms]', 'timedelta64[us]',
@@ -219,30 +221,30 @@ class TestIsNull(object):
             values = idx.values.astype(dtype)
 
             exp = np.array([False, True, False])
-            tm.assert_numpy_array_equal(isnull(values), exp)
-            tm.assert_numpy_array_equal(notnull(values), ~exp)
+            tm.assert_numpy_array_equal(isna(values), exp)
+            tm.assert_numpy_array_equal(notna(values), ~exp)
 
             exp = pd.Series([False, True, False])
             s = pd.Series(values)
-            tm.assert_series_equal(isnull(s), exp)
-            tm.assert_series_equal(notnull(s), ~exp)
+            tm.assert_series_equal(isna(s), exp)
+            tm.assert_series_equal(notna(s), ~exp)
             s = pd.Series(values, dtype=object)
-            tm.assert_series_equal(isnull(s), exp)
-            tm.assert_series_equal(notnull(s), ~exp)
+            tm.assert_series_equal(isna(s), exp)
+            tm.assert_series_equal(notna(s), ~exp)
 
     def test_period(self):
         idx = pd.PeriodIndex(['2011-01', 'NaT', '2012-01'], freq='M')
         exp = np.array([False, True, False])
-        tm.assert_numpy_array_equal(isnull(idx), exp)
-        tm.assert_numpy_array_equal(notnull(idx), ~exp)
+        tm.assert_numpy_array_equal(isna(idx), exp)
+        tm.assert_numpy_array_equal(notna(idx), ~exp)
 
         exp = pd.Series([False, True, False])
         s = pd.Series(idx)
-        tm.assert_series_equal(isnull(s), exp)
-        tm.assert_series_equal(notnull(s), ~exp)
+        tm.assert_series_equal(isna(s), exp)
+        tm.assert_series_equal(notna(s), ~exp)
         s = pd.Series(idx, dtype=object)
-        tm.assert_series_equal(isnull(s), exp)
-        tm.assert_series_equal(notnull(s), ~exp)
+        tm.assert_series_equal(isna(s), exp)
+        tm.assert_series_equal(notna(s), ~exp)
 
 
 def test_array_equivalent():
diff --git a/pandas/tests/frame/test_analytics.py b/pandas/tests/frame/test_analytics.py
index da1c68005..484a09f11 100644
--- a/pandas/tests/frame/test_analytics.py
+++ b/pandas/tests/frame/test_analytics.py
@@ -13,7 +13,7 @@ from numpy.random import randn
 import numpy as np
 
 from pandas.compat import lrange, product
-from pandas import (compat, isnull, notnull, DataFrame, Series,
+from pandas import (compat, isna, notna, DataFrame, Series,
                     MultiIndex, date_range, Timestamp)
 import pandas as pd
 import pandas.core.nanops as nanops
@@ -81,11 +81,11 @@ class TestDataFrameAnalytics(TestData):
                             'C': [np.nan, np.nan, np.nan, np.nan,
                                   np.nan, np.nan]})
             rs = df.corr(meth)
-            assert isnull(rs.loc['A', 'B'])
-            assert isnull(rs.loc['B', 'A'])
+            assert isna(rs.loc['A', 'B'])
+            assert isna(rs.loc['B', 'A'])
             assert rs.loc['A', 'A'] == 1
             assert rs.loc['B', 'B'] == 1
-            assert isnull(rs.loc['C', 'C'])
+            assert isna(rs.loc['C', 'C'])
 
     def test_corr_constant(self):
         tm._skip_if_no_scipy()
@@ -96,7 +96,7 @@ class TestDataFrameAnalytics(TestData):
             df = DataFrame({'A': [1, 1, 1, np.nan, np.nan, np.nan],
                             'B': [np.nan, np.nan, np.nan, 1, 1, 1]})
             rs = df.corr(meth)
-            assert isnull(rs.values).all()
+            assert isna(rs.values).all()
 
     def test_corr_int(self):
         # dtypes other than float64 #1761
@@ -136,7 +136,7 @@ class TestDataFrameAnalytics(TestData):
         tm.assert_frame_equal(expected, result)
 
         result = self.frame.cov(min_periods=len(self.frame) + 1)
-        assert isnull(result.values).all()
+        assert isna(result.values).all()
 
         # with NAs
         frame = self.frame.copy()
@@ -389,7 +389,7 @@ class TestDataFrameAnalytics(TestData):
         tm.assert_series_equal(test, df.T.sum(axis=1))
 
     def test_count(self):
-        f = lambda s: notnull(s).sum()
+        f = lambda s: notna(s).sum()
         self._check_stat_op('count', f,
                             has_skipna=False,
                             has_numeric_only=True,
@@ -477,7 +477,7 @@ class TestDataFrameAnalytics(TestData):
 
     def test_median(self):
         def wrapper(x):
-            if isnull(x).any():
+            if isna(x).any():
                 return np.nan
             return np.median(x)
 
@@ -974,7 +974,7 @@ class TestDataFrameAnalytics(TestData):
 
     def test_median_corner(self):
         def wrapper(x):
-            if isnull(x).any():
+            if isna(x).any():
                 return np.nan
             return np.median(x)
 
@@ -998,7 +998,7 @@ class TestDataFrameAnalytics(TestData):
 
     def test_sum_bools(self):
         df = DataFrame(index=lrange(1), columns=lrange(10))
-        bools = isnull(df)
+        bools = isna(df)
         assert bools.sum(axis=1)[0] == 10
 
     # Index of max / min
diff --git a/pandas/tests/frame/test_apply.py b/pandas/tests/frame/test_apply.py
index a6f39cabb..ab2e810d7 100644
--- a/pandas/tests/frame/test_apply.py
+++ b/pandas/tests/frame/test_apply.py
@@ -9,7 +9,7 @@ from datetime import datetime
 import warnings
 import numpy as np
 
-from pandas import (notnull, DataFrame, Series, MultiIndex, date_range,
+from pandas import (notna, DataFrame, Series, MultiIndex, date_range,
                     Timestamp, compat)
 import pandas as pd
 from pandas.core.dtypes.dtypes import CategoricalDtype
@@ -278,7 +278,7 @@ class TestDataFrameApply(TestData):
             return row
 
         def transform2(row):
-            if (notnull(row['C']) and row['C'].startswith('shin') and
+            if (notna(row['C']) and row['C'].startswith('shin') and
                     row['A'] == 'foo'):
                 row['D'] = 7
             return row
diff --git a/pandas/tests/frame/test_asof.py b/pandas/tests/frame/test_asof.py
index d4e3d5419..fea6a5370 100644
--- a/pandas/tests/frame/test_asof.py
+++ b/pandas/tests/frame/test_asof.py
@@ -23,13 +23,13 @@ class TestFrameAsof(TestData):
                            freq='25s')
 
         result = df.asof(dates)
-        assert result.notnull().all(1).all()
+        assert result.notna().all(1).all()
         lb = df.index[14]
         ub = df.index[30]
 
         dates = list(dates)
         result = df.asof(dates)
-        assert result.notnull().all(1).all()
+        assert result.notna().all(1).all()
 
         mask = (result.index >= lb) & (result.index < ub)
         rs = result[mask]
diff --git a/pandas/tests/frame/test_axis_select_reindex.py b/pandas/tests/frame/test_axis_select_reindex.py
index 87d942101..e76869bf6 100644
--- a/pandas/tests/frame/test_axis_select_reindex.py
+++ b/pandas/tests/frame/test_axis_select_reindex.py
@@ -11,7 +11,7 @@ import numpy as np
 
 from pandas.compat import lrange, lzip, u
 from pandas import (compat, DataFrame, Series, Index, MultiIndex,
-                    date_range, isnull)
+                    date_range, isna)
 import pandas as pd
 
 from pandas.util.testing import assert_frame_equal
@@ -852,11 +852,11 @@ class TestDataFrameSelectReindex(TestData):
 
         reindexed = frame.reindex(np.arange(10))
         assert reindexed.values.dtype == np.object_
-        assert isnull(reindexed[0][1])
+        assert isna(reindexed[0][1])
 
         reindexed = frame.reindex(columns=lrange(3))
         assert reindexed.values.dtype == np.object_
-        assert isnull(reindexed[1]).all()
+        assert isna(reindexed[1]).all()
 
     def test_reindex_objects(self):
         reindexed = self.mixed_frame.reindex(columns=['foo', 'A', 'B'])
diff --git a/pandas/tests/frame/test_block_internals.py b/pandas/tests/frame/test_block_internals.py
index f66070fd6..afa3c4f25 100644
--- a/pandas/tests/frame/test_block_internals.py
+++ b/pandas/tests/frame/test_block_internals.py
@@ -533,7 +533,7 @@ starting,ending,measure
             repr(Y)
             result = Y.sum()  # noqa
             exp = Y['g'].sum()  # noqa
-            assert pd.isnull(Y['g']['c'])
+            assert pd.isna(Y['g']['c'])
 
     def test_get_X_columns(self):
         # numeric and object columns
@@ -566,6 +566,6 @@ starting,ending,measure
 
         myid = 100
 
-        first = len(df.loc[pd.isnull(df[myid]), [myid]])
-        second = len(df.loc[pd.isnull(df[myid]), [myid]])
+        first = len(df.loc[pd.isna(df[myid]), [myid]])
+        second = len(df.loc[pd.isna(df[myid]), [myid]])
         assert first == second == 0
diff --git a/pandas/tests/frame/test_constructors.py b/pandas/tests/frame/test_constructors.py
index 97cf3ce8a..d942330ec 100644
--- a/pandas/tests/frame/test_constructors.py
+++ b/pandas/tests/frame/test_constructors.py
@@ -17,7 +17,7 @@ from pandas.core.dtypes.common import is_integer_dtype
 from pandas.compat import (lmap, long, zip, range, lrange, lzip,
                            OrderedDict, is_platform_little_endian)
 from pandas import compat
-from pandas import (DataFrame, Index, Series, isnull,
+from pandas import (DataFrame, Index, Series, isna,
                     MultiIndex, Timedelta, Timestamp,
                     date_range)
 import pandas as pd
@@ -224,7 +224,7 @@ class TestDataFrameConstructors(TestData):
 
         assert len(frame) == len(self.ts2)
         assert 'col1' not in frame
-        assert isnull(frame['col3']).all()
+        assert isna(frame['col3']).all()
 
         # Corner cases
         assert len(DataFrame({})) == 0
@@ -279,12 +279,12 @@ class TestDataFrameConstructors(TestData):
         tuples = [(2, 3), (3, 3), (3, 3)]
         mi = MultiIndex.from_tuples(tuples)
         df = DataFrame(index=mi, columns=mi)
-        assert pd.isnull(df).values.ravel().all()
+        assert pd.isna(df).values.ravel().all()
 
         tuples = [(3, 3), (2, 3), (3, 3)]
         mi = MultiIndex.from_tuples(tuples)
         df = DataFrame(index=mi, columns=mi)
-        assert pd.isnull(df).values.ravel().all()
+        assert pd.isna(df).values.ravel().all()
 
     def test_constructor_error_msgs(self):
         msg = "Empty data passed with indices specified."
@@ -625,7 +625,7 @@ class TestDataFrameConstructors(TestData):
 
         assert len(frame.index) == 2
         assert len(frame.columns) == 3
-        assert isnull(frame).values.all()
+        assert isna(frame).values.all()
 
         # cast type
         frame = DataFrame(mat, columns=['A', 'B', 'C'],
@@ -1496,7 +1496,7 @@ class TestDataFrameConstructors(TestData):
                 df.iloc[:, i]
 
             # allow single nans to succeed
-            indexer = np.arange(len(df.columns))[isnull(df.columns)]
+            indexer = np.arange(len(df.columns))[isna(df.columns)]
 
             if len(indexer) == 1:
                 tm.assert_series_equal(df.iloc[:, indexer[0]],
@@ -1966,7 +1966,7 @@ class TestDataFrameConstructorWithDatetimeTZ(TestData):
 
         # it works!
         d = DataFrame({'A': 'foo', 'B': ts}, index=dr)
-        assert d['B'].isnull().all()
+        assert d['B'].isna().all()
 
     def test_frame_timeseries_to_records(self):
         index = date_range('1/1/2000', periods=10)
diff --git a/pandas/tests/frame/test_dtypes.py b/pandas/tests/frame/test_dtypes.py
index 065580d56..5941b2ab7 100644
--- a/pandas/tests/frame/test_dtypes.py
+++ b/pandas/tests/frame/test_dtypes.py
@@ -382,7 +382,7 @@ class TestDataFrameDataTypes(TestData):
         assert_series_equal(result, expected)
 
         # compat, GH 8722
-        with option_context('use_inf_as_null', True):
+        with option_context('use_inf_as_na', True):
             df = DataFrame([[1]])
             result = df.dtypes
             assert_series_equal(result, Series({0: np.dtype('int64')}))
diff --git a/pandas/tests/frame/test_indexing.py b/pandas/tests/frame/test_indexing.py
index ff79bedbc..dd2759cd3 100644
--- a/pandas/tests/frame/test_indexing.py
+++ b/pandas/tests/frame/test_indexing.py
@@ -15,7 +15,7 @@ import pytest
 import numpy as np
 
 import pandas.core.common as com
-from pandas import (DataFrame, Index, Series, notnull, isnull,
+from pandas import (DataFrame, Index, Series, notna, isna,
                     MultiIndex, DatetimeIndex, Timestamp,
                     date_range)
 import pandas as pd
@@ -312,7 +312,7 @@ class TestDataFrameIndexing(TestData):
         df = DataFrame(data=np.random.randn(100, 50))
         df = df.where(df > 0)  # create nans
         bools = df > 0
-        mask = isnull(df)
+        mask = isna(df)
         expected = bools.astype(float).mask(mask)
         result = bools.mask(mask)
         assert_frame_equal(result, expected)
@@ -395,7 +395,7 @@ class TestDataFrameIndexing(TestData):
 
         df = DataFrame(np.random.randn(8, 4))
         with catch_warnings(record=True):
-            assert isnull(df.ix[:, [-1]].values).all()
+            assert isna(df.ix[:, [-1]].values).all()
 
         # #1942
         a = DataFrame(randn(20, 2), index=[chr(x + 65) for x in range(20)])
@@ -487,7 +487,7 @@ class TestDataFrameIndexing(TestData):
         self.frame['E'] = s
 
         self.frame['E'][5:10] = nan
-        assert notnull(s[5:10]).all()
+        assert notna(s[5:10]).all()
 
     def test_setitem_boolean(self):
         df = self.frame.copy()
@@ -705,7 +705,7 @@ class TestDataFrameIndexing(TestData):
                            'c': ['111', '222', '333']})
 
         result = df.copy()
-        result.loc[result.b.isnull(), 'a'] = result.a
+        result.loc[result.b.isna(), 'a'] = result.a
         assert_frame_equal(result, df)
 
     def test_setitem_empty_frame_with_boolean(self):
@@ -795,7 +795,7 @@ class TestDataFrameIndexing(TestData):
         # this is OK
         result = df.iloc[:8:2]  # noqa
         df.iloc[:8:2] = np.nan
-        assert isnull(df.iloc[:8:2]).values.all()
+        assert isna(df.iloc[:8:2]).values.all()
 
     def test_getitem_setitem_integer_slice_keyerrors(self):
         df = DataFrame(np.random.randn(10, 5), index=lrange(0, 20, 2))
@@ -1020,7 +1020,7 @@ class TestDataFrameIndexing(TestData):
             assert (result.values == 5).all()
 
             self.mixed_frame.ix[5] = np.nan
-            assert isnull(self.mixed_frame.ix[5]).all()
+            assert isna(self.mixed_frame.ix[5]).all()
 
             self.mixed_frame.ix[5] = self.mixed_frame.ix[6]
             assert_series_equal(self.mixed_frame.ix[5], self.mixed_frame.ix[6],
@@ -1492,15 +1492,15 @@ class TestDataFrameIndexing(TestData):
 
         # set an allowable datetime64 type
         df.loc['b', 'timestamp'] = iNaT
-        assert isnull(df.loc['b', 'timestamp'])
+        assert isna(df.loc['b', 'timestamp'])
 
         # allow this syntax
         df.loc['c', 'timestamp'] = nan
-        assert isnull(df.loc['c', 'timestamp'])
+        assert isna(df.loc['c', 'timestamp'])
 
         # allow this syntax
         df.loc['d', :] = nan
-        assert not isnull(df.loc['c', :]).all()
+        assert not isna(df.loc['c', :]).all()
 
         # as of GH 3216 this will now work!
         # try to set with a list like item
@@ -1695,7 +1695,7 @@ class TestDataFrameIndexing(TestData):
         res = self.frame.copy()
         res3 = res.set_value('foobar', 'baz', 5)
         assert is_float_dtype(res3['baz'])
-        assert isnull(res3['baz'].drop(['foobar'])).all()
+        assert isna(res3['baz'].drop(['foobar'])).all()
         pytest.raises(ValueError, res3.set_value, 'foobar', 'baz', 'sam')
 
     def test_set_value_with_index_dtype_change(self):
@@ -1935,7 +1935,7 @@ class TestDataFrameIndexing(TestData):
         result = df.reindex(lrange(15))
         assert np.issubdtype(result['B'].dtype, np.dtype('M8[ns]'))
 
-        mask = com.isnull(result)['B']
+        mask = com.isna(result)['B']
         assert mask[-5:].all()
         assert not mask[:-5].any()
 
@@ -2590,7 +2590,7 @@ class TestDataFrameIndexing(TestData):
         # GH7506
         a = DataFrame({0: [1, 2], 1: [3, 4], 2: [5, 6]})
         b = DataFrame({0: [np.nan, 8], 1: [9, np.nan], 2: [np.nan, np.nan]})
-        do_not_replace = b.isnull() | (a > b)
+        do_not_replace = b.isna() | (a > b)
 
         expected = a.copy()
         expected[~do_not_replace] = b
@@ -2600,7 +2600,7 @@ class TestDataFrameIndexing(TestData):
 
         a = DataFrame({0: [4, 6], 1: [1, 0]})
         b = DataFrame({0: [np.nan, 3], 1: [3, np.nan]})
-        do_not_replace = b.isnull() | (a > b)
+        do_not_replace = b.isna() | (a > b)
 
         expected = a.copy()
         expected[~do_not_replace] = b
@@ -2633,10 +2633,10 @@ class TestDataFrameIndexing(TestData):
         # GH 7656
         df = DataFrame([{'A': 1, 'B': np.nan, 'C': 'Test'}, {
                        'A': np.nan, 'B': 'Test', 'C': np.nan}])
-        expected = df.where(~isnull(df), None)
+        expected = df.where(~isna(df), None)
         with tm.assert_raises_regex(TypeError, 'boolean setting '
                                     'on mixed-type'):
-            df.where(~isnull(df), None, inplace=True)
+            df.where(~isna(df), None, inplace=True)
 
     def test_where_align(self):
 
@@ -2650,10 +2650,10 @@ class TestDataFrameIndexing(TestData):
         # series
         df = create()
         expected = df.fillna(df.mean())
-        result = df.where(pd.notnull(df), df.mean(), axis='columns')
+        result = df.where(pd.notna(df), df.mean(), axis='columns')
         assert_frame_equal(result, expected)
 
-        df.where(pd.notnull(df), df.mean(), inplace=True, axis='columns')
+        df.where(pd.notna(df), df.mean(), inplace=True, axis='columns')
         assert_frame_equal(df, expected)
 
         df = create().fillna(0)
@@ -2666,7 +2666,7 @@ class TestDataFrameIndexing(TestData):
         # frame
         df = create()
         expected = df.fillna(1)
-        result = df.where(pd.notnull(df), DataFrame(
+        result = df.where(pd.notna(df), DataFrame(
             1, index=df.index, columns=df.columns))
         assert_frame_equal(result, expected)
 
@@ -2948,7 +2948,7 @@ class TestDataFrameIndexingDatetimeWithTZ(TestData):
         df2.iloc[1, 1] = pd.NaT
         df2.iloc[1, 2] = pd.NaT
         result = df2['B']
-        assert_series_equal(notnull(result), Series(
+        assert_series_equal(notna(result), Series(
             [True, False, True], name='B'))
         assert_series_equal(df2.dtypes, df.dtypes)
 
@@ -3000,7 +3000,7 @@ class TestDataFrameIndexingUInt64(TestData):
         df2.iloc[1, 1] = pd.NaT
         df2.iloc[1, 2] = pd.NaT
         result = df2['B']
-        assert_series_equal(notnull(result), Series(
+        assert_series_equal(notna(result), Series(
             [True, False, True], name='B'))
         assert_series_equal(df2.dtypes, Series([np.dtype('uint64'),
                                                 np.dtype('O'), np.dtype('O')],
diff --git a/pandas/tests/frame/test_operators.py b/pandas/tests/frame/test_operators.py
index 438d7481e..5052bef24 100644
--- a/pandas/tests/frame/test_operators.py
+++ b/pandas/tests/frame/test_operators.py
@@ -137,12 +137,12 @@ class TestDataFrameOperators(TestData):
             filled = df.fillna(np.nan)
             result = op(df, 3)
             expected = op(filled, 3).astype(object)
-            expected[com.isnull(expected)] = None
+            expected[com.isna(expected)] = None
             assert_frame_equal(result, expected)
 
             result = op(df, df)
             expected = op(filled, filled).astype(object)
-            expected[com.isnull(expected)] = None
+            expected[com.isna(expected)] = None
             assert_frame_equal(result, expected)
 
             result = op(df, df.fillna(7))
@@ -1045,8 +1045,8 @@ class TestDataFrameOperators(TestData):
 
         combined = df1.combine(df2, np.add)
         combined2 = df2.combine(df1, np.add)
-        assert combined['D'].isnull().all()
-        assert combined2['D'].isnull().all()
+        assert combined['D'].isna().all()
+        assert combined2['D'].isna().all()
 
         chunk = combined.loc[combined.index[:-5], ['A', 'B', 'C']]
         chunk2 = combined2.loc[combined2.index[:-5], ['A', 'B', 'C']]
diff --git a/pandas/tests/frame/test_reshape.py b/pandas/tests/frame/test_reshape.py
index fdb0119d8..e2f362ebd 100644
--- a/pandas/tests/frame/test_reshape.py
+++ b/pandas/tests/frame/test_reshape.py
@@ -528,7 +528,7 @@ class TestDataFrameReshape(TestData):
 
         def verify(df):
             mk_list = lambda a: list(a) if isinstance(a, tuple) else [a]
-            rows, cols = df.notnull().values.nonzero()
+            rows, cols = df.notna().values.nonzero()
             for i, j in zip(rows, cols):
                 left = sorted(df.iloc[i, j].split('.'))
                 right = mk_list(df.index[i]) + mk_list(df.columns[j])
@@ -547,7 +547,7 @@ class TestDataFrameReshape(TestData):
             mi = df.set_index(list(idx))
             for lev in range(2):
                 udf = mi.unstack(level=lev)
-                assert udf.notnull().values.sum() == len(df)
+                assert udf.notna().values.sum() == len(df)
                 verify(udf['jolie'])
 
         df = DataFrame({'1st': ['d'] * 3 + [nan] * 5 + ['a'] * 2 +
@@ -565,7 +565,7 @@ class TestDataFrameReshape(TestData):
             mi = df.set_index(list(idx))
             for lev in range(3):
                 udf = mi.unstack(level=lev)
-                assert udf.notnull().values.sum() == 2 * len(df)
+                assert udf.notna().values.sum() == 2 * len(df)
                 for col in ['4th', '5th']:
                     verify(udf[col])
 
@@ -670,7 +670,7 @@ class TestDataFrameReshape(TestData):
         df.loc[1, '3rd'] = df.loc[4, '3rd'] = nan
 
         left = df.set_index(['1st', '2nd', '3rd']).unstack(['2nd', '3rd'])
-        assert left.notnull().values.sum() == 2 * len(df)
+        assert left.notna().values.sum() == 2 * len(df)
 
         for col in ['jim', 'joe']:
             for _, r in df.iterrows():
diff --git a/pandas/tests/frame/test_timeseries.py b/pandas/tests/frame/test_timeseries.py
index aaca8a60f..19fbf8542 100644
--- a/pandas/tests/frame/test_timeseries.py
+++ b/pandas/tests/frame/test_timeseries.py
@@ -281,7 +281,7 @@ class TestDataFrameTimeSeriesMethods(TestData):
             shifted.append(df)
 
         # sanity check the base case
-        nulls = shifted[0].isnull().sum()
+        nulls = shifted[0].isna().sum()
         assert_series_equal(nulls, Series(range(1, 6), dtype='int64'))
 
         # check all answers are the same
diff --git a/pandas/tests/groupby/test_bin_groupby.py b/pandas/tests/groupby/test_bin_groupby.py
index f527c732f..8b95455b5 100644
--- a/pandas/tests/groupby/test_bin_groupby.py
+++ b/pandas/tests/groupby/test_bin_groupby.py
@@ -6,7 +6,7 @@ from numpy import nan
 import numpy as np
 
 from pandas.core.dtypes.common import _ensure_int64
-from pandas import Index, isnull
+from pandas import Index, isna
 from pandas.util.testing import assert_almost_equal
 import pandas.util.testing as tm
 from pandas._libs import lib, groupby
@@ -97,7 +97,7 @@ def test_group_ohlc():
         func(out, counts, obj[:, None], labels)
 
         def _ohlc(group):
-            if isnull(group).all():
+            if isna(group).all():
                 return np.repeat(nan, 4)
             return [group[0], group.max(), group.min(), group[-1]]
 
diff --git a/pandas/tests/groupby/test_groupby.py b/pandas/tests/groupby/test_groupby.py
index 19124a33b..0dea1e844 100644
--- a/pandas/tests/groupby/test_groupby.py
+++ b/pandas/tests/groupby/test_groupby.py
@@ -2562,7 +2562,7 @@ class TestGroupBy(MixIn):
         inds = np.tile(lrange(10), 10)
 
         result = obj.groupby(inds).agg(Series.median)
-        assert result.isnull().all()
+        assert result.isna().all()
 
     def test_series_grouper_noncontig_index(self):
         index = Index(tm.rands_array(10, 100))
@@ -3540,7 +3540,7 @@ class TestGroupBy(MixIn):
         r = gb[['File']].max()
         e = gb['File'].max().to_frame()
         tm.assert_frame_equal(r, e)
-        assert not r['File'].isnull().any()
+        assert not r['File'].isna().any()
 
     def test_nlargest(self):
         a = Series([1, 3, 5, 7, 2, 9, 0, 4, 6, 10])
diff --git a/pandas/tests/groupby/test_nth.py b/pandas/tests/groupby/test_nth.py
index 47e6e7839..28392537b 100644
--- a/pandas/tests/groupby/test_nth.py
+++ b/pandas/tests/groupby/test_nth.py
@@ -1,6 +1,6 @@
 import numpy as np
 import pandas as pd
-from pandas import DataFrame, MultiIndex, Index, Series, isnull
+from pandas import DataFrame, MultiIndex, Index, Series, isna
 from pandas.compat import lrange
 from pandas.util.testing import assert_frame_equal, assert_series_equal
 
@@ -41,9 +41,9 @@ class TestNth(MixIn):
         grouped['B'].nth(0)
 
         self.df.loc[self.df['A'] == 'foo', 'B'] = np.nan
-        assert isnull(grouped['B'].first()['foo'])
-        assert isnull(grouped['B'].last()['foo'])
-        assert isnull(grouped['B'].nth(0)['foo'])
+        assert isna(grouped['B'].first()['foo'])
+        assert isna(grouped['B'].last()['foo'])
+        assert isna(grouped['B'].nth(0)['foo'])
 
         # v0.14.0 whatsnew
         df = DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=['A', 'B'])
diff --git a/pandas/tests/groupby/test_timegrouper.py b/pandas/tests/groupby/test_timegrouper.py
index 70b6b1e43..df0a93d78 100644
--- a/pandas/tests/groupby/test_timegrouper.py
+++ b/pandas/tests/groupby/test_timegrouper.py
@@ -599,7 +599,7 @@ class TestGroupBy(object):
              'td': [nan, td(days=1), td(days=2), td(days=3), nan]})
         df_test.dt = pd.to_datetime(df_test.dt)
         df_test['group'] = 'A'
-        df_ref = df_test[df_test.dt.notnull()]
+        df_ref = df_test[df_test.dt.notna()]
 
         grouped_test = df_test.groupby('group')
         grouped_ref = df_ref.groupby('group')
diff --git a/pandas/tests/indexes/common.py b/pandas/tests/indexes/common.py
index 1513a1c69..1fdc08d68 100644
--- a/pandas/tests/indexes/common.py
+++ b/pandas/tests/indexes/common.py
@@ -10,7 +10,7 @@ import numpy as np
 from pandas import (Series, Index, Float64Index, Int64Index, UInt64Index,
                     RangeIndex, MultiIndex, CategoricalIndex, DatetimeIndex,
                     TimedeltaIndex, PeriodIndex, IntervalIndex,
-                    notnull, isnull)
+                    notna, isna)
 from pandas.core.indexes.datetimelike import DatetimeIndexOpsMixin
 from pandas.core.dtypes.common import needs_i8_conversion
 from pandas._libs.tslib import iNaT
@@ -514,7 +514,7 @@ class Base(object):
 
     def test_where(self):
         i = self.create_index()
-        result = i.where(notnull(i))
+        result = i.where(notna(i))
         expected = i
         tm.assert_index_equal(result, expected)
 
@@ -884,7 +884,7 @@ class Base(object):
                 pass
             elif isinstance(index, MultiIndex):
                 idx = index.copy()
-                msg = "isnull is not defined for MultiIndex"
+                msg = "isna is not defined for MultiIndex"
                 with tm.assert_raises_regex(NotImplementedError, msg):
                     idx.fillna(idx[0])
             else:
@@ -924,23 +924,23 @@ class Base(object):
         for name, index in self.indices.items():
             if len(index) == 0:
                 tm.assert_numpy_array_equal(
-                    index.isnull(), np.array([], dtype=bool))
+                    index.isna(), np.array([], dtype=bool))
             elif isinstance(index, MultiIndex):
                 idx = index.copy()
-                msg = "isnull is not defined for MultiIndex"
+                msg = "isna is not defined for MultiIndex"
                 with tm.assert_raises_regex(NotImplementedError, msg):
-                    idx.isnull()
+                    idx.isna()
             else:
 
                 if not index.hasnans:
                     tm.assert_numpy_array_equal(
-                        index.isnull(), np.zeros(len(index), dtype=bool))
+                        index.isna(), np.zeros(len(index), dtype=bool))
                     tm.assert_numpy_array_equal(
-                        index.notnull(), np.ones(len(index), dtype=bool))
+                        index.notna(), np.ones(len(index), dtype=bool))
                 else:
-                    result = isnull(index)
-                    tm.assert_numpy_array_equal(index.isnull(), result)
-                    tm.assert_numpy_array_equal(index.notnull(), ~result)
+                    result = isna(index)
+                    tm.assert_numpy_array_equal(index.isna(), result)
+                    tm.assert_numpy_array_equal(index.notna(), ~result)
 
     def test_empty(self):
         # GH 15270
diff --git a/pandas/tests/indexes/datetimes/test_indexing.py b/pandas/tests/indexes/datetimes/test_indexing.py
index 4ef5cc549..9416b08f9 100644
--- a/pandas/tests/indexes/datetimes/test_indexing.py
+++ b/pandas/tests/indexes/datetimes/test_indexing.py
@@ -5,7 +5,7 @@ import numpy as np
 import pandas as pd
 import pandas.util.testing as tm
 import pandas.compat as compat
-from pandas import notnull, Index, DatetimeIndex, datetime, date_range
+from pandas import notna, Index, DatetimeIndex, datetime, date_range
 
 
 class TestDatetimeIndex(object):
@@ -16,29 +16,29 @@ class TestDatetimeIndex(object):
         i = pd.date_range('20130101', periods=3, tz='US/Eastern')
 
         for arr in [np.nan, pd.NaT]:
-            result = i.where(notnull(i), other=np.nan)
+            result = i.where(notna(i), other=np.nan)
             expected = i
             tm.assert_index_equal(result, expected)
 
         i2 = i.copy()
         i2 = Index([pd.NaT, pd.NaT] + i[2:].tolist())
-        result = i.where(notnull(i2), i2)
+        result = i.where(notna(i2), i2)
         tm.assert_index_equal(result, i2)
 
         i2 = i.copy()
         i2 = Index([pd.NaT, pd.NaT] + i[2:].tolist())
-        result = i.where(notnull(i2), i2.values)
+        result = i.where(notna(i2), i2.values)
         tm.assert_index_equal(result, i2)
 
     def test_where_tz(self):
         i = pd.date_range('20130101', periods=3, tz='US/Eastern')
-        result = i.where(notnull(i))
+        result = i.where(notna(i))
         expected = i
         tm.assert_index_equal(result, expected)
 
         i2 = i.copy()
         i2 = Index([pd.NaT, pd.NaT] + i[2:].tolist())
-        result = i.where(notnull(i2))
+        result = i.where(notna(i2))
         expected = i2
         tm.assert_index_equal(result, expected)
 
diff --git a/pandas/tests/indexes/datetimes/test_ops.py b/pandas/tests/indexes/datetimes/test_ops.py
index f33cdf880..86e65feec 100644
--- a/pandas/tests/indexes/datetimes/test_ops.py
+++ b/pandas/tests/indexes/datetimes/test_ops.py
@@ -116,13 +116,13 @@ class TestDatetimeIndexOps(Ops):
         for op in ['min', 'max']:
             # Return NaT
             obj = DatetimeIndex([])
-            assert pd.isnull(getattr(obj, op)())
+            assert pd.isna(getattr(obj, op)())
 
             obj = DatetimeIndex([pd.NaT])
-            assert pd.isnull(getattr(obj, op)())
+            assert pd.isna(getattr(obj, op)())
 
             obj = DatetimeIndex([pd.NaT, pd.NaT, pd.NaT])
-            assert pd.isnull(getattr(obj, op)())
+            assert pd.isna(getattr(obj, op)())
 
     def test_numpy_minmax(self):
         dr = pd.date_range(start='2016-01-15', end='2016-01-20')
diff --git a/pandas/tests/indexes/datetimes/test_tools.py b/pandas/tests/indexes/datetimes/test_tools.py
index a47db755b..7ff9c2b23 100644
--- a/pandas/tests/indexes/datetimes/test_tools.py
+++ b/pandas/tests/indexes/datetimes/test_tools.py
@@ -20,7 +20,7 @@ from pandas.compat.numpy import np_array_datetime64_compat
 from pandas.core.dtypes.common import is_datetime64_ns_dtype
 from pandas.util import testing as tm
 from pandas.util.testing import assert_series_equal, _skip_if_has_locale
-from pandas import (isnull, to_datetime, Timestamp, Series, DataFrame,
+from pandas import (isna, to_datetime, Timestamp, Series, DataFrame,
                     Index, DatetimeIndex, NaT, date_range, bdate_range,
                     compat)
 
@@ -683,7 +683,7 @@ class ToDatetimeMisc(object):
         assert result is NaT
 
         result = to_datetime(['', ''])
-        assert isnull(result).all()
+        assert isna(result).all()
 
         # ints
         result = Timestamp(0)
@@ -751,7 +751,7 @@ class ToDatetimeMisc(object):
 
         expected = np.empty(4, dtype='M8[ns]')
         for i, val in enumerate(strings):
-            if isnull(val):
+            if isna(val):
                 expected[i] = tslib.iNaT
             else:
                 expected[i] = parse_date(val)
@@ -787,7 +787,7 @@ class ToDatetimeMisc(object):
         expected = Series(np.empty(5, dtype='M8[ns]'), index=idx)
         for i in range(5):
             x = series[i]
-            if isnull(x):
+            if isna(x):
                 expected[i] = tslib.iNaT
             else:
                 expected[i] = to_datetime(x)
@@ -977,13 +977,13 @@ class TestDaysInMonth(object):
     # tests for issue #10154
 
     def test_day_not_in_month_coerce(self):
-        assert isnull(to_datetime('2015-02-29', errors='coerce'))
-        assert isnull(to_datetime('2015-02-29', format="%Y-%m-%d",
-                                  errors='coerce'))
-        assert isnull(to_datetime('2015-02-32', format="%Y-%m-%d",
-                                  errors='coerce'))
-        assert isnull(to_datetime('2015-04-31', format="%Y-%m-%d",
-                                  errors='coerce'))
+        assert isna(to_datetime('2015-02-29', errors='coerce'))
+        assert isna(to_datetime('2015-02-29', format="%Y-%m-%d",
+                                errors='coerce'))
+        assert isna(to_datetime('2015-02-32', format="%Y-%m-%d",
+                                errors='coerce'))
+        assert isna(to_datetime('2015-04-31', format="%Y-%m-%d",
+                                errors='coerce'))
 
     def test_day_not_in_month_raise(self):
         pytest.raises(ValueError, to_datetime, '2015-02-29',
diff --git a/pandas/tests/indexes/period/test_period.py b/pandas/tests/indexes/period/test_period.py
index 291ca317f..e24e2ad93 100644
--- a/pandas/tests/indexes/period/test_period.py
+++ b/pandas/tests/indexes/period/test_period.py
@@ -6,7 +6,7 @@ from datetime import timedelta
 
 import pandas as pd
 from pandas.util import testing as tm
-from pandas import (PeriodIndex, period_range, notnull, DatetimeIndex, NaT,
+from pandas import (PeriodIndex, period_range, notna, DatetimeIndex, NaT,
                     Index, Period, Int64Index, Series, DataFrame, date_range,
                     offsets, compat)
 
@@ -92,13 +92,13 @@ class TestPeriodIndex(DatetimeLike):
 
     def test_where(self):
         i = self.create_index()
-        result = i.where(notnull(i))
+        result = i.where(notna(i))
         expected = i
         tm.assert_index_equal(result, expected)
 
         i2 = pd.PeriodIndex([pd.NaT, pd.NaT] + i[2:].tolist(),
                             freq='D')
-        result = i.where(notnull(i2))
+        result = i.where(notna(i2))
         expected = i2
         tm.assert_index_equal(result, expected)
 
@@ -116,20 +116,20 @@ class TestPeriodIndex(DatetimeLike):
 
         i = self.create_index()
         for arr in [np.nan, pd.NaT]:
-            result = i.where(notnull(i), other=np.nan)
+            result = i.where(notna(i), other=np.nan)
             expected = i
             tm.assert_index_equal(result, expected)
 
         i2 = i.copy()
         i2 = pd.PeriodIndex([pd.NaT, pd.NaT] + i[2:].tolist(),
                             freq='D')
-        result = i.where(notnull(i2), i2)
+        result = i.where(notna(i2), i2)
         tm.assert_index_equal(result, i2)
 
         i2 = i.copy()
         i2 = pd.PeriodIndex([pd.NaT, pd.NaT] + i[2:].tolist(),
                             freq='D')
-        result = i.where(notnull(i2), i2.values)
+        result = i.where(notna(i2), i2.values)
         tm.assert_index_equal(result, i2)
 
     def test_get_indexer(self):
diff --git a/pandas/tests/indexes/test_base.py b/pandas/tests/indexes/test_base.py
index 842e8fea0..ef36e4a91 100644
--- a/pandas/tests/indexes/test_base.py
+++ b/pandas/tests/indexes/test_base.py
@@ -16,7 +16,7 @@ import numpy as np
 from pandas import (period_range, date_range, Series,
                     DataFrame, Float64Index, Int64Index,
                     CategoricalIndex, DatetimeIndex, TimedeltaIndex,
-                    PeriodIndex, isnull)
+                    PeriodIndex, isna)
 from pandas.core.index import _get_combined_index
 from pandas.util.testing import assert_almost_equal
 from pandas.compat.numpy import np_datetime64_compat
@@ -504,7 +504,7 @@ class TestIndex(Base):
     def test_asof(self):
         d = self.dateIndex[0]
         assert self.dateIndex.asof(d) == d
-        assert isnull(self.dateIndex.asof(d - timedelta(1)))
+        assert isna(self.dateIndex.asof(d - timedelta(1)))
 
         d = self.dateIndex[-1]
         assert self.dateIndex.asof(d + timedelta(1)) == d
diff --git a/pandas/tests/indexes/test_category.py b/pandas/tests/indexes/test_category.py
index e8d780e04..a3d72fdb8 100644
--- a/pandas/tests/indexes/test_category.py
+++ b/pandas/tests/indexes/test_category.py
@@ -10,7 +10,7 @@ from pandas.compat import range, PY3
 
 import numpy as np
 
-from pandas import Categorical, IntervalIndex, compat, notnull
+from pandas import Categorical, IntervalIndex, compat, notna
 from pandas.util.testing import assert_almost_equal
 import pandas.core.config as cf
 import pandas as pd
@@ -236,13 +236,13 @@ class TestCategoricalIndex(Base):
 
     def test_where(self):
         i = self.create_index()
-        result = i.where(notnull(i))
+        result = i.where(notna(i))
         expected = i
         tm.assert_index_equal(result, expected)
 
         i2 = pd.CategoricalIndex([np.nan, np.nan] + i[2:].tolist(),
                                  categories=i.categories)
-        result = i.where(notnull(i2))
+        result = i.where(notna(i2))
         expected = i2
         tm.assert_index_equal(result, expected)
 
diff --git a/pandas/tests/indexes/test_interval.py b/pandas/tests/indexes/test_interval.py
index 33745017f..fe86a2121 100644
--- a/pandas/tests/indexes/test_interval.py
+++ b/pandas/tests/indexes/test_interval.py
@@ -3,7 +3,7 @@ from __future__ import division
 import pytest
 import numpy as np
 
-from pandas import (Interval, IntervalIndex, Index, isnull,
+from pandas import (Interval, IntervalIndex, Index, isna,
                     interval_range, Timestamp, Timedelta,
                     compat)
 from pandas._libs.interval import IntervalTree
@@ -152,16 +152,16 @@ class TestIntervalIndex(Base):
     def test_with_nans(self):
         index = self.index
         assert not index.hasnans
-        tm.assert_numpy_array_equal(index.isnull(),
+        tm.assert_numpy_array_equal(index.isna(),
                                     np.array([False, False]))
-        tm.assert_numpy_array_equal(index.notnull(),
+        tm.assert_numpy_array_equal(index.notna(),
                                     np.array([True, True]))
 
         index = self.index_with_nan
         assert index.hasnans
-        tm.assert_numpy_array_equal(index.notnull(),
+        tm.assert_numpy_array_equal(index.notna(),
                                     np.array([True, False, True]))
-        tm.assert_numpy_array_equal(index.isnull(),
+        tm.assert_numpy_array_equal(index.isna(),
                                     np.array([False, True, False]))
 
     def test_copy(self):
@@ -228,7 +228,7 @@ class TestIntervalIndex(Base):
 
     def test_where(self):
         expected = self.index
-        result = self.index.where(self.index.notnull())
+        result = self.index.where(self.index.notna())
         tm.assert_index_equal(result, expected)
 
         idx = IntervalIndex.from_breaks([1, 2])
@@ -311,7 +311,7 @@ class TestIntervalIndex(Base):
                                       closed='right')
         assert i[0] == Interval(0.0, 1.0)
         assert i[1] == Interval(1.0, 2.0)
-        assert isnull(i[2])
+        assert isna(i[2])
 
         result = i[0:1]
         expected = IntervalIndex.from_arrays((0.,), (1.,), closed='right')
@@ -620,7 +620,7 @@ class TestIntervalIndex(Base):
         with pytest.raises(ValueError):
             IntervalIndex.from_arrays([np.nan, 0, 1], np.array([0, 1, 2]))
 
-        tm.assert_numpy_array_equal(isnull(idx),
+        tm.assert_numpy_array_equal(isna(idx),
                                     np.array([True, False, False]))
 
     def test_sort_values(self):
@@ -631,15 +631,15 @@ class TestIntervalIndex(Base):
 
         # nan
         idx = self.index_with_nan
-        mask = idx.isnull()
+        mask = idx.isna()
         tm.assert_numpy_array_equal(mask, np.array([False, True, False]))
 
         result = idx.sort_values()
-        mask = result.isnull()
+        mask = result.isna()
         tm.assert_numpy_array_equal(mask, np.array([False, False, True]))
 
         result = idx.sort_values(ascending=False)
-        mask = result.isnull()
+        mask = result.isna()
         tm.assert_numpy_array_equal(mask, np.array([True, False, False]))
 
     def test_datetime(self):
diff --git a/pandas/tests/indexes/test_multi.py b/pandas/tests/indexes/test_multi.py
index 719cd2f7e..da1b309f5 100644
--- a/pandas/tests/indexes/test_multi.py
+++ b/pandas/tests/indexes/test_multi.py
@@ -2366,12 +2366,12 @@ class TestMultiIndex(Base):
                                    names=['x', 'y'])
         assert x[1:].names == x.names
 
-    def test_isnull_behavior(self):
+    def test_isna_behavior(self):
         # should not segfault GH5123
         # NOTE: if MI representation changes, may make sense to allow
-        # isnull(MI)
+        # isna(MI)
         with pytest.raises(NotImplementedError):
-            pd.isnull(self.index)
+            pd.isna(self.index)
 
     def test_level_setting_resets_attributes(self):
         ind = MultiIndex.from_arrays([
@@ -2889,13 +2889,13 @@ class TestMultiIndex(Base):
                              labels=[[0], [0]],
                              names=[0, 1])
         idxm = idx0.join(idx1, how='outer')
-        assert pd.isnull(idx0.get_level_values(1)).all()
+        assert pd.isna(idx0.get_level_values(1)).all()
         # the following failed in 0.14.1
-        assert pd.isnull(idxm.get_level_values(1)[:-1]).all()
+        assert pd.isna(idxm.get_level_values(1)[:-1]).all()
 
         df0 = pd.DataFrame([[1, 2]], index=idx0)
         df1 = pd.DataFrame([[3, 4]], index=idx1)
         dfm = df0 - df1
-        assert pd.isnull(df0.index.get_level_values(1)).all()
+        assert pd.isna(df0.index.get_level_values(1)).all()
         # the following failed in 0.14.1
-        assert pd.isnull(dfm.index.get_level_values(1)[:-1]).all()
+        assert pd.isna(dfm.index.get_level_values(1)[:-1]).all()
diff --git a/pandas/tests/indexes/test_numeric.py b/pandas/tests/indexes/test_numeric.py
index 62ac337d0..1a0a38c17 100644
--- a/pandas/tests/indexes/test_numeric.py
+++ b/pandas/tests/indexes/test_numeric.py
@@ -7,7 +7,7 @@ from pandas.compat import range, PY3
 
 import numpy as np
 
-from pandas import (date_range, notnull, Series, Index, Float64Index,
+from pandas import (date_range, notna, Series, Index, Float64Index,
                     Int64Index, UInt64Index, RangeIndex)
 
 import pandas.util.testing as tm
@@ -228,11 +228,11 @@ class TestFloat64Index(Numeric):
 
         # nan handling
         result = Float64Index([np.nan, np.nan])
-        assert pd.isnull(result.values).all()
+        assert pd.isna(result.values).all()
         result = Float64Index(np.array([np.nan]))
-        assert pd.isnull(result.values).all()
+        assert pd.isna(result.values).all()
         result = Index(np.array([np.nan]))
-        assert pd.isnull(result.values).all()
+        assert pd.isna(result.values).all()
 
     def test_constructor_invalid(self):
 
@@ -717,7 +717,7 @@ class TestInt64Index(NumericInt):
 
     def test_where(self):
         i = self.create_index()
-        result = i.where(notnull(i))
+        result = i.where(notna(i))
         expected = i
         tm.assert_index_equal(result, expected)
 
diff --git a/pandas/tests/indexes/test_range.py b/pandas/tests/indexes/test_range.py
index 0d88e8803..566354da4 100644
--- a/pandas/tests/indexes/test_range.py
+++ b/pandas/tests/indexes/test_range.py
@@ -10,7 +10,7 @@ from pandas.compat import range, u, PY3
 
 import numpy as np
 
-from pandas import (notnull, Series, Index, Float64Index,
+from pandas import (notna, Series, Index, Float64Index,
                     Int64Index, RangeIndex)
 
 import pandas.util.testing as tm
@@ -929,7 +929,7 @@ class TestRangeIndex(Numeric):
 
     def test_where(self):
         i = self.create_index()
-        result = i.where(notnull(i))
+        result = i.where(notna(i))
         expected = i
         tm.assert_index_equal(result, expected)
 
diff --git a/pandas/tests/indexes/timedeltas/test_ops.py b/pandas/tests/indexes/timedeltas/test_ops.py
index 9a9912d4f..f4f669ee1 100644
--- a/pandas/tests/indexes/timedeltas/test_ops.py
+++ b/pandas/tests/indexes/timedeltas/test_ops.py
@@ -71,13 +71,13 @@ class TestTimedeltaIndexOps(Ops):
         for op in ['min', 'max']:
             # Return NaT
             obj = TimedeltaIndex([])
-            assert pd.isnull(getattr(obj, op)())
+            assert pd.isna(getattr(obj, op)())
 
             obj = TimedeltaIndex([pd.NaT])
-            assert pd.isnull(getattr(obj, op)())
+            assert pd.isna(getattr(obj, op)())
 
             obj = TimedeltaIndex([pd.NaT, pd.NaT, pd.NaT])
-            assert pd.isnull(getattr(obj, op)())
+            assert pd.isna(getattr(obj, op)())
 
     def test_numpy_minmax(self):
         dr = pd.date_range(start='2016-01-15', end='2016-01-20')
diff --git a/pandas/tests/indexes/timedeltas/test_tools.py b/pandas/tests/indexes/timedeltas/test_tools.py
index a991b7bbe..1a4d1b1d7 100644
--- a/pandas/tests/indexes/timedeltas/test_tools.py
+++ b/pandas/tests/indexes/timedeltas/test_tools.py
@@ -6,7 +6,7 @@ import numpy as np
 import pandas as pd
 import pandas.util.testing as tm
 from pandas.util.testing import assert_series_equal
-from pandas import (Series, Timedelta, to_timedelta, isnull,
+from pandas import (Series, Timedelta, to_timedelta, isna,
                     TimedeltaIndex)
 from pandas._libs.tslib import iNaT
 
@@ -31,7 +31,7 @@ class TestTimedeltas(object):
         assert result.astype('int64') == iNaT
 
         result = to_timedelta(['', ''])
-        assert isnull(result).all()
+        assert isna(result).all()
 
         # pass thru
         result = to_timedelta(np.array([np.timedelta64(1, 's')]))
diff --git a/pandas/tests/indexing/test_chaining_and_caching.py b/pandas/tests/indexing/test_chaining_and_caching.py
index 27a889e58..25e572ee0 100644
--- a/pandas/tests/indexing/test_chaining_and_caching.py
+++ b/pandas/tests/indexing/test_chaining_and_caching.py
@@ -321,7 +321,7 @@ class TestChaining(object):
         df = pd.DataFrame({'a': list(range(4)),
                            'b': list('ab..'),
                            'c': ['a', 'b', np.nan, 'd']})
-        mask = pd.isnull(df.c)
+        mask = pd.isna(df.c)
 
         def f():
             df[['c']][mask] = df[['b']][mask]
diff --git a/pandas/tests/indexing/test_iloc.py b/pandas/tests/indexing/test_iloc.py
index 769cf8ec3..1ba9f3101 100644
--- a/pandas/tests/indexing/test_iloc.py
+++ b/pandas/tests/indexing/test_iloc.py
@@ -7,7 +7,7 @@ import numpy as np
 
 import pandas as pd
 from pandas.compat import lrange, lmap
-from pandas import Series, DataFrame, date_range, concat, isnull
+from pandas import Series, DataFrame, date_range, concat, isna
 from pandas.util import testing as tm
 from pandas.tests.indexing.common import Base
 
@@ -191,7 +191,7 @@ class TestiLoc(Base):
 
         # cross-sectional indexing
         result = df.iloc[0, 0]
-        assert isnull(result)
+        assert isna(result)
 
         result = df.iloc[0, :]
         expected = Series([np.nan, 1, 3, 3], index=['A', 'B', 'A', 'B'],
diff --git a/pandas/tests/indexing/test_indexing.py b/pandas/tests/indexing/test_indexing.py
index e5b70a9fa..3ecd1f302 100644
--- a/pandas/tests/indexing/test_indexing.py
+++ b/pandas/tests/indexing/test_indexing.py
@@ -363,7 +363,7 @@ class TestFancy(Base):
         df.iloc[1, 0] = np.nan
         df2 = df.copy()
 
-        mask = ~df2.FC.isnull()
+        mask = ~df2.FC.isna()
         cols = ['col1', 'col2']
 
         dft = df2 * 2
diff --git a/pandas/tests/io/parser/common.py b/pandas/tests/io/parser/common.py
index 4d1f9936a..34ed8782b 100644
--- a/pandas/tests/io/parser/common.py
+++ b/pandas/tests/io/parser/common.py
@@ -704,7 +704,7 @@ bar"""
 1,3,3,
 1,4,5"""
         result = self.read_csv(StringIO(data))
-        assert result['D'].isnull()[1:].all()
+        assert result['D'].isna()[1:].all()
 
     def test_skipinitialspace(self):
         s = ('"09-Apr-2012", "01:10:18.300", 2456026.548822908, 12849, '
@@ -718,7 +718,7 @@ bar"""
         # it's 33 columns
         result = self.read_csv(sfile, names=lrange(33), na_values=['-9999.0'],
                                header=None, skipinitialspace=True)
-        assert pd.isnull(result.iloc[0, 29])
+        assert pd.isna(result.iloc[0, 29])
 
     def test_utf16_bom_skiprows(self):
         # #2298
diff --git a/pandas/tests/io/parser/converters.py b/pandas/tests/io/parser/converters.py
index 8fde709e3..1176b1e84 100644
--- a/pandas/tests/io/parser/converters.py
+++ b/pandas/tests/io/parser/converters.py
@@ -133,7 +133,7 @@ c,4,5,01/03/2009
         result = self.read_csv(fh, converters={'score': convert_score,
                                                'days': convert_days},
                                na_values=['', None])
-        assert pd.isnull(result['days'][1])
+        assert pd.isna(result['days'][1])
 
         fh = StringIO(data)
         result2 = self.read_csv(fh, converters={'score': convert_score,
diff --git a/pandas/tests/io/parser/na_values.py b/pandas/tests/io/parser/na_values.py
index c6d1cc79b..7fbf174e1 100644
--- a/pandas/tests/io/parser/na_values.py
+++ b/pandas/tests/io/parser/na_values.py
@@ -249,7 +249,7 @@ nan,B
 
         result = self.read_csv(StringIO(data))
         assert result['Date'][1] == '2012-05-12'
-        assert result['UnitPrice'].isnull().all()
+        assert result['UnitPrice'].isna().all()
 
     def test_na_values_scalar(self):
         # see gh-12224
diff --git a/pandas/tests/io/parser/parse_dates.py b/pandas/tests/io/parser/parse_dates.py
index 4507db108..e1ae1b577 100644
--- a/pandas/tests/io/parser/parse_dates.py
+++ b/pandas/tests/io/parser/parse_dates.py
@@ -461,7 +461,7 @@ KORD6,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
         data = "Date, test\n2012-01-01, 1\n,2"
         result = self.read_csv(StringIO(data), parse_dates=["Date"],
                                na_filter=False)
-        assert result['Date'].isnull()[1]
+        assert result['Date'].isna()[1]
 
     def test_parse_dates_noconvert_thousands(self):
         # see gh-14066
diff --git a/pandas/tests/io/test_html.py b/pandas/tests/io/test_html.py
index 0455ffb06..6fc080c8d 100644
--- a/pandas/tests/io/test_html.py
+++ b/pandas/tests/io/test_html.py
@@ -385,7 +385,7 @@ class TestReadHtml(ReadHtmlMixin):
                              attrs={'class': 'style1'})
         df = dfs[all_non_nan_table_index]
 
-        assert not any(s.isnull().any() for _, s in df.iteritems())
+        assert not any(s.isna().any() for _, s in df.iteritems())
 
     @pytest.mark.slow
     def test_thousands_macau_index_col(self):
@@ -394,7 +394,7 @@ class TestReadHtml(ReadHtmlMixin):
         dfs = self.read_html(macau_data, index_col=0, header=0)
         df = dfs[all_non_nan_table_index]
 
-        assert not any(s.isnull().any() for _, s in df.iteritems())
+        assert not any(s.isna().any() for _, s in df.iteritems())
 
     def test_empty_tables(self):
         """
diff --git a/pandas/tests/io/test_pytables.py b/pandas/tests/io/test_pytables.py
index c0d200560..fc17b5f85 100644
--- a/pandas/tests/io/test_pytables.py
+++ b/pandas/tests/io/test_pytables.py
@@ -14,7 +14,7 @@ import pandas as pd
 from pandas import (Series, DataFrame, Panel, Panel4D, MultiIndex, Int64Index,
                     RangeIndex, Categorical, bdate_range,
                     date_range, timedelta_range, Index, DatetimeIndex,
-                    isnull)
+                    isna)
 
 from pandas.compat import is_platform_windows, PY3, PY35, BytesIO, text_type
 from pandas.io.formats.printing import pprint_thing
@@ -3948,7 +3948,7 @@ class TestHDFStore(Base):
 
             store.append('df2', df2, data_columns=['x'])
             result = store.select('df2', 'x!=none')
-            expected = df2[isnull(df2.x)]
+            expected = df2[isna(df2.x)]
             assert_frame_equal(result, expected)
 
             # int ==/!=
diff --git a/pandas/tests/io/test_sql.py b/pandas/tests/io/test_sql.py
index deeb8cba2..a7c42391e 100644
--- a/pandas/tests/io/test_sql.py
+++ b/pandas/tests/io/test_sql.py
@@ -33,7 +33,7 @@ from datetime import datetime, date, time
 from pandas.core.dtypes.common import (
     is_object_dtype, is_datetime64_dtype,
     is_datetime64tz_dtype)
-from pandas import DataFrame, Series, Index, MultiIndex, isnull, concat
+from pandas import DataFrame, Series, Index, MultiIndex, isna, concat
 from pandas import date_range, to_datetime, to_timedelta, Timestamp
 import pandas.compat as compat
 from pandas.compat import range, lrange, string_types, PY36
@@ -1530,7 +1530,7 @@ class _TestSQLAlchemy(SQLAlchemyMixIn, PandasSQLTest):
         assert isinstance(sqltypea, sqlalchemy.TEXT)
         assert isinstance(sqltypeb, sqlalchemy.TEXT)
 
-    def test_notnull_dtype(self):
+    def test_notna_dtype(self):
         cols = {'Bool': Series([True, None]),
                 'Date': Series([datetime(2012, 5, 1), None]),
                 'Int': Series([1, None], dtype='object'),
@@ -1538,7 +1538,7 @@ class _TestSQLAlchemy(SQLAlchemyMixIn, PandasSQLTest):
                 }
         df = DataFrame(cols)
 
-        tbl = 'notnull_dtype_test'
+        tbl = 'notna_dtype_test'
         df.to_sql(tbl, self.conn)
         returned_df = sql.read_sql_table(tbl, self.conn)  # noqa
         meta = sqlalchemy.schema.MetaData(bind=self.conn)
@@ -2005,7 +2005,7 @@ class TestSQLiteFallback(SQLiteMixIn, PandasSQLTest):
         assert self._get_sqlite_column_type(
             'single_dtype_test', 'B') == 'STRING'
 
-    def test_notnull_dtype(self):
+    def test_notna_dtype(self):
         if self.flavor == 'mysql':
             pytest.skip('Not applicable to MySQL legacy')
 
@@ -2016,7 +2016,7 @@ class TestSQLiteFallback(SQLiteMixIn, PandasSQLTest):
                 }
         df = DataFrame(cols)
 
-        tbl = 'notnull_dtype_test'
+        tbl = 'notna_dtype_test'
         df.to_sql(tbl, self.conn)
 
         assert self._get_sqlite_column_type(tbl, 'Bool') == 'INTEGER'
@@ -2069,7 +2069,7 @@ def format_query(sql, *args):
     """
     processed_args = []
     for arg in args:
-        if isinstance(arg, float) and isnull(arg):
+        if isinstance(arg, float) and isna(arg):
             arg = None
 
         formatter = _formatters[type(arg)]
diff --git a/pandas/tests/reshape/test_concat.py b/pandas/tests/reshape/test_concat.py
index 7486c32f5..46fea86c4 100644
--- a/pandas/tests/reshape/test_concat.py
+++ b/pandas/tests/reshape/test_concat.py
@@ -8,7 +8,7 @@ from datetime import datetime
 from pandas.compat import StringIO, iteritems
 import pandas as pd
 from pandas import (DataFrame, concat,
-                    read_csv, isnull, Series, date_range,
+                    read_csv, isna, Series, date_range,
                     Index, Panel, MultiIndex, Timestamp,
                     DatetimeIndex)
 from pandas.util import testing as tm
@@ -789,8 +789,8 @@ class TestAppend(ConcatenateBase):
         b = df[5:].loc[:, ['strings', 'ints', 'floats']]
 
         appended = a.append(b)
-        assert isnull(appended['strings'][0:4]).all()
-        assert isnull(appended['bools'][5:]).all()
+        assert isna(appended['strings'][0:4]).all()
+        assert isna(appended['bools'][5:]).all()
 
     def test_append_many(self):
         chunks = [self.frame[:5], self.frame[5:10],
@@ -804,7 +804,7 @@ class TestAppend(ConcatenateBase):
         result = chunks[0].append(chunks[1:])
         tm.assert_frame_equal(result.loc[:, self.frame.columns], self.frame)
         assert (result['foo'][15:] == 'bar').all()
-        assert result['foo'][:15].isnull().all()
+        assert result['foo'][:15].isna().all()
 
     def test_append_preserve_index_name(self):
         # #980
diff --git a/pandas/tests/reshape/test_join.py b/pandas/tests/reshape/test_join.py
index e48943079..75c01fabe 100644
--- a/pandas/tests/reshape/test_join.py
+++ b/pandas/tests/reshape/test_join.py
@@ -252,7 +252,7 @@ class TestJoin(object):
         merged = self.target.join(self.source.reindex([]), on='C')
         for col in self.source:
             assert col in merged
-            assert merged[col].isnull().all()
+            assert merged[col].isna().all()
 
         merged2 = self.target.join(self.source.reindex([]), on='C',
                                    how='inner')
@@ -266,7 +266,7 @@ class TestJoin(object):
         joined = df.join(df2, on='key', how='inner')
 
         expected = df.join(df2, on='key')
-        expected = expected[expected['value'].notnull()]
+        expected = expected[expected['value'].notna()]
         tm.assert_series_equal(joined['key'], expected['key'],
                                check_dtype=False)
         tm.assert_series_equal(joined['value'], expected['value'],
@@ -734,7 +734,7 @@ def _check_join(left, right, result, join_col, how='left',
 
     # some smoke tests
     for c in join_col:
-        assert(result[c].notnull().all())
+        assert(result[c].notna().all())
 
     left_grouped = left.groupby(join_col)
     right_grouped = right.groupby(join_col)
@@ -797,7 +797,7 @@ def _assert_all_na(join_chunk, source_columns, join_col):
     for c in source_columns:
         if c in join_col:
             continue
-        assert(join_chunk[c].isnull().all())
+        assert(join_chunk[c].isna().all())
 
 
 def _join_by_hand(a, b, how='left'):
diff --git a/pandas/tests/reshape/test_merge.py b/pandas/tests/reshape/test_merge.py
index 765e8e28b..338596d15 100644
--- a/pandas/tests/reshape/test_merge.py
+++ b/pandas/tests/reshape/test_merge.py
@@ -229,8 +229,8 @@ class TestMerge(object):
         merged2 = merge(right, left, left_on=key, right_on='key', how='outer')
 
         assert_series_equal(merged['key'], merged2['key'])
-        assert merged['key'].notnull().all()
-        assert merged2['key'].notnull().all()
+        assert merged['key'].notna().all()
+        assert merged2['key'].notna().all()
 
         left = DataFrame({'value': lrange(5)}, columns=['value'])
         right = DataFrame({'rvalue': lrange(6)})
@@ -926,8 +926,8 @@ class TestMergeMulti(object):
                 res = left.join(right, on=icols, how='left', sort=sort)
 
                 assert len(left) < len(res) + 1
-                assert not res['4th'].isnull().any()
-                assert not res['5th'].isnull().any()
+                assert not res['4th'].isna().any()
+                assert not res['5th'].isna().any()
 
                 tm.assert_series_equal(
                     res['4th'], - res['5th'], check_names=False)
diff --git a/pandas/tests/reshape/test_merge_ordered.py b/pandas/tests/reshape/test_merge_ordered.py
index 9469e98f3..9b1806ee5 100644
--- a/pandas/tests/reshape/test_merge_ordered.py
+++ b/pandas/tests/reshape/test_merge_ordered.py
@@ -57,7 +57,7 @@ class TestOrderedMerge(object):
         assert_frame_equal(result, result2.loc[:, result.columns])
 
         result = merge_ordered(left, self.right, on='key', left_by='group')
-        assert result['group'].notnull().all()
+        assert result['group'].notna().all()
 
     def test_merge_type(self):
         class NotADataFrame(DataFrame):
diff --git a/pandas/tests/reshape/test_pivot.py b/pandas/tests/reshape/test_pivot.py
index ff9f35b02..5e5852ac5 100644
--- a/pandas/tests/reshape/test_pivot.py
+++ b/pandas/tests/reshape/test_pivot.py
@@ -267,7 +267,7 @@ class TestPivotTable(object):
         df.loc[1, 'b'] = df.loc[4, 'b'] = nan
 
         pv = df.pivot('a', 'b', 'c')
-        assert pv.notnull().values.sum() == len(df)
+        assert pv.notna().values.sum() == len(df)
 
         for _, row in df.iterrows():
             assert pv.loc[row['a'], row['b']] == row['c']
diff --git a/pandas/tests/reshape/test_tile.py b/pandas/tests/reshape/test_tile.py
index 2523f8ab9..91000747b 100644
--- a/pandas/tests/reshape/test_tile.py
+++ b/pandas/tests/reshape/test_tile.py
@@ -4,7 +4,7 @@ import pytest
 import numpy as np
 from pandas.compat import zip
 
-from pandas import (Series, Index, isnull,
+from pandas import (Series, Index, isna,
                     to_datetime, DatetimeIndex, Timestamp,
                     Interval, IntervalIndex, Categorical,
                     cut, qcut, date_range)
@@ -140,12 +140,12 @@ class TestCut(object):
 
         result_arr = np.asarray(result)
 
-        ex_arr = np.where(isnull(arr), np.nan, result_arr)
+        ex_arr = np.where(isna(arr), np.nan, result_arr)
 
         tm.assert_almost_equal(result_arr, ex_arr)
 
         result = cut(arr, 4, labels=False)
-        ex_result = np.where(isnull(arr), np.nan, result)
+        ex_result = np.where(isna(arr), np.nan, result)
         tm.assert_almost_equal(result, ex_result)
 
     def test_inf_handling(self):
@@ -200,7 +200,7 @@ class TestCut(object):
 
         result = cut(arr, [-1, 0, 1])
 
-        mask = isnull(result)
+        mask = isna(result)
         ex_mask = (arr < -1) | (arr > 1)
         tm.assert_numpy_array_equal(mask, ex_mask)
 
@@ -244,7 +244,7 @@ class TestCut(object):
         arr[:20] = np.nan
 
         result = qcut(arr, 4)
-        assert isnull(result[:20]).all()
+        assert isna(result[:20]).all()
 
     def test_qcut_index(self):
         result = qcut([0, 2], 2)
@@ -502,9 +502,9 @@ class TestCut(object):
 
         result = cut(date_range('20130102', periods=5),
                      bins=date_range('20130101', periods=2))
-        mask = result.categories.isnull()
+        mask = result.categories.isna()
         tm.assert_numpy_array_equal(mask, np.array([False]))
-        mask = result.isnull()
+        mask = result.isna()
         tm.assert_numpy_array_equal(
             mask, np.array([False, True, True, True, True]))
 
diff --git a/pandas/tests/scalar/test_nat.py b/pandas/tests/scalar/test_nat.py
index 0695fe224..5f247cae1 100644
--- a/pandas/tests/scalar/test_nat.py
+++ b/pandas/tests/scalar/test_nat.py
@@ -6,7 +6,7 @@ import pytz
 import numpy as np
 from pandas import (NaT, Index, Timestamp, Timedelta, Period,
                     DatetimeIndex, PeriodIndex,
-                    TimedeltaIndex, Series, isnull)
+                    TimedeltaIndex, Series, isna)
 from pandas.util import testing as tm
 from pandas._libs.tslib import iNaT
 
@@ -95,7 +95,7 @@ def test_identity(klass):
     result = klass('NaT')
     assert result is NaT
 
-    assert isnull(klass('nat'))
+    assert isna(klass('nat'))
 
 
 @pytest.mark.parametrize('klass', [Timestamp, Timedelta, Period])
@@ -108,7 +108,7 @@ def test_equality(klass):
     klass('NAT').value == iNaT
     klass(None).value == iNaT
     klass(np.nan).value == iNaT
-    assert isnull(klass('nat'))
+    assert isna(klass('nat'))
 
 
 @pytest.mark.parametrize('klass', [Timestamp, Timedelta])
diff --git a/pandas/tests/scalar/test_timedelta.py b/pandas/tests/scalar/test_timedelta.py
index ecc442049..bc9a0388d 100644
--- a/pandas/tests/scalar/test_timedelta.py
+++ b/pandas/tests/scalar/test_timedelta.py
@@ -638,8 +638,8 @@ class TestTimedeltas(object):
         s[1] = np.nan
 
         result = s.dt.components
-        assert not result.iloc[0].isnull().all()
-        assert result.iloc[1].isnull().all()
+        assert not result.iloc[0].isna().all()
+        assert result.iloc[1].isna().all()
 
     def test_isoformat(self):
         td = Timedelta(days=6, minutes=50, seconds=3,
diff --git a/pandas/tests/series/test_analytics.py b/pandas/tests/series/test_analytics.py
index a736f3aa7..44da0968d 100644
--- a/pandas/tests/series/test_analytics.py
+++ b/pandas/tests/series/test_analytics.py
@@ -10,7 +10,7 @@ from numpy import nan
 import numpy as np
 import pandas as pd
 
-from pandas import (Series, Categorical, DataFrame, isnull, notnull,
+from pandas import (Series, Categorical, DataFrame, isna, notna,
                     bdate_range, date_range, _np_version_under1p10)
 from pandas.core.index import MultiIndex
 from pandas.core.indexes.datetimes import Timestamp
@@ -130,7 +130,7 @@ class TestSeriesAnalytics(TestData):
         arr = np.random.randn(100, 100).astype('f4')
         arr[:, 2] = np.inf
 
-        with cf.option_context("mode.use_inf_as_null", True):
+        with cf.option_context("mode.use_inf_as_na", True):
             assert_almost_equal(s.sum(), s2.sum())
 
         res = nanops.nansum(arr, axis=1)
@@ -269,10 +269,10 @@ class TestSeriesAnalytics(TestData):
         # 1 - element series with ddof=1
         s = self.ts.iloc[[0]]
         result = s.var(ddof=1)
-        assert isnull(result)
+        assert isna(result)
 
         result = s.std(ddof=1)
-        assert isnull(result)
+        assert isna(result)
 
     def test_sem(self):
         alt = lambda x: np.std(x, ddof=1) / np.sqrt(len(x))
@@ -286,7 +286,7 @@ class TestSeriesAnalytics(TestData):
         # 1 - element series with ddof=1
         s = self.ts.iloc[[0]]
         result = s.sem(ddof=1)
-        assert isnull(result)
+        assert isna(result)
 
     def test_skew(self):
         tm._skip_if_no_scipy()
@@ -365,7 +365,7 @@ class TestSeriesAnalytics(TestData):
         assert s.dtype == 'datetime64[ns]'
         shifted = s.shift(-1)
         assert shifted.dtype == 'datetime64[ns]'
-        assert isnull(shifted[4])
+        assert isna(shifted[4])
 
         result = s.argsort()
         expected = Series(lrange(5), dtype='int64')
@@ -524,8 +524,8 @@ class TestSeriesAnalytics(TestData):
                 pytest.raises(TypeError, f, ds)
 
             # skipna or no
-            assert notnull(f(self.series))
-            assert isnull(f(self.series, skipna=False))
+            assert notna(f(self.series))
+            assert isna(f(self.series, skipna=False))
 
             # check the result is correct
             nona = self.series.dropna()
@@ -743,10 +743,10 @@ class TestSeriesAnalytics(TestData):
         assert result == 0
 
         result = Series(dtype=float).mean()
-        assert isnull(result)
+        assert isna(result)
 
         result = Series(dtype=float).median()
-        assert isnull(result)
+        assert isna(result)
 
         # timedelta64[ns]
         result = Series(dtype='m8[ns]').sum()
@@ -769,11 +769,11 @@ class TestSeriesAnalytics(TestData):
         # partial overlap
         tm.assert_almost_equal(self.ts[:15].corr(self.ts[5:]), 1)
 
-        assert isnull(self.ts[:15].corr(self.ts[5:], min_periods=12))
+        assert isna(self.ts[:15].corr(self.ts[5:], min_periods=12))
 
         ts1 = self.ts[:15].reindex(self.ts.index)
         ts2 = self.ts[5:].reindex(self.ts.index)
-        assert isnull(ts1.corr(ts2, min_periods=12))
+        assert isna(ts1.corr(ts2, min_periods=12))
 
         # No overlap
         assert np.isnan(self.ts[::2].corr(self.ts[1::2]))
@@ -781,7 +781,7 @@ class TestSeriesAnalytics(TestData):
         # all NA
         cp = self.ts[:10].copy()
         cp[:] = np.nan
-        assert isnull(cp.corr(cp))
+        assert isna(cp.corr(cp))
 
         A = tm.makeTimeSeries()
         B = tm.makeTimeSeries()
@@ -838,14 +838,14 @@ class TestSeriesAnalytics(TestData):
         # all NA
         cp = self.ts[:10].copy()
         cp[:] = np.nan
-        assert isnull(cp.cov(cp))
+        assert isna(cp.cov(cp))
 
         # min_periods
-        assert isnull(self.ts[:15].cov(self.ts[5:], min_periods=12))
+        assert isna(self.ts[:15].cov(self.ts[5:], min_periods=12))
 
         ts1 = self.ts[:15].reindex(self.ts.index)
         ts2 = self.ts[5:].reindex(self.ts.index)
-        assert isnull(ts1.cov(ts2, min_periods=12))
+        assert isna(ts1.cov(ts2, min_periods=12))
 
     def test_count(self):
         assert self.ts.count() == len(self.ts)
@@ -995,10 +995,10 @@ class TestSeriesAnalytics(TestData):
             thresh = s[2]
             l = s.clip_lower(thresh)
             u = s.clip_upper(thresh)
-            assert l[notnull(l)].min() == thresh
-            assert u[notnull(u)].max() == thresh
-            assert list(isnull(s)) == list(isnull(l))
-            assert list(isnull(s)) == list(isnull(u))
+            assert l[notna(l)].min() == thresh
+            assert u[notna(u)].max() == thresh
+            assert list(isna(s)) == list(isna(l))
+            assert list(isna(s)) == list(isna(u))
 
     def test_clip_against_series(self):
         # GH #6966
@@ -1202,14 +1202,14 @@ class TestSeriesAnalytics(TestData):
 
     def test_idxmin(self):
         # test idxmin
-        # _check_stat_op approach can not be used here because of isnull check.
+        # _check_stat_op approach can not be used here because of isna check.
 
         # add some NaNs
         self.series[5:15] = np.NaN
 
         # skipna or no
         assert self.series[self.series.idxmin()] == self.series.min()
-        assert isnull(self.series.idxmin(skipna=False))
+        assert isna(self.series.idxmin(skipna=False))
 
         # no NaNs
         nona = self.series.dropna()
@@ -1219,7 +1219,7 @@ class TestSeriesAnalytics(TestData):
 
         # all NaNs
         allna = self.series * nan
-        assert isnull(allna.idxmin())
+        assert isna(allna.idxmin())
 
         # datetime64[ns]
         from pandas import date_range
@@ -1244,14 +1244,14 @@ class TestSeriesAnalytics(TestData):
 
     def test_idxmax(self):
         # test idxmax
-        # _check_stat_op approach can not be used here because of isnull check.
+        # _check_stat_op approach can not be used here because of isna check.
 
         # add some NaNs
         self.series[5:15] = np.NaN
 
         # skipna or no
         assert self.series[self.series.idxmax()] == self.series.max()
-        assert isnull(self.series.idxmax(skipna=False))
+        assert isna(self.series.idxmax(skipna=False))
 
         # no NaNs
         nona = self.series.dropna()
@@ -1261,7 +1261,7 @@ class TestSeriesAnalytics(TestData):
 
         # all NaNs
         allna = self.series * nan
-        assert isnull(allna.idxmax())
+        assert isna(allna.idxmax())
 
         from pandas import date_range
         s = Series(date_range('20130102', periods=6))
@@ -1307,7 +1307,7 @@ class TestSeriesAnalytics(TestData):
         # GH11163
         s = Series([3, 5, np.nan, -3, 10])
         assert s.ptp() == 13
-        assert pd.isnull(s.ptp(skipna=False))
+        assert pd.isna(s.ptp(skipna=False))
 
         mi = pd.MultiIndex.from_product([['a', 'b'], [1, 2, 3]])
         s = pd.Series([1, np.nan, 7, 3, 5, np.nan], index=mi)
diff --git a/pandas/tests/series/test_apply.py b/pandas/tests/series/test_apply.py
index 2c5f0d777..e3be54275 100644
--- a/pandas/tests/series/test_apply.py
+++ b/pandas/tests/series/test_apply.py
@@ -8,7 +8,7 @@ from collections import Counter, defaultdict, OrderedDict
 import numpy as np
 import pandas as pd
 
-from pandas import (Index, Series, DataFrame, isnull)
+from pandas import (Index, Series, DataFrame, isna)
 from pandas.compat import lrange
 from pandas import compat
 from pandas.util.testing import assert_series_equal, assert_frame_equal
@@ -393,8 +393,8 @@ class TestSeriesMap(TestData):
 
         merged = left.map(right)
         assert merged.dtype == np.float_
-        assert isnull(merged['d'])
-        assert not isnull(merged['c'])
+        assert isna(merged['d'])
+        assert not isna(merged['c'])
 
     def test_map_type_inference(self):
         s = Series(lrange(3))
diff --git a/pandas/tests/series/test_asof.py b/pandas/tests/series/test_asof.py
index 1f62d618b..3104d8560 100644
--- a/pandas/tests/series/test_asof.py
+++ b/pandas/tests/series/test_asof.py
@@ -3,8 +3,8 @@
 import pytest
 
 import numpy as np
-from pandas import (offsets, Series, notnull,
-                    isnull, date_range, Timestamp)
+from pandas import (offsets, Series, notna,
+                    isna, date_range, Timestamp)
 
 import pandas.util.testing as tm
 
@@ -23,12 +23,12 @@ class TestSeriesAsof(TestData):
         dates = date_range('1/1/1990', periods=N * 3, freq='25s')
 
         result = ts.asof(dates)
-        assert notnull(result).all()
+        assert notna(result).all()
         lb = ts.index[14]
         ub = ts.index[30]
 
         result = ts.asof(list(dates))
-        assert notnull(result).all()
+        assert notna(result).all()
         lb = ts.index[14]
         ub = ts.index[30]
 
@@ -98,12 +98,12 @@ class TestSeriesAsof(TestData):
         dates = date_range('1/1/1990', periods=N * 3, freq='37min')
 
         result = ts.asof(dates)
-        assert notnull(result).all()
+        assert notna(result).all()
         lb = ts.index[14]
         ub = ts.index[30]
 
         result = ts.asof(list(dates))
-        assert notnull(result).all()
+        assert notna(result).all()
         lb = ts.index[14]
         ub = ts.index[30]
 
@@ -130,7 +130,7 @@ class TestSeriesAsof(TestData):
 
         # no as of value
         d = ts.index[0].to_timestamp() - offsets.BDay()
-        assert isnull(ts.asof(d))
+        assert isna(ts.asof(d))
 
     def test_errors(self):
 
@@ -170,7 +170,7 @@ class TestSeriesAsof(TestData):
         # testing scalar input
         date = date_range('1/1/1990', periods=N * 3, freq='25s')[0]
         result = Series(np.nan, index=rng).asof(date)
-        assert isnull(result)
+        assert isna(result)
 
         # test name is propagated
         result = Series(np.nan, index=[1, 2, 3, 4], name='test').asof([4, 5])
diff --git a/pandas/tests/series/test_constructors.py b/pandas/tests/series/test_constructors.py
index a916c42c0..3b95c2803 100644
--- a/pandas/tests/series/test_constructors.py
+++ b/pandas/tests/series/test_constructors.py
@@ -13,7 +13,7 @@ import pandas as pd
 from pandas.core.dtypes.common import (
     is_categorical_dtype,
     is_datetime64tz_dtype)
-from pandas import (Index, Series, isnull, date_range,
+from pandas import (Index, Series, isna, date_range,
                     NaT, period_range, MultiIndex, IntervalIndex)
 from pandas.core.indexes.datetimes import Timestamp, DatetimeIndex
 
@@ -348,22 +348,22 @@ class TestSeriesConstructors(TestData):
     def test_constructor_dtype_datetime64(self):
 
         s = Series(iNaT, dtype='M8[ns]', index=lrange(5))
-        assert isnull(s).all()
+        assert isna(s).all()
 
         # in theory this should be all nulls, but since
         # we are not specifying a dtype is ambiguous
         s = Series(iNaT, index=lrange(5))
-        assert not isnull(s).all()
+        assert not isna(s).all()
 
         s = Series(nan, dtype='M8[ns]', index=lrange(5))
-        assert isnull(s).all()
+        assert isna(s).all()
 
         s = Series([datetime(2001, 1, 2, 0, 0), iNaT], dtype='M8[ns]')
-        assert isnull(s[1])
+        assert isna(s[1])
         assert s.dtype == 'M8[ns]'
 
         s = Series([datetime(2001, 1, 2, 0, 0), nan], dtype='M8[ns]')
-        assert isnull(s[1])
+        assert isna(s[1])
         assert s.dtype == 'M8[ns]'
 
         # GH3416
@@ -760,10 +760,10 @@ class TestSeriesConstructors(TestData):
         series = Series([0, 1000, 2000, iNaT], dtype='M8[ns]')
 
         val = series[3]
-        assert isnull(val)
+        assert isna(val)
 
         series[2] = val
-        assert isnull(series[2])
+        assert isna(series[2])
 
     def test_NaT_cast(self):
         # GH10747
diff --git a/pandas/tests/series/test_indexing.py b/pandas/tests/series/test_indexing.py
index 23283733c..45a92f6d6 100644
--- a/pandas/tests/series/test_indexing.py
+++ b/pandas/tests/series/test_indexing.py
@@ -11,7 +11,7 @@ import pandas as pd
 
 import pandas._libs.index as _index
 from pandas.core.dtypes.common import is_integer, is_scalar
-from pandas import (Index, Series, DataFrame, isnull,
+from pandas import (Index, Series, DataFrame, isna,
                     date_range, NaT, MultiIndex,
                     Timestamp, DatetimeIndex, Timedelta)
 from pandas.core.indexing import IndexingError
@@ -254,7 +254,7 @@ class TestSeriesIndexing(TestData):
     def test_getitem_boolean_empty(self):
         s = Series([], dtype=np.int64)
         s.index.name = 'index_name'
-        s = s[s.isnull()]
+        s = s[s.isna()]
         assert s.index.name == 'index_name'
         assert s.dtype == np.int64
 
@@ -1190,11 +1190,11 @@ class TestSeriesIndexing(TestData):
         s = Series(range(10)).astype(float)
         s[8] = None
         result = s[8]
-        assert isnull(result)
+        assert isna(result)
 
         s = Series(range(10)).astype(float)
         s[s > 8] = None
-        result = s[isnull(s)]
+        result = s[isna(s)]
         expected = Series(np.nan, index=[9])
         assert_series_equal(result, expected)
 
@@ -1988,7 +1988,7 @@ class TestSeriesIndexing(TestData):
         result = series.reindex(lrange(15))
         assert np.issubdtype(result.dtype, np.dtype('M8[ns]'))
 
-        mask = result.isnull()
+        mask = result.isna()
         assert mask[-5:].all()
         assert not mask[:-5].any()
 
@@ -2114,7 +2114,7 @@ class TestSeriesIndexing(TestData):
         ts = self.ts[5:]
         bool_ts = Series(np.zeros(len(ts), dtype=bool), index=ts.index)
         filled_bool = bool_ts.reindex(self.ts.index, method='pad')
-        assert isnull(filled_bool[:5]).all()
+        assert isna(filled_bool[:5]).all()
 
     def test_reindex_like(self):
         other = self.ts[::2]
diff --git a/pandas/tests/series/test_missing.py b/pandas/tests/series/test_missing.py
index 24dd90e40..2d20ac968 100644
--- a/pandas/tests/series/test_missing.py
+++ b/pandas/tests/series/test_missing.py
@@ -11,7 +11,7 @@ from numpy import nan
 import numpy as np
 import pandas as pd
 
-from pandas import (Series, DataFrame, isnull, date_range,
+from pandas import (Series, DataFrame, isna, date_range,
                     MultiIndex, Index, Timestamp, NaT, IntervalIndex)
 from pandas.compat import range
 from pandas._libs.tslib import iNaT
@@ -159,7 +159,7 @@ class TestSeriesMissingData(TestData):
                                Timestamp('2011-01-02 10:00')])
             tm.assert_series_equal(expected, result)
             # check s is not changed
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna(pd.Timestamp('2011-01-02 10:00', tz=tz))
             expected = Series([Timestamp('2011-01-01 10:00'),
@@ -167,14 +167,14 @@ class TestSeriesMissingData(TestData):
                                Timestamp('2011-01-03 10:00'),
                                Timestamp('2011-01-02 10:00', tz=tz)])
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna('AAA')
             expected = Series([Timestamp('2011-01-01 10:00'), 'AAA',
                                Timestamp('2011-01-03 10:00'), 'AAA'],
                               dtype=object)
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna({1: pd.Timestamp('2011-01-02 10:00', tz=tz),
                                3: pd.Timestamp('2011-01-04 10:00')})
@@ -183,7 +183,7 @@ class TestSeriesMissingData(TestData):
                                Timestamp('2011-01-03 10:00'),
                                Timestamp('2011-01-04 10:00')])
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna({1: pd.Timestamp('2011-01-02 10:00'),
                                3: pd.Timestamp('2011-01-04 10:00')})
@@ -192,14 +192,14 @@ class TestSeriesMissingData(TestData):
                                Timestamp('2011-01-03 10:00'),
                                Timestamp('2011-01-04 10:00')])
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             # DatetimeBlockTZ
             idx = pd.DatetimeIndex(['2011-01-01 10:00', pd.NaT,
                                     '2011-01-03 10:00', pd.NaT], tz=tz)
             s = pd.Series(idx)
             assert s.dtype == 'datetime64[ns, {0}]'.format(tz)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna(pd.Timestamp('2011-01-02 10:00'))
             expected = Series([Timestamp('2011-01-01 10:00', tz=tz),
@@ -207,7 +207,7 @@ class TestSeriesMissingData(TestData):
                                Timestamp('2011-01-03 10:00', tz=tz),
                                Timestamp('2011-01-02 10:00')])
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna(pd.Timestamp('2011-01-02 10:00', tz=tz))
             idx = pd.DatetimeIndex(['2011-01-01 10:00', '2011-01-02 10:00',
@@ -215,7 +215,7 @@ class TestSeriesMissingData(TestData):
                                    tz=tz)
             expected = Series(idx)
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna(pd.Timestamp('2011-01-02 10:00',
                                            tz=tz).to_pydatetime())
@@ -224,14 +224,14 @@ class TestSeriesMissingData(TestData):
                                    tz=tz)
             expected = Series(idx)
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna('AAA')
             expected = Series([Timestamp('2011-01-01 10:00', tz=tz), 'AAA',
                                Timestamp('2011-01-03 10:00', tz=tz), 'AAA'],
                               dtype=object)
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna({1: pd.Timestamp('2011-01-02 10:00', tz=tz),
                                3: pd.Timestamp('2011-01-04 10:00')})
@@ -240,7 +240,7 @@ class TestSeriesMissingData(TestData):
                                Timestamp('2011-01-03 10:00', tz=tz),
                                Timestamp('2011-01-04 10:00')])
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna({1: pd.Timestamp('2011-01-02 10:00', tz=tz),
                                3: pd.Timestamp('2011-01-04 10:00', tz=tz)})
@@ -249,7 +249,7 @@ class TestSeriesMissingData(TestData):
                                Timestamp('2011-01-03 10:00', tz=tz),
                                Timestamp('2011-01-04 10:00', tz=tz)])
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             # filling with a naive/other zone, coerce to object
             result = s.fillna(Timestamp('20130101'))
@@ -258,7 +258,7 @@ class TestSeriesMissingData(TestData):
                                Timestamp('2011-01-03 10:00', tz=tz),
                                Timestamp('2013-01-01')])
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna(Timestamp('20130101', tz='US/Pacific'))
             expected = Series([Timestamp('2011-01-01 10:00', tz=tz),
@@ -266,7 +266,7 @@ class TestSeriesMissingData(TestData):
                                Timestamp('2011-01-03 10:00', tz=tz),
                                Timestamp('2013-01-01', tz='US/Pacific')])
             tm.assert_series_equal(expected, result)
-            tm.assert_series_equal(pd.isnull(s), null_loc)
+            tm.assert_series_equal(pd.isna(s), null_loc)
 
         # with timezone
         # GH 15855
@@ -400,10 +400,10 @@ class TestSeriesMissingData(TestData):
         assert_frame_equal(filled, expected)
         assert_frame_equal(filled2, expected)
 
-    def test_isnull_for_inf(self):
+    def test_isna_for_inf(self):
         s = Series(['a', np.inf, np.nan, 1.0])
-        with pd.option_context('mode.use_inf_as_null', True):
-            r = s.isnull()
+        with pd.option_context('mode.use_inf_as_na', True):
+            r = s.isna()
             dr = s.dropna()
         e = Series([False, True, True, False])
         de = Series(['a', 1.0], index=[0, 3])
@@ -526,28 +526,28 @@ class TestSeriesMissingData(TestData):
         # nan ops on timedeltas
         td1 = td.copy()
         td1[0] = np.nan
-        assert isnull(td1[0])
+        assert isna(td1[0])
         assert td1[0].value == iNaT
         td1[0] = td[0]
-        assert not isnull(td1[0])
+        assert not isna(td1[0])
 
         td1[1] = iNaT
-        assert isnull(td1[1])
+        assert isna(td1[1])
         assert td1[1].value == iNaT
         td1[1] = td[1]
-        assert not isnull(td1[1])
+        assert not isna(td1[1])
 
         td1[2] = NaT
-        assert isnull(td1[2])
+        assert isna(td1[2])
         assert td1[2].value == iNaT
         td1[2] = td[2]
-        assert not isnull(td1[2])
+        assert not isna(td1[2])
 
         # boolean setting
         # this doesn't work, not sure numpy even supports it
         # result = td[(td>np.timedelta64(timedelta(days=3))) &
         # td<np.timedelta64(timedelta(days=7)))] = np.nan
-        # assert isnull(result).sum() == 7
+        # assert isna(result).sum() == 7
 
         # NumPy limitiation =(
 
@@ -616,21 +616,21 @@ class TestSeriesMissingData(TestData):
         result = ts.valid()
         assert len(result) == ts.count()
         tm.assert_series_equal(result, ts[1::2])
-        tm.assert_series_equal(result, ts[pd.notnull(ts)])
+        tm.assert_series_equal(result, ts[pd.notna(ts)])
 
-    def test_isnull(self):
+    def test_isna(self):
         ser = Series([0, 5.4, 3, nan, -0.001])
-        np.array_equal(ser.isnull(),
+        np.array_equal(ser.isna(),
                        Series([False, False, False, True, False]).values)
         ser = Series(["hi", "", nan])
-        np.array_equal(ser.isnull(), Series([False, False, True]).values)
+        np.array_equal(ser.isna(), Series([False, False, True]).values)
 
-    def test_notnull(self):
+    def test_notna(self):
         ser = Series([0, 5.4, 3, nan, -0.001])
-        np.array_equal(ser.notnull(),
+        np.array_equal(ser.notna(),
                        Series([True, True, True, False, True]).values)
         ser = Series(["hi", "", nan])
-        np.array_equal(ser.notnull(), Series([True, True, False]).values)
+        np.array_equal(ser.notna(), Series([True, True, False]).values)
 
     def test_pad_nan(self):
         x = Series([np.nan, 1., np.nan, 3., np.nan], ['z', 'a', 'b', 'c', 'd'],
@@ -849,7 +849,7 @@ class TestSeriesInterpolateData(TestData):
         result = s.interpolate(method='index')
 
         expected = s.copy()
-        bad = isnull(expected.values)
+        bad = isna(expected.values)
         good = ~bad
         expected = Series(np.interp(vals[bad], vals[good],
                                     s.values[good]),
diff --git a/pandas/tests/series/test_operators.py b/pandas/tests/series/test_operators.py
index 2e400812e..991c5ff62 100644
--- a/pandas/tests/series/test_operators.py
+++ b/pandas/tests/series/test_operators.py
@@ -13,7 +13,7 @@ from numpy import nan, inf
 import numpy as np
 import pandas as pd
 
-from pandas import (Index, Series, DataFrame, isnull, bdate_range,
+from pandas import (Index, Series, DataFrame, isna, bdate_range,
                     NaT, date_range, timedelta_range,
                     _np_version_under1p8)
 from pandas.core.indexes.datetimes import Timestamp
@@ -999,7 +999,7 @@ class TestSeriesOperators(TestData):
             # boolean &, |, ^ should work with object arrays and propagate NAs
 
         ops = ['and_', 'or_', 'xor']
-        mask = s.isnull()
+        mask = s.isna()
         for bool_op in ops:
             f = getattr(operator, bool_op)
 
@@ -1720,8 +1720,8 @@ class TestSeriesOperators(TestData):
             a = a.reindex(exp_index)
             b = b.reindex(exp_index)
 
-            amask = isnull(a)
-            bmask = isnull(b)
+            amask = isna(a)
+            bmask = isna(b)
 
             exp_values = []
             for i in range(len(exp_index)):
@@ -1787,8 +1787,8 @@ class TestSeriesOperators(TestData):
 
         result = s + s.shift(1)
         result2 = s.shift(1) + s
-        assert isnull(result[0])
-        assert isnull(result2[0])
+        assert isna(result[0])
+        assert isna(result2[0])
 
         s = Series(['foo', 'bar', 'baz', np.nan])
         result = 'prefix_' + s
diff --git a/pandas/tests/series/test_period.py b/pandas/tests/series/test_period.py
index 6e8ee38d3..e907b0edd 100644
--- a/pandas/tests/series/test_period.py
+++ b/pandas/tests/series/test_period.py
@@ -33,12 +33,12 @@ class TestSeriesPeriod(object):
         tm.assert_series_equal(result, exp)
         assert result.dtype == 'object'
 
-    def test_isnull(self):
+    def test_isna(self):
         # GH 13737
         s = Series([pd.Period('2011-01', freq='M'),
                     pd.Period('NaT', freq='M')])
-        tm.assert_series_equal(s.isnull(), Series([False, True]))
-        tm.assert_series_equal(s.notnull(), Series([True, False]))
+        tm.assert_series_equal(s.isna(), Series([False, True]))
+        tm.assert_series_equal(s.notna(), Series([True, False]))
 
     def test_fillna(self):
         # GH 13737
@@ -89,10 +89,10 @@ class TestSeriesPeriod(object):
         series = Series([0, 1000, 2000, iNaT], dtype='period[D]')
 
         val = series[3]
-        assert isnull(val)
+        assert isna(val)
 
         series[2] = val
-        assert isnull(series[2])
+        assert isna(series[2])
 
     def test_NaT_cast(self):
         result = Series([np.nan]).astype('period[D]')
diff --git a/pandas/tests/series/test_quantile.py b/pandas/tests/series/test_quantile.py
index 2d02260ac..21379641a 100644
--- a/pandas/tests/series/test_quantile.py
+++ b/pandas/tests/series/test_quantile.py
@@ -166,8 +166,8 @@ class TestSeriesQuantile(TestData):
 
     def test_datetime_timedelta_quantiles(self):
         # covers #9694
-        assert pd.isnull(Series([], dtype='M8[ns]').quantile(.5))
-        assert pd.isnull(Series([], dtype='m8[ns]').quantile(.5))
+        assert pd.isna(Series([], dtype='M8[ns]').quantile(.5))
+        assert pd.isna(Series([], dtype='m8[ns]').quantile(.5))
 
     def test_quantile_nat(self):
         res = Series([pd.NaT, pd.NaT]).quantile(0.5)
diff --git a/pandas/tests/series/test_replace.py b/pandas/tests/series/test_replace.py
index 35d13a62c..2c07d8786 100644
--- a/pandas/tests/series/test_replace.py
+++ b/pandas/tests/series/test_replace.py
@@ -40,7 +40,7 @@ class TestSeriesReplace(TestData):
         assert (rs[:5] == -1).all()
         assert (rs[6:10] == -1).all()
         assert (rs[20:30] == -1).all()
-        assert (pd.isnull(ser[:5])).all()
+        assert (pd.isna(ser[:5])).all()
 
         # replace with different values
         rs = ser.replace({np.nan: -1, 'foo': -2, 'bar': -3})
@@ -48,7 +48,7 @@ class TestSeriesReplace(TestData):
         assert (rs[:5] == -1).all()
         assert (rs[6:10] == -2).all()
         assert (rs[20:30] == -3).all()
-        assert (pd.isnull(ser[:5])).all()
+        assert (pd.isna(ser[:5])).all()
 
         # replace with different values with 2 lists
         rs2 = ser.replace([np.nan, 'foo', 'bar'], [-1, -2, -3])
@@ -203,7 +203,7 @@ class TestSeriesReplace(TestData):
         assert (rs[:5] == -1).all()
         assert (rs[6:10] == -1).all()
         assert (rs[20:30] == -1).all()
-        assert (pd.isnull(ser[:5])).all()
+        assert (pd.isna(ser[:5])).all()
 
         # replace with different values
         rs = ser.replace({np.nan: -1, 'foo': -2, 'bar': -3})
@@ -211,7 +211,7 @@ class TestSeriesReplace(TestData):
         assert (rs[:5] == -1).all()
         assert (rs[6:10] == -2).all()
         assert (rs[20:30] == -3).all()
-        assert (pd.isnull(ser[:5])).all()
+        assert (pd.isna(ser[:5])).all()
 
         # replace with different values with 2 lists
         rs2 = ser.replace([np.nan, 'foo', 'bar'], [-1, -2, -3])
diff --git a/pandas/tests/sparse/test_frame.py b/pandas/tests/sparse/test_frame.py
index d9cb69d56..f0f8954e5 100644
--- a/pandas/tests/sparse/test_frame.py
+++ b/pandas/tests/sparse/test_frame.py
@@ -1105,12 +1105,12 @@ class TestSparseDataFrame(SharedWithSparse):
         nan_colname_sparse = nan_colname.to_sparse()
         assert np.isnan(nan_colname_sparse.columns[0])
 
-    def test_isnull(self):
+    def test_isna(self):
         # GH 8276
         df = pd.SparseDataFrame({'A': [np.nan, np.nan, 1, 2, np.nan],
                                  'B': [0, np.nan, np.nan, 2, np.nan]})
 
-        res = df.isnull()
+        res = df.isna()
         exp = pd.SparseDataFrame({'A': [True, True, False, False, True],
                                   'B': [False, True, True, False, True]},
                                  default_fill_value=True)
@@ -1121,18 +1121,18 @@ class TestSparseDataFrame(SharedWithSparse):
         df = pd.SparseDataFrame({'A': [0, 0, 1, 2, np.nan],
                                  'B': [0, np.nan, 0, 2, np.nan]},
                                 default_fill_value=0.)
-        res = df.isnull()
+        res = df.isna()
         assert isinstance(res, pd.SparseDataFrame)
         exp = pd.DataFrame({'A': [False, False, False, False, True],
                             'B': [False, True, False, False, True]})
         tm.assert_frame_equal(res.to_dense(), exp)
 
-    def test_isnotnull(self):
+    def test_notna(self):
         # GH 8276
         df = pd.SparseDataFrame({'A': [np.nan, np.nan, 1, 2, np.nan],
                                  'B': [0, np.nan, np.nan, 2, np.nan]})
 
-        res = df.isnotnull()
+        res = df.notna()
         exp = pd.SparseDataFrame({'A': [False, False, True, True, False],
                                   'B': [True, False, False, True, False]},
                                  default_fill_value=False)
@@ -1143,7 +1143,7 @@ class TestSparseDataFrame(SharedWithSparse):
         df = pd.SparseDataFrame({'A': [0, 0, 1, 2, np.nan],
                                  'B': [0, np.nan, 0, 2, np.nan]},
                                 default_fill_value=0.)
-        res = df.isnotnull()
+        res = df.notna()
         assert isinstance(res, pd.SparseDataFrame)
         exp = pd.DataFrame({'A': [True, True, True, True, False],
                             'B': [True, False, True, True, False]})
diff --git a/pandas/tests/sparse/test_series.py b/pandas/tests/sparse/test_series.py
index a7685abd5..b44314d4e 100644
--- a/pandas/tests/sparse/test_series.py
+++ b/pandas/tests/sparse/test_series.py
@@ -9,12 +9,10 @@ from numpy import nan
 import numpy as np
 import pandas as pd
 
-from pandas import Series, DataFrame, bdate_range
-from pandas.core.common import isnull
+from pandas import Series, DataFrame, bdate_range, isna, compat
 from pandas.tseries.offsets import BDay
 import pandas.util.testing as tm
 from pandas.compat import range
-from pandas import compat
 from pandas.core.reshape.util import cartesian_product
 
 import pandas.core.sparse.frame as spf
@@ -314,7 +312,7 @@ class TestSparseSeries(SharedWithSparse):
         sp = SparseSeries(data, np.arange(100))
         sp = sp.reindex(np.arange(200))
         assert (sp.loc[:99] == data).all()
-        assert isnull(sp.loc[100:]).all()
+        assert isna(sp.loc[100:]).all()
 
         data = np.nan
         sp = SparseSeries(data, np.arange(100))
@@ -1292,11 +1290,11 @@ class TestSparseSeriesScipyInteraction(object):
         tm.assert_series_equal(sparse.value_counts(dropna=False),
                                dense.value_counts(dropna=False))
 
-    def test_isnull(self):
+    def test_isna(self):
         # GH 8276
         s = pd.SparseSeries([np.nan, np.nan, 1, 2, np.nan], name='xxx')
 
-        res = s.isnull()
+        res = s.isna()
         exp = pd.SparseSeries([True, True, False, False, True], name='xxx',
                               fill_value=True)
         tm.assert_sp_series_equal(res, exp)
@@ -1304,16 +1302,16 @@ class TestSparseSeriesScipyInteraction(object):
         # if fill_value is not nan, True can be included in sp_values
         s = pd.SparseSeries([np.nan, 0., 1., 2., 0.], name='xxx',
                             fill_value=0.)
-        res = s.isnull()
+        res = s.isna()
         assert isinstance(res, pd.SparseSeries)
         exp = pd.Series([True, False, False, False, False], name='xxx')
         tm.assert_series_equal(res.to_dense(), exp)
 
-    def test_isnotnull(self):
+    def test_notna(self):
         # GH 8276
         s = pd.SparseSeries([np.nan, np.nan, 1, 2, np.nan], name='xxx')
 
-        res = s.isnotnull()
+        res = s.notna()
         exp = pd.SparseSeries([False, False, True, True, False], name='xxx',
                               fill_value=False)
         tm.assert_sp_series_equal(res, exp)
@@ -1321,7 +1319,7 @@ class TestSparseSeriesScipyInteraction(object):
         # if fill_value is not nan, True can be included in sp_values
         s = pd.SparseSeries([np.nan, 0., 1., 2., 0.], name='xxx',
                             fill_value=0.)
-        res = s.isnotnull()
+        res = s.notna()
         assert isinstance(res, pd.SparseSeries)
         exp = pd.Series([False, True, True, True, True], name='xxx')
         tm.assert_series_equal(res.to_dense(), exp)
diff --git a/pandas/tests/test_algos.py b/pandas/tests/test_algos.py
index 9e7b97f19..0e86ec123 100644
--- a/pandas/tests/test_algos.py
+++ b/pandas/tests/test_algos.py
@@ -177,7 +177,7 @@ class TestFactorize(object):
             ids = rizer.factorize(key, sort=True, na_sentinel=na_sentinel)
             expected = np.array([0, 1, 0, na_sentinel], dtype='int32')
             assert len(set(key)) == len(set(expected))
-            tm.assert_numpy_array_equal(pd.isnull(key),
+            tm.assert_numpy_array_equal(pd.isna(key),
                                         expected == na_sentinel)
 
         # nan still maps to na_sentinel when sort=False
@@ -189,7 +189,7 @@ class TestFactorize(object):
 
         expected = np.array([2, -1, 0], dtype='int32')
         assert len(set(key)) == len(set(expected))
-        tm.assert_numpy_array_equal(pd.isnull(key), expected == na_sentinel)
+        tm.assert_numpy_array_equal(pd.isna(key), expected == na_sentinel)
 
     def test_complex_sorting(self):
         # gh 12666 - check no segfault
@@ -1150,7 +1150,7 @@ class TestTseriesUtil(object):
     def test_reindex(self):
         pass
 
-    def test_isnull(self):
+    def test_isna(self):
         pass
 
     def test_groupby(self):
diff --git a/pandas/tests/test_base.py b/pandas/tests/test_base.py
index 85976b9fa..9af4a9ede 100644
--- a/pandas/tests/test_base.py
+++ b/pandas/tests/test_base.py
@@ -353,10 +353,10 @@ class TestIndexOps(Ops):
                 assert getattr(obj, op)() == 2.0
 
                 obj = klass([np.nan])
-                assert pd.isnull(getattr(obj, op)())
+                assert pd.isna(getattr(obj, op)())
 
                 obj = klass([])
-                assert pd.isnull(getattr(obj, op)())
+                assert pd.isna(getattr(obj, op)())
 
                 obj = klass([pd.NaT, datetime(2011, 11, 1)])
                 # check DatetimeIndex monotonic path
@@ -495,10 +495,10 @@ class TestIndexOps(Ops):
                 nanloc = np.zeros(len(o), dtype=np.bool)
                 nanloc[:3] = True
                 if isinstance(o, Index):
-                    tm.assert_numpy_array_equal(pd.isnull(o), nanloc)
+                    tm.assert_numpy_array_equal(pd.isna(o), nanloc)
                 else:
                     exp = pd.Series(nanloc, o.index, name='a')
-                    tm.assert_series_equal(pd.isnull(o), exp)
+                    tm.assert_series_equal(pd.isna(o), exp)
 
                 expected_s_na = Series(list(range(10, 2, -1)) + [3],
                                        index=expected_index[9:0:-1],
@@ -528,7 +528,7 @@ class TestIndexOps(Ops):
                 else:
                     tm.assert_numpy_array_equal(result[1:], values[2:])
 
-                    assert pd.isnull(result[0])
+                    assert pd.isna(result[0])
                     assert result.dtype == orig.dtype
 
                 assert o.nunique() == 8
@@ -689,7 +689,7 @@ class TestIndexOps(Ops):
                 tm.assert_index_equal(unique, exp_idx)
             else:
                 tm.assert_numpy_array_equal(unique[:3], expected)
-                assert pd.isnull(unique[3])
+                assert pd.isna(unique[3])
 
             assert s.nunique() == 3
             assert s.nunique(dropna=False) == 4
diff --git a/pandas/tests/test_categorical.py b/pandas/tests/test_categorical.py
index 667b26c24..eecdd6720 100644
--- a/pandas/tests/test_categorical.py
+++ b/pandas/tests/test_categorical.py
@@ -19,7 +19,7 @@ import pandas as pd
 import pandas.compat as compat
 import pandas.util.testing as tm
 from pandas import (Categorical, Index, Series, DataFrame,
-                    Timestamp, CategoricalIndex, isnull,
+                    Timestamp, CategoricalIndex, isna,
                     date_range, DatetimeIndex,
                     period_range, PeriodIndex,
                     timedelta_range, TimedeltaIndex, NaT,
@@ -233,7 +233,7 @@ class TestCategorical(object):
         # the original type" feature to try to cast the array interface result
         # to...
 
-        # vals = np.asarray(cat[cat.notnull()])
+        # vals = np.asarray(cat[cat.notna()])
         # assert is_integer_dtype(vals)
 
         # corner cases
@@ -309,7 +309,7 @@ class TestCategorical(object):
                                                 categories=ci.categories))
 
     def test_constructor_with_generator(self):
-        # This was raising an Error in isnull(single_val).any() because isnull
+        # This was raising an Error in isna(single_val).any() because isna
         # returned a scalar for a generator
         xrange = range
 
@@ -606,7 +606,7 @@ class TestCategorical(object):
         cat = Categorical(labels, categories, fastpath=True)
         repr(cat)
 
-        tm.assert_numpy_array_equal(isnull(cat), labels == -1)
+        tm.assert_numpy_array_equal(isna(cat), labels == -1)
 
     def test_categories_none(self):
         factor = Categorical(['a', 'b', 'b', 'a',
@@ -1118,10 +1118,10 @@ Categories (3, object): [ああああ, いいいいい, ううううううう]""
         tm.assert_numpy_array_equal(c._codes, np.array([0, 1, -1, 0],
                                                        dtype=np.int8))
 
-    def test_isnull(self):
+    def test_isna(self):
         exp = np.array([False, False, True])
         c = Categorical(["a", "b", np.nan])
-        res = c.isnull()
+        res = c.isna()
 
         tm.assert_numpy_array_equal(res, exp)
 
@@ -2780,7 +2780,7 @@ Categories (10, timedelta64[ns]): [0 days 01:00:00 < 1 days 01:00:00 < 2 days 01
         df = DataFrame({'int64': np.random.randint(100, size=n)})
         df['category'] = Series(np.array(list('abcdefghij')).take(
             np.random.randint(0, 10, size=n))).astype('category')
-        df.isnull()
+        df.isna()
         buf = compat.StringIO()
         df.info(buf=buf)
 
diff --git a/pandas/tests/test_lib.py b/pandas/tests/test_lib.py
index 6be687e26..2662720bb 100644
--- a/pandas/tests/test_lib.py
+++ b/pandas/tests/test_lib.py
@@ -201,20 +201,20 @@ class TestIndexing(object):
         assert np.array_equal(result, expected)
 
 
-class TestNullObj(object):
+class TestNAObj(object):
 
-    _1d_methods = ['isnullobj', 'isnullobj_old']
-    _2d_methods = ['isnullobj2d', 'isnullobj2d_old']
+    _1d_methods = ['isnaobj', 'isnaobj_old']
+    _2d_methods = ['isnaobj2d', 'isnaobj2d_old']
 
     def _check_behavior(self, arr, expected):
-        for method in TestNullObj._1d_methods:
+        for method in TestNAObj._1d_methods:
             result = getattr(lib, method)(arr)
             tm.assert_numpy_array_equal(result, expected)
 
         arr = np.atleast_2d(arr)
         expected = np.atleast_2d(expected)
 
-        for method in TestNullObj._2d_methods:
+        for method in TestNAObj._2d_methods:
             result = getattr(lib, method)(arr)
             tm.assert_numpy_array_equal(result, expected)
 
@@ -237,7 +237,7 @@ class TestNullObj(object):
         self._check_behavior(arr, expected)
 
     def test_empty_str_inp(self):
-        arr = np.array([""])  # empty but not null
+        arr = np.array([""])  # empty but not na
         expected = np.array([False])
 
         self._check_behavior(arr, expected)
diff --git a/pandas/tests/test_multilevel.py b/pandas/tests/test_multilevel.py
index a56ff0fc2..0b2dc9ba7 100644
--- a/pandas/tests/test_multilevel.py
+++ b/pandas/tests/test_multilevel.py
@@ -10,7 +10,7 @@ from numpy.random import randn
 import numpy as np
 
 from pandas.core.index import Index, MultiIndex
-from pandas import Panel, DataFrame, Series, notnull, isnull, Timestamp
+from pandas import Panel, DataFrame, Series, notna, isna, Timestamp
 
 from pandas.core.dtypes.common import is_float_dtype, is_integer_dtype
 import pandas.core.common as com
@@ -287,12 +287,12 @@ class TestMultiLevel(Base):
         s = self.ymd['A']
 
         s[2000, 3] = np.nan
-        assert isnull(s.values[42:65]).all()
-        assert notnull(s.values[:42]).all()
-        assert notnull(s.values[65:]).all()
+        assert isna(s.values[42:65]).all()
+        assert notna(s.values[:42]).all()
+        assert notna(s.values[65:]).all()
 
         s[2000, 3, 10] = np.nan
-        assert isnull(s[49])
+        assert isna(s[49])
 
     def test_series_slice_partial(self):
         pass
@@ -1902,7 +1902,7 @@ Thur,Lunch,Yes,51.51,17"""
         df = DataFrame([[1, 2], [3, 4], [5, 6]], index=mix)
         s = Series({(1, 1): 1, (1, 2): 2})
         df['new'] = s
-        assert df['new'].isnull().all()
+        assert df['new'].isna().all()
 
     def test_join_segfault(self):
         # 1532
@@ -2014,8 +2014,8 @@ Thur,Lunch,Yes,51.51,17"""
                            labels=[[1, 1, 1, 1, -1, 0, 0, 0], [0, 1, 2, 3, 0,
                                                                1, 2, 3]])
 
-        assert isnull(index[4][0])
-        assert isnull(index.values[4][0])
+        assert isna(index[4][0])
+        assert isna(index.values[4][0])
 
     def test_duplicate_groupby_issues(self):
         idx_tp = [('600809', '20061231'), ('600809', '20070331'),
diff --git a/pandas/tests/test_nanops.py b/pandas/tests/test_nanops.py
index 6798e64b0..2a22fc9d3 100644
--- a/pandas/tests/test_nanops.py
+++ b/pandas/tests/test_nanops.py
@@ -8,7 +8,7 @@ import warnings
 import numpy as np
 
 import pandas as pd
-from pandas import Series, isnull, _np_version_under1p9
+from pandas import Series, isna, _np_version_under1p9
 from pandas.core.dtypes.common import is_integer_dtype
 import pandas.core.nanops as nanops
 import pandas.util.testing as tm
@@ -408,7 +408,7 @@ class TestnanopsDataFrame(object):
     def _argminmax_wrap(self, value, axis=None, func=None):
         res = func(value, axis)
         nans = np.min(value, axis)
-        nullnan = isnull(nans)
+        nullnan = isna(nans)
         if res.ndim:
             res[nullnan] = -1
         elif (hasattr(nullnan, 'all') and nullnan.all() or
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index 445611c16..a6113f231 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -11,7 +11,7 @@ import pandas as pd
 
 from pandas.core.dtypes.common import is_float_dtype
 from pandas.core.dtypes.missing import remove_na_arraylike
-from pandas import (Series, DataFrame, Index, date_range, isnull, notnull,
+from pandas import (Series, DataFrame, Index, date_range, isna, notna,
                     pivot, MultiIndex)
 from pandas.core.nanops import nanall, nanany
 from pandas.core.panel import Panel
@@ -79,7 +79,7 @@ class SafeForLongAndSparse(object):
         tm.equalContents(list(self.panel), self.panel.items)
 
     def test_count(self):
-        f = lambda s: notnull(s).sum()
+        f = lambda s: notna(s).sum()
         self._check_stat_op('count', f, obj=self.panel, has_skipna=False)
 
     def test_sum(self):
@@ -93,7 +93,7 @@ class SafeForLongAndSparse(object):
 
     def test_median(self):
         def wrapper(x):
-            if isnull(x).any():
+            if isna(x).any():
                 return np.nan
             return np.median(x)
 
@@ -540,12 +540,12 @@ class CheckIndexing(object):
             df2 = DataFrame([1.0, np.nan, 1.0, np.nan, 1.0, 1.0])
             panel = Panel({'Item1': df1, 'Item2': df2})
 
-            newminor = notnull(panel.iloc[:, :, 0])
+            newminor = notna(panel.iloc[:, :, 0])
             panel.loc[:, :, 'NewMinor'] = newminor
             assert_frame_equal(panel.loc[:, :, 'NewMinor'],
                                newminor.astype(object))
 
-            newmajor = notnull(panel.iloc[:, 0, :])
+            newmajor = notna(panel.iloc[:, 0, :])
             panel.loc[:, 'NewMajor', :] = newmajor
             assert_frame_equal(panel.loc[:, 'NewMajor', :],
                                newmajor.astype(object))
@@ -1694,7 +1694,7 @@ class TestPanel(PanelTests, CheckIndexing, SafeForLongAndSparse,
             assert_panel_equal(result, expected)
 
             panel.values[0, 1, 1] = np.nan
-            assert notnull(result.values[1, 0, 1])
+            assert notna(result.values[1, 0, 1])
 
     def test_to_frame(self):
         with catch_warnings(record=True):
@@ -1863,7 +1863,7 @@ class TestPanel(PanelTests, CheckIndexing, SafeForLongAndSparse,
                                   [0, 1, 2, 3, 4, 5, 2, 3, 4, 5]])
 
             panel = df.to_panel()
-            assert isnull(panel[0].loc[1, [0, 1]]).all()
+            assert isna(panel[0].loc[1, [0, 1]]).all()
 
     def test_to_panel_duplicates(self):
         # #2441
diff --git a/pandas/tests/test_panel4d.py b/pandas/tests/test_panel4d.py
index 18643aff1..863671feb 100644
--- a/pandas/tests/test_panel4d.py
+++ b/pandas/tests/test_panel4d.py
@@ -6,9 +6,9 @@ import pytest
 from warnings import catch_warnings
 import numpy as np
 
+from pandas import Series, Index, isna, notna
 from pandas.core.dtypes.common import is_float_dtype
 from pandas.core.dtypes.missing import remove_na_arraylike
-from pandas import Series, Index, isnull, notnull
 from pandas.core.panel import Panel
 from pandas.core.panel4d import Panel4D
 from pandas.tseries.offsets import BDay
@@ -33,7 +33,7 @@ class SafeForLongAndSparse(object):
         tm.equalContents(list(self.panel4d), self.panel4d.labels)
 
     def test_count(self):
-        f = lambda s: notnull(s).sum()
+        f = lambda s: notna(s).sum()
         self._check_stat_op('count', f, obj=self.panel4d, has_skipna=False)
 
     def test_sum(self):
@@ -47,7 +47,7 @@ class SafeForLongAndSparse(object):
 
     def test_median(self):
         def wrapper(x):
-            if isnull(x).any():
+            if isna(x).any():
                 return np.nan
             return np.median(x)
 
diff --git a/pandas/tests/test_resample.py b/pandas/tests/test_resample.py
index 15bbd7a9e..08fa7992e 100644
--- a/pandas/tests/test_resample.py
+++ b/pandas/tests/test_resample.py
@@ -13,8 +13,8 @@ import numpy as np
 import pandas as pd
 import pandas.tseries.offsets as offsets
 import pandas.util.testing as tm
-from pandas import (Series, DataFrame, Panel, Index, isnull,
-                    notnull, Timestamp)
+from pandas import (Series, DataFrame, Panel, Index, isna,
+                    notna, Timestamp)
 
 from pandas.core.dtypes.generic import ABCSeries, ABCDataFrame
 from pandas.compat import range, lrange, zip, product, OrderedDict
@@ -103,7 +103,7 @@ class TestResampleAPI(object):
             tm.assert_frame_equal(result, expected)
 
         # compat for pandas-like methods
-        for how in ['sort_values', 'isnull']:
+        for how in ['sort_values', 'isna']:
             with tm.assert_produces_warning(FutureWarning,
                                             check_stacklevel=False):
                 getattr(r, how)()
@@ -891,7 +891,7 @@ class TestDatetimeIndex(Base):
             g._cython_agg_general(f)
 
         assert g.ngroups == 2593
-        assert notnull(g.mean()).all()
+        assert notna(g.mean()).all()
 
         # construct expected val
         arr = [1] + [5] * 2592
@@ -948,7 +948,7 @@ class TestDatetimeIndex(Base):
         args = downsample_methods
 
         def _ohlc(group):
-            if isnull(group).all():
+            if isna(group).all():
                 return np.repeat(np.nan, 4)
             return [group[0], group.max(), group.min(), group[-1]]
 
@@ -1445,7 +1445,7 @@ class TestDatetimeIndex(Base):
 
     def test_ohlc_5min(self):
         def _ohlc(group):
-            if isnull(group).all():
+            if isna(group).all():
                 return np.repeat(np.nan, 4)
             return [group[0], group.max(), group.min(), group[-1]]
 
@@ -2606,7 +2606,7 @@ class TestPeriodIndex(Base):
 
         result = ts.resample('W-THU').asfreq()
 
-        assert result.isnull().all()
+        assert result.isna().all()
 
         result = ts.resample('W-THU').asfreq().ffill()[:-1]
         expected = ts.asfreq('W-THU').ffill()
diff --git a/pandas/tests/test_sorting.py b/pandas/tests/test_sorting.py
index f6973cccb..e58042961 100644
--- a/pandas/tests/test_sorting.py
+++ b/pandas/tests/test_sorting.py
@@ -305,9 +305,9 @@ class TestMerge(object):
         out = DataFrame(vals, columns=list('ABCDEFG') + ['left', 'right'])
         out = align(out)
 
-        jmask = {'left': out['left'].notnull(),
-                 'right': out['right'].notnull(),
-                 'inner': out['left'].notnull() & out['right'].notnull(),
+        jmask = {'left': out['left'].notna(),
+                 'right': out['right'].notna(),
+                 'inner': out['left'].notna() & out['right'].notna(),
                  'outer': np.ones(len(out), dtype='bool')}
 
         for how in 'left', 'right', 'outer', 'inner':
diff --git a/pandas/tests/test_strings.py b/pandas/tests/test_strings.py
index bb31fb926..ec2b0b75b 100644
--- a/pandas/tests/test_strings.py
+++ b/pandas/tests/test_strings.py
@@ -11,7 +11,7 @@ from numpy.random import randint
 
 from pandas.compat import range, u
 import pandas.compat as compat
-from pandas import (Index, Series, DataFrame, isnull, MultiIndex, notnull)
+from pandas import Index, Series, DataFrame, isna, MultiIndex, notna
 
 from pandas.util.testing import assert_series_equal
 import pandas.util.testing as tm
@@ -49,7 +49,7 @@ class TestStringMethods(object):
 
             for el in s:
                 # each element of the series is either a basestring/str or nan
-                assert isinstance(el, compat.string_types) or isnull(el)
+                assert isinstance(el, compat.string_types) or isna(el)
 
         # desired behavior is to iterate until everything would be nan on the
         # next iter so make sure the last element of the iterator was 'l' in
@@ -1413,7 +1413,7 @@ class TestStringMethods(object):
         values = Series(['foo', 'fooo', 'fooooo', np.nan, 'fooooooo'])
 
         result = values.str.len()
-        exp = values.map(lambda x: len(x) if notnull(x) else NA)
+        exp = values.map(lambda x: len(x) if notna(x) else NA)
         tm.assert_series_equal(result, exp)
 
         # mixed
@@ -1431,7 +1431,7 @@ class TestStringMethods(object):
             'fooooooo')])
 
         result = values.str.len()
-        exp = values.map(lambda x: len(x) if notnull(x) else NA)
+        exp = values.map(lambda x: len(x) if notna(x) else NA)
         tm.assert_series_equal(result, exp)
 
     def test_findall(self):
@@ -2281,7 +2281,7 @@ class TestStringMethods(object):
                                   (3, 0, -1)]:
             try:
                 result = values.str.slice(start, stop, step)
-                expected = Series([s[start:stop:step] if not isnull(s) else NA
+                expected = Series([s[start:stop:step] if not isna(s) else NA
                                    for s in values])
                 tm.assert_series_equal(result, expected)
             except:
diff --git a/pandas/tests/test_window.py b/pandas/tests/test_window.py
index dd35e4375..5ab33bd6c 100644
--- a/pandas/tests/test_window.py
+++ b/pandas/tests/test_window.py
@@ -10,8 +10,8 @@ import numpy as np
 from distutils.version import LooseVersion
 
 import pandas as pd
-from pandas import (Series, DataFrame, bdate_range, isnull,
-                    notnull, concat, Timestamp, Index)
+from pandas import (Series, DataFrame, bdate_range, isna,
+                    notna, concat, Timestamp, Index)
 import pandas.stats.moments as mom
 import pandas.core.window as rwindow
 import pandas.tseries.offsets as offsets
@@ -249,7 +249,7 @@ class TestApi(Base):
         tm.assert_frame_equal(result, expected)
 
         result = df.rolling(1).count()
-        expected = df.notnull().astype(float)
+        expected = df.notna().astype(float)
         tm.assert_frame_equal(result, expected)
 
     def test_window_with_args(self):
@@ -1223,7 +1223,7 @@ class TestMoments(Base):
         # it works!
         with catch_warnings(record=True):
             result = mom.rolling_apply(arr, 10, np.sum)
-        assert isnull(result).all()
+        assert isna(result).all()
 
         with catch_warnings(record=True):
             result = mom.rolling_apply(arr, 10, np.sum, min_periods=1)
@@ -1384,8 +1384,8 @@ class TestMoments(Base):
 
             arr2 = randn(20)
             result = get_result(arr2, 10, min_periods=5)
-            assert isnull(result[3])
-            assert notnull(result[4])
+            assert isna(result[3])
+            assert notna(result[4])
 
             # min_periods=0
             result0 = get_result(arr, 20, min_periods=0)
@@ -1974,10 +1974,10 @@ def _create_consistency_data():
 
     def is_constant(x):
         values = x.values.ravel()
-        return len(set(values[notnull(values)])) == 1
+        return len(set(values[notna(values)])) == 1
 
     def no_nans(x):
-        return x.notnull().all().all()
+        return x.notna().all().all()
 
     # data is a tuple(object, is_contant, no_nans)
     data = create_series() + create_dataframes()
@@ -2047,7 +2047,7 @@ class TestMomentsConsistency(Base):
                                   var_debiasing_factors=None):
         def _non_null_values(x):
             values = x.values.ravel()
-            return set(values[notnull(values)].tolist())
+            return set(values[notna(values)].tolist())
 
         for (x, is_constant, no_nans) in self.data:
             count_x = count(x)
@@ -2119,7 +2119,7 @@ class TestMomentsConsistency(Base):
 
                 if isinstance(x, Series):
                     for (y, is_constant, no_nans) in self.data:
-                        if not x.isnull().equals(y.isnull()):
+                        if not x.isna().equals(y.isna()):
                             # can only easily test two Series with similar
                             # structure
                             continue
@@ -2172,8 +2172,8 @@ class TestMomentsConsistency(Base):
             w = Series(np.nan, index=s.index)
             alpha = 1. / (1. + com)
             if ignore_na:
-                w[s.notnull()] = _weights(s[s.notnull()], com=com,
-                                          adjust=adjust, ignore_na=False)
+                w[s.notna()] = _weights(s[s.notna()], com=com,
+                                        adjust=adjust, ignore_na=False)
             elif adjust:
                 for i in range(len(s)):
                     if s.iat[i] == s.iat[i]:
@@ -2975,8 +2975,8 @@ class TestMomentsConsistency(Base):
 
             arr2 = randn(20)
             result = func(arr2, min_periods=5)
-            assert isnull(result[3])
-            assert notnull(result[4])
+            assert isna(result[3])
+            assert notna(result[4])
 
             # min_periods=0
             result0 = func(arr, min_periods=0)
diff --git a/pandas/tests/tseries/test_timezones.py b/pandas/tests/tseries/test_timezones.py
index c034a9c60..a9ecfd797 100644
--- a/pandas/tests/tseries/test_timezones.py
+++ b/pandas/tests/tseries/test_timezones.py
@@ -18,7 +18,7 @@ from pandas.compat import lrange, zip
 from pandas.core.indexes.datetimes import bdate_range, date_range
 from pandas.core.dtypes.dtypes import DatetimeTZDtype
 from pandas._libs import tslib
-from pandas import (Index, Series, DataFrame, isnull, Timestamp, NaT,
+from pandas import (Index, Series, DataFrame, isna, Timestamp, NaT,
                     DatetimeIndex, to_datetime)
 from pandas.util.testing import (assert_frame_equal, assert_series_equal,
                                  set_timezone)
@@ -931,7 +931,7 @@ class TestTimeZoneSupportPytz(object):
         idx = to_datetime([Timestamp("2013-1-1", tz=self.tzstr('US/Eastern')),
                            NaT])
 
-        assert isnull(idx[1])
+        assert isna(idx[1])
         assert idx[0].tzinfo is not None
 
 
diff --git a/pandas/util/__init__.py b/pandas/util/__init__.py
index e86af930f..202e58c91 100644
--- a/pandas/util/__init__.py
+++ b/pandas/util/__init__.py
@@ -1,2 +1,2 @@
-from pandas.core.util.hashing import hash_pandas_object, hash_array   # noqa
 from pandas.util._decorators import Appender, Substitution, cache_readonly  # noqa
+from pandas.core.util.hashing import hash_pandas_object, hash_array   # noqa
diff --git a/pandas/util/_decorators.py b/pandas/util/_decorators.py
index 772b206f8..e406698fa 100644
--- a/pandas/util/_decorators.py
+++ b/pandas/util/_decorators.py
@@ -6,12 +6,30 @@ from textwrap import dedent
 from functools import wraps, update_wrapper
 
 
-def deprecate(name, alternative, alt_name=None):
+def deprecate(name, alternative, alt_name=None, klass=None,
+              stacklevel=2):
+    """
+
+    Return a new function that emits a deprecation warning on use
+
+    Parameters
+    ----------
+    name : str
+        Name of function to deprecate
+    alternative : str
+        Name of function to use instead
+    alt_name : str, optional
+        Name to use in preference of alternative.__name__
+    klass : Warning, default FutureWarning
+    stacklevel : int, default 2
+
+    """
     alt_name = alt_name or alternative.__name__
+    klass = klass or FutureWarning
 
     def wrapper(*args, **kwargs):
         warnings.warn("%s is deprecated. Use %s instead" % (name, alt_name),
-                      FutureWarning, stacklevel=2)
+                      klass, stacklevel=stacklevel)
         return alternative(*args, **kwargs)
     return wrapper
 
