commit 32c65bddce5dcd1a736590a3cc7be913a68b8579
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Nov 6 17:57:41 2011 -0500

    ENH: add Series.mad, refactor Series/DataFrame stat methods, fix GH #337 and cleanup from PR #313

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 95436c676..b96c0728e 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -882,7 +882,7 @@ class DataFrame(NDFrame):
         if mask.dtype != np.bool_:
             raise ValueError('Must pass DataFrame with boolean values only')
 
-        if self._data.is_mixed_dtype():
+        if self._is_mixed_type:
             raise ValueError('Cannot do boolean setting on mixed-type frame')
 
         if isinstance(value, DataFrame):
@@ -2026,7 +2026,7 @@ class DataFrame(NDFrame):
             else:
                 return self._apply_broadcast(func, axis)
 
-    def _apply_standard(self, func, axis):
+    def _apply_standard(self, func, axis, ignore_failures=False):
         if axis == 0:
             series_gen = ((c, self[c]) for c in self.columns)
             res_index = self.columns
@@ -2038,8 +2038,20 @@ class DataFrame(NDFrame):
                           for i, v in izip(self.index, self.values))
 
         results = {}
-        for k, v in series_gen:
-            results[k] = func(v)
+        if ignore_failures:
+            successes = []
+            for i, (k, v) in enumerate(series_gen):
+                try:
+                    results[k] = func(v)
+                    successes.append(i)
+                except Exception:
+                    pass
+            # so will work with MultiIndex, need test
+            if len(successes) < len(res_index):
+                res_index = res_index.take(successes)
+        else:
+            for k, v in series_gen:
+                results[k] = func(v)
 
         if hasattr(results.values()[0], '__iter__'):
             result = self._constructor(data=results, index=res_columns,
@@ -2470,10 +2482,10 @@ class DataFrame(NDFrame):
 
         return DataFrame(result, index=index, columns=columns)
 
-    def sum(self, axis=0, numeric_only=False, skipna=True, level=None):
-        if not level is None:
-            sumfunc = lambda x: x.sum(skipna=skipna)
-            return self.groupby(level=level).aggregate(sumfunc)
+    def sum(self, axis=0, numeric_only=True, skipna=True, level=None):
+        if level is not None:
+            return self._agg_by_level('sum', axis=axis, level=level,
+                                      skipna=skipna)
 
         y, axis_labels = self._get_agg_data(axis, numeric_only=numeric_only)
 
@@ -2485,9 +2497,8 @@ class DataFrame(NDFrame):
         else:
             mask = np.isfinite(y)
 
-            if skipna:
-                if not issubclass(y.dtype.type, np.integer):
-                    np.putmask(y, -mask, 0)
+            if skipna and not issubclass(y.dtype.type, np.integer):
+                np.putmask(y, -mask, 0)
 
             the_sum = y.sum(axis)
             the_count = mask.sum(axis)
@@ -2500,119 +2511,106 @@ class DataFrame(NDFrame):
     _add_stat_doc(sum, 'sum', 'sum', extras=_numeric_only_doc)
 
     def min(self, axis=0, skipna=True, level=None):
-        values = self.values.copy()
+        if level is not None:
+            return self._agg_by_level('min', axis=axis, level=level,
+                                      skipna=skipna)
+
+        values, axis_labels = self._get_agg_data(axis, numeric_only=True)
+
         if skipna and not issubclass(values.dtype.type, np.integer):
             np.putmask(values, -np.isfinite(values), np.inf)
 
-        if not level is None:
-            minfunc = lambda x: x.min(skipna=skipna)
-            return self.groupby(level=level).aggregate(minfunc)
-
-        return Series(values.min(axis), index=self._get_agg_axis(axis))
+        return Series(values.min(axis), index=axis_labels)
     _add_stat_doc(min, 'minimum', 'min')
 
     def max(self, axis=0, skipna=True, level=None):
-        values = self.values.copy()
+        if level is not None:
+            return self._agg_by_level('max', axis=axis, level=level,
+                                      skipna=skipna)
+
+        values, axis_labels = self._get_agg_data(axis, numeric_only=True)
         if skipna and not issubclass(values.dtype.type, np.integer):
             np.putmask(values, -np.isfinite(values), -np.inf)
 
-        if not level is None:
-            maxfunc = lambda x: x.max(skipna=skipna)
-            return self.groupby(level=level).aggregate(maxfunc)
-
-        return Series(values.max(axis), index=self._get_agg_axis(axis))
+        return Series(values.max(axis), index=axis_labels)
     _add_stat_doc(max, 'maximum', 'max')
 
     def prod(self, axis=0, skipna=True, level=None):
-        if not level is None:
-            prodfunc = lambda x: x.prod(skipna=skipna)
-            return self.groupby(level=level).aggregate(prodfunc)
+        if level is not None:
+            return self._agg_by_level('prod', axis=axis, level=level,
+                                      skipna=skipna)
 
-        y = np.array(self.values, subok=True)
-        if skipna:
-            if not issubclass(y.dtype.type, np.integer):
-                y[np.isnan(y)] = 1
-        result = y.prod(axis)
-        count = self.count(axis)
+        values, axis_labels = self._get_agg_data(axis, numeric_only=True)
+
+        if skipna and not issubclass(values.dtype.type, np.integer):
+            values[np.isnan(values)] = 1
+        result = values.prod(axis)
+        count = self.count(axis, numeric_only=True)
         result[count == 0] = nan
 
-        return Series(result, index=self._get_agg_axis(axis))
+        return Series(result, index=axis_labels)
     _add_stat_doc(prod, 'product', 'product',
                   na_action='NA/null values are treated as 1')
     product = prod
 
     def mean(self, axis=0, skipna=True, level=None):
-        if not level is None:
-            meanfunc = lambda x: x.mean(skipna=skipna)
-            return self.groupby(level=level).aggregate(meanfunc)
+        if level is not None:
+            return self._agg_by_level('mean', axis=axis, level=level,
+                                      skipna=skipna)
 
         summed = self.sum(axis, numeric_only=True, skipna=skipna)
         count = self.count(axis, numeric_only=True).astype(float)
         return summed / count
     _add_stat_doc(mean, 'mean', 'mean')
 
-    def quantile(self, q=0.5, axis=0):
-        """
-        Return values at the given quantile over requested axis, a la
-        scoreatpercentile in scipy.stats
+    def median(self, axis=0, skipna=True, level=None):
+        if level is not None:
+            return self._agg_by_level('median', axis=axis, level=level,
+                                      skipna=skipna)
 
-        Parameters
-        ----------
-        q : quantile, default 0.5 (50% quantile)
-            0 <= q <= 1
-        axis : {0, 1}
-            0 for row-wise, 1 for column-wise
+        frame = self._get_numeric_frame()
 
-        Returns
-        -------
-        quantiles : Series
-        """
-        from scipy.stats import scoreatpercentile
-        per = q * 100
+        if axis == 0:
+            values = frame.values.T
+            result_index = frame.columns
+        elif axis == 1:
+            values = frame.values
+            result_index = self.index
+        else:
+            raise ValueError('axis must be in {0, 1}')
 
-        def f(arr):
-            arr = arr.values
-            if arr.dtype != np.float_:
-                arr = arr.astype(float)
-            arr = arr[notnull(arr)]
-            if len(arr) == 0:
-                return nan
-            else:
-                return scoreatpercentile(arr, per)
+        def get_median(x):
+            mask = notnull(x)
+            if not skipna and not mask.all():
+                return np.nan
+            return lib.median(x[mask])
 
-        return self.apply(f, axis=axis)
+        if values.dtype != np.float64:
+            values = values.astype('f8')
 
-    def median(self, axis=0, skipna=True, level=None):
-        if not level is None:
-            medianfunc = lambda x: x.median(skipna=skipna)
-            return self.groupby(level=level).aggregate(medianfunc)
+        medians = [get_median(arr) for arr in values]
+        return Series(medians, index=result_index)
 
-        if axis == 0:
-            med = [self[col].median(skipna=skipna) for col in self.columns]
-            return Series(med, index=self.columns)
-        elif axis == 1:
-            med = [self.xs(k).median(skipna=skipna) for k in self.index]
-            return Series(med, index=self.index)
-        else:
-            raise Exception('Must have 0<= axis <= 1')
     _add_stat_doc(median, 'median', 'median')
 
     def mad(self, axis=0, skipna=True, level=None):
-        if not level is None:
-            madfunc = lambda x: x.mad(skipna=skipna)
-            return self.groupby(level=level).aggregate(madfunc)
+        if level is not None:
+            return self._agg_by_level('mad', axis=axis, level=level,
+                                      skipna=skipna)
+
+        frame = self._get_numeric_frame()
 
         if axis == 0:
-            demeaned = self - self.mean(axis=0)
+            demeaned = frame - frame.mean(axis=0)
         else:
-            demeaned = self.sub(self.mean(axis=1), axis=0)
+            demeaned = frame.sub(frame.mean(axis=1), axis=0)
         return np.abs(demeaned).mean(axis=axis, skipna=skipna)
     _add_stat_doc(mad, 'mean absolute deviation', 'mad')
 
     def var(self, axis=0, skipna=True, level=None):
-        if not level is None:
-            varfunc = lambda x: x.var(skipna=skipna)
-            return self.groupby(level=level).aggregate(varfunc)
+        if level is not None:
+            return self._agg_by_level('var', axis=axis, level=level,
+                                      skipna=skipna)
 
         y, axis_labels = self._get_agg_data(axis, numeric_only=True)
 
@@ -2631,17 +2629,17 @@ class DataFrame(NDFrame):
     _add_stat_doc(var, 'unbiased variance', 'var')
 
     def std(self, axis=0, skipna=True, level=None):
-        if not level is None:
-            stdfunc = lambda x: x.std(skipna=skipna)
-            return self.groupby(level=level).aggregate(stdfunc)
+        if level is not None:
+            return self._agg_by_level('std', axis=axis, level=level,
+                                      skipna=skipna)
 
         return np.sqrt(self.var(axis=axis, skipna=skipna))
     _add_stat_doc(std, 'unbiased standard deviation', 'std')
 
     def skew(self, axis=0, skipna=True, level=None):
-        if not level is None:
-            skewfunc = lambda x: x.skew(skipna=skipna)
-            return self.groupby(level=level).aggregate(skewfunc)
+        if level is not None:
+            return self._agg_by_level('skew', axis=axis, level=level,
+                                      skipna=skipna)
 
         y, axis_labels = self._get_agg_data(axis, numeric_only=True)
 
@@ -2667,6 +2665,17 @@ class DataFrame(NDFrame):
         return Series(result, index=axis_labels)
     _add_stat_doc(skew, 'unbiased skewness', 'skew')
 
+    def _get_numeric_frame(self):
+        frame = self
+        if self._is_mixed_type:
+            frame = self.ix[:, self._get_numeric_columns()]
+        return frame
+
+    def _agg_by_level(self, name, axis=0, level=0, skipna=True):
+        method = getattr(type(self), name)
+        applyf = lambda x: method(x, axis=axis, skipna=skipna)
+        return self.groupby(level=level, axis=axis).aggregate(applyf)
+
     def _get_agg_data(self, axis, numeric_only=True, copy=True):
         num_cols = self._get_numeric_columns()
 
@@ -2711,6 +2720,37 @@ class DataFrame(NDFrame):
             else:
                 return self.ix[:, []]
 
+    def quantile(self, q=0.5, axis=0):
+        """
+        Return values at the given quantile over requested axis, a la
+        scoreatpercentile in scipy.stats
+
+        Parameters
+        ----------
+        q : quantile, default 0.5 (50% quantile)
+            0 <= q <= 1
+        axis : {0, 1}
+            0 for row-wise, 1 for column-wise
+
+        Returns
+        -------
+        quantiles : Series
+        """
+        from scipy.stats import scoreatpercentile
+        per = q * 100
+
+        def f(arr):
+            arr = arr.values
+            if arr.dtype != np.float_:
+                arr = arr.astype(float)
+            arr = arr[notnull(arr)]
+            if len(arr) == 0:
+                return nan
+            else:
+                return scoreatpercentile(arr, per)
+
+        return self.apply(f, axis=axis)
+
     def clip(self, upper=None, lower=None):
         """
         Trim values at input threshold(s)
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index bb2b0f005..ddb3a4398 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -171,9 +171,21 @@ class GroupBy(object):
         f = getattr(type(self.obj), name)
 
         def wrapper(*args, **kwargs):
+            # a little trickery for aggregation functions that need an axis
+            # argument
+            kwargs_with_axis = kwargs.copy()
+            if 'axis' not in kwargs_with_axis:
+                kwargs_with_axis['axis'] = self.axis
+
+            def curried_with_axis(x):
+                return f(x, *args, **kwargs_with_axis)
             def curried(x):
                 return f(x, *args, **kwargs)
-            return self.apply(curried)
+
+            try:
+                return self.apply(curried_with_axis)
+            except Exception:
+                return self.apply(curried)
 
         return wrapper
 
@@ -212,16 +224,6 @@ class GroupBy(object):
                 yield it
 
     def _multi_iter(self):
-        # This is slower
-        # groups = self.indices.keys()
-        # try:
-        #     groups = sorted(groups)
-        # except Exception: # pragma: no cover
-        #     pass
-
-        # for key in groups:
-        #     yield key, self.get_group(key)
-
         tipo = type(self.obj)
         data = self.obj
         if (isinstance(self.obj, NDFrame) and
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 95e42b108..09734ebe0 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -85,6 +85,34 @@ def _flex_method(op, name):
     f.__name__ = name
     return f
 
+_stat_doc = """
+Return %(name)s  of values
+%(na_action)s
+
+Parameters
+----------
+skipna : boolean, default True
+    Exclude NA/null values
+level : int, default None
+    If the axis is a MultiIndex (hierarchical), count along a
+    particular level, collapsing into a smaller Series
+%(extras)s
+Returns
+-------
+%(shortname)s : float (or Series if level specified)
+"""
+_doc_exclude_na = "NA/null values are excluded"
+_doc_ndarray_interface = ("Extra parameters are to preserve ndarray"
+                          "interface.\n")
+
+def _add_stat_doc(f, name, shortname, na_action=_doc_exclude_na,
+                  extras=''):
+    doc = _stat_doc % {'name' : name,
+                       'shortname' : shortname,
+                       'na_action' : na_action,
+                       'extras' : extras}
+    f.__doc__ = doc
+
 #-------------------------------------------------------------------------------
 # Series class
 
@@ -558,9 +586,15 @@ copy : boolean, default False
         """
         Return number of non-NA/null observations in the Series
 
+        Parameters
+        ----------
+        level : int, default None
+            If the axis is a MultiIndex (hierarchical), count along a
+            particular level, collapsing into a smaller Series
+
         Returns
         -------
-        nobs : int
+        nobs : int or Series (if level specified)
         """
         if level is not None:
             return self._count_level(level)
@@ -598,24 +632,8 @@ copy : boolean, default False
         return Series(counter).order(ascending=False)
 
     def sum(self, axis=0, dtype=None, out=None, skipna=True, level=None):
-        """
-        Sum of values
-
-        Parameters
-        ----------
-        skipna : boolean, default True
-            Exclude NA/null values
-        level : int, default None
-            If the axis is a MultiIndex (hierarchical), count along a
-            particular level, collapsing into a smaller Series
-
-        Returns
-        -------
-        sum : float (or Series if level specified)
-        """
         if level is not None:
-            sumfunc = lambda x: x.sum(dtype=dtype,skipna=skipna)
-            return self.groupby(level=level).aggregate(sumfunc)
+            return self._agg_by_level('sum', level=level, skipna=skipna)
 
         values = self.values.copy()
 
@@ -626,45 +644,27 @@ copy : boolean, default False
             np.putmask(values, mask, 0)
 
         return values.sum()
+    _add_stat_doc(sum, 'sum', 'sum', extras=_doc_ndarray_interface)
 
     def mean(self, axis=0, dtype=None, out=None, skipna=True, level=None):
-        """
-        Mean of values
+        if level is not None:
+            return self._agg_by_level('mean', level=level, skipna=skipna)
 
-        Parameters
-        ----------
-        skipna : boolean, default True
-            Exclude NA/null values
-        level : int, default None
-            If the axis is a MultiIndex (hierarchical), count along a
-            particular level, collapsing into a smaller Series
+        return self._ndarray_statistic('mean', dtype=dtype, skipna=skipna)
+    _add_stat_doc(mean, 'mean', 'mean', extras=_doc_ndarray_interface)
 
-        Returns
-        -------
-        mean : float (or Series if level specified)
-        """
-        if level is None:
-            return self._ndarray_statistic('mean', dtype=dtype, skipna=skipna)
+    def mad(self, skipna=True, level=None):
+        if level is not None:
+            return self._agg_by_level('mad', level=level, skipna=skipna)
 
-        meanfunc = lambda x: x.mean(dtype=dtype,skipna=skipna)
-        return self.groupby(level=level).aggregate(meanfunc)
+        demeaned = self - self.mean(skipna=skipna)
+        return np.abs(demeaned).mean(skipna=skipna)
+    _add_stat_doc(mad, 'mean absolute deviation', 'mad')
 
     def median(self, skipna=True, level=None):
-        """
-        Compute median of values
-
-        Parameters
-        ----------
-        skipna : boolean, default True
-            Exclude NA/null values
-        level : int, default None
-            If the axis is a MultiIndex (hierarchical), count along a
-            particular level, collapsing into a smaller Series
+        if level is not None:
+            return self._agg_by_level('median', level=level, skipna=skipna)
 
-        Returns
-        -------
-        median : float (or Series if level specified)
-        """
         arr = self.values
         if arr.dtype != np.float_:
             arr = arr.astype(float)
@@ -676,112 +676,46 @@ copy : boolean, default False
             if not mask.all():
                 return np.nan
 
-        if level is None:
-            return lib.median(arr)
-
-        medianfunc = lambda x: x.median(skipna=skipna)
-        return self.groupby(level=level).aggregate(medianfunc)
+        return lib.median(arr)
+    _add_stat_doc(median, 'median', 'median')
 
     def prod(self, axis=0, dtype=None, out=None, skipna=True, level=None):
-        """
-        Product of all values
-
-        Parameters
-        ----------
-        skipna : boolean, default True
-            Exclude NA/null values
-        level : int, default None
-            If the axis is a MultiIndex (hierarchical), count along a
-            particular level, collapsing into a smaller Series
-
-        Returns
-        -------
-        product : float (or Series if level specified)
-        """
-        if level is None:
-            return self._ndarray_statistic('prod', dtype=dtype, skipna=skipna)
+        if level is not None:
+            return self._agg_by_level('prod', level=level, skipna=skipna)
 
-        prodfunc = lambda x: x.prod(dtype=dtype,skipna=skipna)
-        return self.groupby(level=level).aggregate(prodfunc)
+        return self._ndarray_statistic('prod', dtype=dtype, skipna=skipna)
+    _add_stat_doc(prod, 'product', 'product')
 
     def min(self, axis=None, out=None, skipna=True, level=None):
-        """
-        Minimum of values
-
-        Parameters
-        ----------
-        skipna : boolean, default True
-            Exclude NA/null values
-        level : int, default None
-            If the axis is a MultiIndex (hierarchical), count along a
-            particular level, collapsing into a smaller Series
+        if level is not None:
+            return self._agg_by_level('min', level=level, skipna=skipna)
 
-        Returns
-        -------
-        min : float (or Series if level specified)
-        """
         arr = self.values.copy()
 
         if skipna:
             if not issubclass(arr.dtype.type, np.integer):
                 np.putmask(arr, isnull(arr), np.inf)
 
-        if level is None:
-            return arr.min()
-
-        minfunc = lambda x: x.min(axis=None, out=None, skipna=True)
-        return self.groupby(level=level).aggregate(minfunc)
+        return arr.min()
+    _add_stat_doc(min, 'minimum', 'min')
 
     def max(self, axis=None, out=None, skipna=True, level=None):
-        """
-        Maximum of values
-
-        Parameters
-        ----------
-        skipna : boolean, default True
-            Exclude NA/null values
-        level : int, default None
-            If the axis is a MultiIndex (hierarchical), count along a
-            particular level, collapsing into a smaller Series
+        if level is not None:
+            return self._agg_by_level('max', level=level, skipna=skipna)
 
-        Returns
-        -------
-        max : float (or Series if level specified)
-        """
         arr = self.values.copy()
 
         if skipna:
             if not issubclass(arr.dtype.type, np.integer):
                 np.putmask(arr, isnull(arr), -np.inf)
 
-        if level is None:
-            return arr.max()
-
-        maxfunc = lambda x: x.max(axis=None, out=None, skipna=True)
-        return self.groupby(level=level).aggregate(maxfunc)
+        return arr.max()
+    _add_stat_doc(max, 'maximum', 'max')
 
     def std(self, axis=None, dtype=None, out=None, ddof=1, skipna=True,
             level=None):
-        """
-        Unbiased standard deviation of values
-
-        Extra parameters are to preserve ndarray interface.
-
-        Parameters
-        ----------
-        skipna : boolean, default True
-            Exclude NA/null values
-        level : int, default None
-            If the axis is a MultiIndex (hierarchical), count along a
-            particular level, collapsing into a smaller Series
-
-        Returns
-        -------
-        stdev : float (or Series if level specified)
-        """
-        if not level is None:
-            stdfunc = lambda x: x.std(axis=axis,out=out,skipna=skipna)
-            return self.groupby(level=level).aggregate(stdfunc)
+        if level is not None:
+            return self._agg_by_level('std', level=level, skipna=skipna)
 
         if skipna:
             nona = remove_na(self.values)
@@ -790,29 +724,12 @@ copy : boolean, default False
             return ndarray.std(nona, axis, dtype, out, ddof)
 
         return self.values.std(axis, dtype, out, ddof)
+    _add_stat_doc(std, 'unbiased standard deviation', 'stdev')
 
     def var(self, axis=None, dtype=None, out=None, ddof=1, skipna=True,
             level=None):
-        """
-        Unbiased variance of non-NA/null values
-
-        Extra parameters are to preserve ndarray interface.
-
-        Parameters
-        ----------
-        skipna : boolean, default True
-            Exclude NA/null values
-        level : int, default None
-            If the axis is a MultiIndex (hierarchical), count along a
-            particular level, collapsing into a smaller Series
-
-        Returns
-        -------
-        var : float (or Series if level specified)
-        """
-        if not level is None:
-            varfunc = lambda x: x.var(axis=axis,out=out,skipna=skipna)
-            return self.groupby(level=level).aggregate(varfunc)
+        if level is not None:
+            return self._agg_by_level('var', level=level, skipna=skipna)
 
         if skipna:
             nona = remove_na(self.values)
@@ -821,26 +738,11 @@ copy : boolean, default False
             return ndarray.var(nona, axis, dtype, out, ddof)
 
         return self.values.var(axis, dtype, out, ddof)
+    _add_stat_doc(var, 'unbiased variance', 'var')
 
     def skew(self, skipna=True, level=None):
-        """
-        Unbiased skewness of the non-NA/null values
-
-        Parameters
-        ----------
-        skipna : boolean, default True
-            Exclude NA/null values
-        level : int, default None
-            If the axis is a MultiIndex (hierarchical), count along a
-            particular level, collapsing into a smaller Series
-
-        Returns
-        -------
-        skew : float (or Series if level specified)
-        """
-        if not level is None:
-            skewfunc = lambda x: x.skew(skipna=skipna)
-            return self.groupby(level=level).aggregate(skewfunc)
+        if level is not None:
+            return self._agg_by_level('skew', level=level, skipna=skipna)
 
         y = np.array(self.values)
         mask = notnull(y)
@@ -855,6 +757,24 @@ copy : boolean, default False
         C = (y**3).sum() / count - A**3 - 3*A*B
 
         return (np.sqrt((count**2-count))*C) / ((count-2)*np.sqrt(B)**3)
+    _add_stat_doc(skew, 'unbiased skewness', 'skew')
+
+    def _ndarray_statistic(self, funcname, dtype=None, skipna=True):
+        arr = self.values
+        retVal = getattr(arr, funcname)(dtype=dtype)
+
+        if skipna and isnull(retVal):
+            arr = remove_na(arr)
+            if len(arr) == 0:
+                return np.nan
+            retVal = getattr(arr, funcname)(dtype=dtype)
+
+        return retVal
+
+    def _agg_by_level(self, name, level=0, skipna=True):
+        method = getattr(type(self), name)
+        applyf = lambda x: method(x, skipna=skipna)
+        return self.groupby(level=level).aggregate(applyf)
 
     def cumsum(self, axis=0, dtype=None, out=None, skipna=True):
         """
@@ -914,18 +834,6 @@ copy : boolean, default False
 
         return Series(result, index=self.index)
 
-    def _ndarray_statistic(self, funcname, dtype=None, skipna=True):
-        arr = self.values
-        retVal = getattr(arr, funcname)(dtype=dtype)
-
-        if skipna and isnull(retVal):
-            arr = remove_na(arr)
-            if len(arr) == 0:
-                return np.nan
-            retVal = getattr(arr, funcname)(dtype=dtype)
-
-        return retVal
-
     def round(self, decimals=0, out=None):
         """
 
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 5a5b35c4c..9b6803658 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -2853,6 +2853,10 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
         self.assertRaises(Exception, f, axis=2)
 
+        # make sure works on mixed-type frame
+        getattr(self.mixed_frame, name)(axis=0)
+        getattr(self.mixed_frame, name)(axis=1)
+
     def test_sum_corner(self):
         axis0 = self.empty.sum(0)
         axis1 = self.empty.sum(1)
diff --git a/pandas/tests/test_multilevel.py b/pandas/tests/test_multilevel.py
index 8d6c9ee7c..2efad44e4 100644
--- a/pandas/tests/test_multilevel.py
+++ b/pandas/tests/test_multilevel.py
@@ -1,4 +1,4 @@
-# pylint: disable-msg=W0612,E1101
+# pylint: disable-msg=W0612,E1101,W0141
 from cStringIO import StringIO
 import unittest
 
@@ -14,6 +14,19 @@ from pandas.util.testing import (assert_almost_equal,
 
 import pandas.util.testing as tm
 
+try:
+    from itertools import product as cart_product
+except ImportError:  # python 2.5
+    def cart_product(*args, **kwds):
+        # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy
+        # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111
+        pools = map(tuple, args) * kwds.get('repeat', 1)
+        result = [[]]
+        for pool in pools:
+            result = [x+[y] for x in result for y in pool]
+        for prod in result:
+            yield tuple(prod)
+
 class TestMultiLevel(unittest.TestCase):
 
     def setUp(self):
@@ -540,26 +553,38 @@ class TestMultiLevel(unittest.TestCase):
         assert_series_equal(result, expected)
         assert_series_equal(result2, expected)
 
-    def test_series_group_min_max(self):
-        for op in ['sum', 'prod', 'min', 'max', 'median', 'mean', 'skew', 
-                   'std', 'var']:
-            leftside = getattr(self.series.groupby(level=0), op)()
-            rightside = getattr(self.series, op)(level=0)
-            assert_series_equal(leftside, rightside)
+    AGG_FUNCTIONS = ['sum', 'prod', 'min', 'max', 'median', 'mean', 'skew',
+                     'mad', 'std', 'var']
 
-            leftside = getattr(self.series.groupby(level=1), op)()
-            rightside = getattr(self.series, op)(level=1)
+    def test_series_group_min_max(self):
+        for op, level, skipna in cart_product(self.AGG_FUNCTIONS,
+                                              range(2),
+                                              [False, True]):
+            grouped = self.series.groupby(level=level)
+            aggf = lambda x: getattr(x, op)(skipna=skipna)
+            # skipna=True
+            leftside = grouped.agg(aggf)
+            rightside = getattr(self.series, op)(level=level, skipna=skipna)
             assert_series_equal(leftside, rightside)
 
     def test_frame_group_ops(self):
-        for op in ['sum', 'prod', 'min', 'max', 'median', 'mean', 'skew',
-                   'mad', 'std', 'var']:
-            leftside = getattr(self.frame.groupby(level=0), op)()
-            rightside = getattr(self.frame, op)(level=0)
-            assert_frame_equal(leftside, rightside)
-
-            leftside = getattr(self.frame.groupby(level=1), op)()
-            rightside = getattr(self.frame, op)(level=1)
+        self.frame.ix[1, [1, 2]] = np.nan
+        self.frame.ix[7, [0, 1]] = np.nan
+
+        for op, level, axis, skipna in cart_product(self.AGG_FUNCTIONS,
+                                                    range(2), range(2),
+                                                    [False, True]):
+            if axis == 0:
+                frame = self.frame
+            else:
+                frame = self.frame.T
+
+            grouped = frame.groupby(level=level, axis=axis)
+
+            aggf = lambda x: getattr(x, op)(skipna=skipna, axis=axis)
+            leftside = grouped.agg(aggf)
+            rightside = getattr(frame, op)(level=level, axis=axis,
+                                           skipna=skipna)
             assert_frame_equal(leftside, rightside)
 
 if __name__ == '__main__':
