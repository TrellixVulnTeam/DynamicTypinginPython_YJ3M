commit 0670c85c948d0a6579c6effb630a313797b04f70
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Jun 7 22:38:30 2011 +0200

    this is becoming epic. deep breaths

diff --git a/pandas/core/common.py b/pandas/core/common.py
index 8f4c1681a..0dbcbb8ce 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -142,3 +142,10 @@ def _all_not_none(*args):
         if arg is None:
             return False
     return True
+
+def _try_sort(iterable):
+    listed = list(iterable)
+    try:
+        return sorted(listed)
+    except Exception:
+        return listed
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 05962677e..59df9ffd0 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -156,7 +156,7 @@ class DataFrame(PandasGeneric):
             columns = _ensure_index(columns)
             data = dict((k, v) for k, v in data.iteritems() if k in columns)
         else:
-            columns = Index(try_sort(data.keys()))
+            columns = Index(_try_sort(data.keys()))
 
         index = extract_index(data, index)
 
@@ -1669,7 +1669,7 @@ class DataFrame(PandasGeneric):
             this = self.reindex(new_index)
             other = other.reindex(new_index)
 
-        new_columns = try_sort(set(this.cols() + other.cols()))
+        new_columns = _try_sort(set(this.cols() + other.cols()))
         do_fill = fill_value is not None
 
         result = {}
@@ -1796,7 +1796,7 @@ class DataFrame(PandasGeneric):
         overlap = set(self.cols()) & set(other.cols())
 
         if overlap:
-            raise Exception('Columns overlap: %s' % try_sort(overlap))
+            raise Exception('Columns overlap: %s' % _try_sort(overlap))
 
         if len(other.index) == 0:
             result = self.copy()
@@ -1880,7 +1880,7 @@ class DataFrame(PandasGeneric):
         else:
             x = range(len(self))
 
-        for i, col in enumerate(try_sort(self.columns)):
+        for i, col in enumerate(_try_sort(self.columns)):
             if subplots:
                 ax = axes[i]
                 ax.plot(x, self[col].values, 'k', label=col, **kwds)
@@ -1905,7 +1905,7 @@ class DataFrame(PandasGeneric):
             k += 1
         _, axes = plt.subplots(nrows=k, ncols=k)
 
-        for i, col in enumerate(try_sort(self.columns)):
+        for i, col in enumerate(_try_sort(self.columns)):
             ax = axes[i / k][i % k]
             ax.hist(self[col].values)
             ax.set_title(col)
@@ -2448,52 +2448,47 @@ class _DataFrameIndexer(object):
     def __setitem__(self, key, value):
         raise NotImplementedError
 
-def try_sort(iterable):
-    listed = list(iterable)
-    try:
-        return sorted(listed)
-    except Exception:
-        return listed
+def extract_index(data):
+    def _union_if(index, new_index):
+        if index is None:
+            index = new_index
+        else:
+            index = index.union(new_index)
+        return index
 
-def extract_index(data, index):
+    index = None
     if len(data) == 0:
-        if index is None:
-            index = NULL_INDEX
+        index = NULL_INDEX
     elif len(data) > 0 and index is None:
-        # aggregate union of indices
-        need_labels = False
+        _check_data_types(data)
 
-        msg = ('Cannot mix Series / dict objects'
-               ' with ndarray / sequence input')
-        # this is pretty kludgy, better way?
+        # this is still kludgier than I'd like
         for v in data.values():
             if isinstance(v, Series):
-                if index is None:
-                    index = v.index
-                elif need_labels:
-                    raise Exception(msg)
-                elif not index.equals(v.index):
-                    index = index + v.index
-
+                index = _union_if(index, v.index)
             elif isinstance(v, dict):
-                if index is None:
-                    index = Index(try_sort(v))
-                elif need_labels:
-                    raise Exception(msg)
-                else:
-                    index = index + Index(v.keys())
-
+                index = _union_if(index, Index(_try_sort(v)))
             else: # not dict-like, assign integer labels
-                if index is not None and not need_labels:
-                    raise Exception(msg)
-                need_labels = True
                 index = Index(np.arange(len(v)))
 
-    if len(index) == 0 or index is None:
+    if len(index) == 0:
         index = NULL_INDEX
 
     return _ensure_index(index)
 
+def _check_data_types(data):
+    have_series = False
+    have_raw_arrays = False
+    for v in data.values():
+        if isinstance(v, (dict, Series)):
+            have_series = True
+        else:
+            have_raw_arrays = True
+
+    if have_series and have_raw_arrays:
+        raise Exception('Cannot mix Series / dict objects'
+                        ' with ndarray / sequence input')
+
 def _default_index(n):
     if n == 0:
         return NULL_INDEX
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 2164b2cb6..5014cd237 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -241,6 +241,9 @@ class Index(np.ndarray):
         taken = self.view(np.ndarray).take(*args, **kwargs)
         return Index(taken)
 
+    def get_loc(self, key):
+        return self.indexMap[key]
+
     def get_indexer(self, target, method=None):
         """
 
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index f6ae22660..0e445d4e1 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -7,8 +7,8 @@ import sys
 from numpy import NaN
 import numpy as np
 
-from pandas.core.common import (_pickle_array, _unpickle_array)
-from pandas.core.frame import (DataFrame, try_sort, extract_index,
+from pandas.core.common import (_pickle_array, _unpickle_array, _try_sort)
+from pandas.core.frame import (DataFrame, extract_index,
                                _default_index, _ensure_index)
 from pandas.core.index import Index, NULL_INDEX
 from pandas.core.series import Series
@@ -97,94 +97,13 @@ class DataMatrix(DataFrame):
         self.objects = objects
 
     def _get_values(self):
-        return self._float_values
+        return self._data.as_matrix()
 
     def _set_values(self, values):
         raise Exception('Values cannot be assigned to')
 
     values = property(fget=_get_values)
 
-    def _init_dict(self, data, index, columns, objects, dtype):
-        """
-        Segregate Series based on type and coerce into matrices.
-
-        Needs to handle a lot of exceptional cases.
-
-        Somehow this got outrageously complicated
-        """
-        # pre-filter out columns if we passed it
-        if columns is not None:
-            colset = set(columns)
-            data = dict((k, v) for k, v in data.iteritems() if k in colset)
-
-        index = extract_index(data, index)
-
-        objectDict = {}
-        if objects is not None and isinstance(objects, dict):
-            objectDict.update(objects)
-
-        valueDict = {}
-        for k, v in data.iteritems():
-            if isinstance(v, Series):
-                if v.index is not index:
-                    # Forces alignment. No need to copy data since we
-                    # are putting it into an ndarray later
-                    v = v.reindex(index)
-            else:
-                if isinstance(v, dict):
-                    v = [v.get(i, NaN) for i in index]
-                else:
-                    assert(len(v) == len(index))
-
-                try:
-                    v = Series(v, dtype=dtype, index=index)
-                except Exception:
-                    v = Series(v, index=index)
-
-            if issubclass(v.dtype.type, (np.bool_, float, int)):
-                valueDict[k] = v
-            else:
-                objectDict[k] = v
-
-        if columns is None:
-            columns = Index(try_sort(valueDict))
-            objectColumns = Index(try_sort(objectDict))
-        else:
-            objectColumns = Index([c for c in columns if c in objectDict])
-            columns = Index([c for c in columns if c not in objectDict])
-
-        if len(valueDict) == 0:
-            dtype = np.object_
-            valueDict = objectDict
-            columns = objectColumns
-        else:
-            dtypes = set(v.dtype for v in valueDict.values())
-
-            if len(dtypes) > 1:
-                dtype = np.float_
-            else:
-                dtype = list(dtypes)[0]
-
-            if len(objectDict) > 0:
-                new_objects = DataMatrix(objectDict,
-                                         dtype=np.object_,
-                                         index=index,
-                                         columns=objectColumns)
-                if isinstance(objects, DataMatrix):
-                    objects = objects.join(new_objects, how='left')
-                else:
-                    objects = new_objects
-
-        values = np.empty((len(index), len(columns)), dtype=dtype)
-
-        for i, col in enumerate(columns):
-            if col in valueDict:
-                values[:, i] = valueDict[col].values
-            else:
-                values[:, i] = np.NaN
-
-        return index, columns, values, objects
-
     def _init_matrix(self, values, index, columns, dtype):
         if not isinstance(values, np.ndarray):
             arr = np.array(values)
@@ -1050,30 +969,6 @@ def _filter_out(data, columns):
 
     return data
 
-def _homogenize_series(data, index):
-    homogenized = {}
-
-    for k, v in data.iteritems():
-        if isinstance(v, Series):
-            if v.index is not index:
-                # Forces alignment. No need to copy data since we
-                # are putting it into an ndarray later
-                v = v.reindex(index)
-        else:
-            if isinstance(v, dict):
-                v = [v.get(i, NaN) for i in index]
-            else:
-                assert(len(v) == len(index))
-            v = Series(v, index=index)
-
-        if issubclass(v.dtype.type, (float, int)):
-            v = v.astype(np.float64)
-        else:
-            v = v.astype(object)
-
-        homogenized[k] = v
-
-    return homogenized
 
 def _group_dtypes(data, columns):
     import itertools
@@ -1088,26 +983,49 @@ def _group_dtypes(data, columns):
 
     return chunks, chunk_cols
 
-def _init_dict(self, data, index, columns, objects, dtype):
+def _init_dict(data, index, columns):
     """
     Segregate Series based on type and coerce into matrices.
+
     Needs to handle a lot of exceptional cases.
+
     Somehow this got outrageously complicated
     """
     # pre-filter out columns if we passed it
-    data = _filter_out(data, columns)
-    index = extract_index(data, index)
+    if columns is None:
+        columns = _try_sort(data.keys())
+    columns = _ensure_index(columns)
+
+    # prefilter
+    data = dict((k, v) for k, v in data.iteritems() if k in columns)
+
+    # figure out the index, if necessary
+    if index is None:
+        index = extract_index(data)
+    homogenized = _homogenize_series(data, index)
+    # segregates dtypes and forms blocks
+    blocks = _segregate_dtypes(data)
 
     if columns is None:
-        columns = try_sort(data.keys())
+        columns = Index(_try_sort(valueDict))
+        objectColumns = Index(_try_sort(objectDict))
+    else:
+        objectColumns = Index([c for c in columns if c in objectDict])
+        columns = Index([c for c in columns if c not in objectDict])
 
+    values = np.empty((len(index), len(columns)), dtype=dtype)
 
+    for i, col in enumerate(columns):
+        if col in valueDict:
+            values[:, i] = valueDict[col].values
+        else:
+            values[:, i] = np.NaN
 
-    objectDict = {}
-    if objects is not None and isinstance(objects, dict):
-        objectDict.update(objects)
+    return index, columns, values, objects
+
+def _homogenize_series(data, index):
+    homogenized = {}
 
-    valueDict = {}
     for k, v in data.iteritems():
         if isinstance(v, Series):
             if v.index is not index:
@@ -1119,55 +1037,32 @@ def _init_dict(self, data, index, columns, objects, dtype):
                 v = [v.get(i, NaN) for i in index]
             else:
                 assert(len(v) == len(index))
+            v = Series(v, index=index)
 
-            try:
-                v = Series(v, dtype=dtype, index=index)
-            except Exception:
-                v = Series(v, index=index)
-
-        if issubclass(v.dtype.type, (np.bool_, float, int)):
-            valueDict[k] = v
+        if issubclass(v.dtype.type, (float, int)):
+            v = v.astype(np.float64)
         else:
-            objectDict[k] = v
+            v = v.astype(object)
 
-    if columns is None:
-        columns = Index(try_sort(valueDict))
-        objectColumns = Index(try_sort(objectDict))
-    else:
-        objectColumns = Index([c for c in columns if c in objectDict])
-        columns = Index([c for c in columns if c not in objectDict])
+        homogenized[k] = v
 
-    if len(valueDict) == 0:
-        dtype = np.object_
-        valueDict = objectDict
-        columns = objectColumns
-    else:
-        dtypes = set(v.dtype for v in valueDict.values())
+    return homogenized
 
-        if len(dtypes) > 1:
-            dtype = np.float_
+def _segregate_dtypes(data):
+    float_dict = {}
+    object_dict = {}
+    for k, v in data.iteritems():
+        if issubclass(v.dtype.type, (np.floating, np.integer)):
+            float_dict[k] = v
         else:
-            dtype = list(dtypes)[0]
-
-        if len(objectDict) > 0:
-            new_objects = DataMatrix(objectDict,
-                                     dtype=np.object_,
-                                     index=index,
-                                     columns=objectColumns)
-            if isinstance(objects, DataMatrix):
-                objects = objects.join(new_objects, how='left')
-            else:
-                objects = new_objects
+            object_dict[k] = v
 
-    values = np.empty((len(index), len(columns)), dtype=dtype)
+    float_block = _blockify(float_dict, np.float64)
+    object_block = _blockify(object_dict, np.object_)
+    return [float_block, object_block]
 
-    for i, col in enumerate(columns):
-        if col in valueDict:
-            values[:, i] = valueDict[col].values
-        else:
-            values[:, i] = np.NaN
-
-    return index, columns, values, objects
+def _blockify(dct, dtype):
+    pass
 
 def _init_matrix(self, values, index, columns, dtype):
     if not isinstance(values, np.ndarray):
@@ -1204,7 +1099,6 @@ def _reorder_columns(mat, current, desired):
     indexer, mask = common.get_indexer(current, desired, None)
     return mat.take(indexer[mask], axis=1)
 
-
 def _nan_array(index, columns):
     if index is None:
         index = NULL_INDEX
@@ -1214,3 +1108,6 @@ def _nan_array(index, columns):
     values = np.empty((len(index), len(columns)), dtype=dtype)
     values.fill(NaN)
     return values
+
+if __name__ == '__main__':
+    pass
diff --git a/pandas/core/proto.py b/pandas/core/proto.py
index e2817d8e1..2b434f888 100644
--- a/pandas/core/proto.py
+++ b/pandas/core/proto.py
@@ -7,7 +7,6 @@ from pandas.core.index import Index
 from pandas.core.common import _ensure_index
 from pandas.core.series import Series
 import pandas.core.common as common
-import pandas.lib.tseries as tseries
 
 class Block(object):
     """
@@ -19,12 +18,21 @@ class Block(object):
         self.values = values
         self.columns = _ensure_index(columns)
 
+    def __repr__(self):
+        x, y = self.shape
+        return 'Block: %s, %d x %d, dtype %s' % (self.columns, x, y,
+                                                 self.dtype)
+
     def __contains__(self, col):
         return col in self.columns
 
     def __len__(self):
         return len(self.values)
 
+    @property
+    def shape(self):
+        return self.values.shape
+
     @property
     def dtype(self):
         return self.values.dtype
@@ -57,11 +65,10 @@ class Block(object):
         """
         assert(col not in self.columns)
         if loc is None:
-            loc = len(columns)
+            loc = len(self.columns)
 
         new_columns = _insert_into_columns(self.columns, col, loc)
         new_values = _insert_into_values(self.values, value, loc)
-
         return Block(new_values, new_columns)
 
     def set(self, col, value):
@@ -72,18 +79,35 @@ class Block(object):
         -------
         None
         """
-        pass
+        loc = self.columns.get_loc(col)
+        self.values[:, loc] = value
 
-    def delete(self, loc):
+    def delete(self, col):
         """
         Returns
         -------
         y : Block (new object)
         """
-        pass
+        loc = self.columns.get_loc(col)
+        new_columns = _delete_from_columns(self.columns, loc)
+        new_values = _delete_from_values(self.values, loc)
+        return Block(new_values, new_columns)
 
 def _insert_into_columns(columns, col, loc):
-    pass
+    columns = np.asarray(columns)
+    new_columns = np.insert(columns, loc, col)
+    return Index(new_columns)
+
+def _insert_into_values(values, new_vec, loc):
+    return np.insert(values, loc, new_vec, 1)
+
+def _delete_from_columns(columns, loc):
+    columns = np.asarray(columns)
+    new_columns = np.delete(columns, loc)
+    return Index(new_columns)
+
+def _delete_from_values(values, loc):
+    return np.delete(values, loc, 1)
 
 def _convert_if_1d(values):
     if values.ndim == 1:
@@ -103,13 +127,21 @@ def make_block(values, columns):
 class BlockManager(object):
     """
     Manage a bunch of 2D mixed-type ndarrays
+
+    This is not a public API class
     """
-    def __init__(self, columns, blocks):
+    def __init__(self, blocks, columns):
         self.columns = columns
         self.blocks = blocks
 
+    def __repr__(self):
+        output = 'BlockManager'
+        for block in self.blocks:
+            output += '\n%s' % repr(block)
+        return output
+
     def _verify_integrity(self):
-        _ = _union_block_columns(self.columns)
+        _union_block_columns(self.columns)
         length = self.block_length
         for block in self.blocks:
             assert(len(block) == length)
@@ -126,6 +158,7 @@ class BlockManager(object):
     def from_blocks(cls, blocks):
         # also checks for overlap
         columns = _union_block_columns(blocks)
+        return BlockManager(blocks, columns)
 
     def __contains__(self, column):
         return column in self.columns
@@ -146,6 +179,13 @@ class BlockManager(object):
         return np.concatenate([b[i] for b in blocks])
 
     def consolidate(self):
+        """
+
+        Returns
+        -------
+
+        """
+
         new_blocks = _consolidate(self.blocks)
         return BlockManager(new_blocks, self.columns)
 
@@ -159,13 +199,29 @@ class BlockManager(object):
         self.blocks[i] = new_block
 
     def set(self, col, value):
+        """
+        Set new column in-place. Does not consolidate. Adds new Block if not
+        contained in the current set of columns
+        """
         assert(len(value) == self.block_length)
         if col in self.columns:
             i, block = self._find_block(col)
-            _needs_other_dtype
+            if _needs_other_dtype(block, value):
+                # delete from block, create and append new block
+                self.blocks[i] = block.delete(col)
+                self._add_new_block(col, value)
         else:
             # new block
-            pass
+            self._add_new_block(col, value)
+
+            # TODO: where to insert?
+            self.columns = _insert_into_columns(self.columns, col,
+                                                len(self.columns))
+
+    def _add_new_block(self, col, value):
+        # Do we care about dtype at the moment?
+        new_block = Block(value, [col])
+        self._push_new_block(new_block)
 
     def _find_block(self, col):
         self._check_have(col)
@@ -175,6 +231,9 @@ class BlockManager(object):
 
         raise Exception('technically unreachable code')
 
+    def _push_new_block(self, block):
+        self.blocks.append(block)
+
     def _check_have(self, col):
         if col not in self.columns:
             raise KeyError('no column named %s' % col)
@@ -182,8 +241,15 @@ class BlockManager(object):
     def _chunk_index(self, col):
         pass
 
+    def rename(self, mapper):
+        pass
+
+    def reindex(self, indexer, mask):
+        pass
+
 def _needs_other_dtype(block, to_insert):
-    pass
+    if to_insert.dtype != block.dtype:
+        pass
 
 def _blocks_to_series_dict(blocks, index=None):
     series_dict = {}
diff --git a/pandas/core/sparse.py b/pandas/core/sparse.py
index 74c28afac..303f121e4 100644
--- a/pandas/core/sparse.py
+++ b/pandas/core/sparse.py
@@ -9,10 +9,10 @@ import numpy as np
 import operator
 
 from pandas.core.common import (_pickle_array, _unpickle_array, _mut_exclusive,
-                                _ensure_index)
+                                _ensure_index, _try_sort)
 from pandas.core.index import Index
 from pandas.core.series import Series, TimeSeries
-from pandas.core.frame import DataFrame, extract_index, try_sort
+from pandas.core.frame import DataFrame, extract_index
 from pandas.core.matrix import DataMatrix
 from pandas.core.panel import Panel, WidePanel, LongPanelIndex, LongPanel
 import pandas.core.common as common
