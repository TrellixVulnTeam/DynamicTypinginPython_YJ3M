commit 6d1e23cf6e287990261f8ee61e9d435f2e0dec1f
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Apr 25 22:09:26 2011 -0400

    misc refactorings and work related to sparse data structures

diff --git a/pandas/core/common.py b/pandas/core/common.py
index 03d4de5a0..e5e3a0a0a 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -70,28 +70,6 @@ def _unpickle_array(bytes):
     arr = read_array(StringIO(bytes))
     return arr
 
-def _pfixed(s, space, nanRep=None, float_format=None):
-    if isinstance(s, float):
-        if nanRep is not None and isnull(s):
-            if np.isnan(s):
-                return nanRep.ljust(space)
-            else:
-                return ('%s' % s).ljust(space)
-
-        if float_format:
-            formatted = float_format(s)
-        else:
-            is_pos = s >= 0
-            formatted = '%.4g' % np.abs(s)
-
-            if is_pos:
-                formatted = ' ' + formatted
-            else:
-                formatted = '-' + formatted
-        return formatted.ljust(space)
-    else:
-        return ('%s' % s)[:space].ljust(space)
-
 def get_indexer(source, target, fill_method):
     if fill_method:
         fill_method = fill_method.upper()
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index cc2928ec0..15bb1e668 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -10,8 +10,7 @@ import warnings
 from numpy import NaN
 import numpy as np
 
-from pandas.core.common import (_pickle_array, _unpickle_array, _pfixed,
-                                isnull, notnull)
+from pandas.core.common import (_pickle_array, _unpickle_array, isnull, notnull)
 from pandas.core.daterange import DateRange
 from pandas.core.index import Index, NULL_INDEX
 from pandas.core.mixins import Picklable, Groupable
@@ -415,6 +414,22 @@ class DataFrame(Picklable, Groupable):
 
         return np.rec.fromarrays(arrays, names=names)
 
+    def to_sparse(self, fill_value=None, kind='block'):
+        """
+
+        Parameters
+        ----------
+        fill_value : float, default NaN
+        kind : {'block', 'integer'}
+        """
+        from pandas.core.sparse import SparseDataFrame
+
+        sparse_data = {}
+        for k, v in self.iteritems():
+            sparse_data[k] = v.to_sparse(fill_value=fill_value, kind=kind)
+
+        return SparseDataFrame(sparse_data, index=self.index)
+
 #-------------------------------------------------------------------------------
 # Magic methods
 
@@ -433,10 +448,9 @@ class DataFrame(Picklable, Groupable):
         """
         buf = StringIO()
         if len(self.index) < 500 and len(self.columns) < 10:
-            self.toString(buffer=buf)
+            self.toString(buf=buf)
         else:
-            buf.write(str(self.__class__) + '\n')
-            self.info(buffer=buf)
+            self.info(buf=buf)
 
         return buf.getvalue()
 
@@ -758,12 +772,12 @@ class DataFrame(Picklable, Groupable):
         from pandas.core.matrix import DataMatrix
         return DataMatrix(self._series, index=self.index)
 
-    def toString(self, buffer=sys.stdout, columns=None, colSpace=None,
+    def toString(self, buf=sys.stdout, columns=None, colSpace=None,
                  nanRep='NaN', formatters=None, float_format=None):
         """Output a tab-separated version of this DataFrame"""
         series = self._series
         if columns is None:
-            columns = self.columns
+            columns = self._output_columns()
         else:
             columns = [c for c in columns if c in self]
 
@@ -774,71 +788,103 @@ class DataFrame(Picklable, Groupable):
             colSpace = {}
 
             for c in columns:
-                if np.issctype(self[c].dtype):
+                if np.issctype(series[c].dtype):
                     colSpace[c] = max(len(str(c)) + 4, 12)
                 else:
-                    # hack
+                    # HACK
                     colSpace[c] = 15
         else:
-            colSpace = dict((k, 15) for k in columns)
+            colSpace = dict((k, colSpace) for k in columns)
 
         if len(columns) == 0 or len(self.index) == 0:
-            print >> buffer, 'Empty DataFrame'
-            print >> buffer, repr(self.index)
+            print >> buf, 'Empty %s' % type(self).__name__
+            print >> buf, repr(self.index)
         else:
             idxSpace = max([len(str(idx)) for idx in self.index]) + 4
-            head = _pfixed('', idxSpace)
+            head = ' ' * idxSpace
 
             for h in columns:
-                head += _pfixed(h, colSpace[h])
+                head += _put_str(h, colSpace[h])
 
-            print >> buffer, head
+            print >> buf, head
 
             for idx in self.index:
-
-                ot = _pfixed(idx, idxSpace - 1)
+                ot = _put_str(idx, idxSpace - 1)
                 for k in columns:
                     formatter = formatters.get(k, ident)
                     ot += _pfixed(formatter(series[k][idx]),
                                   colSpace[k], nanRep=nanRep,
                                   float_format=float_format)
-                print >> buffer, ot
+                print >> buf, ot
 
-    def head(self, buffer=sys.stdout):
+    def _output_columns(self):
+        return list(self.columns)
+
+    def head(self, buf=sys.stdout):
         chunk = self[:5]
         if len(self.cols()) > 6:
             print 'Probably too wide to display, transposing'
             chunk = chunk.T
 
-        chunk.toString(buffer=buffer)
+        chunk.toString(buf=buf)
 
-    def tail(self, buffer=sys.stdout):
+    def tail(self, buf=sys.stdout):
         chunk = self[-5:]
         if len(self.cols()) > 6:
             print 'Probably too wide to display, transposing'
             chunk = chunk.T
 
-        chunk.toString(buffer=buffer)
+        chunk.toString(buf=buf)
 
-    def info(self, buffer=sys.stdout):
-        """Concise summary of a DataFrame, used in __repr__ when very large."""
-        print >> buffer, 'Index: %s entries' % len(self.index),
+    def info(self, verbose=True, buf=sys.stdout):
+        """
+        Concise summary of a DataFrame, used in __repr__ when very large.
+        """
+        print >> buf, str(type(self))
         if len(self.index) > 0:
-            print >> buffer, ', %s to %s' % (self.index[0], self.index[-1])
+            index_summary = ', %s to %s' % (self.index[0], self.index[-1])
         else:
-            print >> buffer, ''
+            index_summary = ''
+        print >> buf, 'Index: %s entries%s' % (len(self.index), index_summary)
 
-        if len(self._series) == 0:
-            print >> buffer, 'DataFrame is empty!'
+        if len(self.cols()) == 0:
+            name = type(self).__name__
+            print >> buf, 'Empty',
             return
 
-        series = self._series
-        columns = self.columns
-        space = max([len(str(k)) for k in columns]) + 4
-        for k in columns:
-            out = _pfixed(k, space)
-            out += '%d  non-null values' % series[k].count()
-            print >> buffer, out
+        print >> buf, 'Data columns:'
+        space = max([len(str(k)) for k in self.cols()]) + 4
+
+        cols = self.cols()
+
+        if verbose:
+            col_counts = []
+            counts = self.count()
+            assert(len(cols) == len(counts))
+            for col, count in counts.iteritems():
+                col_counts.append('%s%d  non-null values' %
+                                  (_pfixed(col, space), count))
+
+            print >> buf, '\n'.join(col_counts)
+        else:
+            if len(columns) <= 2:
+                print >> buf, 'Columns: %s' % repr(columns)
+            else:
+                print >> buf, 'Columns: %s to %s' % (columns[0], columns[-1])
+
+        counts = self._get_dtype_counts()
+        dtypes = ['%s(%d)' % k for k in sorted(counts.iteritems())]
+        buf.write('dtypes: %s' % ', '.join(dtypes))
+
+    def _get_dtype_counts(self):
+        counts = {}
+        for _, series in self.iteritems():
+            if series.dtype in counts:
+                counts[series.dtype] += 1
+            else:
+                counts[series.dtype] = 1
+
+        return counts
 
     def rows(self):
         """Alias for the frame's index"""
@@ -1283,7 +1329,7 @@ class DataFrame(Picklable, Groupable):
         if len(self.index) == 0:
             return DataFrame(index=index, columns=self.columns)
 
-        indexer, mask = common.get_indexer(self.index, index, method)
+        indexer, mask = self.index.get_indexer(index, method=method)
 
         # Maybe this is a bit much? Wish I had more unit tests...
         typeHierarchy = [
@@ -2360,14 +2406,15 @@ def extract_index(data, index):
         # aggregate union of indices
         need_labels = False
 
+        msg = ('Cannot mix Series / dict objects'
+               ' with ndarray / sequence input')
         # this is pretty kludgy, better way?
         for v in data.values():
             if isinstance(v, Series):
                 if index is None:
                     index = v.index
                 elif need_labels:
-                    raise Exception('Cannot mix Series / dict objects'
-                                    ' with ndarray / sequence input')
+                    raise Exception(msg)
                 elif not index.equals(v.index):
                     index = index + v.index
 
@@ -2375,16 +2422,13 @@ def extract_index(data, index):
                 if index is None:
                     index = Index(try_sort(v))
                 elif need_labels:
-                    raise Exception('Cannot mix Series / dict objects'
-                                    ' with ndarray / sequence input')
+                    raise Exception(msg)
                 else:
                     index = index + Index(v.keys())
 
             else: # not dict-like, assign integer labels
                 if index is not None and not need_labels:
-                    raise Exception('Cannot mix Series / dict objects'
-                                    ' with ndarray / sequence input')
-
+                    raise Exception(msg)
                 need_labels = True
                 index = Index(np.arange(len(v)))
 
@@ -2401,3 +2445,28 @@ def _default_index(n):
         return NULL_INDEX
     else:
         return np.arange(n)
+
+def _pfixed(s, space, nanRep=None, float_format=None):
+    if isinstance(s, float):
+        if nanRep is not None and isnull(s):
+            if np.isnan(s):
+                return nanRep.ljust(space)
+            else:
+                return ('%s' % s).ljust(space)
+
+        if float_format:
+            formatted = float_format(s)
+        else:
+            is_pos = s >= 0
+            formatted = '%.4g' % np.abs(s)
+
+            if is_pos:
+                formatted = ' ' + formatted
+            else:
+                formatted = '-' + formatted
+        return formatted.ljust(space)
+    else:
+        return (' %s' % s)[:space].ljust(space)
+
+def _put_str(s, space):
+    return ('%s' % s)[:space].ljust(space)
diff --git a/pandas/core/index.py b/pandas/core/index.py
index bb1787e74..1d12ba5a5 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -229,6 +229,28 @@ class Index(np.ndarray):
         taken = self.view(np.ndarray).take(*args, **kwargs)
         return Index(taken)
 
+    def get_indexer(self, target, method=None):
+        """
+
+        Parameters
+        ----------
+        target : Index
+        method :
+
+        Returns
+        -------
+        (indexer, mask)
+        """
+        import pandas.lib.tseries as tseries
+
+        if method:
+            method = method.upper()
+
+        indexer, mask = tseries.getFillVec(self, target, self.indexMap,
+                                           target.indexMap, method)
+
+        return indexer, mask
+
 # For utility purposes
 
 NULL_INDEX = Index([])
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index e9299e7d3..116b6a805 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -476,20 +476,6 @@ class DataMatrix(DataFrame):
         else:
             return True
 
-    def __repr__(self):
-        """Return a string representation for a particular DataMatrix"""
-        buffer = StringIO()
-
-        if len(self.cols()) == 0:
-            buffer.write('Empty DataMatrix\nIndex: %s' % repr(self.index))
-        elif 0 < len(self.index) < 500 and self.values.shape[1] < 10:
-            self.toString(buffer=buffer)
-        else:
-            print >> buffer, str(self.__class__)
-            self.info(buffer=buffer)
-
-        return buffer.getvalue()
-
     def __getitem__(self, item):
         """
         Retrieve column, slice, or subset from DataMatrix.
@@ -695,104 +681,13 @@ class DataMatrix(DataFrame):
         return series
     _series = property(_getSeriesDict)
 
-#-------------------------------------------------------------------------------
-# Outputting
-
-    def toString(self, buffer=sys.stdout, columns=None, colSpace=None,
-                 nanRep='NaN', formatters=None, float_format=None):
-        """
-        Output a string version of this DataMatrix
-        """
-        _pf = common._pfixed
-        formatters = formatters or {}
-
-        if columns is None:
-            columns = self.columns
-            values = self.values
-            if self.objects:
-                columns = list(columns) + list(self.objects.columns)
-                values = np.column_stack((values.astype(object),
-                                          self.objects.values))
-        else:
-            columns = [c for c in columns if c in self]
-            values = self.asMatrix(columns)
-
-        ident = lambda x: x
-
-        idxSpace = max([len(str(idx)) for idx in self.index]) + 4
-
-        if colSpace is None:
-            colSpace = {}
-
-            for c in columns:
-                if np.issctype(self[c].dtype):
-                    colSpace[c] = max(len(str(c)) + 4, 12)
-                else:
-                    # hack
-                    colSpace[c] = 15
-        else:
-            colSpace = dict((k, 15) for k in columns)
-
-        if len(self.cols()) == 0:
-            buffer.write('DataMatrix is empty!\n')
-            buffer.write(repr(self.index))
-        else:
-            buffer.write(_pf('', idxSpace))
-            for h in columns:
-                buffer.write(_pf(h, colSpace[h]))
-            buffer.write('\n')
-
-            for i, idx in enumerate(self.index):
-                buffer.write(_pf(idx, idxSpace - 1))
-                for j, col in enumerate(columns):
-                    formatter = formatters.get(col, ident)
-                    buffer.write(_pf(formatter(values[i, j]), colSpace[col],
-                                     float_format=float_format,
-                                     nanRep=nanRep))
-                buffer.write('\n')
-
-    def info(self, buffer=sys.stdout):
-        """
-        Concise summary of a DataMatrix, used in __repr__ when very large.
-        """
-        print >> buffer, 'Index: %s entries' % len(self.index),
-        if len(self.index) > 0:
-            print >> buffer, ', %s to %s' % (self.index[0], self.index[-1])
+    def _output_columns(self):
+        # for toString
+        cols = list(self.columns)
+        if self.objects is None:
+            return cols
         else:
-            print >> buffer, ''
-
-        if len(self.cols()) == 0:
-            print >> buffer, 'DataMatrix is empty!'
-            print >> buffer, repr(self.index)
-            return
-
-        print >> buffer, 'Data columns:'
-        space = max([len(str(k)) for k in self.cols()]) + 4
-
-        counts = self.count()
-
-        cols = self.cols()
-        assert(len(cols) == len(counts))
-
-        columns = []
-        for col, count in counts.iteritems():
-            columns.append('%s%d  non-null values' %
-                           (common._pfixed(col, space), count))
-
-        dtypeLine = ''
-
-        nf = len(self.columns)
-        df = self.values.dtype
-
-        if self.objects is not None:
-            no = len(self.objects.columns)
-            do = self.objects.values.dtype
-            dtypeLine = '\ndtypes: %s(%d), %s(%d)' % (df, nf, do, no)
-        else:
-            dtypeLine = '\ndtype: %s(%d)' % (df, nf)
-
-        buffer.write('\n'.join(columns) + dtypeLine)
-
+            return cols + list(self.objects.columns)
 
 #-------------------------------------------------------------------------------
 # Public methods
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 436b84bc0..2ed89cf62 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -10,7 +10,7 @@ import warnings
 import numpy as np
 
 from pandas.core.index import Index
-from pandas.core.frame import DataFrame
+from pandas.core.frame import DataFrame, _pfixed
 from pandas.core.matrix import DataMatrix
 from pandas.core.mixins import Picklable, Groupable
 import pandas.core.common as common
@@ -1316,11 +1316,11 @@ class LongPanel(Panel):
         self._textConvert(f, format_cols, format_row)
         f.close()
 
-    def toString(self, buffer=sys.stdout, col_space=15):
+    def toString(self, buf=sys.stdout, col_space=15):
         """
         Output a screen-friendly version of this Panel
         """
-        _pf = common._pfixed
+        _pf = _pfixed
         major_space = max(max([len(str(idx))
                                for idx in self.major_axis]) + 4, 9)
         minor_space = max(max([len(str(idx))
@@ -1336,17 +1336,17 @@ class LongPanel(Panel):
                                _pf(minor, minor_space),
                                ''.join(_pf(v, col_space) for v in values))
 
-        self._textConvert(buffer, format_cols, format_row)
+        self._textConvert(buf, format_cols, format_row)
 
-    def _textConvert(self, buffer, format_cols, format_row):
-        print >> buffer, format_cols(self.items)
+    def _textConvert(self, buf, format_cols, format_row):
+        print >> buf, format_cols(self.items)
 
         label_pairs = zip(self.index.major_labels,
                           self.index.minor_labels)
         major, minor = self.major_axis, self.minor_axis
         for i, (major_i, minor_i) in enumerate(label_pairs):
             row = format_row(major[major_i], minor[minor_i], self.values[i])
-            print >> buffer, row
+            print >> buf, row
 
     def swapaxes(self):
         """
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 1c2393f5b..65bd97788 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -209,6 +209,22 @@ class Series(np.ndarray, Picklable, Groupable):
     def toDict(self):
         return dict(self.iteritems())
 
+    def to_sparse(self, kind='block', fill_value=None):
+        """
+        Convert Series to SparseSeries
+
+        Parameters
+        ----------
+        kind : {'block', 'integer'}
+        fill_value : float, defaults to NaN (missing)
+
+        Returns
+        -------
+        sp : SparseSeries
+        """
+        from pandas.core.sparse import SparseSeries
+        return SparseSeries(self, kind=kind, fill_value=fill_value)
+
     @classmethod
     def fromValue(cls, value=np.NaN, index=None, dtype=None): # pragma: no cover
         warnings.warn("'fromValue', can call Series(value, index=index) now",
@@ -319,17 +335,21 @@ class Series(np.ndarray, Picklable, Groupable):
 
     def __repr__(self):
         """Clean string representation of a Series"""
+        if len(self.index) > 500:
+            return self._make_repr(50)
+        elif len(self.index) > 0:
+            return _seriesRepr(self.index, self.values)
+        else:
+            return '%s' % ndarray.__repr__(self)
+
+    def _make_repr(self, max_vals=50):
         vals = self.values
         index = self.index
 
-        if len(index) > 500:
-            head = _seriesRepr(index[:50], vals[:50])
-            tail = _seriesRepr(index[-50:], vals[-50:])
-            return head + '\n...\n' + tail + '\nlength: %d' % len(vals)
-        elif len(index) > 0:
-            return _seriesRepr(index, vals)
-        else:
-            return '%s' % ndarray.__repr__(self)
+        num = max_vals // 2
+        head = _seriesRepr(index[:num], vals[:num])
+        tail = _seriesRepr(index[-(max_vals - num):], vals[-(max_vals - num):])
+        return head + '\n...\n' + tail + '\nlength: %d' % len(vals)
 
     def toString(self, buffer=sys.stdout, nanRep='NaN'):
         print >> buffer, _seriesRepr(self.index, self.values,
@@ -386,6 +406,16 @@ class Series(np.ndarray, Picklable, Groupable):
         """
         return self._ndarray_statistic('mean')
 
+    def _ndarray_statistic(self, funcname):
+        arr = self.values
+        retVal = getattr(arr, funcname)()
+
+        if isnull(retVal):
+            arr = remove_na(arr)
+            retVal = getattr(arr, funcname)()
+
+        return retVal
+
     def quantile(self, q=0.5):
         """
         Return value at the given quantile
@@ -419,16 +449,6 @@ class Series(np.ndarray, Picklable, Groupable):
 
         return Series(data, index=names)
 
-    def _ndarray_statistic(self, funcname):
-        arr = self.values
-        retVal = getattr(arr, funcname)()
-
-        if isnull(retVal):
-            arr = remove_na(arr)
-            retVal = getattr(arr, funcname)()
-
-        return retVal
-
     def min(self, axis=None, out=None):
         """
         Minimum of non-null values
@@ -640,8 +660,8 @@ class Series(np.ndarray, Picklable, Groupable):
         except Exception:
             raise
 
-        newValues = np.concatenate((self, other))
-        return Series(newValues, index=newIndex)
+        new_values = np.concatenate((self, other))
+        return Series(new_values, index=newIndex)
 
     def combineFunc(self, other, func):
         """
@@ -787,15 +807,15 @@ class Series(np.ndarray, Picklable, Groupable):
             indexer, mask = tseries.getMergeVec(self, arg.index.indexMap)
             notmask = -mask
 
-            newValues = arg.view(np.ndarray).take(indexer)
+            new_values = arg.view(np.ndarray).take(indexer)
 
             if notmask.any():
-                if issubclass(newValues.dtype.type, np.integer):
-                    newValues = newValues.astype(float)
+                if issubclass(new_values.dtype.type, np.integer):
+                    new_values = new_values.astype(float)
 
-                np.putmask(newValues, notmask, np.nan)
+                np.putmask(new_values, notmask, np.nan)
 
-            newSer = Series(newValues, index=self.index)
+            newSer = Series(new_values, index=self.index)
             return newSer
         else:
             return Series([arg(x) for x in self], index=self.index)
@@ -854,26 +874,19 @@ class Series(np.ndarray, Picklable, Groupable):
         if len(self.index) == 0:
             return Series(NaN, index=new_index)
 
-        if method is not None:
-            method = method.upper()
-
-        fillVec, mask = tseries.getFillVec(self.index, new_index,
-                                           self.index.indexMap,
-                                           new_index.indexMap,
-                                           kind=method)
-
-        newValues = self.values.take(fillVec)
+        fill_vec, mask = self.index.get_indexer(new_index, method=method)
+        new_values = self.values.take(fill_vec)
 
         notmask = -mask
         if notmask.any():
-            if issubclass(newValues.dtype.type, np.int_):
-                newValues = newValues.astype(float)
-            elif issubclass(newValues.dtype.type, np.bool_):
-                newValues = newValues.astype(object)
+            if issubclass(new_values.dtype.type, np.int_):
+                new_values = new_values.astype(float)
+            elif issubclass(new_values.dtype.type, np.bool_):
+                new_values = new_values.astype(object)
 
-            np.putmask(newValues, notmask, NaN)
+            np.putmask(new_values, notmask, NaN)
 
-        return Series(newValues, index=new_index)
+        return Series(new_values, index=new_index)
 
     def reindex_like(self, other, method=None):
         """
@@ -1079,16 +1092,16 @@ class Series(np.ndarray, Picklable, Groupable):
             offset = datetools.getOffset(timeRule)
 
         if offset is None:
-            newValues = np.empty(len(self), dtype=self.dtype)
+            new_values = np.empty(len(self), dtype=self.dtype)
 
             if periods > 0:
-                newValues[periods:] = self.values[:-periods]
-                newValues[:periods] = np.NaN
+                new_values[periods:] = self.values[:-periods]
+                new_values[:periods] = np.NaN
             elif periods < 0:
-                newValues[:periods] = self.values[-periods:]
-                newValues[periods:] = np.NaN
+                new_values[:periods] = self.values[-periods:]
+                new_values[periods:] = np.NaN
 
-            return Series(newValues, index=self.index)
+            return Series(new_values, index=self.index)
         else:
             return Series(self, index=self.index.shift(periods, offset))
 
diff --git a/pandas/core/sparse.py b/pandas/core/sparse.py
index 69cc049aa..87c409d15 100644
--- a/pandas/core/sparse.py
+++ b/pandas/core/sparse.py
@@ -9,7 +9,7 @@ import numpy as np
 import operator
 
 from pandas.core.index import Index, NULL_INDEX
-from pandas.core.series import Series, TimeSeries
+from pandas.core.series import Series, TimeSeries, remove_na
 from pandas.core.frame import DataFrame, extract_index, try_sort
 import pandas.core.common as common
 
@@ -52,11 +52,6 @@ def make_sparse(arr, kind='block', fill_value=nan):
     sparsified_values = arr[mask]
     return sparsified_values, index
 
-def to_sparse_series(series, kind='block', fill_value=nan):
-    sp_values, sp_index = make_sparse(series, kind=kind, fill_value=fill_value)
-    return SparseSeries(sp_values, index=series.index, sparse_index=sp_index,
-                        fill_value=fill_value)
-
 #-------------------------------------------------------------------------------
 # Wrapper function for Series arithmetic methods
 _MIRROR_OPS = {
@@ -163,19 +158,20 @@ class SparseSeries(Series):
     sp_index = None
     fill_value = None
 
-    def __new__(cls, data, index=None, sparse_index=None,
-                kind='block', fill_value=None, copy=False):
+    def __new__(cls, data, index=None, sparse_index=None, kind='block',
+                fill_value=None, copy=False):
 
         if isinstance(data, SparseSeries):
             if index is None:
                 index = data.index
 
             if fill_value is None:
-                sparse_index = data.fill_value
+                fill_value = data.fill_value
 
             if index is not None:
-                assert(len(index) == data.length)
+                assert(len(index) == len(data))
 
+            sparse_index = data.sp_index
             values = np.asarray(data)
         elif isinstance(data, (Series, dict)):
             if fill_value is None:
@@ -186,6 +182,8 @@ class SparseSeries(Series):
                 index = data.index
             values, sparse_index = make_sparse(data, kind=kind,
                                                fill_value=fill_value)
+        elif np.isscalar(data): # pragma: no cover
+            raise Exception('not supported yet')
         else:
             if fill_value is None:
                 fill_value = nan
@@ -204,7 +202,7 @@ class SparseSeries(Series):
             index = Index(index)
 
         # Create array, do *not* copy data by default
-        subarr = np.array(values, dtype=np.float64, copy=False)
+        subarr = np.array(values, dtype=np.float64, copy=copy)
 
         if index.is_all_dates():
             cls = SparseTimeSeries
@@ -228,6 +226,11 @@ class SparseSeries(Series):
     def __len__(self):
         return self.sp_index.length
 
+    def __repr__(self):
+        series_rep = Series.__repr__(self)
+        rep = '%s\n%s' % (series_rep, repr(self.sp_index))
+        return rep
+
     # Arithmetic operators
 
     __add__ = _sparse_op_wrap('add')
@@ -256,14 +259,19 @@ class SparseSeries(Series):
     def sp_values(self):
         return np.asarray(self)
 
-    def to_dense(self):
+    def to_dense(self, sparse_only=False):
         """
         Convert SparseSeries to (dense) Series
         """
-        return Series(self.values, index=self.index)
+        if sparse_only:
+            int_index = self.sp_index.to_int_index()
+            index = self.index.take(int_index.indices)
+            return Series(self.sp_values, index=index)
+        else:
+            return Series(self.values, index=self.index)
 
     def astype(self, dtype):
-        # HACK
+        # HACK?
         return self.copy()
 
     def copy(self):
@@ -271,28 +279,100 @@ class SparseSeries(Series):
         return SparseSeries(values, index=self.index,
                             sparse_index=self.sp_index)
 
-    def reindex(self, new_index):
-        return SparseSeries(self.to_dense().reindex(new_index))
+    def reindex(self, new_index, method=None):
+        """
+        Conform SparseSeries to new Index
 
-        if self.index.equals(new_index):
-            return self.copy()
+        See Series.reindex docstring for general behavior
 
+        Returns
+        -------
+        reindexed : SparseSeries
+        """
         if not isinstance(new_index, Index):
             new_index = Index(new_index)
 
+        if self.index.equals(new_index):
+            return self.copy()
+
         if len(self.index) == 0:
-            return Series(nan, index=new_index)
+            # FIXME: inelegant / slow
+            values = np.empty(len(new_index), dtype=np.float64)
+            values.fill(nan)
+            return SparseSeries(values, index=new_index,
+                                fill_value=self.fill_value)
+
+        values = self.values
+        indexer, mask = self.index.get_indexer(new_index, method=method)
+        new_values = values.take(indexer)
 
-        indexer, mask = tseries.getFillVec(self.index, new_index,
-                                           self.index.indexMap,
-                                           new_index.indexMap)
+        # TODO: always use NaN here?
+        notmask = -mask
+        if notmask.any():
+            np.putmask(new_values, notmask, nan)
+
+        return SparseSeries(new_values, index=new_index,
+                            fill_value=self.fill_value)
 
     def take(self, indices):
+        """
+        Sparse-compatible version of ndarray.take
+
+        Returns
+        -------
+        y : SparseSeries
+        """
         pass
 
     def put(self, indices, values):
+        """
+        Sparse-compatible version of ndarray.put
+
+        Returns
+        -------
+        y : SparseSeries
+        """
         pass
 
+    def count(self):
+        sp_values = self.sp_values
+        valid_spvals = np.isfinite(sp_values).sum()
+        if self._null_fill_value:
+            return valid_spvals
+        else:
+            return valid_spvals + (len(self) - len(sp_values))
+
+    @property
+    def _null_fill_value(self):
+        return np.isnan(self.fill_value)
+
+    def sum(self, axis=None, dtype=None, out=None):
+        """
+        Sum of non-null values
+        """
+        sp_vals = self.sp_values
+        mask = np.isfinite(sp_vals)
+        sp_sum = sp_vals[mask].sum()
+        num_sparse = len(self) - len(sp_vals)
+        if self._null_fill_value:
+            return sp_sum
+        else:
+            return sp_sum + self.fill_value * num_sparse
+
+    def mean(self, axis=None, dtype=None, out=None):
+        """
+        Mean of non-null values
+        """
+        sp_vals = self.sp_values
+        mask = np.isfinite(sp_vals)
+        ct = mask.sum()
+        sp_sum = sp_vals[mask].sum()
+        num_sparse = len(self) - len(sp_vals)
+        if self._null_fill_value:
+            return sp_sum / ct
+        else:
+            return (sp_sum + self.fill_value * num_sparse) / (ct + num_sparse)
+
 class SparseTimeSeries(SparseSeries, TimeSeries):
     pass
 
@@ -331,9 +411,7 @@ class SparseDataFrame(DataFrame):
             if isinstance(v, Series):
                 # Forces alignment and copies data
                 v = v.reindex(index)
-                if not isinstance(v, SparseSeries):
-                    v = to_sparse_series(v, kind=self.kind,
-                                         fill_value=self.fill_value)
+                v = v.to_sparse()
             else:
                 if isinstance(v, dict):
                     v = [v.get(i, nan) for i in index]
@@ -351,6 +429,17 @@ class SparseDataFrame(DataFrame):
 
         return sdict, columns, index
 
+    def to_dense(self):
+        """
+        Convert to dense DataFrame
+
+        Returns
+        -------
+        df : DataFrame
+        """
+        data = dict((k, v.to_dense) for k, v in self.iteritems())
+        return DataFrame(data, index=self.index)
+
     def _reindex_index(self, index, method):
         if self.index.equals(index):
             return self.copy()
diff --git a/pandas/core/tests/test_frame.py b/pandas/core/tests/test_frame.py
index 54270664c..d7024f52b 100644
--- a/pandas/core/tests/test_frame.py
+++ b/pandas/core/tests/test_frame.py
@@ -344,20 +344,20 @@ class TestDataFrame(unittest.TestCase):
 
         # no columns or index
         buf = StringIO()
-        self.empty.info(buffer=buf)
+        self.empty.info(buf=buf)
 
         # columns are not sortable
         foo = repr(self.unsortable)
 
         # do not fail!
-        self.frame.head(buffer=buf)
-        self.frame.tail(buffer=buf)
+        self.frame.head(buf=buf)
+        self.frame.tail(buf=buf)
 
         for i in range(5):
             self.frame['foo%d' % i] = 1
 
-        self.frame.head(buffer=buf)
-        self.frame.tail(buffer=buf)
+        self.frame.head(buf=buf)
+        self.frame.tail(buf=buf)
 
     def test_repr_corner(self):
         # representing infs poses no problems
@@ -373,17 +373,17 @@ class TestDataFrame(unittest.TestCase):
         biggie['A'][:20] = np.NaN
         biggie['B'][:20] = np.NaN
         buf = StringIO()
-        biggie.toString(buffer=buf)
+        biggie.toString(buf=buf)
 
-        biggie.toString(buffer=buf, columns=['B', 'A'], colSpace=17)
-        biggie.toString(buffer=buf, columns=['B', 'A'],
+        biggie.toString(buf=buf, columns=['B', 'A'], colSpace=17)
+        biggie.toString(buf=buf, columns=['B', 'A'],
                         formatters={'A' : lambda x: '%.1f' % x})
 
-        biggie.toString(buffer=buf, columns=['B', 'A'],
+        biggie.toString(buf=buf, columns=['B', 'A'],
                         float_format=str)
 
         frame = self.klass(index=np.arange(1000))
-        frame.toString(buffer=buf)
+        frame.toString(buf=buf)
 
     def test_getitem(self):
         # slicing
diff --git a/pandas/core/tests/test_sparse.py b/pandas/core/tests/test_sparse.py
index a696d9617..094709c45 100644
--- a/pandas/core/tests/test_sparse.py
+++ b/pandas/core/tests/test_sparse.py
@@ -1,3 +1,5 @@
+# pylint: disable-msg=E1101,W0612
+
 from unittest import TestCase
 import operator
 
@@ -7,8 +9,10 @@ import numpy as np
 from pandas.util.testing import assert_almost_equal, assert_series_equal
 from numpy.testing import assert_equal
 
+from pandas import DateRange
+from pandas.core.series import remove_na
 from pandas.core.sparse import (IntIndex, BlockIndex, SparseSeries)
-import pandas.core.sparse as sparsem
+import pandas.core.sparse as spm
 
 """
 Testing TODO
@@ -92,19 +96,17 @@ class TestSparseSeries(TestCase):
         series = self.iseries.to_dense()
         assert_equal(series, arr)
 
-    def test_to_sparse_series(self):
+    def test_to_sparse(self):
         series = self.bseries.to_dense()
-        bseries = sparsem.to_sparse_series(series, kind='block')
-        iseries = sparsem.to_sparse_series(series, kind='integer')
+        bseries = series.to_sparse(kind='block')
+        iseries = series.to_sparse(kind='integer')
         assert_sp_series_equal(bseries, self.bseries)
         assert_sp_series_equal(iseries, self.iseries)
 
         # non-NaN fill value
         series = self.zbseries.to_dense()
-        zbseries = sparsem.to_sparse_series(series, kind='block',
-                                            fill_value=0)
-        ziseries = sparsem.to_sparse_series(series, kind='integer',
-                                            fill_value=0)
+        zbseries = series.to_sparse(kind='block', fill_value=0)
+        ziseries = series.to_sparse(kind='integer', fill_value=0)
         assert_sp_series_equal(zbseries, self.zbseries)
         assert_sp_series_equal(ziseries, self.ziseries)
 
@@ -119,19 +121,57 @@ class TestSparseSeries(TestCase):
         assert_equal(self.zbseries.values, self.bseries.to_dense().fillna(0))
 
         # pass SparseSeries
+        s2 = SparseSeries(self.bseries)
+        s3 = SparseSeries(self.iseries)
+        s4 = SparseSeries(self.zbseries)
+        assert_sp_series_equal(s2, self.bseries)
+        assert_sp_series_equal(s3, self.iseries)
+        assert_sp_series_equal(s4, self.zbseries)
+
+        # Sparse time series works
+        date_index = DateRange('1/1/2000', periods=len(self.bseries))
+        s5 = SparseSeries(self.bseries, index=date_index)
+        self.assert_(isinstance(s5, spm.SparseTimeSeries))
 
         # pass Series
-        series = self.bseries.to_dense()
-        bseries2 = SparseSeries(series)
+        bseries2 = SparseSeries(self.bseries.to_dense())
         assert_equal(self.bseries.sp_values, bseries2.sp_values)
 
         # pass dict
 
+        # don't copy the data by default
+        values = np.ones(len(self.bseries.sp_values))
+        sp = SparseSeries(values, sparse_index=self.bseries.sp_index)
+        sp.sp_values[:5] = 97
+        self.assert_(values[0] == 97)
+
+        # but can make it copy!
+        sp = SparseSeries(values, sparse_index=self.bseries.sp_index,
+                          copy=True)
+        sp.sp_values[:5] = 100
+        self.assert_(values[0] == 97)
+
     def test_constructor_nonnan(self):
         arr = [0, 0, 0, nan, nan]
         sp_series = SparseSeries(arr, fill_value=0)
         assert_equal(sp_series.values, arr)
 
+    def test_copy_astype(self):
+        cop = self.bseries.astype(np.int32)
+        self.assert_(cop is not self.bseries)
+        self.assert_(cop.sp_index is self.bseries.sp_index)
+        self.assert_(cop.dtype == np.float64)
+
+        cop2 = self.iseries.copy()
+
+        assert_sp_series_equal(cop, self.bseries)
+        assert_sp_series_equal(cop2, self.iseries)
+
+        # test that data is copied
+        cop.sp_values[:5] = 97
+        self.assert_(cop.sp_values[0] == 97)
+        self.assert_(self.bseries.sp_values[0] != 97)
+
     def test_getitem(self):
         pass
 
@@ -187,7 +227,34 @@ class TestSparseSeries(TestCase):
         check(self.ziseries, self.ziseries2)
 
     def test_reindex(self):
-        pass
+        def _compare_with_series(sps, new_index):
+            spsre = sps.reindex(new_index)
+
+            series = sps.to_dense()
+            seriesre = series.reindex(new_index)
+            seriesre = seriesre.to_sparse(fill_value=sps.fill_value)
+
+            assert_sp_series_equal(spsre, seriesre)
+            assert_series_equal(spsre.to_dense(), seriesre.to_dense())
+
+        _compare_with_series(self.bseries, self.bseries.index[::2])
+        _compare_with_series(self.bseries, list(self.bseries.index[::2]))
+        _compare_with_series(self.bseries, self.bseries.index[:10])
+        _compare_with_series(self.bseries, self.bseries.index[5:])
+
+        _compare_with_series(self.zbseries, self.zbseries.index[::2])
+        _compare_with_series(self.zbseries, self.zbseries.index[:10])
+        _compare_with_series(self.zbseries, self.zbseries.index[5:])
+
+        # special cases
+        same_index = self.bseries.reindex(self.bseries.index)
+        assert_sp_series_equal(self.bseries, same_index)
+        self.assert_(same_index is not self.bseries)
+
+        # corner cases
+        sp = SparseSeries([], index=[])
+        sp_zero = SparseSeries([], index=[], fill_value=0)
+        _compare_with_series(sp, np.arange(10))
 
     def test_repr(self):
         pass
@@ -204,9 +271,32 @@ class TestSparseSeries(TestCase):
     def test_groupby(self):
         pass
 
+    def test_reductions(self):
+        self.assertEquals(self.bseries.count(), len(self.bseries.sp_values))
+        self.assertEquals(self.bseries.sum(), self.bseries.sp_values.sum())
+        self.assertEquals(self.bseries.mean(), self.bseries.sp_values.mean())
+
+        self.bseries.sp_values[5:10] = np.NaN
+        self.assertEquals(self.bseries.count(), len(self.bseries.sp_values) - 5)
+        self.assertEquals(self.bseries.sum(), remove_na(self.bseries.sp_values).sum())
+
+        self.assertEquals(self.zbseries.count(), len(self.zbseries))
+        self.zbseries.sp_values[5:10] = np.NaN
+        self.assertEquals(self.zbseries.count(), len(self.zbseries) - 5)
+
+        series = self.zbseries.copy()
+        series.fill_value = 2
+        num_sparse = len(self.zbseries) - len(self.zbseries.sp_values)
+        self.assertEquals(series.sum(), self.zbseries.sum() + 2 * num_sparse)
+
+    def test_mean(self):
+        pass
+
 class TestSparseTimeSeries(TestCase):
     pass
 
+class TestSparseDataFrame(TestCase):
+    pass
 
 if __name__ == '__main__':
     import nose
diff --git a/pandas/lib/bench_sparse.py b/pandas/lib/bench_sparse.py
index d1b295d24..cb68cbd14 100644
--- a/pandas/lib/bench_sparse.py
+++ b/pandas/lib/bench_sparse.py
@@ -1,7 +1,9 @@
 import numpy as np
 
-from pandas.core.sparse import SparseSeries
-from pandas.core.index import Index
+from pandas import *
+import pandas.core.sparse as spm
+reload(spm)
+from pandas.core.sparse import SparseSeries, SparseDataFrame
 
 N = 10000.
 
@@ -25,3 +27,11 @@ is2 = SparseSeries(arr2, kind='integer', index=index)
 
 s1_dense = s1.to_dense()
 s2_dense = s2.to_dense()
+
+dm = DataMatrix.load('/home/wesm/code/pandas/example')
+
+data = {}
+for col, ser in dm.iteritems():
+    data[col] = SparseSeries(ser)
+
+sdf = SparseDataFrame(data)
diff --git a/pandas/lib/src/sparse.pyx b/pandas/lib/src/sparse.pyx
index ac87a64ac..d4205267b 100644
--- a/pandas/lib/src/sparse.pyx
+++ b/pandas/lib/src/sparse.pyx
@@ -173,6 +173,27 @@ cdef class IntIndex(SparseIndex):
 
         return IntIndex(x.length, new_list)
 
+    @cython.wraparound(False)
+    cpdef lookup(self, pyst index):
+        cdef:
+            pyst res, n, cum_len = 0
+            ndarray[int32_t, ndim=1] inds
+
+        inds = self.indices
+        res = inds.searchsorted(index)
+        if inds[res] == index:
+            return res
+        else:
+            return -1
+
+    cpdef put(self, ndarray[float64_t, ndim=1] values,
+              ndarray[int32_t, ndim=1] indices, object to_put):
+        pass
+
+    cpdef take(self, ndarray[float64_t, ndim=1] values,
+               ndarray[int32_t, ndim=1] indices):
+        pass
+
 cpdef get_blocks(ndarray[int32_t, ndim=1] indices):
     cdef:
         pyst i, npoints
@@ -403,6 +424,38 @@ cdef class BlockIndex(SparseIndex):
         '''
         return BlockUnion(self, y.to_block_index()).result
 
+    cpdef lookup(self, pyst index):
+        '''
+
+        Returns -1 if not found
+        '''
+        cdef:
+            pyst i, cum_len = 0
+            ndarray[int32_t, ndim=1] locs, lens
+
+        locs = self.blocs
+        lens = self.blengths
+
+        if self.nblocks == 0:
+            return -1
+        elif index < locs[0]:
+            return -1
+
+        for i from 0 <= i < self.nblocks:
+            if index < locs[i] + lens[i]:
+                return cum_len + index - locs[i]
+            cum_len += lens[i]
+
+        return -1
+
+    cpdef put(self, ndarray[float64_t, ndim=1] values,
+              ndarray[int32_t, ndim=1] indices, object to_put):
+        pass
+
+    cpdef take(self, ndarray[float64_t, ndim=1] values,
+               ndarray[int32_t, ndim=1] indices):
+        pass
+
 
 cdef class BlockMerge(object):
     '''
@@ -927,16 +980,24 @@ def reindex_block(ndarray[float64_t, ndim=1] values,
         if indexer[i] == -1:
             pass
 
+
+# cdef class SparseCruncher(object):
+#     '''
+#     Class to acquire float pointer for convenient operations on sparse data
+#     structures
+#     '''
+#     cdef:
+#         SparseIndex index
+#         float64_t* buf
+
+#     def __init__(self, ndarray[float64_t, ndim=1, mode='c'] values,
+#                  SparseIndex index):
+
+#         self.index = index
+#         self.buf = <float64_t*> values.data
+
+
 def reindex_integer(ndarray[float64_t, ndim=1] values,
                     IntIndex sparse_index,
                     ndarray[int32_t, ndim=1] indexer):
     pass
-
-def sparse_put(ndarray[float64_t, ndim=1] values, SparseIndex index,
-               ndarray[int32_t, ndim=1] indices, object to_put):
-    pass
-
-def sparse_take(ndarray[float64_t, ndim=1] values, SparseIndex index,
-                ndarray[int32_t, ndim=1] indices):
-    pass
-
diff --git a/pandas/lib/tests/test_sparse.py b/pandas/lib/tests/test_sparse.py
index 2cdf7600f..99d08fd88 100644
--- a/pandas/lib/tests/test_sparse.py
+++ b/pandas/lib/tests/test_sparse.py
@@ -8,7 +8,7 @@ import operator
 from numpy.testing import assert_almost_equal, assert_equal
 
 from pandas.lib.sparse import IntIndex, BlockIndex
-import pandas.lib.sparse as sparselib
+import pandas.lib.sparse as splib
 
 TEST_LENGTH = 20
 
@@ -154,6 +154,22 @@ def test_index_make_union():
 
     # TODO: different-length index objects
 
+def test_lookup():
+
+    def _check(index):
+        assert(index.lookup(0) == -1)
+        assert(index.lookup(5) == 0)
+        assert(index.lookup(7) == 2)
+        assert(index.lookup(8) == -1)
+        assert(index.lookup(12) == 3)
+        assert(index.lookup(17) == 8)
+
+    bindex = BlockIndex(20, [5, 12], [3, 6])
+    iindex = bindex.to_int_index()
+
+    _check(bindex)
+    _check(iindex)
+
 class TestBlockIndex(TestCase):
 
     def test_equals(self):
@@ -319,7 +335,7 @@ class TestSparseOperators(TestCase):
 check_ops = ['add', 'sub', 'mul', 'div']
 def make_nanoptestf(op):
     def f(self):
-        sparse_op = getattr(sparselib, 'sparse_nan%s' % op)
+        sparse_op = getattr(splib, 'sparse_nan%s' % op)
         python_op = getattr(operator, op)
         self._nan_op_tests(sparse_op, python_op)
     f.__name__ = 'test_nan%s' % op
@@ -327,7 +343,7 @@ def make_nanoptestf(op):
 
 def make_optestf(op):
     def f(self):
-        sparse_op = getattr(sparselib, 'sparse_%s' % op)
+        sparse_op = getattr(splib, 'sparse_%s' % op)
         python_op = getattr(operator, op)
         self._op_tests(sparse_op, python_op)
     f.__name__ = 'test_%s' % op
