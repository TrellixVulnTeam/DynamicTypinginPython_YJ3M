commit 4a4292bc296431fdb937d4ae785d649130e57164
Author: Jeff Reback <jeff@reback.net>
Date:   Tue Oct 20 14:10:59 2015 -0400

    TST: move some tests to slow

diff --git a/pandas/tests/test_graphics.py b/pandas/tests/test_graphics.py
index 83b76393f..b85f4628a 100644
--- a/pandas/tests/test_graphics.py
+++ b/pandas/tests/test_graphics.py
@@ -3169,6 +3169,7 @@ class TestDataFramePlots(TestPlotBase):
                               ax.get_legend().get_texts()],
                              base_expected[:i] + base_expected[i+1:])
 
+    @slow
     def test_errorbar_plot(self):
         d = {'x': np.arange(12), 'y': np.arange(12, 0, -1)}
         df = DataFrame(d)
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 8eb641ce8..46026a4c8 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -1655,6 +1655,7 @@ class TestGroupBy(tm.TestCase):
             check_nunique(frame, ['jim'])
             check_nunique(frame, ['jim', 'joe'])
 
+    @slow
     def test_series_groupby_value_counts(self):
         from itertools import product
 
diff --git a/pandas/tests/test_indexing.py b/pandas/tests/test_indexing.py
index 90f85b3f4..0f7a5261c 100644
--- a/pandas/tests/test_indexing.py
+++ b/pandas/tests/test_indexing.py
@@ -25,6 +25,7 @@ from pandas.io.common import PerformanceWarning
 
 import pandas.util.testing as tm
 from pandas import date_range
+from numpy.testing.decorators import slow
 
 _verbose = False
 
@@ -1689,74 +1690,71 @@ Region_1,Site_2,3977723089,A,5/20/2015 8:33,5/20/2015 9:09,Yes,No"""
         with tm.assert_produces_warning(PerformanceWarning):
             _ = df.loc[(0,)]
 
+    @slow
     def test_multiindex_get_loc(self):  # GH7724, GH2646
 
-        # ignore the warning here
-        warnings.simplefilter('ignore', PerformanceWarning)
+        with warnings.catch_warnings(PerformanceWarning):
 
-        # test indexing into a multi-index before & past the lexsort depth
-        from numpy.random import randint, choice, randn
-        cols = ['jim', 'joe', 'jolie', 'joline', 'jolia']
+            # test indexing into a multi-index before & past the lexsort depth
+            from numpy.random import randint, choice, randn
+            cols = ['jim', 'joe', 'jolie', 'joline', 'jolia']
 
-        def validate(mi, df, key):
-            mask = np.ones(len(df)).astype('bool')
+            def validate(mi, df, key):
+                mask = np.ones(len(df)).astype('bool')
 
-            # test for all partials of this key
-            for i, k in enumerate(key):
-                mask &= df.iloc[:, i] == k
+                # test for all partials of this key
+                for i, k in enumerate(key):
+                    mask &= df.iloc[:, i] == k
 
-                if not mask.any():
-                    self.assertNotIn(key[:i+1], mi.index)
-                    continue
-
-                self.assertIn(key[:i+1], mi.index)
-                right = df[mask].copy()
+                    if not mask.any():
+                        self.assertNotIn(key[:i+1], mi.index)
+                        continue
 
-                if i + 1 != len(key):  # partial key
-                    right.drop(cols[:i+1], axis=1, inplace=True)
-                    right.set_index(cols[i+1:-1], inplace=True)
-                    assert_frame_equal(mi.loc[key[:i+1]], right)
+                    self.assertIn(key[:i+1], mi.index)
+                    right = df[mask].copy()
 
-                else:  # full key
-                    right.set_index(cols[:-1], inplace=True)
-                    if len(right) == 1:  # single hit
-                        right = Series(right['jolia'].values,
-                                name=right.index[0], index=['jolia'])
-                        assert_series_equal(mi.loc[key[:i+1]], right)
-                    else:  # multi hit
+                    if i + 1 != len(key):  # partial key
+                        right.drop(cols[:i+1], axis=1, inplace=True)
+                        right.set_index(cols[i+1:-1], inplace=True)
                         assert_frame_equal(mi.loc[key[:i+1]], right)
 
-        def loop(mi, df, keys):
-            for key in keys:
-                validate(mi, df, key)
-
-        n, m = 1000, 50
-
-        vals = [randint(0, 10, n), choice(list('abcdefghij'), n),
-                choice(pd.date_range('20141009', periods=10).tolist(), n),
-                choice(list('ZYXWVUTSRQ'), n), randn(n)]
-        vals = list(map(tuple, zip(*vals)))
-
-        # bunch of keys for testing
-        keys = [randint(0, 11, m), choice(list('abcdefghijk'), m),
-                choice(pd.date_range('20141009', periods=11).tolist(), m),
-                choice(list('ZYXWVUTSRQP'), m)]
-        keys = list(map(tuple, zip(*keys)))
-        keys += list(map(lambda t: t[:-1], vals[::n//m]))
-
-        # covers both unique index and non-unique index
-        df = pd.DataFrame(vals, columns=cols)
-        a, b = pd.concat([df, df]), df.drop_duplicates(subset=cols[:-1])
-
-        for frame in a, b:
-            for i in range(5):  # lexsort depth
-                df = frame.copy() if i == 0 else frame.sort_values(by=cols[:i])
-                mi = df.set_index(cols[:-1])
-                assert not mi.index.lexsort_depth < i
-                loop(mi, df, keys)
-
-        # restore
-        warnings.simplefilter('always', PerformanceWarning)
+                    else:  # full key
+                        right.set_index(cols[:-1], inplace=True)
+                        if len(right) == 1:  # single hit
+                            right = Series(right['jolia'].values,
+                                           name=right.index[0], index=['jolia'])
+                            assert_series_equal(mi.loc[key[:i+1]], right)
+                        else:  # multi hit
+                            assert_frame_equal(mi.loc[key[:i+1]], right)
+
+            def loop(mi, df, keys):
+                for key in keys:
+                    validate(mi, df, key)
+
+            n, m = 1000, 50
+
+            vals = [randint(0, 10, n), choice(list('abcdefghij'), n),
+                    choice(pd.date_range('20141009', periods=10).tolist(), n),
+                    choice(list('ZYXWVUTSRQ'), n), randn(n)]
+            vals = list(map(tuple, zip(*vals)))
+
+            # bunch of keys for testing
+            keys = [randint(0, 11, m), choice(list('abcdefghijk'), m),
+                    choice(pd.date_range('20141009', periods=11).tolist(), m),
+                    choice(list('ZYXWVUTSRQP'), m)]
+            keys = list(map(tuple, zip(*keys)))
+            keys += list(map(lambda t: t[:-1], vals[::n//m]))
+
+            # covers both unique index and non-unique index
+            df = pd.DataFrame(vals, columns=cols)
+            a, b = pd.concat([df, df]), df.drop_duplicates(subset=cols[:-1])
+
+            for frame in a, b:
+                for i in range(5):  # lexsort depth
+                    df = frame.copy() if i == 0 else frame.sort_values(by=cols[:i])
+                    mi = df.set_index(cols[:-1])
+                    assert not mi.index.lexsort_depth < i
+                    loop(mi, df, keys)
 
     def test_series_getitem_multiindex(self):
 
@@ -4653,6 +4651,7 @@ Region_1,Site_2,3977723089,A,5/20/2015 8:33,5/20/2015 9:09,Yes,No"""
         assert_series_equal(df2.loc[:,'a'], df2.iloc[:,0])
         assert_series_equal(df2.loc[:,'a'], df2.ix[:,0])
 
+    @slow
     def test_large_dataframe_indexing(self):
         #GH10692
         result = DataFrame({'x': range(10**6)},dtype='int64')
@@ -4660,6 +4659,7 @@ Region_1,Site_2,3977723089,A,5/20/2015 8:33,5/20/2015 9:09,Yes,No"""
         expected = DataFrame({'x': range(10**6 + 1)},dtype='int64')
         assert_frame_equal(result, expected)
 
+    @slow
     def test_large_mi_dataframe_indexing(self):
         #GH10645
         result = MultiIndex.from_arrays([range(10**6), range(10**6)])
diff --git a/pandas/tools/tests/test_merge.py b/pandas/tools/tests/test_merge.py
index 929a72cfd..b555a7dc2 100644
--- a/pandas/tools/tests/test_merge.py
+++ b/pandas/tools/tests/test_merge.py
@@ -20,6 +20,7 @@ from pandas.util.testing import (assert_frame_equal, assert_series_equal,
 from pandas import isnull, DataFrame, Index, MultiIndex, Panel, Series, date_range, read_table, read_csv
 import pandas.algos as algos
 import pandas.util.testing as tm
+from numpy.testing.decorators import slow
 
 a_ = np.array
 
@@ -1410,6 +1411,7 @@ class TestMergeMulti(tm.TestCase):
 
         tm.assert_frame_equal(result, expected)
 
+    @slow
     def test_int64_overflow_issues(self):
         from itertools import product
         from collections import defaultdict
