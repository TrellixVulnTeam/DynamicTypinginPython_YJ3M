commit 3c77f2929c9a81fc8ceeab92d1b75fe41e273474
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Oct 29 18:52:05 2012 -0400

    ENH: dtype specification with dict or string/dtype

diff --git a/pandas/io/tests/test_cparser.py b/pandas/io/tests/test_cparser.py
index 07a345fbb..51a023fc9 100644
--- a/pandas/io/tests/test_cparser.py
+++ b/pandas/io/tests/test_cparser.py
@@ -195,6 +195,57 @@ class TestCParser(unittest.TestCase):
     def test_na_substitution(self):
         pass
 
+    def test_numpy_string_dtype(self):
+        data = """\
+a,1
+aa,2
+aaa,3
+aaaa,4
+aaaaa,5"""
+
+        def _make_reader(**kwds):
+            return TextReader(StringIO(data), delimiter=',', header=None,
+                                **kwds)
+
+        reader = _make_reader(dtype='S5,i4')
+        result = reader.read()
+
+        self.assert_(result[0].dtype == 'S5')
+
+        ex_values = np.array(['a', 'aa', 'aaa', 'aaaa', 'aaaaa'], dtype='S5')
+        self.assert_((result[0] == ex_values).all())
+        self.assert_(result[1].dtype == 'i4')
+
+        reader = _make_reader(dtype='S4')
+        result = reader.read()
+        self.assert_(result[0].dtype == 'S4')
+        ex_values = np.array(['a', 'aa', 'aaa', 'aaaa', 'aaaa'], dtype='S4')
+        self.assert_((result[0] == ex_values).all())
+        self.assert_(result[1].dtype == 'S4')
+
+        reader = _make_reader(dtype='S4', as_recarray=True)
+        result = reader.read()
+        self.assert_(result['0'].dtype == 'S4')
+        ex_values = np.array(['a', 'aa', 'aaa', 'aaaa', 'aaaa'], dtype='S4')
+        self.assert_((result['0'] == ex_values).all())
+        self.assert_(result['1'].dtype == 'S4')
+
+    def test_pass_dtype(self):
+        data = """\
+one,two
+1,a
+2,b
+3,c
+4,d"""
+        def _make_reader(**kwds):
+            return TextReader(StringIO(data), delimiter=',', **kwds)
+
+        reader = _make_reader(dtype={'one': 'u1', 1: 'S1'})
+        result = reader.read()
+
+        self.assert_(result[0].dtype == 'u1')
+        self.assert_(result[1].dtype == 'S1')
+
 
 def assert_array_dicts_equal(left, right):
     for k, v in left.iteritems():
diff --git a/pandas/src/parser.pyx b/pandas/src/parser.pyx
index f2dd625ea..9aa8105ae 100644
--- a/pandas/src/parser.pyx
+++ b/pandas/src/parser.pyx
@@ -2,6 +2,7 @@
 # See LICENSE for the license
 
 from libc.stdlib cimport malloc, free
+from libc.string cimport strncpy
 
 from cpython cimport (PyObject, PyString_FromString,
                       PyString_AsString, PyString_Check)
@@ -224,6 +225,7 @@ cdef class TextReader:
         object low_memory
         object skiprows
         object compact_ints, use_unsigned
+        object dtype
         set noconvert
 
     def __cinit__(self, source,
@@ -251,6 +253,8 @@ cdef class TextReader:
                   decimal=b'.',
                   thousands=None,
 
+                  dtype=None,
+
                   error_bad_lines=True,
                   warn_bad_lines=True,
 
@@ -341,6 +345,19 @@ cdef class TextReader:
         self.low_memory = low_memory
         self.buffer_lines = buffer_lines
 
+        if isinstance(dtype, dict):
+            conv = {}
+            for k in dtype:
+                v = dtype[k]
+                if isinstance(v, basestring):
+                    v = np.dtype(v)
+                conv[k] = v
+            dtype = conv
+        elif dtype is not None:
+            dtype = np.dtype(dtype)
+
+        self.dtype = dtype
+
         # XXX
         self.noconvert = set()
 
@@ -507,7 +524,7 @@ cdef class TextReader:
             columns = self._read_low_memory(rows)
         else:
             # Don't care about memory usage
-            columns = self._read_high_memory(rows, 1)
+            columns = self._read_rows(rows, 1)
 
         if self.as_recarray:
             self._start_clock()
@@ -526,7 +543,7 @@ cdef class TextReader:
         if rows is None:
             while True:
                 try:
-                    chunk = self._read_high_memory(self.buffer_lines, 0)
+                    chunk = self._read_rows(self.buffer_lines, 0)
                     if len(chunk) == 0:
                         break
                 except StopIteration:
@@ -538,7 +555,7 @@ cdef class TextReader:
                 try:
                     crows = min(self.buffer_lines, rows - rows_read)
 
-                    chunk = self._read_high_memory(crows, 0)
+                    chunk = self._read_rows(crows, 0)
                     if len(chunk) == 0:
                         break
 
@@ -563,7 +580,7 @@ cdef class TextReader:
         if status < 0:
             raise_parser_error('Error tokenizing data', self.parser)
 
-    cdef _read_high_memory(self, rows, bint trim):
+    cdef _read_rows(self, rows, bint trim):
         cdef:
             int buffered_lines
             int irows, footer = 0
@@ -633,6 +650,7 @@ cdef class TextReader:
             cast_func func
             kh_str_t *na_hashset = NULL
             int start, end
+            object name
             bint na_filter = 0
 
         start = self.parser_start
@@ -666,19 +684,9 @@ cdef class TextReader:
                 results[i] = _apply_converter(conv, self.parser, i, start, end)
                 continue
 
-            if i in self.noconvert:
-                func = _string_box_factorize
-                col_res, na_count = func(self.parser, i, start, end,
-                                         na_filter, na_hashset)
-                results[i] = col_res
-            else:
-                col_res = None
-                for func in cast_func_order:
-                    col_res, na_count = func(self.parser, i, start, end,
-                                             na_filter, na_hashset)
-                    if col_res is not None:
-                        results[i] = col_res
-                        break
+            # Should return as the desired dtype (inferred or specified)
+            col_res, na_count = self._convert_tokens(i, start, end, name,
+                                                     na_filter, na_hashset)
 
             if na_filter:
                 self._free_na_set(na_hashset)
@@ -698,6 +706,83 @@ cdef class TextReader:
 
         return results
 
+    cdef inline _convert_tokens(self, Py_ssize_t i, int start, int end,
+                                object name, bint na_filter,
+                                kh_str_t *na_hashset):
+        cdef:
+            cast_func func
+            object col_dtype = None
+
+        if self.dtype is not None:
+            if isinstance(self.dtype, dict):
+                if name in self.dtype:
+                    col_dtype = self.dtype[name]
+                elif i in self.dtype:
+                    col_dtype = self.dtype[i]
+            else:
+                if self.dtype.names:
+                    col_dtype = self.dtype.descr[i][1]
+                else:
+                    col_dtype = self.dtype
+
+            if col_dtype is not None:
+                if isinstance(col_dtype, np.dtype):
+                    col_dtype = col_dtype.str
+                return self._convert_with_dtype(col_dtype, i, start, end,
+                                                na_filter, na_hashset)
+
+        if i in self.noconvert:
+            func = _string_box_factorize
+            return func(self.parser, i, start, end, na_filter, na_hashset)
+        else:
+            col_res = None
+            for func in cast_func_order:
+                col_res, na_count = func(self.parser, i, start, end,
+                                         na_filter, na_hashset)
+                if col_res is not None:
+                    break
+
+        return col_res, na_count
+
+    cdef _convert_with_dtype(self, object dtype, Py_ssize_t i,
+                             int start, int end,
+                             bint na_filter, kh_str_t *na_hashset):
+
+        if dtype[1] == 'i' or dtype[1] == 'u':
+            result, na_count = _try_int64(self.parser, i, start, end,
+                                          na_filter, na_hashset)
+            if na_count > 0:
+                raise Exception('Integer column has NA values')
+
+            if dtype[1:] != 'i8':
+                result = result.astype(dtype)
+
+            return result, na_count
+
+        elif dtype[1] == 'f':
+            result, na_count = _try_double(self.parser, i, start, end,
+                                           na_filter, na_hashset)
+
+            if dtype[1:] != 'f8':
+                result = result.astype(dtype)
+            return result, na_count
+
+        elif dtype[1] == 'c':
+            raise NotImplementedError
+
+        elif dtype[1] == 'S':
+            # TODO: na handling
+            width = int(dtype[2:])
+            result = _to_fw_string(self.parser, i, start, end, width)
+            return result, 0
+        elif dtype[1] == 'U':
+            width = int(dtype[2:])
+            raise NotImplementedError
+
+        elif dtype[1] == 'O':
+            return _string_box_factorize(self.parser, i, start, end,
+                                         na_filter, na_hashset)
+
     def _get_converter(self, i, name):
         if self.converters is None:
             return None
@@ -776,6 +861,7 @@ ctypedef object (*cast_func)(parser_t *parser, int col,
                              int line_start, int line_end,
                              bint na_filter, kh_str_t *na_hashset)
 
+
 cdef _string_box_factorize(parser_t *parser, int col,
                            int line_start, int line_end,
                            bint na_filter, kh_str_t *na_hashset):
@@ -831,6 +917,27 @@ cdef _string_box_factorize(parser_t *parser, int col,
     return result, na_count
 
 
+cdef _to_fw_string(parser_t *parser, int col, int line_start,
+                   int line_end, size_t width):
+    cdef:
+        int error
+        Py_ssize_t i, j
+        coliter_t it
+        char *word, *data
+        ndarray result
+
+    result = np.empty(line_end - line_start, dtype='|S%d' % width)
+    data = <char*> result.data
+
+    coliter_setup(&it, parser, col, line_start)
+
+    for i in range(line_end - line_start):
+        word = COLITER_NEXT(it)
+        strncpy(data, word, width)
+        data += width
+
+    return result
+
 
 cdef _try_double(parser_t *parser, int col, int line_start, int line_end,
                  bint na_filter, kh_str_t *na_hashset):
diff --git a/pandas/src/parser/parser.c b/pandas/src/parser/parser.c
index 40cb9348c..4ed348f73 100644
--- a/pandas/src/parser/parser.c
+++ b/pandas/src/parser/parser.c
@@ -231,411 +231,6 @@ int parser_file_source_init(parser_t *self, FILE* fp) {
      return buffer;
  }
 
- typedef struct _typed_array {
-     char type_code;
-     int elsize;
-     size_t length;
-     void *data;
- } typed_array;
-
- #define array_t typed_array
-
-
-
- /*
-  *  XXX Handle errors in any of the functions called by read_rows().
-  *
-  *  XXX Currently *nrows must be at least 1.
-  */
-
- /* void *read_rows(FILE *f, */
- /*              int *nrows, */
- /*              char *fmt, */
- /*                 char delimiter, */
- /*              char quote, */
- /*              char comment, */
- /*                 char sci, */
- /*              char decimal, */
- /*                 int allow_embedded_newline, */
- /*                 char *datetime_fmt, */
- /*                 int tz_offset, */
- /*                 int32_t *usecols, */
- /*              int num_usecols, */
- /*                 int skiprows, */
- /*                 void *data_array, */
- /*                 int *p_error_type, */
- /*              int *p_error_lineno) */
- /* { */
- /*     void *fb; */
- /*     char *data_ptr; */
- /*     int num_fields, current_num_fields; */
- /*     char **result; */
- /*     int fmt_nfields; */
- /*     field_type *ftypes; */
- /*     int size; */
- /*     int row_count; */
- /*     int j; */
- /*     int *valid_usecols; */
- /*     char word_buffer[WORD_BUFFER_SIZE]; */
- /*     int tok_error_type; */
-
- /*     *p_error_type = 0; */
- /*     *p_error_lineno = 0; */
-
- /*     if (datetime_fmt == NULL || strlen(datetime_fmt) == 0) { */
- /*         datetime_fmt = "%Y-%m-%d %H:%M:%S"; */
- /*     } */
-
- /*     size = (*nrows) * calc_size(fmt, &fmt_nfields); */
-
- /*     ftypes = enumerate_fields(fmt);  /\* Must free this when finished. *\/ */
- /*     if (ftypes == NULL) { */
- /*         /\* Out of memory. *\/ */
- /*         *p_error_type = READ_ERROR_OUT_OF_MEMORY; */
- /*         return NULL; */
- /*     } */
-
- /*     /\* */
- /*     for (k = 0; k < fmt_nfields; ++k) { */
- /*         printf("k = %d  typechar = '%c'  size = %d\n", k, ftypes[k].typechar, ftypes[k].size); */
- /*     } */
- /*     printf("size = %d\n", size); */
- /*     printf("-----\n"); */
- /*     *\/ */
-
- /*     if (data_array == NULL) { */
- /*         /\* XXX The case where data_ptr is allocated here is untested. *\/ */
- /*         data_ptr = malloc(size); */
- /*     } */
- /*     else { */
- /*         data_ptr = data_array; */
- /*     } */
-
- /*     fb = new_file_buffer(f, -1); */
- /*     if (fb == NULL) { */
- /*         free(ftypes); */
- /*         *p_error_type = ERROR_OUT_OF_MEMORY; */
- /*         return NULL; */
- /*     } */
-
- /*     /\* XXX Check interaction of skiprows with comments. *\/ */
- /*     while ((skiprows > 0) && ((result = tokenize(fb, word_buffer, WORD_BUFFER_SIZE, */
- /*                               delimiter, quote, comment, &num_fields, TRUE, &tok_error_type)) != NULL)) { */
- /*         if (result == NULL) { */
- /*             break; */
- /*         } */
- /*         free(result); */
- /*         --skiprows; */
- /*     } */
-
- /*     if (skiprows > 0) { */
- /*         /\* There were fewer rows in the file than skiprows. *\/ */
- /*         /\* This is not treated as an error. The result should be an empty array. *\/ */
- /*         *nrows = 0; */
- /*         free(ftypes); */
- /*         del_file_buffer(fb, RESTORE_FINAL); */
- /*         return data_ptr; */
- /*     } */
-
- /*     /\* XXX Assume *nrows > 0! *\/ */
- /*     /\* */
- /*      *  Read the first row to get the number of fields in the file. */
- /*      *  We'll then use this to pre-validate the values in usecols. */
- /*      *  (It might be easier to do this in the Python wrapper, but that */
- /*      *  would require refactoring the C interface a bit to expose more */
- /*      *  to Python.) */
- /*      *\/ */
- /*     row_count = 0; */
- /*     result = tokenize(fb, word_buffer, WORD_BUFFER_SIZE, */
- /*                               delimiter, quote, comment, &num_fields, TRUE, &tok_error_type); */
- /*     if (result == NULL) { */
- /*         *p_error_type = tok_error_type; */
- /*         *p_error_lineno = 1; */
- /*         free(ftypes); */
- /*         del_file_buffer(fb, RESTORE_FINAL); */
- /*         return NULL; */
- /*     } */
-
- /*     valid_usecols = (int *) malloc(num_usecols * sizeof(int)); */
- /*     if (valid_usecols == NULL) { */
- /*         /\* Out of memory. *\/ */
- /*         *p_error_type = ERROR_OUT_OF_MEMORY; */
- /*         free(result); */
- /*         free(ftypes); */
- /*         del_file_buffer(fb, RESTORE_FINAL); */
- /*         return NULL; */
- /*     } */
-
- /*     /\* */
- /*      *  Validate the column indices in usecols, and put the validated */
- /*      *  column indices in valid_usecols. */
- /*      *\/ */
- /*     for (j = 0; j < num_usecols; ++j) { */
-
- /*         int32_t k; */
- /*         k = usecols[j]; */
- /*         if (k < -num_fields || k >= num_fields) { */
- /*             /\* Invalid column index. *\/ */
- /*             *p_error_type = ERROR_INVALID_COLUMN_INDEX; */
- /*             *p_error_lineno = j;  /\* Abuse 'lineno' and put the bad column index there. *\/ */
- /*             free(valid_usecols); */
- /*             free(result); */
- /*             free(ftypes); */
- /*             del_file_buffer(fb, RESTORE_FINAL); */
- /*             return NULL; */
- /*         } */
- /*         if (k < 0) { */
- /*             k += num_fields; */
- /*         } */
- /*         valid_usecols[j] = k; */
- /*     } */
-
- /*     current_num_fields = num_fields; */
- /*     row_count = 0; */
- /*     do { */
- /*         int j, k; */
-
- /*         if (current_num_fields != num_fields) { */
- /*             *p_error_type = ERROR_CHANGED_NUMBER_OF_FIELDS; */
- /*             *p_error_lineno = line_number(fb); */
- /*             break; */
- /*         } */
-
- /*         for (j = 0; j < num_usecols; ++j) { */
-
- /*             int error; */
- /*             char typ = ftypes[j].typechar; */
- /*             /\* k is the column index of the field in the file. *\/ */
- /*             k = valid_usecols[j]; */
-
- /*             /\* XXX Handle error != 0 in the following cases. *\/ */
- /*             if (typ == 'b') { */
- /*                 int8_t x = (int8_t) str_to_int64(result[k], INT8_MIN, INT8_MAX, &error); */
- /*                 *(int8_t *) data_ptr = x; */
- /*                 data_ptr += ftypes[j].size; */
- /*             } */
- /*             else if (typ == 'B') { */
- /*                 uint8_t x = (uint8_t) str_to_uint64(result[k], UINT8_MAX, &error); */
- /*                 *(uint8_t *) data_ptr = x; */
- /*                 data_ptr += ftypes[j].size; */
- /*             } */
- /*             else if (typ == 'h') { */
- /*                 int16_t x = (int16_t) str_to_int64(result[k], INT16_MIN, INT16_MAX, &error); */
- /*                 *(int16_t *) data_ptr = x; */
- /*                 data_ptr += ftypes[j].size; */
- /*             } */
- /*             else if (typ == 'H') { */
- /*                 uint16_t x = (uint16_t) str_to_uint64(result[k], UINT16_MAX, &error); */
- /*                 *(uint16_t *) data_ptr = x; */
- /*                 data_ptr += ftypes[j].size; */
- /*             } */
- /*             else if (typ == 'i') { */
- /*                 int32_t x = (int32_t) str_to_int64(result[k], INT32_MIN, INT32_MAX, &error); */
- /*                 *(int32_t *) data_ptr = x; */
- /*                 data_ptr += ftypes[j].size; */
- /*             } */
- /*             else if (typ == 'I') { */
- /*                 uint32_t x = (uint32_t) str_to_uint64(result[k], UINT32_MAX, &error); */
- /*                 *(uint32_t *) data_ptr = x; */
- /*                 data_ptr += ftypes[j].size; */
- /*             } */
- /*             else if (typ == 'q') { */
- /*                 int64_t x = (int64_t) str_to_int64(result[k], INT64_MIN, INT64_MAX, &error); */
- /*                 *(int64_t *) data_ptr = x; */
- /*                 data_ptr += ftypes[j].size; */
- /*             } */
- /*             else if (typ == 'Q') { */
- /*                 uint64_t x = (uint64_t) str_to_uint64(result[k], UINT64_MAX, &error); */
- /*                 *(uint64_t *) data_ptr = x; */
- /*                 data_ptr += ftypes[j].size; */
- /*             } */
- /*             else if (typ == 'f' || typ == 'd') { */
- /*                 // Convert to float. */
- /*                 double x; */
- /*                 if ((strlen(result[k]) == 0) || !to_double(result[k], &x, sci, decimal)) { */
- /*                     // XXX  Find the canonical platform-independent method to assign nan. */
- /*                     x = 0.0 / 0.0; */
- /*                 } */
- /*                 if (typ == 'f') */
- /*                     *(float *) data_ptr = (float) x; */
- /*                 else */
- /*                     *(double *) data_ptr = x; */
- /*                 data_ptr += ftypes[j].size; */
- /*             } */
- /*             else if (typ == 'c' || typ == 'z') { */
- /*                 // Convert to complex. */
- /*                 double x, y; */
- /*                 if ((strlen(result[k]) == 0) || !to_complex(result[k], &x, &y, sci, decimal)) { */
- /*                     // XXX  Find the canonical platform-independent method to assign nan. */
- /*                     x = 0.0 / 0.0; */
- /*                     y = x; */
- /*                 } */
- /*                 if (typ == 'c') { */
- /*                     *(float *) data_ptr = (float) x; */
- /*                     data_ptr += ftypes[j].size / 2; */
- /*                     *(float *) data_ptr = (float) y; */
- /*                 } */
- /*                 else { */
- /*                     *(double *) data_ptr = x; */
- /*                     data_ptr += ftypes[j].size / 2; */
- /*                     *(double *) data_ptr = y; */
- /*                 } */
- /*                 data_ptr += ftypes[j].size / 2; */
- /*             } */
- /*             else if (typ == 'U') { */
- /*                 // Datetime64, microseconds. */
- /*                 struct tm tm = {0,0,0,0,0,0,0,0,0}; */
- /*                 time_t t; */
-
- /*                 if (strptime(result[k], datetime_fmt, &tm) == NULL) { */
- /*                     memset(data_ptr, 0, 8); */
- /*                 } */
- /*                 else { */
- /*                     tm.tm_isdst = -1; */
- /*                     t = mktime(&tm); */
- /*                     if (t == -1) { */
- /*                         memset(data_ptr, 0, 8); */
- /*                     } */
- /*                     else { */
- /*                         *(uint64_t *) data_ptr = (long long) (t - tz_offset) * 1000000L; */
- /*                     } */
- /*                 } */
- /*                 data_ptr += 8; */
- /*             } */
- /*             else { */
- /*                 // String */
- /*                 strncpy(data_ptr, result[k], ftypes[j].size); */
- /*                 data_ptr += ftypes[j].size; */
- /*             } */
- /*         } */
- /*         free(result); */
- /*         ++row_count; */
- /*     } while ((row_count < *nrows) && (result = tokenize(fb, word_buffer, WORD_BUFFER_SIZE, */
- /*                               delimiter, quote, comment, &current_num_fields, TRUE, &tok_error_type)) != NULL); */
-
- /*     del_file_buffer(fb, RESTORE_FINAL); */
-
- /*     *nrows = row_count; */
-
- /*     free(valid_usecols); */
-
- /*     return (void *) data_ptr; */
- /* } */
-
-
-int merge_chunks(parser_t *parser) {
-    int i, j, ncols = 0;
-
-    // Get a consensus on number of columns and check types
-    for (i = 0; i < parser->nchunks; ++i)
-    {
-        if (i == 0) {
-            ncols = parser->chunks[i].ncols;
-        } else {
-            // XXX this should not happen
-            if (ncols != parser->chunks[i].ncols) {
-                return -1;
-            }
-        }
-    }
-
-    for (i = 0; i < parser->nchunks; ++i)
-    {
-        for (j = 0; j < ncols; ++j)
-        {
-            return -1;
-        }
-    }
-
-    return 0;
-}
-
-int _try_int64(parser_t *parser, array_t *arr, char** strings, size_t length) {
-    int i, error;
-    int64_t *data;
-
-    arr->data = malloc(length * sizeof(int64_t));
-    data = (int64_t*) arr->data;
-
-    for (i = 0; i < length; ++i)
-    {
-        *data++ = (int64_t) str_to_int64(strings[i], INT64_MIN,
-                                         INT64_MAX, &error,
-                                         parser->thousands);
-
-        if (error != 0) {
-            return -1;
-        }
-    }
-
-    return 0;
-}
-
-int _try_float(parser_t *parser, array_t* arr, char** strings, size_t length) {
-    int i, error;
-    double *data;
-
-    arr->data = malloc(length * sizeof(double));
-    data = (double*) arr->data;
-
-    for (i = 0; i < length; ++i)
-    {
-        error = to_double(strings[i], data, parser->sci, parser->decimal);
-
-        if (error != 1) {
-            return -1;
-        }
-    }
-
-    return 0;
-}
-
-
-int _try_boolean(parser_t *parser, array_t* arr, char** strings, size_t length) {
-    int i, error;
-    uint8_t *data;
-
-    arr->data = malloc(length * sizeof(uint8_t));
-    data = (uint8_t*) arr->data;
-
-    for (i = 0; i < length; ++i)
-    {
-        error = to_boolean(strings[i], data);
-
-        if (error != 1) {
-            return -1;
-        }
-    }
-
-    return 0;
-}
-
-typedef int (*cast_func)(parser_t *parser, array_t* arr,
-                         char** strings, size_t length);
-
-static cast_func _inference_order[3] = {_try_int64, _try_float, _try_boolean};
-
-int convert_infer(parser_t *parser, array_t* result,
-                  char** strings, size_t length) {
-
-    int i, status;
-    /* array_t* result = (array_t*) malloc(sizeof(array_t*)); */
-
-    for (i = 0; i < sizeof(_inference_order); ++i)
-    {
-        status = _inference_order[i](parser, result, strings, length);
-
-        if (status == 0) {
-            // success
-            return 0;
-        }
-    }
-
-    free(result);
-
-    return 0;
-}
-
 
 void parser_set_default_options(parser_t *self) {
     // parsing, type inference
