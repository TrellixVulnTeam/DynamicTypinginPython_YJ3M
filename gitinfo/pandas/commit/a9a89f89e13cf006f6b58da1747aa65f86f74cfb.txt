commit a9a89f89e13cf006f6b58da1747aa65f86f74cfb
Author: jreback <jeff@reback.net>
Date:   Tue May 14 16:57:28 2013 -0400

    DOC: updated releasenotes, v0.11.1 whatsnew, io.rst
    
    CLN: changed formatting option: multi_index_columns_compat -> tupleize_cols
    
    BUG: incorrectly writing sparse levels for the multi_index
    
    DOC: slight docs changes
    
    TST: added tests/fixes for dissallowed options in to_csv (cols=not None,index=False)
    
    TST: from_csv not accepting tupleize_cols
    
    ENH: allow index=False in to_csv with a multi_index column
    
         allow reading of a multi_index column with with index_col=None
    
    DOC: updates to examples in io.rst and v0.11.1.rst
    
    TST: disallow names, usecols, non-numeric in index_cols
    
    BUG: raise on too many rows in the header if multi_index of columns

diff --git a/RELEASE.rst b/RELEASE.rst
index acb4f429e..74bafd419 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -34,6 +34,15 @@ pandas 0.11.1
     courtesy of @cpcloud. (GH3477_)
   - Support for reading Amazon S3 files. (GH3504_)
   - Added module for reading and writing Stata files: pandas.io.stata (GH1512_)
+  - Added support for writing in ``to_csv`` and reading in ``read_csv``,
+    multi-index columns. The ``header`` option in ``read_csv`` now accepts a
+    list of the rows from which to read the index. Added the option,
+    ``tupleize_cols`` to provide compatiblity for the pre 0.11.1 behavior of
+    writing and reading multi-index columns via a list of tuples. The default in
+    0.11.1 is to write lists of tuples and *not* interpret list of tuples as a 
+    multi-index column.  
+    Note: The default value will change in 0.12 to make the default *to* write and
+    read multi-index columns in the new format. (GH3571_, GH1651_, GH3141_)
 
 **Improvements to existing features**
 
@@ -180,6 +189,7 @@ pandas 0.11.1
 .. _GH3596: https://github.com/pydata/pandas/issues/3596
 .. _GH3617: https://github.com/pydata/pandas/issues/3617
 .. _GH3435: https://github.com/pydata/pandas/issues/3435
+<<<<<<< HEAD
 .. _GH3611: https://github.com/pydata/pandas/issues/3611
 .. _GH3062: https://github.com/pydata/pandas/issues/3062
 .. _GH3624: https://github.com/pydata/pandas/issues/3624
@@ -187,6 +197,11 @@ pandas 0.11.1
 .. _GH3601: https://github.com/pydata/pandas/issues/3601
 .. _GH3631: https://github.com/pydata/pandas/issues/3631
 .. _GH1512: https://github.com/pydata/pandas/issues/1512
+=======
+.. _GH3571: https://github.com/pydata/pandas/issues/3571
+.. _GH1651: https://github.com/pydata/pandas/issues/1651
+.. _GH3141: https://github.com/pydata/pandas/issues/3141
+>>>>>>> DOC: updated releasenotes, v0.11.1 whatsnew, io.rst
 
 
 pandas 0.11.0
diff --git a/doc/source/io.rst b/doc/source/io.rst
index ef223f64d..42ea4a2ca 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -115,10 +115,10 @@ They can take a number of arguments:
   - ``error_bad_lines``: if False then any lines causing an error will be skipped :ref:`bad lines <io.bad_lines>`
   - ``usecols``: a subset of columns to return, results in much faster parsing 
     time and lower memory usage.
-  - ``mangle_dup_columns``: boolean, default True, then duplicate columns will be specified 
+  - ``mangle_dupe_cols``: boolean, default True, then duplicate columns will be specified 
     as 'X.0'...'X.N', rather than 'X'...'X'
-  - ``multi_index_columns_compat``: boolean, default False, leave a list of tuples on columns
-    as is (default is to convert to a Multi Index on the columns)
+  - ``tupleize_cols``: boolean, default True, if False, convert a list of tuples
+    to a multi-index of columns, otherwise, leave the column index as a list of tuples
 
 .. ipython:: python
    :suppress:
@@ -260,24 +260,6 @@ If the header is in a row other than the first, pass the row number to
     data = 'skip this skip it\na,b,c\n1,2,3\n4,5,6\n7,8,9'
     pd.read_csv(StringIO(data), header=1)
 
-.. _io.multi_index_columns:
-
-Specifying a multi-index columns
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-By specifying list of row locations for the ``header`` argument, you
-can read in a multi-index for the columns. Specifying non-consecutive
-rows will skip the interveaing rows. The ``index_col`` must also be
-specified.
-
-.. ipython:: python
-
-    data = 'C0,C_l0_g0,C_l0_g1\nC1,C_l1_g0,C_l1_g1\nR0,,\nR_l0_g0,R0C0,R0C1\nR_l0_g1,R1C0,R1C1\nR_l0_g2,R2C0,R2C1\n'
-    pd.read_csv(StringIO(data), header=[0,1], index_col=[0])
-
-You can pass ``multi_index_columns_compat=True`` to preserve the pre-0.12 behavior of
-not converting a list of tuples in the columns to a Multi Index.
-
 .. _io.usecols:
 
 Filtering columns (``usecols``)
@@ -787,6 +769,36 @@ column numbers to turn multiple columns into a ``MultiIndex``:
    df
    df.ix[1978]
 
+.. _io.multi_index_columns:
+
+Specifying a multi-index columns
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+By specifying list of row locations for the ``header`` argument, you
+can read in a multi-index for the columns. Specifying non-consecutive
+rows will skip the interveaing rows.
+
+.. ipython:: python
+
+   from pandas.util.testing import makeCustomDataframe as mkdf
+   df = mkdf(5,3,r_idx_nlevels=2,c_idx_nlevels=4)
+   df.to_csv('mi.csv',tupleize_cols=False)
+   print open('mi.csv').read()
+   pd.read_csv('mi.csv',header=[0,1,2,3],index_col=[0,1],tupleize_cols=False)
+
+Note: The default behavior in 0.11.1 remains unchanged (``tupleize_cols=True``),
+but starting with 0.12, the default *to* write and read multi-index columns will be in the new 
+format (``tupleize_cols=False``)
+
+Note: If an ``index_col`` is not specified (e.g. you don't have an index, or wrote it
+with ``df.to_csv(..., index=False``), then any ``names`` on the columns index will be *lost*.
+
+.. ipython:: python
+   :suppress:
+
+   import os
+   os.remove('mi.csv')
+
 .. _io.sniff:
 
 Automatically "sniffing" the delimiter
@@ -870,6 +882,8 @@ function takes a number of arguments. Only the first is required.
   - ``sep`` : Field delimiter for the output file (default ",")
   - ``encoding``: a string representing the encoding to use if the contents are
     non-ascii, for python versions prior to 3
+  - ``tupleize_cols``: boolean, default True, if False, write as a list of tuples,
+    otherwise write in an expanded line format suitable for ``read_csv``
 
 Writing a formatted string
 ~~~~~~~~~~~~~~~~~~~~~~~~~~
@@ -901,6 +915,9 @@ The Series object also has a ``to_string`` method, but with only the ``buf``,
 which, if set to ``True``, will additionally output the length of the Series.
 
 
+HTML
+----
+
 Reading HTML format
 ~~~~~~~~~~~~~~~~~~~~~~
 
diff --git a/doc/source/v0.11.1.txt b/doc/source/v0.11.1.txt
index aed95188d..a724ce96a 100644
--- a/doc/source/v0.11.1.txt
+++ b/doc/source/v0.11.1.txt
@@ -73,6 +73,7 @@ Enhancements
       an index with a different frequency than the existing, or attempting
       to append an index with a different name than the existing
     - support datelike columns with a timezone as data_columns (GH2852_)
+
   - ``fillna`` methods now raise a ``TypeError`` if the ``value`` parameter is
     a list or tuple.
   - Added module for reading and writing Stata files: pandas.io.stata (GH1512_)
@@ -80,6 +81,39 @@ Enhancements
     ``Series`` with object dtype. See the examples section in the regular docs
     :ref:`Replacing via String Expression <missing_data.replace_expression>`
 
+  - Multi-index column support for reading and writing csvs
+
+    - The ``header`` option in ``read_csv`` now accepts a
+      list of the rows from which to read the index.
+
+    - The option, ``tupleize_cols`` can now be specified in both ``to_csv`` and
+      ``read_csv``, to provide compatiblity for the pre 0.11.1 behavior of
+      writing and reading multi-index columns via a list of tuples. The default in
+      0.11.1 is to write lists of tuples and *not* interpret list of tuples as a 
+      multi-index column.  
+
+      Note: The default behavior in 0.11.1 remains unchanged, but starting with 0.12,
+      the default *to* write and read multi-index columns will be in the new 
+      format. (GH3571_, GH1651_, GH3141_)
+
+    - If an ``index_col`` is not specified (e.g. you don't have an index, or wrote it
+      with ``df.to_csv(..., index=False``), then any ``names`` on the columns index will 
+      be *lost*.
+
+    .. ipython:: python
+
+       from pandas.util.testing import makeCustomDataframe as mkdf
+       df = mkdf(5,3,r_idx_nlevels=2,c_idx_nlevels=4)
+       df.to_csv('mi.csv',tupleize_cols=False)
+       print open('mi.csv').read()
+       pd.read_csv('mi.csv',header=[0,1,2,3],index_col=[0,1],tupleize_cols=False)
+
+    .. ipython:: python
+       :suppress:
+
+       import os
+       os.remove('mi.csv')
+
 See the `full release notes
 <https://github.com/pydata/pandas/blob/master/RELEASE.rst>`__ or issue tracker
 on GitHub for a complete list.
@@ -96,3 +130,6 @@ on GitHub for a complete list.
 .. _GH1512: https://github.com/pydata/pandas/issues/1512
 .. _GH2285: https://github.com/pydata/pandas/issues/2285
 .. _GH3631: https://github.com/pydata/pandas/issues/3631
+.. _GH3571: https://github.com/pydata/pandas/issues/3571
+.. _GH1651: https://github.com/pydata/pandas/issues/1651
+.. _GH3141: https://github.com/pydata/pandas/issues/3141
diff --git a/pandas/core/format.py b/pandas/core/format.py
index e7ac54034..cd4364edc 100644
--- a/pandas/core/format.py
+++ b/pandas/core/format.py
@@ -775,7 +775,7 @@ class CSVFormatter(object):
                  cols=None, header=True, index=True, index_label=None,
                  mode='w', nanRep=None, encoding=None, quoting=None,
                  line_terminator='\n', chunksize=None, engine=None,
-                 multi_index_columns_compat=False):
+                 tupleize_cols=True):
 
         self.engine = engine  # remove for 0.12
 
@@ -804,7 +804,15 @@ class CSVFormatter(object):
             msg= "columns.is_unique == False not supported with engine='python'"
             raise NotImplementedError(msg)
 
-        self.multi_index_columns_compat=multi_index_columns_compat
+        self.tupleize_cols = tupleize_cols
+        self.has_mi_columns = isinstance(obj.columns, MultiIndex
+                                         ) and not self.tupleize_cols
+
+        # validate mi options
+        if self.has_mi_columns:
+            if cols is not None:
+                raise Exception("cannot specify cols with a multi_index on the columns")
+
         if cols is not None:
             if isinstance(cols,Index):
                 cols = cols.to_native_types(na_rep=na_rep,float_format=float_format)
@@ -960,9 +968,8 @@ class CSVFormatter(object):
         obj = self.obj
         index_label = self.index_label
         cols = self.cols
+        has_mi_columns = self.has_mi_columns
         header = self.header
-        has_mi_columns = isinstance(obj.columns, MultiIndex
-                                    ) and not self.multi_index_columns_compat
         encoded_labels = []
 
         has_aliases = isinstance(header, (tuple, list, np.ndarray))
@@ -1017,15 +1024,17 @@ class CSVFormatter(object):
             # write out the names for each level, then ALL of the values for each level
             for i in range(columns.nlevels):
 
-                # name is the first column
-                col_line = [ columns.names[i] ]
+                # we need at least 1 index column to write our col names
+                col_line = []
+                if self.index:
+
+                    # name is the first column
+                    col_line.append( columns.names[i] )
 
-                # skipp len labels-1
-                if self.index and isinstance(index_label,list) and len(index_label)>1:
-                    col_line.extend([ '' ] * (len(index_label)-1))
+                    if isinstance(index_label,list) and len(index_label)>1:
+                        col_line.extend([ '' ] * (len(index_label)-1))
 
-                for j in range(len(columns)):
-                    col_line.append(columns.levels[i][j])
+                col_line.extend(columns.get_level_values(i))
 
                 writer.writerow(col_line)
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index bb7416b23..d91d21db3 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1250,7 +1250,7 @@ class DataFrame(NDFrame):
 
     @classmethod
     def from_csv(cls, path, header=0, sep=',', index_col=0,
-                 parse_dates=True, encoding=None):
+                 parse_dates=True, encoding=None, tupleize_cols=False):
         """
         Read delimited file into DataFrame
 
@@ -1266,6 +1266,9 @@ class DataFrame(NDFrame):
             is used. Different default from read_table
         parse_dates : boolean, default True
             Parse dates. Different default from read_table
+        tupleize_cols : boolean, default True
+            write multi_index columns as a list of tuples (if True)
+            or new (expanded format) if False)
 
         Notes
         -----
@@ -1280,7 +1283,7 @@ class DataFrame(NDFrame):
         from pandas.io.parsers import read_table
         return read_table(path, header=header, sep=sep,
                           parse_dates=parse_dates, index_col=index_col,
-                          encoding=encoding)
+                          encoding=encoding,tupleize_cols=False)
 
     @classmethod
     def from_dta(dta, path, parse_dates=True, convert_categoricals=True, encoding=None, index_col=None):
@@ -1392,7 +1395,7 @@ class DataFrame(NDFrame):
                cols=None, header=True, index=True, index_label=None,
                mode='w', nanRep=None, encoding=None, quoting=None,
                line_terminator='\n', chunksize=None,
-               multi_index_columns_compat=False, **kwds):
+               tupleize_cols=True, **kwds):
         """
         Write DataFrame to a comma-separated values (csv) file
 
@@ -1430,9 +1433,9 @@ class DataFrame(NDFrame):
         quoting : optional constant from csv module
             defaults to csv.QUOTE_MINIMAL
         chunksize : rows to write at a time
-        multi_index_columns_compat : boolean, default False
+        tupleize_cols : boolean, default True
             write multi_index columns as a list of tuples (if True)
-            or new (expanded format)m if False)
+            or new (expanded format) if False)
         """
         if nanRep is not None:  # pragma: no cover
             import warnings
@@ -1450,7 +1453,7 @@ class DataFrame(NDFrame):
                                          header=header, index=index,
                                          index_label=index_label,mode=mode,
                                          chunksize=chunksize,engine=kwds.get("engine"),
-                                         multi_index_columns_compat=multi_index_columns_compat)
+                                         tupleize_cols=tupleize_cols)
             formatter.save()
 
     def to_excel(self, excel_writer, sheet_name='sheet1', na_rep='',
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 78a941218..8063a8d66 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -127,9 +127,9 @@ na_filter: boolean, default True
 usecols : array-like
     Return a subset of the columns.
     Results in much faster parsing time and lower memory usage.
-mangle_dup_columns: boolean, default True
+mangle_dupe_cols: boolean, default True
     Duplicate columns will be specified as 'X.0'...'X.N', rather than 'X'...'X'
-multi_index_columns_compat: boolean, default False
+tupleize_cols: boolean, default False
     Leave a list of tuples on columns as is (default is to convert to
     a Multi Index on the columns)
 
@@ -299,7 +299,7 @@ _parser_defaults = {
     'squeeze': False,
     'compression': None,
     'mangle_dupe_cols': True,
-    'multi_index_columns_compat':False,
+    'tupleize_cols':True,
 }
 
 
@@ -387,7 +387,7 @@ def _make_parser_function(name, sep=','):
                  encoding=None,
                  squeeze=False,
                  mangle_dupe_cols=True,
-                 multi_index_columns_compat=False,
+                 tupleize_cols=True,
                  ):
 
         # Alias sep -> delimiter.
@@ -446,6 +446,7 @@ def _make_parser_function(name, sep=','):
                     low_memory=low_memory,
                     buffer_lines=buffer_lines,
                     mangle_dupe_cols=mangle_dupe_cols,
+                    tupleize_cols=tupleize_cols,
             )
 
         return _read(filepath_or_buffer, kwds)
@@ -540,16 +541,6 @@ class TextFileReader(object):
         if kwds.get('header', 'infer') == 'infer':
             kwds['header'] = 0 if kwds.get('names') is None else None
 
-        # validate header options for mi
-        h = kwds['header']
-        if isinstance(h,(list,tuple,np.ndarray)):
-            if kwds.get('index_col') is None:
-                raise Exception("must have an index_col when have a "
-                                "multi-index header is specified")
-            if kwds.get('as_recarray'):
-                raise Exception("cannot specify as_recarray when "
-                                "specifying a multi-index header")
-
         self.orig_options = kwds
 
         # miscellanea
@@ -737,11 +728,31 @@ class ParserBase(object):
         self.na_values = kwds.get('na_values')
         self.true_values = kwds.get('true_values')
         self.false_values = kwds.get('false_values')
-        self.multi_index_columns_compat = kwds.get('multi_index_columns_compat',False)
+        self.tupleize_cols = kwds.get('tupleize_cols',True)
 
         self._date_conv = _make_date_converter(date_parser=self.date_parser,
                                                dayfirst=self.dayfirst)
 
+        # validate header options for mi
+        self.header = kwds.get('header')
+        if isinstance(self.header,(list,tuple,np.ndarray)):
+            if kwds.get('as_recarray'):
+                raise Exception("cannot specify as_recarray when "
+                                "specifying a multi-index header")
+            if kwds.get('usecols'):
+                raise Exception("cannot specify usecols when "
+                                "specifying a multi-index header")
+            if kwds.get('names'):
+                raise Exception("cannot specify names when "
+                                "specifying a multi-index header")
+
+            # validate index_col that only contains integers
+            if self.index_col is not None:
+                if not (isinstance(self.index_col,(list,tuple,np.ndarray)) and all(
+                        [ com.is_integer(i) for i in self.index_col ]) or com.is_integer(self.index_col)):
+                    raise Exception("index_col must only contain row numbers "
+                                    "when specifying a multi-index header")
+                
         self._name_processed = False
 
     @property
@@ -774,27 +785,46 @@ class ParserBase(object):
         # 0 is the name of the index, assuming index_col is a list of column
         # numbers 
         ic = self.index_col
+        if ic is None:
+            ic = []
+
         if not isinstance(ic, (list,tuple,np.ndarray)):
             ic = [ ic ]
         sic = set(ic)
 
         orig_header = list(header)
+
+        # clean the index_names
         index_names = header.pop(-1) 
-        index_names = [ index_names[i] for i in ic ]
-        field_count = len(header[0])
+        (index_names, names, 
+         index_col) = _clean_index_names(index_names, self.index_col)
 
+        # extract the columns
+        field_count = len(header[0])
         def extract(r):
             return tuple([ r[i] for i in range(field_count) if i not in sic ])
+        columns = zip(*[ extract(r) for r in header ])
+        names = ic + columns
+
+        # if we find 'Unnamed' all of a single level, then our header was too long
+        for n in range(len(columns[0])):
+            if all([ 'Unnamed' in c[n] for c in columns ]):
+                raise Exception("Passed header=[%s] are too many rows for this "
+                                "multi_index of columns" % ','.join([ str(x) for x in self.header ]))
+
+        # clean the column names (if we have an index_col)
+        if len(ic):
+            col_names = [ r[0] if len(r[0]) and 'Unnamed' not in r[0] else None for r in header ]
+        else:
+            col_names = [ None ] * len(header)
 
-        names = ic + zip(*[ extract(r) for r in header ])
-        col_names = [ r[0] if len(r[0]) else None for r in header ]
         passed_names = True
 
         return names, index_names, col_names, passed_names
 
     def _maybe_make_multi_index_columns(self, columns, col_names=None):
         # possibly create a column mi here
-        if not self.multi_index_columns_compat and len(columns) and not isinstance(
+        if not self.tupleize_cols and len(columns) and not isinstance(
             columns, MultiIndex) and all([ isinstance(c,tuple) for c in columns]):
             columns = MultiIndex.from_tuples(columns,names=col_names)
         return columns
@@ -1008,13 +1038,8 @@ class CParserWrapper(ParserBase):
         else:
             if len(self._reader.header) > 1:
                 # we have a multi index in the columns
-                if (self._reader.leading_cols == 0 and
-                    _is_index_col(self.index_col)):
-                    self.names, self.index_names, self.col_names, passed_names = self._extract_multi_indexer_columns(
-                        self._reader.header, self.index_names, self.col_names, passed_names)
-                else:
-                    raise Exception("must have an index_col when have a multi-index "
-                                    "header is specified")
+                self.names, self.index_names, self.col_names, passed_names = self._extract_multi_indexer_columns(
+                    self._reader.header, self.index_names, self.col_names, passed_names)
             else:
                 self.names = list(self._reader.header[0])
 
@@ -1248,7 +1273,6 @@ class PythonParser(ParserBase):
             raise Exception("usecols not supported with engine='python'"
                             " or multicharacter separators (yet).")
 
-        self.header = kwds['header']
         self.encoding = kwds['encoding']
         self.compression = kwds['compression']
         self.skiprows = kwds['skiprows']
@@ -1466,14 +1490,15 @@ class PythonParser(ParserBase):
                     else:
                         this_columns.append(c)
 
-                if self.mangle_dupe_cols:
-                    counts = {}
-                    for i, col in enumerate(this_columns):
-                        cur_count = counts.get(col, 0)
-                        if cur_count > 0:
-                            this_columns[i] = '%s.%d' % (col, cur_count)
-                        counts[col] = cur_count + 1
-
+                if not have_mi_columns:
+                    if self.mangle_dupe_cols:
+                        counts = {}
+                        for i, col in enumerate(this_columns):
+                            cur_count = counts.get(col, 0)
+                            if cur_count > 0:
+                                this_columns[i] = '%s.%d' % (col, cur_count)
+                            counts[col] = cur_count + 1
+        
                 columns.append(this_columns)
 
             self._clear_buffer()
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index b9e773a91..be47f2874 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -1014,20 +1014,30 @@ R_l0_g4,R_l1_g4,R4C0,R4C1,R4C2
 
         # basic test with both engines
         for engine in ['c','python']:
-            df = read_csv(StringIO(data), header=[0,2,3,4],index_col=[0,1], engine=engine)
+            df = read_csv(StringIO(data), header=[0,2,3,4],index_col=[0,1], tupleize_cols=False,
+                          engine=engine)
             tm.assert_frame_equal(df, expected)
 
-        # must specify index_col
-        self.assertRaises(Exception, read_csv, StringIO(data), header=[0,1,2,3])
+        # skipping lines in the header
+        df = read_csv(StringIO(data), header=[0,2,3,4],index_col=[0,1], tupleize_cols=False)
+        tm.assert_frame_equal(df, expected)
+
+        #### invalid options ####
 
         # no as_recarray
         self.assertRaises(Exception, read_csv, StringIO(data), header=[0,1,2,3], 
-                          index_col=[0,1], as_recarray=True)
-
-        # skipping lines in the header
-        df = read_csv(StringIO(data), header=[0,2,3,4],index_col=[0,1])
-        tm.assert_frame_equal(df, expected)
+                          index_col=[0,1], as_recarray=True, tupleize_cols=False)
 
+        # names
+        self.assertRaises(Exception, read_csv, StringIO(data), header=[0,1,2,3], 
+                          index_col=[0,1], names=['foo','bar'], tupleize_cols=False)
+        # usecols
+        self.assertRaises(Exception, read_csv, StringIO(data), header=[0,1,2,3], 
+                          index_col=[0,1], usecols=['foo','bar'], tupleize_cols=False)
+        # non-numeric index_col
+        self.assertRaises(Exception, read_csv, StringIO(data), header=[0,1,2,3], 
+                          index_col=['foo','bar'], tupleize_cols=False)
+        
     def test_pass_names_with_index(self):
         lines = self.data1.split('\n')
         no_header = '\n'.join(lines[1:])
diff --git a/pandas/src/parser.pyx b/pandas/src/parser.pyx
index 62e9d39cd..46f74cbdc 100644
--- a/pandas/src/parser.pyx
+++ b/pandas/src/parser.pyx
@@ -252,7 +252,7 @@ cdef class TextReader:
         object encoding
         object compression
         object mangle_dupe_cols
-        object multi_index_columns_compat
+        object tupleize_cols
         set noconvert, usecols
 
     def __cinit__(self, source,
@@ -306,13 +306,13 @@ cdef class TextReader:
                   skip_footer=0,
                   verbose=False,
                   mangle_dupe_cols=True,
-                  multi_index_columns_compat=False):
+                  tupleize_cols=True):
 
         self.parser = parser_new()
         self.parser.chunksize = tokenize_chunksize
 
         self.mangle_dupe_cols=mangle_dupe_cols
-        self.multi_index_columns_compat=multi_index_columns_compat
+        self.tupleize_cols=tupleize_cols
 
         # For timekeeping
         self.clocks = []
@@ -452,6 +452,7 @@ cdef class TextReader:
             if isinstance(header, list) and len(header):
                 # need to artifically skip the final line
                 # which is still a header line
+                header = list(header)
                 header.append(header[-1]+1)
 
                 self.parser.header_start = header[0]
@@ -611,7 +612,7 @@ cdef class TextReader:
                             name = 'Unnamed: %d' % i
 
                     count = counts.get(name, 0)
-                    if count > 0 and self.mangle_dupe_cols:
+                    if count > 0 and self.mangle_dupe_cols and not self.has_mi_columns:
                         this_header.append('%s.%d' % (name, count))
                     else:
                         this_header.append(name)
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 101bdc76b..68e697680 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -4755,13 +4755,15 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         def _do_test(df,path,r_dtype=None,c_dtype=None,rnlvl=None,cnlvl=None,
                      dupe_col=False):
 
-               header = 0
                if cnlvl:
-                    header = range(cnlvl)
-
-               with ensure_clean(path) as path:
-                    df.to_csv(path,encoding='utf8',chunksize=chunksize)
-                    recons = DataFrame.from_csv(path,header=header,parse_dates=False)
+                   header = range(cnlvl)
+                   with ensure_clean(path) as path:
+                        df.to_csv(path,encoding='utf8',chunksize=chunksize,tupleize_cols=False)
+                        recons = DataFrame.from_csv(path,header=range(cnlvl),tupleize_cols=False,parse_dates=False)
+               else:
+                   with ensure_clean(path) as path:
+                       df.to_csv(path,encoding='utf8',chunksize=chunksize)
+                       recons = DataFrame.from_csv(path,header=0,parse_dates=False)
 
                def _to_uni(x):
                    if not isinstance(x,unicode):
@@ -4991,34 +4993,80 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         with ensure_clean(pname) as path:
             # GH3571, GH1651, GH3141
 
+            def _make_frame(names=None):
+                if names is True:
+                    names = ['first','second']
+                return DataFrame(np.random.randint(0,10,size=(3,3)), 
+                                 columns=MultiIndex.from_tuples([('bah', 'foo'), 
+                                                                 ('bah', 'bar'), 
+                                                                 ('ban', 'baz')],
+                                                                names=names))
+
             # column & index are multi-index
             df = mkdf(5,3,r_idx_nlevels=2,c_idx_nlevels=4)
-            df.to_csv(path)
-            result = read_csv(path,header=[0,1,2,3],index_col=[0,1])
+            df.to_csv(path,tupleize_cols=False)
+            result = read_csv(path,header=[0,1,2,3],index_col=[0,1],tupleize_cols=False)
             assert_frame_equal(df,result)
 
             # column is mi
             df = mkdf(5,3,r_idx_nlevels=1,c_idx_nlevels=4)
-            df.to_csv(path)
-            result = read_csv(path,header=[0,1,2,3],index_col=0)
+            df.to_csv(path,tupleize_cols=False)
+            result = read_csv(path,header=[0,1,2,3],index_col=0,tupleize_cols=False)
             assert_frame_equal(df,result)
 
             # dup column names?
             df = mkdf(5,3,r_idx_nlevels=3,c_idx_nlevels=4)
-            df.to_csv(path)
-            result = read_csv(path,header=[0,1,2,3],index_col=[0,1])
+            df.to_csv(path,tupleize_cols=False)
+            result = read_csv(path,header=[0,1,2,3],index_col=[0,1],tupleize_cols=False)
             result.columns = ['R2','A','B','C']
             new_result = result.reset_index().set_index(['R0','R1','R2'])
             new_result.columns = df.columns
             assert_frame_equal(df,new_result)
 
+            # writing with no index
+            df = _make_frame()
+            df.to_csv(path,tupleize_cols=False,index=False)
+            result = read_csv(path,header=[0,1],tupleize_cols=False)
+            assert_frame_equal(df,result)
+
+            # we lose the names here
+            df = _make_frame(True)
+            df.to_csv(path,tupleize_cols=False,index=False)
+            result = read_csv(path,header=[0,1],tupleize_cols=False)
+            self.assert_(all([ x is None for x in result.columns.names ]))
+            result.columns.names = df.columns.names
+            assert_frame_equal(df,result)
+
+            # whatsnew example
+            df = _make_frame()
+            df.to_csv(path,tupleize_cols=False)
+            result = read_csv(path,header=[0,1],index_col=[0],tupleize_cols=False)
+            assert_frame_equal(df,result)
+
+            df = _make_frame(True)
+            df.to_csv(path,tupleize_cols=False)
+            result = read_csv(path,header=[0,1],index_col=[0],tupleize_cols=False)
+            assert_frame_equal(df,result)
+
             # column & index are multi-index (compatibility)
             df = mkdf(5,3,r_idx_nlevels=2,c_idx_nlevels=4)
-            df.to_csv(path,multi_index_columns_compat=True)
-            result = read_csv(path,header=0,index_col=[0,1],multi_index_columns_compat=True)
+            df.to_csv(path,tupleize_cols=True)
+            result = read_csv(path,header=0,index_col=[0,1],tupleize_cols=True)
             result.columns = df.columns
             assert_frame_equal(df,result)
 
+            # invalid options
+            df = _make_frame(True)
+            df.to_csv(path,tupleize_cols=False)
+
+            # catch invalid headers
+            for i in [3,4,5,6,7]: 
+                 self.assertRaises(Exception, read_csv, path, tupleize_cols=False, header=range(i), index_col=0)
+            self.assertRaises(Exception, read_csv, path, tupleize_cols=False, header=[0,2], index_col=0)
+
+            # write with cols
+            self.assertRaises(Exception, df.to_csv, path,tupleize_cols=False,cols=['foo','bar'])
+
         with ensure_clean(pname) as path:
             # empty
             tsframe[:0].to_csv(path)
