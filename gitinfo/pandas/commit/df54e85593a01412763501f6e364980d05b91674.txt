commit df54e85593a01412763501f6e364980d05b91674
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Feb 5 20:59:46 2012 -0500

    ENH: beef up Float64HashTable, add algorithms.py to start collecting central algos, close #502 at some point

diff --git a/pandas/core/algorithms.py b/pandas/core/algorithms.py
new file mode 100644
index 000000000..475172cc5
--- /dev/null
+++ b/pandas/core/algorithms.py
@@ -0,0 +1,80 @@
+"""
+Generic data algorithms
+"""
+
+import numpy as np
+
+from pandas.core.series import Series
+import pandas.core.common as com
+import pandas._tseries as lib
+
+def match(values, index):
+    """
+
+
+    Parameters
+    ----------
+
+    Returns
+    -------
+    match : ndarray
+    """
+    if com.is_float_dtype(index):
+        return _match_generic(values, index, lib.Float64HashTable,
+                              _ensure_float64)
+    elif com.is_integer_dtype(index):
+        return _match_generic(values, index, lib.Int64HashTable,
+                              _ensure_int64)
+    else:
+        return _match_generic(values, index, lib.PyObjectHashTable,
+                              _ensure_object)
+
+
+def count(values, uniques=None):
+    if uniques is not None:
+        raise NotImplementedError
+    else:
+        if com.is_float_dtype(values):
+            return _count_generic(values, lib.Float64HashTable,
+                                  _ensure_float64)
+        elif com.is_integer_dtype(values):
+            return _count_generic(values, lib.Int64HashTable,
+                                  _ensure_int64)
+        else:
+            return _count_generic(values, lib.PyObjectHashTable,
+                                  _ensure_object)
+
+def _count_generic(values, table_type, type_caster):
+    values = type_caster(values)
+    table = table_type(len(values))
+    uniques, labels, counts = table.factorize(values)
+
+    return Series(counts, index=uniques)
+
+def _match_generic(values, index, table_type, type_caster):
+    values = type_caster(values)
+    index = type_caster(index)
+    table = table_type(len(index))
+    table.map_locations(index)
+    return table.lookup(values)
+
+def factorize(values):
+    pass
+
+def unique(values):
+    pass
+
+def _ensure_float64(arr):
+    if arr.dtype != np.float64:
+        arr = arr.astype(np.float64)
+    return arr
+
+def _ensure_int64(arr):
+    if arr.dtype != np.int64:
+        arr = arr.astype(np.int64)
+    return arr
+
+def _ensure_object(arr):
+    if arr.dtype != np.object_:
+        arr = arr.astype('O')
+    return arr
diff --git a/pandas/src/hashtable.pyx b/pandas/src/hashtable.pyx
index a8161654f..e88a40e11 100644
--- a/pandas/src/hashtable.pyx
+++ b/pandas/src/hashtable.pyx
@@ -3,7 +3,7 @@ from khash cimport *
 def test(ndarray arr, Py_ssize_t size_hint):
     cdef:
         kh_pymap_t *table
-        int ret=0
+        int ret = 0
         khiter_t k
         PyObject **data
         Py_ssize_t i, n
@@ -38,7 +38,7 @@ def test_str(ndarray arr, Py_ssize_t size_hint):
     cdef:
         kh_str_t *table
         kh_cstr_t val
-        int ret=0
+        int ret = 0
         khiter_t k
         PyObject **data
         Py_ssize_t i, n
@@ -93,7 +93,7 @@ def obj_unique(ndarray[object] arr):
         # PyObject *obj
         object obj
         PyObject **data
-        int ret=0
+        int ret = 0
         khiter_t k
         Py_ssize_t i, n
         list uniques
@@ -127,7 +127,7 @@ def int64_unique(ndarray[int64_t] arr):
         # PyObject *obj
         int64_t obj
         PyObject **data
-        int ret=0
+        int ret = 0
         khiter_t k
         Py_ssize_t i, j, n
         ndarray[int64_t] uniques
@@ -190,7 +190,7 @@ cdef class StringHashTable:
     cpdef set_item(self, object key, Py_ssize_t val):
         cdef:
             khiter_t k
-            int ret=0
+            int ret = 0
             char* buf
 
         buf = util.get_c_string(key)
@@ -224,7 +224,7 @@ cdef class StringHashTable:
         cdef:
             Py_ssize_t i, n = len(values)
             Py_ssize_t idx, count = 0
-            int ret=0
+            int ret = 0
             object val
             char *buf
             khiter_t k
@@ -252,7 +252,7 @@ cdef class StringHashTable:
             ndarray[int32_t] counts = np.empty(n, dtype=np.int32)
             dict reverse = {}
             Py_ssize_t idx, count = 0
-            int ret=0
+            int ret = 0
             object val
             char *buf
             khiter_t k
@@ -316,7 +316,7 @@ cdef class Int32HashTable:
     cpdef set_item(self, int32_t key, Py_ssize_t val):
         cdef:
             khiter_t k
-            int ret=0
+            int ret = 0
 
         k = kh_put_int32(self.table, key, &ret)
         self.table.keys[k] = key
@@ -328,20 +328,19 @@ cdef class Int32HashTable:
     def map_locations(self, ndarray[int32_t] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            int ret=0
+            int ret = 0
             int32_t val
             khiter_t k
 
         for i in range(n):
             val = values[i]
             k = kh_put_int32(self.table, val, &ret)
-            # print 'putting %s, %s' % (val, count)
             self.table.vals[k] = i
 
-    def lookup_locations(self, ndarray[int32_t] values):
+    def lookup(self, ndarray[int32_t] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            int ret=0
+            int ret = 0
             int32_t val
             khiter_t k
             ndarray[int32_t] locs = np.empty(n, dtype='i4')
@@ -363,7 +362,7 @@ cdef class Int32HashTable:
             ndarray[int32_t] counts = np.empty(n, dtype=np.int32)
             dict reverse = {}
             Py_ssize_t idx, count = 0
-            int ret=0
+            int ret = 0
             int32_t val
             khiter_t k
 
@@ -420,7 +419,7 @@ cdef class Int64HashTable:
     cpdef set_item(self, int64_t key, Py_ssize_t val):
         cdef:
             khiter_t k
-            int ret=0
+            int ret = 0
 
         k = kh_put_int64(self.table, key, &ret)
         self.table.keys[k] = key
@@ -432,7 +431,7 @@ cdef class Int64HashTable:
     def map(self, ndarray[int64_t] keys, ndarray[int64_t] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            int ret=0
+            int ret = 0
             int64_t key
             khiter_t k
 
@@ -444,20 +443,19 @@ cdef class Int64HashTable:
     def map_locations(self, ndarray[int64_t] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            int ret=0
+            int ret = 0
             int64_t val
             khiter_t k
 
         for i in range(n):
             val = values[i]
             k = kh_put_int64(self.table, val, &ret)
-            # print 'putting %s, %s' % (val, count)
             self.table.vals[k] = i
 
     def lookup(self, ndarray[int64_t] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            int ret=0
+            int ret = 0
             int64_t val
             khiter_t k
             ndarray[int64_t] locs = np.empty(n, dtype='i8')
@@ -475,7 +473,7 @@ cdef class Int64HashTable:
     def lookup_i4(self, ndarray[int64_t] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            int ret=0
+            int ret = 0
             int64_t val
             khiter_t k
             ndarray[int32_t] locs = np.empty(n, dtype='i4')
@@ -502,7 +500,7 @@ cdef class Int64HashTable:
             ndarray[int32_t] labels
             ndarray[int32_t] counts
             Py_ssize_t idx, count = count_prior
-            int ret=0
+            int ret = 0
             int64_t val
             khiter_t k
 
@@ -531,7 +529,7 @@ cdef class Int64HashTable:
             Py_ssize_t i, n = len(values)
             ndarray[int32_t] labels
             Py_ssize_t idx, count = 0
-            int ret=0
+            int ret = 0
             int64_t val
             khiter_t k
 
@@ -562,7 +560,7 @@ cdef class Int64HashTable:
         cdef:
             Py_ssize_t i, n = len(values)
             Py_ssize_t idx, count = 0
-            int ret=0
+            int ret = 0
             int64_t val
             khiter_t k
             list uniques = []
@@ -596,16 +594,80 @@ cdef class Float64HashTable:
     def __dealloc__(self):
         kh_destroy_float64(self.table)
 
-    def factorize(self, ndarray[object] values):
-        reverse = {}
-        labels, counts = self.get_labels(values, reverse, 0)
-        return reverse, labels, counts
+    def factorize(self, ndarray[float64_t] values):
+        uniques = []
+        labels, counts = self.get_labels(values, uniques, 0, -1)
+        return uniques, labels, counts
+
+    cpdef get_labels(self, ndarray[float64_t] values, list uniques,
+                     Py_ssize_t count_prior, int32_t na_sentinel):
+        cdef:
+            Py_ssize_t i, n = len(values)
+            ndarray[int32_t] labels
+            ndarray[int32_t] counts
+            Py_ssize_t idx, count = count_prior
+            int ret = 0
+            float64_t val
+            khiter_t k
+
+        labels = np.empty(n, dtype=np.int32)
+        counts = np.empty(count_prior + n, dtype=np.int32)
+
+        for i in range(n):
+            val = values[i]
+
+            if val != val:
+                labels[i] = na_sentinel
+                continue
+
+            k = kh_get_float64(self.table, val)
+            if k != self.table.n_buckets:
+                idx = self.table.vals[k]
+                labels[i] = idx
+                counts[idx] = counts[idx] + 1
+            else:
+                k = kh_put_float64(self.table, val, &ret)
+                self.table.vals[k] = count
+                uniques.append(val)
+                labels[i] = count
+                counts[count] = 1
+                count += 1
+
+        return labels, counts[:count].copy()
+
+    def map_locations(self, ndarray[float64_t] values):
+        cdef:
+            Py_ssize_t i, n = len(values)
+            int ret = 0
+            khiter_t k
+
+        for i in range(n):
+            k = kh_put_float64(self.table, values[i], &ret)
+            self.table.vals[k] = i
+
+    def lookup(self, ndarray[float64_t] values):
+        cdef:
+            Py_ssize_t i, n = len(values)
+            int ret = 0
+            float64_t val
+            khiter_t k
+            ndarray[int32_t] locs = np.empty(n, dtype=np.int32)
+
+        for i in range(n):
+            val = values[i]
+            k = kh_get_float64(self.table, val)
+            if k != self.table.n_buckets:
+                locs[i] = self.table.vals[k]
+            else:
+                locs[i] = -1
+
+        return locs
 
     def unique(self, ndarray[float64_t] values):
         cdef:
             Py_ssize_t i, n = len(values)
             Py_ssize_t idx, count = 0
-            int ret=0
+            int ret = 0
             float64_t val
             khiter_t k
             list uniques = []
@@ -663,7 +725,7 @@ cdef class PyObjectHashTable:
     cpdef set_item(self, object key, Py_ssize_t val):
         cdef:
             khiter_t k
-            int ret=0
+            int ret = 0
             char* buf
 
         k = kh_put_pymap(self.table, <PyObject*>key, &ret)
@@ -676,20 +738,19 @@ cdef class PyObjectHashTable:
     def map_locations(self, ndarray[object] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            int ret=0
+            int ret = 0
             object val
             khiter_t k
 
         for i in range(n):
             val = values[i]
             k = kh_put_pymap(self.table, <PyObject*>val, &ret)
-            # print 'putting %s, %s' % (val, count)
             self.table.vals[k] = i
 
-    def lookup_locations(self, ndarray[object] values):
+    def lookup(self, ndarray[object] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            int ret=0
+            int ret = 0
             object val
             khiter_t k
             ndarray[int32_t] locs = np.empty(n, dtype='i4')
@@ -704,10 +765,10 @@ cdef class PyObjectHashTable:
 
         return locs
 
-    def lookup_locations2(self, ndarray[object] values):
+    def lookup2(self, ndarray[object] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            int ret=0
+            int ret = 0
             object val
             khiter_t k
             long hval
@@ -724,7 +785,7 @@ cdef class PyObjectHashTable:
         cdef:
             Py_ssize_t i, n = len(values)
             Py_ssize_t idx, count = 0
-            int ret=0
+            int ret = 0
             object val
             khiter_t k
             list uniques = []
@@ -751,7 +812,7 @@ cdef class PyObjectHashTable:
             ndarray[int32_t] labels
             ndarray[int32_t] counts
             Py_ssize_t idx, count = count_prior
-            int ret=0
+            int ret = 0
             object val
             khiter_t k
 
@@ -891,7 +952,7 @@ cdef class DictFactorizer:
             ndarray[int32_t] labels
             ndarray[int32_t] counts
             Py_ssize_t idx, count = self.count
-            int ret=0
+            int ret = 0
             object val
 
         labels = np.empty(n, dtype=np.int32)
@@ -957,10 +1018,10 @@ cdef class DictFactorizer:
                 count += 1
         return self.uniques
 
-def lookup_locations2(ndarray[object] values):
+def lookup2(ndarray[object] values):
     cdef:
         Py_ssize_t i, n = len(values)
-        int ret=0
+        int ret = 0
         object val
         khiter_t k
         long hval
