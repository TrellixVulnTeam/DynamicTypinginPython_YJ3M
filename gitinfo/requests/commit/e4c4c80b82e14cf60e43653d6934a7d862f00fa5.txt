commit e4c4c80b82e14cf60e43653d6934a7d862f00fa5
Author: Kenneth Reitz <me@kennethreitz.com>
Date:   Mon Dec 17 07:27:25 2012 -0500

    remove all old tests

diff --git a/.travis.yml b/.travis.yml
index 21986247..3cc2b6c7 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -4,7 +4,7 @@ python:
   - 2.7
   - 3.2
 env: HTTPBIN_URL=http://httpbin.org/
-script: make travis
+script: make test
 install:
-  - pip install nose
+  - make test-deps
   - pip install . --use-mirrors
diff --git a/Makefile b/Makefile
index 7046ff5f..31633578 100644
--- a/Makefile
+++ b/Makefile
@@ -1,34 +1,10 @@
 SHELL := /bin/bash
 
-# test_requests_ext.py depends on external services, and async doesn't work under Python 3
-# Travis/Jenkins should be ensuring that all other tests pass on all supported versions
-CI_TESTS=$(shell find tests/ -name "*.py" ! -name "test_requests_ext.py" ! -name "test_requests_async.py")
-
-iter:
-	python test_iteration.py
-
-init:
-	python setup.py develop
-	pip install -r requirements.txt
-
 test:
-	nosetests ./tests/*
-
-lazy:
-	nosetests --with-color tests/test_requests.py
-
-simple:
-	nosetests tests/test_requests.py
+	py.test
 
-citests:
-	nosetests ${CI_TESTS} --with-xunit --xunit-file=junit-report.xml
-
-ci: citests cipyflakes
-
-travis: citests
-
-server:
-	gunicorn httpbin:app --bind=0.0.0.0:7077 &
+test-deps:
+	pip install py.test
 
 deps: urllib3 certs charade
 
@@ -47,6 +23,4 @@ charade:
 	rm -fr charade
 
 certs:
-	cd requests && curl -O https://raw.github.com/kennethreitz/certifi/master/certifi/cacert.pem
-
-docs: site
+	cd requests && curl -O https://raw.github.com/kennethreitz/certifi/master/certifi/cacert.pem
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index 0b725cae..e44a4724 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,2 +1,2 @@
-nose
-rudolf2
+py.test
+sphinx
\ No newline at end of file
diff --git a/test_iteration.py b/test_iteration.py
deleted file mode 100644
index 96722327..00000000
--- a/test_iteration.py
+++ /dev/null
@@ -1,29 +0,0 @@
-import requests
-import unittest
-
-
-class IterationTestCase(unittest.TestCase):
-
-    def test_assertion(self):
-        assert 1
-
-    # def test_dzubia(self):
-    #     s = requests.Session()
-    #     r = requests.Request(method='GET', url='http://github.com/')
-
-    #     # r = s.send(r)
-
-    def test_prepared_request(self):
-        s = requests.Session()
-        r = requests.Request(method='GET', url='http://github.com/')
-        r = r.prepare()
-
-        r = s.send(r)
-        print r
-
-
-
-
-
-if __name__ == '__main__':
-    unittest.main()
\ No newline at end of file
diff --git a/test_requests.org b/test_requests.org
new file mode 100644
index 00000000..e69de29b
diff --git a/tests/dummy_server.py b/tests/dummy_server.py
deleted file mode 100644
index 1096e25b..00000000
--- a/tests/dummy_server.py
+++ /dev/null
@@ -1,46 +0,0 @@
-import asyncore
-import threading
-import socket
-
-class HttpServer(threading.Thread):
-    def __init__(self, port):
-        threading.Thread.__init__(self)
-        self.dispatcher = HttpServerDispatcher(port)
-
-    def run(self):
-        asyncore.loop()
-
-    @property
-    def connection_count(self):
-        return self.dispatcher.connection_count
-
-    def close(self):
-        asyncore.close_all()
-
-class HttpServerDispatcher(asyncore.dispatcher):
-    def __init__(self, port):
-        asyncore.dispatcher.__init__(self)
-        self.connected = False
-        self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
-        self.bind(('127.0.0.1', port))
-        self.listen(1)
-        self.connection_count = 0
-
-    def handle_accept(self):
-        self.connection_count += 1
-        self.handler = RequestHandler(self.accept()[0])
-
-    def handle_close(self):
-        self.close()
-
-
-class RequestHandler(asyncore.dispatcher_with_send):
-    def __init__(self, sock):
-        asyncore.dispatcher_with_send.__init__(self, sock)
-        self.response = ("HTTP/1.1 200 OK\r\n"
-                         "Connection: keep-alive\r\n"
-                         "Content-Length: 0\r\n\r\n")
-
-    def handle_read(self):
-        self.recv(1024)
-        self.send(self.response)
diff --git a/tests/informal/test_leaked_connections.py b/tests/informal/test_leaked_connections.py
deleted file mode 100644
index 37d964cf..00000000
--- a/tests/informal/test_leaked_connections.py
+++ /dev/null
@@ -1,31 +0,0 @@
-"""
-This is an informal test originally written by Bluehorn;
-it verifies that Requests does not leak connections when
-the body of the request is not read.
-"""
-
-import gc
-import os
-import requests
-import subprocess
-import sys
-
-
-def main():
-    gc.disable()
-
-    for x in range(20):
-        requests.head("http://www.google.com/")
-
-    print("Open sockets after 20 head requests:")
-    pid = os.getpid()
-    subprocess.call("lsof -p%d -a -iTCP" % (pid,), shell=True)
-
-    gcresult = gc.collect()
-    print("Garbage collection result: %s" % (gcresult,))
-
-    print("Open sockets after garbage collection:")
-    subprocess.call("lsof -p%d -a -iTCP" % (pid,), shell=True)
-
-if __name__ == '__main__':
-    sys.exit(main())
diff --git a/tests/test_cookies.py b/tests/test_cookies.py
deleted file mode 100755
index 90141a9a..00000000
--- a/tests/test_cookies.py
+++ /dev/null
@@ -1,244 +0,0 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-import sys
-import json
-import os
-import tempfile
-import unittest
-
-# Path hack.
-sys.path.insert(0, os.path.abspath('..'))
-import requests
-from requests.compat import cookielib
-
-# More hacks
-sys.path.append('.')
-from test_requests import httpbin, TestBaseMixin
-
-
-class CookieTests(TestBaseMixin, unittest.TestCase):
-
-    def test_cookies_from_response(self):
-        """Basic test that we correctly parse received cookies in the Response object."""
-        r = requests.get(httpbin('cookies', 'set', 'myname', 'myvalue'))
-
-        # test deprecated dictionary interface
-        self.assertEqual(r.cookies['myname'], 'myvalue')
-        self.assertEqual(r.cookies.get('myname'), 'myvalue')
-        # test CookieJar interface
-        jar = r.cookies
-        self.assertEqual(len(jar), 1)
-        cookie_from_jar = list(jar)[0]
-        self.assertCookieHas(cookie_from_jar, name='myname', value='myvalue')
-
-        q = requests.get(httpbin('cookies'), cookies=jar)
-        self.assertEqual(json.loads(q.text)['cookies'], {'myname': 'myvalue'})
-
-    def test_crossdomain_cookies(self):
-        """Cookies should not be sent to domains they didn't originate from."""
-        r = requests.get("http://github.com")
-        c = r.cookies
-        # github should send us cookies
-        self.assertTrue(len(c) >= 1)
-
-        # github cookies should not be sent to httpbin.org:
-        r2 = requests.get(httpbin('cookies'), cookies=c)
-        self.assertEqual(json.loads(r2.text)['cookies'], {})
-
-        # let's do this again using the session object
-        s = requests.session()
-        s.get("http://github.com")
-        self.assertTrue(len(s.cookies) >= 1)
-        r = s.get(httpbin('cookies'))
-        self.assertEqual(json.loads(r.text)['cookies'], {})
-        # we can set a cookie and get exactly that same-domain cookie back:
-        r = s.get(httpbin('cookies', 'set', 'myname', 'myvalue'))
-        self.assertEqual(json.loads(r.text)['cookies'], {'myname': 'myvalue'})
-
-    def test_overwrite(self):
-        """Cookies should get overwritten when appropriate."""
-        r = requests.get(httpbin('cookies', 'set', 'shimon', 'yochai'))
-        cookies = r.cookies
-        requests.get(httpbin('cookies', 'set', 'elazar', 'shimon'), cookies=cookies)
-        r = requests.get(httpbin('cookies'), cookies=cookies)
-        self.assertEqual(json.loads(r.text)['cookies'],
-                {'shimon': 'yochai', 'elazar': 'shimon'})
-        # overwrite the value of 'shimon'
-        r = requests.get(httpbin('cookies', 'set', 'shimon', 'gamaliel'), cookies=cookies)
-        self.assertEqual(len(cookies), 2)
-        r = requests.get(httpbin('cookies'), cookies=cookies)
-        self.assertEqual(json.loads(r.text)['cookies'],
-                {'shimon': 'gamaliel', 'elazar': 'shimon'})
-
-    def test_redirects(self):
-        """Test that cookies set by a 302 page are correctly processed."""
-        r = requests.get(httpbin('cookies', 'set', 'redirects', 'work'))
-        self.assertEqual(r.history[0].status_code, 302)
-        expected_cookies = {'redirects': 'work'}
-        self.assertEqual(json.loads(r.text)['cookies'], expected_cookies)
-
-        r2 = requests.get(httpbin('cookies', 'set', 'very', 'well'), cookies=r.cookies)
-        expected_cookies = {'redirects': 'work', 'very': 'well'}
-        self.assertEqual(json.loads(r2.text)['cookies'], expected_cookies)
-        self.assertTrue(r.cookies is r2.cookies)
-
-    def test_none_cookie(self):
-        """Regression test: don't send a Cookie header with a string value of 'None'!"""
-        page = json.loads(requests.get(httpbin('headers')).text)
-        self.assertTrue('Cookie' not in page['headers'])
-
-    def test_secure_cookies(self):
-        """Test that secure cookies can only be sent via https."""
-        header = "Set-Cookie: ThisIsA=SecureCookie; Path=/; Secure; HttpOnly"
-        url = 'https://httpbin.org/response-headers?%s' % (requests.utils.quote(header),)
-        cookies = requests.get(url, verify=False).cookies
-        self.assertEqual(len(cookies), 1)
-        self.assertEqual(list(cookies)[0].secure, True)
-
-        secure_resp = requests.get('https://httpbin.org/cookies', cookies=cookies, verify=False)
-        secure_cookies_sent = json.loads(secure_resp.text)['cookies']
-        self.assertEqual(secure_cookies_sent, {'ThisIsA': 'SecureCookie'})
-
-        insecure_resp = requests.get('http://httpbin.org/cookies', cookies=cookies)
-        insecure_cookies_sent = json.loads(insecure_resp.text)['cookies']
-        self.assertEqual(insecure_cookies_sent, {})
-
-    def test_jar_utility_functions(self):
-        """Test utility functions such as list_domains, list_paths, multiple_domains."""
-        r = requests.get("http://github.com")
-        c = r.cookies
-        # github should send us cookies
-        self.assertTrue(len(c) >= 1)
-        self.assertEqual(len(c), len(r.cookies.keys()))
-        self.assertEqual(len(c), len(r.cookies.values()))
-        self.assertEqual(len(c), len(r.cookies.items()))
-
-        # domain and path utility functions
-        domain = r.cookies.list_domains()[0]
-        path = r.cookies.list_paths()[0]
-        self.assertEqual(dict(r.cookies), r.cookies.get_dict(domain=domain, path=path))
-        self.assertEqual(len(r.cookies.list_domains()), 1)
-        self.assertEqual(len(r.cookies.list_paths()), 1)
-        self.assertFalse(r.cookies.multiple_domains())
-
-    def test_convert_jar_to_dict(self):
-        """Test that keys, values, and items are defined and that we can convert
-        cookie jars to plain old Python dicts."""
-        r = requests.get(httpbin('cookies', 'set', 'myname', 'myvalue'))
-
-        # test keys, values, and items
-        self.assertEqual(r.cookies.keys(), ['myname'])
-        self.assertEqual(r.cookies.values(), ['myvalue'])
-        self.assertEqual(r.cookies.items(), [('myname', 'myvalue')])
-
-        # test if we can convert jar to dict
-        dictOfCookies = dict(r.cookies)
-        self.assertEqual(dictOfCookies, {'myname': 'myvalue'})
-        self.assertEqual(dictOfCookies, r.cookies.get_dict())
-
-
-class LWPCookieJarTest(TestBaseMixin, unittest.TestCase):
-    """Check store/load of cookies to FileCookieJar's, specifically LWPCookieJar's."""
-
-    COOKIEJAR_CLASS = cookielib.LWPCookieJar
-
-    def setUp(self):
-        # blank the file
-        self.cookiejar_file = tempfile.NamedTemporaryFile()
-        self.cookiejar_filename = self.cookiejar_file.name
-        cookiejar = self.COOKIEJAR_CLASS(self.cookiejar_filename)
-        cookiejar.save()
-
-    def tearDown(self):
-        try:
-            self.cookiejar_file.close()
-        except OSError:
-            pass
-
-    def test_cookiejar_persistence(self):
-        """Test that we can save cookies to a FileCookieJar."""
-        cookiejar = self.COOKIEJAR_CLASS(self.cookiejar_filename)
-        cookiejar.load()
-        # initially should be blank
-        self.assertEqual(len(cookiejar), 0)
-
-        response = requests.get(httpbin('cookies', 'set', 'key', 'value'), cookies=cookiejar)
-        self.assertEqual(len(cookiejar), 1)
-        cookie = list(cookiejar)[0]
-        self.assertEqual(json.loads(response.text)['cookies'], {'key': 'value'})
-        self.assertCookieHas(cookie, name='key', value='value')
-
-        # save and reload the cookies from the file:
-        cookiejar.save(ignore_discard=True)
-        cookiejar_2 = self.COOKIEJAR_CLASS(self.cookiejar_filename)
-        cookiejar_2.load(ignore_discard=True)
-        self.assertEqual(len(cookiejar_2), 1)
-        cookie_2 = list(cookiejar_2)[0]
-        # this cookie should have been saved with the correct domain restriction:
-        self.assertCookieHas(cookie_2, name='key', value='value',
-                domain='httpbin.org', path='/')
-
-        # httpbin sets session cookies, so if we don't ignore the discard attribute,
-        # there should be no cookie:
-        cookiejar_3 = self.COOKIEJAR_CLASS(self.cookiejar_filename)
-        cookiejar_3.load()
-        self.assertEqual(len(cookiejar_3), 0)
-
-    def test_crossdomain(self):
-        """Test persistence of the domains associated with the cookies."""
-        cookiejar = self.COOKIEJAR_CLASS(self.cookiejar_filename)
-        cookiejar.load()
-        self.assertEqual(len(cookiejar), 0)
-
-        # github sets a cookie
-        requests.get("http://github.com", cookies=cookiejar)
-        num_github_cookies = len(cookiejar)
-        self.assertTrue(num_github_cookies >= 1)
-        # httpbin sets another
-        requests.get(httpbin('cookies', 'set', 'key', 'value'), cookies=cookiejar)
-        num_total_cookies = len(cookiejar)
-        self.assertTrue(num_total_cookies >= 2)
-        self.assertTrue(num_total_cookies > num_github_cookies)
-
-        # save and load
-        cookiejar.save(ignore_discard=True)
-        cookiejar_2 = self.COOKIEJAR_CLASS(self.cookiejar_filename)
-        cookiejar_2.load(ignore_discard=True)
-        self.assertEqual(len(cookiejar_2), num_total_cookies)
-        r = requests.get(httpbin('cookies'), cookies=cookiejar_2)
-        self.assertEqual(json.loads(r.text)['cookies'], {'key': 'value'})
-
-    def test_persistent_cookies(self):
-        """Test that we correctly interpret persistent cookies."""
-        # httpbin's normal cookie methods don't send persistent cookies,
-        # so cook up the appropriate header and force it to send
-        header = "Set-Cookie: Persistent=CookiesAreScary; expires=Sun, 04-May-2032 04:56:50 GMT; path=/"
-        url = httpbin('response-headers?%s' % (requests.utils.quote(header),))
-        cookiejar = self.COOKIEJAR_CLASS(self.cookiejar_filename)
-
-        requests.get(url, cookies=cookiejar)
-        self.assertEqual(len(cookiejar), 1)
-        self.assertCookieHas(list(cookiejar)[0], name='Persistent', value='CookiesAreScary')
-
-        requests.get(httpbin('cookies', 'set', 'ThisCookieIs', 'SessionOnly'), cookies=cookiejar)
-        self.assertEqual(len(cookiejar), 2)
-        self.assertEqual(len([c for c in cookiejar if c.name == 'Persistent']), 1)
-        self.assertEqual(len([c for c in cookiejar if c.name == 'ThisCookieIs']), 1)
-
-        # save and load
-        cookiejar.save()
-        cookiejar_2 = self.COOKIEJAR_CLASS(self.cookiejar_filename)
-        cookiejar_2.load()
-        # we should only load the persistent cookie
-        self.assertEqual(len(cookiejar_2), 1)
-        self.assertCookieHas(list(cookiejar_2)[0], name='Persistent', value='CookiesAreScary')
-
-
-class MozCookieJarTest(LWPCookieJarTest):
-    """Same test, but substitute MozillaCookieJar."""
-
-    COOKIEJAR_CLASS = cookielib.MozillaCookieJar
-
-if __name__ == '__main__':
-    unittest.main()
diff --git a/tests/test_keep_alive.py b/tests/test_keep_alive.py
deleted file mode 100644
index 8778926c..00000000
--- a/tests/test_keep_alive.py
+++ /dev/null
@@ -1,65 +0,0 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-import os
-import sys
-import unittest
-
-# Path hack.
-sys.path.insert(0, os.path.abspath('..'))
-import requests
-import dummy_server
-
-class KeepAliveTests(unittest.TestCase):
-    server_and_proxy_port = 1234
-    request_count = 2
-    url = 'http://localhost:{0}'.format(server_and_proxy_port)
-    proxies={'http': url}
-
-    def setUp(self):
-        self.session = requests.session()
-        self.proxy_server = dummy_server.HttpServer(self.server_and_proxy_port)
-        self.proxy_server.start()
-
-    def tearDown(self):
-        self.proxy_server.close()
-
-    def test_keep_alive_with_direct_connection(self):
-        self.make_requests()
-        self.check_each_request_are_in_same_connection()
-
-    def test_no_keep_alive_with_direct_connection(self):
-        self.disable_keep_alive_in_session()
-        self.make_requests()
-        self.check_each_request_are_in_different_connection()
-
-    def test_keep_alive_with_proxy_connection(self):
-        self.make_proxy_requests()
-        self.check_each_request_are_in_same_connection()
-
-    def test_no_keep_alive_with_proxy_connection(self):
-        self.disable_keep_alive_in_session()
-        self.make_proxy_requests()
-        self.check_each_request_are_in_different_connection()
-
-    def make_proxy_requests(self):
-        self.make_requests(self.proxies)
-
-    def make_requests(self, proxies=None):
-        for _ in range(self.request_count):
-            self.session.get(self.url, proxies=proxies).text
-
-    def check_each_request_are_in_same_connection(self):
-        """Keep-alive requests open a single connection to the server."""
-        self.assertEqual(self.proxy_server.connection_count, 1)
-
-    def check_each_request_are_in_different_connection(self):
-        """Keep-alive requests open a single connection to the server."""
-        self.assertEqual(self.proxy_server.connection_count, self.request_count)
-
-    def disable_keep_alive_in_session(self):
-        self.session.config['keep_alive'] = False
-
-
-if __name__ == '__main__':
-    unittest.main()
diff --git a/tests/test_proxies.py b/tests/test_proxies.py
deleted file mode 100644
index 5aa5bf36..00000000
--- a/tests/test_proxies.py
+++ /dev/null
@@ -1,29 +0,0 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-import os
-import sys
-import unittest
-
-# Path hack.
-sys.path.insert(0, os.path.abspath('..'))
-import requests
-
-
-class HTTPSProxyTest(unittest.TestCase):
-    """Smoke test for https functionality."""
-
-    smoke_url = "https://github.com"
-
-    def test_empty_https_proxy(self):
-        proxy = {"https": ""}
-        result = requests.get(self.smoke_url, verify=False, proxies=proxy)
-        self.assertEqual(result.status_code, 200)
-
-    def test_empty_http_proxy(self):
-        proxy = {"http": ""}
-        result = requests.get(self.smoke_url, proxies=proxy)
-        self.assertEqual(result.status_code, 200)
-
-if __name__ == '__main__':
-    unittest.main()
diff --git a/tests/test_requests.py b/tests/test_requests.py
deleted file mode 100755
index 8bb61ea5..00000000
--- a/tests/test_requests.py
+++ /dev/null
@@ -1,1151 +0,0 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-# from __future__ import unicode_literals
-
-# Path hack.
-import sys
-import os
-sys.path.insert(0, os.path.abspath('..'))
-import json
-import unittest
-import pickle
-import tempfile
-import collections
-
-import requests
-from requests.compat import str, StringIO
-# import envoy
-from requests import HTTPError
-from requests import get, post, head, put
-from requests.auth import HTTPBasicAuth, HTTPDigestAuth
-from requests.exceptions import InvalidURL
-
-if 'HTTPBIN_URL' not in os.environ:
-    os.environ['HTTPBIN_URL'] = 'http://httpbin.org/'
-
-HTTPBIN_URL = os.environ.get('HTTPBIN_URL')
-
-
-def httpbin(*suffix):
-    """Returns url for HTTPBIN resource."""
-    return HTTPBIN_URL + '/'.join(suffix)
-
-
-SERVICES = (httpbin, )
-
-_httpbin = False
-
-
-class TestSetup(object):
-    """Requests test cases."""
-
-    # It goes to eleven.
-    _multiprocess_can_split_ = True
-
-    def setUp(self):
-
-        global _httpbin
-
-        if (not 'HTTPBIN_URL' in os.environ) and not _httpbin:
-            # c = envoy.connect('httpbin %s' % (PORT))
-            # time.sleep(1)
-            _httpbin = True
-
-
-class TestBaseMixin(object):
-
-    def assertCookieHas(self, cookie, **kwargs):
-        """Assert that a cookie has various specified properties."""
-        for attr, expected_value in kwargs.items():
-            cookie_attr = getattr(cookie, attr)
-            message = 'Failed comparison for %s: %s != %s' % (attr, cookie_attr, expected_value)
-            self.assertEqual(cookie_attr, expected_value, message)
-
-
-class RequestsTestSuite(TestSetup, TestBaseMixin, unittest.TestCase):
-    """Requests test cases."""
-
-    def test_entry_points(self):
-
-        requests.session
-        requests.session().get
-        requests.session().head
-        requests.get
-        requests.head
-        requests.put
-        requests.patch
-        requests.post
-
-    def test_invalid_url(self):
-        self.assertRaises(ValueError, get, 'hiwpefhipowhefopw')
-
-    def test_path_is_not_double_encoded(self):
-        request = requests.Request("http://0.0.0.0/get/test case")
-
-        self.assertEqual(request.path_url, "/get/test%20case")
-
-    def test_params_are_added_before_fragment(self):
-        request = requests.Request(
-            "http://example.com/path#fragment", params={"a": "b"})
-        self.assertEqual(request.full_url,
-            "http://example.com/path?a=b#fragment")
-        request = requests.Request(
-            "http://example.com/path?key=value#fragment", params={"a": "b"})
-        self.assertEqual(request.full_url,
-            "http://example.com/path?key=value&a=b#fragment")
-
-    def test_params_accepts_kv_list(self):
-        request = requests.Request('http://example.com/path',
-                params=[('a', 'b')])
-        self.assertEqual(request.full_url, 'http://example.com/path?a=b')
-
-    def test_HTTP_200_OK_GET(self):
-        r = get(httpbin('get'))
-        self.assertEqual(r.status_code, 200)
-
-    def test_response_sent(self):
-        r = get(httpbin('get'))
-
-        self.assertTrue(r.request.sent)
-
-    def test_HTTP_302_ALLOW_REDIRECT_GET(self):
-        r = get(httpbin('redirect', '1'))
-        self.assertEqual(r.status_code, 200)
-
-    def test_HTTP_302_GET(self):
-        r = get(httpbin('redirect', '1'), allow_redirects=False)
-        self.assertEqual(r.status_code, 302)
-
-    def test_HTTP_200_OK_GET_WITH_PARAMS(self):
-        heads = {'User-agent': 'Mozilla/5.0'}
-
-        r = get(httpbin('user-agent'), headers=heads)
-
-        self.assertTrue(heads['User-agent'] in r.text)
-        self.assertEqual(r.status_code, 200)
-
-    def test_HTTP_200_OK_GET_WITH_MIXED_PARAMS(self):
-        heads = {'User-agent': 'Mozilla/5.0'}
-
-        r = get(httpbin('get') + '?test=true', params={'q': 'test'}, headers=heads)
-        self.assertEqual(r.status_code, 200)
-
-    # def test_unicode_headers(self):
-    #     # Simply calling requests with a unicode instance should simply work
-    #     # when the characters are all representable using latin-1:
-    #     heads = { u'User-Agent': u'Requests Test Suite' }
-    #     requests.get(url=httpbin('get'), headers=heads)
-
-    #     # Characters outside latin-1 should raise an exception:
-    #     heads = { u'User-Agent': u'\u30cd\u30c3\u30c8\u30ef\u30fc\u30af' }
-    #     self.assertRaises(UnicodeEncodeError, requests.get,
-    #                       url=httpbin('get'), headers=heads)
-
-    # def test_session_with_escaped_url(self):
-    #     # Test a URL that contains percent-escaped characters
-    #     # This URL should not be modified (double-escaped)
-    #     # Tests:
-    #     # - Quoted illegal characters ("%20" (' '), "%3C" ('<'), "%3E" ('>'))
-    #     # - Quoted reserved characters ("%25" ('%'), "%23" ('#'), "%2F" ('/'))
-    #     # - Quoted non-ASCII characters ("%C3%98", "%C3%A5")
-    #     path_fully_escaped = '%3Ca%25b%23c%2Fd%3E/%C3%98%20%C3%A5'
-    #     url = httpbin('get/' + path_fully_escaped)
-    #     response = get(url)
-    #     self.assertEqual(response.url, httpbin('get/' + path_fully_escaped))
-
-    #     # Test that illegal characters in a path get properly percent-escaped
-    #     # Tests:
-    #     # - Bare illegal characters (space, '<')
-    #     # - Bare non-ASCII characters ('\u00d8')
-    #     path = u'<a%25b%23c%2Fd%3E/\u00d8 %C3%A5'
-    #     url = httpbin('get/' + path)
-    #     response = get(url)
-    #     self.assertEqual(response.url, httpbin('get/' + path_fully_escaped))
-
-    #     # Test that reserved characters in a path do not get percent-escaped
-    #     # Tests:
-    #     # - All reserved characters (RFC 3986), except '?', '#', '[' and ']',
-    #     #   which are not allowed in the path, and ';' which delimits
-    #     #   parameters.
-    #     #   All such characters must be allowed bare in path, and must not be
-    #     #   encoded.
-    #     # - Special unreserved characters (RFC 3986), which should not be
-    #     #   encoded (even though it wouldn't hurt).
-    #     path_reserved = '!$&\'()*+,/:=@-._~'
-    #     url = httpbin('get/' + path_reserved)
-    #     response = get(url)
-    #     self.assertEqual(response.url, httpbin('get/' + path_reserved))
-
-    #     # Test that percent-encoded unreserved characters in a path get
-    #     # normalised to their un-encoded forms.
-    #     path_unreserved = 'ABCDwxyz1234-._~'
-    #     path_unreserved_escaped = '%41%42%43%44%77%78%79%7A%31%32%33%34%2D%2E%5F%7E'
-    #     url = httpbin('get/' + path_unreserved_escaped)
-    #     response = get(url)
-    #     self.assertEqual(response.url, httpbin('get/' + path_unreserved))
-
-    #     # Re-run all of the same tests on the query part of the URI
-    #     query_fully_escaped = '%3Ca%25b%23c%2Fd%3E=%C3%98%20%C3%A5'
-    #     url = httpbin('get/?' + query_fully_escaped)
-    #     response = get(url)
-    #     self.assertEqual(response.url, httpbin('get/?' + query_fully_escaped))
-
-    #     query = u'<a%25b%23c%2Fd%3E=\u00d8 %C3%A5'
-    #     url = httpbin('get/?' + query)
-    #     response = get(url)
-    #     self.assertEqual(response.url, httpbin('get/?' + query_fully_escaped))
-
-    #     # The legal characters in query happens to be the same as in path
-    #     query_reserved = '!$&\'()*+,/:=@-._~'
-    #     url = httpbin('get/?' + query_reserved)
-    #     response = get(url)
-    #     self.assertEqual(response.url, httpbin('get/?' + query_reserved))
-
-    #     query_unreserved = 'ABCDwxyz=1234-._~'
-    #     query_unreserved_escaped = '%41%42%43%44%77%78%79%7A=%31%32%33%34%2D%2E%5F%7E'
-    #     url = httpbin('get/?' + query_unreserved_escaped)
-    #     response = get(url)
-    #     self.assertEqual(response.url, httpbin('get/?' + query_unreserved))
-
-    def test_user_agent_transfers(self):
-        """Issue XX"""
-
-        heads = {
-            'User-agent':
-                'Mozilla/5.0 (github.com/kennethreitz/requests)'
-        }
-
-        r = get(httpbin('user-agent'), headers=heads)
-        self.assertTrue(heads['User-agent'] in r.text)
-
-        heads = {
-            'user-agent':
-                'Mozilla/5.0 (github.com/kennethreitz/requests)'
-        }
-
-        r = get(httpbin('user-agent'), headers=heads)
-        self.assertTrue(heads['user-agent'] in r.text)
-
-    def test_HTTP_200_OK_HEAD(self):
-        r = head(httpbin('get'))
-        self.assertEqual(r.status_code, 200)
-
-    def test_HTTP_200_OK_PUT(self):
-        r = put(httpbin('put'))
-        self.assertEqual(r.status_code, 200)
-
-    def test_BASICAUTH_TUPLE_HTTP_200_OK_GET(self):
-
-        for service in SERVICES:
-
-            auth = ('user', 'pass')
-            url = service('basic-auth', 'user', 'pass')
-
-            r = get(url, auth=auth)
-            self.assertEqual(r.status_code, 200)
-
-            r = get(url)
-            self.assertEqual(r.status_code, 401)
-
-            s = requests.session(auth=auth)
-            r = get(url, session=s)
-            self.assertEqual(r.status_code, 200)
-
-    def test_BASICAUTH_HTTP_200_OK_GET(self):
-
-        for service in SERVICES:
-
-            auth = HTTPBasicAuth('user', 'pass')
-            url = service('basic-auth', 'user', 'pass')
-
-            r = get(url, auth=auth)
-            self.assertEqual(r.status_code, 200)
-
-            auth = ('user', 'pass')
-            r = get(url, auth=auth)
-            self.assertEqual(r.status_code, 200)
-
-            r = get(url)
-            self.assertEqual(r.status_code, 401)
-
-            s = requests.session(auth=auth)
-            r = get(url, session=s)
-            self.assertEqual(r.status_code, 200)
-
-    def test_DIGESTAUTH_HTTP_200_OK_GET(self):
-
-        for service in SERVICES:
-
-            auth = HTTPDigestAuth('user', 'pass')
-            url = service('digest-auth', 'auth', 'user', 'pass')
-
-            r = get(url, auth=auth)
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(len(r.history), 1)
-
-            r = get(url, auth=auth)
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(len(r.history), 0)
-
-            r = get(url)
-            self.assertEqual(r.status_code, 401)
-
-            s = requests.session(auth=auth)
-            r = get(url, session=s)
-            self.assertEqual(r.status_code, 200)
-
-    def test_DIGESTAUTH_WRONG_HTTP_401_GET(self):
-
-        for service in SERVICES:
-
-            auth = HTTPDigestAuth('user', 'wrongpass')
-            url = service('digest-auth', 'auth', 'user', 'pass')
-
-            r = get(url, auth=auth)
-            self.assertEqual(r.status_code, 401)
-
-            s = requests.session(auth=auth)
-            r = get(url, session=s)
-            self.assertEqual(r.status_code, 401)
-
-    def test_POSTBIN_GET_POST_FILES(self):
-
-        for service in SERVICES:
-
-            url = service('post')
-            post1 = post(url).raise_for_status()
-
-            post1 = post(url, data={'some': 'data'})
-            self.assertEqual(post1.status_code, 200)
-
-            with open(__file__) as f:
-                post2 = post(url, files={'some': f})
-                post3 = post(url, files=[('some', f)])
-            self.assertEqual(post2.status_code, 200)
-            self.assertEqual(post3.status_code, 200)
-
-            post4 = post(url, data='[{"some": "json"}]')
-            self.assertEqual(post4.status_code, 200)
-
-            try:
-                post(url, files=['bad file data'])
-            except ValueError:
-                pass
-
-    def test_POSTBIN_GET_POST_FILES_WITH_PARAMS(self):
-
-        for service in SERVICES:
-
-            with open(__file__) as f:
-                url = service('post')
-                post1 = post(url, data={'some': 'data'}, files={'some': f})
-                post2 = post(url, data={'some': 'data'}, files=[('some', f)])
-                post3 = post(url, data=[('some', 'data')], files=[('some', f)])
-
-            self.assertEqual(post1.status_code, 200)
-            self.assertEqual(post2.status_code, 200)
-            self.assertEqual(post3.status_code, 200)
-
-    def test_POSTBIN_GET_POST_FILES_WITH_CJK_PARAMS(self):
-
-        for service in SERVICES:
-
-            with open(__file__) as f:
-                url = service('post')
-                post1 = post(url, data={'some': '中文'}, files={'some': f})
-                post2 = post(url, data={'some': '日本語'}, files=[('some', f)])
-                post3 = post(url, data=[('some', '한국의')], files=[('some', f)])
-
-            self.assertEqual(post1.status_code, 200)
-            self.assertEqual(post2.status_code, 200)
-            self.assertEqual(post3.status_code, 200)
-
-    def test_POSTBIN_GET_POST_FILES_WITH_HEADERS(self):
-
-        for service in SERVICES:
-
-            url = service('post')
-
-            with open(__file__) as f:
-
-                post2 = post(url,
-                    files={'some': f},
-                    headers={'User-Agent': 'requests-tests'})
-
-            self.assertEqual(post2.status_code, 200)
-
-    def test_POSTBIN_GET_POST_FILES_STRINGS(self):
-
-        for service in SERVICES:
-
-            url = service('post')
-
-            post1 = post(url, files={'fname.txt': 'fdata'})
-            self.assertEqual(post1.status_code, 200)
-
-            post2 = post(url, files={'fname.txt': 'fdata',
-                    'fname2.txt': 'more fdata'})
-            self.assertEqual(post2.status_code, 200)
-
-            post3 = post(url, files={'fname.txt': 'fdata',
-                    'fname2.txt': open(__file__, 'rb')})
-            self.assertEqual(post3.status_code, 200)
-
-            post4 = post(url, files={'fname.txt': 'fdata'})
-            self.assertEqual(post4.status_code, 200)
-
-            post5 = post(url, files={'file': ('file.txt', 'more fdata')})
-            self.assertEqual(post5.status_code, 200)
-
-            # Dirty hack to tide us over until 3.3.
-            # TODO: Remove this hack when Python 3.3 is released.
-            if (sys.version_info[0] == 2):
-                fdata = '\xc3\xa9'.decode('utf-8')
-            else:
-                fdata = '\xe9'
-
-            post6 = post(url, files={'fname.txt': fdata})
-            self.assertEqual(post6.status_code, 200)
-
-            post7 = post(url, files={'fname.txt': 'fdata to verify'})
-            rbody = json.loads(post7.text)
-            self.assertTrue(rbody.get('files', None))
-            self.assertTrue(rbody['files'].get('fname.txt', None))
-            self.assertEqual(rbody['files']['fname.txt'], 'fdata to verify')
-
-            post8 = post(url, files=[('fname.txt', 'fdata')])
-            self.assertEqual(post8.status_code, 200)
-            resp_body = post8.json
-            self.assertTrue(resp_body.get('files', None))
-            self.assertTrue(resp_body['files'].get('fname.txt', None))
-            self.assertEqual(resp_body['files']['fname.txt'], 'fdata')
-
-            post9 = post(url, files=[('fname.txt', fdata)])
-            self.assertEqual(post9.status_code, 200)
-
-            post10 = post(url, files=[('file',
-                        ('file.txt', 'more file data'))])
-            self.assertEqual(post10.status_code, 200)
-
-            post11 = post(url, files=[('fname.txt', 'fdata'),
-                    ('fname2.txt', 'more fdata')])
-            post12 = post(url, files=[('fname.txt', 'fdata'),
-                    ('fname2.txt', open(__file__, 'rb'))])
-            self.assertEqual(post11.status_code, 200)
-            self.assertEqual(post12.status_code, 200)
-
-    def test_nonzero_evaluation(self):
-
-        for service in SERVICES:
-
-            r = get(service('status', '500'))
-            self.assertEqual(bool(r), False)
-
-            r = get(service('/get'))
-            self.assertEqual(bool(r), True)
-
-    def test_request_ok_set(self):
-
-        for service in SERVICES:
-
-            r = get(service('status', '404'))
-            # print r.status_code
-            # r.raise_for_status()
-            self.assertEqual(r.ok, False)
-
-    def test_status_raising(self):
-        r = get(httpbin('status', '404'))
-        self.assertRaises(HTTPError, r.raise_for_status)
-
-        r = get(httpbin('status', '200'))
-        self.assertFalse(r.error)
-        r.raise_for_status()
-
-    def test_decompress_gzip(self):
-
-        r = get(httpbin('gzip'))
-        r.content.decode('ascii')
-
-    def test_response_has_unicode_url(self):
-
-        for service in SERVICES:
-
-            url = service('get')
-
-            response = get(url)
-
-            self.assertTrue(isinstance(response.url, str))
-
-    def test_unicode_get(self):
-
-        for service in SERVICES:
-
-            url = service('/get')
-
-            get(url, params={'foo': 'føø'})
-            get(url, params={'føø': 'føø'})
-            get(url, params={'føø': 'føø'})
-            get(url, params={'foo': 'foo'})
-            get(service('ø'), params={'foo': 'foo'})
-
-    def test_httpauth_recursion(self):
-
-        http_auth = HTTPBasicAuth('user', 'BADpass')
-
-        for service in SERVICES:
-            r = get(service('basic-auth', 'user', 'pass'), auth=http_auth)
-            self.assertEqual(r.status_code, 401)
-
-    def test_urlencoded_post_data(self):
-
-        for service in SERVICES:
-
-            r = post(service('post'), data=dict(test='fooaowpeuf'))
-
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(r.headers['content-type'], 'application/json')
-            self.assertEqual(r.url, service('post'))
-
-            rbody = json.loads(r.text)
-
-            self.assertEqual(rbody.get('form'), dict(test='fooaowpeuf'))
-            self.assertEqual(rbody.get('data'), '')
-
-    def test_nonurlencoded_post_data(self):
-
-        for service in SERVICES:
-
-            r = post(service('post'), data='fooaowpeuf')
-
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(r.headers['content-type'], 'application/json')
-            self.assertEqual(r.url, service('post'))
-
-            rbody = json.loads(r.text)
-            # Body wasn't valid url encoded data, so the server returns None as
-            # "form" and the raw body as "data".
-
-            self.assertTrue(rbody.get('form') in (None, {}))
-            self.assertEqual(rbody.get('data'), 'fooaowpeuf')
-
-    def test_file_post_data(self):
-
-        filecontent = b"fooaowpeufbarasjhf"
-        testfile = tempfile.NamedTemporaryFile(delete=False)
-        testfile.write(filecontent)
-        testfile.flush()
-        testfile.close()
-
-        for service in SERVICES:
-
-            data = open(testfile.name, "rb")
-            r = post(service('post'), data=data,
-                    headers={"content-type": "application/octet-stream"})
-
-            data.close()
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(r.headers['content-type'], 'application/json')
-            self.assertEqual(r.url, service('post'))
-
-            rbody = json.loads(r.text)
-            self.assertTrue(rbody.get('form') in (None, {}))
-            self.assertEqual(rbody.get('data'), filecontent.decode('ascii'))
-        os.remove(testfile.name)
-
-    def test_urlencoded_post_querystring(self):
-
-        for service in SERVICES:
-
-            r = post(service('post'), params=dict(test='fooaowpeuf'))
-
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(r.headers['content-type'], 'application/json')
-            self.assertEqual(r.url, service('post?test=fooaowpeuf'))
-
-            rbody = json.loads(r.text)
-            self.assertEqual(rbody.get('form'), {})  # No form supplied
-            self.assertEqual(rbody.get('data'), '')
-
-    def test_urlencoded_post_query_and_data(self):
-
-        for service in SERVICES:
-
-            r = post(
-                service('post'),
-                params=dict(test='fooaowpeuf'),
-                data=dict(test2="foobar"))
-
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(r.headers['content-type'], 'application/json')
-            self.assertEqual(r.url, service('post?test=fooaowpeuf'))
-
-            rbody = json.loads(r.text)
-            self.assertEqual(rbody.get('form'), dict(test2='foobar'))
-            self.assertEqual(rbody.get('data'), '')
-
-    def test_nonurlencoded_postdata(self):
-
-        for service in SERVICES:
-
-            r = post(service('post'), data="foobar")
-
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(r.headers['content-type'], 'application/json')
-
-            rbody = json.loads(r.text)
-
-            self.assertTrue(rbody.get('form') in (None, {}))
-            self.assertEqual(rbody.get('data'), 'foobar')
-
-    def test_urlencoded_get_query_multivalued_param(self):
-
-        for service in SERVICES:
-
-            r = get(service('get'), params=dict(test=['foo', 'baz']))
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(r.url, service('get?test=foo&test=baz'))
-
-    def test_urlencoded_post_querystring_multivalued(self):
-
-        for service in SERVICES:
-
-            r = post(service('post'), params=dict(test=['foo', 'baz']))
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(r.headers['content-type'], 'application/json')
-            self.assertEqual(r.url, service('post?test=foo&test=baz'))
-
-            rbody = json.loads(r.text)
-            self.assertEqual(rbody.get('form'), {})  # No form supplied
-            self.assertEqual(rbody.get('data'), '')
-
-    def test_urlencoded_post_query_multivalued_and_data(self):
-
-        for service in SERVICES:
-
-            r = post(
-                service('post'),
-                params=dict(test=['foo', 'baz']),
-                data=dict(test2="foobar", test3=['foo', 'baz']))
-
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(r.headers['content-type'], 'application/json')
-            self.assertEqual(r.url, service('post?test=foo&test=baz'))
-
-            # print(r.text)
-            # print('-----------------------')
-
-            rbody = json.loads(r.text)
-            self.assertEqual(rbody.get('form'), dict(test2='foobar', test3=['foo', 'baz']))
-            self.assertEqual(rbody.get('data'), '')
-
-    def test_multivalued_data_encoding(self):
-        """
-        Make sure data encoding works on a value that is an iterable but not
-        a list
-        """
-        for service in SERVICES:
-            # Can't have unicode literals in Python3, so avoid them.
-            # TODO: fixup when moving to Python 3.3
-            if (sys.version_info[0] == 2):
-                nonascii = '\xc3\xa9'.decode('utf-8')
-            else:
-                nonascii = '\xe9'
-
-            r = post(
-                service('post'),
-                data=dict(test=('foo', nonascii)))
-
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(r.headers['content-type'], 'application/json')
-
-            rbody = json.loads(r.text)
-            self.assertEqual(rbody.get('form'),
-                             dict(test=['foo', nonascii]))
-
-    def test_GET_no_redirect(self):
-
-        for service in SERVICES:
-
-            r = get(service('redirect', '3'), allow_redirects=False)
-            self.assertEqual(r.status_code, 302)
-            self.assertEqual(len(r.history), 0)
-
-    def test_HEAD_no_redirect(self):
-
-        for service in SERVICES:
-
-            r = head(service('redirect', '3'), allow_redirects=False)
-            self.assertEqual(r.status_code, 302)
-            self.assertEqual(len(r.history), 0)
-
-    def test_redirect_history(self):
-
-        for service in SERVICES:
-
-            r = get(service('redirect', '3'))
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(len(r.history), 3)
-
-    def test_relative_redirect_history(self):
-
-        for service in SERVICES:
-
-            r = get(service('relative-redirect', '3'))
-            self.assertEqual(r.status_code, 200)
-            self.assertEqual(len(r.history), 3)
-
-    def test_session_HTTP_200_OK_GET(self):
-
-        s = requests.session()
-        r = get(httpbin('get'), session=s)
-        self.assertEqual(r.status_code, 200)
-
-    def test_session_persistent_headers(self):
-
-        heads = {'User-agent': 'Mozilla/5.0'}
-
-        s = requests.session()
-        s.headers = heads
-
-        # Make 2 requests from Session object, should send header both times
-        r1 = get(httpbin('user-agent'), session=s)
-        self.assertTrue(heads['User-agent'] in r1.text)
-
-        r2 = get(httpbin('user-agent'), session=s)
-        self.assertTrue(heads['User-agent'] in r2.text)
-
-        new_heads = {'User-agent': 'blah'}
-        r3 = get(httpbin('user-agent'), headers=new_heads, session=s)
-        self.assertTrue(new_heads['User-agent'] in r3.text)
-
-        self.assertEqual(r2.status_code, 200)
-
-    def test_single_hook(self):
-
-        def add_foo_header(args):
-            if not args.get('headers'):
-                args['headers'] = {}
-
-            args['headers'].update({
-                'X-Foo': 'foo'
-            })
-
-            return args
-
-        for service in SERVICES:
-            url = service('headers')
-            response = get(url=url, hooks={'args': add_foo_header})
-
-            self.assertTrue('foo' in response.text)
-
-    def test_multiple_hooks(self):
-
-        def add_foo_header(args):
-            if not args.get('headers'):
-                args['headers'] = {}
-
-            args['headers'].update({
-                'X-Foo': 'foo'
-            })
-
-            return args
-
-        def add_bar_header(args):
-            if not args.get('headers'):
-                args['headers'] = {}
-
-            args['headers'].update({
-                'X-Bar': 'bar'
-            })
-
-            return args
-
-        for service in SERVICES:
-            url = service('headers')
-
-            response = get(url=url,
-                hooks={
-                    'args': [add_foo_header, add_bar_header]
-                }
-            )
-
-            for text in ('foo', 'bar'):
-                self.assertTrue(text in response.text)
-
-    def test_allow_list_of_hooks_to_register_hook(self):
-        """Issue 785: https://github.com/kennethreitz/requests/issues/785"""
-        def add_foo_header(args):
-            if not args.get('headers'):
-                args['headers'] = {}
-
-            args['headers'].update({
-                'X-Foo': 'foo'
-            })
-
-            return args
-
-        def add_bar_header(args):
-            if not args.get('headers'):
-                args['headers'] = {}
-
-            args['headers'].update({
-                'X-Bar': 'bar'
-            })
-
-            return args
-
-        def assert_hooks_are_callable(hooks):
-            for h in hooks['args']:
-                self.assertTrue(isinstance(h, collections.Callable))
-
-        hooks = [add_foo_header, add_bar_header]
-        r = requests.models.Request()
-        r.register_hook('args', hooks)
-        assert_hooks_are_callable(r.hooks)
-
-        r = requests.models.Request(hooks={'args': hooks})
-        assert_hooks_are_callable(r.hooks)
-
-        hooks.append('string that should not be registered')
-        r = requests.models.Request(hooks={'args': hooks})
-        assert_hooks_are_callable(r.hooks)
-
-    def test_session_persistent_cookies(self):
-
-        s = requests.session()
-
-        # Internally dispatched cookies are sent.
-        _c = {'kenneth': 'reitz', 'bessie': 'monke'}
-        r = get(httpbin('cookies'), cookies=_c, session=s)
-        r = get(httpbin('cookies'), session=s)
-
-        # Those cookies persist transparently.
-        c = json.loads(r.text).get('cookies')
-        self.assertEqual(c, _c)
-
-        # Double check.
-        r = get(httpbin('cookies'), cookies={}, session=s)
-        c = json.loads(r.text).get('cookies')
-        self.assertEqual(c, _c)
-
-        # Remove a cookie by setting it's value to None.
-        r = get(httpbin('cookies'), cookies={'bessie': None}, session=s)
-        c = json.loads(r.text).get('cookies')
-        del _c['bessie']
-        self.assertEqual(c, _c)
-
-        # Test session-level cookies.
-        s = requests.session(cookies=_c)
-        r = get(httpbin('cookies'), session=s)
-        c = json.loads(r.text).get('cookies')
-        self.assertEqual(c, _c)
-
-        # Have the server set a cookie.
-        r = get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True, session=s)
-        c = json.loads(r.text).get('cookies')
-
-        self.assertTrue('k' in c)
-
-        # And server-set cookie persistience.
-        r = get(httpbin('cookies'), session=s)
-        c = json.loads(r.text).get('cookies')
-
-        self.assertTrue('k' in c)
-
-    def test_session_persistent_params(self):
-
-        params = {'a': 'a_test'}
-
-        s = requests.session()
-        s.params = params
-
-        # Make 2 requests from Session object, should send header both times
-        r1 = get(httpbin('get'), session=s)
-        self.assertTrue(params['a'] in r1.text)
-
-        params2 = {'b': 'b_test'}
-
-        r2 = get(httpbin('get'), params=params2, session=s)
-        for param in (params['a'], params2['b']):
-            self.assertTrue(param in r2.text)
-
-        params3 = {'b': 'b_test', 'a': None, 'c': 'c_test'}
-
-        r3 = get(httpbin('get'), params=params3, session=s)
-
-        self.assertFalse(params['a'] in r3.text)
-
-        for param in (params3['b'], params3['c']):
-            self.assertTrue(param in r3.text)
-
-    def test_session_cookies_with_return_response_false(self):
-        s = requests.session()
-        # return_response=False as it does requests.async.get
-        rq = get(httpbin('cookies', 'set', 'k', 'v'), return_response=False,
-                 allow_redirects=True, session=s)
-        rq.send(prefetch=True)
-        c = rq.response.json.get('cookies')
-        self.assertTrue('k' in c)
-        self.assertTrue('k' in s.cookies)
-
-    def test_session_pickling(self):
-
-        s = requests.session(
-                headers={'header': 'value'},
-                cookies={'a-cookie': 'cookie-value'},
-                auth=('username', 'password'))
-
-        ds = pickle.loads(pickle.dumps(s))
-
-        self.assertEqual(s.headers, ds.headers)
-        self.assertEqual(s.auth, ds.auth)
-
-        # Cookie doesn't have a good __eq__, so verify manually:
-        self.assertEqual(len(ds.cookies), 1)
-        for cookie in ds.cookies:
-            self.assertCookieHas(cookie, name='a-cookie', value='cookie-value')
-
-    def test_unpickled_session_requests(self):
-        s = requests.session()
-        r = get(httpbin('cookies', 'set', 'k', 'v'), allow_redirects=True, session=s)
-        c = json.loads(r.text).get('cookies')
-        self.assertTrue('k' in c)
-
-        ds = pickle.loads(pickle.dumps(s))
-        r = get(httpbin('cookies'), session=ds)
-        c = json.loads(r.text).get('cookies')
-        self.assertTrue('k' in c)
-
-        ds1 = pickle.loads(pickle.dumps(requests.session()))
-        ds2 = pickle.loads(pickle.dumps(requests.session(prefetch=False)))
-        self.assertTrue(ds1.prefetch)
-        self.assertFalse(ds2.prefetch)
-
-    def test_connection_error(self):
-        try:
-            get('http://localhost:1/nope')
-        except requests.ConnectionError:
-            pass
-        else:
-            self.fail()
-
-    def test_cached_response(self):
-
-        r1 = get(httpbin('get'), prefetch=False)
-        self.assertFalse(r1._content)
-        self.assertTrue(r1.content)
-        self.assertTrue(r1.text)
-
-        r2 = get(httpbin('get'), prefetch=True)
-        self.assertTrue(r2._content)
-        self.assertTrue(r2.content)
-        self.assertTrue(r2.text)
-
-    def test_iter_lines(self):
-
-        lines = (0, 2, 10, 100)
-
-        for i in lines:
-            r = get(httpbin('stream', str(i)), prefetch=False)
-            lines = list(r.iter_lines())
-            len_lines = len(lines)
-
-            self.assertEqual(i, len_lines)
-
-        # Tests that trailing whitespaces within lines do not get stripped.
-        # Tests that a trailing non-terminated line does not get stripped.
-        quote = (
-            '''Agamemnon  \n'''
-            '''\tWhy will he not upon our fair request\r\n'''
-            '''\tUntent his person and share the air with us?'''
-        )
-
-        # Make a request and monkey-patch its contents
-        r = get(httpbin('get'), prefetch=False)
-        r.raw = StringIO(quote)
-
-        lines = list(r.iter_lines())
-        len_lines = len(lines)
-        self.assertEqual(len_lines, 3)
-
-        joined = lines[0] + '\n' + lines[1] + '\r\n' + lines[2]
-        self.assertEqual(joined, quote)
-
-    def test_permissive_iter_content(self):
-        """Test that iter_content and iter_lines work even after the body has been fetched."""
-        r = get(httpbin('stream', '10'), prefetch=True)
-        self.assertTrue(r._content_consumed)
-        # iter_lines should still work without crashing
-        self.assertEqual(len(list(r.iter_lines())), 10)
-
-        # iter_content should return a one-item iterator over the whole content
-        iter_content_list = list(r.iter_content(chunk_size=1))
-        self.assertTrue(all(len(item) == 1 for item in iter_content_list))
-        # when joined, it should be exactly the original content
-        self.assertEqual(bytes().join(iter_content_list), r.content)
-
-        # test different chunk sizes:
-        for chunk_size in range(2, 20):
-            self.assertEqual(bytes().join(r.iter_content(chunk_size=chunk_size)), r.content)
-
-
-    def test_upload_binary_data(self):
-
-        requests.get(httpbin('post'), auth=('a', 'b'), data='\xff')
-
-    def test_useful_exception_for_invalid_port(self):
-        # If we pass a legitimate URL with an invalid port, we should fail.
-        self.assertRaises(
-              ValueError,
-              get,
-              'http://google.com:banana')
-
-    def test_useful_exception_for_invalid_scheme(self):
-
-        # If we pass a legitimate URL with a scheme not supported
-        # by requests, we should fail.
-        self.assertRaises(
-              ValueError,
-              get,
-              'ftp://ftp.kernel.org/pub/')
-
-    def test_can_have_none_in_header_values(self):
-        try:
-            # Don't choke on headers with none in the value.
-            requests.get(httpbin('headers'), headers={'Foo': None})
-        except TypeError:
-            self.fail('Not able to have none in header values')
-
-
-    def test_empty_response(self):
-        r = requests.get(httpbin('status', '404'))
-        r.text
-
-    def test_connection_keepalive_and_close(self):
-        """Test that we send 'Connection: close' when keep_alive is disabled."""
-        # keep-alive should be on by default
-        r1 = requests.get(httpbin('get'))
-        # XXX due to proxying issues, test the header sent back by httpbin, rather than
-        # the header reported in its message body. See kennethreitz/httpbin#46
-        self.assertEqual(r1.headers['Connection'].lower(), 'keep-alive')
-
-        # but when we disable it, we should send a 'Connection: close'
-        # and get the same back:
-        r2 = requests.get(httpbin('get'), config=dict(keep_alive=False))
-        self.assertEqual(r2.headers['Connection'].lower(), 'close')
-
-    def test_head_content(self):
-        """Test that empty bodies are properly supported."""
-
-        r = requests.head(httpbin('headers'))
-        r.content
-        r.text
-
-    def test_post_fields_with_multiple_values_and_files(self):
-        """Test that it is possible to POST using the files argument and a
-        list for a value in the data argument."""
-
-        data = {'field': ['a', 'b']}
-        files = {'field': 'Garbled data'}
-        r = post(httpbin('post'), data=data, files=files)
-        t = json.loads(r.text)
-        self.assertEqual(t.get('form'), {'field': ['a', 'b']})
-        self.assertEqual(t.get('files'), files)
-        r = post(httpbin('post'), data=data, files=files.items())
-        self.assertEqual(t.get('files'), files)
-
-    def test_str_data_content_type(self):
-        data = 'test string data'
-        r = post(httpbin('post'), data=data)
-        t = json.loads(r.text)
-        self.assertEqual(t.get('headers').get('Content-Type'), '')
-
-    def test_prefetch_redirect_bug(self):
-        """Test that prefetch persists across redirections."""
-        res = get(httpbin('redirect/2'), prefetch=False)
-        # prefetch should persist across the redirect;
-        # the content should not have been consumed
-        self.assertFalse(res._content_consumed)
-        first_line = next(res.iter_lines())
-        self.assertTrue(first_line.strip().decode('utf-8').startswith('{'))
-
-    def test_prefetch_return_response_interaction(self):
-        """Test that prefetch can be overridden as a kwarg to `send`."""
-        req = requests.get(httpbin('get'), return_response=False)
-        req.send(prefetch=False)
-        # content should not have been prefetched
-        self.assertFalse(req.response._content_consumed)
-        first_line = next(req.response.iter_lines())
-        self.assertTrue(first_line.strip().decode('utf-8').startswith('{'))
-
-    def test_accept_objects_with_string_representations_as_urls(self):
-        """Test that URLs can be set to objects with string representations,
-        e.g. for use with furl."""
-        class URL():
-            def __unicode__(self):
-                # Can't have unicode literals in Python3, so avoid them.
-                # TODO: fixup when moving to Python 3.3
-                if (sys.version_info[0] == 2):
-                    return 'http://httpbin.org/get'.decode('utf-8')
-                else:
-                    return 'http://httpbin.org/get'
-
-            def __str__(self):
-                return 'http://httpbin.org/get'
-
-        r = get(URL())
-        self.assertEqual(r.status_code, 200)
-
-    def test_post_fields_with_multiple_values_and_files_as_tuples(self):
-        """Test that it is possible to POST multiple data and file fields
-        with the same name.
-        https://github.com/kennethreitz/requests/pull/746
-        """
-
-        fields = [
-            ('__field__', '__value__'),
-            ('__field__', '__value__'),
-        ]
-
-        r = post(httpbin('post'), data=fields, files=fields)
-        t = json.loads(r.text)
-
-        self.assertEqual(t.get('form'), {
-            '__field__': [
-                '__value__',
-                '__value__',
-            ]
-        })
-
-        # It's not currently possible to test for multiple file fields with
-        # the same name against httpbin so we need to inspect the encoded
-        # body manually.
-        request = r.request
-        body, content_type = request._encode_files(request.files)
-        file_field = (b'Content-Disposition: form-data;'
-                      b' name="__field__"; filename="__field__"')
-        self.assertEqual(body.count(b'__value__'), 4)
-        self.assertEqual(body.count(file_field), 2)
-
-    def test_bytes_files(self):
-        """Test that `bytes` can be used as the values of `files`."""
-        post(httpbin('post'), files={'test': b'test'})
-
-    def test_invalid_urls_throw_requests_exception(self):
-        """Test that URLs with invalid labels throw
-        Requests.exceptions.InvalidURL instead of UnicodeError."""
-        self.assertRaises(InvalidURL, get, 'http://.google.com/')
-
-    def test_none_vals_in_data_are_deleted(self):
-        """Test that keys with None as the value are removed instead of
-        being posted."""
-        data = {'key1': 'value1', 'key2': None}
-        r = post(httpbin('post'), data=data)
-        vals = r.json['form']
-        self.assertEqual(vals['key1'], 'value1')
-        # The 'key2' key should not have been sent.
-        self.assertTrue(vals.get('key2') is None)
-
-if __name__ == '__main__':
-    unittest.main()
diff --git a/tests/test_requests_ext.py b/tests/test_requests_ext.py
deleted file mode 100644
index ae0a2e18..00000000
--- a/tests/test_requests_ext.py
+++ /dev/null
@@ -1,124 +0,0 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-# Path hack.
-import os
-import sys
-sys.path.insert(0, os.path.abspath('..'))
-
-import unittest
-
-import requests
-from requests.compat import is_py2, is_py3
-
-try:
-    import omnijson as json
-except ImportError:
-    import json
-
-
-class RequestsTestSuite(unittest.TestCase):
-    """Requests test cases."""
-
-    # It goes to eleven.
-    _multiprocess_can_split_ = True
-
-    def test_addition(self):
-        self.assertEqual(2, 1 + 1)
-
-    def test_ssl_hostname_ok(self):
-        requests.get('https://github.com', verify=True)
-
-    def test_ssl_hostname_not_ok(self):
-        requests.get('https://kennethreitz.com', verify=False)
-
-        self.assertRaises(requests.exceptions.SSLError, requests.get, 'https://kennethreitz.com')
-
-    def test_ssl_hostname_session_not_ok(self):
-
-        s = requests.session()
-
-        self.assertRaises(requests.exceptions.SSLError, s.get, 'https://kennethreitz.com')
-
-        s.get('https://kennethreitz.com', verify=False)
-
-    def test_binary_post(self):
-        '''We need to be careful how we build the utf-8 string since
-        unicode literals are a syntax error in python3
-        '''
-
-        if is_py2:
-            # Blasphemy!
-            utf8_string = eval("u'Smörgås'.encode('utf-8')")
-        elif is_py3:
-            utf8_string = 'Smörgås'.encode('utf-8')
-        else:
-            raise EnvironmentError('Flesh out this test for your environment.')
-        requests.post('http://www.google.com/', data=utf8_string)
-
-    def test_unicode_error(self):
-        url = 'http://blip.fm/~1abvfu'
-        requests.get(url)
-
-    def test_chunked_head_redirect(self):
-        url = "http://t.co/NFrx0zLG"
-        r = requests.head(url, allow_redirects=True)
-        self.assertEqual(r.status_code, 200)
-
-    def test_unicode_redirect(self):
-        '''This url redirects to a location that has a nonstandard
-        character in it, that breaks requests in python2.7
-
-        After some research, the cause was identified as an unintended
-        sideeffect of overriding of str with unicode.
-
-        In the case that the redirected url is actually a malformed
-        "bytes" object, i.e. a string with character c where
-            ord(c) > 127,
-        then unicode(url) breaks.
-        '''
-        r = requests.get('http://www.marketwire.com/mw/release.' +
-                         'do?id=1628202&sourceType=3')
-        self.assertTrue(r.ok)
-
-    def test_unicode_url_outright(self):
-        '''This url visits in my browser'''
-        r = requests.get('http://www.marketwire.com/press-release/' +
-                         'jp-morgan-behauptet-sich-der-spitze-euro' +
-                         'p%C3%A4ischer-anleihe-analysten-laut-umf' +
-                         'rageergebnissen-1628202.htm')
-        self.assertTrue(r.ok)
-
-    def test_redirect_encoding(self):
-        '''This url redirects to
-        http://www.dealipedia.com/deal_view_investment.php?r=20012'''
-
-        r = requests.get('http://feedproxy.google.com/~r/Dealipedia' +
-                         'News/~3/BQtUJRJeZlo/deal_view_investment.' +
-                         'php')
-        self.assertTrue(r.ok)
-
-    def test_cookies_on_redirects(self):
-        """Test interaction between cookie handling and redirection."""
-        # get a cookie for tinyurl.com ONLY
-        s = requests.session()
-        s.get(url='http://tinyurl.com/preview.php?disable=1')
-        # we should have set a cookie for tinyurl: preview=0
-        self.assertTrue('preview' in s.cookies)
-        self.assertEqual(s.cookies['preview'], '0')
-        self.assertEqual(list(s.cookies)[0].name, 'preview')
-        self.assertEqual(list(s.cookies)[0].domain, 'tinyurl.com')
-
-        # get cookies on another domain
-        r2 = s.get(url='http://httpbin.org/cookies')
-        # the cookie is not there
-        self.assertTrue('preview' not in json.loads(r2.text)['cookies'])
-
-        # this redirects to another domain, httpbin.org
-        # cookies of the first domain should NOT be sent to the next one
-        r3 = s.get(url='http://tinyurl.com/7zp3jnr')
-        self.assertEqual(r3.url, 'http://httpbin.org/cookies')
-        self.assertTrue('preview' not in json.loads(r3.text)['cookies'])
-
-if __name__ == '__main__':
-    unittest.main()
diff --git a/tests/test_requests_https.py b/tests/test_requests_https.py
deleted file mode 100755
index 2da09824..00000000
--- a/tests/test_requests_https.py
+++ /dev/null
@@ -1,32 +0,0 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-import os
-import sys
-import unittest
-
-# Path hack.
-sys.path.insert(0, os.path.abspath('..'))
-import requests
-
-
-class HTTPSTest(unittest.TestCase):
-    """Smoke test for https functionality."""
-
-    smoke_url = "https://github.com"
-
-    def perform_smoke_test(self, verify=False):
-        result = requests.get(self.smoke_url, verify=verify)
-        self.assertEqual(result.status_code, 200)
-
-    def test_smoke(self):
-        """Smoke test without verification."""
-        self.perform_smoke_test(verify=False)
-
-    def test_smoke_verified(self):
-        """Smoke test with SSL verification."""
-        self.perform_smoke_test(verify=True)
-
-
-if __name__ == '__main__':
-    unittest.main()
diff --git a/tests/test_utils.py b/tests/test_utils.py
deleted file mode 100644
index 015cac63..00000000
--- a/tests/test_utils.py
+++ /dev/null
@@ -1,122 +0,0 @@
-#!/usr/bin/env python
-# -*- coding: utf-8 -*-
-
-import codecs
-import os
-import sys
-import unittest
-import random
-
-# Path hack.
-sys.path.insert(0, os.path.abspath('..'))
-from requests.utils import get_environ_proxies
-import requests.utils
-from requests.compat import is_py3, bytes
-
-
-if is_py3:
-    unichr = chr
-    byteschr = lambda c: bytes([c])
-else:
-    byteschr = chr
-
-
-class UtilityTests(unittest.TestCase):
-    """Tests for the JSON UTF encoding guessing code."""
-
-    codecs = (
-        'utf-8', 'utf-8-sig',
-        'utf-16', 'utf-16-le', 'utf-16-be',
-        'utf-32', 'utf-32-le', 'utf-32-be'
-    )
-
-    def test_guess_encoding(self):
-        # Throw 4-character ASCII strings (encoded to a UTF encoding)
-        # at the guess routine; it should correctly guess all codecs.
-        guess = requests.utils.guess_json_utf
-        for c in range(33, 127):  # printable only
-            sample = unichr(c) * 4
-            for codec in self.codecs:
-                res = guess(sample.encode(codec))
-                self.assertEqual(res, codec)
-
-    def test_smoke_encoding(self):
-        # Throw random 4-byte strings at the guess function.
-        # Any guess for a UTF encoding is verified, a decode exception
-        # is a test failure.
-        guess = requests.utils.guess_json_utf
-        for i in range(1000):
-            sample = bytes().join(
-                [byteschr(random.randrange(256)) for _ in range(4)])
-            res = guess(sample)
-            if res is not None:
-                # This should decode without errors if this is *really*
-                # something in this encoding. However, UTF-8 is a lot
-                # more picky, so we expect errors there. UTF-16 surrogate
-                # pairs also fail
-                try:
-                    sample.decode(res)
-                except UnicodeDecodeError as e:
-                    self.assertEqual(e.args[0].replace('-', '').lower(),
-                                     res.replace('-', '').lower())
-                    if res == 'utf-8':
-                        self.assertTrue(e.args[-1], (
-                            'invalid continuation byte',
-                            'invalid start byte'))
-                        continue
-                    if res == 'utf-16':
-                        self.assertEqual(e.args[-1], 'unexpected end of data')
-                        self.assertTrue(sample[:2] in (
-                            codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE))
-                        # the second two bytes are in the range \ud800-\udfff
-                        # if someone wants to add tests for that as well. I don't
-                        # see the need; we are not testing UTF decoding here.
-                        continue
-                    raise
-
-    def test_get_environ_proxies_respects_no_proxy(self):
-        '''This test confirms that the no_proxy environment setting is
-        respected by get_environ_proxies().'''
-
-        # Store the current environment settings.
-        try:
-            old_http_proxy = os.environ['http_proxy']
-        except KeyError:
-            old_http_proxy = None
-
-        try:
-            old_no_proxy = os.environ['no_proxy']
-        except KeyError:
-            old_no_proxy = None
-
-        # Set up some example environment settings.
-        os.environ['http_proxy'] = 'http://www.example.com/'
-        os.environ['no_proxy'] = r'localhost,.0.0.1:8080'
-
-        # Set up expected proxy return values.
-        proxy_yes = {'http': 'http://www.example.com/'}
-        proxy_no = {}
-
-        # Check that we get the right things back.
-        self.assertEqual(proxy_yes,
-                         get_environ_proxies('http://www.google.com/'))
-        self.assertEqual(proxy_no,
-                         get_environ_proxies('http://localhost/test'))
-        self.assertEqual(proxy_no,
-                         get_environ_proxies('http://127.0.0.1:8080/'))
-        self.assertEqual(proxy_yes,
-                         get_environ_proxies('http://127.0.0.1:8081/'))
-
-        # Return the settings to what they were.
-        if old_http_proxy:
-            os.environ['http_proxy'] = old_http_proxy
-        else:
-            del os.environ['http_proxy']
-
-        if old_no_proxy:
-            os.environ['no_proxy'] = old_no_proxy
-        else:
-            del os.environ['no_proxy']
-
-if __name__ == '__main__':
-    unittest.main()
