commit fe10eeb5bec86e4d2055c63d7686eda53f69fd2f
Author: Kenneth Reitz <me@kennethreitz.com>
Date:   Mon Feb 20 12:25:48 2012 -0500

    SCHEMAS

diff --git a/requests/defaults.py b/requests/defaults.py
index 424d3731..f537862b 100644
--- a/requests/defaults.py
+++ b/requests/defaults.py
@@ -19,6 +19,8 @@ Configurations:
 :pool_connections: The number of active HTTP connection pools to use.
 """
 
+SCHEMAS = ['http', 'https']
+
 from . import __version__
 
 defaults = dict()
@@ -38,3 +40,5 @@ defaults['max_retries'] = 0
 defaults['danger_mode'] = False
 defaults['safe_mode'] = False
 defaults['keep_alive'] = True
+
+
diff --git a/requests/models.py b/requests/models.py
index 0acd0f44..a8c9a884 100644
--- a/requests/models.py
+++ b/requests/models.py
@@ -21,12 +21,13 @@ from .packages.urllib3.exceptions import SSLError as _SSLError
 from .packages.urllib3.exceptions import HTTPError as _HTTPError
 from .packages.urllib3 import connectionpool, poolmanager
 from .packages.urllib3.filepost import encode_multipart_formdata
+from .defaults import SCHEMAS
 from .exceptions import (
     ConnectionError, HTTPError, RequestException, Timeout, TooManyRedirects,
     URLRequired, SSLError)
 from .utils import (
     get_encoding_from_headers, stream_untransfer, guess_filename, requote_uri,
-    dict_from_string, supported_schemes, stream_decode_response_unicode)
+    dict_from_string, stream_decode_response_unicode)
 from .compat import (
     urlparse, urlunparse, urljoin, urlsplit, urlencode, str, bytes,
     SimpleCookie, is_py2)
@@ -311,7 +312,7 @@ class Request(object):
         if not scheme:
             raise ValueError("Invalid URL %r: No schema supplied" % url)
 
-        if not scheme in supported_schemes():
+        if not scheme in SCHEMAS:
             raise ValueError("Invalid scheme %r" % scheme)
 
         netloc = netloc.encode('idna').decode('utf-8')
diff --git a/requests/utils.py b/requests/utils.py
index c0900cf8..adb34145 100644
--- a/requests/utils.py
+++ b/requests/utils.py
@@ -11,13 +11,12 @@ that are also useful for external consumption.
 
 import cgi
 import codecs
-import os
 import random
 import re
 import zlib
 
 from .compat import parse_http_list as _parse_list_header
-from .compat import quote, unquote, cookielib, SimpleCookie, is_py2
+from .compat import quote, cookielib, SimpleCookie, is_py2
 from .compat import basestring, bytes
 
 
@@ -29,17 +28,19 @@ def dict_from_string(s):
     c = SimpleCookie()
     c.load(s)
 
-    for k,v in list(c.items()):
+    for k, v in list(c.items()):
         cookies.update({k: v.value})
 
     return cookies
 
+
 def guess_filename(obj):
     """Tries to guess the filename of the given object."""
     name = getattr(obj, 'name', None)
     if name and name[0] != '<' and name[-1] != '>':
         return name
 
+
 # From mitsuhiko/werkzeug (used with permission).
 def parse_list_header(value):
     """Parse lists as described by RFC 2068 Section 2.
@@ -169,10 +170,9 @@ def header_expand(headers):
 
             collector.append('; '.join(_params))
 
-            if not len(headers) == i+1:
+            if not len(headers) == i + 1:
                 collector.append(', ')
 
-
     # Remove trailing separators.
     if collector[-1] in (', ', '; '):
         del collector[-1]
@@ -180,7 +180,6 @@ def header_expand(headers):
     return ''.join(collector)
 
 
-
 def randombytes(n):
     """Return n random bytes."""
     if is_py2:
@@ -341,6 +340,7 @@ def get_unicode_from_response(r):
     except TypeError:
         return r.content
 
+
 def stream_decompress(iterator, mode='gzip'):
     """
     Stream decodes an iterator over compressed data
@@ -373,6 +373,7 @@ def stream_decompress(iterator, mode='gzip'):
         if rv:
             yield rv
 
+
 def stream_untransfer(gen, resp):
     if 'gzip' in resp.headers.get('content-encoding', ''):
         gen = stream_decompress(gen, mode='gzip')
@@ -387,6 +388,7 @@ UNRESERVED_SET = frozenset(
     "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
     + "0123456789-._~")
 
+
 def unquote_unreserved(uri):
     """Un-escape any percent-escape sequences in a URI that are unreserved
     characters.
@@ -405,6 +407,7 @@ def unquote_unreserved(uri):
             parts[i] = '%' + parts[i]
     return ''.join(parts)
 
+
 def requote_uri(uri):
     """Re-quote the given URI.
 
@@ -415,11 +418,3 @@ def requote_uri(uri):
     # Then quote only illegal characters (do not quote reserved, unreserved,
     # or '%')
     return quote(unquote_unreserved(uri), safe="!#$%&'()*+,/:;=?@[]~")
-    return "/".join(parts)
-
-def supported_schemes():
-    """A list of schemes supported by requests.
-
-    return: a list of strings.
-    """
-    return ["http","https"]
