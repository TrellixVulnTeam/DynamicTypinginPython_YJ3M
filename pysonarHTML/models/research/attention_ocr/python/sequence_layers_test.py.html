<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/attention_ocr/python/sequence_layers_test.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net'>fake_net</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels'>fake_labels</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer'>create_layer</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest'>SequenceLayersTest</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape'>test_net_slice_char_logits_with_correct_shape</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape'>test_net_slice_with_autoregression_char_logits_with_correct_shape</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape'>test_attention_char_logits_with_correct_shape</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape'>test_attention_with_autoregression_char_logits_with_correct_shape</a></li></ul>
</li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2017 The TensorFlow Authors All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> &quot;&quot;&quot;Tests for sequence_layers.&quot;&quot;&quot;
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> from __future__ import absolute_import
<span class='lineno'>  19</span> from __future__ import division
<span class='lineno'>  20</span> from __future__ import print_function
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> import numpy as np
<span class='lineno'>  23</span> import tensorflow as tf
<span class='lineno'>  24</span> from tensorflow.contrib import slim
<span class='lineno'>  25</span> 
<span class='lineno'>  26</span> import <a href='model.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.model', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.model', title='model'>model</a>
<span class='lineno'>  27</span> import <a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', title='sequence_layers'>sequence_layers</a>
<span class='lineno'>  28</span> 
<span class='lineno'>  29</span> 
<span class='lineno'>  30</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net', title='(?, ?, ?) -> ? / (?, int, int) -> ? / (int, int, int) -> ?'>fake_net</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.batch_size', title='int'>batch_size</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.num_features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.num_features', title='int'>num_features</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.feature_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.feature_size', title='int'>feature_size</a>):
<span class='lineno'>  31</span>   return tf.convert_to_tensor(
<span class='lineno'>  32</span>       np.random.uniform(size=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.batch_size', title='int'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.num_features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.num_features', title='int'>num_features</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.feature_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net.feature_size', title='int'>feature_size</a>)),
<span class='lineno'>  33</span>       dtype=tf.float32)
<span class='lineno'>  34</span> 
<span class='lineno'>  35</span> 
<span class='lineno'>  36</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels', title='(int, int, int) -> None / (?, ?, ?) -> None'>fake_labels</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.batch_size', title='int'>batch_size</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.seq_length', title='int'>seq_length</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.num_char_classes', title='int'>num_char_classes</a>):
<span class='lineno'>  37</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.labels_np', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.labels_np', title='?'>labels_np</a> = tf.convert_to_tensor(
<span class='lineno'>  38</span>       np.random.randint(
<span class='lineno'>  39</span>           low=0, high=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.num_char_classes', title='int'>num_char_classes</a>, size=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.batch_size', title='int'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.seq_length', title='int'>seq_length</a>)))
<span class='lineno'>  40</span>   return slim.one_hot_encoding(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.labels_np', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.labels_np', title='?'>labels_np</a>, num_classes=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels.num_char_classes', title='int'>num_char_classes</a>)
<span class='lineno'>  41</span> 
<span class='lineno'>  42</span> 
<span class='lineno'>  43</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer', title='(<AttentionWithAutoregression>, int, int, int) -> AttentionWithAutoregression / (<NetSlice>, int, int, int) -> NetSlice / (<NetSliceWithAutoregression>, int, int, int) -> NetSliceWithAutoregression / (?, ?, ?, ?) -> None / (<Attention>, int, int, int) -> Attention'>create_layer</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.layer_class', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.layer_class', title='{<Attention> | <AttentionWithAutoregression> | <NetSlice> | <NetSliceWithAutoregression>}'>layer_class</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.batch_size', title='int'>batch_size</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.seq_length', title='int'>seq_length</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.num_char_classes', title='int'>num_char_classes</a>):
<span class='lineno'>  44</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.model_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.model_params', title='(namedtuple)'>model_params</a> = <a href='model.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.model', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.model', title='model'>model</a>.<a href='model.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.model.ModelParams', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.model.ModelParams', title='<(namedtuple)>'>ModelParams</a>(
<span class='lineno'>  45</span>       num_char_classes=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.num_char_classes', title='int'>num_char_classes</a>,
<span class='lineno'>  46</span>       seq_length=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.seq_length', title='int'>seq_length</a>,
<span class='lineno'>  47</span>       num_views=1,
<span class='lineno'>  48</span>       null_code=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.num_char_classes', title='int'>num_char_classes</a>)
<span class='lineno'>  49</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.net', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.net', title='?'>net</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_net', title='(?, ?, ?) -> ? / (?, int, int) -> ? / (int, int, int) -> ?'>fake_net</a>(
<span class='lineno'>  50</span>       batch_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.batch_size', title='int'>batch_size</a>, num_features=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.seq_length', title='int'>seq_length</a> * 5, feature_size=6)
<span class='lineno'>  51</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.labels_one_hot', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.labels_one_hot', title='None'>labels_one_hot</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.fake_labels', title='(int, int, int) -> None / (?, ?, ?) -> None'>fake_labels</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.batch_size', title='int'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.seq_length', title='int'>seq_length</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.num_char_classes', title='int'>num_char_classes</a>)
<span class='lineno'>  52</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.layer_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.layer_params', title='(namedtuple)'>layer_params</a> = <a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', title='sequence_layers'>sequence_layers</a>.<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.SequenceLayerParams', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.SequenceLayerParams', title='<(namedtuple)>'>SequenceLayerParams</a>(
<span class='lineno'>  53</span>       num_lstm_units=10, weight_decay=0.00004, lstm_state_clip_value=10.0)
<span class='lineno'>  54</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.layer_class', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.layer_class', title='{<Attention> | <AttentionWithAutoregression> | <NetSlice> | <NetSliceWithAutoregression>}'>layer_class</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.net', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.net', title='?'>net</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.labels_one_hot', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.labels_one_hot', title='None'>labels_one_hot</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.model_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.model_params', title='(namedtuple)'>model_params</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.layer_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer.layer_params', title='(namedtuple)'>layer_params</a>)
<span class='lineno'>  55</span> 
<span class='lineno'>  56</span> 
<span class='lineno'>  57</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest', title='<SequenceLayersTest>'>SequenceLayersTest</a>(tf.test.TestCase):
<span class='lineno'>  58</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape', title='SequenceLayersTest -> None'>test_net_slice_char_logits_with_correct_shape</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.self', title='SequenceLayersTest'>self</a>):
<span class='lineno'>  59</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a> = 2
<span class='lineno'>  60</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a> = 4
<span class='lineno'>  61</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a> = 3
<span class='lineno'>  62</span> 
<span class='lineno'>  63</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.layer', title='NetSlice'>layer</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer', title='(<AttentionWithAutoregression>, int, int, int) -> AttentionWithAutoregression / (<NetSlice>, int, int, int) -> NetSlice / (<NetSliceWithAutoregression>, int, int, int) -> NetSliceWithAutoregression / (?, ?, ?, ?) -> None / (<Attention>, int, int, int) -> Attention'>create_layer</a>(<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', title='sequence_layers'>sequence_layers</a>.<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.NetSlice', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.NetSlice', title='<NetSlice>'>NetSlice</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a>,
<span class='lineno'>  64</span>                          <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a>)
<span class='lineno'>  65</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.char_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.char_logits', title='None'>char_logits</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.layer', title='NetSlice'>layer</a>.<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.SequenceLayerBase.create_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.SequenceLayerBase.create_logits', title='AttentionWithAutoregression -> None / NetSlice -> None / Attention -> None / NetSliceWithAutoregression -> None / SequenceLayerBase -> None'>create_logits</a>()
<span class='lineno'>  66</span> 
<span class='lineno'>  67</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.self', title='SequenceLayersTest'>self</a>.assertEqual(
<span class='lineno'>  68</span>         tf.TensorShape([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a>]),
<span class='lineno'>  69</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.char_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_char_logits_with_correct_shape.char_logits', title='None'>char_logits</a>.get_shape())
<span class='lineno'>  70</span> 
<span class='lineno'>  71</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape', title='SequenceLayersTest -> None'>test_net_slice_with_autoregression_char_logits_with_correct_shape</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.self', title='SequenceLayersTest'>self</a>):
<span class='lineno'>  72</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a> = 2
<span class='lineno'>  73</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a> = 4
<span class='lineno'>  74</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a> = 3
<span class='lineno'>  75</span> 
<span class='lineno'>  76</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.layer', title='NetSliceWithAutoregression'>layer</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer', title='(<AttentionWithAutoregression>, int, int, int) -> AttentionWithAutoregression / (<NetSlice>, int, int, int) -> NetSlice / (<NetSliceWithAutoregression>, int, int, int) -> NetSliceWithAutoregression / (?, ?, ?, ?) -> None / (<Attention>, int, int, int) -> Attention'>create_layer</a>(<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', title='sequence_layers'>sequence_layers</a>.<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.NetSliceWithAutoregression', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.NetSliceWithAutoregression', title='<NetSliceWithAutoregression>'>NetSliceWithAutoregression</a>,
<span class='lineno'>  77</span>                          <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a>)
<span class='lineno'>  78</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.char_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.char_logits', title='None'>char_logits</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.layer', title='NetSliceWithAutoregression'>layer</a>.<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.SequenceLayerBase.create_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.SequenceLayerBase.create_logits', title='AttentionWithAutoregression -> None / NetSlice -> None / Attention -> None / NetSliceWithAutoregression -> None / SequenceLayerBase -> None'>create_logits</a>()
<span class='lineno'>  79</span> 
<span class='lineno'>  80</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.self', title='SequenceLayersTest'>self</a>.assertEqual(
<span class='lineno'>  81</span>         tf.TensorShape([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a>]),
<span class='lineno'>  82</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.char_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_net_slice_with_autoregression_char_logits_with_correct_shape.char_logits', title='None'>char_logits</a>.get_shape())
<span class='lineno'>  83</span> 
<span class='lineno'>  84</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape', title='SequenceLayersTest -> None'>test_attention_char_logits_with_correct_shape</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.self', title='SequenceLayersTest'>self</a>):
<span class='lineno'>  85</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a> = 2
<span class='lineno'>  86</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a> = 4
<span class='lineno'>  87</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a> = 3
<span class='lineno'>  88</span> 
<span class='lineno'>  89</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.layer', title='Attention'>layer</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer', title='(<AttentionWithAutoregression>, int, int, int) -> AttentionWithAutoregression / (<NetSlice>, int, int, int) -> NetSlice / (<NetSliceWithAutoregression>, int, int, int) -> NetSliceWithAutoregression / (?, ?, ?, ?) -> None / (<Attention>, int, int, int) -> Attention'>create_layer</a>(<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', title='sequence_layers'>sequence_layers</a>.<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.Attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.Attention', title='<Attention>'>Attention</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a>,
<span class='lineno'>  90</span>                          <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a>)
<span class='lineno'>  91</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.char_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.char_logits', title='None'>char_logits</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.layer', title='Attention'>layer</a>.<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.SequenceLayerBase.create_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.SequenceLayerBase.create_logits', title='AttentionWithAutoregression -> None / NetSlice -> None / Attention -> None / NetSliceWithAutoregression -> None / SequenceLayerBase -> None'>create_logits</a>()
<span class='lineno'>  92</span> 
<span class='lineno'>  93</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.self', title='SequenceLayersTest'>self</a>.assertEqual(
<span class='lineno'>  94</span>         tf.TensorShape([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a>]),
<span class='lineno'>  95</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.char_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_char_logits_with_correct_shape.char_logits', title='None'>char_logits</a>.get_shape())
<span class='lineno'>  96</span> 
<span class='lineno'>  97</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape', title='SequenceLayersTest -> None'>test_attention_with_autoregression_char_logits_with_correct_shape</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.self', title='SequenceLayersTest'>self</a>):
<span class='lineno'>  98</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a> = 2
<span class='lineno'>  99</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a> = 4
<span class='lineno'> 100</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a> = 3
<span class='lineno'> 101</span> 
<span class='lineno'> 102</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.layer', title='AttentionWithAutoregression'>layer</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.create_layer', title='(<AttentionWithAutoregression>, int, int, int) -> AttentionWithAutoregression / (<NetSlice>, int, int, int) -> NetSlice / (<NetSliceWithAutoregression>, int, int, int) -> NetSliceWithAutoregression / (?, ?, ?, ?) -> None / (<Attention>, int, int, int) -> Attention'>create_layer</a>(<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers', title='sequence_layers'>sequence_layers</a>.<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.AttentionWithAutoregression', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.AttentionWithAutoregression', title='<AttentionWithAutoregression>'>AttentionWithAutoregression</a>,
<span class='lineno'> 103</span>                          <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a>)
<span class='lineno'> 104</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.char_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.char_logits', title='None'>char_logits</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.layer', title='AttentionWithAutoregression'>layer</a>.<a href='sequence_layers.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.SequenceLayerBase.create_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers.SequenceLayerBase.create_logits', title='AttentionWithAutoregression -> None / NetSlice -> None / Attention -> None / NetSliceWithAutoregression -> None / SequenceLayerBase -> None'>create_logits</a>()
<span class='lineno'> 105</span> 
<span class='lineno'> 106</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.self', title='SequenceLayersTest'>self</a>.assertEqual(
<span class='lineno'> 107</span>         tf.TensorShape([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.batch_size', title='int'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.seq_length', title='int'>seq_length</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.num_char_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.num_char_classes', title='int'>num_char_classes</a>]),
<span class='lineno'> 108</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.char_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.sequence_layers_test.SequenceLayersTest.test_attention_with_autoregression_char_logits_with_correct_shape.char_logits', title='None'>char_logits</a>.get_shape())
<span class='lineno'> 109</span> 
<span class='lineno'> 110</span> 
<span class='lineno'> 111</span> if __name__ == &#39;__main__&#39;:
<span class='lineno'> 112</span>   tf.test.main()
</pre></td></tr></table></body></html>