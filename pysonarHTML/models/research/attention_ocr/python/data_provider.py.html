<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/attention_ocr/python/data_provider.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.InputEndpoints', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.InputEndpoints'>InputEndpoints</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.ShuffleBatchConfig', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.ShuffleBatchConfig'>ShuffleBatchConfig</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.DEFAULT_SHUFFLE_CONFIG', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.DEFAULT_SHUFFLE_CONFIG'>DEFAULT_SHUFFLE_CONFIG</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image'>augment_image</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop'>central_crop</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image'>preprocess_image</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data', xid='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data'>get_data</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2017 The TensorFlow Authors All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> &quot;&quot;&quot;Functions to read, decode and pre-process input data for the Model.
<span class='lineno'>  17</span> &quot;&quot;&quot;
<span class='lineno'>  18</span> import collections
<span class='lineno'>  19</span> import functools
<span class='lineno'>  20</span> import tensorflow as tf
<span class='lineno'>  21</span> from tensorflow.contrib import slim
<span class='lineno'>  22</span> 
<span class='lineno'>  23</span> import <a href='inception_preprocessing.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing', title='inception_preprocessing'>inception_preprocessing</a>
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> # Tuple to store input data endpoints for the Model.
<span class='lineno'>  26</span> # It has following fields (tensors):
<span class='lineno'>  27</span> #    images: input images,
<span class='lineno'>  28</span> #      shape [batch_size x H x W x 3];
<span class='lineno'>  29</span> #    labels: ground truth label ids,
<span class='lineno'>  30</span> #      shape=[batch_size x seq_length];
<span class='lineno'>  31</span> #    labels_one_hot: labels in one-hot encoding,
<span class='lineno'>  32</span> #      shape [batch_size x seq_length x num_char_classes];
<span class='lineno'>  33</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.InputEndpoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.InputEndpoints', title='<(namedtuple)>'>InputEndpoints</a> = collections.namedtuple(
<span class='lineno'>  34</span>     &#39;InputEndpoints&#39;, [&#39;images&#39;, &#39;images_orig&#39;, &#39;labels&#39;, &#39;labels_one_hot&#39;])
<span class='lineno'>  35</span> 
<span class='lineno'>  36</span> # A namedtuple to define a configuration for shuffled batch fetching.
<span class='lineno'>  37</span> #   num_batching_threads: A number of parallel threads to fetch data.
<span class='lineno'>  38</span> #   queue_capacity: a max number of elements in the batch shuffling queue.
<span class='lineno'>  39</span> #   min_after_dequeue: a min number elements in the queue after a dequeue, used
<span class='lineno'>  40</span> #     to ensure a level of mixing of elements.
<span class='lineno'>  41</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.ShuffleBatchConfig', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.ShuffleBatchConfig', title='<(namedtuple)>'>ShuffleBatchConfig</a> = collections.namedtuple(&#39;ShuffleBatchConfig&#39;, [
<span class='lineno'>  42</span>     &#39;num_batching_threads&#39;, &#39;queue_capacity&#39;, &#39;min_after_dequeue&#39;
<span class='lineno'>  43</span> ])
<span class='lineno'>  44</span> 
<span class='lineno'>  45</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.DEFAULT_SHUFFLE_CONFIG', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.DEFAULT_SHUFFLE_CONFIG', title='(namedtuple)'>DEFAULT_SHUFFLE_CONFIG</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.ShuffleBatchConfig', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.ShuffleBatchConfig', title='<(namedtuple)>'>ShuffleBatchConfig</a>(
<span class='lineno'>  46</span>     num_batching_threads=8, queue_capacity=3000, min_after_dequeue=1000)
<span class='lineno'>  47</span> 
<span class='lineno'>  48</span> 
<span class='lineno'>  49</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image', title='? -> None'>augment_image</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.image', title='?'>image</a>):
<span class='lineno'>  50</span>   &quot;&quot;&quot;Augmentation the image with a random modification.
<span class='lineno'>  51</span> 
<span class='lineno'>  52</span>   Args:
<span class='lineno'>  53</span>     image: input Tensor image of rank 3, with the last dimension
<span class='lineno'>  54</span>            of size 3.
<span class='lineno'>  55</span> 
<span class='lineno'>  56</span>   Returns:
<span class='lineno'>  57</span>     Distorted Tensor image of the same shape.
<span class='lineno'>  58</span>   &quot;&quot;&quot;
<span class='lineno'>  59</span>   with tf.variable_scope(&#39;AugmentImage&#39;):
<span class='lineno'>  60</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.height', title='?'>height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.image', title='?'>image</a>.get_shape().dims[0].value
<span class='lineno'>  61</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.width', title='?'>width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.image', title='?'>image</a>.get_shape().dims[1].value
<span class='lineno'>  62</span> 
<span class='lineno'>  63</span>     # Random crop cut from the street sign image, resized to the same size.
<span class='lineno'>  64</span>     # Assures that the crop is covers at least 0.8 area of the input image.
<span class='lineno'>  65</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.bbox_begin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.bbox_begin', title='?'>bbox_begin</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.bbox_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.bbox_size', title='?'>bbox_size</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image._', title='?'>_</a> = tf.image.sample_distorted_bounding_box(
<span class='lineno'>  66</span>         tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.image', title='?'>image</a>),
<span class='lineno'>  67</span>         bounding_boxes=tf.zeros([0, 0, 4]),
<span class='lineno'>  68</span>         min_object_covered=0.8,
<span class='lineno'>  69</span>         aspect_ratio_range=[0.8, 1.2],
<span class='lineno'>  70</span>         area_range=[0.8, 1.0],
<span class='lineno'>  71</span>         use_image_if_no_bounding_boxes=True)
<span class='lineno'>  72</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', title='?'>distorted_image</a> = tf.slice(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.bbox_begin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.bbox_begin', title='?'>bbox_begin</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.bbox_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.bbox_size', title='?'>bbox_size</a>)
<span class='lineno'>  73</span> 
<span class='lineno'>  74</span>     # Randomly chooses one of the 4 interpolation methods
<span class='lineno'>  75</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', title='None'>distorted_image</a> = <a href='inception_preprocessing.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing', title='inception_preprocessing'>inception_preprocessing</a>.<a href='inception_preprocessing.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing.apply_with_random_selector', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing.apply_with_random_selector', title='(?, (?, int) -> None, int) -> None / (?, (?, int) -> ?, int) -> None / (None, ?, int) -> None / (?, ?, ?) -> None'>apply_with_random_selector</a>(
<span class='lineno'>  76</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', title='?'>distorted_image</a>,
<span class='lineno'>  77</span>         lambda <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.lambda%93.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.lambda%93.x', title='?'>x</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.lambda%93.method', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.lambda%93.method', title='int'>method</a>: tf.image.resize_images(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.lambda%93.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.lambda%93.x', title='?'>x</a>, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.width', title='?'>width</a>], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.lambda%93.method', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.lambda%93.method', title='int'>method</a>),
<span class='lineno'>  78</span>         num_cases=4)
<span class='lineno'>  79</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', title='None'>distorted_image</a>.set_shape([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.width', title='?'>width</a>, 3])
<span class='lineno'>  80</span> 
<span class='lineno'>  81</span>     # Color distortion
<span class='lineno'>  82</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', title='None'>distorted_image</a> = <a href='inception_preprocessing.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing', title='inception_preprocessing'>inception_preprocessing</a>.<a href='inception_preprocessing.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing.apply_with_random_selector', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing.apply_with_random_selector', title='(?, (?, int) -> None, int) -> None / (?, (?, int) -> ?, int) -> None / (None, ?, int) -> None / (?, ?, ?) -> None'>apply_with_random_selector</a>(
<span class='lineno'>  83</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', title='None'>distorted_image</a>,
<span class='lineno'>  84</span>         functools.partial(
<span class='lineno'>  85</span>             <a href='inception_preprocessing.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing', title='inception_preprocessing'>inception_preprocessing</a>.<a href='inception_preprocessing.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing.distort_color', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.inception_preprocessing.distort_color', title='(?, int, bool, None) -> None'>distort_color</a>, fast_mode=False),
<span class='lineno'>  86</span>         num_cases=4)
<span class='lineno'>  87</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', title='?'>distorted_image</a> = tf.clip_by_value(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', title='None'>distorted_image</a>, -1.5, 1.5)
<span class='lineno'>  88</span> 
<span class='lineno'>  89</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image.distorted_image', title='?'>distorted_image</a>
<span class='lineno'>  90</span> 
<span class='lineno'>  91</span> 
<span class='lineno'>  92</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop', title='(?, ?) -> None / (?, (int, ?)) -> None'>central_crop</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.crop_size', title='(int, ?)'>crop_size</a>):
<span class='lineno'>  93</span>   &quot;&quot;&quot;Returns a central crop for the specified size of an image.
<span class='lineno'>  94</span> 
<span class='lineno'>  95</span>   Args:
<span class='lineno'>  96</span>     image: A tensor with shape [height, width, channels]
<span class='lineno'>  97</span>     crop_size: A tuple (crop_width, crop_height)
<span class='lineno'>  98</span> 
<span class='lineno'>  99</span>   Returns:
<span class='lineno'> 100</span>     A tensor of shape [crop_height, crop_width, channels].
<span class='lineno'> 101</span>   &quot;&quot;&quot;
<span class='lineno'> 102</span>   with tf.variable_scope(&#39;CentralCrop&#39;):
<span class='lineno'> 103</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_width', title='int'>target_width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_height', title='?'>target_height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.crop_size', title='(int, ?)'>crop_size</a>
<span class='lineno'> 104</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_height', title='?'>image_height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_width', title='?'>image_width</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image', title='?'>image</a>)[0], tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image', title='?'>image</a>)[1]
<span class='lineno'> 105</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.assert_op1', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.assert_op1', title='?'>assert_op1</a> = tf.Assert(
<span class='lineno'> 106</span>         tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_height', title='?'>image_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_height', title='?'>target_height</a>),
<span class='lineno'> 107</span>         [&#39;image_height &lt; target_height&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_height', title='?'>image_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_height', title='?'>target_height</a>])
<span class='lineno'> 108</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.assert_op2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.assert_op2', title='?'>assert_op2</a> = tf.Assert(
<span class='lineno'> 109</span>         tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_width', title='?'>image_width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_width', title='int'>target_width</a>),
<span class='lineno'> 110</span>         [&#39;image_width &lt; target_width&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_width', title='?'>image_width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_width', title='int'>target_width</a>])
<span class='lineno'> 111</span>     with tf.control_dependencies([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.assert_op1', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.assert_op1', title='?'>assert_op1</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.assert_op2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.assert_op2', title='?'>assert_op2</a>]):
<span class='lineno'> 112</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.offset_width', title='?'>offset_width</a> = tf.cast((<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_width', title='?'>image_width</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_width', title='int'>target_width</a>) / 2, tf.int32)
<span class='lineno'> 113</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.offset_height', title='?'>offset_height</a> = tf.cast((<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image_height', title='?'>image_height</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_height', title='?'>target_height</a>) / 2, tf.int32)
<span class='lineno'> 114</span>       return tf.image.crop_to_bounding_box(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.offset_height', title='?'>offset_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.offset_width', title='?'>offset_width</a>,
<span class='lineno'> 115</span>                                            <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_height', title='?'>target_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop.target_width', title='int'>target_width</a>)
<span class='lineno'> 116</span> 
<span class='lineno'> 117</span> 
<span class='lineno'> 118</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image', title='(?, bool, None, int) -> None'>preprocess_image</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.augment', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.augment', title='bool'>augment</a>=False, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.central_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.central_crop_size', title='None'>central_crop_size</a>=None,
<span class='lineno'> 119</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.num_towers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.num_towers', title='int'>num_towers</a>=4):
<span class='lineno'> 120</span>   &quot;&quot;&quot;Normalizes image to have values in a narrow range around zero.
<span class='lineno'> 121</span> 
<span class='lineno'> 122</span>   Args:
<span class='lineno'> 123</span>     image: a [H x W x 3] uint8 tensor.
<span class='lineno'> 124</span>     augment: optional, if True do random image distortion.
<span class='lineno'> 125</span>     central_crop_size: A tuple (crop_width, crop_height).
<span class='lineno'> 126</span>     num_towers: optional, number of shots of the same image in the input image.
<span class='lineno'> 127</span> 
<span class='lineno'> 128</span>   Returns:
<span class='lineno'> 129</span>     A float32 tensor of shape [H x W x 3] with RGB values in the required
<span class='lineno'> 130</span>     range.
<span class='lineno'> 131</span>   &quot;&quot;&quot;
<span class='lineno'> 132</span>   with tf.variable_scope(&#39;PreprocessImage&#39;):
<span class='lineno'> 133</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', title='?'>image</a> = tf.image.convert_image_dtype(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', title='?'>image</a>, dtype=tf.float32)
<span class='lineno'> 134</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.augment', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.augment', title='bool'>augment</a> or <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.central_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.central_crop_size', title='None'>central_crop_size</a>:
<span class='lineno'> 135</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.num_towers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.num_towers', title='int'>num_towers</a> == 1:
<span class='lineno'> 136</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', title='[?]'>images</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', title='?'>image</a>]
<span class='lineno'> 137</span>       else:
<span class='lineno'> 138</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', title='?'>images</a> = tf.split(value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', title='?'>image</a>, num_or_size_splits=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.num_towers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.num_towers', title='int'>num_towers</a>, axis=1)
<span class='lineno'> 139</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.central_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.central_crop_size', title='None'>central_crop_size</a>:
<span class='lineno'> 140</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.view_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.view_crop_size', title='(int, ?)'>view_crop_size</a> = (int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.central_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.central_crop_size', title='None'>central_crop_size</a>[0] / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.num_towers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.num_towers', title='int'>num_towers</a>),
<span class='lineno'> 141</span>                           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.central_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.central_crop_size', title='None'>central_crop_size</a>[1])
<span class='lineno'> 142</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', title='[None]'>images</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.central_crop', title='(?, ?) -> None / (?, (int, ?)) -> None'>central_crop</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', title='?'>img</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.view_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.view_crop_size', title='(int, ?)'>view_crop_size</a>) for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', title='?'>img</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', title='[?]'>images</a>]
<span class='lineno'> 143</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.augment', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.augment', title='bool'>augment</a>:
<span class='lineno'> 144</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', title='[None]'>images</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.augment_image', title='? -> None'>augment_image</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', title='?'>img</a>) for <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.img', title='?'>img</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', title='{[?] | [None]}'>images</a>]
<span class='lineno'> 145</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', title='?'>image</a> = tf.concat(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.images', title='{[?] | [None]}'>images</a>, 1)
<span class='lineno'> 146</span> 
<span class='lineno'> 147</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', title='?'>image</a> = tf.subtract(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', title='?'>image</a>, 0.5)
<span class='lineno'> 148</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', title='?'>image</a> = tf.multiply(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', title='?'>image</a>, 2.5)
<span class='lineno'> 149</span> 
<span class='lineno'> 150</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image.image', title='?'>image</a>
<span class='lineno'> 151</span> 
<span class='lineno'> 152</span> 
<span class='lineno'> 153</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data', title='(?, int, bool, None, None, bool) -> (namedtuple) / (None, ?, bool, None, None, bool) -> (namedtuple) / (?, ?, bool, None, None, bool) -> (namedtuple)'>get_data</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.dataset', title='None'>dataset</a>,
<span class='lineno'> 154</span>              <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.batch_size', title='int'>batch_size</a>,
<span class='lineno'> 155</span>              <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.augment', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.augment', title='bool'>augment</a>=False,
<span class='lineno'> 156</span>              <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.central_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.central_crop_size', title='None'>central_crop_size</a>=None,
<span class='lineno'> 157</span>              <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', title='None'>shuffle_config</a>=None,
<span class='lineno'> 158</span>              <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle', title='bool'>shuffle</a>=True):
<span class='lineno'> 159</span>   &quot;&quot;&quot;Wraps calls to DatasetDataProviders and shuffle_batch.
<span class='lineno'> 160</span> 
<span class='lineno'> 161</span>   For more details about supported Dataset objects refer to datasets/fsns.py.
<span class='lineno'> 162</span> 
<span class='lineno'> 163</span>   Args:
<span class='lineno'> 164</span>     dataset: a slim.data.dataset.Dataset object.
<span class='lineno'> 165</span>     batch_size: number of samples per batch.
<span class='lineno'> 166</span>     augment: optional, if True does random image distortion.
<span class='lineno'> 167</span>     central_crop_size: A CharLogittuple (crop_width, crop_height).
<span class='lineno'> 168</span>     shuffle_config: A namedtuple ShuffleBatchConfig.
<span class='lineno'> 169</span>     shuffle: if True use data shuffling.
<span class='lineno'> 170</span> 
<span class='lineno'> 171</span>   Returns:
<span class='lineno'> 172</span> 
<span class='lineno'> 173</span>   &quot;&quot;&quot;
<span class='lineno'> 174</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', title='None'>shuffle_config</a>:
<span class='lineno'> 175</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', title='(namedtuple)'>shuffle_config</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.DEFAULT_SHUFFLE_CONFIG', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.DEFAULT_SHUFFLE_CONFIG', title='(namedtuple)'>DEFAULT_SHUFFLE_CONFIG</a>
<span class='lineno'> 176</span> 
<span class='lineno'> 177</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.provider', title='?'>provider</a> = slim.dataset_data_provider.DatasetDataProvider(
<span class='lineno'> 178</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.dataset', title='None'>dataset</a>,
<span class='lineno'> 179</span>       shuffle=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle', title='bool'>shuffle</a>,
<span class='lineno'> 180</span>       common_queue_capacity=2 * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.batch_size', title='int'>batch_size</a>,
<span class='lineno'> 181</span>       common_queue_min=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.batch_size', title='int'>batch_size</a>)
<span class='lineno'> 182</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.image_orig', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.image_orig', title='?'>image_orig</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.label', title='?'>label</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.provider', title='?'>provider</a>.get([&#39;image&#39;, &#39;label&#39;])
<span class='lineno'> 183</span> 
<span class='lineno'> 184</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.preprocess_image', title='(?, bool, None, int) -> None'>preprocess_image</a>(
<span class='lineno'> 185</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.image_orig', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.image_orig', title='?'>image_orig</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.augment', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.augment', title='bool'>augment</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.central_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.central_crop_size', title='None'>central_crop_size</a>, num_towers=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.dataset', title='None'>dataset</a>.num_of_views)
<span class='lineno'> 186</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.label_one_hot', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.label_one_hot', title='?'>label_one_hot</a> = slim.one_hot_encoding(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.label', title='?'>label</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.dataset', title='None'>dataset</a>.num_char_classes)
<span class='lineno'> 187</span> 
<span class='lineno'> 188</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.images', title='?'>images</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.images_orig', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.images_orig', title='?'>images_orig</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.labels_one_hot', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.labels_one_hot', title='?'>labels_one_hot</a> = (tf.train.shuffle_batch(
<span class='lineno'> 189</span>       [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.image', title='None'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.image_orig', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.image_orig', title='?'>image_orig</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.label', title='?'>label</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.label_one_hot', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.label_one_hot', title='?'>label_one_hot</a>],
<span class='lineno'> 190</span>       batch_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.batch_size', title='int'>batch_size</a>,
<span class='lineno'> 191</span>       num_threads=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', title='(namedtuple)'>shuffle_config</a>.num_batching_threads,
<span class='lineno'> 192</span>       capacity=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', title='(namedtuple)'>shuffle_config</a>.queue_capacity,
<span class='lineno'> 193</span>       min_after_dequeue=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.shuffle_config', title='(namedtuple)'>shuffle_config</a>.min_after_dequeue))
<span class='lineno'> 194</span> 
<span class='lineno'> 195</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.InputEndpoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.InputEndpoints', title='<(namedtuple)>'>InputEndpoints</a>(
<span class='lineno'> 196</span>       images=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.images', title='?'>images</a>,
<span class='lineno'> 197</span>       images_orig=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.images_orig', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.images_orig', title='?'>images_orig</a>,
<span class='lineno'> 198</span>       labels=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.labels', title='?'>labels</a>,
<span class='lineno'> 199</span>       labels_one_hot=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.labels_one_hot', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.attention_ocr.python.data_provider.get_data.labels_one_hot', title='?'>labels_one_hot</a>)
</pre></td></tr></table></body></html>