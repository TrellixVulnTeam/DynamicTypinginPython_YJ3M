<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/slim/preprocessing/vgg_preprocessing.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._R_MEAN', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._R_MEAN'>_R_MEAN</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._G_MEAN', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._G_MEAN'>_G_MEAN</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._B_MEAN', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._B_MEAN'>_B_MEAN</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MIN', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MIN'>_RESIZE_SIDE_MIN</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MAX', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MAX'>_RESIZE_SIDE_MAX</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop'>_crop</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop'>_random_crop</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop'>_central_crop</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction'>_mean_image_subtraction</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least'>_smallest_size_at_least</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize'>_aspect_preserving_resize</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train'>preprocess_for_train</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval'>preprocess_for_eval</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image'>preprocess_image</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2016 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> # http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> &quot;&quot;&quot;Provides utilities to preprocess images.
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span> The preprocessing steps for VGG were introduced in the following technical
<span class='lineno'>  18</span> report:
<span class='lineno'>  19</span> 
<span class='lineno'>  20</span>   Very Deep Convolutional Networks For Large-Scale Image Recognition
<span class='lineno'>  21</span>   Karen Simonyan and Andrew Zisserman
<span class='lineno'>  22</span>   arXiv technical report, 2015
<span class='lineno'>  23</span>   PDF: http://arxiv.org/pdf/1409.1556.pdf
<span class='lineno'>  24</span>   ILSVRC 2014 Slides: http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf
<span class='lineno'>  25</span>   CC-BY-4.0
<span class='lineno'>  26</span> 
<span class='lineno'>  27</span> More information can be obtained from the VGG website:
<span class='lineno'>  28</span> www.robots.ox.ac.uk/~vgg/research/very_deep/
<span class='lineno'>  29</span> &quot;&quot;&quot;
<span class='lineno'>  30</span> 
<span class='lineno'>  31</span> from __future__ import absolute_import
<span class='lineno'>  32</span> from __future__ import division
<span class='lineno'>  33</span> from __future__ import print_function
<span class='lineno'>  34</span> 
<span class='lineno'>  35</span> import tensorflow.compat.v1 as tf
<span class='lineno'>  36</span> 
<span class='lineno'>  37</span> 
<span class='lineno'>  38</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._R_MEAN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._R_MEAN', title='float'>_R_MEAN</a> = 123.68
<span class='lineno'>  39</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._G_MEAN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._G_MEAN', title='float'>_G_MEAN</a> = 116.78
<span class='lineno'>  40</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._B_MEAN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._B_MEAN', title='float'>_B_MEAN</a> = 103.94
<span class='lineno'>  41</span> 
<span class='lineno'>  42</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MIN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MIN', title='int'>_RESIZE_SIDE_MIN</a> = 256
<span class='lineno'>  43</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MAX', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MAX', title='int'>_RESIZE_SIDE_MAX</a> = 512
<span class='lineno'>  44</span> 
<span class='lineno'>  45</span> 
<span class='lineno'>  46</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop', title='(?, int, int, ?, ?) -> None / (?, ?, ?, ?, ?) -> None / (None, ?, ?, ?, ?) -> None / (None, int, int, ?, ?) -> None'>_crop</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', title='None'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offset_height', title='int'>offset_height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offset_width', title='int'>offset_width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_height', title='?'>crop_height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_width', title='?'>crop_width</a>):
<span class='lineno'>  47</span>   &quot;&quot;&quot;Crops the given image using the provided offsets and sizes.
<span class='lineno'>  48</span> 
<span class='lineno'>  49</span>   Note that the method doesn&#39;t assume we know the input image size but it does
<span class='lineno'>  50</span>   assume we know the input image rank.
<span class='lineno'>  51</span> 
<span class='lineno'>  52</span>   Args:
<span class='lineno'>  53</span>     image: an image of shape [height, width, channels].
<span class='lineno'>  54</span>     offset_height: a scalar tensor indicating the height offset.
<span class='lineno'>  55</span>     offset_width: a scalar tensor indicating the width offset.
<span class='lineno'>  56</span>     crop_height: the height of the cropped image.
<span class='lineno'>  57</span>     crop_width: the width of the cropped image.
<span class='lineno'>  58</span> 
<span class='lineno'>  59</span>   Returns:
<span class='lineno'>  60</span>     the cropped (and resized) image.
<span class='lineno'>  61</span> 
<span class='lineno'>  62</span>   Raises:
<span class='lineno'>  63</span>     InvalidArgumentError: if the rank is not 3 or if the image dimensions are
<span class='lineno'>  64</span>       less than the crop size.
<span class='lineno'>  65</span>   &quot;&quot;&quot;
<span class='lineno'>  66</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.original_shape', title='?'>original_shape</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', title='None'>image</a>)
<span class='lineno'>  67</span> 
<span class='lineno'>  68</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.rank_assertion', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.rank_assertion', title='?'>rank_assertion</a> = tf.Assert(
<span class='lineno'>  69</span>       tf.equal(tf.rank(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', title='None'>image</a>), 3),
<span class='lineno'>  70</span>       [&#39;Rank of image must be equal to 3.&#39;])
<span class='lineno'>  71</span>   with tf.control_dependencies([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.rank_assertion', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.rank_assertion', title='?'>rank_assertion</a>]):
<span class='lineno'>  72</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.cropped_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.cropped_shape', title='?'>cropped_shape</a> = tf.stack([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_height', title='?'>crop_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_width', title='?'>crop_width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.original_shape', title='?'>original_shape</a>[2]])
<span class='lineno'>  73</span> 
<span class='lineno'>  74</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.size_assertion', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.size_assertion', title='?'>size_assertion</a> = tf.Assert(
<span class='lineno'>  75</span>       tf.logical_and(
<span class='lineno'>  76</span>           tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.original_shape', title='?'>original_shape</a>[0], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_height', title='?'>crop_height</a>),
<span class='lineno'>  77</span>           tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.original_shape', title='?'>original_shape</a>[1], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.crop_width', title='?'>crop_width</a>)),
<span class='lineno'>  78</span>       [&#39;Crop size greater than the image size.&#39;])
<span class='lineno'>  79</span> 
<span class='lineno'>  80</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offsets', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offsets', title='?'>offsets</a> = tf.to_int32(tf.stack([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offset_height', title='int'>offset_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offset_width', title='int'>offset_width</a>, 0]))
<span class='lineno'>  81</span> 
<span class='lineno'>  82</span>   # Use tf.slice instead of crop_to_bounding box as it accepts tensors to
<span class='lineno'>  83</span>   # define the crop size.
<span class='lineno'>  84</span>   with tf.control_dependencies([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.size_assertion', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.size_assertion', title='?'>size_assertion</a>]):
<span class='lineno'>  85</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', title='?'>image</a> = tf.slice(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', title='None'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offsets', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.offsets', title='?'>offsets</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.cropped_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.cropped_shape', title='?'>cropped_shape</a>)
<span class='lineno'>  86</span>   return tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.cropped_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop.cropped_shape', title='?'>cropped_shape</a>)
<span class='lineno'>  87</span> 
<span class='lineno'>  88</span> 
<span class='lineno'>  89</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop', title='(?, ?, ?) -> [None] / ([None], ?, ?) -> [None]'>_random_crop</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', title='[None]'>image_list</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_height', title='?'>crop_height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_width', title='?'>crop_width</a>):
<span class='lineno'>  90</span>   &quot;&quot;&quot;Crops the given list of images.
<span class='lineno'>  91</span> 
<span class='lineno'>  92</span>   The function applies the same crop to each image in the list. This can be
<span class='lineno'>  93</span>   effectively applied when there are multiple image inputs of the same
<span class='lineno'>  94</span>   dimension such as:
<span class='lineno'>  95</span> 
<span class='lineno'>  96</span>     image, depths, normals = _random_crop([image, depths, normals], 120, 150)
<span class='lineno'>  97</span> 
<span class='lineno'>  98</span>   Args:
<span class='lineno'>  99</span>     image_list: a list of image tensors of the same dimension but possibly
<span class='lineno'> 100</span>       varying channel.
<span class='lineno'> 101</span>     crop_height: the new height.
<span class='lineno'> 102</span>     crop_width: the new width.
<span class='lineno'> 103</span> 
<span class='lineno'> 104</span>   Returns:
<span class='lineno'> 105</span>     the image_list with cropped images.
<span class='lineno'> 106</span> 
<span class='lineno'> 107</span>   Raises:
<span class='lineno'> 108</span>     ValueError: if there are multiple image inputs provided with different size
<span class='lineno'> 109</span>       or the images are smaller than the crop dimensions.
<span class='lineno'> 110</span>   &quot;&quot;&quot;
<span class='lineno'> 111</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', title='[None]'>image_list</a>:
<span class='lineno'> 112</span>     raise ValueError(&#39;Empty image_list.&#39;)
<span class='lineno'> 113</span> 
<span class='lineno'> 114</span>   # Compute the rank assertions.
<span class='lineno'> 115</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', title='[?]'>rank_assertions</a> = []
<span class='lineno'> 116</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', title='int'>i</a> in range(len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', title='[None]'>image_list</a>)):
<span class='lineno'> 117</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_rank', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_rank', title='?'>image_rank</a> = tf.rank(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', title='[None]'>image_list</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', title='int'>i</a>])
<span class='lineno'> 118</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assert', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assert', title='?'>rank_assert</a> = tf.Assert(
<span class='lineno'> 119</span>         tf.equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_rank', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_rank', title='?'>image_rank</a>, 3),
<span class='lineno'> 120</span>         [&#39;Wrong rank for tensor  %s [expected] [actual]&#39;,
<span class='lineno'> 121</span>          <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', title='[None]'>image_list</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', title='int'>i</a>].name, 3, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_rank', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_rank', title='?'>image_rank</a>])
<span class='lineno'> 122</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', title='[?]'>rank_assertions</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assert', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assert', title='?'>rank_assert</a>)
<span class='lineno'> 123</span> 
<span class='lineno'> 124</span>   with tf.control_dependencies([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', title='[?]'>rank_assertions</a>[0]]):
<span class='lineno'> 125</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_shape', title='?'>image_shape</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', title='[None]'>image_list</a>[0])
<span class='lineno'> 126</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_height', title='?'>image_height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_shape', title='?'>image_shape</a>[0]
<span class='lineno'> 127</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_width', title='?'>image_width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_shape', title='?'>image_shape</a>[1]
<span class='lineno'> 128</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_size_assert', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_size_assert', title='?'>crop_size_assert</a> = tf.Assert(
<span class='lineno'> 129</span>       tf.logical_and(
<span class='lineno'> 130</span>           tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_height', title='?'>image_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_height', title='?'>crop_height</a>),
<span class='lineno'> 131</span>           tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_width', title='?'>image_width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_width', title='?'>crop_width</a>)),
<span class='lineno'> 132</span>       [&#39;Crop size greater than the image size.&#39;])
<span class='lineno'> 133</span> 
<span class='lineno'> 134</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.asserts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.asserts', title='[?]'>asserts</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', title='[?]'>rank_assertions</a>[0], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_size_assert', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_size_assert', title='?'>crop_size_assert</a>]
<span class='lineno'> 135</span> 
<span class='lineno'> 136</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', title='int'>i</a> in range(1, len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', title='[None]'>image_list</a>)):
<span class='lineno'> 137</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', title='[None]'>image_list</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', title='int'>i</a>]
<span class='lineno'> 138</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.asserts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.asserts', title='[?]'>asserts</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', title='[?]'>rank_assertions</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', title='int'>i</a>])
<span class='lineno'> 139</span>     with tf.control_dependencies([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.rank_assertions', title='[?]'>rank_assertions</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.i', title='int'>i</a>]]):
<span class='lineno'> 140</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.shape', title='?'>shape</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', title='None'>image</a>)
<span class='lineno'> 141</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.height', title='?'>height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.shape', title='?'>shape</a>[0]
<span class='lineno'> 142</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.width', title='?'>width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.shape', title='?'>shape</a>[1]
<span class='lineno'> 143</span> 
<span class='lineno'> 144</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.height_assert', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.height_assert', title='?'>height_assert</a> = tf.Assert(
<span class='lineno'> 145</span>         tf.equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_height', title='?'>image_height</a>),
<span class='lineno'> 146</span>         [&#39;Wrong height for tensor %s [expected][actual]&#39;,
<span class='lineno'> 147</span>          <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', title='None'>image</a>.name, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_height', title='?'>image_height</a>])
<span class='lineno'> 148</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.width_assert', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.width_assert', title='?'>width_assert</a> = tf.Assert(
<span class='lineno'> 149</span>         tf.equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.width', title='?'>width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_width', title='?'>image_width</a>),
<span class='lineno'> 150</span>         [&#39;Wrong width for tensor %s [expected][actual]&#39;,
<span class='lineno'> 151</span>          <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', title='None'>image</a>.name, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.width', title='?'>width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_width', title='?'>image_width</a>])
<span class='lineno'> 152</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.asserts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.asserts', title='[?]'>asserts</a>.extend([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.height_assert', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.height_assert', title='?'>height_assert</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.width_assert', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.width_assert', title='?'>width_assert</a>])
<span class='lineno'> 153</span> 
<span class='lineno'> 154</span>   # Create a random bounding box.
<span class='lineno'> 155</span>   #
<span class='lineno'> 156</span>   # Use tf.random_uniform and not numpy.random.rand as doing the former would
<span class='lineno'> 157</span>   # generate random numbers at graph eval time, unlike the latter which
<span class='lineno'> 158</span>   # generates random numbers at graph definition time.
<span class='lineno'> 159</span>   with tf.control_dependencies(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.asserts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.asserts', title='[?]'>asserts</a>):
<span class='lineno'> 160</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.max_offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.max_offset_height', title='?'>max_offset_height</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_height', title='?'>image_height</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_height', title='?'>crop_height</a> + 1, [])
<span class='lineno'> 161</span>   with tf.control_dependencies(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.asserts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.asserts', title='[?]'>asserts</a>):
<span class='lineno'> 162</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.max_offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.max_offset_width', title='?'>max_offset_width</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_width', title='?'>image_width</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_width', title='?'>crop_width</a> + 1, [])
<span class='lineno'> 163</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.offset_height', title='?'>offset_height</a> = tf.random_uniform(
<span class='lineno'> 164</span>       [], maxval=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.max_offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.max_offset_height', title='?'>max_offset_height</a>, dtype=tf.int32)
<span class='lineno'> 165</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.offset_width', title='?'>offset_width</a> = tf.random_uniform(
<span class='lineno'> 166</span>       [], maxval=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.max_offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.max_offset_width', title='?'>max_offset_width</a>, dtype=tf.int32)
<span class='lineno'> 167</span> 
<span class='lineno'> 168</span>   return [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop', title='(?, int, int, ?, ?) -> None / (?, ?, ?, ?, ?) -> None / (None, ?, ?, ?, ?) -> None / (None, int, int, ?, ?) -> None'>_crop</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', title='None'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.offset_height', title='?'>offset_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.offset_width', title='?'>offset_width</a>,
<span class='lineno'> 169</span>                 <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_height', title='?'>crop_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.crop_width', title='?'>crop_width</a>) for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', title='None'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image', title='None'>image</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop.image_list', title='[None]'>image_list</a>]
<span class='lineno'> 170</span> 
<span class='lineno'> 171</span> 
<span class='lineno'> 172</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop', title='(?, ?, ?) -> [None] / ([None], ?, ?) -> [None]'>_central_crop</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_list', title='[None]'>image_list</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_height', title='?'>crop_height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_width', title='?'>crop_width</a>):
<span class='lineno'> 173</span>   &quot;&quot;&quot;Performs central crops of the given image list.
<span class='lineno'> 174</span> 
<span class='lineno'> 175</span>   Args:
<span class='lineno'> 176</span>     image_list: a list of image tensors of the same dimension but possibly
<span class='lineno'> 177</span>       varying channel.
<span class='lineno'> 178</span>     crop_height: the height of the image following the crop.
<span class='lineno'> 179</span>     crop_width: the width of the image following the crop.
<span class='lineno'> 180</span> 
<span class='lineno'> 181</span>   Returns:
<span class='lineno'> 182</span>     the list of cropped images.
<span class='lineno'> 183</span>   &quot;&quot;&quot;
<span class='lineno'> 184</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.outputs', title='[None]'>outputs</a> = []
<span class='lineno'> 185</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image', title='None'>image</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_list', title='[None]'>image_list</a>:
<span class='lineno'> 186</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_height', title='?'>image_height</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image', title='None'>image</a>)[0]
<span class='lineno'> 187</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_width', title='?'>image_width</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image', title='None'>image</a>)[1]
<span class='lineno'> 188</span> 
<span class='lineno'> 189</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.offset_height', title='int'>offset_height</a> = (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_height', title='?'>image_height</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_height', title='?'>crop_height</a>) / 2
<span class='lineno'> 190</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.offset_width', title='int'>offset_width</a> = (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image_width', title='?'>image_width</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_width', title='?'>crop_width</a>) / 2
<span class='lineno'> 191</span> 
<span class='lineno'> 192</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.outputs', title='[None]'>outputs</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._crop', title='(?, int, int, ?, ?) -> None / (?, ?, ?, ?, ?) -> None / (None, ?, ?, ?, ?) -> None / (None, int, int, ?, ?) -> None'>_crop</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.image', title='None'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.offset_height', title='int'>offset_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.offset_width', title='int'>offset_width</a>,
<span class='lineno'> 193</span>                          <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_height', title='?'>crop_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.crop_width', title='?'>crop_width</a>))
<span class='lineno'> 194</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop.outputs', title='[None]'>outputs</a>
<span class='lineno'> 195</span> 
<span class='lineno'> 196</span> 
<span class='lineno'> 197</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction', title='(?, ?) -> None / (?, [float]) -> None'>_mean_image_subtraction</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.means', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.means', title='[float]'>means</a>):
<span class='lineno'> 198</span>   &quot;&quot;&quot;Subtracts the given means from each image channel.
<span class='lineno'> 199</span> 
<span class='lineno'> 200</span>   For example:
<span class='lineno'> 201</span>     means = [123.68, 116.779, 103.939]
<span class='lineno'> 202</span>     image = _mean_image_subtraction(image, means)
<span class='lineno'> 203</span> 
<span class='lineno'> 204</span>   Note that the rank of `image` must be known.
<span class='lineno'> 205</span> 
<span class='lineno'> 206</span>   Args:
<span class='lineno'> 207</span>     image: a tensor of size [height, width, C].
<span class='lineno'> 208</span>     means: a C-vector of values to subtract from each channel.
<span class='lineno'> 209</span> 
<span class='lineno'> 210</span>   Returns:
<span class='lineno'> 211</span>     the centered image.
<span class='lineno'> 212</span> 
<span class='lineno'> 213</span>   Raises:
<span class='lineno'> 214</span>     ValueError: If the rank of `image` is unknown, if `image` has a rank other
<span class='lineno'> 215</span>       than three or if the number of channels in `image` doesn&#39;t match the
<span class='lineno'> 216</span>       number of values in `means`.
<span class='lineno'> 217</span>   &quot;&quot;&quot;
<span class='lineno'> 218</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.image', title='?'>image</a>.get_shape().ndims != 3:
<span class='lineno'> 219</span>     raise ValueError(&#39;Input must be of size [height, width, C&gt;0]&#39;)
<span class='lineno'> 220</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.num_channels', title='?'>num_channels</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.image', title='?'>image</a>.get_shape().as_list()[-1]
<span class='lineno'> 221</span>   if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.means', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.means', title='[float]'>means</a>) != <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.num_channels', title='?'>num_channels</a>:
<span class='lineno'> 222</span>     raise ValueError(&#39;len(means) must match the number of channels&#39;)
<span class='lineno'> 223</span> 
<span class='lineno'> 224</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.channels', title='?'>channels</a> = tf.split(axis=2, num_or_size_splits=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.num_channels', title='?'>num_channels</a>, value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.image', title='?'>image</a>)
<span class='lineno'> 225</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.i', title='int'>i</a> in range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.num_channels', title='?'>num_channels</a>):
<span class='lineno'> 226</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.channels', title='?'>channels</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.i', title='int'>i</a>] -= <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.means', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.means', title='[float]'>means</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.i', title='int'>i</a>]
<span class='lineno'> 227</span>   return tf.concat(axis=2, values=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction.channels', title='?'>channels</a>)
<span class='lineno'> 228</span> 
<span class='lineno'> 229</span> 
<span class='lineno'> 230</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least', title='(?, ?, ?) -> (?, ?)'>_smallest_size_at_least</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', title='?'>height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', title='?'>width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', title='?'>smallest_side</a>):
<span class='lineno'> 231</span>   &quot;&quot;&quot;Computes new shape with the smallest side equal to `smallest_side`.
<span class='lineno'> 232</span> 
<span class='lineno'> 233</span>   Computes new shape with the smallest side equal to `smallest_side` while
<span class='lineno'> 234</span>   preserving the original aspect ratio.
<span class='lineno'> 235</span> 
<span class='lineno'> 236</span>   Args:
<span class='lineno'> 237</span>     height: an int32 scalar tensor indicating the current height.
<span class='lineno'> 238</span>     width: an int32 scalar tensor indicating the current width.
<span class='lineno'> 239</span>     smallest_side: A python integer or scalar `Tensor` indicating the size of
<span class='lineno'> 240</span>       the smallest side after resize.
<span class='lineno'> 241</span> 
<span class='lineno'> 242</span>   Returns:
<span class='lineno'> 243</span>     new_height: an int32 scalar tensor indicating the new height.
<span class='lineno'> 244</span>     new_width: and int32 scalar tensor indicating the new width.
<span class='lineno'> 245</span>   &quot;&quot;&quot;
<span class='lineno'> 246</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', title='?'>smallest_side</a> = tf.convert_to_tensor(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', title='?'>smallest_side</a>, dtype=tf.int32)
<span class='lineno'> 247</span> 
<span class='lineno'> 248</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', title='?'>height</a> = tf.to_float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', title='?'>height</a>)
<span class='lineno'> 249</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', title='?'>width</a> = tf.to_float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', title='?'>width</a>)
<span class='lineno'> 250</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', title='?'>smallest_side</a> = tf.to_float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', title='?'>smallest_side</a>)
<span class='lineno'> 251</span> 
<span class='lineno'> 252</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.scale', title='?'>scale</a> = tf.cond(tf.greater(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', title='?'>width</a>),
<span class='lineno'> 253</span>                   lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', title='?'>smallest_side</a> / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', title='?'>width</a>,
<span class='lineno'> 254</span>                   lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.smallest_side', title='?'>smallest_side</a> / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', title='?'>height</a>)
<span class='lineno'> 255</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.new_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.new_height', title='?'>new_height</a> = tf.to_int32(tf.rint(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.height', title='?'>height</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.scale', title='?'>scale</a>))
<span class='lineno'> 256</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.new_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.new_width', title='?'>new_width</a> = tf.to_int32(tf.rint(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.width', title='?'>width</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.scale', title='?'>scale</a>))
<span class='lineno'> 257</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.new_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.new_height', title='?'>new_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.new_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least.new_width', title='?'>new_width</a>
<span class='lineno'> 258</span> 
<span class='lineno'> 259</span> 
<span class='lineno'> 260</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize', title='(?, int) -> None / (?, ?) -> None'>_aspect_preserving_resize</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.smallest_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.smallest_side', title='int'>smallest_side</a>):
<span class='lineno'> 261</span>   &quot;&quot;&quot;Resize images preserving the original aspect ratio.
<span class='lineno'> 262</span> 
<span class='lineno'> 263</span>   Args:
<span class='lineno'> 264</span>     image: A 3-D image `Tensor`.
<span class='lineno'> 265</span>     smallest_side: A python integer or scalar `Tensor` indicating the size of
<span class='lineno'> 266</span>       the smallest side after resize.
<span class='lineno'> 267</span> 
<span class='lineno'> 268</span>   Returns:
<span class='lineno'> 269</span>     resized_image: A 3-D tensor containing the resized image.
<span class='lineno'> 270</span>   &quot;&quot;&quot;
<span class='lineno'> 271</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.smallest_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.smallest_side', title='?'>smallest_side</a> = tf.convert_to_tensor(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.smallest_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.smallest_side', title='int'>smallest_side</a>, dtype=tf.int32)
<span class='lineno'> 272</span> 
<span class='lineno'> 273</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.shape', title='?'>shape</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.image', title='?'>image</a>)
<span class='lineno'> 274</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.height', title='?'>height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.shape', title='?'>shape</a>[0]
<span class='lineno'> 275</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.width', title='?'>width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.shape', title='?'>shape</a>[1]
<span class='lineno'> 276</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.new_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.new_height', title='?'>new_height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.new_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.new_width', title='?'>new_width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._smallest_size_at_least', title='(?, ?, ?) -> (?, ?)'>_smallest_size_at_least</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.width', title='?'>width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.smallest_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.smallest_side', title='?'>smallest_side</a>)
<span class='lineno'> 277</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.image', title='?'>image</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.image', title='?'>image</a>, 0)
<span class='lineno'> 278</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.resized_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.resized_image', title='?'>resized_image</a> = tf.image.resize_bilinear(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.image', title='?'>image</a>, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.new_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.new_height', title='?'>new_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.new_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.new_width', title='?'>new_width</a>],
<span class='lineno'> 279</span>                                            align_corners=False)
<span class='lineno'> 280</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.resized_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.resized_image', title='?'>resized_image</a> = tf.squeeze(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.resized_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.resized_image', title='?'>resized_image</a>)
<span class='lineno'> 281</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.resized_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.resized_image', title='?'>resized_image</a>.set_shape([None, None, 3])
<span class='lineno'> 282</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.resized_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize.resized_image', title='?'>resized_image</a>
<span class='lineno'> 283</span> 
<span class='lineno'> 284</span> 
<span class='lineno'> 285</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train', title='(?, ?, ?, int, int, bool) -> None'>preprocess_for_train</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='?'>image</a>,
<span class='lineno'> 286</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_height', title='?'>output_height</a>,
<span class='lineno'> 287</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_width', title='?'>output_width</a>,
<span class='lineno'> 288</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side_min', title='int'>resize_side_min</a>=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MIN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MIN', title='int'>_RESIZE_SIDE_MIN</a>,
<span class='lineno'> 289</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side_max', title='int'>resize_side_max</a>=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MAX', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MAX', title='int'>_RESIZE_SIDE_MAX</a>,
<span class='lineno'> 290</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.use_grayscale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.use_grayscale', title='bool'>use_grayscale</a>=False):
<span class='lineno'> 291</span>   &quot;&quot;&quot;Preprocesses the given image for training.
<span class='lineno'> 292</span> 
<span class='lineno'> 293</span>   Note that the actual resizing scale is sampled from
<span class='lineno'> 294</span>     [`resize_size_min`, `resize_size_max`].
<span class='lineno'> 295</span> 
<span class='lineno'> 296</span>   Args:
<span class='lineno'> 297</span>     image: A `Tensor` representing an image of arbitrary size.
<span class='lineno'> 298</span>     output_height: The height of the image after preprocessing.
<span class='lineno'> 299</span>     output_width: The width of the image after preprocessing.
<span class='lineno'> 300</span>     resize_side_min: The lower bound for the smallest side of the image for
<span class='lineno'> 301</span>       aspect-preserving resizing.
<span class='lineno'> 302</span>     resize_side_max: The upper bound for the smallest side of the image for
<span class='lineno'> 303</span>       aspect-preserving resizing.
<span class='lineno'> 304</span>     use_grayscale: Whether to convert the image from RGB to grayscale.
<span class='lineno'> 305</span> 
<span class='lineno'> 306</span>   Returns:
<span class='lineno'> 307</span>     A preprocessed image.
<span class='lineno'> 308</span>   &quot;&quot;&quot;
<span class='lineno'> 309</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side', title='?'>resize_side</a> = tf.random_uniform(
<span class='lineno'> 310</span>       [], minval=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side_min', title='int'>resize_side_min</a>, maxval=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side_max', title='int'>resize_side_max</a>+1, dtype=tf.int32)
<span class='lineno'> 311</span> 
<span class='lineno'> 312</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize', title='(?, int) -> None / (?, ?) -> None'>_aspect_preserving_resize</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.resize_side', title='?'>resize_side</a>)
<span class='lineno'> 313</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._random_crop', title='(?, ?, ?) -> [None] / ([None], ?, ?) -> [None]'>_random_crop</a>([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='None'>image</a>], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_height', title='?'>output_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_width', title='?'>output_width</a>)[0]
<span class='lineno'> 314</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='None'>image</a>.set_shape([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_height', title='?'>output_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.output_width', title='?'>output_width</a>, 3])
<span class='lineno'> 315</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='?'>image</a> = tf.to_float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='None'>image</a>)
<span class='lineno'> 316</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.use_grayscale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.use_grayscale', title='bool'>use_grayscale</a>:
<span class='lineno'> 317</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='?'>image</a> = tf.image.rgb_to_grayscale(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='?'>image</a>)
<span class='lineno'> 318</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='?'>image</a> = tf.image.random_flip_left_right(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='?'>image</a>)
<span class='lineno'> 319</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction', title='(?, ?) -> None / (?, [float]) -> None'>_mean_image_subtraction</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train.image', title='?'>image</a>, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._R_MEAN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._R_MEAN', title='float'>_R_MEAN</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._G_MEAN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._G_MEAN', title='float'>_G_MEAN</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._B_MEAN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._B_MEAN', title='float'>_B_MEAN</a>])
<span class='lineno'> 320</span> 
<span class='lineno'> 321</span> 
<span class='lineno'> 322</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval', title='(?, ?, ?, ?, bool) -> None / (?, ?, ?, int, bool) -> None'>preprocess_for_eval</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', title='?'>image</a>,
<span class='lineno'> 323</span>                         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_height', title='?'>output_height</a>,
<span class='lineno'> 324</span>                         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_width', title='?'>output_width</a>,
<span class='lineno'> 325</span>                         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.resize_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.resize_side', title='int'>resize_side</a>,
<span class='lineno'> 326</span>                         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.use_grayscale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.use_grayscale', title='bool'>use_grayscale</a>=False):
<span class='lineno'> 327</span>   &quot;&quot;&quot;Preprocesses the given image for evaluation.
<span class='lineno'> 328</span> 
<span class='lineno'> 329</span>   Args:
<span class='lineno'> 330</span>     image: A `Tensor` representing an image of arbitrary size.
<span class='lineno'> 331</span>     output_height: The height of the image after preprocessing.
<span class='lineno'> 332</span>     output_width: The width of the image after preprocessing.
<span class='lineno'> 333</span>     resize_side: The smallest side of the image for aspect-preserving resizing.
<span class='lineno'> 334</span>     use_grayscale: Whether to convert the image from RGB to grayscale.
<span class='lineno'> 335</span> 
<span class='lineno'> 336</span>   Returns:
<span class='lineno'> 337</span>     A preprocessed image.
<span class='lineno'> 338</span>   &quot;&quot;&quot;
<span class='lineno'> 339</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._aspect_preserving_resize', title='(?, int) -> None / (?, ?) -> None'>_aspect_preserving_resize</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.resize_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.resize_side', title='int'>resize_side</a>)
<span class='lineno'> 340</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._central_crop', title='(?, ?, ?) -> [None] / ([None], ?, ?) -> [None]'>_central_crop</a>([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', title='None'>image</a>], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_height', title='?'>output_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_width', title='?'>output_width</a>)[0]
<span class='lineno'> 341</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', title='None'>image</a>.set_shape([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_height', title='?'>output_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.output_width', title='?'>output_width</a>, 3])
<span class='lineno'> 342</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', title='?'>image</a> = tf.to_float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', title='None'>image</a>)
<span class='lineno'> 343</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.use_grayscale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.use_grayscale', title='bool'>use_grayscale</a>:
<span class='lineno'> 344</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', title='?'>image</a> = tf.image.rgb_to_grayscale(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', title='?'>image</a>)
<span class='lineno'> 345</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._mean_image_subtraction', title='(?, ?) -> None / (?, [float]) -> None'>_mean_image_subtraction</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval.image', title='?'>image</a>, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._R_MEAN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._R_MEAN', title='float'>_R_MEAN</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._G_MEAN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._G_MEAN', title='float'>_G_MEAN</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._B_MEAN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._B_MEAN', title='float'>_B_MEAN</a>])
<span class='lineno'> 346</span> 
<span class='lineno'> 347</span> 
<span class='lineno'> 348</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image', title='(?, ?, ?, bool, int, int, bool) -> None'>preprocess_image</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.image', title='?'>image</a>,
<span class='lineno'> 349</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_height', title='?'>output_height</a>,
<span class='lineno'> 350</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_width', title='?'>output_width</a>,
<span class='lineno'> 351</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.is_training', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.is_training', title='bool'>is_training</a>=False,
<span class='lineno'> 352</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.resize_side_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.resize_side_min', title='int'>resize_side_min</a>=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MIN', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MIN', title='int'>_RESIZE_SIDE_MIN</a>,
<span class='lineno'> 353</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.resize_side_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.resize_side_max', title='int'>resize_side_max</a>=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MAX', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing._RESIZE_SIDE_MAX', title='int'>_RESIZE_SIDE_MAX</a>,
<span class='lineno'> 354</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.use_grayscale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.use_grayscale', title='bool'>use_grayscale</a>=False):
<span class='lineno'> 355</span>   &quot;&quot;&quot;Preprocesses the given image.
<span class='lineno'> 356</span> 
<span class='lineno'> 357</span>   Args:
<span class='lineno'> 358</span>     image: A `Tensor` representing an image of arbitrary size.
<span class='lineno'> 359</span>     output_height: The height of the image after preprocessing.
<span class='lineno'> 360</span>     output_width: The width of the image after preprocessing.
<span class='lineno'> 361</span>     is_training: `True` if we&#39;re preprocessing the image for training and
<span class='lineno'> 362</span>       `False` otherwise.
<span class='lineno'> 363</span>     resize_side_min: The lower bound for the smallest side of the image for
<span class='lineno'> 364</span>       aspect-preserving resizing. If `is_training` is `False`, then this value
<span class='lineno'> 365</span>       is used for rescaling.
<span class='lineno'> 366</span>     resize_side_max: The upper bound for the smallest side of the image for
<span class='lineno'> 367</span>       aspect-preserving resizing. If `is_training` is `False`, this value is
<span class='lineno'> 368</span>       ignored. Otherwise, the resize side is sampled from
<span class='lineno'> 369</span>         [resize_size_min, resize_size_max].
<span class='lineno'> 370</span>     use_grayscale: Whether to convert the image from RGB to grayscale.
<span class='lineno'> 371</span> 
<span class='lineno'> 372</span>   Returns:
<span class='lineno'> 373</span>     A preprocessed image.
<span class='lineno'> 374</span>   &quot;&quot;&quot;
<span class='lineno'> 375</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.is_training', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.is_training', title='bool'>is_training</a>:
<span class='lineno'> 376</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_train', title='(?, ?, ?, int, int, bool) -> None'>preprocess_for_train</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_height', title='?'>output_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_width', title='?'>output_width</a>,
<span class='lineno'> 377</span>                                 <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.resize_side_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.resize_side_min', title='int'>resize_side_min</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.resize_side_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.resize_side_max', title='int'>resize_side_max</a>,
<span class='lineno'> 378</span>                                 <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.use_grayscale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.use_grayscale', title='bool'>use_grayscale</a>)
<span class='lineno'> 379</span>   else:
<span class='lineno'> 380</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_for_eval', title='(?, ?, ?, ?, bool) -> None / (?, ?, ?, int, bool) -> None'>preprocess_for_eval</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_height', title='?'>output_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.output_width', title='?'>output_width</a>,
<span class='lineno'> 381</span>                                <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.resize_side_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.resize_side_min', title='int'>resize_side_min</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.use_grayscale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.preprocessing.vgg_preprocessing.preprocess_image.use_grayscale', title='bool'>use_grayscale</a>)
</pre></td></tr></table></body></html>