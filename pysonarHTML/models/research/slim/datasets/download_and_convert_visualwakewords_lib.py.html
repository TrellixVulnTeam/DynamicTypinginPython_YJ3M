<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/slim/datasets/download_and_convert_visualwakewords_lib.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.FLAGS', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.FLAGS'>FLAGS</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset'>download_coco_dataset</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file'>create_labels_file</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations'>create_visual_wakeword_annotations</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations'>_filter_annotations</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset'>create_tf_record_for_visualwakewords_dataset</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example'>_create_tf_example</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2019 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> r&quot;&quot;&quot;Helper functions to generate the Visual WakeWords dataset.
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span>     It filters raw COCO annotations file to Visual WakeWords Dataset
<span class='lineno'>  18</span>     annotations. The resulting annotations and COCO images are then converted
<span class='lineno'>  19</span>     to TF records.
<span class='lineno'>  20</span>     See download_and_convert_visualwakewords.py for the sample usage.
<span class='lineno'>  21</span> &quot;&quot;&quot;
<span class='lineno'>  22</span> from __future__ import absolute_import
<span class='lineno'>  23</span> from __future__ import division
<span class='lineno'>  24</span> from __future__ import print_function
<span class='lineno'>  25</span> 
<span class='lineno'>  26</span> import collections
<span class='lineno'>  27</span> import hashlib
<span class='lineno'>  28</span> import io
<span class='lineno'>  29</span> import json
<span class='lineno'>  30</span> import os
<span class='lineno'>  31</span> import contextlib2
<span class='lineno'>  32</span> 
<span class='lineno'>  33</span> import PIL.Image
<span class='lineno'>  34</span> 
<span class='lineno'>  35</span> import six
<span class='lineno'>  36</span> import tensorflow.compat.v1 as tf
<span class='lineno'>  37</span> 
<span class='lineno'>  38</span> from datasets import dataset_utils
<span class='lineno'>  39</span> 
<span class='lineno'>  40</span> tf.logging.set_verbosity(tf.logging.INFO)
<span class='lineno'>  41</span> 
<span class='lineno'>  42</span> tf.app.flags.DEFINE_string(
<span class='lineno'>  43</span>     &#39;coco_train_url&#39;,
<span class='lineno'>  44</span>     &#39;http://images.cocodataset.org/zips/train2014.zip&#39;,
<span class='lineno'>  45</span>     &#39;Link to zip file containing coco training data&#39;)
<span class='lineno'>  46</span> tf.app.flags.DEFINE_string(
<span class='lineno'>  47</span>     &#39;coco_validation_url&#39;,
<span class='lineno'>  48</span>     &#39;http://images.cocodataset.org/zips/val2014.zip&#39;,
<span class='lineno'>  49</span>     &#39;Link to zip file containing coco validation data&#39;)
<span class='lineno'>  50</span> tf.app.flags.DEFINE_string(
<span class='lineno'>  51</span>     &#39;coco_annotations_url&#39;,
<span class='lineno'>  52</span>     &#39;http://images.cocodataset.org/annotations/annotations_trainval2014.zip&#39;,
<span class='lineno'>  53</span>     &#39;Link to zip file containing coco annotation data&#39;)
<span class='lineno'>  54</span> 
<span class='lineno'>  55</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.FLAGS', title='?'>FLAGS</a> = tf.app.flags.FLAGS
<span class='lineno'>  56</span> 
<span class='lineno'>  57</span> 
<span class='lineno'>  58</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset', title='? -> None'>download_coco_dataset</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset.dataset_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset.dataset_dir', title='?'>dataset_dir</a>):
<span class='lineno'>  59</span>   &quot;&quot;&quot;Download the coco dataset.
<span class='lineno'>  60</span> 
<span class='lineno'>  61</span>   Args:
<span class='lineno'>  62</span>     dataset_dir: Path where coco dataset should be downloaded.
<span class='lineno'>  63</span>   &quot;&quot;&quot;
<span class='lineno'>  64</span>   dataset_utils.download_and_uncompress_zipfile(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.FLAGS', title='?'>FLAGS</a>.coco_train_url,
<span class='lineno'>  65</span>                                                 <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset.dataset_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset.dataset_dir', title='?'>dataset_dir</a>)
<span class='lineno'>  66</span>   dataset_utils.download_and_uncompress_zipfile(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.FLAGS', title='?'>FLAGS</a>.coco_validation_url,
<span class='lineno'>  67</span>                                                 <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset.dataset_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset.dataset_dir', title='?'>dataset_dir</a>)
<span class='lineno'>  68</span>   dataset_utils.download_and_uncompress_zipfile(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.FLAGS', title='?'>FLAGS</a>.coco_annotations_url,
<span class='lineno'>  69</span>                                                 <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset.dataset_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.download_coco_dataset.dataset_dir', title='?'>dataset_dir</a>)
<span class='lineno'>  70</span> 
<span class='lineno'>  71</span> 
<span class='lineno'>  72</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file', title='(?, ?) -> None'>create_labels_file</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.foreground_class_of_interest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.foreground_class_of_interest', title='?'>foreground_class_of_interest</a>,
<span class='lineno'>  73</span>                        <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.visualwakewords_labels_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.visualwakewords_labels_file', title='?'>visualwakewords_labels_file</a>):
<span class='lineno'>  74</span>   &quot;&quot;&quot;Generate visualwakewords labels file.
<span class='lineno'>  75</span> 
<span class='lineno'>  76</span>   Args:
<span class='lineno'>  77</span>     foreground_class_of_interest: category from COCO dataset that is filtered by
<span class='lineno'>  78</span>       the visualwakewords dataset
<span class='lineno'>  79</span>     visualwakewords_labels_file: output visualwakewords label file
<span class='lineno'>  80</span>   &quot;&quot;&quot;
<span class='lineno'>  81</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.labels_to_class_names', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.labels_to_class_names', title='dict'>labels_to_class_names</a> = {0: &#39;background&#39;, 1: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.foreground_class_of_interest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.foreground_class_of_interest', title='?'>foreground_class_of_interest</a>}
<span class='lineno'>  82</span>   with open(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.visualwakewords_labels_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.visualwakewords_labels_file', title='?'>visualwakewords_labels_file</a>, &#39;w&#39;) as <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.fp', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.fp', title='file'>fp</a>:
<span class='lineno'>  83</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.label', title='?'>label</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.labels_to_class_names', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.labels_to_class_names', title='dict'>labels_to_class_names</a>:
<span class='lineno'>  84</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.fp', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.fp', title='file'>fp</a>.write(str(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.label', title='?'>label</a>) + &#39;:&#39; + str(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.labels_to_class_names', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.labels_to_class_names', title='dict'>labels_to_class_names</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_labels_file.label', title='?'>label</a>]) + &#39;\n&#39;)
<span class='lineno'>  85</span> 
<span class='lineno'>  86</span> 
<span class='lineno'>  87</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations', title='(?, ?, ?, ?) -> None'>create_visual_wakeword_annotations</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_file', title='?'>annotations_file</a>,
<span class='lineno'>  88</span>                                        <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.visualwakewords_annotations_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.visualwakewords_annotations_file', title='?'>visualwakewords_annotations_file</a>,
<span class='lineno'>  89</span>                                        <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.small_object_area_threshold', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.small_object_area_threshold', title='?'>small_object_area_threshold</a>,
<span class='lineno'>  90</span>                                        <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.foreground_class_of_interest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.foreground_class_of_interest', title='?'>foreground_class_of_interest</a>):
<span class='lineno'>  91</span>   &quot;&quot;&quot;Generate visual wakewords annotations file.
<span class='lineno'>  92</span> 
<span class='lineno'>  93</span>   Loads COCO annotation json files to generate visualwakewords annotations file.
<span class='lineno'>  94</span> 
<span class='lineno'>  95</span>   Args:
<span class='lineno'>  96</span>     annotations_file: JSON file containing COCO bounding box annotations
<span class='lineno'>  97</span>     visualwakewords_annotations_file: path to output annotations file
<span class='lineno'>  98</span>     small_object_area_threshold: threshold on fraction of image area below which
<span class='lineno'>  99</span>       small object bounding boxes are filtered
<span class='lineno'> 100</span>     foreground_class_of_interest: category from COCO dataset that is filtered by
<span class='lineno'> 101</span>       the visual wakewords dataset
<span class='lineno'> 102</span>   &quot;&quot;&quot;
<span class='lineno'> 103</span>   # default object of interest is person
<span class='lineno'> 104</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.foreground_class_of_interest_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.foreground_class_of_interest_id', title='int'>foreground_class_of_interest_id</a> = 1
<span class='lineno'> 105</span>   with tf.gfile.GFile(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_file', title='?'>annotations_file</a>, &#39;r&#39;) as <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.fid', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.fid', title='?'>fid</a>:
<span class='lineno'> 106</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.groundtruth_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.groundtruth_data', title='?'>groundtruth_data</a> = json.load(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.fid', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.fid', title='?'>fid</a>)
<span class='lineno'> 107</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.images', title='?'>images</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.groundtruth_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.groundtruth_data', title='?'>groundtruth_data</a>[&#39;images&#39;]
<span class='lineno'> 108</span>     # Create category index
<span class='lineno'> 109</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category_index', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category_index', title='dict'>category_index</a> = {}
<span class='lineno'> 110</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category', title='?'>category</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.groundtruth_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.groundtruth_data', title='?'>groundtruth_data</a>[&#39;categories&#39;]:
<span class='lineno'> 111</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category', title='?'>category</a>[&#39;name&#39;] == <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.foreground_class_of_interest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.foreground_class_of_interest', title='?'>foreground_class_of_interest</a>:
<span class='lineno'> 112</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.foreground_class_of_interest_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.foreground_class_of_interest_id', title='?'>foreground_class_of_interest_id</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category', title='?'>category</a>[&#39;id&#39;]
<span class='lineno'> 113</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category_index', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category_index', title='dict'>category_index</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category', title='?'>category</a>[&#39;id&#39;]] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category', title='?'>category</a>
<span class='lineno'> 114</span>     # Create annotations index, a map of image_id to it&#39;s annotations
<span class='lineno'> 115</span>     tf.logging.info(&#39;Building annotations index...&#39;)
<span class='lineno'> 116</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index', title='defaultdict'>annotations_index</a> = collections.defaultdict(
<span class='lineno'> 117</span>         lambda: collections.defaultdict(list))
<span class='lineno'> 118</span>     # structure is { &quot;image_id&quot;: {&quot;objects&quot; : [list of the image annotations]}}
<span class='lineno'> 119</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotation', title='?'>annotation</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.groundtruth_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.groundtruth_data', title='?'>groundtruth_data</a>[&#39;annotations&#39;]:
<span class='lineno'> 120</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index', title='defaultdict'>annotations_index</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotation', title='?'>annotation</a>[&#39;image_id&#39;]][&#39;objects&#39;].append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotation', title='?'>annotation</a>)
<span class='lineno'> 121</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.missing_annotation_count', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.missing_annotation_count', title='int'>missing_annotation_count</a> = len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.images', title='?'>images</a>) - len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index', title='defaultdict'>annotations_index</a>)
<span class='lineno'> 122</span>     tf.logging.info(&#39;%d images are missing annotations.&#39;,
<span class='lineno'> 123</span>                     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.missing_annotation_count', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.missing_annotation_count', title='int'>missing_annotation_count</a>)
<span class='lineno'> 124</span>     # Create filtered annotations index
<span class='lineno'> 125</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index_filtered', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index_filtered', title='dict'>annotations_index_filtered</a> = {}
<span class='lineno'> 126</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.idx', title='?'>idx</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.image', title='?'>image</a> in enumerate(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.images', title='?'>images</a>):
<span class='lineno'> 127</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.idx', title='?'>idx</a> % 100 == 0:
<span class='lineno'> 128</span>         tf.logging.info(&#39;On image %d of %d&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.idx', title='?'>idx</a>, len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.images', title='?'>images</a>))
<span class='lineno'> 129</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations', title='?'>annotations</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index', title='defaultdict'>annotations_index</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.image', title='?'>image</a>[&#39;id&#39;]]
<span class='lineno'> 130</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_filtered', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_filtered', title='dict'>annotations_filtered</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations', title='(?, ?, ?, ?) -> dict / (?, ?, ?, int) -> dict'>_filter_annotations</a>(
<span class='lineno'> 131</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations', title='?'>annotations</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.small_object_area_threshold', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.small_object_area_threshold', title='?'>small_object_area_threshold</a>,
<span class='lineno'> 132</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.foreground_class_of_interest_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.foreground_class_of_interest_id', title='int'>foreground_class_of_interest_id</a>)
<span class='lineno'> 133</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index_filtered', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index_filtered', title='dict'>annotations_index_filtered</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.image', title='?'>image</a>[&#39;id&#39;]] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_filtered', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_filtered', title='dict'>annotations_filtered</a>
<span class='lineno'> 134</span> 
<span class='lineno'> 135</span>     with open(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.visualwakewords_annotations_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.visualwakewords_annotations_file', title='?'>visualwakewords_annotations_file</a>, &#39;w&#39;) as <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.fp', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.fp', title='file'>fp</a>:
<span class='lineno'> 136</span>       json.dump(
<span class='lineno'> 137</span>           {
<span class='lineno'> 138</span>               &#39;images&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.images', title='?'>images</a>,
<span class='lineno'> 139</span>               &#39;annotations&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index_filtered', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.annotations_index_filtered', title='dict'>annotations_index_filtered</a>,
<span class='lineno'> 140</span>               &#39;categories&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category_index', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.category_index', title='dict'>category_index</a>
<span class='lineno'> 141</span>           }, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.fp', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations.fp', title='file'>fp</a>)
<span class='lineno'> 142</span> 
<span class='lineno'> 143</span> 
<span class='lineno'> 144</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations', title='(?, ?, ?, ?) -> dict / (?, ?, ?, int) -> dict'>_filter_annotations</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotations', title='?'>annotations</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.small_object_area_threshold', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.small_object_area_threshold', title='?'>small_object_area_threshold</a>,
<span class='lineno'> 145</span>                         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.foreground_class_of_interest_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.foreground_class_of_interest_id', title='int'>foreground_class_of_interest_id</a>):
<span class='lineno'> 146</span>   &quot;&quot;&quot;Filters COCO annotations to visual wakewords annotations.
<span class='lineno'> 147</span> 
<span class='lineno'> 148</span>   Args:
<span class='lineno'> 149</span>     annotations: dicts with keys: {
<span class='lineno'> 150</span>       u&#39;objects&#39;: [{u&#39;id&#39;, u&#39;image_id&#39;, u&#39;category_id&#39;, u&#39;segmentation&#39;,
<span class='lineno'> 151</span>                   u&#39;area&#39;, u&#39;bbox&#39; : [x,y,width,height], u&#39;iscrowd&#39;}] } Notice
<span class='lineno'> 152</span>                     that bounding box coordinates in the official COCO dataset
<span class='lineno'> 153</span>                     are given as [x, y, width, height] tuples using absolute
<span class='lineno'> 154</span>                     coordinates where x, y represent the top-left (0-indexed)
<span class='lineno'> 155</span>                     corner.
<span class='lineno'> 156</span>     image: dict with keys: [u&#39;license&#39;, u&#39;file_name&#39;, u&#39;coco_url&#39;, u&#39;height&#39;,
<span class='lineno'> 157</span>       u&#39;width&#39;, u&#39;date_captured&#39;, u&#39;flickr_url&#39;, u&#39;id&#39;]
<span class='lineno'> 158</span>     small_object_area_threshold: threshold on fraction of image area below which
<span class='lineno'> 159</span>       small objects are filtered
<span class='lineno'> 160</span>     foreground_class_of_interest_id: category of COCO dataset which visual
<span class='lineno'> 161</span>       wakewords filters
<span class='lineno'> 162</span> 
<span class='lineno'> 163</span>   Returns:
<span class='lineno'> 164</span>     annotations_filtered: dict with keys: {
<span class='lineno'> 165</span>       u&#39;objects&#39;: [{&quot;area&quot;, &quot;bbox&quot; : [x,y,width,height]}],
<span class='lineno'> 166</span>       u&#39;label&#39;,
<span class='lineno'> 167</span>       }
<span class='lineno'> 168</span>   &quot;&quot;&quot;
<span class='lineno'> 169</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.objects', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.objects', title='[dict]'>objects</a> = []
<span class='lineno'> 170</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.image_area', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.image_area', title='?'>image_area</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.image', title='?'>image</a>[&#39;height&#39;] * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.image', title='?'>image</a>[&#39;width&#39;]
<span class='lineno'> 171</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotation', title='?'>annotation</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotations', title='?'>annotations</a>[&#39;objects&#39;]:
<span class='lineno'> 172</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.normalized_object_area', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.normalized_object_area', title='?'>normalized_object_area</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotation', title='?'>annotation</a>[&#39;area&#39;] / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.image_area', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.image_area', title='?'>image_area</a>
<span class='lineno'> 173</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.category_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.category_id', title='int'>category_id</a> = int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotation', title='?'>annotation</a>[&#39;category_id&#39;])
<span class='lineno'> 174</span>     # Filter valid bounding boxes
<span class='lineno'> 175</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.category_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.category_id', title='int'>category_id</a> == <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.foreground_class_of_interest_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.foreground_class_of_interest_id', title='int'>foreground_class_of_interest_id</a> and \
<span class='lineno'> 176</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.normalized_object_area', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.normalized_object_area', title='?'>normalized_object_area</a> &gt; <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.small_object_area_threshold', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.small_object_area_threshold', title='?'>small_object_area_threshold</a>:
<span class='lineno'> 177</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.objects', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.objects', title='[dict]'>objects</a>.append({
<span class='lineno'> 178</span>           u&#39;area&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotation', title='?'>annotation</a>[&#39;area&#39;],
<span class='lineno'> 179</span>           u&#39;bbox&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.annotation', title='?'>annotation</a>[&#39;bbox&#39;],
<span class='lineno'> 180</span>       })
<span class='lineno'> 181</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.label', title='int'>label</a> = 1 if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.objects', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.objects', title='[dict]'>objects</a> else 0
<span class='lineno'> 182</span>   return {
<span class='lineno'> 183</span>       &#39;objects&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.objects', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.objects', title='[dict]'>objects</a>,
<span class='lineno'> 184</span>       &#39;label&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._filter_annotations.label', title='int'>label</a>,
<span class='lineno'> 185</span>   }
<span class='lineno'> 186</span> 
<span class='lineno'> 187</span> 
<span class='lineno'> 188</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset', title='(?, ?, ?, ?) -> None'>create_tf_record_for_visualwakewords_dataset</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_file', title='?'>annotations_file</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.image_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.image_dir', title='?'>image_dir</a>,
<span class='lineno'> 189</span>                                                  <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.output_path', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.output_path', title='?'>output_path</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.num_shards', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.num_shards', title='?'>num_shards</a>):
<span class='lineno'> 190</span>   &quot;&quot;&quot;Loads Visual WakeWords annotations/images and converts to tf.Record format.
<span class='lineno'> 191</span> 
<span class='lineno'> 192</span>   Args:
<span class='lineno'> 193</span>     annotations_file: JSON file containing bounding box annotations.
<span class='lineno'> 194</span>     image_dir: Directory containing the image files.
<span class='lineno'> 195</span>     output_path: Path to output tf.Record file.
<span class='lineno'> 196</span>     num_shards: number of output file shards.
<span class='lineno'> 197</span>   &quot;&quot;&quot;
<span class='lineno'> 198</span>   with contextlib2.ExitStack() as <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.tf_record_close_stack', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.tf_record_close_stack', title='?'>tf_record_close_stack</a>, \
<span class='lineno'> 199</span>       tf.gfile.GFile(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_file', title='?'>annotations_file</a>, &#39;r&#39;) as <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.fid', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.fid', title='?'>fid</a>:
<span class='lineno'> 200</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.output_tfrecords', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.output_tfrecords', title='?'>output_tfrecords</a> = dataset_utils.open_sharded_output_tfrecords(
<span class='lineno'> 201</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.tf_record_close_stack', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.tf_record_close_stack', title='?'>tf_record_close_stack</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.output_path', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.output_path', title='?'>output_path</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.num_shards', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.num_shards', title='?'>num_shards</a>)
<span class='lineno'> 202</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.groundtruth_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.groundtruth_data', title='?'>groundtruth_data</a> = json.load(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.fid', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.fid', title='?'>fid</a>)
<span class='lineno'> 203</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.images', title='?'>images</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.groundtruth_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.groundtruth_data', title='?'>groundtruth_data</a>[&#39;images&#39;]
<span class='lineno'> 204</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_index', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_index', title='?'>annotations_index</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.groundtruth_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.groundtruth_data', title='?'>groundtruth_data</a>[&#39;annotations&#39;]
<span class='lineno'> 205</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_index', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_index', title='dict'>annotations_index</a> = {int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.k', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.k', title='?'>k</a>): <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.v', title='?'>v</a> for <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.k', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.k', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.k', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.k', title='?'>k</a></a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.v', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.v', title='?'>v</a></a> in six.iteritems(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_index', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_index', title='?'>annotations_index</a>)}
<span class='lineno'> 206</span>     # convert &#39;unicode&#39; key to &#39;int&#39; key after we parse the json file
<span class='lineno'> 207</span> 
<span class='lineno'> 208</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.idx', title='?'>idx</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.image', title='?'>image</a> in enumerate(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.images', title='?'>images</a>):
<span class='lineno'> 209</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.idx', title='?'>idx</a> % 100 == 0:
<span class='lineno'> 210</span>         tf.logging.info(&#39;On image %d of %d&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.idx', title='?'>idx</a>, len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.images', title='?'>images</a>))
<span class='lineno'> 211</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations', title='?'>annotations</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_index', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations_index', title='dict'>annotations_index</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.image', title='?'>image</a>[&#39;id&#39;]]
<span class='lineno'> 212</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.tf_example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.tf_example', title='None'>tf_example</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example', title='(?, ?, ?) -> None'>_create_tf_example</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.annotations', title='?'>annotations</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.image_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.image_dir', title='?'>image_dir</a>)
<span class='lineno'> 213</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.shard_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.shard_idx', title='?'>shard_idx</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.idx', title='?'>idx</a> % <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.num_shards', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.num_shards', title='?'>num_shards</a>
<span class='lineno'> 214</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.output_tfrecords', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.output_tfrecords', title='?'>output_tfrecords</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.shard_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.shard_idx', title='?'>shard_idx</a>].write(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.tf_example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset.tf_example', title='None'>tf_example</a>.SerializeToString())
<span class='lineno'> 215</span> 
<span class='lineno'> 216</span> 
<span class='lineno'> 217</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example', title='(?, ?, ?) -> None'>_create_tf_example</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.annotations', title='?'>annotations</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_dir', title='?'>image_dir</a>):
<span class='lineno'> 218</span>   &quot;&quot;&quot;Converts image and annotations to a tf.Example proto.
<span class='lineno'> 219</span> 
<span class='lineno'> 220</span>   Args:
<span class='lineno'> 221</span>     image: dict with keys: [u&#39;license&#39;, u&#39;file_name&#39;, u&#39;coco_url&#39;, u&#39;height&#39;,
<span class='lineno'> 222</span>       u&#39;width&#39;, u&#39;date_captured&#39;, u&#39;flickr_url&#39;, u&#39;id&#39;]
<span class='lineno'> 223</span>     annotations: dict with objects (a list of image annotations) and a label.
<span class='lineno'> 224</span>       {u&#39;objects&#39;:[{&quot;area&quot;, &quot;bbox&quot; : [x,y,width,height}], u&#39;label&#39;}. Notice
<span class='lineno'> 225</span>       that bounding box coordinates in the COCO dataset are given as[x, y,
<span class='lineno'> 226</span>       width, height] tuples using absolute coordinates where x, y represent
<span class='lineno'> 227</span>       the top-left (0-indexed) corner. This function also converts to the format
<span class='lineno'> 228</span>       that can be used by the Tensorflow Object Detection API (which is [ymin,
<span class='lineno'> 229</span>       xmin, ymax, xmax] with coordinates normalized relative to image size).
<span class='lineno'> 230</span>     image_dir: directory containing the image files.
<span class='lineno'> 231</span>   Returns:
<span class='lineno'> 232</span>     tf_example: The converted tf.Example
<span class='lineno'> 233</span> 
<span class='lineno'> 234</span>   Raises:
<span class='lineno'> 235</span>     ValueError: if the image pointed to by data[&#39;filename&#39;] is not a valid JPEG
<span class='lineno'> 236</span>   &quot;&quot;&quot;
<span class='lineno'> 237</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_height', title='?'>image_height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', title='?'>image</a>[&#39;height&#39;]
<span class='lineno'> 238</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_width', title='?'>image_width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', title='?'>image</a>[&#39;width&#39;]
<span class='lineno'> 239</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.filename', title='?'>filename</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', title='?'>image</a>[&#39;file_name&#39;]
<span class='lineno'> 240</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_id', title='?'>image_id</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', title='?'>image</a>[&#39;id&#39;]
<span class='lineno'> 241</span> 
<span class='lineno'> 242</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.full_path', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.full_path', title='str'>full_path</a> = os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_dir', title='?'>image_dir</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.filename', title='?'>filename</a>)
<span class='lineno'> 243</span>   with tf.gfile.GFile(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.full_path', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.full_path', title='str'>full_path</a>, &#39;rb&#39;) as <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.fid', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.fid', title='?'>fid</a>:
<span class='lineno'> 244</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg', title='?'>encoded_jpg</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.fid', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.fid', title='?'>fid</a>.read()
<span class='lineno'> 245</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg_io', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg_io', title='?'>encoded_jpg_io</a> = io.BytesIO(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg', title='?'>encoded_jpg</a>)
<span class='lineno'> 246</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image', title='?'>image</a> = PIL.Image.open(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg_io', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg_io', title='?'>encoded_jpg_io</a>)
<span class='lineno'> 247</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.key', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.key', title='?'>key</a> = hashlib.sha256(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg', title='?'>encoded_jpg</a>).hexdigest()
<span class='lineno'> 248</span> 
<span class='lineno'> 249</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmin', title='[float]'>xmin</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmax', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmax', title='[float]'>xmax</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymin', title='[float]'>ymin</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymax', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymax', title='[float]'>ymax</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.area', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.area', title='[?]'>area</a> = [], [], [], [], []
<span class='lineno'> 250</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.obj', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.obj', title='?'>obj</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.annotations', title='?'>annotations</a>[&#39;objects&#39;]:
<span class='lineno'> 251</span>     (<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.x', title='?'>x</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.y', title='?'>y</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.width', title='?'>width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.height', title='?'>height</a>) = tuple(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.obj', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.obj', title='?'>obj</a>[&#39;bbox&#39;])
<span class='lineno'> 252</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmin', title='[float]'>xmin</a>.append(float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.x', title='?'>x</a>) / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_width', title='?'>image_width</a>)
<span class='lineno'> 253</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmax', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmax', title='[float]'>xmax</a>.append(float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.x', title='?'>x</a> + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.width', title='?'>width</a>) / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_width', title='?'>image_width</a>)
<span class='lineno'> 254</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymin', title='[float]'>ymin</a>.append(float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.y', title='?'>y</a>) / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_height', title='?'>image_height</a>)
<span class='lineno'> 255</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymax', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymax', title='[float]'>ymax</a>.append(float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.y', title='?'>y</a> + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.height', title='?'>height</a>) / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_height', title='?'>image_height</a>)
<span class='lineno'> 256</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.area', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.area', title='[?]'>area</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.obj', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.obj', title='?'>obj</a>[&#39;area&#39;])
<span class='lineno'> 257</span> 
<span class='lineno'> 258</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.feature_dict', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.feature_dict', title='dict'>feature_dict</a> = {
<span class='lineno'> 259</span>       &#39;image/height&#39;:
<span class='lineno'> 260</span>           dataset_utils.int64_feature(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_height', title='?'>image_height</a>),
<span class='lineno'> 261</span>       &#39;image/width&#39;:
<span class='lineno'> 262</span>           dataset_utils.int64_feature(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_width', title='?'>image_width</a>),
<span class='lineno'> 263</span>       &#39;image/filename&#39;:
<span class='lineno'> 264</span>           dataset_utils.bytes_feature(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.filename', title='?'>filename</a>.encode(&#39;utf8&#39;)),
<span class='lineno'> 265</span>       &#39;image/source_id&#39;:
<span class='lineno'> 266</span>           dataset_utils.bytes_feature(str(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.image_id', title='?'>image_id</a>).encode(&#39;utf8&#39;)),
<span class='lineno'> 267</span>       &#39;image/key/sha256&#39;:
<span class='lineno'> 268</span>           dataset_utils.bytes_feature(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.key', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.key', title='?'>key</a>.encode(&#39;utf8&#39;)),
<span class='lineno'> 269</span>       &#39;image/encoded&#39;:
<span class='lineno'> 270</span>           dataset_utils.bytes_feature(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.encoded_jpg', title='?'>encoded_jpg</a>),
<span class='lineno'> 271</span>       &#39;image/format&#39;:
<span class='lineno'> 272</span>           dataset_utils.bytes_feature(&#39;jpeg&#39;.encode(&#39;utf8&#39;)),
<span class='lineno'> 273</span>       &#39;image/class/label&#39;:
<span class='lineno'> 274</span>           dataset_utils.int64_feature(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.annotations', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.annotations', title='?'>annotations</a>[&#39;label&#39;]),
<span class='lineno'> 275</span>       &#39;image/object/bbox/xmin&#39;:
<span class='lineno'> 276</span>           dataset_utils.float_list_feature(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmin', title='[float]'>xmin</a>),
<span class='lineno'> 277</span>       &#39;image/object/bbox/xmax&#39;:
<span class='lineno'> 278</span>           dataset_utils.float_list_feature(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmax', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.xmax', title='[float]'>xmax</a>),
<span class='lineno'> 279</span>       &#39;image/object/bbox/ymin&#39;:
<span class='lineno'> 280</span>           dataset_utils.float_list_feature(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymin', title='[float]'>ymin</a>),
<span class='lineno'> 281</span>       &#39;image/object/bbox/ymax&#39;:
<span class='lineno'> 282</span>           dataset_utils.float_list_feature(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymax', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.ymax', title='[float]'>ymax</a>),
<span class='lineno'> 283</span>       &#39;image/object/area&#39;:
<span class='lineno'> 284</span>           dataset_utils.float_list_feature(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.area', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.area', title='[?]'>area</a>),
<span class='lineno'> 285</span>   }
<span class='lineno'> 286</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.example', title='?'>example</a> = tf.train.Example(features=tf.train.Features(feature=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.feature_dict', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.feature_dict', title='dict'>feature_dict</a>))
<span class='lineno'> 287</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords_lib._create_tf_example.example', title='?'>example</a>
</pre></td></tr></table></body></html>