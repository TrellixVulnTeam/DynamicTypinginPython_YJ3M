<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/slim/datasets/download_and_convert_visualwakewords.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.FLAGS', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.FLAGS'>FLAGS</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run', xid='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run'>run</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2019 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> r&quot;&quot;&quot;Downloads and converts VisualWakewords data to TFRecords of TF-Example protos.
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span> This module downloads the COCO dataset, uncompresses it, derives the
<span class='lineno'>  18</span> VisualWakeWords dataset to create two TFRecord datasets: one for
<span class='lineno'>  19</span> train and one for test. Each TFRecord dataset is comprised of a set of
<span class='lineno'>  20</span> TF-Example protocol buffers, each of which contain a single image and label.
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> The script should take several minutes to run.
<span class='lineno'>  23</span> Please note that this tool creates sharded output files.
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> VisualWakeWords dataset is used to design tiny models classifying two classes,
<span class='lineno'>  26</span> such as person/not-person. The two steps to generate the VisualWakeWords
<span class='lineno'>  27</span> dataset from the COCO dataset are given below:
<span class='lineno'>  28</span> 
<span class='lineno'>  29</span> 1. Use COCO annotations to create VisualWakeWords annotations:
<span class='lineno'>  30</span> 
<span class='lineno'>  31</span> Note: A bounding box is &#39;valid&#39; if it has the foreground_class_of_interest
<span class='lineno'>  32</span> (e.g. person) and it&#39;s area is greater than 0.5% of the image area.
<span class='lineno'>  33</span> 
<span class='lineno'>  34</span> The resulting annotations file has the following fields, where &#39;images&#39; are
<span class='lineno'>  35</span> the same as COCO dataset. &#39;categories&#39; only contains information about the
<span class='lineno'>  36</span> foreground_class_of_interest (e.g. person) and &#39;annotations&#39; maps an image to
<span class='lineno'>  37</span> objects (a list of valid bounding boxes) and label (value is 1 if it has
<span class='lineno'>  38</span> atleast one valid bounding box, otherwise 0)
<span class='lineno'>  39</span> 
<span class='lineno'>  40</span>   images[{
<span class='lineno'>  41</span>   &quot;id&quot;, &quot;width&quot;, &quot;height&quot;, &quot;file_name&quot;, &quot;flickr_url&quot;, &quot;coco_url&quot;,
<span class='lineno'>  42</span>   &quot;license&quot;, &quot;date_captured&quot;,
<span class='lineno'>  43</span>   }]
<span class='lineno'>  44</span> 
<span class='lineno'>  45</span>   categories{
<span class='lineno'>  46</span>   &quot;id&quot;: {&quot;id&quot;, &quot;name&quot;, &quot;supercategory&quot;}
<span class='lineno'>  47</span>   }
<span class='lineno'>  48</span> 
<span class='lineno'>  49</span>   annotations{
<span class='lineno'>  50</span>   &quot;image_id&quot;: {&quot;objects&quot;:[{&quot;area&quot;, &quot;bbox&quot; : [x,y,width,height]}], &quot;label&quot;}
<span class='lineno'>  51</span>   }
<span class='lineno'>  52</span> 
<span class='lineno'>  53</span> 2. Use VisualWakeWords annotations to create TFRecords:
<span class='lineno'>  54</span> 
<span class='lineno'>  55</span> The resulting TFRecord file contains the following features:
<span class='lineno'>  56</span> { image/height, image/width, image/source_id, image/encoded,
<span class='lineno'>  57</span>   image/class/label_text, image/class/label,
<span class='lineno'>  58</span>   image/object/class/text,
<span class='lineno'>  59</span>   image/object/bbox/ymin, image/object/bbox/xmin, image/object/bbox/ymax,
<span class='lineno'>  60</span>   image/object/bbox/xmax, image/object/area
<span class='lineno'>  61</span>   image/filename, image/format, image/key/sha256}
<span class='lineno'>  62</span> For classification models, you need the image/encoded and image/class/label.
<span class='lineno'>  63</span> 
<span class='lineno'>  64</span> Example usage:
<span class='lineno'>  65</span> Run download_and_convert_data.py in the parent directory as follows:
<span class='lineno'>  66</span> 
<span class='lineno'>  67</span>     python download_and_convert_visualwakewords.py --logtostderr \
<span class='lineno'>  68</span>       --dataset_name=visualwakewords \
<span class='lineno'>  69</span>       --dataset_dir=&quot;${DATASET_DIR}&quot; \
<span class='lineno'>  70</span>       --small_object_area_threshold=0.005 \
<span class='lineno'>  71</span>       --foreground_class_of_interest=&#39;person&#39;
<span class='lineno'>  72</span> 
<span class='lineno'>  73</span> &quot;&quot;&quot;
<span class='lineno'>  74</span> 
<span class='lineno'>  75</span> from __future__ import absolute_import
<span class='lineno'>  76</span> from __future__ import division
<span class='lineno'>  77</span> from __future__ import print_function
<span class='lineno'>  78</span> 
<span class='lineno'>  79</span> import os
<span class='lineno'>  80</span> import tensorflow.compat.v1 as tf
<span class='lineno'>  81</span> from datasets import download_and_convert_visualwakewords_lib
<span class='lineno'>  82</span> 
<span class='lineno'>  83</span> tf.logging.set_verbosity(tf.logging.INFO)
<span class='lineno'>  84</span> 
<span class='lineno'>  85</span> tf.app.flags.DEFINE_string(
<span class='lineno'>  86</span>     &#39;coco_dirname&#39;, &#39;coco_dataset&#39;,
<span class='lineno'>  87</span>     &#39;A subdirectory in visualwakewords dataset directory&#39;
<span class='lineno'>  88</span>     &#39;containing the coco dataset&#39;)
<span class='lineno'>  89</span> 
<span class='lineno'>  90</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.FLAGS', title='?'>FLAGS</a> = tf.app.flags.FLAGS
<span class='lineno'>  91</span> 
<span class='lineno'>  92</span> 
<span class='lineno'>  93</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run', title='(?, ?, ?) -> None'>run</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', title='?'>dataset_dir</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.small_object_area_threshold', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.small_object_area_threshold', title='?'>small_object_area_threshold</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.foreground_class_of_interest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.foreground_class_of_interest', title='?'>foreground_class_of_interest</a>):
<span class='lineno'>  94</span>   &quot;&quot;&quot;Runs the download and conversion operation.
<span class='lineno'>  95</span> 
<span class='lineno'>  96</span>   Args:
<span class='lineno'>  97</span>     dataset_dir: The dataset directory where the dataset is stored.
<span class='lineno'>  98</span>     small_object_area_threshold: Threshold of fraction of image area below which
<span class='lineno'>  99</span>       small objects are filtered
<span class='lineno'> 100</span>     foreground_class_of_interest: Build a binary classifier based on the
<span class='lineno'> 101</span>       presence or absence of this object in the image.
<span class='lineno'> 102</span>   &quot;&quot;&quot;
<span class='lineno'> 103</span>   # 1. Download the coco dataset into a subdirectory under the visualwakewords
<span class='lineno'> 104</span>   #    dataset directory
<span class='lineno'> 105</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', title='str'>coco_dir</a> = os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', title='?'>dataset_dir</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.FLAGS', title='?'>FLAGS</a>.coco_dirname)
<span class='lineno'> 106</span> 
<span class='lineno'> 107</span>   if not tf.gfile.IsDirectory(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', title='str'>coco_dir</a>):
<span class='lineno'> 108</span>     tf.gfile.MakeDirs(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', title='str'>coco_dir</a>)
<span class='lineno'> 109</span> 
<span class='lineno'> 110</span>   download_and_convert_visualwakewords_lib.download_coco_dataset(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', title='str'>coco_dir</a>)
<span class='lineno'> 111</span> 
<span class='lineno'> 112</span>   # Path to COCO annotations
<span class='lineno'> 113</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_annotations_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_annotations_file', title='str'>train_annotations_file</a> = os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', title='str'>coco_dir</a>, &#39;annotations&#39;,
<span class='lineno'> 114</span>                                         &#39;instances_train2014.json&#39;)
<span class='lineno'> 115</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_annotations_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_annotations_file', title='str'>val_annotations_file</a> = os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', title='str'>coco_dir</a>, &#39;annotations&#39;,
<span class='lineno'> 116</span>                                       &#39;instances_val2014.json&#39;)
<span class='lineno'> 117</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_image_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_image_dir', title='str'>train_image_dir</a> = os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', title='str'>coco_dir</a>, &#39;train2014&#39;)
<span class='lineno'> 118</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_image_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_image_dir', title='str'>val_image_dir</a> = os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.coco_dir', title='str'>coco_dir</a>, &#39;val2014&#39;)
<span class='lineno'> 119</span> 
<span class='lineno'> 120</span>   # Path to VisualWakeWords annotations
<span class='lineno'> 121</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_train', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_train', title='str'>visualwakewords_annotations_train</a> = os.path.join(
<span class='lineno'> 122</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', title='?'>dataset_dir</a>, &#39;instances_visualwakewords_train2014.json&#39;)
<span class='lineno'> 123</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_val', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_val', title='str'>visualwakewords_annotations_val</a> = os.path.join(
<span class='lineno'> 124</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', title='?'>dataset_dir</a>, &#39;instances_visualwakewords_val2014.json&#39;)
<span class='lineno'> 125</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_labels_filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_labels_filename', title='str'>visualwakewords_labels_filename</a> = os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', title='?'>dataset_dir</a>, &#39;labels.txt&#39;)
<span class='lineno'> 126</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_output_path', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_output_path', title='str'>train_output_path</a> = os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', title='?'>dataset_dir</a>, &#39;train.record&#39;)
<span class='lineno'> 127</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_output_path', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_output_path', title='str'>val_output_path</a> = os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.dataset_dir', title='?'>dataset_dir</a>, &#39;val.record&#39;)
<span class='lineno'> 128</span> 
<span class='lineno'> 129</span>   # 2. Create a labels file
<span class='lineno'> 130</span>   tf.logging.info(&#39;Creating a labels file...&#39;)
<span class='lineno'> 131</span>   download_and_convert_visualwakewords_lib.create_labels_file(
<span class='lineno'> 132</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.foreground_class_of_interest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.foreground_class_of_interest', title='?'>foreground_class_of_interest</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_labels_filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_labels_filename', title='str'>visualwakewords_labels_filename</a>)
<span class='lineno'> 133</span> 
<span class='lineno'> 134</span>   # 3. Use COCO annotations to create VisualWakeWords annotations
<span class='lineno'> 135</span>   tf.logging.info(&#39;Creating train VisualWakeWords annotations...&#39;)
<span class='lineno'> 136</span>   download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations(
<span class='lineno'> 137</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_annotations_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_annotations_file', title='str'>train_annotations_file</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_train', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_train', title='str'>visualwakewords_annotations_train</a>,
<span class='lineno'> 138</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.small_object_area_threshold', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.small_object_area_threshold', title='?'>small_object_area_threshold</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.foreground_class_of_interest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.foreground_class_of_interest', title='?'>foreground_class_of_interest</a>)
<span class='lineno'> 139</span>   tf.logging.info(&#39;Creating validation VisualWakeWords annotations...&#39;)
<span class='lineno'> 140</span>   download_and_convert_visualwakewords_lib.create_visual_wakeword_annotations(
<span class='lineno'> 141</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_annotations_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_annotations_file', title='str'>val_annotations_file</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_val', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_val', title='str'>visualwakewords_annotations_val</a>,
<span class='lineno'> 142</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.small_object_area_threshold', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.small_object_area_threshold', title='?'>small_object_area_threshold</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.foreground_class_of_interest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.foreground_class_of_interest', title='?'>foreground_class_of_interest</a>)
<span class='lineno'> 143</span> 
<span class='lineno'> 144</span>   # 4. Use VisualWakeWords annotations to create the TFRecords
<span class='lineno'> 145</span>   tf.logging.info(&#39;Creating train TFRecords for VisualWakeWords dataset...&#39;)
<span class='lineno'> 146</span>   download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset(
<span class='lineno'> 147</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_train', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_train', title='str'>visualwakewords_annotations_train</a>,
<span class='lineno'> 148</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_image_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_image_dir', title='str'>train_image_dir</a>,
<span class='lineno'> 149</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_output_path', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.train_output_path', title='str'>train_output_path</a>,
<span class='lineno'> 150</span>       num_shards=100)
<span class='lineno'> 151</span> 
<span class='lineno'> 152</span>   tf.logging.info(
<span class='lineno'> 153</span>       &#39;Creating validation TFRecords for VisualWakeWords dataset...&#39;)
<span class='lineno'> 154</span>   download_and_convert_visualwakewords_lib.create_tf_record_for_visualwakewords_dataset(
<span class='lineno'> 155</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_val', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.visualwakewords_annotations_val', title='str'>visualwakewords_annotations_val</a>,
<span class='lineno'> 156</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_image_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_image_dir', title='str'>val_image_dir</a>,
<span class='lineno'> 157</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_output_path', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.slim.datasets.download_and_convert_visualwakewords.run.val_output_path', title='str'>val_output_path</a>,
<span class='lineno'> 158</span>       num_shards=10)
</pre></td></tr></table></body></html>