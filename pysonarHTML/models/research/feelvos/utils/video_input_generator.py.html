<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/feelvos/utils/video_input_generator.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.slim', xid='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.slim'>slim</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.dataset_data_provider', xid='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.dataset_data_provider'>dataset_data_provider</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', xid='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT'>MIN_LABEL_COUNT</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence', xid='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence'>decode_image_sequence</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data', xid='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data'>_get_data</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame', xid='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame'>_has_foreground_and_background_in_first_frame</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2', xid='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2'>_has_foreground_and_background_in_first_frame_2</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame', xid='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame'>_has_enough_pixels_of_each_object_in_first_frame</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get', xid='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get'>get</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2018 The TensorFlow Authors All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> &quot;&quot;&quot;Wrapper for providing semantic segmentation video data.&quot;&quot;&quot;
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> import tensorflow as tf
<span class='lineno'>  19</span> from feelvos import input_preprocess
<span class='lineno'>  20</span> from feelvos import model
<span class='lineno'>  21</span> from feelvos.utils import mask_damaging
<span class='lineno'>  22</span> from feelvos.utils import train_utils
<span class='lineno'>  23</span> 
<span class='lineno'>  24</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.slim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.slim', title='?'>slim</a> = tf.contrib.slim
<span class='lineno'>  25</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.dataset_data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.dataset_data_provider', title='?'>dataset_data_provider</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.slim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.slim', title='?'>slim</a>.dataset_data_provider
<span class='lineno'>  26</span> 
<span class='lineno'>  27</span> 
<span class='lineno'>  28</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', title='int'>MIN_LABEL_COUNT</a> = 10
<span class='lineno'>  29</span> 
<span class='lineno'>  30</span> 
<span class='lineno'>  31</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence', title='(None, str, None, int, ?) -> None / (?, str, None, int, ?) -> None'>decode_image_sequence</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.tensor', title='None'>tensor</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.image_format', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.image_format', title='str'>image_format</a>=&#39;jpeg&#39;, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.shape', title='None'>shape</a>=None,
<span class='lineno'>  32</span>                           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.channels', title='int'>channels</a>=3, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.raw_dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.raw_dtype', title='?'>raw_dtype</a>=tf.uint8):
<span class='lineno'>  33</span>   &quot;&quot;&quot;Decodes a sequence of images.
<span class='lineno'>  34</span> 
<span class='lineno'>  35</span>   Args:
<span class='lineno'>  36</span>     tensor: the tensor of strings to decode, shape: [num_images]
<span class='lineno'>  37</span>     image_format: a string (possibly tensor) with the format of the image.
<span class='lineno'>  38</span>       Options include &#39;jpeg&#39;, &#39;png&#39;, and &#39;raw&#39;.
<span class='lineno'>  39</span>     shape: a list or tensor of the decoded image shape for a single image.
<span class='lineno'>  40</span>     channels: if &#39;shape&#39; is None, the third dimension of the image is set to
<span class='lineno'>  41</span>       this value.
<span class='lineno'>  42</span>     raw_dtype: if the image is encoded as raw bytes, this is the method of
<span class='lineno'>  43</span>       decoding the bytes into values.
<span class='lineno'>  44</span>   Returns:
<span class='lineno'>  45</span>     The decoded images with shape [time, height, width, channels].
<span class='lineno'>  46</span>   &quot;&quot;&quot;
<span class='lineno'>  47</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.handler', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.handler', title='?'>handler</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.slim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.slim', title='?'>slim</a>.tfexample_decoder.Image(
<span class='lineno'>  48</span>       shape=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.shape', title='None'>shape</a>, channels=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.channels', title='int'>channels</a>, dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.raw_dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.raw_dtype', title='?'>raw_dtype</a>, repeated=True)
<span class='lineno'>  49</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.handler', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.handler', title='?'>handler</a>.tensors_to_item({&#39;image/encoded&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.tensor', title='None'>tensor</a>,
<span class='lineno'>  50</span>                                   &#39;image/format&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.image_format', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence.image_format', title='str'>image_format</a>})
<span class='lineno'>  51</span> 
<span class='lineno'>  52</span> 
<span class='lineno'>  53</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data', title='(?, None, bool) -> (?, None, None, ?, ?, ?, ?) / (?, ?, ?) -> (?, None, None, ?, ?, ?, ?)'>_get_data</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', title='?'>data_provider</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.dataset_split', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.dataset_split', title='None'>dataset_split</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.video_frames_are_decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.video_frames_are_decoded', title='bool'>video_frames_are_decoded</a>):
<span class='lineno'>  54</span>   &quot;&quot;&quot;Gets data from data provider.
<span class='lineno'>  55</span> 
<span class='lineno'>  56</span>   Args:
<span class='lineno'>  57</span>     data_provider: An object of slim.data_provider.
<span class='lineno'>  58</span>     dataset_split: Dataset split.
<span class='lineno'>  59</span>     video_frames_are_decoded: Boolean, whether the video frames are already
<span class='lineno'>  60</span>         decoded
<span class='lineno'>  61</span> 
<span class='lineno'>  62</span>   Returns:
<span class='lineno'>  63</span>     image: Image Tensor.
<span class='lineno'>  64</span>     label: Label Tensor storing segmentation annotations.
<span class='lineno'>  65</span>     object_label: An integer refers to object_label according to labelmap. If
<span class='lineno'>  66</span>       the example has more than one object_label, take the first one.
<span class='lineno'>  67</span>     image_name: Image name.
<span class='lineno'>  68</span>     height: Image height.
<span class='lineno'>  69</span>     width: Image width.
<span class='lineno'>  70</span>     video_id: String tensor representing the name of the video.
<span class='lineno'>  71</span> 
<span class='lineno'>  72</span>   Raises:
<span class='lineno'>  73</span>     ValueError: Failed to find label.
<span class='lineno'>  74</span>   &quot;&quot;&quot;
<span class='lineno'>  75</span> 
<span class='lineno'>  76</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.video_frames_are_decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.video_frames_are_decoded', title='bool'>video_frames_are_decoded</a>:
<span class='lineno'>  77</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image', title='?'>image</a>, = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', title='?'>data_provider</a>.get([&#39;image&#39;])
<span class='lineno'>  78</span>   else:
<span class='lineno'>  79</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image', title='?'>image</a>, = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', title='?'>data_provider</a>.get([&#39;image/encoded&#39;])
<span class='lineno'>  80</span> 
<span class='lineno'>  81</span>   # Some datasets do not contain image_name.
<span class='lineno'>  82</span>   if &#39;image_name&#39; in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', title='?'>data_provider</a>.list_items():
<span class='lineno'>  83</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image_name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image_name', title='?'>image_name</a>, = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', title='?'>data_provider</a>.get([&#39;image_name&#39;])
<span class='lineno'>  84</span>   else:
<span class='lineno'>  85</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image_name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image_name', title='?'>image_name</a> = tf.constant(&#39;&#39;)
<span class='lineno'>  86</span> 
<span class='lineno'>  87</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.height', title='?'>height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.width', title='?'>width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', title='?'>data_provider</a>.get([&#39;height&#39;, &#39;width&#39;])
<span class='lineno'>  88</span> 
<span class='lineno'>  89</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.label', title='None'>label</a> = None
<span class='lineno'>  90</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.dataset_split', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.dataset_split', title='None'>dataset_split</a> != &#39;test&#39;:
<span class='lineno'>  91</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.video_frames_are_decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.video_frames_are_decoded', title='bool'>video_frames_are_decoded</a>:
<span class='lineno'>  92</span>       if &#39;labels_class&#39; not in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', title='?'>data_provider</a>.list_items():
<span class='lineno'>  93</span>         raise ValueError(&#39;Failed to find labels.&#39;)
<span class='lineno'>  94</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.label', title='?'>label</a>, = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', title='?'>data_provider</a>.get([&#39;labels_class&#39;])
<span class='lineno'>  95</span>     else:
<span class='lineno'>  96</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.key', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.key', title='str'>key</a> = &#39;segmentation/object/encoded&#39;
<span class='lineno'>  97</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.key', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.key', title='str'>key</a> not in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', title='?'>data_provider</a>.list_items():
<span class='lineno'>  98</span>         raise ValueError(&#39;Failed to find labels.&#39;)
<span class='lineno'>  99</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.label', title='?'>label</a>, = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', title='?'>data_provider</a>.get([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.key', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.key', title='str'>key</a>])
<span class='lineno'> 100</span> 
<span class='lineno'> 101</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.object_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.object_label', title='None'>object_label</a> = None
<span class='lineno'> 102</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.video_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.video_id', title='?'>video_id</a>, = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.data_provider', title='?'>data_provider</a>.get([&#39;video_id&#39;])
<span class='lineno'> 103</span> 
<span class='lineno'> 104</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.label', title='None'>label</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.object_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.object_label', title='None'>object_label</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image_name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.image_name', title='?'>image_name</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.width', title='?'>width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.video_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data.video_id', title='?'>video_id</a>
<span class='lineno'> 105</span> 
<span class='lineno'> 106</span> 
<span class='lineno'> 107</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame', title='(?, ?) -> None'>_has_foreground_and_background_in_first_frame</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.label', title='?'>label</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.subsampling_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.subsampling_factor', title='?'>subsampling_factor</a>):
<span class='lineno'> 108</span>   &quot;&quot;&quot;Checks if the labels have foreground and background in the first frame.
<span class='lineno'> 109</span> 
<span class='lineno'> 110</span>   Args:
<span class='lineno'> 111</span>     label: Label tensor of shape [num_frames, height, width, 1].
<span class='lineno'> 112</span>     subsampling_factor: Integer, the subsampling factor.
<span class='lineno'> 113</span> 
<span class='lineno'> 114</span>   Returns:
<span class='lineno'> 115</span>     Boolean, whether the labels have foreground and background in the first
<span class='lineno'> 116</span>       frame.
<span class='lineno'> 117</span>   &quot;&quot;&quot;
<span class='lineno'> 118</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.h', title='?'>h</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.w', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.w', title='?'>w</a> = train_utils.resolve_shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.label', title='?'>label</a>)[1:3]
<span class='lineno'> 119</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.label_downscaled', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.label_downscaled', title='?'>label_downscaled</a> = tf.squeeze(
<span class='lineno'> 120</span>       tf.image.resize_nearest_neighbor(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.label', title='?'>label</a>[0, tf.newaxis],
<span class='lineno'> 121</span>                                        [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.h', title='?'>h</a> // <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.subsampling_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.subsampling_factor', title='?'>subsampling_factor</a>,
<span class='lineno'> 122</span>                                         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.w', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.w', title='?'>w</a> // <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.subsampling_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.subsampling_factor', title='?'>subsampling_factor</a>],
<span class='lineno'> 123</span>                                        align_corners=True),
<span class='lineno'> 124</span>       axis=0)
<span class='lineno'> 125</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.is_bg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.is_bg', title='?'>is_bg</a> = tf.equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.label_downscaled', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.label_downscaled', title='?'>label_downscaled</a>, 0)
<span class='lineno'> 126</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.is_fg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.is_fg', title='?'>is_fg</a> = tf.logical_not(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.is_bg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.is_bg', title='?'>is_bg</a>)
<span class='lineno'> 127</span>   # Just using reduce_any was not robust enough, so lets make sure the count
<span class='lineno'> 128</span>   # is above MIN_LABEL_COUNT.
<span class='lineno'> 129</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.fg_count', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.fg_count', title='?'>fg_count</a> = tf.reduce_sum(tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.is_fg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.is_fg', title='?'>is_fg</a>, tf.int32))
<span class='lineno'> 130</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.bg_count', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.bg_count', title='?'>bg_count</a> = tf.reduce_sum(tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.is_bg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.is_bg', title='?'>is_bg</a>, tf.int32))
<span class='lineno'> 131</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.has_bg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.has_bg', title='?'>has_bg</a> = tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.fg_count', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.fg_count', title='?'>fg_count</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', title='int'>MIN_LABEL_COUNT</a>)
<span class='lineno'> 132</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.has_fg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.has_fg', title='?'>has_fg</a> = tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.bg_count', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.bg_count', title='?'>bg_count</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', title='int'>MIN_LABEL_COUNT</a>)
<span class='lineno'> 133</span>   return tf.logical_and(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.has_bg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.has_bg', title='?'>has_bg</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.has_fg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame.has_fg', title='?'>has_fg</a>)
<span class='lineno'> 134</span> 
<span class='lineno'> 135</span> 
<span class='lineno'> 136</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2', title='(?, ?) -> None / (None, None) -> None'>_has_foreground_and_background_in_first_frame_2</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.label', title='None'>label</a>,
<span class='lineno'> 137</span>                                                     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.decoder_output_stride', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.decoder_output_stride', title='None'>decoder_output_stride</a>):
<span class='lineno'> 138</span>   &quot;&quot;&quot;Checks if the labels have foreground and background in the first frame.
<span class='lineno'> 139</span> 
<span class='lineno'> 140</span>   Second attempt, this time we use the actual output dimension for resizing.
<span class='lineno'> 141</span> 
<span class='lineno'> 142</span>   Args:
<span class='lineno'> 143</span>     label: Label tensor of shape [num_frames, height, width, 1].
<span class='lineno'> 144</span>     decoder_output_stride: Integer, the stride of the decoder output.
<span class='lineno'> 145</span> 
<span class='lineno'> 146</span>   Returns:
<span class='lineno'> 147</span>     Boolean, whether the labels have foreground and background in the first
<span class='lineno'> 148</span>       frame.
<span class='lineno'> 149</span>   &quot;&quot;&quot;
<span class='lineno'> 150</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.h', title='?'>h</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.w', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.w', title='?'>w</a> = train_utils.resolve_shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.label', title='None'>label</a>)[1:3]
<span class='lineno'> 151</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.h_sub', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.h_sub', title='?'>h_sub</a> = model.scale_dimension(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.h', title='?'>h</a>, 1.0 / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.decoder_output_stride', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.decoder_output_stride', title='None'>decoder_output_stride</a>)
<span class='lineno'> 152</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.w_sub', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.w_sub', title='?'>w_sub</a> = model.scale_dimension(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.w', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.w', title='?'>w</a>, 1.0 / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.decoder_output_stride', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.decoder_output_stride', title='None'>decoder_output_stride</a>)
<span class='lineno'> 153</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.label_downscaled', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.label_downscaled', title='?'>label_downscaled</a> = tf.squeeze(
<span class='lineno'> 154</span>       tf.image.resize_nearest_neighbor(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.label', title='None'>label</a>[0, tf.newaxis], [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.h_sub', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.h_sub', title='?'>h_sub</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.w_sub', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.w_sub', title='?'>w_sub</a>],
<span class='lineno'> 155</span>                                        align_corners=True), axis=0)
<span class='lineno'> 156</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.is_bg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.is_bg', title='?'>is_bg</a> = tf.equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.label_downscaled', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.label_downscaled', title='?'>label_downscaled</a>, 0)
<span class='lineno'> 157</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.is_fg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.is_fg', title='?'>is_fg</a> = tf.logical_not(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.is_bg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.is_bg', title='?'>is_bg</a>)
<span class='lineno'> 158</span>   # Just using reduce_any was not robust enough, so lets make sure the count
<span class='lineno'> 159</span>   # is above MIN_LABEL_COUNT.
<span class='lineno'> 160</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.fg_count', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.fg_count', title='?'>fg_count</a> = tf.reduce_sum(tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.is_fg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.is_fg', title='?'>is_fg</a>, tf.int32))
<span class='lineno'> 161</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.bg_count', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.bg_count', title='?'>bg_count</a> = tf.reduce_sum(tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.is_bg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.is_bg', title='?'>is_bg</a>, tf.int32))
<span class='lineno'> 162</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.has_bg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.has_bg', title='?'>has_bg</a> = tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.fg_count', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.fg_count', title='?'>fg_count</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', title='int'>MIN_LABEL_COUNT</a>)
<span class='lineno'> 163</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.has_fg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.has_fg', title='?'>has_fg</a> = tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.bg_count', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.bg_count', title='?'>bg_count</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', title='int'>MIN_LABEL_COUNT</a>)
<span class='lineno'> 164</span>   return tf.logical_and(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.has_bg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.has_bg', title='?'>has_bg</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.has_fg', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2.has_fg', title='?'>has_fg</a>)
<span class='lineno'> 165</span> 
<span class='lineno'> 166</span> 
<span class='lineno'> 167</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame', title='(None, None) -> None / (?, ?) -> None'>_has_enough_pixels_of_each_object_in_first_frame</a>(
<span class='lineno'> 168</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.label', title='None'>label</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.decoder_output_stride', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.decoder_output_stride', title='None'>decoder_output_stride</a>):
<span class='lineno'> 169</span>   &quot;&quot;&quot;Checks if for each object (incl. background) enough pixels are visible.
<span class='lineno'> 170</span> 
<span class='lineno'> 171</span>   During test time, we will usually not see a reference frame in which only
<span class='lineno'> 172</span>   very few pixels of one object are visible. These cases can be problematic
<span class='lineno'> 173</span>   during training, especially if more than the 1-nearest neighbor is used.
<span class='lineno'> 174</span>   That&#39;s why this function can be used to detect and filter these cases.
<span class='lineno'> 175</span> 
<span class='lineno'> 176</span>   Args:
<span class='lineno'> 177</span>     label: Label tensor of shape [num_frames, height, width, 1].
<span class='lineno'> 178</span>     decoder_output_stride: Integer, the stride of the decoder output.
<span class='lineno'> 179</span> 
<span class='lineno'> 180</span>   Returns:
<span class='lineno'> 181</span>     Boolean, whether the labels have enough pixels of each object in the first
<span class='lineno'> 182</span>       frame.
<span class='lineno'> 183</span>   &quot;&quot;&quot;
<span class='lineno'> 184</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.h', title='?'>h</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.w', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.w', title='?'>w</a> = train_utils.resolve_shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.label', title='None'>label</a>)[1:3]
<span class='lineno'> 185</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.h_sub', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.h_sub', title='?'>h_sub</a> = model.scale_dimension(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.h', title='?'>h</a>, 1.0 / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.decoder_output_stride', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.decoder_output_stride', title='None'>decoder_output_stride</a>)
<span class='lineno'> 186</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.w_sub', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.w_sub', title='?'>w_sub</a> = model.scale_dimension(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.w', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.w', title='?'>w</a>, 1.0 / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.decoder_output_stride', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.decoder_output_stride', title='None'>decoder_output_stride</a>)
<span class='lineno'> 187</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.label_downscaled', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.label_downscaled', title='?'>label_downscaled</a> = tf.squeeze(
<span class='lineno'> 188</span>       tf.image.resize_nearest_neighbor(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.label', title='None'>label</a>[0, tf.newaxis], [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.h_sub', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.h_sub', title='?'>h_sub</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.w_sub', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.w_sub', title='?'>w_sub</a>],
<span class='lineno'> 189</span>                                        align_corners=True), axis=0)
<span class='lineno'> 190</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame._', title='?'>_</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame._', title='?'>_</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.counts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.counts', title='?'>counts</a> = tf.unique_with_counts(
<span class='lineno'> 191</span>       tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.label_downscaled', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.label_downscaled', title='?'>label_downscaled</a>, [-1]))
<span class='lineno'> 192</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.has_enough_pixels_per_object', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.has_enough_pixels_per_object', title='?'>has_enough_pixels_per_object</a> = tf.reduce_all(
<span class='lineno'> 193</span>       tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.counts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.counts', title='?'>counts</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.MIN_LABEL_COUNT', title='int'>MIN_LABEL_COUNT</a>))
<span class='lineno'> 194</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.has_enough_pixels_per_object', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame.has_enough_pixels_per_object', title='?'>has_enough_pixels_per_object</a>
<span class='lineno'> 195</span> 
<span class='lineno'> 196</span> 
<span class='lineno'> 197</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get', title='(?, ?, ?, ?, None, None, None, float, float, int, bool, int, int, None, bool, None, int, bool, None, bool, bool, bool, bool, bool, bool, bool) -> None'>get</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset', title='?'>dataset</a>,
<span class='lineno'> 198</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='?'>num_frames_per_video</a>,
<span class='lineno'> 199</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a>,
<span class='lineno'> 200</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', title='?'>batch_size</a>,
<span class='lineno'> 201</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_resize_value', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_resize_value', title='None'>min_resize_value</a>=None,
<span class='lineno'> 202</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_resize_value', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_resize_value', title='None'>max_resize_value</a>=None,
<span class='lineno'> 203</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.resize_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.resize_factor', title='None'>resize_factor</a>=None,
<span class='lineno'> 204</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_scale_factor', title='float'>min_scale_factor</a>=1.,
<span class='lineno'> 205</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_scale_factor', title='float'>max_scale_factor</a>=1.,
<span class='lineno'> 206</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.scale_factor_step_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.scale_factor_step_size', title='int'>scale_factor_step_size</a>=0,
<span class='lineno'> 207</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preprocess_image_and_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preprocess_image_and_label', title='bool'>preprocess_image_and_label</a>=True,
<span class='lineno'> 208</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_readers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_readers', title='int'>num_readers</a>=1,
<span class='lineno'> 209</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_threads', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_threads', title='int'>num_threads</a>=1,
<span class='lineno'> 210</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset_split', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset_split', title='None'>dataset_split</a>=None,
<span class='lineno'> 211</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', title='bool'>is_training</a>=True,
<span class='lineno'> 212</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.model_variant', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.model_variant', title='None'>model_variant</a>=None,
<span class='lineno'> 213</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_capacity_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_capacity_factor', title='int'>batch_capacity_factor</a>=32,
<span class='lineno'> 214</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_frames_are_decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_frames_are_decoded', title='bool'>video_frames_are_decoded</a>=False,
<span class='lineno'> 215</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.decoder_output_stride', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.decoder_output_stride', title='None'>decoder_output_stride</a>=None,
<span class='lineno'> 216</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_frame_finetuning', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_frame_finetuning', title='bool'>first_frame_finetuning</a>=False,
<span class='lineno'> 217</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_only_first_frame_for_finetuning', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_only_first_frame_for_finetuning', title='bool'>sample_only_first_frame_for_finetuning</a>=False,
<span class='lineno'> 218</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', title='bool'>sample_adjacent_and_consistent_query_frames</a>=False,
<span class='lineno'> 219</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remap_labels_to_reference_frame', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remap_labels_to_reference_frame', title='bool'>remap_labels_to_reference_frame</a>=True,
<span class='lineno'> 220</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.generate_prev_frame_mask_by_mask_damaging', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.generate_prev_frame_mask_by_mask_damaging', title='bool'>generate_prev_frame_mask_by_mask_damaging</a>=False,
<span class='lineno'> 221</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.three_frame_dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.three_frame_dataset', title='bool'>three_frame_dataset</a>=False,
<span class='lineno'> 222</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.add_prev_frame_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.add_prev_frame_label', title='bool'>add_prev_frame_label</a>=True):
<span class='lineno'> 223</span>   &quot;&quot;&quot;Gets the dataset split for semantic segmentation.
<span class='lineno'> 224</span> 
<span class='lineno'> 225</span>   This functions gets the dataset split for semantic segmentation. In
<span class='lineno'> 226</span>   particular, it is a wrapper of (1) dataset_data_provider which returns the raw
<span class='lineno'> 227</span>   dataset split, (2) input_preprcess which preprocess the raw data, and (3) the
<span class='lineno'> 228</span>   Tensorflow operation of batching the preprocessed data. Then, the output could
<span class='lineno'> 229</span>   be directly used by training, evaluation or visualization.
<span class='lineno'> 230</span> 
<span class='lineno'> 231</span>   Args:
<span class='lineno'> 232</span>     dataset: An instance of slim Dataset.
<span class='lineno'> 233</span>     num_frames_per_video: The number of frames used per video
<span class='lineno'> 234</span>     crop_size: Image crop size [height, width].
<span class='lineno'> 235</span>     batch_size: Batch size.
<span class='lineno'> 236</span>     min_resize_value: Desired size of the smaller image side.
<span class='lineno'> 237</span>     max_resize_value: Maximum allowed size of the larger image side.
<span class='lineno'> 238</span>     resize_factor: Resized dimensions are multiple of factor plus one.
<span class='lineno'> 239</span>     min_scale_factor: Minimum scale factor value.
<span class='lineno'> 240</span>     max_scale_factor: Maximum scale factor value.
<span class='lineno'> 241</span>     scale_factor_step_size: The step size from min scale factor to max scale
<span class='lineno'> 242</span>       factor. The input is randomly scaled based on the value of
<span class='lineno'> 243</span>       (min_scale_factor, max_scale_factor, scale_factor_step_size).
<span class='lineno'> 244</span>     preprocess_image_and_label: Boolean variable specifies if preprocessing of
<span class='lineno'> 245</span>       image and label will be performed or not.
<span class='lineno'> 246</span>     num_readers: Number of readers for data provider.
<span class='lineno'> 247</span>     num_threads: Number of threads for batching data.
<span class='lineno'> 248</span>     dataset_split: Dataset split.
<span class='lineno'> 249</span>     is_training: Is training or not.
<span class='lineno'> 250</span>     model_variant: Model variant (string) for choosing how to mean-subtract the
<span class='lineno'> 251</span>       images. See feature_extractor.network_map for supported model variants.
<span class='lineno'> 252</span>     batch_capacity_factor: Batch capacity factor affecting the training queue
<span class='lineno'> 253</span>       batch capacity.
<span class='lineno'> 254</span>     video_frames_are_decoded: Boolean, whether the video frames are already
<span class='lineno'> 255</span>         decoded
<span class='lineno'> 256</span>     decoder_output_stride: Integer, the stride of the decoder output.
<span class='lineno'> 257</span>     first_frame_finetuning: Boolean, whether to only sample the first frame
<span class='lineno'> 258</span>       for fine-tuning.
<span class='lineno'> 259</span>     sample_only_first_frame_for_finetuning: Boolean, whether to only sample the
<span class='lineno'> 260</span>       first frame during fine-tuning. This should be False when using lucid or
<span class='lineno'> 261</span>       wonderland data, but true when fine-tuning on the first frame only.
<span class='lineno'> 262</span>       Only has an effect if first_frame_finetuning is True.
<span class='lineno'> 263</span>     sample_adjacent_and_consistent_query_frames: Boolean, if true, the query
<span class='lineno'> 264</span>       frames (all but the first frame which is the reference frame) will be
<span class='lineno'> 265</span>       sampled such that they are adjacent video frames and have the same
<span class='lineno'> 266</span>       crop coordinates and flip augmentation.
<span class='lineno'> 267</span>     remap_labels_to_reference_frame: Boolean, whether to remap the labels of
<span class='lineno'> 268</span>       the query frames to match the labels of the (downscaled) reference frame.
<span class='lineno'> 269</span>       If a query frame contains a label which is not present in the reference,
<span class='lineno'> 270</span>       it will be mapped to background.
<span class='lineno'> 271</span>     generate_prev_frame_mask_by_mask_damaging: Boolean, whether to generate
<span class='lineno'> 272</span>       the masks used as guidance from the previous frame by damaging the
<span class='lineno'> 273</span>       ground truth mask.
<span class='lineno'> 274</span>     three_frame_dataset: Boolean, whether the dataset has exactly three frames
<span class='lineno'> 275</span>       per video of which the first is to be used as reference and the two
<span class='lineno'> 276</span>       others are consecutive frames to be used as query frames.
<span class='lineno'> 277</span>     add_prev_frame_label: Boolean, whether to sample one more frame before the
<span class='lineno'> 278</span>       first query frame to obtain a previous frame label. Only has an effect,
<span class='lineno'> 279</span>       if sample_adjacent_and_consistent_query_frames is True and
<span class='lineno'> 280</span>       generate_prev_frame_mask_by_mask_damaging is False.
<span class='lineno'> 281</span> 
<span class='lineno'> 282</span>   Returns:
<span class='lineno'> 283</span>     A dictionary of batched Tensors for semantic segmentation.
<span class='lineno'> 284</span> 
<span class='lineno'> 285</span>   Raises:
<span class='lineno'> 286</span>     ValueError: dataset_split is None, or Failed to find labels.
<span class='lineno'> 287</span>   &quot;&quot;&quot;
<span class='lineno'> 288</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset_split', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset_split', title='None'>dataset_split</a> is None:
<span class='lineno'> 289</span>     raise ValueError(&#39;Unknown dataset split.&#39;)
<span class='lineno'> 290</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.model_variant', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.model_variant', title='None'>model_variant</a> is None:
<span class='lineno'> 291</span>     tf.logging.warning(&#39;Please specify a model_variant. See &#39;
<span class='lineno'> 292</span>                        &#39;feature_extractor.network_map for supported model &#39;
<span class='lineno'> 293</span>                        &#39;variants.&#39;)
<span class='lineno'> 294</span> 
<span class='lineno'> 295</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.data_provider', title='?'>data_provider</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.dataset_data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.dataset_data_provider', title='?'>dataset_data_provider</a>.DatasetDataProvider(
<span class='lineno'> 296</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset', title='?'>dataset</a>,
<span class='lineno'> 297</span>       num_readers=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_readers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_readers', title='int'>num_readers</a>,
<span class='lineno'> 298</span>       num_epochs=None if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', title='bool'>is_training</a> else 1,
<span class='lineno'> 299</span>       shuffle=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', title='bool'>is_training</a>)
<span class='lineno'> 300</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.object_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.object_label', title='None'>object_label</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_name', title='?'>image_name</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.height', title='?'>height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.width', title='?'>width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_id', title='?'>video_id</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._get_data', title='(?, None, bool) -> (?, None, None, ?, ?, ?, ?) / (?, ?, ?) -> (?, None, None, ?, ?, ?, ?)'>_get_data</a>(
<span class='lineno'> 301</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.data_provider', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.data_provider', title='?'>data_provider</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset_split', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset_split', title='None'>dataset_split</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_frames_are_decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_frames_are_decoded', title='bool'>video_frames_are_decoded</a>)
<span class='lineno'> 302</span> 
<span class='lineno'> 303</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sampling_is_valid', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sampling_is_valid', title='?'>sampling_is_valid</a> = tf.constant(True)
<span class='lineno'> 304</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='?'>num_frames_per_video</a> is not None:
<span class='lineno'> 305</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', title='?'>total_num_frames</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='?'>image</a>)[0]
<span class='lineno'> 306</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_frame_finetuning', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_frame_finetuning', title='bool'>first_frame_finetuning</a> or <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.three_frame_dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.three_frame_dataset', title='bool'>three_frame_dataset</a>:
<span class='lineno'> 307</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_only_first_frame_for_finetuning', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_only_first_frame_for_finetuning', title='bool'>sample_only_first_frame_for_finetuning</a>:
<span class='lineno'> 308</span>         assert not <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', title='bool'>sample_adjacent_and_consistent_query_frames</a>, (
<span class='lineno'> 309</span>             &#39;this option does not make sense for sampling only first frame.&#39;)
<span class='lineno'> 310</span>         # Sample the first frame num_frames_per_video times.
<span class='lineno'> 311</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', title='?'>sel_indices</a> = tf.tile(tf.constant(0, dtype=tf.int32)[tf.newaxis],
<span class='lineno'> 312</span>                               multiples=[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='?'>num_frames_per_video</a>])
<span class='lineno'> 313</span>       else:
<span class='lineno'> 314</span>         if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', title='bool'>sample_adjacent_and_consistent_query_frames</a>:
<span class='lineno'> 315</span>           if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.add_prev_frame_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.add_prev_frame_label', title='bool'>add_prev_frame_label</a>:
<span class='lineno'> 316</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a></a> += 1
<span class='lineno'> 317</span>           # Since this is first frame fine-tuning, we&#39;ll for now assume that
<span class='lineno'> 318</span>           # each sequence has exactly 3 images: the ref frame and 2 adjacent
<span class='lineno'> 319</span>           # query frames.
<span class='lineno'> 320</span>           assert <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a> == 3
<span class='lineno'> 321</span>           with tf.control_dependencies([tf.assert_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', title='?'>total_num_frames</a>, 3)]):
<span class='lineno'> 322</span>             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', title='?'>sel_indices</a> = tf.constant([1, 2], dtype=tf.int32)
<span class='lineno'> 323</span>         else:
<span class='lineno'> 324</span>           # Sample num_frames_per_video - 1 query frames which are not the
<span class='lineno'> 325</span>           # first frame.
<span class='lineno'> 326</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', title='?'>sel_indices</a> = tf.random_shuffle(
<span class='lineno'> 327</span>               tf.range(1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', title='?'>total_num_frames</a>))[:(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='?'>num_frames_per_video</a> - 1)]
<span class='lineno'> 328</span>         # Concat first frame as reference frame to the front.
<span class='lineno'> 329</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', title='?'>sel_indices</a> = tf.concat([tf.constant(0, dtype=tf.int32)[tf.newaxis],
<span class='lineno'> 330</span>                                  <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', title='?'>sel_indices</a>], axis=0)
<span class='lineno'> 331</span>     else:
<span class='lineno'> 332</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', title='bool'>sample_adjacent_and_consistent_query_frames</a>:
<span class='lineno'> 333</span>         if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.add_prev_frame_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.add_prev_frame_label', title='bool'>add_prev_frame_label</a>:
<span class='lineno'> 334</span>           # Sample one more frame which we can use to provide initial softmax
<span class='lineno'> 335</span>           # feedback.
<span class='lineno'> 336</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a></a> += 1
<span class='lineno'> 337</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.ref_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.ref_idx', title='?'>ref_idx</a> = tf.random_shuffle(tf.range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', title='?'>total_num_frames</a>))[0]
<span class='lineno'> 338</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sampling_is_valid', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sampling_is_valid', title='?'>sampling_is_valid</a> = tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', title='?'>total_num_frames</a>,
<span class='lineno'> 339</span>                                              <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>)
<span class='lineno'> 340</span>         def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_query_start_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_query_start_idx', title='() -> ?'>sample_query_start_idx</a>():
<span class='lineno'> 341</span>           return tf.random_shuffle(
<span class='lineno'> 342</span>               tf.range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', title='?'>total_num_frames</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a> + 1))[0]
<span class='lineno'> 343</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.query_start_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.query_start_idx', title='?'>query_start_idx</a> = tf.cond(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sampling_is_valid', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sampling_is_valid', title='?'>sampling_is_valid</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_query_start_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_query_start_idx', title='() -> ?'>sample_query_start_idx</a>,
<span class='lineno'> 344</span>                                   lambda: tf.constant(0, dtype=tf.int32))
<span class='lineno'> 345</span>         def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_sel_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_sel_indices', title='() -> ?'>sample_sel_indices</a>():
<span class='lineno'> 346</span>           return tf.concat(
<span class='lineno'> 347</span>               [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.ref_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.ref_idx', title='?'>ref_idx</a>[tf.newaxis],
<span class='lineno'> 348</span>                tf.range(
<span class='lineno'> 349</span>                    <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.query_start_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.query_start_idx', title='?'>query_start_idx</a>,
<span class='lineno'> 350</span>                    <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.query_start_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.query_start_idx', title='?'>query_start_idx</a> + (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a> - 1))], axis=0)
<span class='lineno'> 351</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', title='?'>sel_indices</a> = tf.cond(
<span class='lineno'> 352</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sampling_is_valid', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sampling_is_valid', title='?'>sampling_is_valid</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_sel_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_sel_indices', title='() -> ?'>sample_sel_indices</a>,
<span class='lineno'> 353</span>             lambda: tf.zeros((<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>,), dtype=tf.int32))
<span class='lineno'> 354</span>       else:
<span class='lineno'> 355</span>         # Randomly sample some frames from the video.
<span class='lineno'> 356</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', title='?'>sel_indices</a> = tf.random_shuffle(
<span class='lineno'> 357</span>             tf.range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.total_num_frames', title='?'>total_num_frames</a>))[:<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>]
<span class='lineno'> 358</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='?'>image</a> = tf.gather(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', title='?'>sel_indices</a>, axis=0)
<span class='lineno'> 359</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_frames_are_decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_frames_are_decoded', title='bool'>video_frames_are_decoded</a>:
<span class='lineno'> 360</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence', title='(None, str, None, int, ?) -> None / (?, str, None, int, ?) -> None'>decode_image_sequence</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='?'>image</a>)
<span class='lineno'> 361</span> 
<span class='lineno'> 362</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a> is not None:
<span class='lineno'> 363</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a> is not None:
<span class='lineno'> 364</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='?'>label</a> = tf.gather(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sel_indices', title='?'>sel_indices</a>, axis=0)
<span class='lineno'> 365</span>     if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_frames_are_decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_frames_are_decoded', title='bool'>video_frames_are_decoded</a>:
<span class='lineno'> 366</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.decode_image_sequence', title='(None, str, None, int, ?) -> None / (?, str, None, int, ?) -> None'>decode_image_sequence</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>, image_format=&#39;png&#39;, channels=1)
<span class='lineno'> 367</span> 
<span class='lineno'> 368</span>     # Sometimes, label is saved as [num_frames_per_video, height, width] or
<span class='lineno'> 369</span>     # [num_frames_per_video, height, width, 1]. We change it to be
<span class='lineno'> 370</span>     # [num_frames_per_video, height, width, 1].
<span class='lineno'> 371</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>.shape.ndims == 3:
<span class='lineno'> 372</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='?'>label</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>, 3)
<span class='lineno'> 373</span>     elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>.shape.ndims == 4 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>.shape.dims[3] == 1:
<span class='lineno'> 374</span>       pass
<span class='lineno'> 375</span>     else:
<span class='lineno'> 376</span>       raise ValueError(&#39;Input label shape must be &#39;
<span class='lineno'> 377</span>                        &#39;[num_frames_per_video, height, width],&#39;
<span class='lineno'> 378</span>                        &#39; or [num_frames, height, width, 1]. &#39;
<span class='lineno'> 379</span>                        &#39;Got {}&#39;.format(label.shape.ndims))
<span class='lineno'> 380</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>.set_shape([None, None, None, 1])
<span class='lineno'> 381</span> 
<span class='lineno'> 382</span>   # Add size of first dimension since tf can&#39;t figure it out automatically.
<span class='lineno'> 383</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='None'>image</a>.set_shape((<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>, None, None, None))
<span class='lineno'> 384</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a> is not None:
<span class='lineno'> 385</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>.set_shape((<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>, None, None, None))
<span class='lineno'> 386</span> 
<span class='lineno'> 387</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preceding_frame_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preceding_frame_label', title='None'>preceding_frame_label</a> = None
<span class='lineno'> 388</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preprocess_image_and_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preprocess_image_and_label', title='bool'>preprocess_image_and_label</a>:
<span class='lineno'> 389</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a> is None:
<span class='lineno'> 390</span>       raise ValueError(&#39;num_frame_per_video must be specified for preproc.&#39;)
<span class='lineno'> 391</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', title='[?]'>original_images</a> = []
<span class='lineno'> 392</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', title='[?]'>images</a> = []
<span class='lineno'> 393</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a> = []
<span class='lineno'> 394</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', title='bool'>sample_adjacent_and_consistent_query_frames</a>:
<span class='lineno'> 395</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_individual_preproc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_individual_preproc', title='int'>num_frames_individual_preproc</a> = 1
<span class='lineno'> 396</span>     else:
<span class='lineno'> 397</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_individual_preproc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_individual_preproc', title='int'>num_frames_individual_preproc</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>
<span class='lineno'> 398</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', title='int'>frame_idx</a> in range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_individual_preproc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_individual_preproc', title='int'>num_frames_individual_preproc</a>):
<span class='lineno'> 399</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image_t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image_t', title='?'>original_image_t</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_t', title='?'>image_t</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label_t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label_t', title='?'>label_t</a> = (
<span class='lineno'> 400</span>           input_preprocess.preprocess_image_and_label(
<span class='lineno'> 401</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='None'>image</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', title='int'>frame_idx</a>],
<span class='lineno'> 402</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', title='int'>frame_idx</a>],
<span class='lineno'> 403</span>               crop_height=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a>[0] if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a> is not None else None,
<span class='lineno'> 404</span>               crop_width=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a>[1] if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a> is not None else None,
<span class='lineno'> 405</span>               min_resize_value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_resize_value', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_resize_value', title='None'>min_resize_value</a>,
<span class='lineno'> 406</span>               max_resize_value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_resize_value', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_resize_value', title='None'>max_resize_value</a>,
<span class='lineno'> 407</span>               resize_factor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.resize_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.resize_factor', title='None'>resize_factor</a>,
<span class='lineno'> 408</span>               min_scale_factor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_scale_factor', title='float'>min_scale_factor</a>,
<span class='lineno'> 409</span>               max_scale_factor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_scale_factor', title='float'>max_scale_factor</a>,
<span class='lineno'> 410</span>               scale_factor_step_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.scale_factor_step_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.scale_factor_step_size', title='int'>scale_factor_step_size</a>,
<span class='lineno'> 411</span>               ignore_label=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset', title='?'>dataset</a>.ignore_label,
<span class='lineno'> 412</span>               is_training=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', title='bool'>is_training</a>,
<span class='lineno'> 413</span>               model_variant=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.model_variant', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.model_variant', title='None'>model_variant</a>))
<span class='lineno'> 414</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', title='[?]'>original_images</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image_t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image_t', title='?'>original_image_t</a>)
<span class='lineno'> 415</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', title='[?]'>images</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_t', title='?'>image_t</a>)
<span class='lineno'> 416</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label_t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label_t', title='?'>label_t</a>)
<span class='lineno'> 417</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', title='bool'>sample_adjacent_and_consistent_query_frames</a>:
<span class='lineno'> 418</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.imgs_for_preproc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.imgs_for_preproc', title='[?]'>imgs_for_preproc</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='None'>image</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', title='int'>frame_idx</a>] for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', title='int'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', title='int'>frame_idx</a></a> in
<span class='lineno'> 419</span>                           range(1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>)]
<span class='lineno'> 420</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_for_preproc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_for_preproc', title='[?]'>labels_for_preproc</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', title='int'>frame_idx</a>] for <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', title='int'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.frame_idx', title='int'>frame_idx</a></a> in
<span class='lineno'> 421</span>                             range(1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>)]
<span class='lineno'> 422</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image_rest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image_rest', title='?'>original_image_rest</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_rest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_rest', title='?'>image_rest</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label_rest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label_rest', title='?'>label_rest</a> = (
<span class='lineno'> 423</span>           input_preprocess.preprocess_images_and_labels_consistently(
<span class='lineno'> 424</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.imgs_for_preproc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.imgs_for_preproc', title='[?]'>imgs_for_preproc</a>,
<span class='lineno'> 425</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_for_preproc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_for_preproc', title='[?]'>labels_for_preproc</a>,
<span class='lineno'> 426</span>               crop_height=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a>[0] if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a> is not None else None,
<span class='lineno'> 427</span>               crop_width=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a>[1] if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a> is not None else None,
<span class='lineno'> 428</span>               min_resize_value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_resize_value', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_resize_value', title='None'>min_resize_value</a>,
<span class='lineno'> 429</span>               max_resize_value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_resize_value', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_resize_value', title='None'>max_resize_value</a>,
<span class='lineno'> 430</span>               resize_factor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.resize_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.resize_factor', title='None'>resize_factor</a>,
<span class='lineno'> 431</span>               min_scale_factor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.min_scale_factor', title='float'>min_scale_factor</a>,
<span class='lineno'> 432</span>               max_scale_factor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.max_scale_factor', title='float'>max_scale_factor</a>,
<span class='lineno'> 433</span>               scale_factor_step_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.scale_factor_step_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.scale_factor_step_size', title='int'>scale_factor_step_size</a>,
<span class='lineno'> 434</span>               ignore_label=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.dataset', title='?'>dataset</a>.ignore_label,
<span class='lineno'> 435</span>               is_training=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', title='bool'>is_training</a>,
<span class='lineno'> 436</span>               model_variant=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.model_variant', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.model_variant', title='None'>model_variant</a>))
<span class='lineno'> 437</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', title='[?]'>original_images</a>.extend(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image_rest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image_rest', title='?'>original_image_rest</a>)
<span class='lineno'> 438</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', title='[?]'>images</a>.extend(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_rest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_rest', title='?'>image_rest</a>)
<span class='lineno'> 439</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>.extend(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label_rest', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label_rest', title='?'>label_rest</a>)
<span class='lineno'> 440</span>     assert len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', title='[?]'>original_images</a>) == <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>
<span class='lineno'> 441</span>     assert len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', title='[?]'>images</a>) == <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>
<span class='lineno'> 442</span>     assert len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>) == <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>
<span class='lineno'> 443</span> 
<span class='lineno'> 444</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remap_labels_to_reference_frame', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remap_labels_to_reference_frame', title='bool'>remap_labels_to_reference_frame</a>:
<span class='lineno'> 445</span>       # Remap labels to indices into the labels of the (downscaled) reference
<span class='lineno'> 446</span>       # frame, or 0, i.e. background, for labels which are not present
<span class='lineno'> 447</span>       # in the reference.
<span class='lineno'> 448</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.reference_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.reference_labels', title='?'>reference_labels</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>[0][tf.newaxis]
<span class='lineno'> 449</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.h', title='?'>h</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.w', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.w', title='?'>w</a> = train_utils.resolve_shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.reference_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.reference_labels', title='?'>reference_labels</a>)[1:3]
<span class='lineno'> 450</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.embedding_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.embedding_height', title='?'>embedding_height</a> = model.scale_dimension(
<span class='lineno'> 451</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.h', title='?'>h</a>, 1.0 / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.decoder_output_stride', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.decoder_output_stride', title='None'>decoder_output_stride</a>)
<span class='lineno'> 452</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.embedding_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.embedding_width', title='?'>embedding_width</a> = model.scale_dimension(
<span class='lineno'> 453</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.w', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.w', title='?'>w</a>, 1.0 / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.decoder_output_stride', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.decoder_output_stride', title='None'>decoder_output_stride</a>)
<span class='lineno'> 454</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.reference_labels_embedding_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.reference_labels_embedding_size', title='?'>reference_labels_embedding_size</a> = tf.squeeze(
<span class='lineno'> 455</span>           tf.image.resize_nearest_neighbor(
<span class='lineno'> 456</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.reference_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.reference_labels', title='?'>reference_labels</a>, tf.stack([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.embedding_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.embedding_height', title='?'>embedding_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.embedding_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.embedding_width', title='?'>embedding_width</a>]),
<span class='lineno'> 457</span>               align_corners=True),
<span class='lineno'> 458</span>           axis=0)
<span class='lineno'> 459</span>       # Get sorted unique labels in the reference frame.
<span class='lineno'> 460</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_in_ref_frame', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_in_ref_frame', title='?'>labels_in_ref_frame</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get._', title='?'>_</a> = tf.unique(
<span class='lineno'> 461</span>           tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.reference_labels_embedding_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.reference_labels_embedding_size', title='?'>reference_labels_embedding_size</a>, [-1]))
<span class='lineno'> 462</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_in_ref_frame', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_in_ref_frame', title='?'>labels_in_ref_frame</a> = tf.contrib.framework.sort(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_in_ref_frame', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_in_ref_frame', title='?'>labels_in_ref_frame</a>)
<span class='lineno'> 463</span>       for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.idx', title='int'>idx</a> in range(1, len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>)):
<span class='lineno'> 464</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.ref_label_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.ref_label_mask', title='?'>ref_label_mask</a> = tf.equal(
<span class='lineno'> 465</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.idx', title='int'>idx</a>],
<span class='lineno'> 466</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_in_ref_frame', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels_in_ref_frame', title='?'>labels_in_ref_frame</a>[tf.newaxis, tf.newaxis, :])
<span class='lineno'> 467</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remapped', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remapped', title='?'>remapped</a> = tf.argmax(tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.ref_label_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.ref_label_mask', title='?'>ref_label_mask</a>, tf.uint8), axis=-1,
<span class='lineno'> 468</span>                              output_type=tf.int32)
<span class='lineno'> 469</span>         # Set to 0 if label is not present
<span class='lineno'> 470</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_in_ref', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_in_ref', title='?'>is_in_ref</a> = tf.reduce_any(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.ref_label_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.ref_label_mask', title='?'>ref_label_mask</a>, axis=-1)
<span class='lineno'> 471</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remapped', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remapped', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remapped', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remapped', title='?'>remapped</a></a> *= tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_in_ref', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_in_ref', title='?'>is_in_ref</a>, tf.int32)
<span class='lineno'> 472</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.idx', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.idx', title='int'>idx</a>] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remapped', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.remapped', title='?'>remapped</a>[..., tf.newaxis]
<span class='lineno'> 473</span> 
<span class='lineno'> 474</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample_adjacent_and_consistent_query_frames', title='bool'>sample_adjacent_and_consistent_query_frames</a>:
<span class='lineno'> 475</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_frame_finetuning', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_frame_finetuning', title='bool'>first_frame_finetuning</a> and <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.generate_prev_frame_mask_by_mask_damaging', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.generate_prev_frame_mask_by_mask_damaging', title='bool'>generate_prev_frame_mask_by_mask_damaging</a>:
<span class='lineno'> 476</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preceding_frame_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preceding_frame_label', title='?'>preceding_frame_label</a> = mask_damaging.damage_masks(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>[1])
<span class='lineno'> 477</span>       elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.add_prev_frame_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.add_prev_frame_label', title='bool'>add_prev_frame_label</a>:
<span class='lineno'> 478</span>         # Discard the image of the additional frame and take the label as
<span class='lineno'> 479</span>         # initialization for softmax feedback.
<span class='lineno'> 480</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', title='[?]'>original_images</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', title='[?]'>original_images</a>[0]] + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', title='[?]'>original_images</a>[2:]
<span class='lineno'> 481</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preceding_frame_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preceding_frame_label', title='?'>preceding_frame_label</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>[1]
<span class='lineno'> 482</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', title='[?]'>images</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', title='[?]'>images</a>[0]] + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', title='[?]'>images</a>[2:]
<span class='lineno'> 483</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>[0]] + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>[2:]
<span class='lineno'> 484</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a></a> -= 1
<span class='lineno'> 485</span> 
<span class='lineno'> 486</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image', title='?'>original_image</a> = tf.stack(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_images', title='[?]'>original_images</a>, axis=0)
<span class='lineno'> 487</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='?'>image</a> = tf.stack(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.images', title='[?]'>images</a>, axis=0)
<span class='lineno'> 488</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='?'>label</a> = tf.stack(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.labels', title='[?]'>labels</a>, axis=0)
<span class='lineno'> 489</span>   else:
<span class='lineno'> 490</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a> is not None:
<span class='lineno'> 491</span>       # Need to set label shape due to batching.
<span class='lineno'> 492</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>.set_shape([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>,
<span class='lineno'> 493</span>                        None if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a> is None else <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a>[0],
<span class='lineno'> 494</span>                        None if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a> is None else <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a>[1],
<span class='lineno'> 495</span>                        1])
<span class='lineno'> 496</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image', title='?'>original_image</a> = tf.to_float(tf.zeros_like(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>))
<span class='lineno'> 497</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a> is None:
<span class='lineno'> 498</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.height', title='?'>height</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='None'>image</a>)[1]
<span class='lineno'> 499</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.width', title='?'>width</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='None'>image</a>)[2]
<span class='lineno'> 500</span>     else:
<span class='lineno'> 501</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.height', title='?'>height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a>[0]
<span class='lineno'> 502</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.width', title='?'>width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.crop_size', title='?'>crop_size</a>[1]
<span class='lineno'> 503</span> 
<span class='lineno'> 504</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', title='dict'>sample</a> = {&#39;image&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image', title='None'>image</a>,
<span class='lineno'> 505</span>             &#39;image_name&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.image_name', title='?'>image_name</a>,
<span class='lineno'> 506</span>             &#39;height&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.height', title='?'>height</a>,
<span class='lineno'> 507</span>             &#39;width&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.width', title='?'>width</a>,
<span class='lineno'> 508</span>             &#39;video_id&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.video_id', title='?'>video_id</a>}
<span class='lineno'> 509</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a> is not None:
<span class='lineno'> 510</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', title='dict'>sample</a>[&#39;label&#39;] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>
<span class='lineno'> 511</span> 
<span class='lineno'> 512</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.object_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.object_label', title='None'>object_label</a> is not None:
<span class='lineno'> 513</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', title='dict'>sample</a>[&#39;object_label&#39;] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.object_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.object_label', title='None'>object_label</a>
<span class='lineno'> 514</span> 
<span class='lineno'> 515</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preceding_frame_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preceding_frame_label', title='None'>preceding_frame_label</a> is not None:
<span class='lineno'> 516</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', title='dict'>sample</a>[&#39;preceding_frame_label&#39;] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preceding_frame_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.preceding_frame_label', title='None'>preceding_frame_label</a>
<span class='lineno'> 517</span> 
<span class='lineno'> 518</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', title='bool'>is_training</a>:
<span class='lineno'> 519</span>     # Original image is only used during visualization.
<span class='lineno'> 520</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', title='dict'>sample</a>[&#39;original_image&#39;] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.original_image', title='?'>original_image</a>
<span class='lineno'> 521</span> 
<span class='lineno'> 522</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.is_training', title='bool'>is_training</a>:
<span class='lineno'> 523</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_frame_finetuning', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_frame_finetuning', title='bool'>first_frame_finetuning</a>:
<span class='lineno'> 524</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.keep_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.keep_input', title='?'>keep_input</a> = tf.constant(True)
<span class='lineno'> 525</span>     else:
<span class='lineno'> 526</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.keep_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.keep_input', title='?'>keep_input</a> = tf.logical_and(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sampling_is_valid', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sampling_is_valid', title='?'>sampling_is_valid</a>, tf.logical_and(
<span class='lineno'> 527</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_enough_pixels_of_each_object_in_first_frame', title='(None, None) -> None / (?, ?) -> None'>_has_enough_pixels_of_each_object_in_first_frame</a>(
<span class='lineno'> 528</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.decoder_output_stride', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.decoder_output_stride', title='None'>decoder_output_stride</a>),
<span class='lineno'> 529</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator._has_foreground_and_background_in_first_frame_2', title='(?, ?) -> None / (None, None) -> None'>_has_foreground_and_background_in_first_frame_2</a>(
<span class='lineno'> 530</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.decoder_output_stride', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.decoder_output_stride', title='None'>decoder_output_stride</a>)))
<span class='lineno'> 531</span> 
<span class='lineno'> 532</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', title='?'>batched</a> = tf.train.maybe_batch(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', title='dict'>sample</a>,
<span class='lineno'> 533</span>                                    keep_input=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.keep_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.keep_input', title='?'>keep_input</a>,
<span class='lineno'> 534</span>                                    batch_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', title='?'>batch_size</a>,
<span class='lineno'> 535</span>                                    num_threads=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_threads', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_threads', title='int'>num_threads</a>,
<span class='lineno'> 536</span>                                    capacity=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_capacity_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_capacity_factor', title='int'>batch_capacity_factor</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', title='?'>batch_size</a>,
<span class='lineno'> 537</span>                                    dynamic_pad=True)
<span class='lineno'> 538</span>   else:
<span class='lineno'> 539</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', title='?'>batched</a> = tf.train.batch(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.sample', title='dict'>sample</a>,
<span class='lineno'> 540</span>                              batch_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', title='?'>batch_size</a>,
<span class='lineno'> 541</span>                              num_threads=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_threads', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_threads', title='int'>num_threads</a>,
<span class='lineno'> 542</span>                              capacity=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_capacity_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_capacity_factor', title='int'>batch_capacity_factor</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', title='?'>batch_size</a>,
<span class='lineno'> 543</span>                              dynamic_pad=True)
<span class='lineno'> 544</span> 
<span class='lineno'> 545</span>   # Flatten from [batch, num_frames_per_video, ...] to
<span class='lineno'> 546</span>   # batch * num_frames_per_video, ...].
<span class='lineno'> 547</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_height', title='?'>cropped_height</a> = train_utils.resolve_shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', title='?'>batched</a>[&#39;image&#39;])[2]
<span class='lineno'> 548</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_width', title='?'>cropped_width</a> = train_utils.resolve_shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', title='?'>batched</a>[&#39;image&#39;])[3]
<span class='lineno'> 549</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a> is None:
<span class='lineno'> 550</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_dim', title='int'>first_dim</a> = -1
<span class='lineno'> 551</span>   else:
<span class='lineno'> 552</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_dim', title='int'>first_dim</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batch_size', title='?'>batch_size</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.num_frames_per_video', title='int'>num_frames_per_video</a>
<span class='lineno'> 553</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', title='?'>batched</a>[&#39;image&#39;] = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', title='?'>batched</a>[&#39;image&#39;],
<span class='lineno'> 554</span>                                 [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_dim', title='int'>first_dim</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_height', title='?'>cropped_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_width', title='?'>cropped_width</a>, 3])
<span class='lineno'> 555</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.label', title='None'>label</a> is not None:
<span class='lineno'> 556</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', title='?'>batched</a>[&#39;label&#39;] = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', title='?'>batched</a>[&#39;label&#39;],
<span class='lineno'> 557</span>                                   [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.first_dim', title='int'>first_dim</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_height', title='?'>cropped_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.cropped_width', title='?'>cropped_width</a>, 1])
<span class='lineno'> 558</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.feelvos.utils.video_input_generator.get.batched', title='?'>batched</a>
</pre></td></tr></table></body></html>