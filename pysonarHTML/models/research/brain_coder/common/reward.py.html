<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/brain_coder/common/reward.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff'>abs_diff</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff'>mod_abs_diff</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance'>absolute_distance</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance'>log_absolute_distance</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward'>absolute_distance_reward</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward'>absolute_mod_distance_reward</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward'>absolute_log_distance_reward</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager'>RewardManager</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__metaclass__', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__metaclass__'>__metaclass__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__call__', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__call__'>__call__</a></li></ul>
</li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager'>DeltaRewardManager</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff'>_diff</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward'>_delta_reward</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__'>__call__</a></li></ul>
</li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager'>FloorRewardManager</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff'>_max_diff</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff'>_diff</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward'>_delta_reward</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__', xid='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__'>__call__</a></li></ul>
</li></ul>
</td><td><pre><span class='lineno'>   1</span> from __future__ import absolute_import
<span class='lineno'>   2</span> from __future__ import division
<span class='lineno'>   3</span> from __future__ import print_function
<span class='lineno'>   4</span> 
<span class='lineno'>   5</span> &quot;&quot;&quot;Reward functions, distance functions, and reward managers.&quot;&quot;&quot;
<span class='lineno'>   6</span> 
<span class='lineno'>   7</span> from abc import ABCMeta
<span class='lineno'>   8</span> from abc import abstractmethod
<span class='lineno'>   9</span> from math import log
<span class='lineno'>  10</span> 
<span class='lineno'>  11</span> 
<span class='lineno'>  12</span> # All sequences here are assumed to be lists of ints bounded
<span class='lineno'>  13</span> # between 0 and `base`-1 (inclusive).
<span class='lineno'>  14</span> 
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> #################################
<span class='lineno'>  17</span> ### Scalar Distance Functions ###
<span class='lineno'>  18</span> #################################
<span class='lineno'>  19</span> 
<span class='lineno'>  20</span> 
<span class='lineno'>  21</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff', title='(?, ?, int) -> int / (?, ?, ?) -> int'>abs_diff</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.a', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.a', title='?'>a</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.b', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.b', title='?'>b</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.base', title='int'>base</a>=0):
<span class='lineno'>  22</span>   &quot;&quot;&quot;Absolute value of difference between scalars.
<span class='lineno'>  23</span> 
<span class='lineno'>  24</span>   abs_diff is symmetric, i.e. `a` and `b` are interchangeable.
<span class='lineno'>  25</span> 
<span class='lineno'>  26</span>   Args:
<span class='lineno'>  27</span>     a: First argument. An int.
<span class='lineno'>  28</span>     b: Seconds argument. An int.
<span class='lineno'>  29</span>     base: Dummy argument so that the argument signature matches other scalar
<span class='lineno'>  30</span>         diff functions. abs_diff is the same in all bases.
<span class='lineno'>  31</span> 
<span class='lineno'>  32</span>   Returns:
<span class='lineno'>  33</span>     abs(a - b).
<span class='lineno'>  34</span>   &quot;&quot;&quot;
<span class='lineno'>  35</span>   del <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.base', title='int'>base</a>  # Unused.
<span class='lineno'>  36</span>   return abs(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.a', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.a', title='?'>a</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.b', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff.b', title='?'>b</a>)
<span class='lineno'>  37</span> 
<span class='lineno'>  38</span> 
<span class='lineno'>  39</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff', title='(?, ?, ?) -> int'>mod_abs_diff</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.a', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.a', title='?'>a</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.b', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.b', title='?'>b</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.base', title='?'>base</a>):
<span class='lineno'>  40</span>   &quot;&quot;&quot;Shortest distance between `a` and `b` in the modular integers base `base`.
<span class='lineno'>  41</span> 
<span class='lineno'>  42</span>   The smallest distance between a and b is returned.
<span class='lineno'>  43</span>   Example: mod_abs_diff(1, 99, 100) ==&gt; 2. It is not 98.
<span class='lineno'>  44</span> 
<span class='lineno'>  45</span>   mod_abs_diff is symmetric, i.e. `a` and `b` are interchangeable.
<span class='lineno'>  46</span> 
<span class='lineno'>  47</span>   Args:
<span class='lineno'>  48</span>     a: First argument. An int.
<span class='lineno'>  49</span>     b: Seconds argument. An int.
<span class='lineno'>  50</span>     base: The modulo base. A positive int.
<span class='lineno'>  51</span> 
<span class='lineno'>  52</span>   Returns:
<span class='lineno'>  53</span>     Shortest distance.
<span class='lineno'>  54</span>   &quot;&quot;&quot;
<span class='lineno'>  55</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', title='int'>diff</a> = abs(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.a', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.a', title='?'>a</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.b', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.b', title='?'>b</a>)
<span class='lineno'>  56</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', title='int'>diff</a> &gt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.base', title='?'>base</a>:
<span class='lineno'>  57</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', title='int'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', title='int'>diff</a></a> %= <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.base', title='?'>base</a>
<span class='lineno'>  58</span>   return min(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', title='int'>diff</a>, (-<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.diff', title='int'>diff</a>) + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff.base', title='?'>base</a>)
<span class='lineno'>  59</span> 
<span class='lineno'>  60</span> 
<span class='lineno'>  61</span> ###############################
<span class='lineno'>  62</span> ### List Distance Functions ###
<span class='lineno'>  63</span> ###############################
<span class='lineno'>  64</span> 
<span class='lineno'>  65</span> 
<span class='lineno'>  66</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>absolute_distance</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.pred', title='?'>pred</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target', title='?'>target</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.base', title='?'>base</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.scalar_diff_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.scalar_diff_fn', title='(?, ?, int) -> int / (?, ?, ?) -> int'>scalar_diff_fn</a>=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff', title='(?, ?, int) -> int / (?, ?, ?) -> int'>abs_diff</a>):
<span class='lineno'>  67</span>   &quot;&quot;&quot;Asymmetric list distance function.
<span class='lineno'>  68</span> 
<span class='lineno'>  69</span>   List distance is the sum of element-wise distances, like Hamming distance, but
<span class='lineno'>  70</span>   where `pred` can be longer or shorter than `target`. For each position in both
<span class='lineno'>  71</span>   `pred` and `target`, distance between those elements is computed with
<span class='lineno'>  72</span>   `scalar_diff_fn`. For missing or extra elements in `pred`, the maximum
<span class='lineno'>  73</span>   distance is assigned, which is equal to `base`.
<span class='lineno'>  74</span> 
<span class='lineno'>  75</span>   Distance is 0 when `pred` and `target` are identical, and will be a positive
<span class='lineno'>  76</span>   integer when they are not.
<span class='lineno'>  77</span> 
<span class='lineno'>  78</span>   Args:
<span class='lineno'>  79</span>     pred: Prediction list. Distance from this list is computed.
<span class='lineno'>  80</span>     target: Target list. Distance to this list is computed.
<span class='lineno'>  81</span>     base: The integer base to use. For example, a list of chars would use base
<span class='lineno'>  82</span>         256.
<span class='lineno'>  83</span>     scalar_diff_fn: Element-wise distance function.
<span class='lineno'>  84</span> 
<span class='lineno'>  85</span>   Returns:
<span class='lineno'>  86</span>     List distance between `pred` and `target`.
<span class='lineno'>  87</span>   &quot;&quot;&quot;
<span class='lineno'>  88</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', title='int'>d</a> = 0
<span class='lineno'>  89</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.i', title='?'>i</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target_t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target_t', title='?'>target_t</a> in enumerate(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target', title='?'>target</a>):
<span class='lineno'>  90</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.i', title='?'>i</a> &gt;= len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.pred', title='?'>pred</a>):
<span class='lineno'>  91</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', title='int'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', title='int'>d</a></a> += <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.base', title='?'>base</a>  # A missing slot is worth the max distance.
<span class='lineno'>  92</span>     else:
<span class='lineno'>  93</span>       # Add element-wise distance for this slot.
<span class='lineno'>  94</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', title='int'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', title='int'>d</a></a> += <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.scalar_diff_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.scalar_diff_fn', title='(?, ?, int) -> int / (?, ?, ?) -> int'>scalar_diff_fn</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.pred', title='?'>pred</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.i', title='?'>i</a>], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target_t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target_t', title='?'>target_t</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.base', title='?'>base</a>)
<span class='lineno'>  95</span>   if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.pred', title='?'>pred</a>) &gt; len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target', title='?'>target</a>):
<span class='lineno'>  96</span>     # Each extra slot is worth the max distance.
<span class='lineno'>  97</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', title='int'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', title='int'>d</a></a> += (len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.pred', title='?'>pred</a>) - len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.target', title='?'>target</a>)) * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.base', title='?'>base</a>
<span class='lineno'>  98</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance.d', title='int'>d</a>
<span class='lineno'>  99</span> 
<span class='lineno'> 100</span> 
<span class='lineno'> 101</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance', title='(?, ?, ?) -> float'>log_absolute_distance</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', title='?'>pred</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', title='?'>target</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.base', title='?'>base</a>):
<span class='lineno'> 102</span>   &quot;&quot;&quot;Asymmetric list distance function that uses log distance.
<span class='lineno'> 103</span> 
<span class='lineno'> 104</span>   A list distance which computes sum of element-wise distances, similar to
<span class='lineno'> 105</span>   `absolute_distance`. Unlike `absolute_distance`, this scales the resulting
<span class='lineno'> 106</span>   distance to be a float.
<span class='lineno'> 107</span> 
<span class='lineno'> 108</span>   Element-wise distance are log-scale. Distance between two list changes
<span class='lineno'> 109</span>   relatively less for elements that are far apart, but changes a lot (goes to 0
<span class='lineno'> 110</span>   faster) when values get close together.
<span class='lineno'> 111</span> 
<span class='lineno'> 112</span>   Args:
<span class='lineno'> 113</span>     pred: List of ints. Computes distance from this list to the target.
<span class='lineno'> 114</span>     target: List of ints. This is the &quot;correct&quot; list which the prediction list
<span class='lineno'> 115</span>         is trying to match.
<span class='lineno'> 116</span>     base: Integer base.
<span class='lineno'> 117</span> 
<span class='lineno'> 118</span>   Returns:
<span class='lineno'> 119</span>     Float distance normalized so that when `pred` is at most as long as `target`
<span class='lineno'> 120</span>     the distance is between 0.0 and 1.0. Distance grows unboundedly large
<span class='lineno'> 121</span>     as `pred` grows past `target` in length.
<span class='lineno'> 122</span>   &quot;&quot;&quot;
<span class='lineno'> 123</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', title='?'>target</a>:
<span class='lineno'> 124</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.length_normalizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.length_normalizer', title='float'>length_normalizer</a> = 1.0
<span class='lineno'> 125</span>     if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', title='?'>pred</a>:
<span class='lineno'> 126</span>       # Distance between [] and [] is 0.0 since they are equal.
<span class='lineno'> 127</span>       return 0.0
<span class='lineno'> 128</span>   else:
<span class='lineno'> 129</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.length_normalizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.length_normalizer', title='float'>length_normalizer</a> = float(len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', title='?'>target</a>))
<span class='lineno'> 130</span>   # max_dist is the maximum element-wise distance, before taking log and
<span class='lineno'> 131</span>   # scaling. Since we use `mod_abs_diff`, it would be (base // 2), but we add
<span class='lineno'> 132</span>   # 1 to it so that missing or extra positions get the maximum penalty.
<span class='lineno'> 133</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.max_dist', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.max_dist', title='int'>max_dist</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.base', title='?'>base</a> // 2 + 1
<span class='lineno'> 134</span> 
<span class='lineno'> 135</span>   # The log-distance will be scaled by a factor.
<span class='lineno'> 136</span>   # Note: +1 is added to the numerator and denominator to avoid log(0). This
<span class='lineno'> 137</span>   # only has a translational effect, i.e. log(dist + 1) / log(max_dist + 1).
<span class='lineno'> 138</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.factor', title='int'>factor</a> = log(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.max_dist', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.max_dist', title='int'>max_dist</a> + 1)
<span class='lineno'> 139</span> 
<span class='lineno'> 140</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', title='float'>d</a> = 0.0  # Total distance to be computed.
<span class='lineno'> 141</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.i', title='?'>i</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target_t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target_t', title='?'>target_t</a> in enumerate(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', title='?'>target</a>):
<span class='lineno'> 142</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.i', title='?'>i</a> &gt;= len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', title='?'>pred</a>):
<span class='lineno'> 143</span>       # Assign the max element-wise distance for missing positions. This is 1.0
<span class='lineno'> 144</span>       # after scaling.
<span class='lineno'> 145</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', title='float'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', title='float'>d</a></a> += 1.0
<span class='lineno'> 146</span>     else:
<span class='lineno'> 147</span>       # Add the log-dist divided by a scaling factor.
<span class='lineno'> 148</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', title='float'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', title='float'>d</a></a> += log(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff', title='(?, ?, ?) -> int'>mod_abs_diff</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', title='?'>pred</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.i', title='?'>i</a>], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target_t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target_t', title='?'>target_t</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.base', title='?'>base</a>) + 1) / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.factor', title='int'>factor</a>
<span class='lineno'> 149</span>   if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', title='?'>pred</a>) &gt; len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', title='?'>target</a>):
<span class='lineno'> 150</span>     # Add the max element-wise distance for each extra position.
<span class='lineno'> 151</span>     # Since max dist after scaling is 1, this is just the difference in list
<span class='lineno'> 152</span>     # lengths.
<span class='lineno'> 153</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', title='float'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', title='float'>d</a></a> += (len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.pred', title='?'>pred</a>) - len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.target', title='?'>target</a>))
<span class='lineno'> 154</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.d', title='float'>d</a> / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.length_normalizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance.length_normalizer', title='float'>length_normalizer</a>  # Normalize again by the target length.
<span class='lineno'> 155</span> 
<span class='lineno'> 156</span> 
<span class='lineno'> 157</span> ########################
<span class='lineno'> 158</span> ### Reward Functions ###
<span class='lineno'> 159</span> ########################
<span class='lineno'> 160</span> 
<span class='lineno'> 161</span> # Reward functions assign reward based on program output.
<span class='lineno'> 162</span> # Warning: only use these functions as the terminal rewards in episodes, i.e.
<span class='lineno'> 163</span> # for the &quot;final&quot; programs.
<span class='lineno'> 164</span> 
<span class='lineno'> 165</span> 
<span class='lineno'> 166</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward', title='(?, ?, ?, (?, ?, ?) -> int) -> float / (?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> float'>absolute_distance_reward</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.pred', title='?'>pred</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.target', title='?'>target</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.base', title='?'>base</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.scalar_diff_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.scalar_diff_fn', title='{(?, ?, ?) -> int | (?, ?, int) -> int / (?, ?, ?) -> int}'>scalar_diff_fn</a>=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.abs_diff', title='(?, ?, int) -> int / (?, ?, ?) -> int'>abs_diff</a>):
<span class='lineno'> 167</span>   &quot;&quot;&quot;Reward function based on absolute_distance function.
<span class='lineno'> 168</span> 
<span class='lineno'> 169</span>   Maximum reward, 1.0, is given when the lists are equal. Reward is scaled
<span class='lineno'> 170</span>   so that 0.0 reward is given when `pred` is the empty list (assuming `target`
<span class='lineno'> 171</span>   is not empty). Reward can go negative when `pred` is longer than `target`.
<span class='lineno'> 172</span> 
<span class='lineno'> 173</span>   This is an asymmetric reward function, so which list is the prediction and
<span class='lineno'> 174</span>   which is the target matters.
<span class='lineno'> 175</span> 
<span class='lineno'> 176</span>   Args:
<span class='lineno'> 177</span>     pred: Prediction sequence. This should be the sequence outputted by the
<span class='lineno'> 178</span>         generated code. List of ints n, where 0 &lt;= n &lt; base.
<span class='lineno'> 179</span>     target: Target sequence. The correct sequence that the generated code needs
<span class='lineno'> 180</span>         to output. List of ints n, where 0 &lt;= n &lt; base.
<span class='lineno'> 181</span>     base: Base of the computation.
<span class='lineno'> 182</span>     scalar_diff_fn: Element-wise distance function.
<span class='lineno'> 183</span> 
<span class='lineno'> 184</span>   Returns:
<span class='lineno'> 185</span>     Reward computed based on `pred` and `target`. A float.
<span class='lineno'> 186</span>   &quot;&quot;&quot;
<span class='lineno'> 187</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.unit_dist', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.unit_dist', title='float'>unit_dist</a> = float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.base', title='?'>base</a> * len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.target', title='?'>target</a>))
<span class='lineno'> 188</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.unit_dist', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.unit_dist', title='float'>unit_dist</a> == 0:
<span class='lineno'> 189</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.unit_dist', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.unit_dist', title='?'>unit_dist</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.base', title='?'>base</a>
<span class='lineno'> 190</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.dist', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.dist', title='int'>dist</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>absolute_distance</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.pred', title='?'>pred</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.target', title='?'>target</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.base', title='?'>base</a>, scalar_diff_fn=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.scalar_diff_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.scalar_diff_fn', title='{(?, ?, ?) -> int | (?, ?, int) -> int / (?, ?, ?) -> int}'>scalar_diff_fn</a>)
<span class='lineno'> 191</span>   return (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.unit_dist', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.unit_dist', title='float'>unit_dist</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.dist', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.dist', title='int'>dist</a>) / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.unit_dist', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward.unit_dist', title='float'>unit_dist</a>
<span class='lineno'> 192</span> 
<span class='lineno'> 193</span> 
<span class='lineno'> 194</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward', title='(?, ?, ?) -> float'>absolute_mod_distance_reward</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.pred', title='?'>pred</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.target', title='?'>target</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.base', title='?'>base</a>):
<span class='lineno'> 195</span>   &quot;&quot;&quot;Same as `absolute_distance_reward` but `mod_abs_diff` scalar diff is used.
<span class='lineno'> 196</span> 
<span class='lineno'> 197</span>   Args:
<span class='lineno'> 198</span>     pred: Prediction sequence. This should be the sequence outputted by the
<span class='lineno'> 199</span>         generated code. List of ints n, where 0 &lt;= n &lt; base.
<span class='lineno'> 200</span>     target: Target sequence. The correct sequence that the generated code needs
<span class='lineno'> 201</span>         to output. List of ints n, where 0 &lt;= n &lt; base.
<span class='lineno'> 202</span>     base: Base of the computation.
<span class='lineno'> 203</span> 
<span class='lineno'> 204</span>   Returns:
<span class='lineno'> 205</span>     Reward computed based on `pred` and `target`. A float.
<span class='lineno'> 206</span>   &quot;&quot;&quot;
<span class='lineno'> 207</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance_reward', title='(?, ?, ?, (?, ?, ?) -> int) -> float / (?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> float'>absolute_distance_reward</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.pred', title='?'>pred</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.target', title='?'>target</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_mod_distance_reward.base', title='?'>base</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.mod_abs_diff', title='(?, ?, ?) -> int'>mod_abs_diff</a>)
<span class='lineno'> 208</span> 
<span class='lineno'> 209</span> 
<span class='lineno'> 210</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward', title='(?, ?, ?) -> float'>absolute_log_distance_reward</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.pred', title='?'>pred</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.target', title='?'>target</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.base', title='?'>base</a>):
<span class='lineno'> 211</span>   &quot;&quot;&quot;Compute reward using `log_absolute_distance`.
<span class='lineno'> 212</span> 
<span class='lineno'> 213</span>   Maximum reward, 1.0, is given when the lists are equal. Reward is scaled
<span class='lineno'> 214</span>   so that 0.0 reward is given when `pred` is the empty list (assuming `target`
<span class='lineno'> 215</span>   is not empty). Reward can go negative when `pred` is longer than `target`.
<span class='lineno'> 216</span> 
<span class='lineno'> 217</span>   This is an asymmetric reward function, so which list is the prediction and
<span class='lineno'> 218</span>   which is the target matters.
<span class='lineno'> 219</span> 
<span class='lineno'> 220</span>   This reward function has the nice property that much more reward is given
<span class='lineno'> 221</span>   for getting the correct value (at each position) than for there being any
<span class='lineno'> 222</span>   value at all. For example, in base 100, lets say pred = [1] * 1000
<span class='lineno'> 223</span>   and target = [10] * 1000. A lot of reward would be given for being 80%
<span class='lineno'> 224</span>   accurate (worst element-wise distance is 50, distances here are 9) using
<span class='lineno'> 225</span>   `absolute_distance`. `log_absolute_distance` on the other hand will give
<span class='lineno'> 226</span>   greater and greater reward increments the closer each predicted value gets to
<span class='lineno'> 227</span>   the target. That makes the reward given for accuracy somewhat independant of
<span class='lineno'> 228</span>   the base.
<span class='lineno'> 229</span> 
<span class='lineno'> 230</span>   Args:
<span class='lineno'> 231</span>     pred: Prediction sequence. This should be the sequence outputted by the
<span class='lineno'> 232</span>         generated code. List of ints n, where 0 &lt;= n &lt; base.
<span class='lineno'> 233</span>     target: Target sequence. The correct sequence that the generated code needs
<span class='lineno'> 234</span>         to output. List of ints n, where 0 &lt;= n &lt; base.
<span class='lineno'> 235</span>     base: Base of the computation.
<span class='lineno'> 236</span> 
<span class='lineno'> 237</span>   Returns:
<span class='lineno'> 238</span>     Reward computed based on `pred` and `target`. A float.
<span class='lineno'> 239</span>   &quot;&quot;&quot;
<span class='lineno'> 240</span>   return 1.0 - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.log_absolute_distance', title='(?, ?, ?) -> float'>log_absolute_distance</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.pred', title='?'>pred</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.target', title='?'>target</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_log_distance_reward.base', title='?'>base</a>)
<span class='lineno'> 241</span> 
<span class='lineno'> 242</span> 
<span class='lineno'> 243</span> #######################
<span class='lineno'> 244</span> ### Reward Managers ###
<span class='lineno'> 245</span> #######################
<span class='lineno'> 246</span> 
<span class='lineno'> 247</span> # Reward managers assign reward to many code attempts throughout an episode.
<span class='lineno'> 248</span> 
<span class='lineno'> 249</span> 
<span class='lineno'> 250</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager', title='<RewardManager>'>RewardManager</a>(object):
<span class='lineno'> 251</span>   &quot;&quot;&quot;Reward managers administer reward across an episode.
<span class='lineno'> 252</span> 
<span class='lineno'> 253</span>   Reward managers are used for &quot;editor&quot; environments. These are environments
<span class='lineno'> 254</span>   where the agent has some way to edit its code over time, and run its code
<span class='lineno'> 255</span>   many time in the same episode, so that it can make incremental improvements.
<span class='lineno'> 256</span> 
<span class='lineno'> 257</span>   Reward managers are instantiated with a target sequence, which is the known
<span class='lineno'> 258</span>   correct program output. The manager is called on the output from a proposed
<span class='lineno'> 259</span>   code, and returns reward. If many proposal outputs are tried, reward may be
<span class='lineno'> 260</span>   some stateful function that takes previous tries into account. This is done,
<span class='lineno'> 261</span>   in part, so that an agent cannot accumulate unbounded reward just by trying
<span class='lineno'> 262</span>   junk programs as often as possible. So reward managers should not give the
<span class='lineno'> 263</span>   same reward twice if the next proposal is not better than the last.
<span class='lineno'> 264</span>   &quot;&quot;&quot;
<span class='lineno'> 265</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__metaclass__', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__metaclass__', title='?'>__metaclass__</a> = ABCMeta
<span class='lineno'> 266</span> 
<span class='lineno'> 267</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.self', title='RewardManager'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.target', title='?'>target</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.base', title='?'>base</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.distance_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.distance_fn', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>distance_fn</a>=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>absolute_distance</a>):
<span class='lineno'> 268</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.self', title='RewardManager'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._target', title='list'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._target', title='list'>_target</a></a> = list(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.target', title='?'>target</a>)
<span class='lineno'> 269</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.self', title='RewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._base', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._base', title='?'>_base</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.base', title='?'>base</a>
<span class='lineno'> 270</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.self', title='RewardManager'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._distance_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._distance_fn', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._distance_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager._distance_fn', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>_distance_fn</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.distance_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__init__.distance_fn', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>distance_fn</a>
<span class='lineno'> 271</span> 
<span class='lineno'> 272</span>   @abstractmethod
<span class='lineno'> 273</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__call__', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__call__', title='(RewardManager, ?) -> float'>__call__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__call__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__call__.self', title='RewardManager'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__call__.sequence', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager.__call__.sequence', title='?'>sequence</a>):
<span class='lineno'> 274</span>     &quot;&quot;&quot;Call this reward manager like a function to get reward.
<span class='lineno'> 275</span> 
<span class='lineno'> 276</span>     Calls to reward manager are stateful, and will take previous sequences
<span class='lineno'> 277</span>     into account. Repeated calls with the same sequence may produce different
<span class='lineno'> 278</span>     rewards.
<span class='lineno'> 279</span> 
<span class='lineno'> 280</span>     Args:
<span class='lineno'> 281</span>       sequence: List of integers (each between 0 and base - 1). This is the
<span class='lineno'> 282</span>           proposal sequence. Reward will be computed based on the distance
<span class='lineno'> 283</span>           from this sequence to the target (distance function and target are
<span class='lineno'> 284</span>           given in the constructor), as well as previous sequences tried during
<span class='lineno'> 285</span>           the lifetime of this object.
<span class='lineno'> 286</span> 
<span class='lineno'> 287</span>     Returns:
<span class='lineno'> 288</span>       Float value. The reward received from this call.
<span class='lineno'> 289</span>     &quot;&quot;&quot;
<span class='lineno'> 290</span>     return 0.0
<span class='lineno'> 291</span> 
<span class='lineno'> 292</span> 
<span class='lineno'> 293</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager', title='<DeltaRewardManager>'>DeltaRewardManager</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager', title='<RewardManager>'>RewardManager</a>):
<span class='lineno'> 294</span>   &quot;&quot;&quot;Simple reward manager that assigns reward for the net change in distance.
<span class='lineno'> 295</span> 
<span class='lineno'> 296</span>   Given some (possibly asymmetric) list distance function, gives reward for
<span class='lineno'> 297</span>   relative changes in prediction distance to the target.
<span class='lineno'> 298</span> 
<span class='lineno'> 299</span>   For example, if on the first call the distance is 3.0, the change in distance
<span class='lineno'> 300</span>   is -3 (from starting distance of 0). That relative change will be scaled to
<span class='lineno'> 301</span>   produce a negative reward for this step. On the next call, the distance is 2.0
<span class='lineno'> 302</span>   which is a +1 change, and that will be scaled to give a positive reward.
<span class='lineno'> 303</span>   If the final call has distance 0 (the target is achieved), that is another
<span class='lineno'> 304</span>   positive change of +2. The total reward across all 3 calls is then 0, which is
<span class='lineno'> 305</span>   the highest posible episode total.
<span class='lineno'> 306</span> 
<span class='lineno'> 307</span>   Reward is scaled so that the maximum element-wise distance is worth 1.0.
<span class='lineno'> 308</span>   Maximum total episode reward attainable is 0.
<span class='lineno'> 309</span>   &quot;&quot;&quot;
<span class='lineno'> 310</span> 
<span class='lineno'> 311</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.self', title='DeltaRewardManager'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.target', title='?'>target</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.base', title='?'>base</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.distance_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.distance_fn', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>distance_fn</a>=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>absolute_distance</a>):
<span class='lineno'> 312</span>     super(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager', title='<DeltaRewardManager>'>DeltaRewardManager</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.self', title='DeltaRewardManager'>self</a>).__init__(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.target', title='?'>target</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.base', title='?'>base</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.distance_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.distance_fn', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>distance_fn</a>)
<span class='lineno'> 313</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__init__.self', title='DeltaRewardManager'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._last_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._last_diff', title='int'>_last_diff</a> = 0
<span class='lineno'> 314</span> 
<span class='lineno'> 315</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff', title='(DeltaRewardManager, ?) -> ?'>_diff</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.self', title='DeltaRewardManager'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.seq', title='?'>seq</a>):
<span class='lineno'> 316</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.self', title='DeltaRewardManager'>self</a>._distance_fn(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.seq', title='?'>seq</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.self', title='DeltaRewardManager'>self</a>._target, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff.self', title='DeltaRewardManager'>self</a>._base)
<span class='lineno'> 317</span> 
<span class='lineno'> 318</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward', title='(DeltaRewardManager, ?) -> int'>_delta_reward</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.self', title='DeltaRewardManager'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.seq', title='?'>seq</a>):
<span class='lineno'> 319</span>     # Reward is relative to previous sequence diff.
<span class='lineno'> 320</span>     # Reward is scaled so that maximum token difference is worth 1.0.
<span class='lineno'> 321</span>     # Reward = (last_diff - this_diff) / self.base.
<span class='lineno'> 322</span>     # Reward is positive if this sequence is closer to the target than the
<span class='lineno'> 323</span>     # previous sequence, and negative if this sequence is further away.
<span class='lineno'> 324</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.diff', title='?'>diff</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.self', title='DeltaRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._diff', title='(DeltaRewardManager, ?) -> ?'>_diff</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.seq', title='?'>seq</a>)
<span class='lineno'> 325</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.reward', title='int'>reward</a> = (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.self', title='DeltaRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._last_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._last_diff', title='int'>_last_diff</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.diff', title='?'>diff</a>) / float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.self', title='DeltaRewardManager'>self</a>._base)
<span class='lineno'> 326</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.self', title='DeltaRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._last_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._last_diff', title='int'>_last_diff</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.diff', title='?'>diff</a>
<span class='lineno'> 327</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward.reward', title='int'>reward</a>
<span class='lineno'> 328</span> 
<span class='lineno'> 329</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__', title='(DeltaRewardManager, ?) -> int'>__call__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__.self', title='DeltaRewardManager'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__.seq', title='?'>seq</a>):
<span class='lineno'> 330</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__.self', title='DeltaRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager._delta_reward', title='(DeltaRewardManager, ?) -> int'>_delta_reward</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.DeltaRewardManager.__call__.seq', title='?'>seq</a>)
<span class='lineno'> 331</span> 
<span class='lineno'> 332</span> 
<span class='lineno'> 333</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager', title='<FloorRewardManager>'>FloorRewardManager</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.RewardManager', title='<RewardManager>'>RewardManager</a>):
<span class='lineno'> 334</span>   &quot;&quot;&quot;Assigns positive reward for each step taken closer to the target.
<span class='lineno'> 335</span> 
<span class='lineno'> 336</span>   Given some (possibly asymmetric) list distance function, gives reward for
<span class='lineno'> 337</span>   whenever a new episode minimum distance is reached. No reward is given if
<span class='lineno'> 338</span>   the distance regresses to a higher value, so that the sum of rewards
<span class='lineno'> 339</span>   for the episode is positive.
<span class='lineno'> 340</span> 
<span class='lineno'> 341</span>   Reward is scaled so that the maximum element-wise distance is worth 1.0.
<span class='lineno'> 342</span>   Maximum total episode reward attainable is len(target).
<span class='lineno'> 343</span> 
<span class='lineno'> 344</span>   If the prediction sequence is longer than the target, a reward of -1 is given.
<span class='lineno'> 345</span>   Subsequence predictions which are also longer get 0 reward. The -1 penalty
<span class='lineno'> 346</span>   will be canceled out with a +1 reward when a prediction is given which is at
<span class='lineno'> 347</span>   most the length of the target.
<span class='lineno'> 348</span>   &quot;&quot;&quot;
<span class='lineno'> 349</span> 
<span class='lineno'> 350</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', title='FloorRewardManager'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.target', title='?'>target</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.base', title='?'>base</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.distance_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.distance_fn', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>distance_fn</a>=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.absolute_distance', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>absolute_distance</a>):
<span class='lineno'> 351</span>     super(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager', title='<FloorRewardManager>'>FloorRewardManager</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', title='FloorRewardManager'>self</a>).__init__(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.target', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.target', title='?'>target</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.base', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.base', title='?'>base</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.distance_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.distance_fn', title='(?, ?, ?, (?, ?, int) -> int / (?, ?, ?) -> int) -> int'>distance_fn</a>)
<span class='lineno'> 352</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', title='FloorRewardManager'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._last_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._last_diff', title='int'>_last_diff</a> = 0
<span class='lineno'> 353</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', title='FloorRewardManager'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._min_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._min_diff', title='?'>_min_diff</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', title='FloorRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff', title='FloorRewardManager -> ?'>_max_diff</a>()
<span class='lineno'> 354</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__init__.self', title='FloorRewardManager'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._too_long_penality_given', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._too_long_penality_given', title='bool'>_too_long_penality_given</a> = False
<span class='lineno'> 355</span> 
<span class='lineno'> 356</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff', title='FloorRewardManager -> ?'>_max_diff</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff.self', title='FloorRewardManager'>self</a>):
<span class='lineno'> 357</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff.self', title='FloorRewardManager'>self</a>._distance_fn([], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff.self', title='FloorRewardManager'>self</a>._target, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._max_diff.self', title='FloorRewardManager'>self</a>._base)
<span class='lineno'> 358</span> 
<span class='lineno'> 359</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff', title='(FloorRewardManager, ?) -> ?'>_diff</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.self', title='FloorRewardManager'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.seq', title='?'>seq</a>):
<span class='lineno'> 360</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.self', title='FloorRewardManager'>self</a>._distance_fn(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.seq', title='?'>seq</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.self', title='FloorRewardManager'>self</a>._target, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff.self', title='FloorRewardManager'>self</a>._base)
<span class='lineno'> 361</span> 
<span class='lineno'> 362</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward', title='(FloorRewardManager, ?) -> float'>_delta_reward</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', title='FloorRewardManager'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.seq', title='?'>seq</a>):
<span class='lineno'> 363</span>     # Reward is only given if this sequence is closer to the target than any
<span class='lineno'> 364</span>     # previous sequence.
<span class='lineno'> 365</span>     # Reward is scaled so that maximum token difference is worth 1.0
<span class='lineno'> 366</span>     # Reward = (min_diff - this_diff) / self.base
<span class='lineno'> 367</span>     # Reward is always positive.
<span class='lineno'> 368</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.diff', title='?'>diff</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', title='FloorRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._diff', title='(FloorRewardManager, ?) -> ?'>_diff</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.seq', title='?'>seq</a>)
<span class='lineno'> 369</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.diff', title='?'>diff</a> &lt; <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', title='FloorRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._min_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._min_diff', title='?'>_min_diff</a>:
<span class='lineno'> 370</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.reward', title='float'>reward</a> = (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', title='FloorRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._min_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._min_diff', title='?'>_min_diff</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.diff', title='?'>diff</a>) / float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', title='FloorRewardManager'>self</a>._base)
<span class='lineno'> 371</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.self', title='FloorRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._min_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._min_diff', title='?'>_min_diff</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.diff', title='?'>diff</a>
<span class='lineno'> 372</span>     else:
<span class='lineno'> 373</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.reward', title='float'>reward</a> = 0.0
<span class='lineno'> 374</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward.reward', title='float'>reward</a>
<span class='lineno'> 375</span> 
<span class='lineno'> 376</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__', title='(FloorRewardManager, ?) -> float'>__call__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', title='FloorRewardManager'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.seq', title='?'>seq</a>):
<span class='lineno'> 377</span>     if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.seq', title='?'>seq</a>) &gt; len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', title='FloorRewardManager'>self</a>._target):  # Output is too long.
<span class='lineno'> 378</span>       if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', title='FloorRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._too_long_penality_given', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._too_long_penality_given', title='bool'>_too_long_penality_given</a>:
<span class='lineno'> 379</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', title='FloorRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._too_long_penality_given', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._too_long_penality_given', title='bool'>_too_long_penality_given</a> = True
<span class='lineno'> 380</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', title='float'>reward</a> = -1.0
<span class='lineno'> 381</span>       else:
<span class='lineno'> 382</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', title='float'>reward</a> = 0.0  # Don&#39;t give this penalty more than once.
<span class='lineno'> 383</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', title='float'>reward</a>
<span class='lineno'> 384</span> 
<span class='lineno'> 385</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', title='float'>reward</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', title='FloorRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._delta_reward', title='(FloorRewardManager, ?) -> float'>_delta_reward</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.seq', title='?'>seq</a>)
<span class='lineno'> 386</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', title='FloorRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._too_long_penality_given', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._too_long_penality_given', title='bool'>_too_long_penality_given</a>:
<span class='lineno'> 387</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', title='float'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', title='float'>reward</a></a> += 1.0  # Return the subtracted reward.
<span class='lineno'> 388</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.self', title='FloorRewardManager'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._too_long_penality_given', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager._too_long_penality_given', title='bool'>_too_long_penality_given</a> = False
<span class='lineno'> 389</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.brain_coder.common.reward.FloorRewardManager.__call__.reward', title='float'>reward</a>
</pre></td></tr></table></body></html>