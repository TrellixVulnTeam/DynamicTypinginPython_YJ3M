<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/tcn/preprocessing.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector'>apply_with_random_selector</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop'>distorted_bounding_box_crop</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color'>distort_color</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center'>crop_center</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad'>pad</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200'>pad_200</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central'>pad_crop_central</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy'>crop_image_by_strategy</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop'>scale_augment_crop</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range'>scale_to_inception_range</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image'>resize_image</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad'>crop_or_pad</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox'>get_central_bbox</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max'>pad_to_max</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation'>scale_up_augmentation</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation'>scale_down_augmentation</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale'>augment_image_scale</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image'>decode_image</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_images', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_images'>decode_images</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images'>preprocess_training_images</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image'>preprocess_training_image</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image'>preprocess_test_image</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images'>preprocess_test_images</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images'>preprocess_images</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage'>cv2rotateimage</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge'>cv2resizeminedge</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring'>shapestring</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode', xid='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode'>unscale_jpeg_encode</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2017 The TensorFlow Authors All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> &quot;&quot;&quot;Image preprocessing helpers.&quot;&quot;&quot;
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> from __future__ import absolute_import
<span class='lineno'>  19</span> from __future__ import division
<span class='lineno'>  20</span> from __future__ import print_function
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> import cv2
<span class='lineno'>  23</span> from scipy import ndimage
<span class='lineno'>  24</span> import tensorflow as tf
<span class='lineno'>  25</span> from tensorflow.python.ops import control_flow_ops
<span class='lineno'>  26</span> 
<span class='lineno'>  27</span> 
<span class='lineno'>  28</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector', title='(?, (?, int) -> None, int) -> None / (?, ?, ?) -> None'>apply_with_random_selector</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.x', title='?'>x</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.func', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.func', title='(?, int) -> None'>func</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.num_cases', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.num_cases', title='int'>num_cases</a>):
<span class='lineno'>  29</span>   &quot;&quot;&quot;Computes func(x, sel), with sel sampled from [0...num_cases-1].
<span class='lineno'>  30</span> 
<span class='lineno'>  31</span>   TODO(coreylynch): add as a dependency, when slim or tensorflow/models are
<span class='lineno'>  32</span>   pipfied.
<span class='lineno'>  33</span>   Source:
<span class='lineno'>  34</span>   https://raw.githubusercontent.com/tensorflow/models/a9d0e6e8923a4/slim/preprocessing/inception_preprocessing.py
<span class='lineno'>  35</span> 
<span class='lineno'>  36</span>   Args:
<span class='lineno'>  37</span>     x: input Tensor.
<span class='lineno'>  38</span>     func: Python function to apply.
<span class='lineno'>  39</span>     num_cases: Python int32, number of cases to sample sel from.
<span class='lineno'>  40</span>   Returns:
<span class='lineno'>  41</span>     The result of func(x, sel), where func receives the value of the
<span class='lineno'>  42</span>     selector as a python integer, but sel is sampled dynamically.
<span class='lineno'>  43</span>   &quot;&quot;&quot;
<span class='lineno'>  44</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.sel', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.sel', title='?'>sel</a> = tf.random_uniform([], maxval=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.num_cases', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.num_cases', title='int'>num_cases</a>, dtype=tf.int32)
<span class='lineno'>  45</span>   # Pass the real x only to one of the func calls.
<span class='lineno'>  46</span>   return control_flow_ops.merge([
<span class='lineno'>  47</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.func', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.func', title='(?, int) -> None'>func</a>(control_flow_ops.switch(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.x', title='?'>x</a>, tf.equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.sel', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.sel', title='?'>sel</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.case', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.case', title='int'>case</a>))[1], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.case', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.case', title='int'>case</a>)
<span class='lineno'>  48</span>       for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.case', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.case', title='int'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.case', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.case', title='int'>case</a></a> in range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.num_cases', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector.num_cases', title='int'>num_cases</a>)])[0]
<span class='lineno'>  49</span> 
<span class='lineno'>  50</span> 
<span class='lineno'>  51</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop', title='(?, ?, float, (float, float), (float, float), int, None) -> (?, ?) / (None, ?, float, (float, float), (float, float), int, None) -> (?, ?) / (?, None, float, (float, float), (float, float), int, None) -> (?, ?)'>distorted_bounding_box_crop</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.image', title='None'>image</a>,
<span class='lineno'>  52</span>                                 <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox', title='None'>bbox</a>,
<span class='lineno'>  53</span>                                 <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.min_object_covered', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.min_object_covered', title='float'>min_object_covered</a>=0.1,
<span class='lineno'>  54</span>                                 <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.aspect_ratio_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.aspect_ratio_range', title='(float, float)'>aspect_ratio_range</a>=(0.75, 1.33),
<span class='lineno'>  55</span>                                 <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.area_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.area_range', title='(float, float)'>area_range</a>=(0.05, 1.0),
<span class='lineno'>  56</span>                                 <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.max_attempts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.max_attempts', title='int'>max_attempts</a>=100,
<span class='lineno'>  57</span>                                 <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.scope', title='None'>scope</a>=None):
<span class='lineno'>  58</span>   &quot;&quot;&quot;Generates cropped_image using a one of the bboxes randomly distorted.
<span class='lineno'>  59</span> 
<span class='lineno'>  60</span>   TODO(coreylynch): add as a dependency, when slim or tensorflow/models are
<span class='lineno'>  61</span>   pipfied.
<span class='lineno'>  62</span>   Source:
<span class='lineno'>  63</span>   https://raw.githubusercontent.com/tensorflow/models/a9d0e6e8923a4/slim/preprocessing/inception_preprocessing.py
<span class='lineno'>  64</span> 
<span class='lineno'>  65</span>   See `tf.image.sample_distorted_bounding_box` for more documentation.
<span class='lineno'>  66</span> 
<span class='lineno'>  67</span>   Args:
<span class='lineno'>  68</span>     image: 3-D Tensor of image (it will be converted to floats in [0, 1]).
<span class='lineno'>  69</span>     bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]
<span class='lineno'>  70</span>       where each coordinate is [0, 1) and the coordinates are arranged
<span class='lineno'>  71</span>       as [ymin, xmin, ymax, xmax]. If num_boxes is 0 then it would use the whole
<span class='lineno'>  72</span>       image.
<span class='lineno'>  73</span>     min_object_covered: An optional `float`. Defaults to `0.1`. The cropped
<span class='lineno'>  74</span>       area of the image must contain at least this fraction of any bounding box
<span class='lineno'>  75</span>       supplied.
<span class='lineno'>  76</span>     aspect_ratio_range: An optional list of `floats`. The cropped area of the
<span class='lineno'>  77</span>       image must have an aspect ratio = width / height within this range.
<span class='lineno'>  78</span>     area_range: An optional list of `floats`. The cropped area of the image
<span class='lineno'>  79</span>       must contain a fraction of the supplied image within in this range.
<span class='lineno'>  80</span>     max_attempts: An optional `int`. Number of attempts at generating a cropped
<span class='lineno'>  81</span>       region of the image of the specified constraints. After `max_attempts`
<span class='lineno'>  82</span>       failures, return the entire image.
<span class='lineno'>  83</span>     scope: Optional scope for name_scope.
<span class='lineno'>  84</span>   Returns:
<span class='lineno'>  85</span>     A tuple, a 3-D Tensor cropped_image and the distorted bbox
<span class='lineno'>  86</span>   &quot;&quot;&quot;
<span class='lineno'>  87</span>   with tf.name_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.scope', title='None'>scope</a>, &#39;distorted_bounding_box_crop&#39;, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.image', title='None'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox', title='None'>bbox</a>]):
<span class='lineno'>  88</span>     # Each bounding box has shape [1, num_boxes, box coords] and
<span class='lineno'>  89</span>     # the coordinates are ordered [ymin, xmin, ymax, xmax].
<span class='lineno'>  90</span> 
<span class='lineno'>  91</span>     # A large fraction of image datasets contain a human-annotated bounding
<span class='lineno'>  92</span>     # box delineating the region of the image containing the object of interest.
<span class='lineno'>  93</span>     # We choose to create a new bounding box for the object which is a randomly
<span class='lineno'>  94</span>     # distorted version of the human-annotated bounding box that obeys an
<span class='lineno'>  95</span>     # allowed range of aspect ratios, sizes and overlap with the human-annotated
<span class='lineno'>  96</span>     # bounding box. If no box is supplied, then we assume the bounding box is
<span class='lineno'>  97</span>     # the entire image.
<span class='lineno'>  98</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.sample_distorted_bounding_box', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.sample_distorted_bounding_box', title='?'>sample_distorted_bounding_box</a> = tf.image.sample_distorted_bounding_box(
<span class='lineno'>  99</span>         tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.image', title='None'>image</a>),
<span class='lineno'> 100</span>         bounding_boxes=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox', title='None'>bbox</a>,
<span class='lineno'> 101</span>         min_object_covered=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.min_object_covered', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.min_object_covered', title='float'>min_object_covered</a>,
<span class='lineno'> 102</span>         aspect_ratio_range=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.aspect_ratio_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.aspect_ratio_range', title='(float, float)'>aspect_ratio_range</a>,
<span class='lineno'> 103</span>         area_range=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.area_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.area_range', title='(float, float)'>area_range</a>,
<span class='lineno'> 104</span>         max_attempts=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.max_attempts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.max_attempts', title='int'>max_attempts</a>,
<span class='lineno'> 105</span>         use_image_if_no_bounding_boxes=True)
<span class='lineno'> 106</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox_begin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox_begin', title='?'>bbox_begin</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox_size', title='?'>bbox_size</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.distort_bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.distort_bbox', title='?'>distort_bbox</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.sample_distorted_bounding_box', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.sample_distorted_bounding_box', title='?'>sample_distorted_bounding_box</a>
<span class='lineno'> 107</span> 
<span class='lineno'> 108</span>     # Crop the image to the specified bounding box.
<span class='lineno'> 109</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.cropped_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.cropped_image', title='?'>cropped_image</a> = tf.slice(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.image', title='None'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox_begin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox_begin', title='?'>bbox_begin</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.bbox_size', title='?'>bbox_size</a>)
<span class='lineno'> 110</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.cropped_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.cropped_image', title='?'>cropped_image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.distort_bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop.distort_bbox', title='?'>distort_bbox</a>
<span class='lineno'> 111</span> 
<span class='lineno'> 112</span> 
<span class='lineno'> 113</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color', title='(?, int, bool, None) -> None'>distort_color</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', title='int'>color_ordering</a>=0, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.fast_mode', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.fast_mode', title='bool'>fast_mode</a>=True, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.scope', title='None'>scope</a>=None):
<span class='lineno'> 114</span>   &quot;&quot;&quot;Distort the color of a Tensor image.
<span class='lineno'> 115</span> 
<span class='lineno'> 116</span>   TODO(coreylynch): add as a dependency, when slim or tensorflow/models are
<span class='lineno'> 117</span>   pipfied.
<span class='lineno'> 118</span>   Source:
<span class='lineno'> 119</span>   https://raw.githubusercontent.com/tensorflow/models/a9d0e6e8923a4/slim/preprocessing/inception_preprocessing.py
<span class='lineno'> 120</span> 
<span class='lineno'> 121</span>   Each color distortion is non-commutative and thus ordering of the color ops
<span class='lineno'> 122</span>   matters. Ideally we would randomly permute the ordering of the color ops.
<span class='lineno'> 123</span>   Rather than adding that level of complication, we select a distinct ordering
<span class='lineno'> 124</span>   of color ops for each preprocessing thread.
<span class='lineno'> 125</span>   Args:
<span class='lineno'> 126</span>     image: 3-D Tensor containing single image in [0, 1].
<span class='lineno'> 127</span>     color_ordering: Python int, a type of distortion (valid values: 0-3).
<span class='lineno'> 128</span>     fast_mode: Avoids slower ops (random_hue and random_contrast)
<span class='lineno'> 129</span>     scope: Optional scope for name_scope.
<span class='lineno'> 130</span>   Returns:
<span class='lineno'> 131</span>     3-D Tensor color-distorted image on range [0, 1]
<span class='lineno'> 132</span>   Raises:
<span class='lineno'> 133</span>     ValueError: if color_ordering not in [0, 3]
<span class='lineno'> 134</span>   &quot;&quot;&quot;
<span class='lineno'> 135</span>   with tf.name_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.scope', title='None'>scope</a>, &#39;distort_color&#39;, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>]):
<span class='lineno'> 136</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.fast_mode', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.fast_mode', title='bool'>fast_mode</a>:
<span class='lineno'> 137</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', title='int'>color_ordering</a> == 0:
<span class='lineno'> 138</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_brightness(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, max_delta=32. / 255.)
<span class='lineno'> 139</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_saturation(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, lower=0.5, upper=1.5)
<span class='lineno'> 140</span>       else:
<span class='lineno'> 141</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_saturation(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, lower=0.5, upper=1.5)
<span class='lineno'> 142</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_brightness(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, max_delta=32. / 255.)
<span class='lineno'> 143</span>     else:
<span class='lineno'> 144</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', title='int'>color_ordering</a> == 0:
<span class='lineno'> 145</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_brightness(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, max_delta=32. / 255.)
<span class='lineno'> 146</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_saturation(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, lower=0.5, upper=1.5)
<span class='lineno'> 147</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_hue(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, max_delta=0.2)
<span class='lineno'> 148</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_contrast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, lower=0.5, upper=1.5)
<span class='lineno'> 149</span>       elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', title='int'>color_ordering</a> == 1:
<span class='lineno'> 150</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_saturation(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, lower=0.5, upper=1.5)
<span class='lineno'> 151</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_brightness(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, max_delta=32. / 255.)
<span class='lineno'> 152</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_contrast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, lower=0.5, upper=1.5)
<span class='lineno'> 153</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_hue(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, max_delta=0.2)
<span class='lineno'> 154</span>       elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', title='int'>color_ordering</a> == 2:
<span class='lineno'> 155</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_contrast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, lower=0.5, upper=1.5)
<span class='lineno'> 156</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_hue(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, max_delta=0.2)
<span class='lineno'> 157</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_brightness(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, max_delta=32. / 255.)
<span class='lineno'> 158</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_saturation(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, lower=0.5, upper=1.5)
<span class='lineno'> 159</span>       elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.color_ordering', title='int'>color_ordering</a> == 3:
<span class='lineno'> 160</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_hue(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, max_delta=0.2)
<span class='lineno'> 161</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_saturation(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, lower=0.5, upper=1.5)
<span class='lineno'> 162</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_contrast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, lower=0.5, upper=1.5)
<span class='lineno'> 163</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a> = tf.image.random_brightness(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, max_delta=32. / 255.)
<span class='lineno'> 164</span>       else:
<span class='lineno'> 165</span>         raise ValueError(&#39;color_ordering must be in [0, 3]&#39;)
<span class='lineno'> 166</span> 
<span class='lineno'> 167</span>     # The random_* ops do not necessarily clamp.
<span class='lineno'> 168</span>     return tf.clip_by_value(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color.image', title='?'>image</a>, 0.0, 1.0)
<span class='lineno'> 169</span> 
<span class='lineno'> 170</span> 
<span class='lineno'> 171</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center', title='? -> None'>crop_center</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.image', title='?'>image</a>):
<span class='lineno'> 172</span>   &quot;&quot;&quot;Returns a cropped square image.&quot;&quot;&quot;
<span class='lineno'> 173</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', title='?'>shape</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.image', title='?'>image</a>)
<span class='lineno'> 174</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.new_shape', title='?'>new_shape</a> = tf.minimum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', title='?'>shape</a>[0], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', title='?'>shape</a>[1])
<span class='lineno'> 175</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.offset_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.offset_y', title='int'>offset_y</a> = tf.maximum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', title='?'>shape</a>[0] - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', title='?'>shape</a>[1], 0) // 2
<span class='lineno'> 176</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.offset_x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.offset_x', title='int'>offset_x</a> = tf.maximum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', title='?'>shape</a>[1] - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.shape', title='?'>shape</a>[0], 0) // 2
<span class='lineno'> 177</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.image', title='?'>image</a> = tf.image.crop_to_bounding_box(
<span class='lineno'> 178</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.offset_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.offset_y', title='int'>offset_y</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.offset_x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.offset_x', title='int'>offset_x</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.new_shape', title='?'>new_shape</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.new_shape', title='?'>new_shape</a>)
<span class='lineno'> 179</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center.image', title='?'>image</a>
<span class='lineno'> 180</span> 
<span class='lineno'> 181</span> 
<span class='lineno'> 182</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad', title='? -> None'>pad</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.image', title='?'>image</a>):
<span class='lineno'> 183</span>   &quot;&quot;&quot;Returns an image padded to be square.&quot;&quot;&quot;
<span class='lineno'> 184</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.shape', title='?'>shape</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.image', title='?'>image</a>)
<span class='lineno'> 185</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.new_shape', title='?'>new_shape</a> = tf.maximum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.shape', title='?'>shape</a>[0], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.shape', title='?'>shape</a>[1])
<span class='lineno'> 186</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.height', title='?'>height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.shape', title='?'>shape</a>[0]
<span class='lineno'> 187</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.width', title='?'>width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.shape', title='?'>shape</a>[1]
<span class='lineno'> 188</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.offset_x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.offset_x', title='int'>offset_x</a> = tf.maximum((<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.height', title='?'>height</a>-<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.width', title='?'>width</a>), 0) // 2
<span class='lineno'> 189</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.offset_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.offset_y', title='int'>offset_y</a> = tf.maximum((<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.width', title='?'>width</a>-<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.height', title='?'>height</a>), 0) // 2
<span class='lineno'> 190</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.image', title='?'>image</a> = tf.image.pad_to_bounding_box(
<span class='lineno'> 191</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.offset_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.offset_y', title='int'>offset_y</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.offset_x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.offset_x', title='int'>offset_x</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.new_shape', title='?'>new_shape</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.new_shape', title='?'>new_shape</a>)
<span class='lineno'> 192</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad.image', title='?'>image</a>
<span class='lineno'> 193</span> 
<span class='lineno'> 194</span> 
<span class='lineno'> 195</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200', title='? -> None'>pad_200</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', title='?'>image</a>):
<span class='lineno'> 196</span>   &quot;&quot;&quot;Returns an image padded width-padded with 200 pixels.&quot;&quot;&quot;
<span class='lineno'> 197</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', title='?'>shape</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', title='?'>image</a>)
<span class='lineno'> 198</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', title='?'>image</a> = tf.image.pad_to_bounding_box(
<span class='lineno'> 199</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', title='?'>image</a>, 0, 200, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', title='?'>shape</a>[0], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', title='?'>shape</a>[1]+400)
<span class='lineno'> 200</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', title='?'>shape</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', title='?'>image</a>)
<span class='lineno'> 201</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.new_shape', title='?'>new_shape</a> = tf.minimum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', title='?'>shape</a>[0], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', title='?'>shape</a>[1])
<span class='lineno'> 202</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.offset_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.offset_y', title='int'>offset_y</a> = tf.maximum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', title='?'>shape</a>[0] - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', title='?'>shape</a>[1], 0) // 2
<span class='lineno'> 203</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.offset_x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.offset_x', title='int'>offset_x</a> = tf.maximum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', title='?'>shape</a>[1] - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.shape', title='?'>shape</a>[0], 0) // 2
<span class='lineno'> 204</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', title='?'>image</a> = tf.image.crop_to_bounding_box(
<span class='lineno'> 205</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.offset_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.offset_y', title='int'>offset_y</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.offset_x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.offset_x', title='int'>offset_x</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.new_shape', title='?'>new_shape</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.new_shape', title='?'>new_shape</a>)
<span class='lineno'> 206</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200.image', title='?'>image</a>
<span class='lineno'> 207</span> 
<span class='lineno'> 208</span> 
<span class='lineno'> 209</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central', title='(?, float) -> None'>pad_crop_central</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.central_fraction', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.central_fraction', title='float'>central_fraction</a>=0.875):
<span class='lineno'> 210</span>   &quot;&quot;&quot;Pads the image to the maximum length, crops the central fraction.&quot;&quot;&quot;
<span class='lineno'> 211</span>   # Pad the image to be square.
<span class='lineno'> 212</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad', title='? -> None'>pad</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', title='?'>image</a>)
<span class='lineno'> 213</span>   # Crop the central region of the image with an area containing 87.5% of
<span class='lineno'> 214</span>   # the original image.
<span class='lineno'> 215</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', title='?'>image</a> = tf.image.central_crop(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', title='None'>image</a>, central_fraction=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.central_fraction', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.central_fraction', title='float'>central_fraction</a>)
<span class='lineno'> 216</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central.image', title='?'>image</a>
<span class='lineno'> 217</span> 
<span class='lineno'> 218</span> 
<span class='lineno'> 219</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy', title='(?, str) -> None / (?, ?) -> None'>crop_image_by_strategy</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.cropping', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.cropping', title='str'>cropping</a>):
<span class='lineno'> 220</span>   &quot;&quot;&quot;Crops an image according to a strategy defined in config.
<span class='lineno'> 221</span> 
<span class='lineno'> 222</span>   Args:
<span class='lineno'> 223</span>     image: 3-d image tensor.
<span class='lineno'> 224</span>     cropping: str, name of cropping strategy.
<span class='lineno'> 225</span>   Returns:
<span class='lineno'> 226</span>     image: cropped image.
<span class='lineno'> 227</span>   Raises:
<span class='lineno'> 228</span>     ValueError: When unknown cropping strategy is specified.
<span class='lineno'> 229</span>   &quot;&quot;&quot;
<span class='lineno'> 230</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.strategy_to_method', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.strategy_to_method', title='dict'>strategy_to_method</a> = {
<span class='lineno'> 231</span>       &#39;crop_center&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center', title='? -> None'>crop_center</a>,
<span class='lineno'> 232</span>       &#39;pad&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad', title='? -> None'>pad</a>,
<span class='lineno'> 233</span>       &#39;pad200&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_200', title='? -> None'>pad_200</a>,
<span class='lineno'> 234</span>       &#39;pad_crop_central&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_crop_central', title='(?, float) -> None'>pad_crop_central</a>
<span class='lineno'> 235</span>   }
<span class='lineno'> 236</span>   tf.logging.info(&#39;Cropping strategy: %s.&#39; % <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.cropping', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.cropping', title='str'>cropping</a>)
<span class='lineno'> 237</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.cropping', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.cropping', title='str'>cropping</a> not in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.strategy_to_method', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.strategy_to_method', title='dict'>strategy_to_method</a>:
<span class='lineno'> 238</span>     raise ValueError(&#39;Unknown cropping strategy: %s&#39; % cropping)
<span class='lineno'> 239</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.strategy_to_method', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.strategy_to_method', title='dict'>strategy_to_method</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.cropping', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.cropping', title='str'>cropping</a>](<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy.image', title='?'>image</a>)
<span class='lineno'> 240</span> 
<span class='lineno'> 241</span> 
<span class='lineno'> 242</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop', title='(None, ?, (float, float), float) -> None / (?, None, (float, float), float) -> None / (None, ?, (?, float), ?) -> None / (?, ?, ?, ?) -> None'>scale_augment_crop</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.image', title='None'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.central_bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.central_bbox', title='None'>central_bbox</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.area_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.area_range', title='(float, float)'>area_range</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.min_object_covered', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.min_object_covered', title='float'>min_object_covered</a>):
<span class='lineno'> 243</span>   &quot;&quot;&quot;Training time scale augmentation.
<span class='lineno'> 244</span> 
<span class='lineno'> 245</span>   Args:
<span class='lineno'> 246</span>     image: 3-d float tensor.
<span class='lineno'> 247</span>     central_bbox: Bounding box defining the central region of interest.
<span class='lineno'> 248</span>     area_range: Range of allowed areas for the augmented bounding box.
<span class='lineno'> 249</span>     min_object_covered: Constraint for the fraction of original image in
<span class='lineno'> 250</span>       augmented bounding box.
<span class='lineno'> 251</span>   Returns:
<span class='lineno'> 252</span>     distort_image: The scaled, cropped image.
<span class='lineno'> 253</span>   &quot;&quot;&quot;
<span class='lineno'> 254</span>   (<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.distorted_image', title='?'>distorted_image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop._', title='?'>_</a>) = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distorted_bounding_box_crop', title='(?, ?, float, (float, float), (float, float), int, None) -> (?, ?) / (None, ?, float, (float, float), (float, float), int, None) -> (?, ?) / (?, None, float, (float, float), (float, float), int, None) -> (?, ?)'>distorted_bounding_box_crop</a>(
<span class='lineno'> 255</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.image', title='None'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.central_bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.central_bbox', title='None'>central_bbox</a>, area_range=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.area_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.area_range', title='(float, float)'>area_range</a>,
<span class='lineno'> 256</span>       aspect_ratio_range=(1.0, 1.0),
<span class='lineno'> 257</span>       min_object_covered=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.min_object_covered', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.min_object_covered', title='float'>min_object_covered</a>)
<span class='lineno'> 258</span>   # Restore the shape since the dynamic slice based upon the bbox_size loses
<span class='lineno'> 259</span>   # the third dimension.
<span class='lineno'> 260</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.distorted_image', title='?'>distorted_image</a>.set_shape([None, None, 3])
<span class='lineno'> 261</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.distorted_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop.distorted_image', title='?'>distorted_image</a>
<span class='lineno'> 262</span> 
<span class='lineno'> 263</span> 
<span class='lineno'> 264</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range', title='? -> None / None -> None'>scale_to_inception_range</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', title='None'>image</a>):
<span class='lineno'> 265</span>   &quot;&quot;&quot;Scales an image in the range [0,1] to [-1,1] as expected by inception.&quot;&quot;&quot;
<span class='lineno'> 266</span>   # Assert that incoming images have been properly scaled to [0,1].
<span class='lineno'> 267</span>   with tf.control_dependencies(
<span class='lineno'> 268</span>       [tf.assert_less_equal(tf.reduce_max(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', title='None'>image</a>), 1.),
<span class='lineno'> 269</span>        tf.assert_greater_equal(tf.reduce_min(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', title='None'>image</a>), 0.)]):
<span class='lineno'> 270</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', title='?'>image</a> = tf.subtract(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', title='None'>image</a>, 0.5)
<span class='lineno'> 271</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', title='?'>image</a> = tf.multiply(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', title='?'>image</a>, 2.0)
<span class='lineno'> 272</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range.image', title='?'>image</a>
<span class='lineno'> 273</span> 
<span class='lineno'> 274</span> 
<span class='lineno'> 275</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image', title='(?, ?, ?) -> None / (None, ?, ?) -> None'>resize_image</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', title='None'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.height', title='?'>height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.width', title='?'>width</a>):
<span class='lineno'> 276</span>   &quot;&quot;&quot;Resizes an image to a target height and width.&quot;&quot;&quot;
<span class='lineno'> 277</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', title='?'>image</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', title='None'>image</a>, 0)
<span class='lineno'> 278</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', title='?'>image</a> = tf.image.resize_bilinear(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', title='?'>image</a>, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.width', title='?'>width</a>], align_corners=False)
<span class='lineno'> 279</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', title='?'>image</a> = tf.squeeze(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', title='?'>image</a>, [0])
<span class='lineno'> 280</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image.image', title='?'>image</a>
<span class='lineno'> 281</span> 
<span class='lineno'> 282</span> 
<span class='lineno'> 283</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad', title='(?, ?, ?, ?, bool, bool) -> None'>crop_or_pad</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.curr_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.curr_height', title='?'>curr_height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.curr_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.curr_width', title='?'>curr_width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.new', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.new', title='?'>new</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.height', title='bool'>height</a>=True, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.crop', title='bool'>crop</a>=True):
<span class='lineno'> 284</span>   &quot;&quot;&quot;Crops or pads an image.
<span class='lineno'> 285</span> 
<span class='lineno'> 286</span>   Args:
<span class='lineno'> 287</span>     image: 3-D float32 `Tensor` image.
<span class='lineno'> 288</span>     curr_height: Int, current height.
<span class='lineno'> 289</span>     curr_width: Int, current width.
<span class='lineno'> 290</span>     new: Int, new width or height.
<span class='lineno'> 291</span>     height: Boolean, cropping or padding for height.
<span class='lineno'> 292</span>     crop: Boolean, True if we&#39;re cropping, False if we&#39;re padding.
<span class='lineno'> 293</span>   Returns:
<span class='lineno'> 294</span>     image: 3-D float32 `Tensor` image.
<span class='lineno'> 295</span>   &quot;&quot;&quot;
<span class='lineno'> 296</span>   # Crop the image to fit the new shape.
<span class='lineno'> 297</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.abs_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.abs_diff', title='int'>abs_diff</a> = tf.abs(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.new', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.new', title='?'>new</a>-<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.curr_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.curr_height', title='?'>curr_height</a>)//2 if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.height', title='bool'>height</a> else tf.abs(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.new', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.new', title='?'>new</a>-<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.curr_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.curr_width', title='?'>curr_width</a>)//2
<span class='lineno'> 298</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_x', title='int'>offset_x</a> = 0 if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.height', title='bool'>height</a> else <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.abs_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.abs_diff', title='int'>abs_diff</a>
<span class='lineno'> 299</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_y', title='int'>offset_y</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.abs_diff', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.abs_diff', title='int'>abs_diff</a> if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.height', title='bool'>height</a> else 0
<span class='lineno'> 300</span> 
<span class='lineno'> 301</span>   # We process height first, so always pad/crop to new height.
<span class='lineno'> 302</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_height', title='?'>target_height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.new', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.new', title='?'>new</a>
<span class='lineno'> 303</span>   # We process height first, so pad/crop to new width only if not doing height.
<span class='lineno'> 304</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_width', title='?'>target_width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.curr_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.curr_width', title='?'>curr_width</a> if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.height', title='bool'>height</a> else <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.new', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.new', title='?'>new</a>
<span class='lineno'> 305</span> 
<span class='lineno'> 306</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.crop', title='bool'>crop</a>:
<span class='lineno'> 307</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', title='?'>image</a> = tf.image.crop_to_bounding_box(
<span class='lineno'> 308</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_y', title='int'>offset_y</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_x', title='int'>offset_x</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_height', title='?'>target_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_width', title='?'>target_width</a>)
<span class='lineno'> 309</span>   else:
<span class='lineno'> 310</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', title='?'>image</a> = tf.image.pad_to_bounding_box(
<span class='lineno'> 311</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_y', title='int'>offset_y</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.offset_x', title='int'>offset_x</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_height', title='?'>target_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.target_width', title='?'>target_width</a>)
<span class='lineno'> 312</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad.image', title='?'>image</a>
<span class='lineno'> 313</span> 
<span class='lineno'> 314</span> 
<span class='lineno'> 315</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox', title='(?, ?) -> None'>get_central_bbox</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_side', title='?'>min_side</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.new_size', title='?'>new_size</a>):
<span class='lineno'> 316</span>   &quot;&quot;&quot;Gets the central bounding box for an image.
<span class='lineno'> 317</span> 
<span class='lineno'> 318</span>   If image is square, returns bounding box [0,0,1,1].
<span class='lineno'> 319</span>   Otherwise, returns the bounding box containing the central
<span class='lineno'> 320</span>   smallest side x smallest side square.
<span class='lineno'> 321</span> 
<span class='lineno'> 322</span>   Args:
<span class='lineno'> 323</span>     min_side: Int, size of smallest side in pixels.
<span class='lineno'> 324</span>     new_size: Int, resize image to a square of new_size x new_size pixels.
<span class='lineno'> 325</span>   Returns:
<span class='lineno'> 326</span>     bbox: A 4-D Int `Tensor`, holding the coordinates of the central bounding
<span class='lineno'> 327</span>       box.
<span class='lineno'> 328</span>   &quot;&quot;&quot;
<span class='lineno'> 329</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.max_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.max_shape', title='?'>max_shape</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.new_size', title='?'>new_size</a>, tf.float32)
<span class='lineno'> 330</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_shape', title='?'>min_shape</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_side', title='?'>min_side</a>, tf.float32)
<span class='lineno'> 331</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.top_xy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.top_xy', title='int'>top_xy</a> = ((<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.max_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.max_shape', title='?'>max_shape</a>-<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_shape', title='?'>min_shape</a>)/2)/<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.max_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.max_shape', title='?'>max_shape</a>
<span class='lineno'> 332</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bottom_xy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bottom_xy', title='int'>bottom_xy</a> = (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_shape', title='?'>min_shape</a>+(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.max_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.max_shape', title='?'>max_shape</a>-<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.min_shape', title='?'>min_shape</a>)/2)/<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.max_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.max_shape', title='?'>max_shape</a>
<span class='lineno'> 333</span>   # Create a bbox for the center region of interest.
<span class='lineno'> 334</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bbox', title='?'>bbox</a> = tf.stack([[[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.top_xy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.top_xy', title='int'>top_xy</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.top_xy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.top_xy', title='int'>top_xy</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bottom_xy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bottom_xy', title='int'>bottom_xy</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bottom_xy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bottom_xy', title='int'>bottom_xy</a>]]])
<span class='lineno'> 335</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bbox', title='?'>bbox</a>.set_shape([1, 1, 4])
<span class='lineno'> 336</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox.bbox', title='?'>bbox</a>
<span class='lineno'> 337</span> 
<span class='lineno'> 338</span> 
<span class='lineno'> 339</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max', title='(?, float) -> (?, None) / (?, ?) -> (?, None)'>pad_to_max</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.max_scale', title='float'>max_scale</a>):
<span class='lineno'> 340</span>   &quot;&quot;&quot;Pads an image to max_scale times the current center crop size.
<span class='lineno'> 341</span> 
<span class='lineno'> 342</span>   E.g.: For an image with dimensions 1920x1080 and a max_scale of 1.5,
<span class='lineno'> 343</span>   returns an image that is 1.5 * (1080x1080).
<span class='lineno'> 344</span> 
<span class='lineno'> 345</span>   Args:
<span class='lineno'> 346</span>     image: 3-D float32 `Tensor` image.
<span class='lineno'> 347</span>     max_scale: Float, maximum scale of the image, as a multiplier on the
<span class='lineno'> 348</span>       central bounding box.
<span class='lineno'> 349</span>   Returns:
<span class='lineno'> 350</span>     image: 3-D float32 `Tensor` image.
<span class='lineno'> 351</span>   &quot;&quot;&quot;
<span class='lineno'> 352</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_shape', title='?'>orig_shape</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', title='?'>image</a>)
<span class='lineno'> 353</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', title='?'>orig_height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_shape', title='?'>orig_shape</a>[0]
<span class='lineno'> 354</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', title='?'>orig_width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_shape', title='?'>orig_shape</a>[1]
<span class='lineno'> 355</span> 
<span class='lineno'> 356</span>   # Find the smallest side and corresponding new size.
<span class='lineno'> 357</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.min_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.min_side', title='?'>min_side</a> = tf.cast(tf.minimum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', title='?'>orig_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', title='?'>orig_width</a>), tf.float32)
<span class='lineno'> 358</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', title='?'>new_shape</a> = tf.cast(tf.sqrt(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.max_scale', title='float'>max_scale</a>*<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.min_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.min_side', title='?'>min_side</a>*<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.min_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.min_side', title='?'>min_side</a>), tf.int32)
<span class='lineno'> 359</span> 
<span class='lineno'> 360</span>   # Crop or pad height.
<span class='lineno'> 361</span>   # pylint: disable=g-long-lambda
<span class='lineno'> 362</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', title='?'>image</a> = tf.cond(
<span class='lineno'> 363</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', title='?'>orig_height</a> &gt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', title='?'>new_shape</a>,
<span class='lineno'> 364</span>       lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad', title='(?, ?, ?, ?, bool, bool) -> None'>crop_or_pad</a>(
<span class='lineno'> 365</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', title='?'>orig_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', title='?'>orig_width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', title='?'>new_shape</a>, height=True, crop=True),
<span class='lineno'> 366</span>       lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad', title='(?, ?, ?, ?, bool, bool) -> None'>crop_or_pad</a>(
<span class='lineno'> 367</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', title='?'>orig_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', title='?'>orig_width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', title='?'>new_shape</a>, height=True, crop=False))
<span class='lineno'> 368</span> 
<span class='lineno'> 369</span>   # Crop or pad width.
<span class='lineno'> 370</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', title='?'>image</a> = tf.cond(
<span class='lineno'> 371</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', title='?'>orig_width</a> &gt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', title='?'>new_shape</a>,
<span class='lineno'> 372</span>       lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad', title='(?, ?, ?, ?, bool, bool) -> None'>crop_or_pad</a>(
<span class='lineno'> 373</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', title='?'>orig_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', title='?'>orig_width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', title='?'>new_shape</a>, height=False, crop=True),
<span class='lineno'> 374</span>       lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_or_pad', title='(?, ?, ?, ?, bool, bool) -> None'>crop_or_pad</a>(
<span class='lineno'> 375</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_height', title='?'>orig_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.orig_width', title='?'>orig_width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', title='?'>new_shape</a>, height=False, crop=False))
<span class='lineno'> 376</span> 
<span class='lineno'> 377</span>   # Get the bounding box of the original centered box in the new resized image.
<span class='lineno'> 378</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.original_bounding_box', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.original_bounding_box', title='None'>original_bounding_box</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.get_central_bbox', title='(?, ?) -> None'>get_central_bbox</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.min_side', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.min_side', title='?'>min_side</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.new_shape', title='?'>new_shape</a>)
<span class='lineno'> 379</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.original_bounding_box', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max.original_bounding_box', title='None'>original_bounding_box</a>
<span class='lineno'> 380</span> 
<span class='lineno'> 381</span> 
<span class='lineno'> 382</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation', title='(?, float) -> None / (?, ?) -> None'>scale_up_augmentation</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.max_scale', title='float'>max_scale</a>):
<span class='lineno'> 383</span>   &quot;&quot;&quot;Scales an image randomly &gt;100% up to some max scale.&quot;&quot;&quot;
<span class='lineno'> 384</span>   # Pad to max size.
<span class='lineno'> 385</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.original_central_bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.original_central_bbox', title='None'>original_central_bbox</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.pad_to_max', title='(?, float) -> (?, None) / (?, ?) -> (?, None)'>pad_to_max</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.max_scale', title='float'>max_scale</a>)
<span class='lineno'> 386</span> 
<span class='lineno'> 387</span>   # Determine area range of the augmented crop, as a percentage of the
<span class='lineno'> 388</span>   # new max area.
<span class='lineno'> 389</span>   # aug_max == 100% of new max area.
<span class='lineno'> 390</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.aug_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.aug_max', title='float'>aug_max</a> = 1.0
<span class='lineno'> 391</span>   # aug_min == original_area/new_area == original_area/(max_scale*original_area)
<span class='lineno'> 392</span>   # == 1/max_scale.
<span class='lineno'> 393</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.aug_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.aug_min', title='float'>aug_min</a> = 1.0/<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.max_scale', title='float'>max_scale</a>
<span class='lineno'> 394</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.area_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.area_range', title='(float, float)'>area_range</a> = (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.aug_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.aug_min', title='float'>aug_min</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.aug_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.aug_max', title='float'>aug_max</a>)
<span class='lineno'> 395</span>   # Since we&#39;re doing &gt;100% scale, always have the full original crop in frame.
<span class='lineno'> 396</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.min_object_covered', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.min_object_covered', title='float'>min_object_covered</a> = 1.0
<span class='lineno'> 397</span>   # Get a random scaled, cropped image.
<span class='lineno'> 398</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop', title='(None, ?, (float, float), float) -> None / (?, None, (float, float), float) -> None / (None, ?, (?, float), ?) -> None / (?, ?, ?, ?) -> None'>scale_augment_crop</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.original_central_bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.original_central_bbox', title='None'>original_central_bbox</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.area_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.area_range', title='(float, float)'>area_range</a>,
<span class='lineno'> 399</span>                              <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.min_object_covered', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.min_object_covered', title='float'>min_object_covered</a>)
<span class='lineno'> 400</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation.image', title='None'>image</a>
<span class='lineno'> 401</span> 
<span class='lineno'> 402</span> 
<span class='lineno'> 403</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation', title='(?, float) -> None / (?, ?) -> None'>scale_down_augmentation</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.min_scale', title='float'>min_scale</a>):
<span class='lineno'> 404</span>   &quot;&quot;&quot;Scales an image randomly &lt;100% down to some min scale.&quot;&quot;&quot;
<span class='lineno'> 405</span>   # Crop the center, and consider the whole image the bounding box ROI.
<span class='lineno'> 406</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center', title='? -> None'>crop_center</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', title='?'>image</a>)
<span class='lineno'> 407</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.bbox', title='?'>bbox</a> = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])
<span class='lineno'> 408</span>   # Determine area range of the augmented crop, as a percentage of the
<span class='lineno'> 409</span>   # original crop center area.
<span class='lineno'> 410</span>   # aug_max == 100% of original area.
<span class='lineno'> 411</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.area_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.area_range', title='(float, float)'>area_range</a> = (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.min_scale', title='float'>min_scale</a>, 1.0)
<span class='lineno'> 412</span>   # Get a random scaled, cropped image.
<span class='lineno'> 413</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_augment_crop', title='(None, ?, (float, float), float) -> None / (?, None, (float, float), float) -> None / (None, ?, (?, float), ?) -> None / (?, ?, ?, ?) -> None'>scale_augment_crop</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', title='None'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.bbox', title='?'>bbox</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.area_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.area_range', title='(float, float)'>area_range</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.min_scale', title='float'>min_scale</a>)
<span class='lineno'> 414</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation.image', title='None'>image</a>
<span class='lineno'> 415</span> 
<span class='lineno'> 416</span> 
<span class='lineno'> 417</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale', title='(?, float, float, float) -> None / (?, ?, ?, ?) -> None'>augment_image_scale</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', title='float'>min_scale</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', title='float'>max_scale</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.p_scale_up', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.p_scale_up', title='float'>p_scale_up</a>):
<span class='lineno'> 418</span>   &quot;&quot;&quot;Training time scale augmentation.
<span class='lineno'> 419</span> 
<span class='lineno'> 420</span>   Args:
<span class='lineno'> 421</span>     image: 3-d float tensor representing image.
<span class='lineno'> 422</span>     min_scale: minimum scale augmentation allowed, as a fraction of the
<span class='lineno'> 423</span>       central min_side * min_side area of the original image.
<span class='lineno'> 424</span>     max_scale: maximum scale augmentation allowed, as a fraction of the
<span class='lineno'> 425</span>       central min_side * min_side area of the original image.
<span class='lineno'> 426</span>     p_scale_up: Fraction of images scaled up.
<span class='lineno'> 427</span>   Returns:
<span class='lineno'> 428</span>     image: The scale-augmented image.
<span class='lineno'> 429</span>   &quot;&quot;&quot;
<span class='lineno'> 430</span>   assert <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', title='float'>max_scale</a> &gt;= 1.0
<span class='lineno'> 431</span>   assert <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', title='float'>min_scale</a> &lt;= 1.0
<span class='lineno'> 432</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', title='float'>min_scale</a> == <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', title='float'>max_scale</a> == 1.0:
<span class='lineno'> 433</span>     tf.logging.info(&#39;Min and max scale are 1.0, don`t augment.&#39;)
<span class='lineno'> 434</span>     # Do no augmentation, just crop the center.
<span class='lineno'> 435</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_center', title='? -> None'>crop_center</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', title='?'>image</a>)
<span class='lineno'> 436</span>   elif (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', title='float'>max_scale</a> == 1.0) and (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', title='float'>min_scale</a> &lt; 1.0):
<span class='lineno'> 437</span>     tf.logging.info(&#39;Max scale is 1.0, only scale down augment.&#39;)
<span class='lineno'> 438</span>     # Always do &lt;100% augmentation.
<span class='lineno'> 439</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation', title='(?, float) -> None / (?, ?) -> None'>scale_down_augmentation</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', title='float'>min_scale</a>)
<span class='lineno'> 440</span>   elif (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', title='float'>min_scale</a> == 1.0) and (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', title='float'>max_scale</a> &gt; 1.0):
<span class='lineno'> 441</span>     tf.logging.info(&#39;Min scale is 1.0, only scale up augment.&#39;)
<span class='lineno'> 442</span>     # Always do &gt;100% augmentation.
<span class='lineno'> 443</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation', title='(?, float) -> None / (?, ?) -> None'>scale_up_augmentation</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', title='float'>max_scale</a>)
<span class='lineno'> 444</span>   else:
<span class='lineno'> 445</span>     tf.logging.info(&#39;Sample both augmentations.&#39;)
<span class='lineno'> 446</span>     # Choose to scale image up or down.
<span class='lineno'> 447</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.rn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.rn', title='?'>rn</a> = tf.random_uniform([], minval=0., maxval=1., dtype=tf.float32)
<span class='lineno'> 448</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', title='?'>image</a> = tf.cond(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.rn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.rn', title='?'>rn</a> &gt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.p_scale_up', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.p_scale_up', title='float'>p_scale_up</a>,
<span class='lineno'> 449</span>                     lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_up_augmentation', title='(?, float) -> None / (?, ?) -> None'>scale_up_augmentation</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.max_scale', title='?'>max_scale</a>),
<span class='lineno'> 450</span>                     lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_down_augmentation', title='(?, float) -> None / (?, ?) -> None'>scale_down_augmentation</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.min_scale', title='?'>min_scale</a>))
<span class='lineno'> 451</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale.image', title='?'>image</a>
<span class='lineno'> 452</span> 
<span class='lineno'> 453</span> 
<span class='lineno'> 454</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image', title='? -> None'>decode_image</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image_str', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image_str', title='?'>image_str</a>):
<span class='lineno'> 455</span>   &quot;&quot;&quot;Decodes a jpeg-encoded image string into a image in range [0,1].&quot;&quot;&quot;
<span class='lineno'> 456</span>   # Decode jpeg string into np.uint8 tensor.
<span class='lineno'> 457</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image', title='?'>image</a> = tf.image.decode_jpeg(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image_str', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image_str', title='?'>image_str</a>, channels=3)
<span class='lineno'> 458</span>   # Convert the image to range [0,1].
<span class='lineno'> 459</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image', title='?'>image</a>.dtype != tf.float32:
<span class='lineno'> 460</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image', title='?'>image</a> = tf.image.convert_image_dtype(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image', title='?'>image</a>, dtype=tf.float32)
<span class='lineno'> 461</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image.image', title='?'>image</a>
<span class='lineno'> 462</span> 
<span class='lineno'> 463</span> 
<span class='lineno'> 464</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_images', title='? -> None'>decode_images</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_images.image_strs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_images.image_strs', title='?'>image_strs</a>):
<span class='lineno'> 465</span>   &quot;&quot;&quot;Decodes a tensor of image strings.&quot;&quot;&quot;
<span class='lineno'> 466</span>   return tf.map_fn(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_image', title='? -> None'>decode_image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_images.image_strs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.decode_images.image_strs', title='?'>image_strs</a>, dtype=tf.float32)
<span class='lineno'> 467</span> 
<span class='lineno'> 468</span> 
<span class='lineno'> 469</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images', title='(?, ?, ?, ?, ?, ?, bool, bool) -> None / (?, ?, ?, float, float, float, bool, bool) -> None'>preprocess_training_images</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.images', title='?'>images</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.height', title='?'>height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.width', title='?'>width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.min_scale', title='float'>min_scale</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.max_scale', title='float'>max_scale</a>,
<span class='lineno'> 470</span>                                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.p_scale_up', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.p_scale_up', title='float'>p_scale_up</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.aug_color', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.aug_color', title='bool'>aug_color</a>=True, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.fast_mode', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.fast_mode', title='bool'>fast_mode</a>=True):
<span class='lineno'> 471</span>   &quot;&quot;&quot;Preprocesses a batch of images for training.
<span class='lineno'> 472</span> 
<span class='lineno'> 473</span>   This applies training-time scale and color augmentation, crops/resizes,
<span class='lineno'> 474</span>   and scales images to the [-1,1] range expected by pre-trained Inception nets.
<span class='lineno'> 475</span> 
<span class='lineno'> 476</span>   Args:
<span class='lineno'> 477</span>     images: A 4-D float32 `Tensor` holding raw images to be preprocessed.
<span class='lineno'> 478</span>     height: Int, height in pixels to resize image to.
<span class='lineno'> 479</span>     width: Int, width in pixels to resize image to.
<span class='lineno'> 480</span>     min_scale: Float, minimum scale augmentation allowed, as a fraction of the
<span class='lineno'> 481</span>       central min_side * min_side area of the original image.
<span class='lineno'> 482</span>     max_scale: Float, maximum scale augmentation allowed, as a fraction of the
<span class='lineno'> 483</span>       central min_side * min_side area of the original image.
<span class='lineno'> 484</span>     p_scale_up: Float, fraction of images scaled up.
<span class='lineno'> 485</span>     aug_color: Whether or not to do color augmentation.
<span class='lineno'> 486</span>     fast_mode: Boolean, avoids slower ops (random_hue and random_contrast).
<span class='lineno'> 487</span>   Returns:
<span class='lineno'> 488</span>     preprocessed_images: A 4-D float32 `Tensor` holding preprocessed images.
<span class='lineno'> 489</span>   &quot;&quot;&quot;
<span class='lineno'> 490</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images._prepro_train', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images._prepro_train', title='? -> None'>_prepro_train</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images._prepro_train.im', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images._prepro_train.im', title='?'>im</a>):
<span class='lineno'> 491</span>     &quot;&quot;&quot;Map this preprocessing function over each image in the batch.&quot;&quot;&quot;
<span class='lineno'> 492</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image', title='(?, ?, ?, float, float, float, bool, bool) -> None / (?, ?, ?, ?, ?, ?, bool, bool) -> None'>preprocess_training_image</a>(
<span class='lineno'> 493</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images._prepro_train.im', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images._prepro_train.im', title='?'>im</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.width', title='?'>width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.min_scale', title='float'>min_scale</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.max_scale', title='float'>max_scale</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.p_scale_up', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.p_scale_up', title='float'>p_scale_up</a>,
<span class='lineno'> 494</span>         aug_color=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.aug_color', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.aug_color', title='bool'>aug_color</a>, fast_mode=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.fast_mode', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.fast_mode', title='bool'>fast_mode</a>)
<span class='lineno'> 495</span>   return tf.map_fn(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images._prepro_train', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images._prepro_train', title='? -> None'>_prepro_train</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images.images', title='?'>images</a>)
<span class='lineno'> 496</span> 
<span class='lineno'> 497</span> 
<span class='lineno'> 498</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image', title='(?, ?, ?, float, float, float, bool, bool) -> None / (?, ?, ?, ?, ?, ?, bool, bool) -> None'>preprocess_training_image</a>(
<span class='lineno'> 499</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.height', title='?'>height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.width', title='?'>width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.min_scale', title='float'>min_scale</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.max_scale', title='float'>max_scale</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.p_scale_up', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.p_scale_up', title='float'>p_scale_up</a>,
<span class='lineno'> 500</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.aug_color', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.aug_color', title='bool'>aug_color</a>=True, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.fast_mode', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.fast_mode', title='bool'>fast_mode</a>=True):
<span class='lineno'> 501</span>   &quot;&quot;&quot;Preprocesses an image for training.
<span class='lineno'> 502</span> 
<span class='lineno'> 503</span>   Args:
<span class='lineno'> 504</span>     image: A 3-d float tensor representing the image.
<span class='lineno'> 505</span>     height: Target image height.
<span class='lineno'> 506</span>     width: Target image width.
<span class='lineno'> 507</span>     min_scale: Minimum scale of bounding box (as a percentage of full
<span class='lineno'> 508</span>       bounding box) used to crop image during scale augmentation.
<span class='lineno'> 509</span>     max_scale: Minimum scale of bounding box (as a percentage of full
<span class='lineno'> 510</span>       bounding box) used to crop image during scale augmentation.
<span class='lineno'> 511</span>     p_scale_up: Fraction of images to scale &gt;100%.
<span class='lineno'> 512</span>     aug_color: Whether or not to do color augmentation.
<span class='lineno'> 513</span>     fast_mode: Avoids slower ops (random_hue and random_contrast).
<span class='lineno'> 514</span>   Returns:
<span class='lineno'> 515</span>     scaled_image: An scaled image tensor in the range [-1,1].
<span class='lineno'> 516</span>   &quot;&quot;&quot;
<span class='lineno'> 517</span>   # Get a random scaled, cropped image.
<span class='lineno'> 518</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.augment_image_scale', title='(?, float, float, float) -> None / (?, ?, ?, ?) -> None'>augment_image_scale</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.min_scale', title='float'>min_scale</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.max_scale', title='float'>max_scale</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.p_scale_up', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.p_scale_up', title='float'>p_scale_up</a>)
<span class='lineno'> 519</span> 
<span class='lineno'> 520</span>   # Resize image to desired height, width.
<span class='lineno'> 521</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='?'>image</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='None'>image</a>, 0)
<span class='lineno'> 522</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='?'>image</a> = tf.image.resize_bilinear(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='?'>image</a>, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.width', title='?'>width</a>], align_corners=False)
<span class='lineno'> 523</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='?'>image</a> = tf.squeeze(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='?'>image</a>, [0])
<span class='lineno'> 524</span> 
<span class='lineno'> 525</span>   # Optionally augment the color.
<span class='lineno'> 526</span>   # pylint: disable=g-long-lambda
<span class='lineno'> 527</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.aug_color', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.aug_color', title='bool'>aug_color</a>:
<span class='lineno'> 528</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.apply_with_random_selector', title='(?, (?, int) -> None, int) -> None / (?, ?, ?) -> None'>apply_with_random_selector</a>(
<span class='lineno'> 529</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='?'>image</a>,
<span class='lineno'> 530</span>         lambda <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.lambda%188.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.lambda%188.x', title='?'>x</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.lambda%188.ordering', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.lambda%188.ordering', title='int'>ordering</a>: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.distort_color', title='(?, int, bool, None) -> None'>distort_color</a>(
<span class='lineno'> 531</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.lambda%188.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.lambda%188.x', title='?'>x</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.lambda%188.ordering', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.lambda%188.ordering', title='int'>ordering</a>, fast_mode=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.fast_mode', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.fast_mode', title='bool'>fast_mode</a>), num_cases=4)
<span class='lineno'> 532</span> 
<span class='lineno'> 533</span>   # Scale to [-1,1] range as expected by inception.
<span class='lineno'> 534</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.scaled_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.scaled_image', title='None'>scaled_image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range', title='? -> None / None -> None'>scale_to_inception_range</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.image', title='None'>image</a>)
<span class='lineno'> 535</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.scaled_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_image.scaled_image', title='None'>scaled_image</a>
<span class='lineno'> 536</span> 
<span class='lineno'> 537</span> 
<span class='lineno'> 538</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image', title='(?, ?, ?, str) -> None / (?, ?, ?, ?) -> None'>preprocess_test_image</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.height', title='?'>height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.width', title='?'>width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.crop_strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.crop_strategy', title='str'>crop_strategy</a>):
<span class='lineno'> 539</span>   &quot;&quot;&quot;Preprocesses an image for test/inference.
<span class='lineno'> 540</span> 
<span class='lineno'> 541</span>   Args:
<span class='lineno'> 542</span>     image: A 3-d float tensor representing the image.
<span class='lineno'> 543</span>     height: Target image height.
<span class='lineno'> 544</span>     width: Target image width.
<span class='lineno'> 545</span>     crop_strategy: String, name of the strategy used to crop test-time images.
<span class='lineno'> 546</span>       Can be: &#39;crop_center&#39;, &#39;pad&#39;, &#39;pad_200&#39;, &#39;pad_crop_central&#39;.
<span class='lineno'> 547</span>   Returns:
<span class='lineno'> 548</span>     scaled_image: An scaled image tensor in the range [-1,1].
<span class='lineno'> 549</span>   &quot;&quot;&quot;
<span class='lineno'> 550</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.crop_image_by_strategy', title='(?, str) -> None / (?, ?) -> None'>crop_image_by_strategy</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.crop_strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.crop_strategy', title='str'>crop_strategy</a>)
<span class='lineno'> 551</span>   # Resize.
<span class='lineno'> 552</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.resize_image', title='(?, ?, ?) -> None / (None, ?, ?) -> None'>resize_image</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', title='None'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.width', title='?'>width</a>)
<span class='lineno'> 553</span>   # Scale the input range to [-1,1] as expected by inception.
<span class='lineno'> 554</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.scale_to_inception_range', title='? -> None / None -> None'>scale_to_inception_range</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', title='None'>image</a>)
<span class='lineno'> 555</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image.image', title='None'>image</a>
<span class='lineno'> 556</span> 
<span class='lineno'> 557</span> 
<span class='lineno'> 558</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images', title='(?, ?, ?, str) -> None / (?, ?, ?, ?) -> None'>preprocess_test_images</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.images', title='?'>images</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.height', title='?'>height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.width', title='?'>width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.crop_strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.crop_strategy', title='str'>crop_strategy</a>):
<span class='lineno'> 559</span>   &quot;&quot;&quot;Apply test-time preprocessing to a batch of images.
<span class='lineno'> 560</span> 
<span class='lineno'> 561</span>   This crops images (given a named strategy for doing so), resizes them,
<span class='lineno'> 562</span>   and scales them to the [-1,1] range expected by pre-trained Inception nets.
<span class='lineno'> 563</span> 
<span class='lineno'> 564</span>   Args:
<span class='lineno'> 565</span>     images: A 4-D float32 `Tensor` holding raw images to be preprocessed.
<span class='lineno'> 566</span>     height: Int, height in pixels to resize image to.
<span class='lineno'> 567</span>     width: Int, width in pixels to resize image to.
<span class='lineno'> 568</span>     crop_strategy: String, name of the strategy used to crop test-time images.
<span class='lineno'> 569</span>       Can be: &#39;crop_center&#39;, &#39;pad&#39;, &#39;pad_200&#39;, &#39;pad_crop_central&#39;.
<span class='lineno'> 570</span>   Returns:
<span class='lineno'> 571</span>     preprocessed_images: A 4-D float32 `Tensor` holding preprocessed images.
<span class='lineno'> 572</span>   &quot;&quot;&quot;
<span class='lineno'> 573</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images._prepro_test', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images._prepro_test', title='? -> None'>_prepro_test</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images._prepro_test.im', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images._prepro_test.im', title='?'>im</a>):
<span class='lineno'> 574</span>     &quot;&quot;&quot;Map this preprocessing function over each image in the batch.&quot;&quot;&quot;
<span class='lineno'> 575</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_image', title='(?, ?, ?, str) -> None / (?, ?, ?, ?) -> None'>preprocess_test_image</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images._prepro_test.im', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images._prepro_test.im', title='?'>im</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.width', title='?'>width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.crop_strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.crop_strategy', title='str'>crop_strategy</a>)
<span class='lineno'> 576</span>   if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.images', title='?'>images</a>.shape) == 3:
<span class='lineno'> 577</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images._prepro_test', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images._prepro_test', title='? -> None'>_prepro_test</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.images', title='?'>images</a>)
<span class='lineno'> 578</span>   else:
<span class='lineno'> 579</span>     return tf.map_fn(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images._prepro_test', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images._prepro_test', title='? -> None'>_prepro_test</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images.images', title='?'>images</a>)
<span class='lineno'> 580</span> 
<span class='lineno'> 581</span> 
<span class='lineno'> 582</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images', title='(?, ?, ?, ?, float, float, float, bool, bool, str) -> None'>preprocess_images</a>(
<span class='lineno'> 583</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.images', title='?'>images</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.is_training', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.is_training', title='?'>is_training</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.height', title='?'>height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.width', title='?'>width</a>,
<span class='lineno'> 584</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.min_scale', title='float'>min_scale</a>=1.0, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.max_scale', title='float'>max_scale</a>=1.0, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.p_scale_up', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.p_scale_up', title='float'>p_scale_up</a>=0.0,
<span class='lineno'> 585</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.aug_color', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.aug_color', title='bool'>aug_color</a>=True, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.fast_mode', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.fast_mode', title='bool'>fast_mode</a>=True,
<span class='lineno'> 586</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.crop_strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.crop_strategy', title='str'>crop_strategy</a>=&#39;pad_crop_central&#39;):
<span class='lineno'> 587</span>   &quot;&quot;&quot;Preprocess a batch of images.
<span class='lineno'> 588</span> 
<span class='lineno'> 589</span>   Args:
<span class='lineno'> 590</span>     images: A 4-D float32 `Tensor` holding raw images to be preprocessed.
<span class='lineno'> 591</span>     is_training: Boolean, whether to preprocess them for training or test.
<span class='lineno'> 592</span>     height: Int, height in pixels to resize image to.
<span class='lineno'> 593</span>     width: Int, width in pixels to resize image to.
<span class='lineno'> 594</span>     min_scale: Float, minimum scale augmentation allowed, as a fraction of the
<span class='lineno'> 595</span>       central min_side * min_side area of the original image.
<span class='lineno'> 596</span>     max_scale: Float, maximum scale augmentation allowed, as a fraction of the
<span class='lineno'> 597</span>       central min_side * min_side area of the original image.
<span class='lineno'> 598</span>     p_scale_up: Float, fraction of images scaled up.
<span class='lineno'> 599</span>     aug_color: Whether or not to do color augmentation.
<span class='lineno'> 600</span>     fast_mode: Boolean, avoids slower ops (random_hue and random_contrast).
<span class='lineno'> 601</span>     crop_strategy: String, name of the strategy used to crop test-time images.
<span class='lineno'> 602</span>       Can be: &#39;crop_center&#39;, &#39;pad&#39;, &#39;pad_200&#39;, &#39;pad_crop_central&#39;.
<span class='lineno'> 603</span>   Returns:
<span class='lineno'> 604</span>     preprocessed_images: A 4-D float32 `Tensor` holding preprocessed images.
<span class='lineno'> 605</span>   &quot;&quot;&quot;
<span class='lineno'> 606</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.is_training', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.is_training', title='?'>is_training</a>:
<span class='lineno'> 607</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_training_images', title='(?, ?, ?, ?, ?, ?, bool, bool) -> None / (?, ?, ?, float, float, float, bool, bool) -> None'>preprocess_training_images</a>(
<span class='lineno'> 608</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.images', title='?'>images</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.width', title='?'>width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.min_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.min_scale', title='float'>min_scale</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.max_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.max_scale', title='float'>max_scale</a>,
<span class='lineno'> 609</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.p_scale_up', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.p_scale_up', title='float'>p_scale_up</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.aug_color', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.aug_color', title='bool'>aug_color</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.fast_mode', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.fast_mode', title='bool'>fast_mode</a>)
<span class='lineno'> 610</span>   else:
<span class='lineno'> 611</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_test_images', title='(?, ?, ?, str) -> None / (?, ?, ?, ?) -> None'>preprocess_test_images</a>(
<span class='lineno'> 612</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.images', title='?'>images</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.width', title='?'>width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.crop_strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.preprocess_images.crop_strategy', title='str'>crop_strategy</a>)
<span class='lineno'> 613</span> 
<span class='lineno'> 614</span> 
<span class='lineno'> 615</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage', title='(?, ?) -> None'>cv2rotateimage</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', title='?'>angle</a>):
<span class='lineno'> 616</span>   &quot;&quot;&quot;Efficient rotation if 90 degrees rotations, slow otherwise.
<span class='lineno'> 617</span> 
<span class='lineno'> 618</span>   Not a tensorflow function, using cv2 and scipy on numpy arrays.
<span class='lineno'> 619</span> 
<span class='lineno'> 620</span>   Args:
<span class='lineno'> 621</span>     image: a numpy array with shape [height, width, channels].
<span class='lineno'> 622</span>     angle: the rotation angle in degrees in the range [-180, 180].
<span class='lineno'> 623</span>   Returns:
<span class='lineno'> 624</span>     The rotated image.
<span class='lineno'> 625</span>   &quot;&quot;&quot;
<span class='lineno'> 626</span>   # Limit angle to [-180, 180] degrees.
<span class='lineno'> 627</span>   assert <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', title='?'>angle</a> &lt;= 180 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', title='?'>angle</a> &gt;= -180
<span class='lineno'> 628</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', title='?'>angle</a> == 0:
<span class='lineno'> 629</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a>
<span class='lineno'> 630</span>   # Efficient rotations.
<span class='lineno'> 631</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', title='?'>angle</a> == -90:
<span class='lineno'> 632</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a> = cv2.transpose(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a>)
<span class='lineno'> 633</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a> = cv2.flip(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a>, 0)
<span class='lineno'> 634</span>   elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', title='?'>angle</a> == 90:
<span class='lineno'> 635</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a> = cv2.transpose(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a>)
<span class='lineno'> 636</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a> = cv2.flip(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a>, 1)
<span class='lineno'> 637</span>   elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', title='?'>angle</a> == 180 or <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.angle', title='?'>angle</a> == -180:
<span class='lineno'> 638</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a> = cv2.flip(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a>, 0)
<span class='lineno'> 639</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a> = cv2.flip(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a>, 1)
<span class='lineno'> 640</span>   else:  # Slow rotation.
<span class='lineno'> 641</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a> = ndimage.interpolation.rotate(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a>, 270)
<span class='lineno'> 642</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2rotateimage.image', title='?'>image</a>
<span class='lineno'> 643</span> 
<span class='lineno'> 644</span> 
<span class='lineno'> 645</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge', title='(?, ?) -> None'>cv2resizeminedge</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.min_edge_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.min_edge_size', title='?'>min_edge_size</a>):
<span class='lineno'> 646</span>   &quot;&quot;&quot;Resize smallest edge of image to min_edge_size.&quot;&quot;&quot;
<span class='lineno'> 647</span>   assert <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.min_edge_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.min_edge_size', title='?'>min_edge_size</a> &gt;= 0
<span class='lineno'> 648</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.height', title='?'>height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.width', title='?'>width</a> = (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.image', title='?'>image</a>.shape[0], <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.image', title='?'>image</a>.shape[1])
<span class='lineno'> 649</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_height', title='int'>new_height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_width', title='int'>new_width</a> = (0, 0)
<span class='lineno'> 650</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.height', title='?'>height</a> &gt; <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.width', title='?'>width</a>:
<span class='lineno'> 651</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_width', title='?'>new_width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.min_edge_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.min_edge_size', title='?'>min_edge_size</a>
<span class='lineno'> 652</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_height', title='int'>new_height</a> = int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.height', title='?'>height</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_width', title='?'>new_width</a> / float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.width', title='?'>width</a>))
<span class='lineno'> 653</span>   else:
<span class='lineno'> 654</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_height', title='?'>new_height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.min_edge_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.min_edge_size', title='?'>min_edge_size</a>
<span class='lineno'> 655</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_width', title='int'>new_width</a> = int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.width', title='?'>width</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_height', title='?'>new_height</a> / float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.height', title='?'>height</a>))
<span class='lineno'> 656</span>   return cv2.resize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.image', title='?'>image</a>, (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_width', title='int'>new_width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.cv2resizeminedge.new_height', title='int'>new_height</a>),
<span class='lineno'> 657</span>                     interpolation=cv2.INTER_AREA)
<span class='lineno'> 658</span> 
<span class='lineno'> 659</span> 
<span class='lineno'> 660</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring', title='? -> str'>shapestring</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.array', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.array', title='?'>array</a>):
<span class='lineno'> 661</span>   &quot;&quot;&quot;Returns a compact string describing shape of an array.&quot;&quot;&quot;
<span class='lineno'> 662</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.shape', title='?'>shape</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.array', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.array', title='?'>array</a>.shape
<span class='lineno'> 663</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.s', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.s', title='str'>s</a> = str(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.shape', title='?'>shape</a>[0])
<span class='lineno'> 664</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.i', title='int'>i</a> in range(1, len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.shape', title='?'>shape</a>)):
<span class='lineno'> 665</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.s', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.s', title='str'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.s', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.s', title='str'>s</a></a> += &#39;x&#39; + str(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.shape', title='?'>shape</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.i', title='int'>i</a>])
<span class='lineno'> 666</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.s', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.shapestring.s', title='str'>s</a>
<span class='lineno'> 667</span> 
<span class='lineno'> 668</span> 
<span class='lineno'> 669</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode', title='? -> None'>unscale_jpeg_encode</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='?'>ims</a>):
<span class='lineno'> 670</span>   &quot;&quot;&quot;Unscales pixel values and jpeg encodes preprocessed image.
<span class='lineno'> 671</span> 
<span class='lineno'> 672</span>   Args:
<span class='lineno'> 673</span>     ims: A 4-D float32 `Tensor` holding preprocessed images.
<span class='lineno'> 674</span>   Returns:
<span class='lineno'> 675</span>     im_strings: A 1-D string `Tensor` holding images that have been unscaled
<span class='lineno'> 676</span>       (reversing the inception [-1,1] scaling), and jpeg encoded.
<span class='lineno'> 677</span>   &quot;&quot;&quot;
<span class='lineno'> 678</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='float'>ims</a></a> /= 2.0
<span class='lineno'> 679</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='float'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='float'>ims</a></a> += 0.5
<span class='lineno'> 680</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='float'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='float'>ims</a></a> *= 255.0
<span class='lineno'> 681</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='?'>ims</a> = tf.clip_by_value(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='float'>ims</a>, 0, 255)
<span class='lineno'> 682</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='?'>ims</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='?'>ims</a>, tf.uint8)
<span class='lineno'> 683</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.im_strings', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.im_strings', title='?'>im_strings</a> = tf.map_fn(
<span class='lineno'> 684</span>       lambda <a name='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.lambda%189.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.lambda%189.x', title='?'>x</a>: tf.image.encode_jpeg(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.lambda%189.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.lambda%189.x', title='?'>x</a>, format=&#39;rgb&#39;, quality=100),
<span class='lineno'> 685</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.ims', title='?'>ims</a>, dtype=tf.string)
<span class='lineno'> 686</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.im_strings', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.tcn.preprocessing.unscale_jpeg_encode.im_strings', title='?'>im_strings</a>
</pre></td></tr></table></body></html>