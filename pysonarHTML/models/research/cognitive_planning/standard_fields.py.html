<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/cognitive_planning/standard_fields.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields'>InputDataFields</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.image', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.image'>image</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.image_additional_channels', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.image_additional_channels'>image_additional_channels</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.original_image', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.original_image'>original_image</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.key', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.key'>key</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.source_id', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.source_id'>source_id</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.filename', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.filename'>filename</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_image_classes', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_image_classes'>groundtruth_image_classes</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_boxes', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_boxes'>groundtruth_boxes</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_classes', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_classes'>groundtruth_classes</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_label_types', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_label_types'>groundtruth_label_types</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_is_crowd', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_is_crowd'>groundtruth_is_crowd</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_area', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_area'>groundtruth_area</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_difficult', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_difficult'>groundtruth_difficult</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_group_of', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_group_of'>groundtruth_group_of</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.proposal_boxes', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.proposal_boxes'>proposal_boxes</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.proposal_objectness', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.proposal_objectness'>proposal_objectness</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_masks', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_masks'>groundtruth_instance_masks</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_boundaries', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_boundaries'>groundtruth_instance_boundaries</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_classes', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_classes'>groundtruth_instance_classes</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_keypoints', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_keypoints'>groundtruth_keypoints</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_keypoint_visibilities', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_keypoint_visibilities'>groundtruth_keypoint_visibilities</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_label_scores', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_label_scores'>groundtruth_label_scores</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_weights', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_weights'>groundtruth_weights</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.num_groundtruth_boxes', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.num_groundtruth_boxes'>num_groundtruth_boxes</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.true_image_shape', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.true_image_shape'>true_image_shape</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.multiclass_scores', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.multiclass_scores'>multiclass_scores</a></li></ul>
</li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields'>DetectionResultFields</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.source_id', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.source_id'>source_id</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.key', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.key'>key</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_boxes', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_boxes'>detection_boxes</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_scores', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_scores'>detection_scores</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_classes', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_classes'>detection_classes</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_masks', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_masks'>detection_masks</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_boundaries', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_boundaries'>detection_boundaries</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_keypoints', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_keypoints'>detection_keypoints</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.num_detections', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.num_detections'>num_detections</a></li></ul>
</li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields'>BoxListFields</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.boxes', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.boxes'>boxes</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.classes', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.classes'>classes</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.scores', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.scores'>scores</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.weights', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.weights'>weights</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.objectness', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.objectness'>objectness</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.masks', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.masks'>masks</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.boundaries', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.boundaries'>boundaries</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.keypoints', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.keypoints'>keypoints</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.keypoint_heatmaps', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.keypoint_heatmaps'>keypoint_heatmaps</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.is_crowd', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.is_crowd'>is_crowd</a></li></ul>
</li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields'>TfExampleFields</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_encoded', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_encoded'>image_encoded</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_format', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_format'>image_format</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.filename', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.filename'>filename</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.channels', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.channels'>channels</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.colorspace', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.colorspace'>colorspace</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.height', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.height'>height</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.width', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.width'>width</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.source_id', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.source_id'>source_id</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_class_text', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_class_text'>image_class_text</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_class_label', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_class_label'>image_class_label</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_class_text', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_class_text'>object_class_text</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_class_label', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_class_label'>object_class_label</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_ymin', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_ymin'>object_bbox_ymin</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_xmin', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_xmin'>object_bbox_xmin</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_ymax', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_ymax'>object_bbox_ymax</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_xmax', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_xmax'>object_bbox_xmax</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_view', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_view'>object_view</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_truncated', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_truncated'>object_truncated</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_occluded', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_occluded'>object_occluded</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_difficult', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_difficult'>object_difficult</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_group_of', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_group_of'>object_group_of</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_depiction', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_depiction'>object_depiction</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_is_crowd', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_is_crowd'>object_is_crowd</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_segment_area', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_segment_area'>object_segment_area</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_weight', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_weight'>object_weight</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_masks', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_masks'>instance_masks</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_boundaries', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_boundaries'>instance_boundaries</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_classes', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_classes'>instance_classes</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_class_label', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_class_label'>detection_class_label</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_ymin', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_ymin'>detection_bbox_ymin</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_xmin', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_xmin'>detection_bbox_xmin</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_ymax', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_ymax'>detection_bbox_ymax</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_xmax', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_xmax'>detection_bbox_xmax</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_score', xid='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_score'>detection_score</a></li></ul>
</li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2017 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> &quot;&quot;&quot;Contains classes specifying naming conventions used for object detection.
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> 
<span class='lineno'>  19</span> Specifies:
<span class='lineno'>  20</span>   InputDataFields: standard fields used by reader/preprocessor/batcher.
<span class='lineno'>  21</span>   DetectionResultFields: standard fields returned by object detector.
<span class='lineno'>  22</span>   BoxListFields: standard field used by BoxList
<span class='lineno'>  23</span>   TfExampleFields: standard fields for tf-example data format (go/tf-example).
<span class='lineno'>  24</span> &quot;&quot;&quot;
<span class='lineno'>  25</span> 
<span class='lineno'>  26</span> 
<span class='lineno'>  27</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields', title='<InputDataFields>'>InputDataFields</a>(object):
<span class='lineno'>  28</span>   &quot;&quot;&quot;Names for the input tensors.
<span class='lineno'>  29</span> 
<span class='lineno'>  30</span>   Holds the standard data field names to use for identifying input tensors. This
<span class='lineno'>  31</span>   should be used by the decoder to identify keys for the returned tensor_dict
<span class='lineno'>  32</span>   containing input tensors. And it should be used by the model to identify the
<span class='lineno'>  33</span>   tensors it needs.
<span class='lineno'>  34</span> 
<span class='lineno'>  35</span>   Attributes:
<span class='lineno'>  36</span>     image: image.
<span class='lineno'>  37</span>     image_additional_channels: additional channels.
<span class='lineno'>  38</span>     original_image: image in the original input size.
<span class='lineno'>  39</span>     key: unique key corresponding to image.
<span class='lineno'>  40</span>     source_id: source of the original image.
<span class='lineno'>  41</span>     filename: original filename of the dataset (without common path).
<span class='lineno'>  42</span>     groundtruth_image_classes: image-level class labels.
<span class='lineno'>  43</span>     groundtruth_boxes: coordinates of the ground truth boxes in the image.
<span class='lineno'>  44</span>     groundtruth_classes: box-level class labels.
<span class='lineno'>  45</span>     groundtruth_label_types: box-level label types (e.g. explicit negative).
<span class='lineno'>  46</span>     groundtruth_is_crowd: [DEPRECATED, use groundtruth_group_of instead]
<span class='lineno'>  47</span>       is the groundtruth a single object or a crowd.
<span class='lineno'>  48</span>     groundtruth_area: area of a groundtruth segment.
<span class='lineno'>  49</span>     groundtruth_difficult: is a `difficult` object
<span class='lineno'>  50</span>     groundtruth_group_of: is a `group_of` objects, e.g. multiple objects of the
<span class='lineno'>  51</span>       same class, forming a connected group, where instances are heavily
<span class='lineno'>  52</span>       occluding each other.
<span class='lineno'>  53</span>     proposal_boxes: coordinates of object proposal boxes.
<span class='lineno'>  54</span>     proposal_objectness: objectness score of each proposal.
<span class='lineno'>  55</span>     groundtruth_instance_masks: ground truth instance masks.
<span class='lineno'>  56</span>     groundtruth_instance_boundaries: ground truth instance boundaries.
<span class='lineno'>  57</span>     groundtruth_instance_classes: instance mask-level class labels.
<span class='lineno'>  58</span>     groundtruth_keypoints: ground truth keypoints.
<span class='lineno'>  59</span>     groundtruth_keypoint_visibilities: ground truth keypoint visibilities.
<span class='lineno'>  60</span>     groundtruth_label_scores: groundtruth label scores.
<span class='lineno'>  61</span>     groundtruth_weights: groundtruth weight factor for bounding boxes.
<span class='lineno'>  62</span>     num_groundtruth_boxes: number of groundtruth boxes.
<span class='lineno'>  63</span>     true_image_shapes: true shapes of images in the resized images, as resized
<span class='lineno'>  64</span>       images can be padded with zeros.
<span class='lineno'>  65</span>     multiclass_scores: the label score per class for each box.
<span class='lineno'>  66</span>   &quot;&quot;&quot;
<span class='lineno'>  67</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.image', title='str'>image</a> = &#39;image&#39;
<span class='lineno'>  68</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.image_additional_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.image_additional_channels', title='str'>image_additional_channels</a> = &#39;image_additional_channels&#39;
<span class='lineno'>  69</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.original_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.original_image', title='str'>original_image</a> = &#39;original_image&#39;
<span class='lineno'>  70</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.key', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.key', title='str'>key</a> = &#39;key&#39;
<span class='lineno'>  71</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.source_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.source_id', title='str'>source_id</a> = &#39;source_id&#39;
<span class='lineno'>  72</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.filename', title='str'>filename</a> = &#39;filename&#39;
<span class='lineno'>  73</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_image_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_image_classes', title='str'>groundtruth_image_classes</a> = &#39;groundtruth_image_classes&#39;
<span class='lineno'>  74</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_boxes', title='str'>groundtruth_boxes</a> = &#39;groundtruth_boxes&#39;
<span class='lineno'>  75</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_classes', title='str'>groundtruth_classes</a> = &#39;groundtruth_classes&#39;
<span class='lineno'>  76</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_label_types', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_label_types', title='str'>groundtruth_label_types</a> = &#39;groundtruth_label_types&#39;
<span class='lineno'>  77</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_is_crowd', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_is_crowd', title='str'>groundtruth_is_crowd</a> = &#39;groundtruth_is_crowd&#39;
<span class='lineno'>  78</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_area', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_area', title='str'>groundtruth_area</a> = &#39;groundtruth_area&#39;
<span class='lineno'>  79</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_difficult', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_difficult', title='str'>groundtruth_difficult</a> = &#39;groundtruth_difficult&#39;
<span class='lineno'>  80</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_group_of', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_group_of', title='str'>groundtruth_group_of</a> = &#39;groundtruth_group_of&#39;
<span class='lineno'>  81</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.proposal_boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.proposal_boxes', title='str'>proposal_boxes</a> = &#39;proposal_boxes&#39;
<span class='lineno'>  82</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.proposal_objectness', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.proposal_objectness', title='str'>proposal_objectness</a> = &#39;proposal_objectness&#39;
<span class='lineno'>  83</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_masks', title='str'>groundtruth_instance_masks</a> = &#39;groundtruth_instance_masks&#39;
<span class='lineno'>  84</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_boundaries', title='str'>groundtruth_instance_boundaries</a> = &#39;groundtruth_instance_boundaries&#39;
<span class='lineno'>  85</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_instance_classes', title='str'>groundtruth_instance_classes</a> = &#39;groundtruth_instance_classes&#39;
<span class='lineno'>  86</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_keypoints', title='str'>groundtruth_keypoints</a> = &#39;groundtruth_keypoints&#39;
<span class='lineno'>  87</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_keypoint_visibilities', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_keypoint_visibilities', title='str'>groundtruth_keypoint_visibilities</a> = &#39;groundtruth_keypoint_visibilities&#39;
<span class='lineno'>  88</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_label_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_label_scores', title='str'>groundtruth_label_scores</a> = &#39;groundtruth_label_scores&#39;
<span class='lineno'>  89</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.groundtruth_weights', title='str'>groundtruth_weights</a> = &#39;groundtruth_weights&#39;
<span class='lineno'>  90</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.num_groundtruth_boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.num_groundtruth_boxes', title='str'>num_groundtruth_boxes</a> = &#39;num_groundtruth_boxes&#39;
<span class='lineno'>  91</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.true_image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.true_image_shape', title='str'>true_image_shape</a> = &#39;true_image_shape&#39;
<span class='lineno'>  92</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.multiclass_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.InputDataFields.multiclass_scores', title='str'>multiclass_scores</a> = &#39;multiclass_scores&#39;
<span class='lineno'>  93</span> 
<span class='lineno'>  94</span> 
<span class='lineno'>  95</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields', title='<DetectionResultFields>'>DetectionResultFields</a>(object):
<span class='lineno'>  96</span>   &quot;&quot;&quot;Naming conventions for storing the output of the detector.
<span class='lineno'>  97</span> 
<span class='lineno'>  98</span>   Attributes:
<span class='lineno'>  99</span>     source_id: source of the original image.
<span class='lineno'> 100</span>     key: unique key corresponding to image.
<span class='lineno'> 101</span>     detection_boxes: coordinates of the detection boxes in the image.
<span class='lineno'> 102</span>     detection_scores: detection scores for the detection boxes in the image.
<span class='lineno'> 103</span>     detection_classes: detection-level class labels.
<span class='lineno'> 104</span>     detection_masks: contains a segmentation mask for each detection box.
<span class='lineno'> 105</span>     detection_boundaries: contains an object boundary for each detection box.
<span class='lineno'> 106</span>     detection_keypoints: contains detection keypoints for each detection box.
<span class='lineno'> 107</span>     num_detections: number of detections in the batch.
<span class='lineno'> 108</span>   &quot;&quot;&quot;
<span class='lineno'> 109</span> 
<span class='lineno'> 110</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.source_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.source_id', title='str'>source_id</a> = &#39;source_id&#39;
<span class='lineno'> 111</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.key', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.key', title='str'>key</a> = &#39;key&#39;
<span class='lineno'> 112</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_boxes', title='str'>detection_boxes</a> = &#39;detection_boxes&#39;
<span class='lineno'> 113</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_scores', title='str'>detection_scores</a> = &#39;detection_scores&#39;
<span class='lineno'> 114</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_classes', title='str'>detection_classes</a> = &#39;detection_classes&#39;
<span class='lineno'> 115</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_masks', title='str'>detection_masks</a> = &#39;detection_masks&#39;
<span class='lineno'> 116</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_boundaries', title='str'>detection_boundaries</a> = &#39;detection_boundaries&#39;
<span class='lineno'> 117</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.detection_keypoints', title='str'>detection_keypoints</a> = &#39;detection_keypoints&#39;
<span class='lineno'> 118</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.num_detections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.DetectionResultFields.num_detections', title='str'>num_detections</a> = &#39;num_detections&#39;
<span class='lineno'> 119</span> 
<span class='lineno'> 120</span> 
<span class='lineno'> 121</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields', title='<BoxListFields>'>BoxListFields</a>(object):
<span class='lineno'> 122</span>   &quot;&quot;&quot;Naming conventions for BoxLists.
<span class='lineno'> 123</span> 
<span class='lineno'> 124</span>   Attributes:
<span class='lineno'> 125</span>     boxes: bounding box coordinates.
<span class='lineno'> 126</span>     classes: classes per bounding box.
<span class='lineno'> 127</span>     scores: scores per bounding box.
<span class='lineno'> 128</span>     weights: sample weights per bounding box.
<span class='lineno'> 129</span>     objectness: objectness score per bounding box.
<span class='lineno'> 130</span>     masks: masks per bounding box.
<span class='lineno'> 131</span>     boundaries: boundaries per bounding box.
<span class='lineno'> 132</span>     keypoints: keypoints per bounding box.
<span class='lineno'> 133</span>     keypoint_heatmaps: keypoint heatmaps per bounding box.
<span class='lineno'> 134</span>     is_crowd: is_crowd annotation per bounding box.
<span class='lineno'> 135</span>   &quot;&quot;&quot;
<span class='lineno'> 136</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.boxes', title='str'>boxes</a> = &#39;boxes&#39;
<span class='lineno'> 137</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.classes', title='str'>classes</a> = &#39;classes&#39;
<span class='lineno'> 138</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.scores', title='str'>scores</a> = &#39;scores&#39;
<span class='lineno'> 139</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.weights', title='str'>weights</a> = &#39;weights&#39;
<span class='lineno'> 140</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.objectness', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.objectness', title='str'>objectness</a> = &#39;objectness&#39;
<span class='lineno'> 141</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.masks', title='str'>masks</a> = &#39;masks&#39;
<span class='lineno'> 142</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.boundaries', title='str'>boundaries</a> = &#39;boundaries&#39;
<span class='lineno'> 143</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.keypoints', title='str'>keypoints</a> = &#39;keypoints&#39;
<span class='lineno'> 144</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.keypoint_heatmaps', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.keypoint_heatmaps', title='str'>keypoint_heatmaps</a> = &#39;keypoint_heatmaps&#39;
<span class='lineno'> 145</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.is_crowd', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.BoxListFields.is_crowd', title='str'>is_crowd</a> = &#39;is_crowd&#39;
<span class='lineno'> 146</span> 
<span class='lineno'> 147</span> 
<span class='lineno'> 148</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields', title='<TfExampleFields>'>TfExampleFields</a>(object):
<span class='lineno'> 149</span>   &quot;&quot;&quot;TF-example proto feature names for object detection.
<span class='lineno'> 150</span> 
<span class='lineno'> 151</span>   Holds the standard feature names to load from an Example proto for object
<span class='lineno'> 152</span>   detection.
<span class='lineno'> 153</span> 
<span class='lineno'> 154</span>   Attributes:
<span class='lineno'> 155</span>     image_encoded: JPEG encoded string
<span class='lineno'> 156</span>     image_format: image format, e.g. &quot;JPEG&quot;
<span class='lineno'> 157</span>     filename: filename
<span class='lineno'> 158</span>     channels: number of channels of image
<span class='lineno'> 159</span>     colorspace: colorspace, e.g. &quot;RGB&quot;
<span class='lineno'> 160</span>     height: height of image in pixels, e.g. 462
<span class='lineno'> 161</span>     width: width of image in pixels, e.g. 581
<span class='lineno'> 162</span>     source_id: original source of the image
<span class='lineno'> 163</span>     image_class_text: image-level label in text format
<span class='lineno'> 164</span>     image_class_label: image-level label in numerical format
<span class='lineno'> 165</span>     object_class_text: labels in text format, e.g. [&quot;person&quot;, &quot;cat&quot;]
<span class='lineno'> 166</span>     object_class_label: labels in numbers, e.g. [16, 8]
<span class='lineno'> 167</span>     object_bbox_xmin: xmin coordinates of groundtruth box, e.g. 10, 30
<span class='lineno'> 168</span>     object_bbox_xmax: xmax coordinates of groundtruth box, e.g. 50, 40
<span class='lineno'> 169</span>     object_bbox_ymin: ymin coordinates of groundtruth box, e.g. 40, 50
<span class='lineno'> 170</span>     object_bbox_ymax: ymax coordinates of groundtruth box, e.g. 80, 70
<span class='lineno'> 171</span>     object_view: viewpoint of object, e.g. [&quot;frontal&quot;, &quot;left&quot;]
<span class='lineno'> 172</span>     object_truncated: is object truncated, e.g. [true, false]
<span class='lineno'> 173</span>     object_occluded: is object occluded, e.g. [true, false]
<span class='lineno'> 174</span>     object_difficult: is object difficult, e.g. [true, false]
<span class='lineno'> 175</span>     object_group_of: is object a single object or a group of objects
<span class='lineno'> 176</span>     object_depiction: is object a depiction
<span class='lineno'> 177</span>     object_is_crowd: [DEPRECATED, use object_group_of instead]
<span class='lineno'> 178</span>       is the object a single object or a crowd
<span class='lineno'> 179</span>     object_segment_area: the area of the segment.
<span class='lineno'> 180</span>     object_weight: a weight factor for the object&#39;s bounding box.
<span class='lineno'> 181</span>     instance_masks: instance segmentation masks.
<span class='lineno'> 182</span>     instance_boundaries: instance boundaries.
<span class='lineno'> 183</span>     instance_classes: Classes for each instance segmentation mask.
<span class='lineno'> 184</span>     detection_class_label: class label in numbers.
<span class='lineno'> 185</span>     detection_bbox_ymin: ymin coordinates of a detection box.
<span class='lineno'> 186</span>     detection_bbox_xmin: xmin coordinates of a detection box.
<span class='lineno'> 187</span>     detection_bbox_ymax: ymax coordinates of a detection box.
<span class='lineno'> 188</span>     detection_bbox_xmax: xmax coordinates of a detection box.
<span class='lineno'> 189</span>     detection_score: detection score for the class label and box.
<span class='lineno'> 190</span>   &quot;&quot;&quot;
<span class='lineno'> 191</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_encoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_encoded', title='str'>image_encoded</a> = &#39;image/encoded&#39;
<span class='lineno'> 192</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_format', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_format', title='str'>image_format</a> = &#39;image/format&#39;  # format is reserved keyword
<span class='lineno'> 193</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.filename', title='str'>filename</a> = &#39;image/filename&#39;
<span class='lineno'> 194</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.channels', title='str'>channels</a> = &#39;image/channels&#39;
<span class='lineno'> 195</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.colorspace', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.colorspace', title='str'>colorspace</a> = &#39;image/colorspace&#39;
<span class='lineno'> 196</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.height', title='str'>height</a> = &#39;image/height&#39;
<span class='lineno'> 197</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.width', title='str'>width</a> = &#39;image/width&#39;
<span class='lineno'> 198</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.source_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.source_id', title='str'>source_id</a> = &#39;image/source_id&#39;
<span class='lineno'> 199</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_class_text', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_class_text', title='str'>image_class_text</a> = &#39;image/class/text&#39;
<span class='lineno'> 200</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_class_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.image_class_label', title='str'>image_class_label</a> = &#39;image/class/label&#39;
<span class='lineno'> 201</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_class_text', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_class_text', title='str'>object_class_text</a> = &#39;image/object/class/text&#39;
<span class='lineno'> 202</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_class_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_class_label', title='str'>object_class_label</a> = &#39;image/object/class/label&#39;
<span class='lineno'> 203</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_ymin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_ymin', title='str'>object_bbox_ymin</a> = &#39;image/object/bbox/ymin&#39;
<span class='lineno'> 204</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_xmin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_xmin', title='str'>object_bbox_xmin</a> = &#39;image/object/bbox/xmin&#39;
<span class='lineno'> 205</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_ymax', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_ymax', title='str'>object_bbox_ymax</a> = &#39;image/object/bbox/ymax&#39;
<span class='lineno'> 206</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_xmax', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_bbox_xmax', title='str'>object_bbox_xmax</a> = &#39;image/object/bbox/xmax&#39;
<span class='lineno'> 207</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_view', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_view', title='str'>object_view</a> = &#39;image/object/view&#39;
<span class='lineno'> 208</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_truncated', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_truncated', title='str'>object_truncated</a> = &#39;image/object/truncated&#39;
<span class='lineno'> 209</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_occluded', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_occluded', title='str'>object_occluded</a> = &#39;image/object/occluded&#39;
<span class='lineno'> 210</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_difficult', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_difficult', title='str'>object_difficult</a> = &#39;image/object/difficult&#39;
<span class='lineno'> 211</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_group_of', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_group_of', title='str'>object_group_of</a> = &#39;image/object/group_of&#39;
<span class='lineno'> 212</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_depiction', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_depiction', title='str'>object_depiction</a> = &#39;image/object/depiction&#39;
<span class='lineno'> 213</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_is_crowd', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_is_crowd', title='str'>object_is_crowd</a> = &#39;image/object/is_crowd&#39;
<span class='lineno'> 214</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_segment_area', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_segment_area', title='str'>object_segment_area</a> = &#39;image/object/segment/area&#39;
<span class='lineno'> 215</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_weight', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.object_weight', title='str'>object_weight</a> = &#39;image/object/weight&#39;
<span class='lineno'> 216</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_masks', title='str'>instance_masks</a> = &#39;image/segmentation/object&#39;
<span class='lineno'> 217</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_boundaries', title='str'>instance_boundaries</a> = &#39;image/boundaries/object&#39;
<span class='lineno'> 218</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.instance_classes', title='str'>instance_classes</a> = &#39;image/segmentation/object/class&#39;
<span class='lineno'> 219</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_class_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_class_label', title='str'>detection_class_label</a> = &#39;image/detection/label&#39;
<span class='lineno'> 220</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_ymin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_ymin', title='str'>detection_bbox_ymin</a> = &#39;image/detection/bbox/ymin&#39;
<span class='lineno'> 221</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_xmin', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_xmin', title='str'>detection_bbox_xmin</a> = &#39;image/detection/bbox/xmin&#39;
<span class='lineno'> 222</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_ymax', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_ymax', title='str'>detection_bbox_ymax</a> = &#39;image/detection/bbox/ymax&#39;
<span class='lineno'> 223</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_xmax', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_bbox_xmax', title='str'>detection_bbox_xmax</a> = &#39;image/detection/bbox/xmax&#39;
<span class='lineno'> 224</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_score', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.cognitive_planning.standard_fields.TfExampleFields.detection_score', title='str'>detection_score</a> = &#39;image/detection/score&#39;
</pre></td></tr></table></body></html>