<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/video_prediction/lstm_ops.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state', xid='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state'>init_state</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell', xid='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell'>basic_conv_lstm_cell</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2016 The TensorFlow Authors All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> &quot;&quot;&quot;Convolutional LSTM implementation.&quot;&quot;&quot;
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> import tensorflow as tf
<span class='lineno'>  19</span> 
<span class='lineno'>  20</span> from tensorflow.contrib.slim import add_arg_scope
<span class='lineno'>  21</span> from tensorflow.contrib.slim import layers
<span class='lineno'>  22</span> 
<span class='lineno'>  23</span> 
<span class='lineno'>  24</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state', title='(?, ?, ?, ?) -> None'>init_state</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inputs', title='?'>inputs</a>,
<span class='lineno'>  25</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.state_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.state_shape', title='?'>state_shape</a>,
<span class='lineno'>  26</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.state_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.state_initializer', title='?'>state_initializer</a>=tf.zeros_initializer(),
<span class='lineno'>  27</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.dtype', title='?'>dtype</a>=tf.float32):
<span class='lineno'>  28</span>   &quot;&quot;&quot;Helper function to create an initial state given inputs.
<span class='lineno'>  29</span> 
<span class='lineno'>  30</span>   Args:
<span class='lineno'>  31</span>     inputs: input Tensor, at least 2D, the first dimension being batch_size
<span class='lineno'>  32</span>     state_shape: the shape of the state.
<span class='lineno'>  33</span>     state_initializer: Initializer(shape, dtype) for state Tensor.
<span class='lineno'>  34</span>     dtype: Optional dtype, needed when inputs is None.
<span class='lineno'>  35</span>   Returns:
<span class='lineno'>  36</span>      A tensors representing the initial state.
<span class='lineno'>  37</span>   &quot;&quot;&quot;
<span class='lineno'>  38</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inputs', title='?'>inputs</a> is not None:
<span class='lineno'>  39</span>     # Handle both the dynamic shape as well as the inferred shape.
<span class='lineno'>  40</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inferred_batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inferred_batch_size', title='?'>inferred_batch_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inputs', title='?'>inputs</a>.get_shape().with_rank_at_least(1)[0]
<span class='lineno'>  41</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.dtype', title='?'>dtype</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inputs', title='?'>inputs</a>.dtype
<span class='lineno'>  42</span>   else:
<span class='lineno'>  43</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inferred_batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inferred_batch_size', title='int'>inferred_batch_size</a> = 0
<span class='lineno'>  44</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.initial_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.initial_state', title='?'>initial_state</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.state_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.state_initializer', title='?'>state_initializer</a>(
<span class='lineno'>  45</span>       [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inferred_batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.inferred_batch_size', title='int'>inferred_batch_size</a>] + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.state_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.state_shape', title='?'>state_shape</a>, dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.dtype', title='?'>dtype</a>)
<span class='lineno'>  46</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.initial_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state.initial_state', title='?'>initial_state</a>
<span class='lineno'>  47</span> 
<span class='lineno'>  48</span> 
<span class='lineno'>  49</span> @add_arg_scope
<span class='lineno'>  50</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell', title='(?, ?, ?, int, float, None, None) -> (?, ?) / (?, None, ?, int, float, None, None) -> (?, ?)'>basic_conv_lstm_cell</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', title='?'>inputs</a>,
<span class='lineno'>  51</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', title='None'>state</a>,
<span class='lineno'>  52</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.num_channels', title='?'>num_channels</a>,
<span class='lineno'>  53</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.filter_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.filter_size', title='int'>filter_size</a>=5,
<span class='lineno'>  54</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.forget_bias', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.forget_bias', title='float'>forget_bias</a>=1.0,
<span class='lineno'>  55</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.scope', title='None'>scope</a>=None,
<span class='lineno'>  56</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.reuse', title='None'>reuse</a>=None):
<span class='lineno'>  57</span>   &quot;&quot;&quot;Basic LSTM recurrent network cell, with 2D convolution connctions.
<span class='lineno'>  58</span> 
<span class='lineno'>  59</span>   We add forget_bias (default: 1) to the biases of the forget gate in order to
<span class='lineno'>  60</span>   reduce the scale of forgetting in the beginning of the training.
<span class='lineno'>  61</span> 
<span class='lineno'>  62</span>   It does not allow cell clipping, a projection layer, and does not
<span class='lineno'>  63</span>   use peep-hole connections: it is the basic baseline.
<span class='lineno'>  64</span> 
<span class='lineno'>  65</span>   Args:
<span class='lineno'>  66</span>     inputs: input Tensor, 4D, batch x height x width x channels.
<span class='lineno'>  67</span>     state: state Tensor, 4D, batch x height x width x channels.
<span class='lineno'>  68</span>     num_channels: the number of output channels in the layer.
<span class='lineno'>  69</span>     filter_size: the shape of the each convolution filter.
<span class='lineno'>  70</span>     forget_bias: the initial value of the forget biases.
<span class='lineno'>  71</span>     scope: Optional scope for variable_scope.
<span class='lineno'>  72</span>     reuse: whether or not the layer and the variables should be reused.
<span class='lineno'>  73</span> 
<span class='lineno'>  74</span>   Returns:
<span class='lineno'>  75</span>      a tuple of tensors representing output and the new state.
<span class='lineno'>  76</span>   &quot;&quot;&quot;
<span class='lineno'>  77</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.spatial_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.spatial_size', title='?'>spatial_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', title='?'>inputs</a>.get_shape()[1:3]
<span class='lineno'>  78</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', title='None'>state</a> is None:
<span class='lineno'>  79</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', title='None'>state</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.init_state', title='(?, ?, ?, ?) -> None'>init_state</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', title='?'>inputs</a>, list(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.spatial_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.spatial_size', title='?'>spatial_size</a>) + [2 * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.num_channels', title='?'>num_channels</a>])
<span class='lineno'>  80</span>   with tf.variable_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.scope', title='None'>scope</a>,
<span class='lineno'>  81</span>                          &#39;BasicConvLstmCell&#39;,
<span class='lineno'>  82</span>                          [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', title='?'>inputs</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', title='None'>state</a>],
<span class='lineno'>  83</span>                          reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.reuse', title='None'>reuse</a>):
<span class='lineno'>  84</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', title='?'>inputs</a>.get_shape().assert_has_rank(4)
<span class='lineno'>  85</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', title='None'>state</a>.get_shape().assert_has_rank(4)
<span class='lineno'>  86</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.c', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.c', title='?'>c</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.h', title='?'>h</a> = tf.split(axis=3, num_or_size_splits=2, value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.state', title='None'>state</a>)
<span class='lineno'>  87</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs_h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs_h', title='?'>inputs_h</a> = tf.concat(axis=3, values=[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs', title='?'>inputs</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.h', title='?'>h</a>])
<span class='lineno'>  88</span>     # Parameters of gates are concatenated into one conv for efficiency.
<span class='lineno'>  89</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.i_j_f_o', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.i_j_f_o', title='?'>i_j_f_o</a> = layers.conv2d(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs_h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.inputs_h', title='?'>inputs_h</a>,
<span class='lineno'>  90</span>                             4 * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.num_channels', title='?'>num_channels</a>, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.filter_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.filter_size', title='int'>filter_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.filter_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.filter_size', title='int'>filter_size</a>],
<span class='lineno'>  91</span>                             stride=1,
<span class='lineno'>  92</span>                             activation_fn=None,
<span class='lineno'>  93</span>                             scope=&#39;Gates&#39;)
<span class='lineno'>  94</span> 
<span class='lineno'>  95</span>     # i = input_gate, j = new_input, f = forget_gate, o = output_gate
<span class='lineno'>  96</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.i', title='?'>i</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.j', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.j', title='?'>j</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.f', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.f', title='?'>f</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.o', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.o', title='?'>o</a> = tf.split(axis=3, num_or_size_splits=4, value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.i_j_f_o', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.i_j_f_o', title='?'>i_j_f_o</a>)
<span class='lineno'>  97</span> 
<span class='lineno'>  98</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_c', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_c', title='?'>new_c</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.c', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.c', title='?'>c</a> * tf.sigmoid(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.f', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.f', title='?'>f</a> + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.forget_bias', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.forget_bias', title='float'>forget_bias</a>) + tf.sigmoid(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.i', title='?'>i</a>) * tf.tanh(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.j', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.j', title='?'>j</a>)
<span class='lineno'>  99</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_h', title='?'>new_h</a> = tf.tanh(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_c', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_c', title='?'>new_c</a>) * tf.sigmoid(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.o', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.o', title='?'>o</a>)
<span class='lineno'> 100</span> 
<span class='lineno'> 101</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_h', title='?'>new_h</a>, tf.concat(axis=3, values=[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_c', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_c', title='?'>new_c</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_h', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.video_prediction.lstm_ops.basic_conv_lstm_cell.new_h', title='?'>new_h</a>])
</pre></td></tr></table></body></html>