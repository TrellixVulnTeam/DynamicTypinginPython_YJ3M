<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/deeplab/utils/train_utils.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero', xid='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero'>_div_maybe_zero</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale', xid='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale'>add_softmax_cross_entropy_loss_for_each_scale</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn', xid='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn'>get_model_init_fn</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers', xid='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers'>get_model_gradient_multipliers</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate', xid='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate'>get_model_learning_rate</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Lint as: python2, python3
<span class='lineno'>   2</span> # Copyright 2018 The TensorFlow Authors All Rights Reserved.
<span class='lineno'>   3</span> #
<span class='lineno'>   4</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   5</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   6</span> # You may obtain a copy of the License at
<span class='lineno'>   7</span> #
<span class='lineno'>   8</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   9</span> #
<span class='lineno'>  10</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  11</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  12</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  13</span> # See the License for the specific language governing permissions and
<span class='lineno'>  14</span> # limitations under the License.
<span class='lineno'>  15</span> # ==============================================================================
<span class='lineno'>  16</span> &quot;&quot;&quot;Utility functions for training.&quot;&quot;&quot;
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> import six
<span class='lineno'>  19</span> import tensorflow as tf
<span class='lineno'>  20</span> from tensorflow.contrib import framework as contrib_framework
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> from deeplab.core import preprocess_utils
<span class='lineno'>  23</span> from deeplab.core import utils
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> 
<span class='lineno'>  26</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero', title='(?, ?) -> None'>_div_maybe_zero</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero.total_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero.total_loss', title='?'>total_loss</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero.num_present', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero.num_present', title='?'>num_present</a>):
<span class='lineno'>  27</span>   &quot;&quot;&quot;Normalizes the total loss with the number of present pixels.&quot;&quot;&quot;
<span class='lineno'>  28</span>   return tf.to_float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero.num_present', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero.num_present', title='?'>num_present</a> &gt; 0) * tf.math.divide(
<span class='lineno'>  29</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero.total_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero.total_loss', title='?'>total_loss</a>,
<span class='lineno'>  30</span>       tf.maximum(1e-5, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero.num_present', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero.num_present', title='?'>num_present</a>))
<span class='lineno'>  31</span> 
<span class='lineno'>  32</span> 
<span class='lineno'>  33</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale', title='(?, ?, ?, ?, float, bool, int, float, bool, None) -> None'>add_softmax_cross_entropy_loss_for_each_scale</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scales_to_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scales_to_logits', title='?'>scales_to_logits</a>,
<span class='lineno'>  34</span>                                                   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', title='?'>labels</a>,
<span class='lineno'>  35</span>                                                   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_classes', title='?'>num_classes</a>,
<span class='lineno'>  36</span>                                                   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ignore_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ignore_label', title='?'>ignore_label</a>,
<span class='lineno'>  37</span>                                                   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_weight', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_weight', title='float'>loss_weight</a>=1.0,
<span class='lineno'>  38</span>                                                   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.upsample_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.upsample_logits', title='bool'>upsample_logits</a>=True,
<span class='lineno'>  39</span>                                                   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.hard_example_mining_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.hard_example_mining_step', title='int'>hard_example_mining_step</a>=0,
<span class='lineno'>  40</span>                                                   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_percent_pixels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_percent_pixels', title='float'>top_k_percent_pixels</a>=1.0,
<span class='lineno'>  41</span>                                                   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.gt_is_matting_map', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.gt_is_matting_map', title='bool'>gt_is_matting_map</a>=False,
<span class='lineno'>  42</span>                                                   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scope', title='None'>scope</a>=None):
<span class='lineno'>  43</span>   &quot;&quot;&quot;Adds softmax cross entropy loss for logits of each scale.
<span class='lineno'>  44</span> 
<span class='lineno'>  45</span>   Args:
<span class='lineno'>  46</span>     scales_to_logits: A map from logits names for different scales to logits.
<span class='lineno'>  47</span>       The logits have shape [batch, logits_height, logits_width, num_classes].
<span class='lineno'>  48</span>     labels: Groundtruth labels with shape [batch, image_height, image_width, 1].
<span class='lineno'>  49</span>     num_classes: Integer, number of target classes.
<span class='lineno'>  50</span>     ignore_label: Integer, label to ignore.
<span class='lineno'>  51</span>     loss_weight: A float or a list of loss weights. If it is a float, it means
<span class='lineno'>  52</span>       all the labels have the same weight. If it is a list of weights, then each
<span class='lineno'>  53</span>       element in the list represents the weight for the label of its index, for
<span class='lineno'>  54</span>       example, loss_weight = [0.1, 0.5] means the weight for label 0 is 0.1 and
<span class='lineno'>  55</span>       the weight for label 1 is 0.5.
<span class='lineno'>  56</span>     upsample_logits: Boolean, upsample logits or not.
<span class='lineno'>  57</span>     hard_example_mining_step: An integer, the training step in which the hard
<span class='lineno'>  58</span>       exampling mining kicks off. Note that we gradually reduce the mining
<span class='lineno'>  59</span>       percent to the top_k_percent_pixels. For example, if
<span class='lineno'>  60</span>       hard_example_mining_step = 100K and top_k_percent_pixels = 0.25, then
<span class='lineno'>  61</span>       mining percent will gradually reduce from 100% to 25% until 100K steps
<span class='lineno'>  62</span>       after which we only mine top 25% pixels.
<span class='lineno'>  63</span>     top_k_percent_pixels: A float, the value lies in [0.0, 1.0]. When its value
<span class='lineno'>  64</span>       &lt; 1.0, only compute the loss for the top k percent pixels (e.g., the top
<span class='lineno'>  65</span>       20% pixels). This is useful for hard pixel mining.
<span class='lineno'>  66</span>     gt_is_matting_map: If true, the groundtruth is a matting map of confidence
<span class='lineno'>  67</span>       score. If false, the groundtruth is an integer valued class mask.
<span class='lineno'>  68</span>     scope: String, the scope for the loss.
<span class='lineno'>  69</span> 
<span class='lineno'>  70</span>   Raises:
<span class='lineno'>  71</span>     ValueError: Label or logits is None, or groundtruth is matting map while
<span class='lineno'>  72</span>       label is not floating value.
<span class='lineno'>  73</span>   &quot;&quot;&quot;
<span class='lineno'>  74</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', title='?'>labels</a> is None:
<span class='lineno'>  75</span>     raise ValueError(&#39;No label for softmax cross entropy loss.&#39;)
<span class='lineno'>  76</span> 
<span class='lineno'>  77</span>   # If input groundtruth is a matting map of confidence, check if the input
<span class='lineno'>  78</span>   # labels are floating point values.
<span class='lineno'>  79</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.gt_is_matting_map', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.gt_is_matting_map', title='bool'>gt_is_matting_map</a> and not <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', title='?'>labels</a>.dtype.is_floating:
<span class='lineno'>  80</span>     raise ValueError(&#39;Labels must be floats if groundtruth is a matting map.&#39;)
<span class='lineno'>  81</span> 
<span class='lineno'>  82</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scale', title='?'>scale</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', title='?'>logits</a> in six.iteritems(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scales_to_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scales_to_logits', title='?'>scales_to_logits</a>):
<span class='lineno'>  83</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_scope', title='None'>loss_scope</a> = None
<span class='lineno'>  84</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scope', title='None'>scope</a>:
<span class='lineno'>  85</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_scope', title='?'>loss_scope</a> = &#39;%s_%s&#39; % (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scope', title='None'>scope</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scale', title='?'>scale</a>)
<span class='lineno'>  86</span> 
<span class='lineno'>  87</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.upsample_logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.upsample_logits', title='bool'>upsample_logits</a>:
<span class='lineno'>  88</span>       # Label is not downsampled, and instead we upsample logits.
<span class='lineno'>  89</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', title='?'>logits</a> = tf.image.resize_bilinear(
<span class='lineno'>  90</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', title='?'>logits</a>,
<span class='lineno'>  91</span>           preprocess_utils.resolve_shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', title='?'>labels</a>, 4)[1:3],
<span class='lineno'>  92</span>           align_corners=True)
<span class='lineno'>  93</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', title='?'>scaled_labels</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', title='?'>labels</a>
<span class='lineno'>  94</span>     else:
<span class='lineno'>  95</span>       # Label is downsampled to the same size as logits.
<span class='lineno'>  96</span>       # When gt_is_matting_map = true, label downsampling with nearest neighbor
<span class='lineno'>  97</span>       # method may introduce artifacts. However, to avoid ignore_label from
<span class='lineno'>  98</span>       # being interpolated with other labels, we still perform nearest neighbor
<span class='lineno'>  99</span>       # interpolation.
<span class='lineno'> 100</span>       # TODO(huizhongc): Change to bilinear interpolation by processing padded
<span class='lineno'> 101</span>       # and non-padded label separately.
<span class='lineno'> 102</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.gt_is_matting_map', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.gt_is_matting_map', title='bool'>gt_is_matting_map</a>:
<span class='lineno'> 103</span>         tf.logging.warning(
<span class='lineno'> 104</span>             &#39;Label downsampling with nearest neighbor may introduce artifacts.&#39;)
<span class='lineno'> 105</span> 
<span class='lineno'> 106</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', title='?'>scaled_labels</a> = tf.image.resize_nearest_neighbor(
<span class='lineno'> 107</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.labels', title='?'>labels</a>,
<span class='lineno'> 108</span>           preprocess_utils.resolve_shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', title='?'>logits</a>, 4)[1:3],
<span class='lineno'> 109</span>           align_corners=True)
<span class='lineno'> 110</span> 
<span class='lineno'> 111</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', title='?'>scaled_labels</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', title='?'>scaled_labels</a>, shape=[-1])
<span class='lineno'> 112</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weights', title='?'>weights</a> = utils.get_label_weight_mask(
<span class='lineno'> 113</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', title='?'>scaled_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ignore_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ignore_label', title='?'>ignore_label</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_classes', title='?'>num_classes</a>, label_weights=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_weight', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_weight', title='float'>loss_weight</a>)
<span class='lineno'> 114</span>     # Dimension of keep_mask is equal to the total number of pixels.
<span class='lineno'> 115</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.keep_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.keep_mask', title='?'>keep_mask</a> = tf.cast(
<span class='lineno'> 116</span>         tf.not_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', title='?'>scaled_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ignore_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ignore_label', title='?'>ignore_label</a>), dtype=tf.float32)
<span class='lineno'> 117</span> 
<span class='lineno'> 118</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', title='None'>train_labels</a> = None
<span class='lineno'> 119</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', title='?'>logits</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', title='?'>logits</a>, shape=[-1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_classes', title='?'>num_classes</a>])
<span class='lineno'> 120</span> 
<span class='lineno'> 121</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.gt_is_matting_map', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.gt_is_matting_map', title='bool'>gt_is_matting_map</a>:
<span class='lineno'> 122</span>       # When the groundtruth is integer label mask, we can assign class
<span class='lineno'> 123</span>       # dependent label weights to the loss. When the groundtruth is image
<span class='lineno'> 124</span>       # matting confidence, we do not apply class-dependent label weight (i.e.,
<span class='lineno'> 125</span>       # label_weight = 1.0).
<span class='lineno'> 126</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_weight', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_weight', title='float'>loss_weight</a> != 1.0:
<span class='lineno'> 127</span>         raise ValueError(
<span class='lineno'> 128</span>             &#39;loss_weight must equal to 1 if groundtruth is matting map.&#39;)
<span class='lineno'> 129</span> 
<span class='lineno'> 130</span>       # Assign label value 0 to ignore pixels. The exact label value of ignore
<span class='lineno'> 131</span>       # pixel does not matter, because those ignore_value pixel losses will be
<span class='lineno'> 132</span>       # multiplied to 0 weight.
<span class='lineno'> 133</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', title='?'>train_labels</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', title='?'>scaled_labels</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.keep_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.keep_mask', title='?'>keep_mask</a>
<span class='lineno'> 134</span> 
<span class='lineno'> 135</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', title='?'>train_labels</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', title='?'>train_labels</a>, 1)
<span class='lineno'> 136</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', title='?'>train_labels</a> = tf.concat([1 - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', title='?'>train_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', title='?'>train_labels</a>], axis=1)
<span class='lineno'> 137</span>     else:
<span class='lineno'> 138</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', title='?'>train_labels</a> = tf.one_hot(
<span class='lineno'> 139</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.scaled_labels', title='?'>scaled_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_classes', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_classes', title='?'>num_classes</a>, on_value=1.0, off_value=0.0)
<span class='lineno'> 140</span> 
<span class='lineno'> 141</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.default_loss_scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.default_loss_scope', title='str'>default_loss_scope</a> = (&#39;softmax_all_pixel_loss&#39;
<span class='lineno'> 142</span>                           if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_percent_pixels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_percent_pixels', title='float'>top_k_percent_pixels</a> == 1.0 else
<span class='lineno'> 143</span>                           &#39;softmax_hard_example_mining&#39;)
<span class='lineno'> 144</span>     with tf.name_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss_scope', title='None'>loss_scope</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.default_loss_scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.default_loss_scope', title='str'>default_loss_scope</a>,
<span class='lineno'> 145</span>                        [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', title='?'>train_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weights', title='?'>weights</a>]):
<span class='lineno'> 146</span>       # Compute the loss for all pixels.
<span class='lineno'> 147</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.pixel_losses', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.pixel_losses', title='?'>pixel_losses</a> = tf.nn.softmax_cross_entropy_with_logits_v2(
<span class='lineno'> 148</span>           labels=tf.stop_gradient(
<span class='lineno'> 149</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.train_labels', title='?'>train_labels</a>, name=&#39;train_labels_stop_gradient&#39;),
<span class='lineno'> 150</span>           logits=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', title='?'>logits</a>,
<span class='lineno'> 151</span>           name=&#39;pixel_losses&#39;)
<span class='lineno'> 152</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weighted_pixel_losses', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weighted_pixel_losses', title='?'>weighted_pixel_losses</a> = tf.multiply(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.pixel_losses', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.pixel_losses', title='?'>pixel_losses</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weights', title='?'>weights</a>)
<span class='lineno'> 153</span> 
<span class='lineno'> 154</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_percent_pixels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_percent_pixels', title='float'>top_k_percent_pixels</a> == 1.0:
<span class='lineno'> 155</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.total_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.total_loss', title='?'>total_loss</a> = tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weighted_pixel_losses', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weighted_pixel_losses', title='?'>weighted_pixel_losses</a>)
<span class='lineno'> 156</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_present', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_present', title='?'>num_present</a> = tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.keep_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.keep_mask', title='?'>keep_mask</a>)
<span class='lineno'> 157</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss', title='None'>loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero', title='(?, ?) -> None'>_div_maybe_zero</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.total_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.total_loss', title='?'>total_loss</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_present', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_present', title='?'>num_present</a>)
<span class='lineno'> 158</span>         tf.losses.add_loss(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss', title='None'>loss</a>)
<span class='lineno'> 159</span>       else:
<span class='lineno'> 160</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_pixels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_pixels', title='?'>num_pixels</a> = tf.to_float(tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.logits', title='?'>logits</a>)[0])
<span class='lineno'> 161</span>         # Compute the top_k_percent pixels based on current training step.
<span class='lineno'> 162</span>         if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.hard_example_mining_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.hard_example_mining_step', title='int'>hard_example_mining_step</a> == 0:
<span class='lineno'> 163</span>           # Directly focus on the top_k pixels.
<span class='lineno'> 164</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_pixels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_pixels', title='?'>top_k_pixels</a> = tf.to_int32(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_percent_pixels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_percent_pixels', title='float'>top_k_percent_pixels</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_pixels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_pixels', title='?'>num_pixels</a>)
<span class='lineno'> 165</span>         else:
<span class='lineno'> 166</span>           # Gradually reduce the mining percent to top_k_percent_pixels.
<span class='lineno'> 167</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.global_step', title='?'>global_step</a> = tf.to_float(tf.train.get_or_create_global_step())
<span class='lineno'> 168</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ratio', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ratio', title='?'>ratio</a> = tf.minimum(1.0, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.global_step', title='?'>global_step</a> / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.hard_example_mining_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.hard_example_mining_step', title='int'>hard_example_mining_step</a>)
<span class='lineno'> 169</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_pixels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_pixels', title='?'>top_k_pixels</a> = tf.to_int32(
<span class='lineno'> 170</span>               (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ratio', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ratio', title='?'>ratio</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_percent_pixels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_percent_pixels', title='float'>top_k_percent_pixels</a> + (1.0 - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ratio', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.ratio', title='?'>ratio</a>)) * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_pixels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_pixels', title='?'>num_pixels</a>)
<span class='lineno'> 171</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_losses', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_losses', title='?'>top_k_losses</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale._', title='?'>_</a> = tf.nn.top_k(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weighted_pixel_losses', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.weighted_pixel_losses', title='?'>weighted_pixel_losses</a>,
<span class='lineno'> 172</span>                                       k=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_pixels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_pixels', title='?'>top_k_pixels</a>,
<span class='lineno'> 173</span>                                       sorted=True,
<span class='lineno'> 174</span>                                       name=&#39;top_k_percent_pixels&#39;)
<span class='lineno'> 175</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.total_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.total_loss', title='?'>total_loss</a> = tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_losses', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_losses', title='?'>top_k_losses</a>)
<span class='lineno'> 176</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_present', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_present', title='?'>num_present</a> = tf.reduce_sum(
<span class='lineno'> 177</span>             tf.to_float(tf.not_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_losses', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.top_k_losses', title='?'>top_k_losses</a>, 0.0)))
<span class='lineno'> 178</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss', title='None'>loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils._div_maybe_zero', title='(?, ?) -> None'>_div_maybe_zero</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.total_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.total_loss', title='?'>total_loss</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_present', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.num_present', title='?'>num_present</a>)
<span class='lineno'> 179</span>         tf.losses.add_loss(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.add_softmax_cross_entropy_loss_for_each_scale.loss', title='None'>loss</a>)
<span class='lineno'> 180</span> 
<span class='lineno'> 181</span> 
<span class='lineno'> 182</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn', title='(?, ?, ?, ?, bool) -> ? -> None'>get_model_init_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.train_logdir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.train_logdir', title='?'>train_logdir</a>,
<span class='lineno'> 183</span>                       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.tf_initial_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.tf_initial_checkpoint', title='?'>tf_initial_checkpoint</a>,
<span class='lineno'> 184</span>                       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.initialize_last_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.initialize_last_layer', title='?'>initialize_last_layer</a>,
<span class='lineno'> 185</span>                       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.last_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.last_layers', title='?'>last_layers</a>,
<span class='lineno'> 186</span>                       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.ignore_missing_vars', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.ignore_missing_vars', title='bool'>ignore_missing_vars</a>=False):
<span class='lineno'> 187</span>   &quot;&quot;&quot;Gets the function initializing model variables from a checkpoint.
<span class='lineno'> 188</span> 
<span class='lineno'> 189</span>   Args:
<span class='lineno'> 190</span>     train_logdir: Log directory for training.
<span class='lineno'> 191</span>     tf_initial_checkpoint: TensorFlow checkpoint for initialization.
<span class='lineno'> 192</span>     initialize_last_layer: Initialize last layer or not.
<span class='lineno'> 193</span>     last_layers: Last layers of the model.
<span class='lineno'> 194</span>     ignore_missing_vars: Ignore missing variables in the checkpoint.
<span class='lineno'> 195</span> 
<span class='lineno'> 196</span>   Returns:
<span class='lineno'> 197</span>     Initialization function.
<span class='lineno'> 198</span>   &quot;&quot;&quot;
<span class='lineno'> 199</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.tf_initial_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.tf_initial_checkpoint', title='?'>tf_initial_checkpoint</a> is None:
<span class='lineno'> 200</span>     tf.logging.info(&#39;Not initializing the model from a checkpoint.&#39;)
<span class='lineno'> 201</span>     return None
<span class='lineno'> 202</span> 
<span class='lineno'> 203</span>   if tf.train.latest_checkpoint(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.train_logdir', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.train_logdir', title='?'>train_logdir</a>):
<span class='lineno'> 204</span>     tf.logging.info(&#39;Ignoring initialization; other checkpoint exists&#39;)
<span class='lineno'> 205</span>     return None
<span class='lineno'> 206</span> 
<span class='lineno'> 207</span>   tf.logging.info(&#39;Initializing model from path: %s&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.tf_initial_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.tf_initial_checkpoint', title='?'>tf_initial_checkpoint</a>)
<span class='lineno'> 208</span> 
<span class='lineno'> 209</span>   # Variables that will not be restored.
<span class='lineno'> 210</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.exclude_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.exclude_list', title='[str]'>exclude_list</a> = [&#39;global_step&#39;]
<span class='lineno'> 211</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.initialize_last_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.initialize_last_layer', title='?'>initialize_last_layer</a>:
<span class='lineno'> 212</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.exclude_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.exclude_list', title='[str]'>exclude_list</a>.extend(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.last_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.last_layers', title='?'>last_layers</a>)
<span class='lineno'> 213</span> 
<span class='lineno'> 214</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.variables_to_restore', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.variables_to_restore', title='?'>variables_to_restore</a> = contrib_framework.get_variables_to_restore(
<span class='lineno'> 215</span>       exclude=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.exclude_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.exclude_list', title='[str]'>exclude_list</a>)
<span class='lineno'> 216</span> 
<span class='lineno'> 217</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.variables_to_restore', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.variables_to_restore', title='?'>variables_to_restore</a>:
<span class='lineno'> 218</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.init_op', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.init_op', title='?'>init_op</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.init_feed_dict', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.init_feed_dict', title='?'>init_feed_dict</a> = contrib_framework.assign_from_checkpoint(
<span class='lineno'> 219</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.tf_initial_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.tf_initial_checkpoint', title='?'>tf_initial_checkpoint</a>,
<span class='lineno'> 220</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.variables_to_restore', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.variables_to_restore', title='?'>variables_to_restore</a>,
<span class='lineno'> 221</span>         ignore_missing_vars=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.ignore_missing_vars', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.ignore_missing_vars', title='bool'>ignore_missing_vars</a>)
<span class='lineno'> 222</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.global_step', title='?'>global_step</a> = tf.train.get_or_create_global_step()
<span class='lineno'> 223</span> 
<span class='lineno'> 224</span>     def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.restore_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.restore_fn', title='? -> None'>restore_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.restore_fn.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.restore_fn.sess', title='?'>sess</a>):
<span class='lineno'> 225</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.restore_fn.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.restore_fn.sess', title='?'>sess</a>.run(init_op, init_feed_dict)
<span class='lineno'> 226</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.restore_fn.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.restore_fn.sess', title='?'>sess</a>.run([global_step])
<span class='lineno'> 227</span> 
<span class='lineno'> 228</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.restore_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_init_fn.restore_fn', title='? -> None'>restore_fn</a>
<span class='lineno'> 229</span> 
<span class='lineno'> 230</span>   return None
<span class='lineno'> 231</span> 
<span class='lineno'> 232</span> 
<span class='lineno'> 233</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers', title='(?, ?) -> dict'>get_model_gradient_multipliers</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.last_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.last_layers', title='?'>last_layers</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.last_layer_gradient_multiplier', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.last_layer_gradient_multiplier', title='?'>last_layer_gradient_multiplier</a>):
<span class='lineno'> 234</span>   &quot;&quot;&quot;Gets the gradient multipliers.
<span class='lineno'> 235</span> 
<span class='lineno'> 236</span>   The gradient multipliers will adjust the learning rates for model
<span class='lineno'> 237</span>   variables. For the task of semantic segmentation, the models are
<span class='lineno'> 238</span>   usually fine-tuned from the models trained on the task of image
<span class='lineno'> 239</span>   classification. To fine-tune the models, we usually set larger (e.g.,
<span class='lineno'> 240</span>   10 times larger) learning rate for the parameters of last layer.
<span class='lineno'> 241</span> 
<span class='lineno'> 242</span>   Args:
<span class='lineno'> 243</span>     last_layers: Scopes of last layers.
<span class='lineno'> 244</span>     last_layer_gradient_multiplier: The gradient multiplier for last layers.
<span class='lineno'> 245</span> 
<span class='lineno'> 246</span>   Returns:
<span class='lineno'> 247</span>     The gradient multiplier map with variables as key, and multipliers as value.
<span class='lineno'> 248</span>   &quot;&quot;&quot;
<span class='lineno'> 249</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.gradient_multipliers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.gradient_multipliers', title='dict'>gradient_multipliers</a> = {}
<span class='lineno'> 250</span> 
<span class='lineno'> 251</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', title='?'>var</a> in tf.model_variables():
<span class='lineno'> 252</span>     # Double the learning rate for biases.
<span class='lineno'> 253</span>     if &#39;biases&#39; in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', title='?'>var</a>.op.name:
<span class='lineno'> 254</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.gradient_multipliers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.gradient_multipliers', title='dict'>gradient_multipliers</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', title='?'>var</a>.op.name] = 2.
<span class='lineno'> 255</span> 
<span class='lineno'> 256</span>     # Use larger learning rate for last layer variables.
<span class='lineno'> 257</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.layer', title='?'>layer</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.last_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.last_layers', title='?'>last_layers</a>:
<span class='lineno'> 258</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.layer', title='?'>layer</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', title='?'>var</a>.op.name and &#39;biases&#39; in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', title='?'>var</a>.op.name:
<span class='lineno'> 259</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.gradient_multipliers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.gradient_multipliers', title='dict'>gradient_multipliers</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', title='?'>var</a>.op.name] = 2 * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.last_layer_gradient_multiplier', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.last_layer_gradient_multiplier', title='?'>last_layer_gradient_multiplier</a>
<span class='lineno'> 260</span>         break
<span class='lineno'> 261</span>       elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.layer', title='?'>layer</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', title='?'>var</a>.op.name:
<span class='lineno'> 262</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.gradient_multipliers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.gradient_multipliers', title='dict'>gradient_multipliers</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.var', title='?'>var</a>.op.name] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.last_layer_gradient_multiplier', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.last_layer_gradient_multiplier', title='?'>last_layer_gradient_multiplier</a>
<span class='lineno'> 263</span>         break
<span class='lineno'> 264</span> 
<span class='lineno'> 265</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.gradient_multipliers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_gradient_multipliers.gradient_multipliers', title='dict'>gradient_multipliers</a>
<span class='lineno'> 266</span> 
<span class='lineno'> 267</span> 
<span class='lineno'> 268</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate', title='(?, ?, ?, ?, ?, ?, ?, ?, str, float, float, None, None) -> None'>get_model_learning_rate</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_policy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_policy', title='?'>learning_policy</a>,
<span class='lineno'> 269</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.base_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.base_learning_rate', title='?'>base_learning_rate</a>,
<span class='lineno'> 270</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate_decay_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate_decay_step', title='?'>learning_rate_decay_step</a>,
<span class='lineno'> 271</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate_decay_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate_decay_factor', title='?'>learning_rate_decay_factor</a>,
<span class='lineno'> 272</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.training_number_of_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.training_number_of_steps', title='?'>training_number_of_steps</a>,
<span class='lineno'> 273</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_power', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_power', title='?'>learning_power</a>,
<span class='lineno'> 274</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', title='?'>slow_start_step</a>,
<span class='lineno'> 275</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_learning_rate', title='?'>slow_start_learning_rate</a>,
<span class='lineno'> 276</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_burnin_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_burnin_type', title='str'>slow_start_burnin_type</a>=&#39;none&#39;,
<span class='lineno'> 277</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.decay_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.decay_steps', title='float'>decay_steps</a>=0.0,
<span class='lineno'> 278</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.end_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.end_learning_rate', title='float'>end_learning_rate</a>=0.0,
<span class='lineno'> 279</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundaries', title='None'>boundaries</a>=None,
<span class='lineno'> 280</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundary_learning_rates', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundary_learning_rates', title='None'>boundary_learning_rates</a>=None):
<span class='lineno'> 281</span>   &quot;&quot;&quot;Gets model&#39;s learning rate.
<span class='lineno'> 282</span> 
<span class='lineno'> 283</span>   Computes the model&#39;s learning rate for different learning policy.
<span class='lineno'> 284</span>   Right now, only &quot;step&quot; and &quot;poly&quot; are supported.
<span class='lineno'> 285</span>   (1) The learning policy for &quot;step&quot; is computed as follows:
<span class='lineno'> 286</span>     current_learning_rate = base_learning_rate *
<span class='lineno'> 287</span>       learning_rate_decay_factor ^ (global_step / learning_rate_decay_step)
<span class='lineno'> 288</span>   See tf.train.exponential_decay for details.
<span class='lineno'> 289</span>   (2) The learning policy for &quot;poly&quot; is computed as follows:
<span class='lineno'> 290</span>     current_learning_rate = base_learning_rate *
<span class='lineno'> 291</span>       (1 - global_step / training_number_of_steps) ^ learning_power
<span class='lineno'> 292</span> 
<span class='lineno'> 293</span>   Args:
<span class='lineno'> 294</span>     learning_policy: Learning rate policy for training.
<span class='lineno'> 295</span>     base_learning_rate: The base learning rate for model training.
<span class='lineno'> 296</span>     learning_rate_decay_step: Decay the base learning rate at a fixed step.
<span class='lineno'> 297</span>     learning_rate_decay_factor: The rate to decay the base learning rate.
<span class='lineno'> 298</span>     training_number_of_steps: Number of steps for training.
<span class='lineno'> 299</span>     learning_power: Power used for &#39;poly&#39; learning policy.
<span class='lineno'> 300</span>     slow_start_step: Training model with small learning rate for the first
<span class='lineno'> 301</span>       few steps.
<span class='lineno'> 302</span>     slow_start_learning_rate: The learning rate employed during slow start.
<span class='lineno'> 303</span>     slow_start_burnin_type: The burnin type for the slow start stage. Can be
<span class='lineno'> 304</span>       `none` which means no burnin or `linear` which means the learning rate
<span class='lineno'> 305</span>       increases linearly from slow_start_learning_rate and reaches
<span class='lineno'> 306</span>       base_learning_rate after slow_start_steps.
<span class='lineno'> 307</span>     decay_steps: Float, `decay_steps` for polynomial learning rate.
<span class='lineno'> 308</span>     end_learning_rate: Float, `end_learning_rate` for polynomial learning rate.
<span class='lineno'> 309</span>     boundaries: A list of `Tensor`s or `int`s or `float`s with strictly
<span class='lineno'> 310</span>       increasing entries.
<span class='lineno'> 311</span>     boundary_learning_rates: A list of `Tensor`s or `float`s or `int`s that
<span class='lineno'> 312</span>       specifies the values for the intervals defined by `boundaries`. It should
<span class='lineno'> 313</span>       have one more element than `boundaries`, and all elements should have the
<span class='lineno'> 314</span>       same type.
<span class='lineno'> 315</span> 
<span class='lineno'> 316</span>   Returns:
<span class='lineno'> 317</span>     Learning rate for the specified learning policy.
<span class='lineno'> 318</span> 
<span class='lineno'> 319</span>   Raises:
<span class='lineno'> 320</span>     ValueError: If learning policy or slow start burnin type is not recognized.
<span class='lineno'> 321</span>     ValueError: If `boundaries` and `boundary_learning_rates` are not set for
<span class='lineno'> 322</span>       multi_steps learning rate decay.
<span class='lineno'> 323</span>   &quot;&quot;&quot;
<span class='lineno'> 324</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.global_step', title='?'>global_step</a> = tf.train.get_or_create_global_step()
<span class='lineno'> 325</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_global_step', title='?'>adjusted_global_step</a> = tf.maximum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.global_step', title='?'>global_step</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', title='?'>slow_start_step</a>, 0)
<span class='lineno'> 326</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.decay_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.decay_steps', title='float'>decay_steps</a> == 0.0:
<span class='lineno'> 327</span>     tf.logging.info(&#39;Setting decay_steps to total training steps.&#39;)
<span class='lineno'> 328</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.decay_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.decay_steps', title='?'>decay_steps</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.training_number_of_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.training_number_of_steps', title='?'>training_number_of_steps</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', title='?'>slow_start_step</a>
<span class='lineno'> 329</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_policy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_policy', title='?'>learning_policy</a> == &#39;step&#39;:
<span class='lineno'> 330</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate', title='?'>learning_rate</a> = tf.train.exponential_decay(
<span class='lineno'> 331</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.base_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.base_learning_rate', title='?'>base_learning_rate</a>,
<span class='lineno'> 332</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_global_step', title='?'>adjusted_global_step</a>,
<span class='lineno'> 333</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate_decay_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate_decay_step', title='?'>learning_rate_decay_step</a>,
<span class='lineno'> 334</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate_decay_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate_decay_factor', title='?'>learning_rate_decay_factor</a>,
<span class='lineno'> 335</span>         staircase=True)
<span class='lineno'> 336</span>   elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_policy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_policy', title='?'>learning_policy</a> == &#39;poly&#39;:
<span class='lineno'> 337</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate', title='?'>learning_rate</a> = tf.train.polynomial_decay(
<span class='lineno'> 338</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.base_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.base_learning_rate', title='?'>base_learning_rate</a>,
<span class='lineno'> 339</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_global_step', title='?'>adjusted_global_step</a>,
<span class='lineno'> 340</span>         decay_steps=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.decay_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.decay_steps', title='float'>decay_steps</a>,
<span class='lineno'> 341</span>         end_learning_rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.end_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.end_learning_rate', title='float'>end_learning_rate</a>,
<span class='lineno'> 342</span>         power=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_power', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_power', title='?'>learning_power</a>)
<span class='lineno'> 343</span>   elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_policy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_policy', title='?'>learning_policy</a> == &#39;cosine&#39;:
<span class='lineno'> 344</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate', title='?'>learning_rate</a> = tf.train.cosine_decay(
<span class='lineno'> 345</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.base_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.base_learning_rate', title='?'>base_learning_rate</a>,
<span class='lineno'> 346</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_global_step', title='?'>adjusted_global_step</a>,
<span class='lineno'> 347</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.training_number_of_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.training_number_of_steps', title='?'>training_number_of_steps</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', title='?'>slow_start_step</a>)
<span class='lineno'> 348</span>   elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_policy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_policy', title='?'>learning_policy</a> == &#39;multi_steps&#39;:
<span class='lineno'> 349</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundaries', title='None'>boundaries</a> is None or <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundary_learning_rates', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundary_learning_rates', title='None'>boundary_learning_rates</a> is None:
<span class='lineno'> 350</span>       raise ValueError(&#39;Must set `boundaries` and `boundary_learning_rates` &#39;
<span class='lineno'> 351</span>                        &#39;for multi_steps learning rate decay.&#39;)
<span class='lineno'> 352</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate', title='?'>learning_rate</a> = tf.train.piecewise_constant_decay(
<span class='lineno'> 353</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_global_step', title='?'>adjusted_global_step</a>,
<span class='lineno'> 354</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundaries', title='None'>boundaries</a>,
<span class='lineno'> 355</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundary_learning_rates', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.boundary_learning_rates', title='None'>boundary_learning_rates</a>)
<span class='lineno'> 356</span>   else:
<span class='lineno'> 357</span>     raise ValueError(&#39;Unknown learning policy.&#39;)
<span class='lineno'> 358</span> 
<span class='lineno'> 359</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_slow_start_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_slow_start_learning_rate', title='?'>adjusted_slow_start_learning_rate</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_learning_rate', title='?'>slow_start_learning_rate</a>
<span class='lineno'> 360</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_burnin_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_burnin_type', title='str'>slow_start_burnin_type</a> == &#39;linear&#39;:
<span class='lineno'> 361</span>     # Do linear burnin. Increase linearly from slow_start_learning_rate and
<span class='lineno'> 362</span>     # reach base_learning_rate after (global_step &gt;= slow_start_steps).
<span class='lineno'> 363</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_slow_start_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_slow_start_learning_rate', title='?'>adjusted_slow_start_learning_rate</a> = (
<span class='lineno'> 364</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_learning_rate', title='?'>slow_start_learning_rate</a> +
<span class='lineno'> 365</span>         (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.base_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.base_learning_rate', title='?'>base_learning_rate</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_learning_rate', title='?'>slow_start_learning_rate</a>) *
<span class='lineno'> 366</span>         tf.to_float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.global_step', title='?'>global_step</a>) / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', title='?'>slow_start_step</a>)
<span class='lineno'> 367</span>   elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_burnin_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_burnin_type', title='str'>slow_start_burnin_type</a> != &#39;none&#39;:
<span class='lineno'> 368</span>     raise ValueError(&#39;Unknown burnin type.&#39;)
<span class='lineno'> 369</span> 
<span class='lineno'> 370</span>   # Employ small learning rate at the first few steps for warm start.
<span class='lineno'> 371</span>   return tf.where(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.global_step', title='?'>global_step</a> &lt; <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.slow_start_step', title='?'>slow_start_step</a>,
<span class='lineno'> 372</span>                   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_slow_start_learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.adjusted_slow_start_learning_rate', title='?'>adjusted_slow_start_learning_rate</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.deeplab.utils.train_utils.get_model_learning_rate.learning_rate', title='?'>learning_rate</a>)
</pre></td></tr></table></body></html>