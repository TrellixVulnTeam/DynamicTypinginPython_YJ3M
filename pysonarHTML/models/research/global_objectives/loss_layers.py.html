<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/global_objectives/loss_layers.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss'>precision_recall_auc_loss</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss'>roc_auc_loss</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss'>recall_at_precision_loss</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss'>precision_at_recall_loss</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss'>false_positive_rate_at_true_positive_rate_loss</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss'>true_positive_rate_at_false_positive_rate_loss</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights'>_prepare_labels_logits_weights</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta'>_range_to_anchors_and_delta</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable'>_create_dual_variable</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors'>maybe_create_label_priors</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound'>true_positives_lower_bound</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound', xid='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound'>false_positives_upper_bound</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2018 The TensorFlow Global Objectives Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> &quot;&quot;&quot;Loss functions for learning global objectives.
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span> These functions have two return values: a Tensor with the value of
<span class='lineno'>  18</span> the loss, and a dictionary of internal quantities for customizability.
<span class='lineno'>  19</span> &quot;&quot;&quot;
<span class='lineno'>  20</span> 
<span class='lineno'>  21</span> # Dependency imports
<span class='lineno'>  22</span> import numpy
<span class='lineno'>  23</span> import tensorflow as tf
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> from global_objectives import util
<span class='lineno'>  26</span> 
<span class='lineno'>  27</span> 
<span class='lineno'>  28</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss', title='(?, ?, (float, float), int, float, float, None, str, ?, None, None, bool, None) -> (?, dict)'>precision_recall_auc_loss</a>(
<span class='lineno'>  29</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', title='?'>labels</a>,
<span class='lineno'>  30</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>,
<span class='lineno'>  31</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_range', title='(float, float)'>precision_range</a>=(0.0, 1.0),
<span class='lineno'>  32</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_anchors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_anchors', title='int'>num_anchors</a>=20,
<span class='lineno'>  33</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', title='float'>weights</a>=1.0,
<span class='lineno'>  34</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.dual_rate_factor', title='float'>dual_rate_factor</a>=0.1,
<span class='lineno'>  35</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', title='None'>label_priors</a>=None,
<span class='lineno'>  36</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.surrogate_type', title='str'>surrogate_type</a>=&#39;xent&#39;,
<span class='lineno'>  37</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas_initializer', title='?'>lambdas_initializer</a>=tf.constant_initializer(1.0),
<span class='lineno'>  38</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.reuse', title='None'>reuse</a>=None,
<span class='lineno'>  39</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.variables_collections', title='None'>variables_collections</a>=None,
<span class='lineno'>  40</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.trainable', title='bool'>trainable</a>=True,
<span class='lineno'>  41</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scope', title='None'>scope</a>=None):
<span class='lineno'>  42</span>   &quot;&quot;&quot;Computes precision-recall AUC loss.
<span class='lineno'>  43</span> 
<span class='lineno'>  44</span>   The loss is based on a sum of losses for recall at a range of
<span class='lineno'>  45</span>   precision values (anchor points). This sum is a Riemann sum that
<span class='lineno'>  46</span>   approximates the area under the precision-recall curve.
<span class='lineno'>  47</span> 
<span class='lineno'>  48</span>   The per-example `weights` argument changes not only the coefficients of
<span class='lineno'>  49</span>   individual training examples, but how the examples are counted toward the
<span class='lineno'>  50</span>   constraint. If `label_priors` is given, it MUST take `weights` into account.
<span class='lineno'>  51</span>   That is,
<span class='lineno'>  52</span>       label_priors = P / (P + N)
<span class='lineno'>  53</span>   where
<span class='lineno'>  54</span>       P = sum_i (wt_i on positives)
<span class='lineno'>  55</span>       N = sum_i (wt_i on negatives).
<span class='lineno'>  56</span> 
<span class='lineno'>  57</span>   Args:
<span class='lineno'>  58</span>     labels: A `Tensor` of shape [batch_size] or [batch_size, num_labels].
<span class='lineno'>  59</span>     logits: A `Tensor` with the same shape as `labels`.
<span class='lineno'>  60</span>     precision_range: A length-two tuple, the range of precision values over
<span class='lineno'>  61</span>       which to compute AUC. The entries must be nonnegative, increasing, and
<span class='lineno'>  62</span>       less than or equal to 1.0.
<span class='lineno'>  63</span>     num_anchors: The number of grid points used to approximate the Riemann sum.
<span class='lineno'>  64</span>     weights: Coefficients for the loss. Must be a scalar or `Tensor` of shape
<span class='lineno'>  65</span>       [batch_size] or [batch_size, num_labels].
<span class='lineno'>  66</span>     dual_rate_factor: A floating point value which controls the step size for
<span class='lineno'>  67</span>       the Lagrange multipliers.
<span class='lineno'>  68</span>     label_priors: None, or a floating point `Tensor` of shape [num_labels]
<span class='lineno'>  69</span>       containing the prior probability of each label (i.e. the fraction of the
<span class='lineno'>  70</span>       training data consisting of positive examples). If None, the label
<span class='lineno'>  71</span>       priors are computed from `labels` with a moving average. See the notes
<span class='lineno'>  72</span>       above regarding the interaction with `weights` and do not set this unless
<span class='lineno'>  73</span>       you have a good reason to do so.
<span class='lineno'>  74</span>     surrogate_type: Either &#39;xent&#39; or &#39;hinge&#39;, specifying which upper bound
<span class='lineno'>  75</span>       should be used for indicator functions.
<span class='lineno'>  76</span>     lambdas_initializer: An initializer for the Lagrange multipliers.
<span class='lineno'>  77</span>     reuse: Whether or not the layer and its variables should be reused. To be
<span class='lineno'>  78</span>       able to reuse the layer scope must be given.
<span class='lineno'>  79</span>     variables_collections: Optional list of collections for the variables.
<span class='lineno'>  80</span>     trainable: If `True` also add variables to the graph collection
<span class='lineno'>  81</span>       `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).
<span class='lineno'>  82</span>     scope: Optional scope for `variable_scope`.
<span class='lineno'>  83</span> 
<span class='lineno'>  84</span>   Returns:
<span class='lineno'>  85</span>     loss: A `Tensor` of the same shape as `logits` with the component-wise
<span class='lineno'>  86</span>       loss.
<span class='lineno'>  87</span>     other_outputs: A dictionary of useful internal quantities for debugging. For
<span class='lineno'>  88</span>       more details, see http://arxiv.org/pdf/1608.04802.pdf.
<span class='lineno'>  89</span>       lambdas: A Tensor of shape [1, num_labels, num_anchors] consisting of the
<span class='lineno'>  90</span>         Lagrange multipliers.
<span class='lineno'>  91</span>       biases: A Tensor of shape [1, num_labels, num_anchors] consisting of the
<span class='lineno'>  92</span>         learned bias term for each.
<span class='lineno'>  93</span>       label_priors: A Tensor of shape [1, num_labels, 1] consisting of the prior
<span class='lineno'>  94</span>         probability of each label learned by the loss, if not provided.
<span class='lineno'>  95</span>       true_positives_lower_bound: Lower bound on the number of true positives
<span class='lineno'>  96</span>         given `labels` and `logits`. This is the same lower bound which is used
<span class='lineno'>  97</span>         in the loss expression to be optimized.
<span class='lineno'>  98</span>       false_positives_upper_bound: Upper bound on the number of false positives
<span class='lineno'>  99</span>         given `labels` and `logits`. This is the same upper bound which is used
<span class='lineno'> 100</span>         in the loss expression to be optimized.
<span class='lineno'> 101</span> 
<span class='lineno'> 102</span>   Raises:
<span class='lineno'> 103</span>     ValueError: If `surrogate_type` is not `xent` or `hinge`.
<span class='lineno'> 104</span>   &quot;&quot;&quot;
<span class='lineno'> 105</span>   with tf.variable_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scope', title='None'>scope</a>,
<span class='lineno'> 106</span>                          &#39;precision_recall_auc&#39;,
<span class='lineno'> 107</span>                          [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', title='None'>label_priors</a>],
<span class='lineno'> 108</span>                          reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.reuse', title='None'>reuse</a>):
<span class='lineno'> 109</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', title='?'>weights</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.original_shape', title='?'>original_shape</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', title='(?, ?, ?) -> (?, ?, ?, ?) / (?, ?, float) -> (?, ?, ?, ?)'>_prepare_labels_logits_weights</a>(
<span class='lineno'> 110</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', title='float'>weights</a>)
<span class='lineno'> 111</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_labels', title='?'>num_labels</a> = util.get_num_labels(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>)
<span class='lineno'> 112</span> 
<span class='lineno'> 113</span>     # Convert other inputs to tensors and standardize dtypes.
<span class='lineno'> 114</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.dual_rate_factor', title='?'>dual_rate_factor</a> = util.convert_and_cast(
<span class='lineno'> 115</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.dual_rate_factor', title='float'>dual_rate_factor</a>, &#39;dual_rate_factor&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>.dtype)
<span class='lineno'> 116</span> 
<span class='lineno'> 117</span>     # Create Tensor of anchor points and distance between anchors.
<span class='lineno'> 118</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_values', title='?'>precision_values</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.delta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.delta', title='?'>delta</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta', title='(?, ?, ?) -> (?, ?) / ((float, float), int, ?) -> (?, ?)'>_range_to_anchors_and_delta</a>(
<span class='lineno'> 119</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_range', title='(float, float)'>precision_range</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_anchors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_anchors', title='int'>num_anchors</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>.dtype)
<span class='lineno'> 120</span>     # Create lambdas with shape [1, num_labels, num_anchors].
<span class='lineno'> 121</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas', title='?'>lambdas</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas_variable', title='?'>lambdas_variable</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable', title='(?, ?, ?, ?, ?, ?, ?) -> (?, ?) / (str, [?], ?, ?, None, bool, ?) -> (?, ?) / (str, [int], ?, ?, None, bool, ?) -> (?, ?)'>_create_dual_variable</a>(
<span class='lineno'> 122</span>         &#39;lambdas&#39;,
<span class='lineno'> 123</span>         shape=[1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_labels', title='?'>num_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_anchors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_anchors', title='int'>num_anchors</a>],
<span class='lineno'> 124</span>         dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>.dtype,
<span class='lineno'> 125</span>         initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas_initializer', title='?'>lambdas_initializer</a>,
<span class='lineno'> 126</span>         collections=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.variables_collections', title='None'>variables_collections</a>,
<span class='lineno'> 127</span>         trainable=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.trainable', title='bool'>trainable</a>,
<span class='lineno'> 128</span>         dual_rate_factor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.dual_rate_factor', title='?'>dual_rate_factor</a>)
<span class='lineno'> 129</span>     # Create biases with shape [1, num_labels, num_anchors].
<span class='lineno'> 130</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.biases', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.biases', title='?'>biases</a> = tf.contrib.framework.model_variable(
<span class='lineno'> 131</span>         name=&#39;biases&#39;,
<span class='lineno'> 132</span>         shape=[1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_labels', title='?'>num_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_anchors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_anchors', title='int'>num_anchors</a>],
<span class='lineno'> 133</span>         dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>.dtype,
<span class='lineno'> 134</span>         initializer=tf.zeros_initializer(),
<span class='lineno'> 135</span>         collections=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.variables_collections', title='None'>variables_collections</a>,
<span class='lineno'> 136</span>         trainable=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.trainable', title='bool'>trainable</a>)
<span class='lineno'> 137</span>     # Maybe create label_priors.
<span class='lineno'> 138</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', title='None'>label_priors</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors', title='(None, ?, ?, None) -> None / (?, ?, ?, ?) -> None'>maybe_create_label_priors</a>(
<span class='lineno'> 139</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', title='None'>label_priors</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.variables_collections', title='None'>variables_collections</a>)
<span class='lineno'> 140</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', title='?'>label_priors</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', title='None'>label_priors</a>, [1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.num_labels', title='?'>num_labels</a>, 1])
<span class='lineno'> 141</span> 
<span class='lineno'> 142</span>     # Expand logits, labels, and weights to shape [batch_size, num_labels, 1].
<span class='lineno'> 143</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>, 2)
<span class='lineno'> 144</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', title='?'>labels</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', title='?'>labels</a>, 2)
<span class='lineno'> 145</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', title='?'>weights</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', title='?'>weights</a>, 2)
<span class='lineno'> 146</span> 
<span class='lineno'> 147</span>     # Calculate weighted loss and other outputs. The log(2.0) term corrects for
<span class='lineno'> 148</span>     # logloss not being an upper bound on the indicator function.
<span class='lineno'> 149</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.loss', title='?'>loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', title='?'>weights</a> * util.weighted_surrogate_loss(
<span class='lineno'> 150</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', title='?'>labels</a>,
<span class='lineno'> 151</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a> + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.biases', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.biases', title='?'>biases</a>,
<span class='lineno'> 152</span>         surrogate_type=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.surrogate_type', title='str'>surrogate_type</a>,
<span class='lineno'> 153</span>         positive_weights=1.0 + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas', title='?'>lambdas</a> * (1.0 - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_values', title='?'>precision_values</a>),
<span class='lineno'> 154</span>         negative_weights=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas', title='?'>lambdas</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_values', title='?'>precision_values</a>)
<span class='lineno'> 155</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.maybe_log2', title='float'>maybe_log2</a> = tf.log(2.0) if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.surrogate_type', title='str'>surrogate_type</a> == &#39;xent&#39; else 1.0
<span class='lineno'> 156</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.maybe_log2', title='?'>maybe_log2</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.maybe_log2', title='float'>maybe_log2</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>.dtype.base_dtype)
<span class='lineno'> 157</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambda_term', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambda_term', title='float'>lambda_term</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas', title='?'>lambdas</a> * (1.0 - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_values', title='?'>precision_values</a>) * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', title='?'>label_priors</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.maybe_log2', title='?'>maybe_log2</a>
<span class='lineno'> 158</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.per_anchor_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.per_anchor_loss', title='float'>per_anchor_loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.loss', title='?'>loss</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambda_term', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambda_term', title='float'>lambda_term</a>
<span class='lineno'> 159</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.per_label_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.per_label_loss', title='?'>per_label_loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.delta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.delta', title='?'>delta</a> * tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.per_anchor_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.per_anchor_loss', title='float'>per_anchor_loss</a>, 2)
<span class='lineno'> 160</span>     # Normalize the AUC such that a perfect score function will have AUC 1.0.
<span class='lineno'> 161</span>     # Because precision_range is discretized into num_anchors + 1 intervals
<span class='lineno'> 162</span>     # but only num_anchors terms are included in the Riemann sum, the
<span class='lineno'> 163</span>     # effective length of the integration interval is `delta` less than the
<span class='lineno'> 164</span>     # length of precision_range.
<span class='lineno'> 165</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scaled_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scaled_loss', title='?'>scaled_loss</a> = tf.div(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.per_label_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.per_label_loss', title='?'>per_label_loss</a>,
<span class='lineno'> 166</span>                          <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_range', title='(float, float)'>precision_range</a>[1] - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.precision_range', title='(float, float)'>precision_range</a>[0] - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.delta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.delta', title='?'>delta</a>,
<span class='lineno'> 167</span>                          name=&#39;AUC_Normalize&#39;)
<span class='lineno'> 168</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scaled_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scaled_loss', title='?'>scaled_loss</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scaled_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scaled_loss', title='?'>scaled_loss</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.original_shape', title='?'>original_shape</a>)
<span class='lineno'> 169</span> 
<span class='lineno'> 170</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.other_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.other_outputs', title='dict'>other_outputs</a> = {
<span class='lineno'> 171</span>         &#39;lambdas&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.lambdas_variable', title='?'>lambdas_variable</a>,
<span class='lineno'> 172</span>         &#39;biases&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.biases', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.biases', title='?'>biases</a>,
<span class='lineno'> 173</span>         &#39;label_priors&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.label_priors', title='?'>label_priors</a>,
<span class='lineno'> 174</span>         &#39;true_positives_lower_bound&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound', title='(?, ?, ?, ?) -> None / (?, ?, ?, str) -> None'>true_positives_lower_bound</a>(
<span class='lineno'> 175</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.surrogate_type', title='str'>surrogate_type</a>),
<span class='lineno'> 176</span>         &#39;false_positives_upper_bound&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound', title='(?, ?, ?, ?) -> None / (?, ?, ?, str) -> None'>false_positives_upper_bound</a>(
<span class='lineno'> 177</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.surrogate_type', title='str'>surrogate_type</a>)}
<span class='lineno'> 178</span> 
<span class='lineno'> 179</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scaled_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.scaled_loss', title='?'>scaled_loss</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.other_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_recall_auc_loss.other_outputs', title='dict'>other_outputs</a>
<span class='lineno'> 180</span> 
<span class='lineno'> 181</span> 
<span class='lineno'> 182</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss', title='(?, ?, float, str, None) -> (?, dict)'>roc_auc_loss</a>(
<span class='lineno'> 183</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', title='?'>labels</a>,
<span class='lineno'> 184</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', title='?'>logits</a>,
<span class='lineno'> 185</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', title='float'>weights</a>=1.0,
<span class='lineno'> 186</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.surrogate_type', title='str'>surrogate_type</a>=&#39;xent&#39;,
<span class='lineno'> 187</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.scope', title='None'>scope</a>=None):
<span class='lineno'> 188</span>   &quot;&quot;&quot;Computes ROC AUC loss.
<span class='lineno'> 189</span> 
<span class='lineno'> 190</span>   The area under the ROC curve is the probability p that a randomly chosen
<span class='lineno'> 191</span>   positive example will be scored higher than a randomly chosen negative
<span class='lineno'> 192</span>   example. This loss approximates 1-p by using a surrogate (either hinge loss or
<span class='lineno'> 193</span>   cross entropy) for the indicator function. Specifically, the loss is:
<span class='lineno'> 194</span> 
<span class='lineno'> 195</span>     sum_i sum_j w_i*w_j*loss(logit_i - logit_j)
<span class='lineno'> 196</span> 
<span class='lineno'> 197</span>   where i ranges over the positive datapoints, j ranges over the negative
<span class='lineno'> 198</span>   datapoints, logit_k denotes the logit (or score) of the k-th datapoint, and
<span class='lineno'> 199</span>   loss is either the hinge or log loss given a positive label.
<span class='lineno'> 200</span> 
<span class='lineno'> 201</span>   Args:
<span class='lineno'> 202</span>     labels: A `Tensor` of shape [batch_size] or [batch_size, num_labels].
<span class='lineno'> 203</span>     logits: A `Tensor` with the same shape and dtype as `labels`.
<span class='lineno'> 204</span>     weights: Coefficients for the loss. Must be a scalar or `Tensor` of shape
<span class='lineno'> 205</span>       [batch_size] or [batch_size, num_labels].
<span class='lineno'> 206</span>     surrogate_type: Either &#39;xent&#39; or &#39;hinge&#39;, specifying which upper bound
<span class='lineno'> 207</span>       should be used for the indicator function.
<span class='lineno'> 208</span>     scope: Optional scope for `name_scope`.
<span class='lineno'> 209</span> 
<span class='lineno'> 210</span>   Returns:
<span class='lineno'> 211</span>     loss: A `Tensor` of the same shape as `logits` with the component-wise loss.
<span class='lineno'> 212</span>     other_outputs: An empty dictionary, for consistency.
<span class='lineno'> 213</span> 
<span class='lineno'> 214</span>   Raises:
<span class='lineno'> 215</span>     ValueError: If `surrogate_type` is not `xent` or `hinge`.
<span class='lineno'> 216</span>   &quot;&quot;&quot;
<span class='lineno'> 217</span>   with tf.name_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.scope', title='None'>scope</a>, &#39;roc_auc&#39;, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', title='float'>weights</a>]):
<span class='lineno'> 218</span>     # Convert inputs to tensors and standardize dtypes.
<span class='lineno'> 219</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', title='?'>weights</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.original_shape', title='?'>original_shape</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', title='(?, ?, ?) -> (?, ?, ?, ?) / (?, ?, float) -> (?, ?, ?, ?)'>_prepare_labels_logits_weights</a>(
<span class='lineno'> 220</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', title='float'>weights</a>)
<span class='lineno'> 221</span> 
<span class='lineno'> 222</span>     # Create tensors of pairwise differences for logits and labels, and
<span class='lineno'> 223</span>     # pairwise products of weights. These have shape
<span class='lineno'> 224</span>     # [batch_size, batch_size, num_labels].
<span class='lineno'> 225</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits_difference', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits_difference', title='?'>logits_difference</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', title='?'>logits</a>, 0) - tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits', title='?'>logits</a>, 1)
<span class='lineno'> 226</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels_difference', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels_difference', title='?'>labels_difference</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', title='?'>labels</a>, 0) - tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels', title='?'>labels</a>, 1)
<span class='lineno'> 227</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights_product', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights_product', title='?'>weights_product</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', title='?'>weights</a>, 0) * tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights', title='?'>weights</a>, 1)
<span class='lineno'> 228</span> 
<span class='lineno'> 229</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.signed_logits_difference', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.signed_logits_difference', title='?'>signed_logits_difference</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels_difference', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels_difference', title='?'>labels_difference</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits_difference', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.logits_difference', title='?'>logits_difference</a>
<span class='lineno'> 230</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.raw_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.raw_loss', title='?'>raw_loss</a> = util.weighted_surrogate_loss(
<span class='lineno'> 231</span>         labels=tf.ones_like(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.signed_logits_difference', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.signed_logits_difference', title='?'>signed_logits_difference</a>),
<span class='lineno'> 232</span>         logits=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.signed_logits_difference', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.signed_logits_difference', title='?'>signed_logits_difference</a>,
<span class='lineno'> 233</span>         surrogate_type=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.surrogate_type', title='str'>surrogate_type</a>)
<span class='lineno'> 234</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weighted_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weighted_loss', title='?'>weighted_loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights_product', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weights_product', title='?'>weights_product</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.raw_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.raw_loss', title='?'>raw_loss</a>
<span class='lineno'> 235</span> 
<span class='lineno'> 236</span>     # Zero out entries of the loss where labels_difference zero (so loss is only
<span class='lineno'> 237</span>     # computed on pairs with different labels).
<span class='lineno'> 238</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.loss', title='float'>loss</a> = tf.reduce_mean(tf.abs(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels_difference', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.labels_difference', title='?'>labels_difference</a>) * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weighted_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.weighted_loss', title='?'>weighted_loss</a>, 0) * 0.5
<span class='lineno'> 239</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.loss', title='?'>loss</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.loss', title='float'>loss</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.original_shape', title='?'>original_shape</a>)
<span class='lineno'> 240</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.roc_auc_loss.loss', title='?'>loss</a>, {}
<span class='lineno'> 241</span> 
<span class='lineno'> 242</span> 
<span class='lineno'> 243</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss', title='(?, ?, ?, float, float, None, str, ?, None, None, bool, None) -> (?, dict)'>recall_at_precision_loss</a>(
<span class='lineno'> 244</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', title='?'>labels</a>,
<span class='lineno'> 245</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>,
<span class='lineno'> 246</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', title='?'>target_precision</a>,
<span class='lineno'> 247</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', title='float'>weights</a>=1.0,
<span class='lineno'> 248</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.dual_rate_factor', title='float'>dual_rate_factor</a>=0.1,
<span class='lineno'> 249</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', title='None'>label_priors</a>=None,
<span class='lineno'> 250</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.surrogate_type', title='str'>surrogate_type</a>=&#39;xent&#39;,
<span class='lineno'> 251</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas_initializer', title='?'>lambdas_initializer</a>=tf.constant_initializer(1.0),
<span class='lineno'> 252</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.reuse', title='None'>reuse</a>=None,
<span class='lineno'> 253</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.variables_collections', title='None'>variables_collections</a>=None,
<span class='lineno'> 254</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.trainable', title='bool'>trainable</a>=True,
<span class='lineno'> 255</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.scope', title='None'>scope</a>=None):
<span class='lineno'> 256</span>   &quot;&quot;&quot;Computes recall at precision loss.
<span class='lineno'> 257</span> 
<span class='lineno'> 258</span>   The loss is based on a surrogate of the form
<span class='lineno'> 259</span>       wt * w(+) * loss(+) + wt * w(-) * loss(-) - c * pi,
<span class='lineno'> 260</span>   where:
<span class='lineno'> 261</span>   - w(+) =  1 + lambdas * (1 - target_precision)
<span class='lineno'> 262</span>   - loss(+) is the cross-entropy loss on the positive examples
<span class='lineno'> 263</span>   - w(-) = lambdas * target_precision
<span class='lineno'> 264</span>   - loss(-) is the cross-entropy loss on the negative examples
<span class='lineno'> 265</span>   - wt is a scalar or tensor of per-example weights
<span class='lineno'> 266</span>   - c = lambdas * (1 - target_precision)
<span class='lineno'> 267</span>   - pi is the label_priors.
<span class='lineno'> 268</span> 
<span class='lineno'> 269</span>   The per-example weights change not only the coefficients of individual
<span class='lineno'> 270</span>   training examples, but how the examples are counted toward the constraint.
<span class='lineno'> 271</span>   If `label_priors` is given, it MUST take `weights` into account. That is,
<span class='lineno'> 272</span>       label_priors = P / (P + N)
<span class='lineno'> 273</span>   where
<span class='lineno'> 274</span>       P = sum_i (wt_i on positives)
<span class='lineno'> 275</span>       N = sum_i (wt_i on negatives).
<span class='lineno'> 276</span> 
<span class='lineno'> 277</span>   Args:
<span class='lineno'> 278</span>     labels: A `Tensor` of shape [batch_size] or [batch_size, num_labels].
<span class='lineno'> 279</span>     logits: A `Tensor` with the same shape as `labels`.
<span class='lineno'> 280</span>     target_precision: The precision at which to compute the loss. Can be a
<span class='lineno'> 281</span>       floating point value between 0 and 1 for a single precision value, or a
<span class='lineno'> 282</span>       `Tensor` of shape [num_labels], holding each label&#39;s target precision
<span class='lineno'> 283</span>       value.
<span class='lineno'> 284</span>     weights: Coefficients for the loss. Must be a scalar or `Tensor` of shape
<span class='lineno'> 285</span>       [batch_size] or [batch_size, num_labels].
<span class='lineno'> 286</span>     dual_rate_factor: A floating point value which controls the step size for
<span class='lineno'> 287</span>       the Lagrange multipliers.
<span class='lineno'> 288</span>     label_priors: None, or a floating point `Tensor` of shape [num_labels]
<span class='lineno'> 289</span>       containing the prior probability of each label (i.e. the fraction of the
<span class='lineno'> 290</span>       training data consisting of positive examples). If None, the label
<span class='lineno'> 291</span>       priors are computed from `labels` with a moving average. See the notes
<span class='lineno'> 292</span>       above regarding the interaction with `weights` and do not set this unless
<span class='lineno'> 293</span>       you have a good reason to do so.
<span class='lineno'> 294</span>     surrogate_type: Either &#39;xent&#39; or &#39;hinge&#39;, specifying which upper bound
<span class='lineno'> 295</span>       should be used for indicator functions.
<span class='lineno'> 296</span>     lambdas_initializer: An initializer for the Lagrange multipliers.
<span class='lineno'> 297</span>     reuse: Whether or not the layer and its variables should be reused. To be
<span class='lineno'> 298</span>       able to reuse the layer scope must be given.
<span class='lineno'> 299</span>     variables_collections: Optional list of collections for the variables.
<span class='lineno'> 300</span>     trainable: If `True` also add variables to the graph collection
<span class='lineno'> 301</span>       `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).
<span class='lineno'> 302</span>     scope: Optional scope for `variable_scope`.
<span class='lineno'> 303</span> 
<span class='lineno'> 304</span>   Returns:
<span class='lineno'> 305</span>     loss: A `Tensor` of the same shape as `logits` with the component-wise
<span class='lineno'> 306</span>       loss.
<span class='lineno'> 307</span>     other_outputs: A dictionary of useful internal quantities for debugging. For
<span class='lineno'> 308</span>       more details, see http://arxiv.org/pdf/1608.04802.pdf.
<span class='lineno'> 309</span>       lambdas: A Tensor of shape [num_labels] consisting of the Lagrange
<span class='lineno'> 310</span>         multipliers.
<span class='lineno'> 311</span>       label_priors: A Tensor of shape [num_labels] consisting of the prior
<span class='lineno'> 312</span>         probability of each label learned by the loss, if not provided.
<span class='lineno'> 313</span>       true_positives_lower_bound: Lower bound on the number of true positives
<span class='lineno'> 314</span>         given `labels` and `logits`. This is the same lower bound which is used
<span class='lineno'> 315</span>         in the loss expression to be optimized.
<span class='lineno'> 316</span>       false_positives_upper_bound: Upper bound on the number of false positives
<span class='lineno'> 317</span>         given `labels` and `logits`. This is the same upper bound which is used
<span class='lineno'> 318</span>         in the loss expression to be optimized.
<span class='lineno'> 319</span> 
<span class='lineno'> 320</span>   Raises:
<span class='lineno'> 321</span>     ValueError: If `logits` and `labels` do not have the same shape.
<span class='lineno'> 322</span>   &quot;&quot;&quot;
<span class='lineno'> 323</span>   with tf.variable_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.scope', title='None'>scope</a>,
<span class='lineno'> 324</span>                          &#39;recall_at_precision&#39;,
<span class='lineno'> 325</span>                          [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', title='None'>label_priors</a>],
<span class='lineno'> 326</span>                          reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.reuse', title='None'>reuse</a>):
<span class='lineno'> 327</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', title='?'>weights</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.original_shape', title='?'>original_shape</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', title='(?, ?, ?) -> (?, ?, ?, ?) / (?, ?, float) -> (?, ?, ?, ?)'>_prepare_labels_logits_weights</a>(
<span class='lineno'> 328</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', title='float'>weights</a>)
<span class='lineno'> 329</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.num_labels', title='?'>num_labels</a> = util.get_num_labels(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>)
<span class='lineno'> 330</span> 
<span class='lineno'> 331</span>     # Convert other inputs to tensors and standardize dtypes.
<span class='lineno'> 332</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', title='?'>target_precision</a> = util.convert_and_cast(
<span class='lineno'> 333</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', title='?'>target_precision</a>, &#39;target_precision&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>.dtype)
<span class='lineno'> 334</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.dual_rate_factor', title='?'>dual_rate_factor</a> = util.convert_and_cast(
<span class='lineno'> 335</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.dual_rate_factor', title='float'>dual_rate_factor</a>, &#39;dual_rate_factor&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>.dtype)
<span class='lineno'> 336</span> 
<span class='lineno'> 337</span>     # Create lambdas.
<span class='lineno'> 338</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas', title='?'>lambdas</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas_variable', title='?'>lambdas_variable</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable', title='(?, ?, ?, ?, ?, ?, ?) -> (?, ?) / (str, [?], ?, ?, None, bool, ?) -> (?, ?) / (str, [int], ?, ?, None, bool, ?) -> (?, ?)'>_create_dual_variable</a>(
<span class='lineno'> 339</span>         &#39;lambdas&#39;,
<span class='lineno'> 340</span>         shape=[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.num_labels', title='?'>num_labels</a>],
<span class='lineno'> 341</span>         dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>.dtype,
<span class='lineno'> 342</span>         initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas_initializer', title='?'>lambdas_initializer</a>,
<span class='lineno'> 343</span>         collections=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.variables_collections', title='None'>variables_collections</a>,
<span class='lineno'> 344</span>         trainable=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.trainable', title='bool'>trainable</a>,
<span class='lineno'> 345</span>         dual_rate_factor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.dual_rate_factor', title='?'>dual_rate_factor</a>)
<span class='lineno'> 346</span>     # Maybe create label_priors.
<span class='lineno'> 347</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', title='None'>label_priors</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors', title='(None, ?, ?, None) -> None / (?, ?, ?, ?) -> None'>maybe_create_label_priors</a>(
<span class='lineno'> 348</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', title='None'>label_priors</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.variables_collections', title='None'>variables_collections</a>)
<span class='lineno'> 349</span> 
<span class='lineno'> 350</span>     # Calculate weighted loss and other outputs. The log(2.0) term corrects for
<span class='lineno'> 351</span>     # logloss not being an upper bound on the indicator function.
<span class='lineno'> 352</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weighted_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weighted_loss', title='?'>weighted_loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', title='?'>weights</a> * util.weighted_surrogate_loss(
<span class='lineno'> 353</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', title='?'>labels</a>,
<span class='lineno'> 354</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>,
<span class='lineno'> 355</span>         surrogate_type=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.surrogate_type', title='str'>surrogate_type</a>,
<span class='lineno'> 356</span>         positive_weights=1.0 + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas', title='?'>lambdas</a> * (1.0 - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', title='?'>target_precision</a>),
<span class='lineno'> 357</span>         negative_weights=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas', title='?'>lambdas</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', title='?'>target_precision</a>)
<span class='lineno'> 358</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.maybe_log2', title='float'>maybe_log2</a> = tf.log(2.0) if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.surrogate_type', title='str'>surrogate_type</a> == &#39;xent&#39; else 1.0
<span class='lineno'> 359</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.maybe_log2', title='?'>maybe_log2</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.maybe_log2', title='float'>maybe_log2</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>.dtype.base_dtype)
<span class='lineno'> 360</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambda_term', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambda_term', title='float'>lambda_term</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas', title='?'>lambdas</a> * (1.0 - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.target_precision', title='?'>target_precision</a>) * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', title='None'>label_priors</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.maybe_log2', title='?'>maybe_log2</a>
<span class='lineno'> 361</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.loss', title='?'>loss</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weighted_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weighted_loss', title='?'>weighted_loss</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambda_term', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambda_term', title='float'>lambda_term</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.original_shape', title='?'>original_shape</a>)
<span class='lineno'> 362</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.other_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.other_outputs', title='dict'>other_outputs</a> = {
<span class='lineno'> 363</span>         &#39;lambdas&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.lambdas_variable', title='?'>lambdas_variable</a>,
<span class='lineno'> 364</span>         &#39;label_priors&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.label_priors', title='None'>label_priors</a>,
<span class='lineno'> 365</span>         &#39;true_positives_lower_bound&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound', title='(?, ?, ?, ?) -> None / (?, ?, ?, str) -> None'>true_positives_lower_bound</a>(
<span class='lineno'> 366</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.surrogate_type', title='str'>surrogate_type</a>),
<span class='lineno'> 367</span>         &#39;false_positives_upper_bound&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound', title='(?, ?, ?, ?) -> None / (?, ?, ?, str) -> None'>false_positives_upper_bound</a>(
<span class='lineno'> 368</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.surrogate_type', title='str'>surrogate_type</a>)}
<span class='lineno'> 369</span> 
<span class='lineno'> 370</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.loss', title='?'>loss</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.other_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.recall_at_precision_loss.other_outputs', title='dict'>other_outputs</a>
<span class='lineno'> 371</span> 
<span class='lineno'> 372</span> 
<span class='lineno'> 373</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss', title='(?, ?, ?, float, float, None, str, ?, None, None, bool, None) -> (?, dict)'>precision_at_recall_loss</a>(
<span class='lineno'> 374</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', title='?'>labels</a>,
<span class='lineno'> 375</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>,
<span class='lineno'> 376</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.target_recall', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.target_recall', title='?'>target_recall</a>,
<span class='lineno'> 377</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', title='float'>weights</a>=1.0,
<span class='lineno'> 378</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.dual_rate_factor', title='float'>dual_rate_factor</a>=0.1,
<span class='lineno'> 379</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', title='None'>label_priors</a>=None,
<span class='lineno'> 380</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.surrogate_type', title='str'>surrogate_type</a>=&#39;xent&#39;,
<span class='lineno'> 381</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas_initializer', title='?'>lambdas_initializer</a>=tf.constant_initializer(1.0),
<span class='lineno'> 382</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.reuse', title='None'>reuse</a>=None,
<span class='lineno'> 383</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.variables_collections', title='None'>variables_collections</a>=None,
<span class='lineno'> 384</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.trainable', title='bool'>trainable</a>=True,
<span class='lineno'> 385</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.scope', title='None'>scope</a>=None):
<span class='lineno'> 386</span>   &quot;&quot;&quot;Computes precision at recall loss.
<span class='lineno'> 387</span> 
<span class='lineno'> 388</span>   The loss is based on a surrogate of the form
<span class='lineno'> 389</span>      wt * loss(-) + lambdas * (pi * (b - 1) + wt * loss(+))
<span class='lineno'> 390</span>   where:
<span class='lineno'> 391</span>   - loss(-) is the cross-entropy loss on the negative examples
<span class='lineno'> 392</span>   - loss(+) is the cross-entropy loss on the positive examples
<span class='lineno'> 393</span>   - wt is a scalar or tensor of per-example weights
<span class='lineno'> 394</span>   - b is the target recall
<span class='lineno'> 395</span>   - pi is the label_priors.
<span class='lineno'> 396</span> 
<span class='lineno'> 397</span>   The per-example weights change not only the coefficients of individual
<span class='lineno'> 398</span>   training examples, but how the examples are counted toward the constraint.
<span class='lineno'> 399</span>   If `label_priors` is given, it MUST take `weights` into account. That is,
<span class='lineno'> 400</span>       label_priors = P / (P + N)
<span class='lineno'> 401</span>   where
<span class='lineno'> 402</span>       P = sum_i (wt_i on positives)
<span class='lineno'> 403</span>       N = sum_i (wt_i on negatives).
<span class='lineno'> 404</span> 
<span class='lineno'> 405</span>   Args:
<span class='lineno'> 406</span>     labels: A `Tensor` of shape [batch_size] or [batch_size, num_labels].
<span class='lineno'> 407</span>     logits: A `Tensor` with the same shape as `labels`.
<span class='lineno'> 408</span>     target_recall: The recall at which to compute the loss. Can be a floating
<span class='lineno'> 409</span>       point value between 0 and 1 for a single target recall value, or a
<span class='lineno'> 410</span>       `Tensor` of shape [num_labels] holding each label&#39;s target recall value.
<span class='lineno'> 411</span>     weights: Coefficients for the loss. Must be a scalar or `Tensor` of shape
<span class='lineno'> 412</span>       [batch_size] or [batch_size, num_labels].
<span class='lineno'> 413</span>     dual_rate_factor: A floating point value which controls the step size for
<span class='lineno'> 414</span>       the Lagrange multipliers.
<span class='lineno'> 415</span>     label_priors: None, or a floating point `Tensor` of shape [num_labels]
<span class='lineno'> 416</span>       containing the prior probability of each label (i.e. the fraction of the
<span class='lineno'> 417</span>       training data consisting of positive examples). If None, the label
<span class='lineno'> 418</span>       priors are computed from `labels` with a moving average. See the notes
<span class='lineno'> 419</span>       above regarding the interaction with `weights` and do not set this unless
<span class='lineno'> 420</span>       you have a good reason to do so.
<span class='lineno'> 421</span>     surrogate_type: Either &#39;xent&#39; or &#39;hinge&#39;, specifying which upper bound
<span class='lineno'> 422</span>       should be used for indicator functions.
<span class='lineno'> 423</span>     lambdas_initializer: An initializer for the Lagrange multipliers.
<span class='lineno'> 424</span>     reuse: Whether or not the layer and its variables should be reused. To be
<span class='lineno'> 425</span>       able to reuse the layer scope must be given.
<span class='lineno'> 426</span>     variables_collections: Optional list of collections for the variables.
<span class='lineno'> 427</span>     trainable: If `True` also add variables to the graph collection
<span class='lineno'> 428</span>       `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).
<span class='lineno'> 429</span>     scope: Optional scope for `variable_scope`.
<span class='lineno'> 430</span> 
<span class='lineno'> 431</span>   Returns:
<span class='lineno'> 432</span>     loss: A `Tensor` of the same shape as `logits` with the component-wise
<span class='lineno'> 433</span>       loss.
<span class='lineno'> 434</span>     other_outputs: A dictionary of useful internal quantities for debugging. For
<span class='lineno'> 435</span>       more details, see http://arxiv.org/pdf/1608.04802.pdf.
<span class='lineno'> 436</span>       lambdas: A Tensor of shape [num_labels] consisting of the Lagrange
<span class='lineno'> 437</span>         multipliers.
<span class='lineno'> 438</span>       label_priors: A Tensor of shape [num_labels] consisting of the prior
<span class='lineno'> 439</span>         probability of each label learned by the loss, if not provided.
<span class='lineno'> 440</span>       true_positives_lower_bound: Lower bound on the number of true positives
<span class='lineno'> 441</span>         given `labels` and `logits`. This is the same lower bound which is used
<span class='lineno'> 442</span>         in the loss expression to be optimized.
<span class='lineno'> 443</span>       false_positives_upper_bound: Upper bound on the number of false positives
<span class='lineno'> 444</span>         given `labels` and `logits`. This is the same upper bound which is used
<span class='lineno'> 445</span>         in the loss expression to be optimized.
<span class='lineno'> 446</span>   &quot;&quot;&quot;
<span class='lineno'> 447</span>   with tf.variable_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.scope', title='None'>scope</a>,
<span class='lineno'> 448</span>                          &#39;precision_at_recall&#39;,
<span class='lineno'> 449</span>                          [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', title='None'>label_priors</a>],
<span class='lineno'> 450</span>                          reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.reuse', title='None'>reuse</a>):
<span class='lineno'> 451</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', title='?'>weights</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.original_shape', title='?'>original_shape</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', title='(?, ?, ?) -> (?, ?, ?, ?) / (?, ?, float) -> (?, ?, ?, ?)'>_prepare_labels_logits_weights</a>(
<span class='lineno'> 452</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', title='float'>weights</a>)
<span class='lineno'> 453</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.num_labels', title='?'>num_labels</a> = util.get_num_labels(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>)
<span class='lineno'> 454</span> 
<span class='lineno'> 455</span>     # Convert other inputs to tensors and standardize dtypes.
<span class='lineno'> 456</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.target_recall', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.target_recall', title='?'>target_recall</a> = util.convert_and_cast(
<span class='lineno'> 457</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.target_recall', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.target_recall', title='?'>target_recall</a>, &#39;target_recall&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>.dtype)
<span class='lineno'> 458</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.dual_rate_factor', title='?'>dual_rate_factor</a> = util.convert_and_cast(
<span class='lineno'> 459</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.dual_rate_factor', title='float'>dual_rate_factor</a>, &#39;dual_rate_factor&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>.dtype)
<span class='lineno'> 460</span> 
<span class='lineno'> 461</span>     # Create lambdas.
<span class='lineno'> 462</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas', title='?'>lambdas</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas_variable', title='?'>lambdas_variable</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable', title='(?, ?, ?, ?, ?, ?, ?) -> (?, ?) / (str, [?], ?, ?, None, bool, ?) -> (?, ?) / (str, [int], ?, ?, None, bool, ?) -> (?, ?)'>_create_dual_variable</a>(
<span class='lineno'> 463</span>         &#39;lambdas&#39;,
<span class='lineno'> 464</span>         shape=[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.num_labels', title='?'>num_labels</a>],
<span class='lineno'> 465</span>         dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>.dtype,
<span class='lineno'> 466</span>         initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas_initializer', title='?'>lambdas_initializer</a>,
<span class='lineno'> 467</span>         collections=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.variables_collections', title='None'>variables_collections</a>,
<span class='lineno'> 468</span>         trainable=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.trainable', title='bool'>trainable</a>,
<span class='lineno'> 469</span>         dual_rate_factor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.dual_rate_factor', title='?'>dual_rate_factor</a>)
<span class='lineno'> 470</span>     # Maybe create label_priors.
<span class='lineno'> 471</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', title='None'>label_priors</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors', title='(None, ?, ?, None) -> None / (?, ?, ?, ?) -> None'>maybe_create_label_priors</a>(
<span class='lineno'> 472</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', title='None'>label_priors</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.variables_collections', title='None'>variables_collections</a>)
<span class='lineno'> 473</span> 
<span class='lineno'> 474</span>     # Calculate weighted loss and other outputs. The log(2.0) term corrects for
<span class='lineno'> 475</span>     # logloss not being an upper bound on the indicator function.
<span class='lineno'> 476</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weighted_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weighted_loss', title='?'>weighted_loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', title='?'>weights</a> * util.weighted_surrogate_loss(
<span class='lineno'> 477</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', title='?'>labels</a>,
<span class='lineno'> 478</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>,
<span class='lineno'> 479</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.surrogate_type', title='str'>surrogate_type</a>,
<span class='lineno'> 480</span>         positive_weights=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas', title='?'>lambdas</a>,
<span class='lineno'> 481</span>         negative_weights=1.0)
<span class='lineno'> 482</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.maybe_log2', title='float'>maybe_log2</a> = tf.log(2.0) if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.surrogate_type', title='str'>surrogate_type</a> == &#39;xent&#39; else 1.0
<span class='lineno'> 483</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.maybe_log2', title='?'>maybe_log2</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.maybe_log2', title='float'>maybe_log2</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>.dtype.base_dtype)
<span class='lineno'> 484</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambda_term', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambda_term', title='?'>lambda_term</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas', title='?'>lambdas</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', title='None'>label_priors</a> * (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.target_recall', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.target_recall', title='?'>target_recall</a> - 1.0) * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.maybe_log2', title='?'>maybe_log2</a>
<span class='lineno'> 485</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.loss', title='?'>loss</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weighted_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weighted_loss', title='?'>weighted_loss</a> + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambda_term', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambda_term', title='?'>lambda_term</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.original_shape', title='?'>original_shape</a>)
<span class='lineno'> 486</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.other_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.other_outputs', title='dict'>other_outputs</a> = {
<span class='lineno'> 487</span>         &#39;lambdas&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.lambdas_variable', title='?'>lambdas_variable</a>,
<span class='lineno'> 488</span>         &#39;label_priors&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.label_priors', title='None'>label_priors</a>,
<span class='lineno'> 489</span>         &#39;true_positives_lower_bound&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound', title='(?, ?, ?, ?) -> None / (?, ?, ?, str) -> None'>true_positives_lower_bound</a>(
<span class='lineno'> 490</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.surrogate_type', title='str'>surrogate_type</a>),
<span class='lineno'> 491</span>         &#39;false_positives_upper_bound&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound', title='(?, ?, ?, ?) -> None / (?, ?, ?, str) -> None'>false_positives_upper_bound</a>(
<span class='lineno'> 492</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.surrogate_type', title='str'>surrogate_type</a>)}
<span class='lineno'> 493</span> 
<span class='lineno'> 494</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.loss', title='?'>loss</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.other_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss.other_outputs', title='dict'>other_outputs</a>
<span class='lineno'> 495</span> 
<span class='lineno'> 496</span> 
<span class='lineno'> 497</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss', title='(?, ?, ?, float, float, None, str, ?, None, None, bool, None) -> (?, dict)'>false_positive_rate_at_true_positive_rate_loss</a>(
<span class='lineno'> 498</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.labels', title='?'>labels</a>,
<span class='lineno'> 499</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.logits', title='?'>logits</a>,
<span class='lineno'> 500</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.target_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.target_rate', title='?'>target_rate</a>,
<span class='lineno'> 501</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.weights', title='float'>weights</a>=1.0,
<span class='lineno'> 502</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.dual_rate_factor', title='float'>dual_rate_factor</a>=0.1,
<span class='lineno'> 503</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.label_priors', title='None'>label_priors</a>=None,
<span class='lineno'> 504</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.surrogate_type', title='str'>surrogate_type</a>=&#39;xent&#39;,
<span class='lineno'> 505</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.lambdas_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.lambdas_initializer', title='?'>lambdas_initializer</a>=tf.constant_initializer(1.0),
<span class='lineno'> 506</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.reuse', title='None'>reuse</a>=None,
<span class='lineno'> 507</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.variables_collections', title='None'>variables_collections</a>=None,
<span class='lineno'> 508</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.trainable', title='bool'>trainable</a>=True,
<span class='lineno'> 509</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.scope', title='None'>scope</a>=None):
<span class='lineno'> 510</span>   &quot;&quot;&quot;Computes false positive rate at true positive rate loss.
<span class='lineno'> 511</span> 
<span class='lineno'> 512</span>   Note that `true positive rate` is a synonym for Recall, and that minimizing
<span class='lineno'> 513</span>   the false positive rate and maximizing precision are equivalent for a fixed
<span class='lineno'> 514</span>   Recall. Therefore, this function is identical to precision_at_recall_loss.
<span class='lineno'> 515</span> 
<span class='lineno'> 516</span>   The per-example weights change not only the coefficients of individual
<span class='lineno'> 517</span>   training examples, but how the examples are counted toward the constraint.
<span class='lineno'> 518</span>   If `label_priors` is given, it MUST take `weights` into account. That is,
<span class='lineno'> 519</span>       label_priors = P / (P + N)
<span class='lineno'> 520</span>   where
<span class='lineno'> 521</span>       P = sum_i (wt_i on positives)
<span class='lineno'> 522</span>       N = sum_i (wt_i on negatives).
<span class='lineno'> 523</span> 
<span class='lineno'> 524</span>   Args:
<span class='lineno'> 525</span>     labels: A `Tensor` of shape [batch_size] or [batch_size, num_labels].
<span class='lineno'> 526</span>     logits: A `Tensor` with the same shape as `labels`.
<span class='lineno'> 527</span>     target_rate: The true positive rate at which to compute the loss. Can be a
<span class='lineno'> 528</span>       floating point value between 0 and 1 for a single true positive rate, or
<span class='lineno'> 529</span>       a `Tensor` of shape [num_labels] holding each label&#39;s true positive rate.
<span class='lineno'> 530</span>     weights: Coefficients for the loss. Must be a scalar or `Tensor` of shape
<span class='lineno'> 531</span>       [batch_size] or [batch_size, num_labels].
<span class='lineno'> 532</span>     dual_rate_factor: A floating point value which controls the step size for
<span class='lineno'> 533</span>       the Lagrange multipliers.
<span class='lineno'> 534</span>     label_priors: None, or a floating point `Tensor` of shape [num_labels]
<span class='lineno'> 535</span>       containing the prior probability of each label (i.e. the fraction of the
<span class='lineno'> 536</span>       training data consisting of positive examples). If None, the label
<span class='lineno'> 537</span>       priors are computed from `labels` with a moving average. See the notes
<span class='lineno'> 538</span>       above regarding the interaction with `weights` and do not set this unless
<span class='lineno'> 539</span>       you have a good reason to do so.
<span class='lineno'> 540</span>     surrogate_type: Either &#39;xent&#39; or &#39;hinge&#39;, specifying which upper bound
<span class='lineno'> 541</span>       should be used for indicator functions. &#39;xent&#39; will use the cross-entropy
<span class='lineno'> 542</span>       loss surrogate, and &#39;hinge&#39; will use the hinge loss.
<span class='lineno'> 543</span>     lambdas_initializer: An initializer op for the Lagrange multipliers.
<span class='lineno'> 544</span>     reuse: Whether or not the layer and its variables should be reused. To be
<span class='lineno'> 545</span>       able to reuse the layer scope must be given.
<span class='lineno'> 546</span>     variables_collections: Optional list of collections for the variables.
<span class='lineno'> 547</span>     trainable: If `True` also add variables to the graph collection
<span class='lineno'> 548</span>       `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).
<span class='lineno'> 549</span>     scope: Optional scope for `variable_scope`.
<span class='lineno'> 550</span> 
<span class='lineno'> 551</span>   Returns:
<span class='lineno'> 552</span>     loss: A `Tensor` of the same shape as `logits` with the component-wise
<span class='lineno'> 553</span>       loss.
<span class='lineno'> 554</span>     other_outputs: A dictionary of useful internal quantities for debugging. For
<span class='lineno'> 555</span>       more details, see http://arxiv.org/pdf/1608.04802.pdf.
<span class='lineno'> 556</span>       lambdas: A Tensor of shape [num_labels] consisting of the Lagrange
<span class='lineno'> 557</span>         multipliers.
<span class='lineno'> 558</span>       label_priors: A Tensor of shape [num_labels] consisting of the prior
<span class='lineno'> 559</span>         probability of each label learned by the loss, if not provided.
<span class='lineno'> 560</span>       true_positives_lower_bound: Lower bound on the number of true positives
<span class='lineno'> 561</span>         given `labels` and `logits`. This is the same lower bound which is used
<span class='lineno'> 562</span>         in the loss expression to be optimized.
<span class='lineno'> 563</span>       false_positives_upper_bound: Upper bound on the number of false positives
<span class='lineno'> 564</span>         given `labels` and `logits`. This is the same upper bound which is used
<span class='lineno'> 565</span>         in the loss expression to be optimized.
<span class='lineno'> 566</span> 
<span class='lineno'> 567</span>   Raises:
<span class='lineno'> 568</span>     ValueError: If `surrogate_type` is not `xent` or `hinge`.
<span class='lineno'> 569</span>   &quot;&quot;&quot;
<span class='lineno'> 570</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.precision_at_recall_loss', title='(?, ?, ?, float, float, None, str, ?, None, None, bool, None) -> (?, dict)'>precision_at_recall_loss</a>(labels=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.labels', title='?'>labels</a>,
<span class='lineno'> 571</span>                                   logits=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.logits', title='?'>logits</a>,
<span class='lineno'> 572</span>                                   target_recall=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.target_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.target_rate', title='?'>target_rate</a>,
<span class='lineno'> 573</span>                                   weights=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.weights', title='float'>weights</a>,
<span class='lineno'> 574</span>                                   dual_rate_factor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.dual_rate_factor', title='float'>dual_rate_factor</a>,
<span class='lineno'> 575</span>                                   label_priors=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.label_priors', title='None'>label_priors</a>,
<span class='lineno'> 576</span>                                   surrogate_type=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.surrogate_type', title='str'>surrogate_type</a>,
<span class='lineno'> 577</span>                                   lambdas_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.lambdas_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.lambdas_initializer', title='?'>lambdas_initializer</a>,
<span class='lineno'> 578</span>                                   reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.reuse', title='None'>reuse</a>,
<span class='lineno'> 579</span>                                   variables_collections=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.variables_collections', title='None'>variables_collections</a>,
<span class='lineno'> 580</span>                                   trainable=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.trainable', title='bool'>trainable</a>,
<span class='lineno'> 581</span>                                   scope=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positive_rate_at_true_positive_rate_loss.scope', title='None'>scope</a>)
<span class='lineno'> 582</span> 
<span class='lineno'> 583</span> 
<span class='lineno'> 584</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss', title='(?, ?, ?, float, float, None, str, ?, None, None, bool, None) -> (?, dict)'>true_positive_rate_at_false_positive_rate_loss</a>(
<span class='lineno'> 585</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', title='?'>labels</a>,
<span class='lineno'> 586</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>,
<span class='lineno'> 587</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.target_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.target_rate', title='?'>target_rate</a>,
<span class='lineno'> 588</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', title='float'>weights</a>=1.0,
<span class='lineno'> 589</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.dual_rate_factor', title='float'>dual_rate_factor</a>=0.1,
<span class='lineno'> 590</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', title='None'>label_priors</a>=None,
<span class='lineno'> 591</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.surrogate_type', title='str'>surrogate_type</a>=&#39;xent&#39;,
<span class='lineno'> 592</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas_initializer', title='?'>lambdas_initializer</a>=tf.constant_initializer(1.0),
<span class='lineno'> 593</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.reuse', title='None'>reuse</a>=None,
<span class='lineno'> 594</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.variables_collections', title='None'>variables_collections</a>=None,
<span class='lineno'> 595</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.trainable', title='bool'>trainable</a>=True,
<span class='lineno'> 596</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.scope', title='None'>scope</a>=None):
<span class='lineno'> 597</span>   &quot;&quot;&quot;Computes true positive rate at false positive rate loss.
<span class='lineno'> 598</span> 
<span class='lineno'> 599</span>   The loss is based on a surrogate of the form
<span class='lineno'> 600</span>       wt * loss(+) + lambdas * (wt * loss(-) - r * (1 - pi))
<span class='lineno'> 601</span>   where:
<span class='lineno'> 602</span>   - loss(-) is the loss on the negative examples
<span class='lineno'> 603</span>   - loss(+) is the loss on the positive examples
<span class='lineno'> 604</span>   - wt is a scalar or tensor of per-example weights
<span class='lineno'> 605</span>   - r is the target rate
<span class='lineno'> 606</span>   - pi is the label_priors.
<span class='lineno'> 607</span> 
<span class='lineno'> 608</span>   The per-example weights change not only the coefficients of individual
<span class='lineno'> 609</span>   training examples, but how the examples are counted toward the constraint.
<span class='lineno'> 610</span>   If `label_priors` is given, it MUST take `weights` into account. That is,
<span class='lineno'> 611</span>       label_priors = P / (P + N)
<span class='lineno'> 612</span>   where
<span class='lineno'> 613</span>       P = sum_i (wt_i on positives)
<span class='lineno'> 614</span>       N = sum_i (wt_i on negatives).
<span class='lineno'> 615</span> 
<span class='lineno'> 616</span>   Args:
<span class='lineno'> 617</span>     labels: A `Tensor` of shape [batch_size] or [batch_size, num_labels].
<span class='lineno'> 618</span>     logits: A `Tensor` with the same shape as `labels`.
<span class='lineno'> 619</span>     target_rate: The false positive rate at which to compute the loss. Can be a
<span class='lineno'> 620</span>       floating point value between 0 and 1 for a single false positive rate, or
<span class='lineno'> 621</span>       a `Tensor` of shape [num_labels] holding each label&#39;s false positive rate.
<span class='lineno'> 622</span>     weights: Coefficients for the loss. Must be a scalar or `Tensor` of shape
<span class='lineno'> 623</span>       [batch_size] or [batch_size, num_labels].
<span class='lineno'> 624</span>     dual_rate_factor: A floating point value which controls the step size for
<span class='lineno'> 625</span>       the Lagrange multipliers.
<span class='lineno'> 626</span>     label_priors: None, or a floating point `Tensor` of shape [num_labels]
<span class='lineno'> 627</span>       containing the prior probability of each label (i.e. the fraction of the
<span class='lineno'> 628</span>       training data consisting of positive examples). If None, the label
<span class='lineno'> 629</span>       priors are computed from `labels` with a moving average. See the notes
<span class='lineno'> 630</span>       above regarding the interaction with `weights` and do not set this unless
<span class='lineno'> 631</span>       you have a good reason to do so.
<span class='lineno'> 632</span>     surrogate_type: Either &#39;xent&#39; or &#39;hinge&#39;, specifying which upper bound
<span class='lineno'> 633</span>       should be used for indicator functions. &#39;xent&#39; will use the cross-entropy
<span class='lineno'> 634</span>       loss surrogate, and &#39;hinge&#39; will use the hinge loss.
<span class='lineno'> 635</span>     lambdas_initializer: An initializer op for the Lagrange multipliers.
<span class='lineno'> 636</span>     reuse: Whether or not the layer and its variables should be reused. To be
<span class='lineno'> 637</span>       able to reuse the layer scope must be given.
<span class='lineno'> 638</span>     variables_collections: Optional list of collections for the variables.
<span class='lineno'> 639</span>     trainable: If `True` also add variables to the graph collection
<span class='lineno'> 640</span>       `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).
<span class='lineno'> 641</span>     scope: Optional scope for `variable_scope`.
<span class='lineno'> 642</span> 
<span class='lineno'> 643</span>   Returns:
<span class='lineno'> 644</span>     loss: A `Tensor` of the same shape as `logits` with the component-wise
<span class='lineno'> 645</span>       loss.
<span class='lineno'> 646</span>     other_outputs: A dictionary of useful internal quantities for debugging. For
<span class='lineno'> 647</span>       more details, see http://arxiv.org/pdf/1608.04802.pdf.
<span class='lineno'> 648</span>       lambdas: A Tensor of shape [num_labels] consisting of the Lagrange
<span class='lineno'> 649</span>         multipliers.
<span class='lineno'> 650</span>       label_priors: A Tensor of shape [num_labels] consisting of the prior
<span class='lineno'> 651</span>         probability of each label learned by the loss, if not provided.
<span class='lineno'> 652</span>       true_positives_lower_bound: Lower bound on the number of true positives
<span class='lineno'> 653</span>         given `labels` and `logits`. This is the same lower bound which is used
<span class='lineno'> 654</span>         in the loss expression to be optimized.
<span class='lineno'> 655</span>       false_positives_upper_bound: Upper bound on the number of false positives
<span class='lineno'> 656</span>         given `labels` and `logits`. This is the same upper bound which is used
<span class='lineno'> 657</span>         in the loss expression to be optimized.
<span class='lineno'> 658</span> 
<span class='lineno'> 659</span>   Raises:
<span class='lineno'> 660</span>     ValueError: If `surrogate_type` is not `xent` or `hinge`.
<span class='lineno'> 661</span>   &quot;&quot;&quot;
<span class='lineno'> 662</span>   with tf.variable_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.scope', title='None'>scope</a>,
<span class='lineno'> 663</span>                          &#39;tpr_at_fpr&#39;,
<span class='lineno'> 664</span>                          [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', title='None'>label_priors</a>],
<span class='lineno'> 665</span>                          reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.reuse', title='None'>reuse</a>):
<span class='lineno'> 666</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', title='?'>weights</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.original_shape', title='?'>original_shape</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', title='(?, ?, ?) -> (?, ?, ?, ?) / (?, ?, float) -> (?, ?, ?, ?)'>_prepare_labels_logits_weights</a>(
<span class='lineno'> 667</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', title='float'>weights</a>)
<span class='lineno'> 668</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.num_labels', title='?'>num_labels</a> = util.get_num_labels(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>)
<span class='lineno'> 669</span> 
<span class='lineno'> 670</span>     # Convert other inputs to tensors and standardize dtypes.
<span class='lineno'> 671</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.target_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.target_rate', title='?'>target_rate</a> = util.convert_and_cast(
<span class='lineno'> 672</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.target_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.target_rate', title='?'>target_rate</a>, &#39;target_rate&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>.dtype)
<span class='lineno'> 673</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.dual_rate_factor', title='?'>dual_rate_factor</a> = util.convert_and_cast(
<span class='lineno'> 674</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.dual_rate_factor', title='float'>dual_rate_factor</a>, &#39;dual_rate_factor&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>.dtype)
<span class='lineno'> 675</span> 
<span class='lineno'> 676</span>     # Create lambdas.
<span class='lineno'> 677</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas', title='?'>lambdas</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas_variable', title='?'>lambdas_variable</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable', title='(?, ?, ?, ?, ?, ?, ?) -> (?, ?) / (str, [?], ?, ?, None, bool, ?) -> (?, ?) / (str, [int], ?, ?, None, bool, ?) -> (?, ?)'>_create_dual_variable</a>(
<span class='lineno'> 678</span>         &#39;lambdas&#39;,
<span class='lineno'> 679</span>         shape=[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.num_labels', title='?'>num_labels</a>],
<span class='lineno'> 680</span>         dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>.dtype,
<span class='lineno'> 681</span>         initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas_initializer', title='?'>lambdas_initializer</a>,
<span class='lineno'> 682</span>         collections=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.variables_collections', title='None'>variables_collections</a>,
<span class='lineno'> 683</span>         trainable=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.trainable', title='bool'>trainable</a>,
<span class='lineno'> 684</span>         dual_rate_factor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.dual_rate_factor', title='?'>dual_rate_factor</a>)
<span class='lineno'> 685</span>     # Maybe create label_priors.
<span class='lineno'> 686</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', title='None'>label_priors</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors', title='(None, ?, ?, None) -> None / (?, ?, ?, ?) -> None'>maybe_create_label_priors</a>(
<span class='lineno'> 687</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', title='None'>label_priors</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.variables_collections', title='None'>variables_collections</a>)
<span class='lineno'> 688</span> 
<span class='lineno'> 689</span>     # Loss op and other outputs. The log(2.0) term corrects for
<span class='lineno'> 690</span>     # logloss not being an upper bound on the indicator function.
<span class='lineno'> 691</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weighted_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weighted_loss', title='?'>weighted_loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', title='?'>weights</a> * util.weighted_surrogate_loss(
<span class='lineno'> 692</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', title='?'>labels</a>,
<span class='lineno'> 693</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>,
<span class='lineno'> 694</span>         surrogate_type=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.surrogate_type', title='str'>surrogate_type</a>,
<span class='lineno'> 695</span>         positive_weights=1.0,
<span class='lineno'> 696</span>         negative_weights=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas', title='?'>lambdas</a>)
<span class='lineno'> 697</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.maybe_log2', title='float'>maybe_log2</a> = tf.log(2.0) if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.surrogate_type', title='str'>surrogate_type</a> == &#39;xent&#39; else 1.0
<span class='lineno'> 698</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.maybe_log2', title='?'>maybe_log2</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.maybe_log2', title='float'>maybe_log2</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>.dtype.base_dtype)
<span class='lineno'> 699</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambda_term', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambda_term', title='float'>lambda_term</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas', title='?'>lambdas</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.target_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.target_rate', title='?'>target_rate</a> * (1.0 - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', title='None'>label_priors</a>) * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.maybe_log2', title='?'>maybe_log2</a>
<span class='lineno'> 700</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.loss', title='?'>loss</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weighted_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weighted_loss', title='?'>weighted_loss</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambda_term', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambda_term', title='float'>lambda_term</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.original_shape', title='?'>original_shape</a>)
<span class='lineno'> 701</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.other_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.other_outputs', title='dict'>other_outputs</a> = {
<span class='lineno'> 702</span>         &#39;lambdas&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.lambdas_variable', title='?'>lambdas_variable</a>,
<span class='lineno'> 703</span>         &#39;label_priors&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.label_priors', title='None'>label_priors</a>,
<span class='lineno'> 704</span>         &#39;true_positives_lower_bound&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound', title='(?, ?, ?, ?) -> None / (?, ?, ?, str) -> None'>true_positives_lower_bound</a>(
<span class='lineno'> 705</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.surrogate_type', title='str'>surrogate_type</a>),
<span class='lineno'> 706</span>         &#39;false_positives_upper_bound&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound', title='(?, ?, ?, ?) -> None / (?, ?, ?, str) -> None'>false_positives_upper_bound</a>(
<span class='lineno'> 707</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.surrogate_type', title='str'>surrogate_type</a>)}
<span class='lineno'> 708</span> 
<span class='lineno'> 709</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.loss', title='?'>loss</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.other_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positive_rate_at_false_positive_rate_loss.other_outputs', title='dict'>other_outputs</a>
<span class='lineno'> 710</span> 
<span class='lineno'> 711</span> 
<span class='lineno'> 712</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights', title='(?, ?, ?) -> (?, ?, ?, ?) / (?, ?, float) -> (?, ?, ?, ?)'>_prepare_labels_logits_weights</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', title='float'>weights</a>):
<span class='lineno'> 713</span>   &quot;&quot;&quot;Validates labels, logits, and weights.
<span class='lineno'> 714</span> 
<span class='lineno'> 715</span>   Converts inputs to tensors, checks shape compatibility, and casts dtype if
<span class='lineno'> 716</span>   necessary.
<span class='lineno'> 717</span> 
<span class='lineno'> 718</span>   Args:
<span class='lineno'> 719</span>     labels: A `Tensor` of shape [batch_size] or [batch_size, num_labels].
<span class='lineno'> 720</span>     logits: A `Tensor` with the same shape as `labels`.
<span class='lineno'> 721</span>     weights: Either `None` or a `Tensor` with shape broadcastable to `logits`.
<span class='lineno'> 722</span> 
<span class='lineno'> 723</span>   Returns:
<span class='lineno'> 724</span>     labels: Same as `labels` arg after possible conversion to tensor, cast, and
<span class='lineno'> 725</span>       reshape.
<span class='lineno'> 726</span>     logits: Same as `logits` arg after possible conversion to tensor and
<span class='lineno'> 727</span>       reshape.
<span class='lineno'> 728</span>     weights: Same as `weights` arg after possible conversion, cast, and reshape.
<span class='lineno'> 729</span>     original_shape: Shape of `labels` and `logits` before reshape.
<span class='lineno'> 730</span> 
<span class='lineno'> 731</span>   Raises:
<span class='lineno'> 732</span>     ValueError: If `labels` and `logits` do not have the same shape.
<span class='lineno'> 733</span>   &quot;&quot;&quot;
<span class='lineno'> 734</span>   # Convert `labels` and `logits` to Tensors and standardize dtypes.
<span class='lineno'> 735</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', title='?'>logits</a> = tf.convert_to_tensor(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', title='?'>logits</a>, name=&#39;logits&#39;)
<span class='lineno'> 736</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', title='?'>labels</a> = util.convert_and_cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', title='?'>labels</a>, &#39;labels&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', title='?'>logits</a>.dtype.base_dtype)
<span class='lineno'> 737</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', title='?'>weights</a> = util.convert_and_cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', title='float'>weights</a>, &#39;weights&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', title='?'>logits</a>.dtype.base_dtype)
<span class='lineno'> 738</span> 
<span class='lineno'> 739</span>   try:
<span class='lineno'> 740</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', title='?'>labels</a>.get_shape().merge_with(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', title='?'>logits</a>.get_shape())
<span class='lineno'> 741</span>   except ValueError:
<span class='lineno'> 742</span>     raise ValueError(&#39;logits and labels must have the same shape (%s vs %s)&#39; %
<span class='lineno'> 743</span>                      (logits.get_shape(), labels.get_shape()))
<span class='lineno'> 744</span> 
<span class='lineno'> 745</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.original_shape', title='?'>original_shape</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', title='?'>labels</a>.get_shape().as_list()
<span class='lineno'> 746</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', title='?'>labels</a>.get_shape().ndims &gt; 0:
<span class='lineno'> 747</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.original_shape', title='?'>original_shape</a>[0] = -1
<span class='lineno'> 748</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', title='?'>labels</a>.get_shape().ndims &lt;= 1:
<span class='lineno'> 749</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', title='?'>labels</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', title='?'>labels</a>, [-1, 1])
<span class='lineno'> 750</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', title='?'>logits</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', title='?'>logits</a>, [-1, 1])
<span class='lineno'> 751</span> 
<span class='lineno'> 752</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', title='?'>weights</a>.get_shape().ndims == 1:
<span class='lineno'> 753</span>     # Weights has shape [batch_size]. Reshape to [batch_size, 1].
<span class='lineno'> 754</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', title='?'>weights</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', title='?'>weights</a>, [-1, 1])
<span class='lineno'> 755</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', title='?'>weights</a>.get_shape().ndims == 0:
<span class='lineno'> 756</span>     # Weights is a scalar. Change shape of weights to match logits.
<span class='lineno'> 757</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', title='?'>weights</a></a> *= tf.ones_like(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', title='?'>logits</a>)
<span class='lineno'> 758</span> 
<span class='lineno'> 759</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.weights', title='?'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.original_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._prepare_labels_logits_weights.original_shape', title='?'>original_shape</a>
<span class='lineno'> 760</span> 
<span class='lineno'> 761</span> 
<span class='lineno'> 762</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta', title='(?, ?, ?) -> (?, ?) / ((float, float), int, ?) -> (?, ?)'>_range_to_anchors_and_delta</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', title='(float, float)'>precision_range</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.num_anchors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.num_anchors', title='int'>num_anchors</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.dtype', title='?'>dtype</a>):
<span class='lineno'> 763</span>   &quot;&quot;&quot;Calculates anchor points from precision range.
<span class='lineno'> 764</span> 
<span class='lineno'> 765</span>   Args:
<span class='lineno'> 766</span>     precision_range: As required in precision_recall_auc_loss.
<span class='lineno'> 767</span>     num_anchors: int, number of equally spaced anchor points.
<span class='lineno'> 768</span>     dtype: Data type of returned tensors.
<span class='lineno'> 769</span> 
<span class='lineno'> 770</span>   Returns:
<span class='lineno'> 771</span>     precision_values: A `Tensor` of data type dtype with equally spaced values
<span class='lineno'> 772</span>       in the interval precision_range.
<span class='lineno'> 773</span>     delta: The spacing between the values in precision_values.
<span class='lineno'> 774</span> 
<span class='lineno'> 775</span>   Raises:
<span class='lineno'> 776</span>     ValueError: If precision_range is invalid.
<span class='lineno'> 777</span>   &quot;&quot;&quot;
<span class='lineno'> 778</span>   # Validate precision_range.
<span class='lineno'> 779</span>   if not 0 &lt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', title='(float, float)'>precision_range</a>[0] &lt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', title='(float, float)'>precision_range</a>[-1] &lt;= 1:
<span class='lineno'> 780</span>     raise ValueError(&#39;precision values must obey 0 &lt;= %f &lt;= %f &lt;= 1&#39; %
<span class='lineno'> 781</span>                      (precision_range[0], precision_range[-1]))
<span class='lineno'> 782</span>   if not 0 &lt; len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', title='(float, float)'>precision_range</a>) &lt; 3:
<span class='lineno'> 783</span>     raise ValueError(&#39;length of precision_range (%d) must be 1 or 2&#39; %
<span class='lineno'> 784</span>                      len(precision_range))
<span class='lineno'> 785</span> 
<span class='lineno'> 786</span>   # Sets precision_values uniformly between min_precision and max_precision.
<span class='lineno'> 787</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.values', title='?'>values</a> = numpy.linspace(start=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', title='(float, float)'>precision_range</a>[0],
<span class='lineno'> 788</span>                           stop=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', title='(float, float)'>precision_range</a>[1],
<span class='lineno'> 789</span>                           num=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.num_anchors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.num_anchors', title='int'>num_anchors</a>+2)[1:-1]
<span class='lineno'> 790</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_values', title='?'>precision_values</a> = util.convert_and_cast(
<span class='lineno'> 791</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.values', title='?'>values</a>, &#39;precision_values&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.dtype', title='?'>dtype</a>)
<span class='lineno'> 792</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.delta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.delta', title='?'>delta</a> = util.convert_and_cast(
<span class='lineno'> 793</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.values', title='?'>values</a>[0] - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_range', title='(float, float)'>precision_range</a>[0], &#39;delta&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.dtype', title='?'>dtype</a>)
<span class='lineno'> 794</span>   # Makes precision_values [1, 1, num_anchors].
<span class='lineno'> 795</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_values', title='?'>precision_values</a> = util.expand_outer(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_values', title='?'>precision_values</a>, 3)
<span class='lineno'> 796</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.precision_values', title='?'>precision_values</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.delta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._range_to_anchors_and_delta.delta', title='?'>delta</a>
<span class='lineno'> 797</span> 
<span class='lineno'> 798</span> 
<span class='lineno'> 799</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable', title='(?, ?, ?, ?, ?, ?, ?) -> (?, ?) / (str, [?], ?, ?, None, bool, ?) -> (?, ?) / (str, [int], ?, ?, None, bool, ?) -> (?, ?)'>_create_dual_variable</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.name', title='str'>name</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.shape', title='{[?] | [int]}'>shape</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dtype', title='?'>dtype</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.initializer', title='?'>initializer</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.collections', title='None'>collections</a>,
<span class='lineno'> 800</span>                           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.trainable', title='bool'>trainable</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_rate_factor', title='?'>dual_rate_factor</a>):
<span class='lineno'> 801</span>   &quot;&quot;&quot;Creates a new dual variable.
<span class='lineno'> 802</span> 
<span class='lineno'> 803</span>   Dual variables are required to be nonnegative. If trainable, their gradient
<span class='lineno'> 804</span>   is reversed so that they are maximized (rather than minimized) by the
<span class='lineno'> 805</span>   optimizer.
<span class='lineno'> 806</span> 
<span class='lineno'> 807</span>   Args:
<span class='lineno'> 808</span>     name: A string, the name for the new variable.
<span class='lineno'> 809</span>     shape: Shape of the new variable.
<span class='lineno'> 810</span>     dtype: Data type for the new variable.
<span class='lineno'> 811</span>     initializer: Initializer for the new variable.
<span class='lineno'> 812</span>     collections: List of graph collections keys. The new variable is added to
<span class='lineno'> 813</span>       these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.
<span class='lineno'> 814</span>     trainable: If `True`, the default, also adds the variable to the graph
<span class='lineno'> 815</span>       collection `GraphKeys.TRAINABLE_VARIABLES`. This collection is used as
<span class='lineno'> 816</span>       the default list of variables to use by the `Optimizer` classes.
<span class='lineno'> 817</span>     dual_rate_factor: A floating point value or `Tensor`. The learning rate for
<span class='lineno'> 818</span>       the dual variable is scaled by this factor.
<span class='lineno'> 819</span> 
<span class='lineno'> 820</span>   Returns:
<span class='lineno'> 821</span>     dual_value: An op that computes the absolute value of the dual variable
<span class='lineno'> 822</span>       and reverses its gradient.
<span class='lineno'> 823</span>     dual_variable: The underlying variable itself.
<span class='lineno'> 824</span>   &quot;&quot;&quot;
<span class='lineno'> 825</span>   # We disable partitioning while constructing dual variables because they will
<span class='lineno'> 826</span>   # be updated with assign, which is not available for partitioned variables.
<span class='lineno'> 827</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.partitioner', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.partitioner', title='?'>partitioner</a> = tf.get_variable_scope().partitioner
<span class='lineno'> 828</span>   try:
<span class='lineno'> 829</span>     tf.get_variable_scope().set_partitioner(None)
<span class='lineno'> 830</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_variable', title='?'>dual_variable</a> = tf.contrib.framework.model_variable(
<span class='lineno'> 831</span>         name=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.name', title='str'>name</a>,
<span class='lineno'> 832</span>         shape=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.shape', title='{[?] | [int]}'>shape</a>,
<span class='lineno'> 833</span>         dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dtype', title='?'>dtype</a>,
<span class='lineno'> 834</span>         initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.initializer', title='?'>initializer</a>,
<span class='lineno'> 835</span>         collections=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.collections', title='None'>collections</a>,
<span class='lineno'> 836</span>         trainable=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.trainable', title='bool'>trainable</a>)
<span class='lineno'> 837</span>   finally:
<span class='lineno'> 838</span>     tf.get_variable_scope().set_partitioner(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.partitioner', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.partitioner', title='?'>partitioner</a>)
<span class='lineno'> 839</span>   # Using the absolute value enforces nonnegativity.
<span class='lineno'> 840</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_value', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_value', title='?'>dual_value</a> = tf.abs(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_variable', title='?'>dual_variable</a>)
<span class='lineno'> 841</span> 
<span class='lineno'> 842</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.trainable', title='bool'>trainable</a>:
<span class='lineno'> 843</span>     # To reverse the gradient on the dual variable, multiply the gradient by
<span class='lineno'> 844</span>     # -dual_rate_factor
<span class='lineno'> 845</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_value', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_value', title='?'>dual_value</a> = (tf.stop_gradient((1.0 + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_rate_factor', title='?'>dual_rate_factor</a>) * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_value', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_value', title='?'>dual_value</a>)
<span class='lineno'> 846</span>                   - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_rate_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_rate_factor', title='?'>dual_rate_factor</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_value', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_value', title='?'>dual_value</a>)
<span class='lineno'> 847</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_value', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_value', title='?'>dual_value</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_variable', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers._create_dual_variable.dual_variable', title='?'>dual_variable</a>
<span class='lineno'> 848</span> 
<span class='lineno'> 849</span> 
<span class='lineno'> 850</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors', title='(None, ?, ?, None) -> None / (?, ?, ?, ?) -> None'>maybe_create_label_priors</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', title='None'>label_priors</a>,
<span class='lineno'> 851</span>                               <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.labels', title='?'>labels</a>,
<span class='lineno'> 852</span>                               <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.weights', title='?'>weights</a>,
<span class='lineno'> 853</span>                               <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.variables_collections', title='None'>variables_collections</a>):
<span class='lineno'> 854</span>   &quot;&quot;&quot;Creates moving average ops to track label priors, if necessary.
<span class='lineno'> 855</span> 
<span class='lineno'> 856</span>   Args:
<span class='lineno'> 857</span>     label_priors: As required in e.g. precision_recall_auc_loss.
<span class='lineno'> 858</span>     labels: A `Tensor` of shape [batch_size] or [batch_size, num_labels].
<span class='lineno'> 859</span>     weights: As required in e.g. precision_recall_auc_loss.
<span class='lineno'> 860</span>     variables_collections: Optional list of collections for the variables, if
<span class='lineno'> 861</span>       any must be created.
<span class='lineno'> 862</span> 
<span class='lineno'> 863</span>   Returns:
<span class='lineno'> 864</span>     label_priors: A Tensor of shape [num_labels] consisting of the
<span class='lineno'> 865</span>       weighted label priors, after updating with moving average ops if created.
<span class='lineno'> 866</span>   &quot;&quot;&quot;
<span class='lineno'> 867</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', title='None'>label_priors</a> is not None:
<span class='lineno'> 868</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', title='?'>label_priors</a> = util.convert_and_cast(
<span class='lineno'> 869</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', title='None'>label_priors</a>, name=&#39;label_priors&#39;, dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.labels', title='?'>labels</a>.dtype.base_dtype)
<span class='lineno'> 870</span>     return tf.squeeze(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', title='?'>label_priors</a>)
<span class='lineno'> 871</span> 
<span class='lineno'> 872</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', title='?'>label_priors</a> = util.build_label_priors(
<span class='lineno'> 873</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.labels', title='?'>labels</a>,
<span class='lineno'> 874</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.weights', title='?'>weights</a>,
<span class='lineno'> 875</span>       variables_collections=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.variables_collections', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.variables_collections', title='None'>variables_collections</a>)
<span class='lineno'> 876</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.maybe_create_label_priors.label_priors', title='?'>label_priors</a>
<span class='lineno'> 877</span> 
<span class='lineno'> 878</span> 
<span class='lineno'> 879</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound', title='(?, ?, ?, ?) -> None / (?, ?, ?, str) -> None'>true_positives_lower_bound</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.weights', title='?'>weights</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.surrogate_type', title='str'>surrogate_type</a>):
<span class='lineno'> 880</span>   &quot;&quot;&quot;Calculate a lower bound on the number of true positives.
<span class='lineno'> 881</span> 
<span class='lineno'> 882</span>   This lower bound on the number of true positives given `logits` and `labels`
<span class='lineno'> 883</span>   is the same one used in the global objectives loss functions.
<span class='lineno'> 884</span> 
<span class='lineno'> 885</span>   Args:
<span class='lineno'> 886</span>     labels: A `Tensor` of shape [batch_size] or [batch_size, num_labels].
<span class='lineno'> 887</span>     logits: A `Tensor` of shape [batch_size, num_labels] or
<span class='lineno'> 888</span>       [batch_size, num_labels, num_anchors]. If the third dimension is present,
<span class='lineno'> 889</span>       the lower bound is computed on each slice [:, :, k] independently.
<span class='lineno'> 890</span>     weights: Per-example loss coefficients, with shape broadcast-compatible with
<span class='lineno'> 891</span>         that of `labels`.
<span class='lineno'> 892</span>     surrogate_type: Either &#39;xent&#39; or &#39;hinge&#39;, specifying which upper bound
<span class='lineno'> 893</span>       should be used for indicator functions.
<span class='lineno'> 894</span> 
<span class='lineno'> 895</span>   Returns:
<span class='lineno'> 896</span>     A `Tensor` of shape [num_labels] or [num_labels, num_anchors].
<span class='lineno'> 897</span>   &quot;&quot;&quot;
<span class='lineno'> 898</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.maybe_log2', title='float'>maybe_log2</a> = tf.log(2.0) if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.surrogate_type', title='str'>surrogate_type</a> == &#39;xent&#39; else 1.0
<span class='lineno'> 899</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.maybe_log2', title='?'>maybe_log2</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.maybe_log2', title='float'>maybe_log2</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.logits', title='?'>logits</a>.dtype.base_dtype)
<span class='lineno'> 900</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.logits', title='?'>logits</a>.get_shape().ndims == 3 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', title='?'>labels</a>.get_shape().ndims &lt; 3:
<span class='lineno'> 901</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', title='?'>labels</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', title='?'>labels</a>, 2)
<span class='lineno'> 902</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.loss_on_positives', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.loss_on_positives', title='?'>loss_on_positives</a> = util.weighted_surrogate_loss(
<span class='lineno'> 903</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.surrogate_type', title='str'>surrogate_type</a>, negative_weights=0.0) / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.maybe_log2', title='?'>maybe_log2</a>
<span class='lineno'> 904</span>   return tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.weights', title='?'>weights</a> * (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.labels', title='?'>labels</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.loss_on_positives', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.true_positives_lower_bound.loss_on_positives', title='?'>loss_on_positives</a>), 0)
<span class='lineno'> 905</span> 
<span class='lineno'> 906</span> 
<span class='lineno'> 907</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound', title='(?, ?, ?, ?) -> None / (?, ?, ?, str) -> None'>false_positives_upper_bound</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.weights', title='?'>weights</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.surrogate_type', title='str'>surrogate_type</a>):
<span class='lineno'> 908</span>   &quot;&quot;&quot;Calculate an upper bound on the number of false positives.
<span class='lineno'> 909</span> 
<span class='lineno'> 910</span>   This upper bound on the number of false positives given `logits` and `labels`
<span class='lineno'> 911</span>   is the same one used in the global objectives loss functions.
<span class='lineno'> 912</span> 
<span class='lineno'> 913</span>   Args:
<span class='lineno'> 914</span>     labels: A `Tensor` of shape [batch_size, num_labels]
<span class='lineno'> 915</span>     logits: A `Tensor` of shape [batch_size, num_labels]  or
<span class='lineno'> 916</span>       [batch_size, num_labels, num_anchors]. If the third dimension is present,
<span class='lineno'> 917</span>       the lower bound is computed on each slice [:, :, k] independently.
<span class='lineno'> 918</span>     weights: Per-example loss coefficients, with shape broadcast-compatible with
<span class='lineno'> 919</span>         that of `labels`.
<span class='lineno'> 920</span>     surrogate_type: Either &#39;xent&#39; or &#39;hinge&#39;, specifying which upper bound
<span class='lineno'> 921</span>       should be used for indicator functions.
<span class='lineno'> 922</span> 
<span class='lineno'> 923</span>   Returns:
<span class='lineno'> 924</span>     A `Tensor` of shape [num_labels] or [num_labels, num_anchors].
<span class='lineno'> 925</span>   &quot;&quot;&quot;
<span class='lineno'> 926</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.maybe_log2', title='float'>maybe_log2</a> = tf.log(2.0) if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.surrogate_type', title='str'>surrogate_type</a> == &#39;xent&#39; else 1.0
<span class='lineno'> 927</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.maybe_log2', title='?'>maybe_log2</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.maybe_log2', title='float'>maybe_log2</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.logits', title='?'>logits</a>.dtype.base_dtype)
<span class='lineno'> 928</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.loss_on_negatives', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.loss_on_negatives', title='?'>loss_on_negatives</a> = util.weighted_surrogate_loss(
<span class='lineno'> 929</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.surrogate_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.surrogate_type', title='str'>surrogate_type</a>, positive_weights=0.0) / <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.maybe_log2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.maybe_log2', title='?'>maybe_log2</a>
<span class='lineno'> 930</span>   return tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.weights', title='?'>weights</a> *  <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.loss_on_negatives', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.global_objectives.loss_layers.false_positives_upper_bound.loss_on_negatives', title='?'>loss_on_negatives</a>, 0)
</pre></td></tr></table></body></html>