<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/qa_kg/model_n2nmn/netgen_att.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell', xid='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell'>_get_lstm_cell</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq', xid='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq'>AttentionSeq2Seq</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder', xid='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder'>_build_encoder</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder', xid='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder'>_build_decoder</a></li></ul>
</li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2017 The TensorFlow Authors All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> import tensorflow as tf
<span class='lineno'>  17</span> from util.nn import fc_layer as fc
<span class='lineno'>  18</span> 
<span class='lineno'>  19</span> 
<span class='lineno'>  20</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell', title='(?, ?) -> None'>_get_lstm_cell</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.num_layers', title='?'>num_layers</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.lstm_dim', title='?'>lstm_dim</a>):
<span class='lineno'>  21</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.cell_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.cell_list', title='[?]'>cell_list</a> = [
<span class='lineno'>  22</span>       tf.contrib.rnn.BasicLSTMCell(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.lstm_dim', title='?'>lstm_dim</a>, state_is_tuple=True)
<span class='lineno'>  23</span>       for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell._', title='int'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell._', title='int'>_</a></a> in range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.num_layers', title='?'>num_layers</a>)
<span class='lineno'>  24</span>   ]
<span class='lineno'>  25</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.cell', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.cell', title='?'>cell</a> = tf.contrib.rnn.MultiRNNCell(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.cell_list', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.cell_list', title='[?]'>cell_list</a>, state_is_tuple=True)
<span class='lineno'>  26</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.cell', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell.cell', title='?'>cell</a>
<span class='lineno'>  27</span> 
<span class='lineno'>  28</span> 
<span class='lineno'>  29</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq', title='<AttentionSeq2Seq>'>AttentionSeq2Seq</a>:
<span class='lineno'>  30</span> 
<span class='lineno'>  31</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>,
<span class='lineno'>  32</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', title='?'>config</a>,
<span class='lineno'>  33</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.text_seq_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.text_seq_batch', title='?'>text_seq_batch</a>,
<span class='lineno'>  34</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.seq_length_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.seq_length_batch', title='?'>seq_length_batch</a>,
<span class='lineno'>  35</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.num_vocab_txt', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.num_vocab_txt', title='?'>num_vocab_txt</a>,
<span class='lineno'>  36</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.num_vocab_nmn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.num_vocab_nmn', title='?'>num_vocab_nmn</a>,
<span class='lineno'>  37</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.EOS_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.EOS_token', title='?'>EOS_token</a>,
<span class='lineno'>  38</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.decoder_sampling', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.decoder_sampling', title='?'>decoder_sampling</a>,
<span class='lineno'>  39</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.embedding_mat', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.embedding_mat', title='?'>embedding_mat</a>,
<span class='lineno'>  40</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.use_gt_layout', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.use_gt_layout', title='None'>use_gt_layout</a>=None,
<span class='lineno'>  41</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.gt_layout_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.gt_layout_batch', title='None'>gt_layout_batch</a>=None,
<span class='lineno'>  42</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.scope', title='str'>scope</a>=&#39;encoder_decoder&#39;,
<span class='lineno'>  43</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.reuse', title='None'>reuse</a>=None):
<span class='lineno'>  44</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.T_decoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.T_decoder', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.T_decoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.T_decoder', title='?'>T_decoder</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', title='?'>config</a>.T_decoder
<span class='lineno'>  45</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_num_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_num_vocab', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_num_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_num_vocab', title='?'>encoder_num_vocab</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.num_vocab_txt', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.num_vocab_txt', title='?'>num_vocab_txt</a>
<span class='lineno'>  46</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_embed_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_embed_dim', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_embed_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_embed_dim', title='?'>encoder_embed_dim</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', title='?'>config</a>.embed_dim_txt
<span class='lineno'>  47</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', title='?'>decoder_num_vocab</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.num_vocab_nmn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.num_vocab_nmn', title='?'>num_vocab_nmn</a>
<span class='lineno'>  48</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_embed_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_embed_dim', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_embed_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_embed_dim', title='?'>decoder_embed_dim</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', title='?'>config</a>.embed_dim_nmn
<span class='lineno'>  49</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.lstm_dim', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.lstm_dim', title='?'>lstm_dim</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', title='?'>config</a>.lstm_dim
<span class='lineno'>  50</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.num_layers', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.num_layers', title='?'>num_layers</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.config', title='?'>config</a>.num_layers
<span class='lineno'>  51</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.EOS_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.EOS_token', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.EOS_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.EOS_token', title='?'>EOS_token</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.EOS_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.EOS_token', title='?'>EOS_token</a>
<span class='lineno'>  52</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_sampling', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_sampling', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_sampling', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_sampling', title='?'>decoder_sampling</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.decoder_sampling', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.decoder_sampling', title='?'>decoder_sampling</a>
<span class='lineno'>  53</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.embedding_mat', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.embedding_mat', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.embedding_mat', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.embedding_mat', title='?'>embedding_mat</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.embedding_mat', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.embedding_mat', title='?'>embedding_mat</a>
<span class='lineno'>  54</span> 
<span class='lineno'>  55</span>     with tf.variable_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.scope', title='str'>scope</a>, reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.reuse', title='None'>reuse</a>):
<span class='lineno'>  56</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder', title='(AttentionSeq2Seq, ?, ?, str, None) -> None'>_build_encoder</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.text_seq_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.text_seq_batch', title='?'>text_seq_batch</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.seq_length_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.seq_length_batch', title='?'>seq_length_batch</a>)
<span class='lineno'>  57</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder', title='(AttentionSeq2Seq, ?, ?, str, None) -> None / (AttentionSeq2Seq, None, None, str, None) -> None'>_build_decoder</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.use_gt_layout', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.use_gt_layout', title='None'>use_gt_layout</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.gt_layout_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.__init__.gt_layout_batch', title='None'>gt_layout_batch</a>)
<span class='lineno'>  58</span> 
<span class='lineno'>  59</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder', title='(AttentionSeq2Seq, ?, ?, str, None) -> None'>_build_encoder</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', title='AttentionSeq2Seq'>self</a>,
<span class='lineno'>  60</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.text_seq_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.text_seq_batch', title='?'>text_seq_batch</a>,
<span class='lineno'>  61</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_length_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_length_batch', title='?'>seq_length_batch</a>,
<span class='lineno'>  62</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.scope', title='str'>scope</a>=&#39;encoder&#39;,
<span class='lineno'>  63</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.reuse', title='None'>reuse</a>=None):
<span class='lineno'>  64</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.lstm_dim', title='?'>lstm_dim</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.lstm_dim', title='?'>lstm_dim</a>
<span class='lineno'>  65</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.num_layers', title='?'>num_layers</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.num_layers', title='?'>num_layers</a>
<span class='lineno'>  66</span> 
<span class='lineno'>  67</span>     with tf.variable_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.scope', title='str'>scope</a>, reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.reuse', title='None'>reuse</a>):
<span class='lineno'>  68</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.T', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.T', title='?'>T</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.text_seq_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.text_seq_batch', title='?'>text_seq_batch</a>)[0]
<span class='lineno'>  69</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.N', title='?'>N</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.text_seq_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.text_seq_batch', title='?'>text_seq_batch</a>)[1]
<span class='lineno'>  70</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', title='AttentionSeq2Seq'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.T_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.T_encoder', title='?'>T_encoder</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.T', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.T', title='?'>T</a>
<span class='lineno'>  71</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', title='AttentionSeq2Seq'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.N', title='?'>N</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.N', title='?'>N</a>
<span class='lineno'>  72</span> 
<span class='lineno'>  73</span>       # text_seq has shape [T, N] and embedded_seq has shape [T, N, D]
<span class='lineno'>  74</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.embedded_seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.embedded_seq', title='?'>embedded_seq</a> = tf.nn.embedding_lookup(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.embedding_mat', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.embedding_mat', title='?'>embedding_mat</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.text_seq_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.text_seq_batch', title='?'>text_seq_batch</a>)
<span class='lineno'>  75</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', title='AttentionSeq2Seq'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.embedded_input_seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.embedded_input_seq', title='?'>embedded_input_seq</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.embedded_seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.embedded_seq', title='?'>embedded_seq</a>
<span class='lineno'>  76</span> 
<span class='lineno'>  77</span>       # The RNN
<span class='lineno'>  78</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.cell', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.cell', title='None'>cell</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell', title='(?, ?) -> None'>_get_lstm_cell</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.num_layers', title='?'>num_layers</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.lstm_dim', title='?'>lstm_dim</a>)
<span class='lineno'>  79</span> 
<span class='lineno'>  80</span>       # encoder_outputs has shape [T, N, lstm_dim]
<span class='lineno'>  81</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_outputs', title='?'>encoder_outputs</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_states', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_states', title='?'>encoder_states</a> = tf.nn.dynamic_rnn(
<span class='lineno'>  82</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.cell', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.cell', title='None'>cell</a>,
<span class='lineno'>  83</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.embedded_seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.embedded_seq', title='?'>embedded_seq</a>,
<span class='lineno'>  84</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_length_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_length_batch', title='?'>seq_length_batch</a>,
<span class='lineno'>  85</span>           dtype=tf.float32,
<span class='lineno'>  86</span>           time_major=True,
<span class='lineno'>  87</span>           scope=&#39;lstm&#39;)
<span class='lineno'>  88</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', title='AttentionSeq2Seq'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_outputs', title='?'>encoder_outputs</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_outputs', title='?'>encoder_outputs</a>
<span class='lineno'>  89</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', title='AttentionSeq2Seq'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_states', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_states', title='?'>encoder_states</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_states', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_states', title='?'>encoder_states</a>
<span class='lineno'>  90</span> 
<span class='lineno'>  91</span>       # transform the encoder outputs for further attention alignments
<span class='lineno'>  92</span>       # encoder_outputs_flat has shape [T, N, lstm_dim]
<span class='lineno'>  93</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_h_transformed', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_h_transformed', title='?'>encoder_h_transformed</a> = fc(
<span class='lineno'>  94</span>           &#39;encoder_h_transform&#39;,
<span class='lineno'>  95</span>           tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_outputs', title='?'>encoder_outputs</a>, [-1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.lstm_dim', title='?'>lstm_dim</a>]),
<span class='lineno'>  96</span>           output_dim=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.lstm_dim', title='?'>lstm_dim</a>)
<span class='lineno'>  97</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_h_transformed', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_h_transformed', title='?'>encoder_h_transformed</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_h_transformed', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_h_transformed', title='?'>encoder_h_transformed</a>,
<span class='lineno'>  98</span>                                          [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.T', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.T', title='?'>T</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.N', title='?'>N</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.lstm_dim', title='?'>lstm_dim</a>])
<span class='lineno'>  99</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', title='AttentionSeq2Seq'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_h_transformed', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_h_transformed', title='?'>encoder_h_transformed</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_h_transformed', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.encoder_h_transformed', title='?'>encoder_h_transformed</a>
<span class='lineno'> 100</span> 
<span class='lineno'> 101</span>       # seq_not_finished is a shape [T, N, 1] tensor,
<span class='lineno'> 102</span>       # where seq_not_finished[t, n]
<span class='lineno'> 103</span>       # is 1 iff sequence n is not finished at time t, and 0 otherwise
<span class='lineno'> 104</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_not_finished', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_not_finished', title='?'>seq_not_finished</a> = tf.less(
<span class='lineno'> 105</span>           tf.range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.T', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.T', title='?'>T</a>)[:, tf.newaxis, tf.newaxis],
<span class='lineno'> 106</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_length_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_length_batch', title='?'>seq_length_batch</a>[:, tf.newaxis])
<span class='lineno'> 107</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_not_finished', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_not_finished', title='?'>seq_not_finished</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_not_finished', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_not_finished', title='?'>seq_not_finished</a>, tf.float32)
<span class='lineno'> 108</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.self', title='AttentionSeq2Seq'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.seq_not_finished', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.seq_not_finished', title='?'>seq_not_finished</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_not_finished', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_encoder.seq_not_finished', title='?'>seq_not_finished</a>
<span class='lineno'> 109</span> 
<span class='lineno'> 110</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder', title='(AttentionSeq2Seq, ?, ?, str, None) -> None / (AttentionSeq2Seq, None, None, str, None) -> None'>_build_decoder</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>,
<span class='lineno'> 111</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.use_gt_layout', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.use_gt_layout', title='None'>use_gt_layout</a>,
<span class='lineno'> 112</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.gt_layout_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.gt_layout_batch', title='None'>gt_layout_batch</a>,
<span class='lineno'> 113</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.scope', title='str'>scope</a>=&#39;decoder&#39;,
<span class='lineno'> 114</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.reuse', title='None'>reuse</a>=None):
<span class='lineno'> 115</span>     # The main difference from before is that the decoders now takes another
<span class='lineno'> 116</span>     # input (the attention) when computing the next step
<span class='lineno'> 117</span>     # T_max is the maximum length of decoded sequence (including &lt;eos&gt;)
<span class='lineno'> 118</span>     #
<span class='lineno'> 119</span>     # This function is for decoding only. It performs greedy search or sampling.
<span class='lineno'> 120</span>     # the first input is &lt;go&gt; (its embedding vector) and the subsequent inputs
<span class='lineno'> 121</span>     # are the outputs from previous time step
<span class='lineno'> 122</span>     # num_vocab does not include &lt;go&gt;
<span class='lineno'> 123</span>     #
<span class='lineno'> 124</span>     # use_gt_layout is None or a bool tensor, and gt_layout_batch is a tensor
<span class='lineno'> 125</span>     # with shape [T_max, N].
<span class='lineno'> 126</span>     # If use_gt_layout is not None, then when use_gt_layout is true, predict
<span class='lineno'> 127</span>     # exactly the tokens in gt_layout_batch, regardless of actual probability.
<span class='lineno'> 128</span>     # Otherwise, if sampling is True, sample from the token probability
<span class='lineno'> 129</span>     # If sampling is False, do greedy decoding (beam size 1)
<span class='lineno'> 130</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', title='?'>N</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.N', title='?'>N</a>
<span class='lineno'> 131</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.encoder_states', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.encoder_states', title='?'>encoder_states</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_states', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_states', title='?'>encoder_states</a>
<span class='lineno'> 132</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.T_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.T_max', title='?'>T_max</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.T_decoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.T_decoder', title='?'>T_decoder</a>
<span class='lineno'> 133</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', title='?'>lstm_dim</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.lstm_dim', title='?'>lstm_dim</a>
<span class='lineno'> 134</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.num_layers', title='?'>num_layers</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.num_layers', title='?'>num_layers</a>
<span class='lineno'> 135</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.EOS_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.EOS_token', title='?'>EOS_token</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.EOS_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.EOS_token', title='?'>EOS_token</a>
<span class='lineno'> 136</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.sampling', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.sampling', title='?'>sampling</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_sampling', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_sampling', title='?'>decoder_sampling</a>
<span class='lineno'> 137</span> 
<span class='lineno'> 138</span>     with tf.variable_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.scope', title='str'>scope</a>, reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.reuse', title='None'>reuse</a>):
<span class='lineno'> 139</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.embedding_mat', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.embedding_mat', title='?'>embedding_mat</a> = tf.get_variable(
<span class='lineno'> 140</span>           &#39;embedding_mat&#39;, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', title='?'>decoder_num_vocab</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_embed_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_embed_dim', title='?'>decoder_embed_dim</a>])
<span class='lineno'> 141</span>       # we use a separate embedding for &lt;go&gt;, as it is only used in the
<span class='lineno'> 142</span>       # beginning of the sequence
<span class='lineno'> 143</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.go_embedding', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.go_embedding', title='?'>go_embedding</a> = tf.get_variable(&#39;go_embedding&#39;,
<span class='lineno'> 144</span>                                      [1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_embed_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_embed_dim', title='?'>decoder_embed_dim</a>])
<span class='lineno'> 145</span> 
<span class='lineno'> 146</span>       with tf.variable_scope(&#39;att_prediction&#39;):
<span class='lineno'> 147</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.v', title='?'>v</a> = tf.get_variable(&#39;v&#39;, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', title='?'>lstm_dim</a>])
<span class='lineno'> 148</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.W_a', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.W_a', title='?'>W_a</a> = tf.get_variable(
<span class='lineno'> 149</span>             &#39;weights&#39;, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', title='?'>lstm_dim</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', title='?'>lstm_dim</a>],
<span class='lineno'> 150</span>             initializer=tf.contrib.layers.xavier_initializer())
<span class='lineno'> 151</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.b_a', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.b_a', title='?'>b_a</a> = tf.get_variable(
<span class='lineno'> 152</span>             &#39;biases&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', title='?'>lstm_dim</a>, initializer=tf.constant_initializer(0.))
<span class='lineno'> 153</span> 
<span class='lineno'> 154</span>       # The parameters to predict the next token
<span class='lineno'> 155</span>       with tf.variable_scope(&#39;token_prediction&#39;):
<span class='lineno'> 156</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.W_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.W_y', title='?'>W_y</a> = tf.get_variable(
<span class='lineno'> 157</span>             &#39;weights&#39;, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', title='?'>lstm_dim</a> * 2, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', title='?'>decoder_num_vocab</a>],
<span class='lineno'> 158</span>             initializer=tf.contrib.layers.xavier_initializer())
<span class='lineno'> 159</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.b_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.b_y', title='?'>b_y</a> = tf.get_variable(
<span class='lineno'> 160</span>             &#39;biases&#39;,
<span class='lineno'> 161</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', title='?'>decoder_num_vocab</a>,
<span class='lineno'> 162</span>             initializer=tf.constant_initializer(0.))
<span class='lineno'> 163</span> 
<span class='lineno'> 164</span>       # Attentional decoding
<span class='lineno'> 165</span>       # Loop function is called at time t BEFORE the cell execution at time t,
<span class='lineno'> 166</span>       # and its next_input is used as the input at time t (not t+1)
<span class='lineno'> 167</span>       # c.f. https://www.tensorflow.org/api_docs/python/tf/nn/raw_rnn
<span class='lineno'> 168</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.mask_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.mask_range', title='?'>mask_range</a> = tf.reshape(
<span class='lineno'> 169</span>           tf.range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.decoder_num_vocab', title='?'>decoder_num_vocab</a>, dtype=tf.int32), [1, -1])
<span class='lineno'> 170</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_eos_pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_eos_pred', title='?'>all_eos_pred</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.EOS_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.EOS_token', title='?'>EOS_token</a> * tf.ones([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', title='?'>N</a>], tf.int32)
<span class='lineno'> 171</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_one_prob', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_one_prob', title='?'>all_one_prob</a> = tf.ones([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', title='?'>N</a>], tf.float32)
<span class='lineno'> 172</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_zero_entropy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_zero_entropy', title='?'>all_zero_entropy</a> = tf.zeros([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', title='?'>N</a>], tf.float32)
<span class='lineno'> 173</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.use_gt_layout', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.use_gt_layout', title='None'>use_gt_layout</a> is not None:
<span class='lineno'> 174</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.gt_layout_mult', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.gt_layout_mult', title='?'>gt_layout_mult</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.use_gt_layout', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.use_gt_layout', title='None'>use_gt_layout</a>, tf.int32)
<span class='lineno'> 175</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.pred_layout_mult', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.pred_layout_mult', title='int'>pred_layout_mult</a> = 1 - <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.gt_layout_mult', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.gt_layout_mult', title='?'>gt_layout_mult</a>
<span class='lineno'> 176</span> 
<span class='lineno'> 177</span>       def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn', title='(?, ?, ?, ?) -> (?, ?, ?, ?, (?, ?, ?, ?, ?))'>loop_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.time', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.time', title='?'>time</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_output', title='?'>cell_output</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_state', title='?'>cell_state</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', title='?'>loop_state</a>):
<span class='lineno'> 178</span>         if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_output', title='?'>cell_output</a> is None:  # time == 0
<span class='lineno'> 179</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_cell_state', title='?'>next_cell_state</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.encoder_states', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.encoder_states', title='?'>encoder_states</a>
<span class='lineno'> 180</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_input', title='?'>next_input</a> = tf.tile(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.go_embedding', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.go_embedding', title='?'>go_embedding</a>, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', title='?'>N</a>, 1])
<span class='lineno'> 181</span>         else:  # time &gt; 0
<span class='lineno'> 182</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_cell_state', title='?'>next_cell_state</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_state', title='?'>cell_state</a>
<span class='lineno'> 183</span> 
<span class='lineno'> 184</span>           # compute the attention map over the input sequence
<span class='lineno'> 185</span>           # a_raw has shape [T, N, 1]
<span class='lineno'> 186</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att_raw', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att_raw', title='?'>att_raw</a> = tf.reduce_sum(
<span class='lineno'> 187</span>               tf.tanh(
<span class='lineno'> 188</span>                   tf.nn.xw_plus_b(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_output', title='?'>cell_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.W_a', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.W_a', title='?'>W_a</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.b_a', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.b_a', title='?'>b_a</a>) +
<span class='lineno'> 189</span>                   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_h_transformed', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_h_transformed', title='?'>encoder_h_transformed</a>) * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.v', title='?'>v</a>,
<span class='lineno'> 190</span>               axis=2,
<span class='lineno'> 191</span>               keep_dims=True)
<span class='lineno'> 192</span>           # softmax along the first dimension (T) over not finished examples
<span class='lineno'> 193</span>           # att has shape [T, N, 1]
<span class='lineno'> 194</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', title='?'>att</a> = tf.nn.softmax(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att_raw', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att_raw', title='?'>att_raw</a>, dim=0) * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.seq_not_finished', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.seq_not_finished', title='?'>seq_not_finished</a>
<span class='lineno'> 195</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', title='?'>att</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', title='?'>att</a> / tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', title='?'>att</a>, axis=0, keep_dims=True)
<span class='lineno'> 196</span>           # d has shape [N, lstm_dim]
<span class='lineno'> 197</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.d2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.d2', title='?'>d2</a> = tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', title='?'>att</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_outputs', title='?'>encoder_outputs</a>, axis=0)
<span class='lineno'> 198</span> 
<span class='lineno'> 199</span>           # token_scores has shape [N, num_vocab]
<span class='lineno'> 200</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_scores', title='?'>token_scores</a> = tf.nn.xw_plus_b(
<span class='lineno'> 201</span>               tf.concat([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_output', title='?'>cell_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.d2', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.d2', title='?'>d2</a>], axis=1), <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.W_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.W_y', title='?'>W_y</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.b_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.b_y', title='?'>b_y</a>)
<span class='lineno'> 202</span>           # predict the next token (behavior depending on parameters)
<span class='lineno'> 203</span>           if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.sampling', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.sampling', title='?'>sampling</a>:
<span class='lineno'> 204</span>             # predicted_token has shape [N]
<span class='lineno'> 205</span>             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.logits', title='?'>logits</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_scores', title='?'>token_scores</a>
<span class='lineno'> 206</span>             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', title='?'>predicted_token</a> = tf.cast(
<span class='lineno'> 207</span>                 tf.reshape(tf.multinomial(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_scores', title='?'>token_scores</a>, 1), [-1]), tf.int32)
<span class='lineno'> 208</span>           else:
<span class='lineno'> 209</span>             # predicted_token has shape [N]
<span class='lineno'> 210</span>             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', title='?'>predicted_token</a> = tf.cast(tf.argmax(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_scores', title='?'>token_scores</a>, 1), tf.int32)
<span class='lineno'> 211</span>           if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.use_gt_layout', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.use_gt_layout', title='None'>use_gt_layout</a> is not None:
<span class='lineno'> 212</span>             <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', title='int'>predicted_token</a> = (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.gt_layout_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.gt_layout_batch', title='None'>gt_layout_batch</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.time', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.time', title='?'>time</a> - 1] * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.gt_layout_mult', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.gt_layout_mult', title='?'>gt_layout_mult</a> +
<span class='lineno'> 213</span>                                <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', title='?'>predicted_token</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.pred_layout_mult', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.pred_layout_mult', title='int'>pred_layout_mult</a>)
<span class='lineno'> 214</span> 
<span class='lineno'> 215</span>           # token_prob has shape [N], the probability of the predicted token
<span class='lineno'> 216</span>           # although token_prob is not needed for predicting the next token
<span class='lineno'> 217</span>           # it is needed in output (for policy gradient training)
<span class='lineno'> 218</span>           # [N, num_vocab]
<span class='lineno'> 219</span>           # mask has shape [N, num_vocab]
<span class='lineno'> 220</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.mask', title='?'>mask</a> = tf.equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.mask_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.mask_range', title='?'>mask_range</a>, tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', title='int'>predicted_token</a>, [-1, 1]))
<span class='lineno'> 221</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.all_token_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.all_token_probs', title='?'>all_token_probs</a> = tf.nn.softmax(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_scores', title='?'>token_scores</a>)
<span class='lineno'> 222</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob', title='?'>token_prob</a> = tf.reduce_sum(
<span class='lineno'> 223</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.all_token_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.all_token_probs', title='?'>all_token_probs</a> * tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.mask', title='?'>mask</a>, tf.float32), axis=1)
<span class='lineno'> 224</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.neg_entropy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.neg_entropy', title='?'>neg_entropy</a> = tf.reduce_sum(
<span class='lineno'> 225</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.all_token_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.all_token_probs', title='?'>all_token_probs</a> * tf.log(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.all_token_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.all_token_probs', title='?'>all_token_probs</a>), axis=1)
<span class='lineno'> 226</span> 
<span class='lineno'> 227</span>           # is_eos_predicted is a [N] bool tensor, indicating whether
<span class='lineno'> 228</span>           # &lt;eos&gt; has already been predicted previously in each sequence
<span class='lineno'> 229</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', title='?'>is_eos_predicted</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', title='?'>loop_state</a>[2]
<span class='lineno'> 230</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token_old', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token_old', title='int'>predicted_token_old</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', title='int'>predicted_token</a>
<span class='lineno'> 231</span>           # if &lt;eos&gt; has already been predicted, now predict &lt;eos&gt; with
<span class='lineno'> 232</span>           # prob 1
<span class='lineno'> 233</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', title='?'>predicted_token</a> = tf.where(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', title='?'>is_eos_predicted</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_eos_pred', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_eos_pred', title='?'>all_eos_pred</a>,
<span class='lineno'> 234</span>                                      <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', title='int'>predicted_token</a>)
<span class='lineno'> 235</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob', title='?'>token_prob</a> = tf.where(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', title='?'>is_eos_predicted</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_one_prob', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_one_prob', title='?'>all_one_prob</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob', title='?'>token_prob</a>)
<span class='lineno'> 236</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.neg_entropy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.neg_entropy', title='?'>neg_entropy</a> = tf.where(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', title='?'>is_eos_predicted</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_zero_entropy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.all_zero_entropy', title='?'>all_zero_entropy</a>,
<span class='lineno'> 237</span>                                  <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.neg_entropy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.neg_entropy', title='?'>neg_entropy</a>)
<span class='lineno'> 238</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', title='?'>is_eos_predicted</a> = tf.logical_or(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', title='?'>is_eos_predicted</a>,
<span class='lineno'> 239</span>                                            tf.equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token_old', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token_old', title='int'>predicted_token_old</a>,
<span class='lineno'> 240</span>                                                     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.EOS_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.EOS_token', title='?'>EOS_token</a>))
<span class='lineno'> 241</span> 
<span class='lineno'> 242</span>           # the prediction is from the cell output of the last step
<span class='lineno'> 243</span>           # timestep (t-1), feed it as input into timestep t
<span class='lineno'> 244</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_input', title='?'>next_input</a> = tf.nn.embedding_lookup(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.embedding_mat', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.embedding_mat', title='?'>embedding_mat</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', title='?'>predicted_token</a>)
<span class='lineno'> 245</span> 
<span class='lineno'> 246</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.elements_finished', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.elements_finished', title='?'>elements_finished</a> = tf.greater_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.time', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.time', title='?'>time</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.T_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.T_max', title='?'>T_max</a>)
<span class='lineno'> 247</span> 
<span class='lineno'> 248</span>         # loop_state is a 5-tuple, representing
<span class='lineno'> 249</span>         #   1) the predicted_tokens
<span class='lineno'> 250</span>         #   2) the prob of predicted_tokens
<span class='lineno'> 251</span>         #   3) whether &lt;eos&gt; has already been predicted
<span class='lineno'> 252</span>         #   4) the negative entropy of policy (accumulated across timesteps)
<span class='lineno'> 253</span>         #   5) the attention
<span class='lineno'> 254</span>         if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', title='?'>loop_state</a> is None:  # time == 0
<span class='lineno'> 255</span>           # Write the predicted token into the output
<span class='lineno'> 256</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token_array', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token_array', title='?'>predicted_token_array</a> = tf.TensorArray(
<span class='lineno'> 257</span>               dtype=tf.int32, size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.T_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.T_max', title='?'>T_max</a>, infer_shape=False)
<span class='lineno'> 258</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob_array', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob_array', title='?'>token_prob_array</a> = tf.TensorArray(
<span class='lineno'> 259</span>               dtype=tf.float32, size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.T_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.T_max', title='?'>T_max</a>, infer_shape=False)
<span class='lineno'> 260</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att_array', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att_array', title='?'>att_array</a> = tf.TensorArray(
<span class='lineno'> 261</span>               dtype=tf.float32, size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.T_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.T_max', title='?'>T_max</a>, infer_shape=False)
<span class='lineno'> 262</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_loop_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_loop_state', title='(?, ?, ?, ?, ?)'>next_loop_state</a> = (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token_array', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token_array', title='?'>predicted_token_array</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob_array', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob_array', title='?'>token_prob_array</a>, tf.zeros(
<span class='lineno'> 263</span>               [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', title='?'>N</a>], dtype=tf.bool), tf.zeros([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.N', title='?'>N</a>], dtype=tf.float32), <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att_array', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att_array', title='?'>att_array</a>)
<span class='lineno'> 264</span>         else:  # time &gt; 0
<span class='lineno'> 265</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.t_write', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.t_write', title='int'>t_write</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.time', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.time', title='?'>time</a> - 1
<span class='lineno'> 266</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_loop_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_loop_state', title='(?, ?, ?, ?, ?)'>next_loop_state</a> = (
<span class='lineno'> 267</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', title='?'>loop_state</a>[0].write(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.t_write', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.t_write', title='int'>t_write</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.predicted_token', title='?'>predicted_token</a>),
<span class='lineno'> 268</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', title='?'>loop_state</a>[1].write(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.t_write', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.t_write', title='int'>t_write</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.token_prob', title='?'>token_prob</a>),
<span class='lineno'> 269</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.is_eos_predicted', title='?'>is_eos_predicted</a>,
<span class='lineno'> 270</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', title='?'>loop_state</a>[3] + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.neg_entropy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.neg_entropy', title='?'>neg_entropy</a>,
<span class='lineno'> 271</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.loop_state', title='?'>loop_state</a>[4].write(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.t_write', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.t_write', title='int'>t_write</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.att', title='?'>att</a>))
<span class='lineno'> 272</span>         return (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.elements_finished', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.elements_finished', title='?'>elements_finished</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_input', title='?'>next_input</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_cell_state', title='?'>next_cell_state</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.cell_output', title='?'>cell_output</a>,
<span class='lineno'> 273</span>                 <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_loop_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn.next_loop_state', title='(?, ?, ?, ?, ?)'>next_loop_state</a>)
<span class='lineno'> 274</span> 
<span class='lineno'> 275</span>       # The RNN
<span class='lineno'> 276</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.cell', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.cell', title='None'>cell</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att._get_lstm_cell', title='(?, ?) -> None'>_get_lstm_cell</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.num_layers', title='?'>num_layers</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.lstm_dim', title='?'>lstm_dim</a>)
<span class='lineno'> 277</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder._', title='?'>_</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder._', title='?'>_</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.decodes_ta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.decodes_ta', title='?'>decodes_ta</a> = tf.nn.raw_rnn(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.cell', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.cell', title='None'>cell</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.loop_fn', title='(?, ?, ?, ?) -> (?, ?, ?, ?, (?, ?, ?, ?, ?))'>loop_fn</a>, scope=&#39;lstm&#39;)
<span class='lineno'> 278</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.predicted_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.predicted_tokens', title='?'>predicted_tokens</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.decodes_ta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.decodes_ta', title='?'>decodes_ta</a>[0].stack()
<span class='lineno'> 279</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.token_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.token_probs', title='?'>token_probs</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.decodes_ta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.decodes_ta', title='?'>decodes_ta</a>[1].stack()
<span class='lineno'> 280</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.neg_entropy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.neg_entropy', title='?'>neg_entropy</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.decodes_ta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.decodes_ta', title='?'>decodes_ta</a>[3]
<span class='lineno'> 281</span>       # atts has shape [T_decoder, T_encoder, N, 1]
<span class='lineno'> 282</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.atts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.atts', title='?'>atts</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.decodes_ta', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.decodes_ta', title='?'>decodes_ta</a>[4].stack()
<span class='lineno'> 283</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.atts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.atts', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.atts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.atts', title='?'>atts</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.atts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.atts', title='?'>atts</a>
<span class='lineno'> 284</span>       # word_vec has shape [T_decoder, N, D]
<span class='lineno'> 285</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.word_vecs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.word_vecs', title='?'>word_vecs</a> = tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.atts', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.atts', title='?'>atts</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.embedded_input_seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.embedded_input_seq', title='?'>embedded_input_seq</a>, axis=1)
<span class='lineno'> 286</span> 
<span class='lineno'> 287</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.predicted_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.predicted_tokens', title='?'>predicted_tokens</a>.set_shape([None, None])
<span class='lineno'> 288</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.token_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.token_probs', title='?'>token_probs</a>.set_shape([None, None])
<span class='lineno'> 289</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.neg_entropy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.neg_entropy', title='?'>neg_entropy</a>.set_shape([None])
<span class='lineno'> 290</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.word_vecs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.word_vecs', title='?'>word_vecs</a>.set_shape([None, None, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_embed_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.encoder_embed_dim', title='?'>encoder_embed_dim</a>])
<span class='lineno'> 291</span> 
<span class='lineno'> 292</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.predicted_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.predicted_tokens', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.predicted_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.predicted_tokens', title='?'>predicted_tokens</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.predicted_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.predicted_tokens', title='?'>predicted_tokens</a>
<span class='lineno'> 293</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.token_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.token_probs', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.token_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.token_probs', title='?'>token_probs</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.token_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.token_probs', title='?'>token_probs</a>
<span class='lineno'> 294</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.neg_entropy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.neg_entropy', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.neg_entropy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.neg_entropy', title='?'>neg_entropy</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.neg_entropy', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.neg_entropy', title='?'>neg_entropy</a>
<span class='lineno'> 295</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.self', title='AttentionSeq2Seq'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.word_vecs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.word_vecs', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.word_vecs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq.word_vecs', title='?'>word_vecs</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.word_vecs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.qa_kg.model_n2nmn.netgen_att.AttentionSeq2Seq._build_decoder.word_vecs', title='?'>word_vecs</a>
</pre></td></tr></table></body></html>