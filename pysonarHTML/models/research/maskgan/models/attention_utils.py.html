<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/maskgan/models/attention_utils.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.__all__', xid='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.__all__'>__all__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train', xid='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train'>attention_decoder_fn_train</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference', xid='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference'>attention_decoder_fn_inference</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention', xid='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention'>prepare_attention</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention', xid='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention'>_init_attention</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn', xid='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn'>_create_attention_construct_fn</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun', xid='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun'>_attn_add_fun</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun', xid='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun'>_attn_mul_fun</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn', xid='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn'>_create_attention_score_fn</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2017 The TensorFlow Authors All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> &quot;&quot;&quot;Attention-based decoder functions.&quot;&quot;&quot;
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> from __future__ import absolute_import
<span class='lineno'>  19</span> from __future__ import division
<span class='lineno'>  20</span> from __future__ import print_function
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> import tensorflow as tf
<span class='lineno'>  23</span> from tensorflow.python.framework import function
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.__all__', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.__all__', title='[str]'>__all__</a> = [
<span class='lineno'>  26</span>     &quot;prepare_attention&quot;, &quot;attention_decoder_fn_train&quot;,
<span class='lineno'>  27</span>     &quot;attention_decoder_fn_inference&quot;
<span class='lineno'>  28</span> ]
<span class='lineno'>  29</span> 
<span class='lineno'>  30</span> 
<span class='lineno'>  31</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train', title='(?, ?, ?, ?, ?, None) -> (?, ?, ?, ?, ?) -> (None, ?, ?, ?, ?)'>attention_decoder_fn_train</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.encoder_state', title='?'>encoder_state</a>,
<span class='lineno'>  32</span>                                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_keys', title='?'>attention_keys</a>,
<span class='lineno'>  33</span>                                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_values', title='?'>attention_values</a>,
<span class='lineno'>  34</span>                                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_score_fn', title='?'>attention_score_fn</a>,
<span class='lineno'>  35</span>                                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_construct_fn', title='?'>attention_construct_fn</a>,
<span class='lineno'>  36</span>                                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.name', title='None'>name</a>=None):
<span class='lineno'>  37</span>   &quot;&quot;&quot;Attentional decoder function for `dynamic_rnn_decoder` during training.
<span class='lineno'>  38</span> 
<span class='lineno'>  39</span>   The `attention_decoder_fn_train` is a training function for an
<span class='lineno'>  40</span>   attention-based sequence-to-sequence model. It should be used when
<span class='lineno'>  41</span>   `dynamic_rnn_decoder` is in the training mode.
<span class='lineno'>  42</span> 
<span class='lineno'>  43</span>   The `attention_decoder_fn_train` is called with a set of the user arguments
<span class='lineno'>  44</span>   and returns the `decoder_fn`, which can be passed to the
<span class='lineno'>  45</span>   `dynamic_rnn_decoder`, such that
<span class='lineno'>  46</span> 
<span class='lineno'>  47</span>   ```
<span class='lineno'>  48</span>   dynamic_fn_train = attention_decoder_fn_train(encoder_state)
<span class='lineno'>  49</span>   outputs_train, state_train = dynamic_rnn_decoder(
<span class='lineno'>  50</span>       decoder_fn=dynamic_fn_train, ...)
<span class='lineno'>  51</span>   ```
<span class='lineno'>  52</span> 
<span class='lineno'>  53</span>   Further usage can be found in the `kernel_tests/seq2seq_test.py`.
<span class='lineno'>  54</span> 
<span class='lineno'>  55</span>   Args:
<span class='lineno'>  56</span>     encoder_state: The encoded state to initialize the `dynamic_rnn_decoder`.
<span class='lineno'>  57</span>     attention_keys: to be compared with target states.
<span class='lineno'>  58</span>     attention_values: to be used to construct context vectors.
<span class='lineno'>  59</span>     attention_score_fn: to compute similarity between key and target states.
<span class='lineno'>  60</span>     attention_construct_fn: to build attention states.
<span class='lineno'>  61</span>     name: (default: `None`) NameScope for the decoder function;
<span class='lineno'>  62</span>       defaults to &quot;simple_decoder_fn_train&quot;
<span class='lineno'>  63</span> 
<span class='lineno'>  64</span>   Returns:
<span class='lineno'>  65</span>     A decoder function with the required interface of `dynamic_rnn_decoder`
<span class='lineno'>  66</span>     intended for training.
<span class='lineno'>  67</span>   &quot;&quot;&quot;
<span class='lineno'>  68</span>   with tf.name_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.name', title='None'>name</a>, &quot;attention_decoder_fn_train&quot;, [
<span class='lineno'>  69</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.encoder_state', title='?'>encoder_state</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_keys', title='?'>attention_keys</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_values', title='?'>attention_values</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_score_fn', title='?'>attention_score_fn</a>,
<span class='lineno'>  70</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_construct_fn', title='?'>attention_construct_fn</a>
<span class='lineno'>  71</span>   ]):
<span class='lineno'>  72</span>     pass
<span class='lineno'>  73</span> 
<span class='lineno'>  74</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn', title='(?, ?, ?, ?, ?) -> (None, ?, ?, ?, ?)'>decoder_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.time', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.time', title='?'>time</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_state', title='?'>cell_state</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_input', title='?'>cell_input</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_output', title='?'>cell_output</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.context_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.context_state', title='?'>context_state</a>):
<span class='lineno'>  75</span>     &quot;&quot;&quot;Decoder function used in the `dynamic_rnn_decoder` for training.
<span class='lineno'>  76</span> 
<span class='lineno'>  77</span>     Args:
<span class='lineno'>  78</span>       time: positive integer constant reflecting the current timestep.
<span class='lineno'>  79</span>       cell_state: state of RNNCell.
<span class='lineno'>  80</span>       cell_input: input provided by `dynamic_rnn_decoder`.
<span class='lineno'>  81</span>       cell_output: output of RNNCell.
<span class='lineno'>  82</span>       context_state: context state provided by `dynamic_rnn_decoder`.
<span class='lineno'>  83</span> 
<span class='lineno'>  84</span>     Returns:
<span class='lineno'>  85</span>       A tuple (done, next state, next input, emit output, next context state)
<span class='lineno'>  86</span>       where:
<span class='lineno'>  87</span> 
<span class='lineno'>  88</span>       done: `None`, which is used by the `dynamic_rnn_decoder` to indicate
<span class='lineno'>  89</span>       that `sequence_lengths` in `dynamic_rnn_decoder` should be used.
<span class='lineno'>  90</span> 
<span class='lineno'>  91</span>       next state: `cell_state`, this decoder function does not modify the
<span class='lineno'>  92</span>       given state.
<span class='lineno'>  93</span> 
<span class='lineno'>  94</span>       next input: `cell_input`, this decoder function does not modify the
<span class='lineno'>  95</span>       given input. The input could be modified when applying e.g. attention.
<span class='lineno'>  96</span> 
<span class='lineno'>  97</span>       emit output: `cell_output`, this decoder function does not modify the
<span class='lineno'>  98</span>       given output.
<span class='lineno'>  99</span> 
<span class='lineno'> 100</span>       next context state: `context_state`, this decoder function does not
<span class='lineno'> 101</span>       modify the given context state. The context state could be modified when
<span class='lineno'> 102</span>       applying e.g. beam search.
<span class='lineno'> 103</span>     &quot;&quot;&quot;
<span class='lineno'> 104</span>     with tf.name_scope(
<span class='lineno'> 105</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.name', title='None'>name</a>, &quot;attention_decoder_fn_train&quot;,
<span class='lineno'> 106</span>         [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.time', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.time', title='?'>time</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_state', title='?'>cell_state</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_input', title='?'>cell_input</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_output', title='?'>cell_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.context_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.context_state', title='?'>context_state</a>]):
<span class='lineno'> 107</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_state', title='?'>cell_state</a> is None:  # first call, return encoder_state
<span class='lineno'> 108</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_state', title='?'>cell_state</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.encoder_state', title='?'>encoder_state</a>
<span class='lineno'> 109</span> 
<span class='lineno'> 110</span>         # init attention
<span class='lineno'> 111</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.attention', title='None'>attention</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention', title='? -> None'>_init_attention</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.encoder_state', title='?'>encoder_state</a>)
<span class='lineno'> 112</span>       else:
<span class='lineno'> 113</span>         # construct attention
<span class='lineno'> 114</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.attention', title='?'>attention</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_construct_fn', title='?'>attention_construct_fn</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_output', title='?'>cell_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_keys', title='?'>attention_keys</a>,
<span class='lineno'> 115</span>                                            <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.attention_values', title='?'>attention_values</a>)
<span class='lineno'> 116</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_output', title='?'>cell_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.attention', title='?'>attention</a>
<span class='lineno'> 117</span> 
<span class='lineno'> 118</span>       # combine cell_input and attention
<span class='lineno'> 119</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.next_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.next_input', title='?'>next_input</a> = tf.concat([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_input', title='?'>cell_input</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.attention', title='None'>attention</a>], 1)
<span class='lineno'> 120</span> 
<span class='lineno'> 121</span>       return (None, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_state', title='?'>cell_state</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.next_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.next_input', title='?'>next_input</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.cell_output', title='?'>cell_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.context_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn.context_state', title='?'>context_state</a>)
<span class='lineno'> 122</span> 
<span class='lineno'> 123</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_train.decoder_fn', title='(?, ?, ?, ?, ?) -> (None, ?, ?, ?, ?)'>decoder_fn</a>
<span class='lineno'> 124</span> 
<span class='lineno'> 125</span> 
<span class='lineno'> 126</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference', title='(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, None) -> (?, ?, ?, ?, ?) -> (?, ?, ?, ?, ?)'>attention_decoder_fn_inference</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.output_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.output_fn', title='?'>output_fn</a>,
<span class='lineno'> 127</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_state', title='?'>encoder_state</a>,
<span class='lineno'> 128</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_keys', title='?'>attention_keys</a>,
<span class='lineno'> 129</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_values', title='?'>attention_values</a>,
<span class='lineno'> 130</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_score_fn', title='?'>attention_score_fn</a>,
<span class='lineno'> 131</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_construct_fn', title='?'>attention_construct_fn</a>,
<span class='lineno'> 132</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.embeddings', title='?'>embeddings</a>,
<span class='lineno'> 133</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.start_of_sequence_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.start_of_sequence_id', title='?'>start_of_sequence_id</a>,
<span class='lineno'> 134</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.end_of_sequence_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.end_of_sequence_id', title='?'>end_of_sequence_id</a>,
<span class='lineno'> 135</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.maximum_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.maximum_length', title='?'>maximum_length</a>,
<span class='lineno'> 136</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.num_decoder_symbols', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.num_decoder_symbols', title='?'>num_decoder_symbols</a>,
<span class='lineno'> 137</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', title='?'>dtype</a>=tf.int32,
<span class='lineno'> 138</span>                                    <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.name', title='None'>name</a>=None):
<span class='lineno'> 139</span>   &quot;&quot;&quot;Attentional decoder function for `dynamic_rnn_decoder` during inference.
<span class='lineno'> 140</span> 
<span class='lineno'> 141</span>   The `attention_decoder_fn_inference` is a simple inference function for a
<span class='lineno'> 142</span>   sequence-to-sequence model. It should be used when `dynamic_rnn_decoder` is
<span class='lineno'> 143</span>   in the inference mode.
<span class='lineno'> 144</span> 
<span class='lineno'> 145</span>   The `attention_decoder_fn_inference` is called with user arguments
<span class='lineno'> 146</span>   and returns the `decoder_fn`, which can be passed to the
<span class='lineno'> 147</span>   `dynamic_rnn_decoder`, such that
<span class='lineno'> 148</span> 
<span class='lineno'> 149</span>   ```
<span class='lineno'> 150</span>   dynamic_fn_inference = attention_decoder_fn_inference(...)
<span class='lineno'> 151</span>   outputs_inference, state_inference = dynamic_rnn_decoder(
<span class='lineno'> 152</span>       decoder_fn=dynamic_fn_inference, ...)
<span class='lineno'> 153</span>   ```
<span class='lineno'> 154</span> 
<span class='lineno'> 155</span>   Further usage can be found in the `kernel_tests/seq2seq_test.py`.
<span class='lineno'> 156</span> 
<span class='lineno'> 157</span>   Args:
<span class='lineno'> 158</span>     output_fn: An output function to project your `cell_output` onto class
<span class='lineno'> 159</span>     logits.
<span class='lineno'> 160</span> 
<span class='lineno'> 161</span>     An example of an output function;
<span class='lineno'> 162</span> 
<span class='lineno'> 163</span>     ```
<span class='lineno'> 164</span>       tf.variable_scope(&quot;decoder&quot;) as varscope
<span class='lineno'> 165</span>         output_fn = lambda x: tf.contrib.layers.linear(x, num_decoder_symbols,
<span class='lineno'> 166</span>                                             scope=varscope)
<span class='lineno'> 167</span> 
<span class='lineno'> 168</span>         outputs_train, state_train = seq2seq.dynamic_rnn_decoder(...)
<span class='lineno'> 169</span>         logits_train = output_fn(outputs_train)
<span class='lineno'> 170</span> 
<span class='lineno'> 171</span>         varscope.reuse_variables()
<span class='lineno'> 172</span>         logits_inference, state_inference = seq2seq.dynamic_rnn_decoder(
<span class='lineno'> 173</span>             output_fn=output_fn, ...)
<span class='lineno'> 174</span>     ```
<span class='lineno'> 175</span> 
<span class='lineno'> 176</span>     If `None` is supplied it will act as an identity function, which
<span class='lineno'> 177</span>     might be wanted when using the RNNCell `OutputProjectionWrapper`.
<span class='lineno'> 178</span> 
<span class='lineno'> 179</span>     encoder_state: The encoded state to initialize the `dynamic_rnn_decoder`.
<span class='lineno'> 180</span>     attention_keys: to be compared with target states.
<span class='lineno'> 181</span>     attention_values: to be used to construct context vectors.
<span class='lineno'> 182</span>     attention_score_fn: to compute similarity between key and target states.
<span class='lineno'> 183</span>     attention_construct_fn: to build attention states.
<span class='lineno'> 184</span>     embeddings: The embeddings matrix used for the decoder sized
<span class='lineno'> 185</span>     `[num_decoder_symbols, embedding_size]`.
<span class='lineno'> 186</span>     start_of_sequence_id: The start of sequence ID in the decoder embeddings.
<span class='lineno'> 187</span>     end_of_sequence_id: The end of sequence ID in the decoder embeddings.
<span class='lineno'> 188</span>     maximum_length: The maximum allowed of time steps to decode.
<span class='lineno'> 189</span>     num_decoder_symbols: The number of classes to decode at each time step.
<span class='lineno'> 190</span>     dtype: (default: `tf.int32`) The default data type to use when
<span class='lineno'> 191</span>     handling integer objects.
<span class='lineno'> 192</span>     name: (default: `None`) NameScope for the decoder function;
<span class='lineno'> 193</span>       defaults to &quot;attention_decoder_fn_inference&quot;
<span class='lineno'> 194</span> 
<span class='lineno'> 195</span>   Returns:
<span class='lineno'> 196</span>     A decoder function with the required interface of `dynamic_rnn_decoder`
<span class='lineno'> 197</span>     intended for inference.
<span class='lineno'> 198</span>   &quot;&quot;&quot;
<span class='lineno'> 199</span>   with tf.name_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.name', title='None'>name</a>, &quot;attention_decoder_fn_inference&quot;, [
<span class='lineno'> 200</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.output_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.output_fn', title='?'>output_fn</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_state', title='?'>encoder_state</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_keys', title='?'>attention_keys</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_values', title='?'>attention_values</a>,
<span class='lineno'> 201</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_score_fn', title='?'>attention_score_fn</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_construct_fn', title='?'>attention_construct_fn</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.embeddings', title='?'>embeddings</a>,
<span class='lineno'> 202</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.start_of_sequence_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.start_of_sequence_id', title='?'>start_of_sequence_id</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.end_of_sequence_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.end_of_sequence_id', title='?'>end_of_sequence_id</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.maximum_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.maximum_length', title='?'>maximum_length</a>,
<span class='lineno'> 203</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.num_decoder_symbols', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.num_decoder_symbols', title='?'>num_decoder_symbols</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', title='?'>dtype</a>
<span class='lineno'> 204</span>   ]):
<span class='lineno'> 205</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.start_of_sequence_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.start_of_sequence_id', title='?'>start_of_sequence_id</a> = tf.convert_to_tensor(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.start_of_sequence_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.start_of_sequence_id', title='?'>start_of_sequence_id</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', title='?'>dtype</a>)
<span class='lineno'> 206</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.end_of_sequence_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.end_of_sequence_id', title='?'>end_of_sequence_id</a> = tf.convert_to_tensor(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.end_of_sequence_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.end_of_sequence_id', title='?'>end_of_sequence_id</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', title='?'>dtype</a>)
<span class='lineno'> 207</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.maximum_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.maximum_length', title='?'>maximum_length</a> = tf.convert_to_tensor(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.maximum_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.maximum_length', title='?'>maximum_length</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', title='?'>dtype</a>)
<span class='lineno'> 208</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.num_decoder_symbols', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.num_decoder_symbols', title='?'>num_decoder_symbols</a> = tf.convert_to_tensor(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.num_decoder_symbols', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.num_decoder_symbols', title='?'>num_decoder_symbols</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', title='?'>dtype</a>)
<span class='lineno'> 209</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_info', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_info', title='?'>encoder_info</a> = tf.contrib.framework.nest.flatten(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_state', title='?'>encoder_state</a>)[0]
<span class='lineno'> 210</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', title='?'>batch_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_info', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_info', title='?'>encoder_info</a>.get_shape()[0].value
<span class='lineno'> 211</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.output_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.output_fn', title='?'>output_fn</a> is None:
<span class='lineno'> 212</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.output_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.output_fn', title='? -> ?'>output_fn</a> = lambda <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.lambda%409.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.lambda%409.x', title='?'>x</a>: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.lambda%409.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.lambda%409.x', title='?'>x</a>
<span class='lineno'> 213</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', title='?'>batch_size</a> is None:
<span class='lineno'> 214</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', title='?'>batch_size</a> = tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_info', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_info', title='?'>encoder_info</a>)[0]
<span class='lineno'> 215</span> 
<span class='lineno'> 216</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn', title='(?, ?, ?, ?, ?) -> (?, ?, ?, ?, ?)'>decoder_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.time', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.time', title='?'>time</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_state', title='?'>cell_state</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', title='?'>cell_input</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', title='?'>cell_output</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.context_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.context_state', title='?'>context_state</a>):
<span class='lineno'> 217</span>     &quot;&quot;&quot;Decoder function used in the `dynamic_rnn_decoder` for inference.
<span class='lineno'> 218</span> 
<span class='lineno'> 219</span>     The main difference between this decoder function and the `decoder_fn` in
<span class='lineno'> 220</span>     `attention_decoder_fn_train` is how `next_cell_input` is calculated. In
<span class='lineno'> 221</span>     decoder function we calculate the next input by applying an argmax across
<span class='lineno'> 222</span>     the feature dimension of the output from the decoder. This is a
<span class='lineno'> 223</span>     greedy-search approach. (Bahdanau et al., 2014) &amp; (Sutskever et al., 2014)
<span class='lineno'> 224</span>     use beam-search instead.
<span class='lineno'> 225</span> 
<span class='lineno'> 226</span>     Args:
<span class='lineno'> 227</span>       time: positive integer constant reflecting the current timestep.
<span class='lineno'> 228</span>       cell_state: state of RNNCell.
<span class='lineno'> 229</span>       cell_input: input provided by `dynamic_rnn_decoder`.
<span class='lineno'> 230</span>       cell_output: output of RNNCell.
<span class='lineno'> 231</span>       context_state: context state provided by `dynamic_rnn_decoder`.
<span class='lineno'> 232</span> 
<span class='lineno'> 233</span>     Returns:
<span class='lineno'> 234</span>       A tuple (done, next state, next input, emit output, next context state)
<span class='lineno'> 235</span>       where:
<span class='lineno'> 236</span> 
<span class='lineno'> 237</span>       done: A boolean vector to indicate which sentences has reached a
<span class='lineno'> 238</span>       `end_of_sequence_id`. This is used for early stopping by the
<span class='lineno'> 239</span>       `dynamic_rnn_decoder`. When `time&gt;=maximum_length` a boolean vector with
<span class='lineno'> 240</span>       all elements as `true` is returned.
<span class='lineno'> 241</span> 
<span class='lineno'> 242</span>       next state: `cell_state`, this decoder function does not modify the
<span class='lineno'> 243</span>       given state.
<span class='lineno'> 244</span> 
<span class='lineno'> 245</span>       next input: The embedding from argmax of the `cell_output` is used as
<span class='lineno'> 246</span>       `next_input`.
<span class='lineno'> 247</span> 
<span class='lineno'> 248</span>       emit output: If `output_fn is None` the supplied `cell_output` is
<span class='lineno'> 249</span>       returned, else the `output_fn` is used to update the `cell_output`
<span class='lineno'> 250</span>       before calculating `next_input` and returning `cell_output`.
<span class='lineno'> 251</span> 
<span class='lineno'> 252</span>       next context state: `context_state`, this decoder function does not
<span class='lineno'> 253</span>       modify the given context state. The context state could be modified when
<span class='lineno'> 254</span>       applying e.g. beam search.
<span class='lineno'> 255</span> 
<span class='lineno'> 256</span>     Raises:
<span class='lineno'> 257</span>       ValueError: if cell_input is not None.
<span class='lineno'> 258</span> 
<span class='lineno'> 259</span>     &quot;&quot;&quot;
<span class='lineno'> 260</span>     with tf.name_scope(
<span class='lineno'> 261</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.name', title='None'>name</a>, &quot;attention_decoder_fn_inference&quot;,
<span class='lineno'> 262</span>         [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.time', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.time', title='?'>time</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_state', title='?'>cell_state</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', title='?'>cell_input</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', title='?'>cell_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.context_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.context_state', title='?'>context_state</a>]):
<span class='lineno'> 263</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', title='?'>cell_input</a> is not None:
<span class='lineno'> 264</span>         raise ValueError(
<span class='lineno'> 265</span>             &quot;Expected cell_input to be None, but saw: %s&quot; % cell_input)
<span class='lineno'> 266</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', title='?'>cell_output</a> is None:
<span class='lineno'> 267</span>         # invariant that this is time == 0
<span class='lineno'> 268</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input_id', title='?'>next_input_id</a> = tf.ones(
<span class='lineno'> 269</span>             [
<span class='lineno'> 270</span>                 <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', title='?'>batch_size</a>,
<span class='lineno'> 271</span>             ], dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', title='?'>dtype</a>) * (
<span class='lineno'> 272</span>                 <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.start_of_sequence_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.start_of_sequence_id', title='?'>start_of_sequence_id</a>)
<span class='lineno'> 273</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.done', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.done', title='?'>done</a> = tf.zeros(
<span class='lineno'> 274</span>             [
<span class='lineno'> 275</span>                 <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', title='?'>batch_size</a>,
<span class='lineno'> 276</span>             ], dtype=tf.bool)
<span class='lineno'> 277</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_state', title='?'>cell_state</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_state', title='?'>encoder_state</a>
<span class='lineno'> 278</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', title='?'>cell_output</a> = tf.zeros([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.num_decoder_symbols', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.num_decoder_symbols', title='?'>num_decoder_symbols</a>], dtype=tf.float32)
<span class='lineno'> 279</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', title='?'>cell_input</a> = tf.gather(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.embeddings', title='?'>embeddings</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input_id', title='?'>next_input_id</a>)
<span class='lineno'> 280</span> 
<span class='lineno'> 281</span>         # init attention
<span class='lineno'> 282</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.attention', title='None'>attention</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention', title='? -> None'>_init_attention</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.encoder_state', title='?'>encoder_state</a>)
<span class='lineno'> 283</span>       else:
<span class='lineno'> 284</span>         # construct attention
<span class='lineno'> 285</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.attention', title='?'>attention</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_construct_fn', title='?'>attention_construct_fn</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', title='?'>cell_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_keys', title='?'>attention_keys</a>,
<span class='lineno'> 286</span>                                            <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.attention_values', title='?'>attention_values</a>)
<span class='lineno'> 287</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', title='?'>cell_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.attention', title='?'>attention</a>
<span class='lineno'> 288</span> 
<span class='lineno'> 289</span>         # argmax decoder
<span class='lineno'> 290</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', title='?'>cell_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.output_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.output_fn', title='? -> ?'>output_fn</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', title='?'>cell_output</a>)  # logits
<span class='lineno'> 291</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input_id', title='?'>next_input_id</a> = tf.cast(tf.argmax(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', title='?'>cell_output</a>, 1), dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.dtype', title='?'>dtype</a>)
<span class='lineno'> 292</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.done', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.done', title='?'>done</a> = tf.equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input_id', title='?'>next_input_id</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.end_of_sequence_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.end_of_sequence_id', title='?'>end_of_sequence_id</a>)
<span class='lineno'> 293</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', title='?'>cell_input</a> = tf.gather(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.embeddings', title='?'>embeddings</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input_id', title='?'>next_input_id</a>)
<span class='lineno'> 294</span> 
<span class='lineno'> 295</span>       # combine cell_input and attention
<span class='lineno'> 296</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input', title='?'>next_input</a> = tf.concat([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_input', title='?'>cell_input</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.attention', title='None'>attention</a>], 1)
<span class='lineno'> 297</span> 
<span class='lineno'> 298</span>       # if time &gt; maxlen, return all true vector
<span class='lineno'> 299</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.done', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.done', title='?'>done</a> = tf.cond(
<span class='lineno'> 300</span>           tf.greater(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.time', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.time', title='?'>time</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.maximum_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.maximum_length', title='?'>maximum_length</a>),
<span class='lineno'> 301</span>           lambda: tf.ones([
<span class='lineno'> 302</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.batch_size', title='?'>batch_size</a>,], dtype=tf.bool), lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.done', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.done', title='?'>done</a>)
<span class='lineno'> 303</span>       return (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.done', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.done', title='?'>done</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_state', title='?'>cell_state</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.next_input', title='?'>next_input</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.cell_output', title='?'>cell_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.context_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn.context_state', title='?'>context_state</a>)
<span class='lineno'> 304</span> 
<span class='lineno'> 305</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.attention_decoder_fn_inference.decoder_fn', title='(?, ?, ?, ?, ?) -> (?, ?, ?, ?, ?)'>decoder_fn</a>
<span class='lineno'> 306</span> 
<span class='lineno'> 307</span> 
<span class='lineno'> 308</span> ## Helper functions ##
<span class='lineno'> 309</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention', title='(?, ?, ?, None) -> (?, ?, (?, ?, ?) -> None, (?, ?, ?) -> None)'>prepare_attention</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_states', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_states', title='?'>attention_states</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_option', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_option', title='?'>attention_option</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.num_units', title='?'>num_units</a>,
<span class='lineno'> 310</span>                       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.reuse', title='None'>reuse</a>=None):
<span class='lineno'> 311</span>   &quot;&quot;&quot;Prepare keys/values/functions for attention.
<span class='lineno'> 312</span> 
<span class='lineno'> 313</span>   Args:
<span class='lineno'> 314</span>     attention_states: hidden states to attend over.
<span class='lineno'> 315</span>     attention_option: how to compute attention, either &quot;luong&quot; or &quot;bahdanau&quot;.
<span class='lineno'> 316</span>     num_units: hidden state dimension.
<span class='lineno'> 317</span>     reuse: whether to reuse variable scope.
<span class='lineno'> 318</span> 
<span class='lineno'> 319</span>   Returns:
<span class='lineno'> 320</span>     attention_keys: to be compared with target states.
<span class='lineno'> 321</span>     attention_values: to be used to construct context vectors.
<span class='lineno'> 322</span>     attention_score_fn: to compute similarity between key and target states.
<span class='lineno'> 323</span>     attention_construct_fn: to build attention states.
<span class='lineno'> 324</span>   &quot;&quot;&quot;
<span class='lineno'> 325</span>   # Prepare attention keys / values from attention_states
<span class='lineno'> 326</span>   with tf.variable_scope(&quot;attention_keys&quot;, reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.reuse', title='None'>reuse</a>) as <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.scope', title='?'>scope</a>:
<span class='lineno'> 327</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_keys', title='?'>attention_keys</a> = tf.contrib.layers.linear(
<span class='lineno'> 328</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_states', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_states', title='?'>attention_states</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.num_units', title='?'>num_units</a>, biases_initializer=None, scope=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.scope', title='?'>scope</a>)
<span class='lineno'> 329</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_values', title='?'>attention_values</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_states', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_states', title='?'>attention_states</a>
<span class='lineno'> 330</span> 
<span class='lineno'> 331</span>   # Attention score function
<span class='lineno'> 332</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_score_fn', title='(?, ?, ?) -> None'>attention_score_fn</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn', title='(str, ?, ?, None, ?) -> (?, ?, ?) -> None / (?, ?, ?, ?, ?) -> (?, ?, ?) -> None'>_create_attention_score_fn</a>(&quot;attention_score&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.num_units', title='?'>num_units</a>,
<span class='lineno'> 333</span>                                                   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_option', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_option', title='?'>attention_option</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.reuse', title='None'>reuse</a>)
<span class='lineno'> 334</span>   # Attention construction function
<span class='lineno'> 335</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_construct_fn', title='(?, ?, ?) -> None'>attention_construct_fn</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn', title='(?, ?, ?, ?) -> ? -> ? / (str, ?, (?, ?, ?) -> None, None) -> (?, ?, ?) -> None'>_create_attention_construct_fn</a>(
<span class='lineno'> 336</span>       &quot;attention_construct&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.num_units', title='?'>num_units</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_score_fn', title='(?, ?, ?) -> None'>attention_score_fn</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.reuse', title='None'>reuse</a>)
<span class='lineno'> 337</span> 
<span class='lineno'> 338</span>   return (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_keys', title='?'>attention_keys</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_values', title='?'>attention_values</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_score_fn', title='(?, ?, ?) -> None'>attention_score_fn</a>,
<span class='lineno'> 339</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils.prepare_attention.attention_construct_fn', title='(?, ?, ?) -> None'>attention_construct_fn</a>)
<span class='lineno'> 340</span> 
<span class='lineno'> 341</span> 
<span class='lineno'> 342</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention', title='? -> None'>_init_attention</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.encoder_state', title='?'>encoder_state</a>):
<span class='lineno'> 343</span>   &quot;&quot;&quot;Initialize attention. Handling both LSTM and GRU.
<span class='lineno'> 344</span> 
<span class='lineno'> 345</span>   Args:
<span class='lineno'> 346</span>     encoder_state: The encoded state to initialize the `dynamic_rnn_decoder`.
<span class='lineno'> 347</span> 
<span class='lineno'> 348</span>   Returns:
<span class='lineno'> 349</span>     attn: initial zero attention vector.
<span class='lineno'> 350</span>   &quot;&quot;&quot;
<span class='lineno'> 351</span> 
<span class='lineno'> 352</span>   # Multi- vs single-layer
<span class='lineno'> 353</span>   # TODO(thangluong): is this the best way to check?
<span class='lineno'> 354</span>   if isinstance(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.encoder_state', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.encoder_state', title='? -> tuple'>encoder_state</a></a>, tuple):
<span class='lineno'> 355</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', title='?'>top_state</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.encoder_state', title='? -> tuple'>encoder_state</a>[-1]
<span class='lineno'> 356</span>   else:
<span class='lineno'> 357</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', title='?'>top_state</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.encoder_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.encoder_state', title='?'>encoder_state</a>
<span class='lineno'> 358</span> 
<span class='lineno'> 359</span>   # LSTM vs GRU
<span class='lineno'> 360</span>   if isinstance(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', title='?'>top_state</a></a>, tf.contrib.rnn.LSTMStateTuple):
<span class='lineno'> 361</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.attn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.attn', title='?'>attn</a> = tf.zeros_like(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', title='?'>top_state</a>.h)
<span class='lineno'> 362</span>   else:
<span class='lineno'> 363</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.attn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.attn', title='?'>attn</a> = tf.zeros_like(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.top_state', title='?'>top_state</a>)
<span class='lineno'> 364</span> 
<span class='lineno'> 365</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.attn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._init_attention.attn', title='?'>attn</a>
<span class='lineno'> 366</span> 
<span class='lineno'> 367</span> 
<span class='lineno'> 368</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn', title='(?, ?, ?, ?) -> ? -> ? / (str, ?, (?, ?, ?) -> None, None) -> (?, ?, ?) -> None'>_create_attention_construct_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.name', title='str'>name</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.num_units', title='?'>num_units</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.attention_score_fn', title='(?, ?, ?) -> None'>attention_score_fn</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.reuse', title='None'>reuse</a>):
<span class='lineno'> 369</span>   &quot;&quot;&quot;Function to compute attention vectors.
<span class='lineno'> 370</span> 
<span class='lineno'> 371</span>   Args:
<span class='lineno'> 372</span>     name: to label variables.
<span class='lineno'> 373</span>     num_units: hidden state dimension.
<span class='lineno'> 374</span>     attention_score_fn: to compute similarity between key and target states.
<span class='lineno'> 375</span>     reuse: whether to reuse variable scope.
<span class='lineno'> 376</span> 
<span class='lineno'> 377</span>   Returns:
<span class='lineno'> 378</span>     attention_construct_fn: to build attention states.
<span class='lineno'> 379</span>   &quot;&quot;&quot;
<span class='lineno'> 380</span> 
<span class='lineno'> 381</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn', title='(?, ?, ?) -> None'>construct_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_query', title='?'>attention_query</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_keys', title='?'>attention_keys</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_values', title='?'>attention_values</a>):
<span class='lineno'> 382</span>     with tf.variable_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.name', title='str'>name</a>, reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.reuse', title='None'>reuse</a>) as <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.scope', title='?'>scope</a>:
<span class='lineno'> 383</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.context', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.context', title='None'>context</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.attention_score_fn', title='(?, ?, ?) -> None'>attention_score_fn</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_query', title='?'>attention_query</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_keys', title='?'>attention_keys</a>,
<span class='lineno'> 384</span>                                    <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_values', title='?'>attention_values</a>)
<span class='lineno'> 385</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.concat_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.concat_input', title='?'>concat_input</a> = tf.concat([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention_query', title='?'>attention_query</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.context', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.context', title='None'>context</a>], 1)
<span class='lineno'> 386</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention', title='?'>attention</a> = tf.contrib.layers.linear(
<span class='lineno'> 387</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.concat_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.concat_input', title='?'>concat_input</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.num_units', title='?'>num_units</a>, biases_initializer=None, scope=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.scope', title='?'>scope</a>)
<span class='lineno'> 388</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn.attention', title='?'>attention</a>
<span class='lineno'> 389</span> 
<span class='lineno'> 390</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_construct_fn.construct_fn', title='(?, ?, ?) -> None'>construct_fn</a>
<span class='lineno'> 391</span> 
<span class='lineno'> 392</span> 
<span class='lineno'> 393</span> # keys: [batch_size, attention_length, attn_size]
<span class='lineno'> 394</span> # query: [batch_size, 1, attn_size]
<span class='lineno'> 395</span> # return weights [batch_size, attention_length]
<span class='lineno'> 396</span> @function.Defun(func_name=&quot;attn_add_fun&quot;, noinline=True)
<span class='lineno'> 397</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun', title='(?, ?, ?) -> ?'>_attn_add_fun</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.v', title='?'>v</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.keys', title='?'>keys</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.query', title='?'>query</a>):
<span class='lineno'> 398</span>   return tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.v', title='?'>v</a> * tf.tanh(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.keys', title='?'>keys</a> + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun.query', title='?'>query</a>), [2])
<span class='lineno'> 399</span> 
<span class='lineno'> 400</span> 
<span class='lineno'> 401</span> @function.Defun(func_name=&quot;attn_mul_fun&quot;, noinline=True)
<span class='lineno'> 402</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun', title='(?, ?) -> ?'>_attn_mul_fun</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun.keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun.keys', title='?'>keys</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun.query', title='?'>query</a>):
<span class='lineno'> 403</span>   return tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun.keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun.keys', title='?'>keys</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun.query', title='?'>query</a>, [2])
<span class='lineno'> 404</span> 
<span class='lineno'> 405</span> 
<span class='lineno'> 406</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn', title='(str, ?, ?, None, ?) -> (?, ?, ?) -> None / (?, ?, ?, ?, ?) -> (?, ?, ?) -> None'>_create_attention_score_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.name', title='str'>name</a>,
<span class='lineno'> 407</span>                                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', title='?'>num_units</a>,
<span class='lineno'> 408</span>                                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_option', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_option', title='?'>attention_option</a>,
<span class='lineno'> 409</span>                                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.reuse', title='None'>reuse</a>,
<span class='lineno'> 410</span>                                <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.dtype', title='?'>dtype</a>=tf.float32):
<span class='lineno'> 411</span>   &quot;&quot;&quot;Different ways to compute attention scores.
<span class='lineno'> 412</span> 
<span class='lineno'> 413</span>   Args:
<span class='lineno'> 414</span>     name: to label variables.
<span class='lineno'> 415</span>     num_units: hidden state dimension.
<span class='lineno'> 416</span>     attention_option: how to compute attention, either &quot;luong&quot; or &quot;bahdanau&quot;.
<span class='lineno'> 417</span>       &quot;bahdanau&quot;: additive (Bahdanau et al., ICLR&#39;2015)
<span class='lineno'> 418</span>       &quot;luong&quot;: multiplicative (Luong et al., EMNLP&#39;2015)
<span class='lineno'> 419</span>     reuse: whether to reuse variable scope.
<span class='lineno'> 420</span>     dtype: (default: `tf.float32`) data type to use.
<span class='lineno'> 421</span> 
<span class='lineno'> 422</span>   Returns:
<span class='lineno'> 423</span>     attention_score_fn: to compute similarity between key and target states.
<span class='lineno'> 424</span>   &quot;&quot;&quot;
<span class='lineno'> 425</span>   with tf.variable_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.name', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.name', title='str'>name</a>, reuse=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.reuse', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.reuse', title='None'>reuse</a>):
<span class='lineno'> 426</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_option', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_option', title='?'>attention_option</a> == &quot;bahdanau&quot;:
<span class='lineno'> 427</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.query_w', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.query_w', title='?'>query_w</a> = tf.get_variable(&quot;attnW&quot;, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', title='?'>num_units</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', title='?'>num_units</a>], dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.dtype', title='?'>dtype</a>)
<span class='lineno'> 428</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.score_v', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.score_v', title='?'>score_v</a> = tf.get_variable(&quot;attnV&quot;, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', title='?'>num_units</a>], dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.dtype', title='?'>dtype</a>)
<span class='lineno'> 429</span> 
<span class='lineno'> 430</span>     def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn', title='(?, ?, ?) -> None'>attention_score_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', title='?'>query</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.keys', title='?'>keys</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.values', title='?'>values</a>):
<span class='lineno'> 431</span>       &quot;&quot;&quot;Put attention masks on attention_values using attention_keys and query.
<span class='lineno'> 432</span> 
<span class='lineno'> 433</span>       Args:
<span class='lineno'> 434</span>         query: A Tensor of shape [batch_size, num_units].
<span class='lineno'> 435</span>         keys: A Tensor of shape [batch_size, attention_length, num_units].
<span class='lineno'> 436</span>         values: A Tensor of shape [batch_size, attention_length, num_units].
<span class='lineno'> 437</span> 
<span class='lineno'> 438</span>       Returns:
<span class='lineno'> 439</span>         context_vector: A Tensor of shape [batch_size, num_units].
<span class='lineno'> 440</span> 
<span class='lineno'> 441</span>       Raises:
<span class='lineno'> 442</span>         ValueError: if attention_option is neither &quot;luong&quot; or &quot;bahdanau&quot;.
<span class='lineno'> 443</span> 
<span class='lineno'> 444</span> 
<span class='lineno'> 445</span>       &quot;&quot;&quot;
<span class='lineno'> 446</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_option', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_option', title='?'>attention_option</a> == &quot;bahdanau&quot;:
<span class='lineno'> 447</span>         # transform query
<span class='lineno'> 448</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', title='?'>query</a> = tf.matmul(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', title='?'>query</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.query_w', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.query_w', title='?'>query_w</a>)
<span class='lineno'> 449</span> 
<span class='lineno'> 450</span>         # reshape query: [batch_size, 1, num_units]
<span class='lineno'> 451</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', title='?'>query</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', title='?'>query</a>, [-1, 1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', title='?'>num_units</a>])
<span class='lineno'> 452</span> 
<span class='lineno'> 453</span>         # attn_fun
<span class='lineno'> 454</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.scores', title='?'>scores</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_add_fun', title='(?, ?, ?) -> ?'>_attn_add_fun</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.score_v', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.score_v', title='?'>score_v</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.keys', title='?'>keys</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', title='?'>query</a>)
<span class='lineno'> 455</span>       elif <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_option', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_option', title='?'>attention_option</a> == &quot;luong&quot;:
<span class='lineno'> 456</span>         # reshape query: [batch_size, 1, num_units]
<span class='lineno'> 457</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', title='?'>query</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', title='?'>query</a>, [-1, 1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', title='?'>num_units</a>])
<span class='lineno'> 458</span> 
<span class='lineno'> 459</span>         # attn_fun
<span class='lineno'> 460</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.scores', title='?'>scores</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._attn_mul_fun', title='(?, ?) -> ?'>_attn_mul_fun</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.keys', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.keys', title='?'>keys</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.query', title='?'>query</a>)
<span class='lineno'> 461</span>       else:
<span class='lineno'> 462</span>         raise ValueError(&quot;Unknown attention option %s!&quot; % attention_option)
<span class='lineno'> 463</span> 
<span class='lineno'> 464</span>       # Compute alignment weights
<span class='lineno'> 465</span>       #   scores: [batch_size, length]
<span class='lineno'> 466</span>       #   alignments: [batch_size, length]
<span class='lineno'> 467</span>       # TODO(thangluong): not normalize over padding positions.
<span class='lineno'> 468</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.alignments', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.alignments', title='?'>alignments</a> = tf.nn.softmax(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.scores', title='?'>scores</a>)
<span class='lineno'> 469</span> 
<span class='lineno'> 470</span>       # Now calculate the attention-weighted vector.
<span class='lineno'> 471</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.alignments', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.alignments', title='?'>alignments</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.alignments', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.alignments', title='?'>alignments</a>, 2)
<span class='lineno'> 472</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.context_vector', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.context_vector', title='?'>context_vector</a> = tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.alignments', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.alignments', title='?'>alignments</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.values', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.values', title='?'>values</a>, [1])
<span class='lineno'> 473</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.context_vector', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.context_vector', title='?'>context_vector</a>.set_shape([None, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.num_units', title='?'>num_units</a>])
<span class='lineno'> 474</span> 
<span class='lineno'> 475</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.context_vector', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn.context_vector', title='?'>context_vector</a>
<span class='lineno'> 476</span> 
<span class='lineno'> 477</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.maskgan.models.attention_utils._create_attention_score_fn.attention_score_fn', title='(?, ?, ?) -> None'>attention_score_fn</a>
</pre></td></tr></table></body></html>