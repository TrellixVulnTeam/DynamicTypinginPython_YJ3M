<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/audioset/vggish/vggish_train_demo.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags', xid='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags'>flags</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.FLAGS', xid='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.FLAGS'>FLAGS</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._NUM_CLASSES', xid='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._NUM_CLASSES'>_NUM_CLASSES</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch', xid='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch'>_get_examples_batch</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main', xid='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main'>main</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2017 The TensorFlow Authors All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> r&quot;&quot;&quot;A simple demonstration of running VGGish in training mode.
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> This is intended as a toy example that demonstrates how to use the VGGish model
<span class='lineno'>  19</span> definition within a larger model that adds more layers on top, and then train
<span class='lineno'>  20</span> the larger model. If you let VGGish train as well, then this allows you to
<span class='lineno'>  21</span> fine-tune the VGGish model parameters for your application. If you don&#39;t let
<span class='lineno'>  22</span> VGGish train, then you use VGGish as a feature extractor for the layers above
<span class='lineno'>  23</span> it.
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> For this toy task, we are training a classifier to distinguish between three
<span class='lineno'>  26</span> classes: sine waves, constant signals, and white noise. We generate synthetic
<span class='lineno'>  27</span> waveforms from each of these classes, convert into shuffled batches of log mel
<span class='lineno'>  28</span> spectrogram examples with associated labels, and feed the batches into a model
<span class='lineno'>  29</span> that includes VGGish at the bottom and a couple of additional layers on top. We
<span class='lineno'>  30</span> also plumb in labels that are associated with the examples, which feed a label
<span class='lineno'>  31</span> loss used for training.
<span class='lineno'>  32</span> 
<span class='lineno'>  33</span> Usage:
<span class='lineno'>  34</span>   # Run training for 100 steps using a model checkpoint in the default
<span class='lineno'>  35</span>   # location (vggish_model.ckpt in the current directory). Allow VGGish
<span class='lineno'>  36</span>   # to get fine-tuned.
<span class='lineno'>  37</span>   $ python vggish_train_demo.py --num_batches 100
<span class='lineno'>  38</span> 
<span class='lineno'>  39</span>   # Same as before but run for fewer steps and don&#39;t change VGGish parameters
<span class='lineno'>  40</span>   # and use a checkpoint in a different location
<span class='lineno'>  41</span>   $ python vggish_train_demo.py --num_batches 50 \
<span class='lineno'>  42</span>                                 --train_vggish=False \
<span class='lineno'>  43</span>                                 --checkpoint /path/to/model/checkpoint
<span class='lineno'>  44</span> &quot;&quot;&quot;
<span class='lineno'>  45</span> 
<span class='lineno'>  46</span> from __future__ import print_function
<span class='lineno'>  47</span> 
<span class='lineno'>  48</span> from random import shuffle
<span class='lineno'>  49</span> 
<span class='lineno'>  50</span> import numpy as np
<span class='lineno'>  51</span> import tensorflow.compat.v1 as tf
<span class='lineno'>  52</span> tf.disable_v2_behavior()
<span class='lineno'>  53</span> import tf_slim as slim
<span class='lineno'>  54</span> 
<span class='lineno'>  55</span> import <a href='vggish_input.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', title='vggish_input'>vggish_input</a>
<span class='lineno'>  56</span> import <a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', title='vggish_params'>vggish_params</a>
<span class='lineno'>  57</span> import <a href='vggish_slim.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', title='vggish_slim'>vggish_slim</a>
<span class='lineno'>  58</span> 
<span class='lineno'>  59</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags', title='?'>flags</a> = tf.app.flags
<span class='lineno'>  60</span> 
<span class='lineno'>  61</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags', title='?'>flags</a>.DEFINE_integer(
<span class='lineno'>  62</span>     &#39;num_batches&#39;, 30,
<span class='lineno'>  63</span>     &#39;Number of batches of examples to feed into the model. Each batch is of &#39;
<span class='lineno'>  64</span>     &#39;variable size and contains shuffled examples of each class of audio.&#39;)
<span class='lineno'>  65</span> 
<span class='lineno'>  66</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags', title='?'>flags</a>.DEFINE_boolean(
<span class='lineno'>  67</span>     &#39;train_vggish&#39;, True,
<span class='lineno'>  68</span>     &#39;If True, allow VGGish parameters to change during training, thus &#39;
<span class='lineno'>  69</span>     &#39;fine-tuning VGGish. If False, VGGish parameters are fixed, thus using &#39;
<span class='lineno'>  70</span>     &#39;VGGish as a fixed feature extractor.&#39;)
<span class='lineno'>  71</span> 
<span class='lineno'>  72</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags', title='?'>flags</a>.DEFINE_string(
<span class='lineno'>  73</span>     &#39;checkpoint&#39;, &#39;vggish_model.ckpt&#39;,
<span class='lineno'>  74</span>     &#39;Path to the VGGish checkpoint file.&#39;)
<span class='lineno'>  75</span> 
<span class='lineno'>  76</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.FLAGS', title='?'>FLAGS</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.flags', title='?'>flags</a>.FLAGS
<span class='lineno'>  77</span> 
<span class='lineno'>  78</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._NUM_CLASSES', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._NUM_CLASSES', title='int'>_NUM_CLASSES</a> = 3
<span class='lineno'>  79</span> 
<span class='lineno'>  80</span> 
<span class='lineno'>  81</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch', title='() -> ([?], [?])'>_get_examples_batch</a>():
<span class='lineno'>  82</span>   &quot;&quot;&quot;Returns a shuffled batch of examples of all audio classes.
<span class='lineno'>  83</span> 
<span class='lineno'>  84</span>   Note that this is just a toy function because this is a simple demo intended
<span class='lineno'>  85</span>   to illustrate how the training code might work.
<span class='lineno'>  86</span> 
<span class='lineno'>  87</span>   Returns:
<span class='lineno'>  88</span>     a tuple (features, labels) where features is a NumPy array of shape
<span class='lineno'>  89</span>     [batch_size, num_frames, num_bands] where the batch_size is variable and
<span class='lineno'>  90</span>     each row is a log mel spectrogram patch of shape [num_frames, num_bands]
<span class='lineno'>  91</span>     suitable for feeding VGGish, while labels is a NumPy array of shape
<span class='lineno'>  92</span>     [batch_size, num_classes] where each row is a multi-hot label vector that
<span class='lineno'>  93</span>     provides the labels for corresponding rows in features.
<span class='lineno'>  94</span>   &quot;&quot;&quot;
<span class='lineno'>  95</span>   # Make a waveform for each class.
<span class='lineno'>  96</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.num_seconds', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.num_seconds', title='int'>num_seconds</a> = 5
<span class='lineno'>  97</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sr', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sr', title='int'>sr</a> = 44100  # Sampling rate.
<span class='lineno'>  98</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.t', title='?'>t</a> = np.linspace(0, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.num_seconds', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.num_seconds', title='int'>num_seconds</a>, int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.num_seconds', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.num_seconds', title='int'>num_seconds</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sr', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sr', title='int'>sr</a>))  # Time axis.
<span class='lineno'>  99</span>   # Random sine wave.
<span class='lineno'> 100</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.freq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.freq', title='?'>freq</a> = np.random.uniform(100, 1000)
<span class='lineno'> 101</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine', title='?'>sine</a> = np.sin(2 * np.pi * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.freq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.freq', title='?'>freq</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.t', title='?'>t</a>)
<span class='lineno'> 102</span>   # Random constant signal.
<span class='lineno'> 103</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.magnitude', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.magnitude', title='?'>magnitude</a> = np.random.uniform(-1, 1)
<span class='lineno'> 104</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const', title='?'>const</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.magnitude', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.magnitude', title='?'>magnitude</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.t', title='?'>t</a>
<span class='lineno'> 105</span>   # White noise.
<span class='lineno'> 106</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise', title='?'>noise</a> = np.random.normal(-1, 1, size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.t', title='?'>t</a>.shape)
<span class='lineno'> 107</span> 
<span class='lineno'> 108</span>   # Make examples of each signal and corresponding labels.
<span class='lineno'> 109</span>   # Sine is class index 0, Const class index 1, Noise class index 2.
<span class='lineno'> 110</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine_examples', title='None'>sine_examples</a> = <a href='vggish_input.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', title='vggish_input'>vggish_input</a>.<a href='vggish_input.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input.waveform_to_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input.waveform_to_examples', title='(float, ?) -> None / (?, int) -> None'>waveform_to_examples</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine', title='?'>sine</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sr', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sr', title='int'>sr</a>)
<span class='lineno'> 111</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine_labels', title='?'>sine_labels</a> = np.array([[1, 0, 0]] * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine_examples', title='None'>sine_examples</a>.shape[0])
<span class='lineno'> 112</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const_examples', title='None'>const_examples</a> = <a href='vggish_input.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', title='vggish_input'>vggish_input</a>.<a href='vggish_input.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input.waveform_to_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input.waveform_to_examples', title='(float, ?) -> None / (?, int) -> None'>waveform_to_examples</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const', title='?'>const</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sr', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sr', title='int'>sr</a>)
<span class='lineno'> 113</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const_labels', title='?'>const_labels</a> = np.array([[0, 1, 0]] * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const_examples', title='None'>const_examples</a>.shape[0])
<span class='lineno'> 114</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise_examples', title='None'>noise_examples</a> = <a href='vggish_input.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', title='vggish_input'>vggish_input</a>.<a href='vggish_input.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input.waveform_to_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input.waveform_to_examples', title='(float, ?) -> None / (?, int) -> None'>waveform_to_examples</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise', title='?'>noise</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sr', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sr', title='int'>sr</a>)
<span class='lineno'> 115</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise_labels', title='?'>noise_labels</a> = np.array([[0, 0, 1]] * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise_examples', title='None'>noise_examples</a>.shape[0])
<span class='lineno'> 116</span> 
<span class='lineno'> 117</span>   # Shuffle (example, label) pairs across all classes.
<span class='lineno'> 118</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.all_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.all_examples', title='?'>all_examples</a> = np.concatenate((<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine_examples', title='None'>sine_examples</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const_examples', title='None'>const_examples</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise_examples', title='None'>noise_examples</a>))
<span class='lineno'> 119</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.all_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.all_labels', title='?'>all_labels</a> = np.concatenate((<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.sine_labels', title='?'>sine_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.const_labels', title='?'>const_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.noise_labels', title='?'>noise_labels</a>))
<span class='lineno'> 120</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labeled_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labeled_examples', title='list'>labeled_examples</a> = list(zip(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.all_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.all_examples', title='?'>all_examples</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.all_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.all_labels', title='?'>all_labels</a>))
<span class='lineno'> 121</span>   shuffle(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labeled_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labeled_examples', title='list'>labeled_examples</a>)
<span class='lineno'> 122</span> 
<span class='lineno'> 123</span>   # Separate and return the features and labels.
<span class='lineno'> 124</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.features', title='[?]'>features</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.example', title='?'>example</a> for (<a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.example', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.example', title='?'>example</a></a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch._', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch._', title='?'>_</a></a>) in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labeled_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labeled_examples', title='list'>labeled_examples</a>]
<span class='lineno'> 125</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labels', title='[?]'>labels</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.label', title='?'>label</a> for (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch._', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch._', title='?'>_</a></a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.label', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.label', title='?'>label</a></a>) in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labeled_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labeled_examples', title='list'>labeled_examples</a>]
<span class='lineno'> 126</span>   return (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.features', title='[?]'>features</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch.labels', title='[?]'>labels</a>)
<span class='lineno'> 127</span> 
<span class='lineno'> 128</span> 
<span class='lineno'> 129</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main', title='? -> None'>main</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main._', title='?'>_</a>):
<span class='lineno'> 130</span>   with tf.Graph().as_default(), tf.Session() as <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', title='?'>sess</a>:
<span class='lineno'> 131</span>     # Define VGGish.
<span class='lineno'> 132</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.embeddings', title='None'>embeddings</a> = <a href='vggish_slim.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', title='vggish_slim'>vggish_slim</a>.<a href='vggish_slim.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim.define_vggish_slim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim.define_vggish_slim', title='? -> None / bool -> None'>define_vggish_slim</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.FLAGS', title='?'>FLAGS</a>.train_vggish)
<span class='lineno'> 133</span> 
<span class='lineno'> 134</span>     # Define a shallow classification model and associated training ops on top
<span class='lineno'> 135</span>     # of VGGish.
<span class='lineno'> 136</span>     with tf.variable_scope(&#39;mymodel&#39;):
<span class='lineno'> 137</span>       # Add a fully connected layer with 100 units.
<span class='lineno'> 138</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.num_units', title='int'>num_units</a> = 100
<span class='lineno'> 139</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.fc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.fc', title='?'>fc</a> = slim.fully_connected(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.embeddings', title='None'>embeddings</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.num_units', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.num_units', title='int'>num_units</a>)
<span class='lineno'> 140</span> 
<span class='lineno'> 141</span>       # Add a classifier layer at the end, consisting of parallel logistic
<span class='lineno'> 142</span>       # classifiers, one per class. This allows for multi-class tasks.
<span class='lineno'> 143</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.logits', title='?'>logits</a> = slim.fully_connected(
<span class='lineno'> 144</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.fc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.fc', title='?'>fc</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._NUM_CLASSES', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._NUM_CLASSES', title='int'>_NUM_CLASSES</a>, activation_fn=None, scope=&#39;logits&#39;)
<span class='lineno'> 145</span>       tf.sigmoid(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.logits', title='?'>logits</a>, name=&#39;prediction&#39;)
<span class='lineno'> 146</span> 
<span class='lineno'> 147</span>       # Add training ops.
<span class='lineno'> 148</span>       with tf.variable_scope(&#39;train&#39;):
<span class='lineno'> 149</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.global_step', title='?'>global_step</a> = tf.Variable(
<span class='lineno'> 150</span>             0, name=&#39;global_step&#39;, trainable=False,
<span class='lineno'> 151</span>             collections=[tf.GraphKeys.GLOBAL_VARIABLES,
<span class='lineno'> 152</span>                          tf.GraphKeys.GLOBAL_STEP])
<span class='lineno'> 153</span> 
<span class='lineno'> 154</span>         # Labels are assumed to be fed as a batch multi-hot vectors, with
<span class='lineno'> 155</span>         # a 1 in the position of each positive class label, and 0 elsewhere.
<span class='lineno'> 156</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels', title='?'>labels</a> = tf.placeholder(
<span class='lineno'> 157</span>             tf.float32, shape=(None, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._NUM_CLASSES', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._NUM_CLASSES', title='int'>_NUM_CLASSES</a>), name=&#39;labels&#39;)
<span class='lineno'> 158</span> 
<span class='lineno'> 159</span>         # Cross-entropy label loss.
<span class='lineno'> 160</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.xent', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.xent', title='?'>xent</a> = tf.nn.sigmoid_cross_entropy_with_logits(
<span class='lineno'> 161</span>             logits=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.logits', title='?'>logits</a>, labels=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels', title='?'>labels</a>, name=&#39;xent&#39;)
<span class='lineno'> 162</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss', title='?'>loss</a> = tf.reduce_mean(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.xent', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.xent', title='?'>xent</a>, name=&#39;loss_op&#39;)
<span class='lineno'> 163</span>         tf.summary.scalar(&#39;loss&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss', title='?'>loss</a>)
<span class='lineno'> 164</span> 
<span class='lineno'> 165</span>         # We use the same optimizer and hyperparameters as used to train VGGish.
<span class='lineno'> 166</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.optimizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.optimizer', title='?'>optimizer</a> = tf.train.AdamOptimizer(
<span class='lineno'> 167</span>             learning_rate=<a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', title='vggish_params'>vggish_params</a>.<a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.LEARNING_RATE', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.LEARNING_RATE', title='float'>LEARNING_RATE</a>,
<span class='lineno'> 168</span>             epsilon=<a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', title='vggish_params'>vggish_params</a>.<a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.ADAM_EPSILON', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.ADAM_EPSILON', title='float'>ADAM_EPSILON</a>)
<span class='lineno'> 169</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.optimizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.optimizer', title='?'>optimizer</a>.minimize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss', title='?'>loss</a>, global_step=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.global_step', title='?'>global_step</a>, name=&#39;train_op&#39;)
<span class='lineno'> 170</span> 
<span class='lineno'> 171</span>     # Initialize all variables in the model, and then load the pre-trained
<span class='lineno'> 172</span>     # VGGish checkpoint.
<span class='lineno'> 173</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', title='?'>sess</a>.run(tf.global_variables_initializer())
<span class='lineno'> 174</span>     <a href='vggish_slim.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', title='vggish_slim'>vggish_slim</a>.<a href='vggish_slim.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim.load_vggish_slim_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim.load_vggish_slim_checkpoint', title='(?, ?) -> None / (?, str) -> None'>load_vggish_slim_checkpoint</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', title='?'>sess</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.FLAGS', title='?'>FLAGS</a>.checkpoint)
<span class='lineno'> 175</span> 
<span class='lineno'> 176</span>     # Locate all the tensors and ops we need for the training loop.
<span class='lineno'> 177</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.features_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.features_tensor', title='?'>features_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', title='?'>sess</a>.graph.get_tensor_by_name(
<span class='lineno'> 178</span>         <a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', title='vggish_params'>vggish_params</a>.<a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.INPUT_TENSOR_NAME', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.INPUT_TENSOR_NAME', title='str'>INPUT_TENSOR_NAME</a>)
<span class='lineno'> 179</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels_tensor', title='?'>labels_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', title='?'>sess</a>.graph.get_tensor_by_name(&#39;mymodel/train/labels:0&#39;)
<span class='lineno'> 180</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.global_step_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.global_step_tensor', title='?'>global_step_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', title='?'>sess</a>.graph.get_tensor_by_name(
<span class='lineno'> 181</span>         &#39;mymodel/train/global_step:0&#39;)
<span class='lineno'> 182</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss_tensor', title='?'>loss_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', title='?'>sess</a>.graph.get_tensor_by_name(&#39;mymodel/train/loss_op:0&#39;)
<span class='lineno'> 183</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.train_op', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.train_op', title='?'>train_op</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', title='?'>sess</a>.graph.get_operation_by_name(&#39;mymodel/train/train_op&#39;)
<span class='lineno'> 184</span> 
<span class='lineno'> 185</span>     # The training loop.
<span class='lineno'> 186</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main._', title='int'>_</a> in range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.FLAGS', title='?'>FLAGS</a>.num_batches):
<span class='lineno'> 187</span>       (<a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.features', title='[?]'>features</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels', title='[?]'>labels</a>) = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo._get_examples_batch', title='() -> ([?], [?])'>_get_examples_batch</a>()
<span class='lineno'> 188</span>       [<a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.num_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.num_steps', title='?'>num_steps</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss', title='?'>loss</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main._', title='?'>_</a>] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.sess', title='?'>sess</a>.run(
<span class='lineno'> 189</span>           [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.global_step_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.global_step_tensor', title='?'>global_step_tensor</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss_tensor', title='?'>loss_tensor</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.train_op', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.train_op', title='?'>train_op</a>],
<span class='lineno'> 190</span>           feed_dict={<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.features_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.features_tensor', title='?'>features_tensor</a>: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.features', title='[?]'>features</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels_tensor', title='?'>labels_tensor</a>: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.labels', title='[?]'>labels</a>})
<span class='lineno'> 191</span>       print(&#39;Step %d: loss %g&#39; % (<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.num_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.num_steps', title='?'>num_steps</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_train_demo.main.loss', title='?'>loss</a>))
<span class='lineno'> 192</span> 
<span class='lineno'> 193</span> if __name__ == &#39;__main__&#39;:
<span class='lineno'> 194</span>   tf.app.run()
</pre></td></tr></table></body></html>