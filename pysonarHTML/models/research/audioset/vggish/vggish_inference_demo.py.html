<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/audioset/vggish/vggish_inference_demo.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', xid='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags'>flags</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', xid='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS'>FLAGS</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main', xid='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main'>main</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2017 The TensorFlow Authors All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> r&quot;&quot;&quot;A simple demonstration of running VGGish in inference mode.
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> This is intended as a toy example that demonstrates how the various building
<span class='lineno'>  19</span> blocks (feature extraction, model definition and loading, postprocessing) work
<span class='lineno'>  20</span> together in an inference context.
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> A WAV file (assumed to contain signed 16-bit PCM samples) is read in, converted
<span class='lineno'>  23</span> into log mel spectrogram examples, fed into VGGish, the raw embedding output is
<span class='lineno'>  24</span> whitened and quantized, and the postprocessed embeddings are optionally written
<span class='lineno'>  25</span> in a SequenceExample to a TFRecord file (using the same format as the embedding
<span class='lineno'>  26</span> features released in AudioSet).
<span class='lineno'>  27</span> 
<span class='lineno'>  28</span> Usage:
<span class='lineno'>  29</span>   # Run a WAV file through the model and print the embeddings. The model
<span class='lineno'>  30</span>   # checkpoint is loaded from vggish_model.ckpt and the PCA parameters are
<span class='lineno'>  31</span>   # loaded from vggish_pca_params.npz in the current directory.
<span class='lineno'>  32</span>   $ python vggish_inference_demo.py --wav_file /path/to/a/wav/file
<span class='lineno'>  33</span> 
<span class='lineno'>  34</span>   # Run a WAV file through the model and also write the embeddings to
<span class='lineno'>  35</span>   # a TFRecord file. The model checkpoint and PCA parameters are explicitly
<span class='lineno'>  36</span>   # passed in as well.
<span class='lineno'>  37</span>   $ python vggish_inference_demo.py --wav_file /path/to/a/wav/file \
<span class='lineno'>  38</span>                                     --tfrecord_file /path/to/tfrecord/file \
<span class='lineno'>  39</span>                                     --checkpoint /path/to/model/checkpoint \
<span class='lineno'>  40</span>                                     --pca_params /path/to/pca/params
<span class='lineno'>  41</span> 
<span class='lineno'>  42</span>   # Run a built-in input (a sine wav) through the model and print the
<span class='lineno'>  43</span>   # embeddings. Associated model files are read from the current directory.
<span class='lineno'>  44</span>   $ python vggish_inference_demo.py
<span class='lineno'>  45</span> &quot;&quot;&quot;
<span class='lineno'>  46</span> 
<span class='lineno'>  47</span> from __future__ import print_function
<span class='lineno'>  48</span> 
<span class='lineno'>  49</span> import numpy as np
<span class='lineno'>  50</span> import six
<span class='lineno'>  51</span> import soundfile
<span class='lineno'>  52</span> import tensorflow.compat.v1 as tf
<span class='lineno'>  53</span> tf.disable_v2_behavior()
<span class='lineno'>  54</span> 
<span class='lineno'>  55</span> import <a href='vggish_input.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', title='vggish_input'>vggish_input</a>
<span class='lineno'>  56</span> import <a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', title='vggish_params'>vggish_params</a>
<span class='lineno'>  57</span> import <a href='vggish_postprocess.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_postprocess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_postprocess', title='vggish_postprocess'>vggish_postprocess</a>
<span class='lineno'>  58</span> import <a href='vggish_slim.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', title='vggish_slim'>vggish_slim</a>
<span class='lineno'>  59</span> 
<span class='lineno'>  60</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', title='?'>flags</a> = tf.app.flags
<span class='lineno'>  61</span> 
<span class='lineno'>  62</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', title='?'>flags</a>.DEFINE_string(
<span class='lineno'>  63</span>     &#39;wav_file&#39;, None,
<span class='lineno'>  64</span>     &#39;Path to a wav file. Should contain signed 16-bit PCM samples. &#39;
<span class='lineno'>  65</span>     &#39;If none is provided, a synthetic sound is used.&#39;)
<span class='lineno'>  66</span> 
<span class='lineno'>  67</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', title='?'>flags</a>.DEFINE_string(
<span class='lineno'>  68</span>     &#39;checkpoint&#39;, &#39;vggish_model.ckpt&#39;,
<span class='lineno'>  69</span>     &#39;Path to the VGGish checkpoint file.&#39;)
<span class='lineno'>  70</span> 
<span class='lineno'>  71</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', title='?'>flags</a>.DEFINE_string(
<span class='lineno'>  72</span>     &#39;pca_params&#39;, &#39;vggish_pca_params.npz&#39;,
<span class='lineno'>  73</span>     &#39;Path to the VGGish PCA parameters file.&#39;)
<span class='lineno'>  74</span> 
<span class='lineno'>  75</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', title='?'>flags</a>.DEFINE_string(
<span class='lineno'>  76</span>     &#39;tfrecord_file&#39;, None,
<span class='lineno'>  77</span>     &#39;Path to a TFRecord file where embeddings will be written.&#39;)
<span class='lineno'>  78</span> 
<span class='lineno'>  79</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', title='?'>FLAGS</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.flags', title='?'>flags</a>.FLAGS
<span class='lineno'>  80</span> 
<span class='lineno'>  81</span> 
<span class='lineno'>  82</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main', title='? -> None'>main</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main._', title='?'>_</a>):
<span class='lineno'>  83</span>   # In this simple example, we run the examples from a single audio file through
<span class='lineno'>  84</span>   # the model. If none is provided, we generate a synthetic input.
<span class='lineno'>  85</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', title='?'>FLAGS</a>.wav_file:
<span class='lineno'>  86</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.wav_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.wav_file', title='?'>wav_file</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', title='?'>FLAGS</a>.wav_file
<span class='lineno'>  87</span>   else:
<span class='lineno'>  88</span>     # Write a WAV of a sine wav into an in-memory file object.
<span class='lineno'>  89</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.num_secs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.num_secs', title='int'>num_secs</a> = 5
<span class='lineno'>  90</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.freq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.freq', title='int'>freq</a> = 1000
<span class='lineno'>  91</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sr', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sr', title='int'>sr</a> = 44100
<span class='lineno'>  92</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.t', title='?'>t</a> = np.linspace(0, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.num_secs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.num_secs', title='int'>num_secs</a>, int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.num_secs', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.num_secs', title='int'>num_secs</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sr', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sr', title='int'>sr</a>))
<span class='lineno'>  93</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.x', title='?'>x</a> = np.sin(2 * np.pi * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.freq', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.freq', title='int'>freq</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.t', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.t', title='?'>t</a>)
<span class='lineno'>  94</span>     # Convert to signed 16-bit samples.
<span class='lineno'>  95</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.samples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.samples', title='?'>samples</a> = np.clip(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.x', title='?'>x</a> * 32768, -32768, 32767).astype(np.int16)
<span class='lineno'>  96</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.wav_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.wav_file', title='?'>wav_file</a> = six.BytesIO()
<span class='lineno'>  97</span>     soundfile.write(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.wav_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.wav_file', title='?'>wav_file</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.samples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.samples', title='?'>samples</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sr', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sr', title='int'>sr</a>, format=&#39;WAV&#39;, subtype=&#39;PCM_16&#39;)
<span class='lineno'>  98</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.wav_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.wav_file', title='?'>wav_file</a>.seek(0)
<span class='lineno'>  99</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.examples_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.examples_batch', title='None'>examples_batch</a> = <a href='vggish_input.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input', title='vggish_input'>vggish_input</a>.<a href='vggish_input.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input.wavfile_to_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_input.wavfile_to_examples', title='? -> None'>wavfile_to_examples</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.wav_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.wav_file', title='?'>wav_file</a>)
<span class='lineno'> 100</span>   print(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.examples_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.examples_batch', title='None'>examples_batch</a>)
<span class='lineno'> 101</span> 
<span class='lineno'> 102</span>   # Prepare a postprocessor to munge the model embeddings.
<span class='lineno'> 103</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.pproc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.pproc', title='Postprocessor'>pproc</a> = <a href='vggish_postprocess.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_postprocess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_postprocess', title='vggish_postprocess'>vggish_postprocess</a>.<a href='vggish_postprocess.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_postprocess.Postprocessor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_postprocess.Postprocessor', title='<Postprocessor>'>Postprocessor</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', title='?'>FLAGS</a>.pca_params)
<span class='lineno'> 104</span> 
<span class='lineno'> 105</span>   # If needed, prepare a record writer to store the postprocessed embeddings.
<span class='lineno'> 106</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.writer', title='None'>writer</a> = tf.python_io.TFRecordWriter(
<span class='lineno'> 107</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', title='?'>FLAGS</a>.tfrecord_file) if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', title='?'>FLAGS</a>.tfrecord_file else None
<span class='lineno'> 108</span> 
<span class='lineno'> 109</span>   with tf.Graph().as_default(), tf.Session() as <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sess', title='?'>sess</a>:
<span class='lineno'> 110</span>     # Define the model in inference mode, load the checkpoint, and
<span class='lineno'> 111</span>     # locate input and output tensors.
<span class='lineno'> 112</span>     <a href='vggish_slim.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', title='vggish_slim'>vggish_slim</a>.<a href='vggish_slim.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim.define_vggish_slim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim.define_vggish_slim', title='? -> None / bool -> None'>define_vggish_slim</a>(training=False)
<span class='lineno'> 113</span>     <a href='vggish_slim.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim', title='vggish_slim'>vggish_slim</a>.<a href='vggish_slim.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim.load_vggish_slim_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_slim.load_vggish_slim_checkpoint', title='(?, ?) -> None / (?, str) -> None'>load_vggish_slim_checkpoint</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sess', title='?'>sess</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.FLAGS', title='?'>FLAGS</a>.checkpoint)
<span class='lineno'> 114</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.features_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.features_tensor', title='?'>features_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sess', title='?'>sess</a>.graph.get_tensor_by_name(
<span class='lineno'> 115</span>         <a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', title='vggish_params'>vggish_params</a>.<a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.INPUT_TENSOR_NAME', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.INPUT_TENSOR_NAME', title='str'>INPUT_TENSOR_NAME</a>)
<span class='lineno'> 116</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding_tensor', title='?'>embedding_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sess', title='?'>sess</a>.graph.get_tensor_by_name(
<span class='lineno'> 117</span>         <a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', title='vggish_params'>vggish_params</a>.<a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.OUTPUT_TENSOR_NAME', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.OUTPUT_TENSOR_NAME', title='str'>OUTPUT_TENSOR_NAME</a>)
<span class='lineno'> 118</span> 
<span class='lineno'> 119</span>     # Run inference and postprocessing.
<span class='lineno'> 120</span>     [<a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding_batch', title='?'>embedding_batch</a>] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.sess', title='?'>sess</a>.run([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding_tensor', title='?'>embedding_tensor</a>],
<span class='lineno'> 121</span>                                  feed_dict={<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.features_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.features_tensor', title='?'>features_tensor</a>: <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.examples_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.examples_batch', title='None'>examples_batch</a>})
<span class='lineno'> 122</span>     print(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding_batch', title='?'>embedding_batch</a>)
<span class='lineno'> 123</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.postprocessed_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.postprocessed_batch', title='None'>postprocessed_batch</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.pproc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.pproc', title='Postprocessor'>pproc</a>.<a href='vggish_postprocess.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_postprocess.Postprocessor.postprocess', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_postprocess.Postprocessor.postprocess', title='(Postprocessor, ?) -> None'>postprocess</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding_batch', title='?'>embedding_batch</a>)
<span class='lineno'> 124</span>     print(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.postprocessed_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.postprocessed_batch', title='None'>postprocessed_batch</a>)
<span class='lineno'> 125</span> 
<span class='lineno'> 126</span>     # Write the postprocessed embeddings as a SequenceExample, in a similar
<span class='lineno'> 127</span>     # format as the features released in AudioSet. Each row of the batch of
<span class='lineno'> 128</span>     # embeddings corresponds to roughly a second of audio (96 10ms frames), and
<span class='lineno'> 129</span>     # the rows are written as a sequence of bytes-valued features, where each
<span class='lineno'> 130</span>     # feature value contains the 128 bytes of the whitened quantized embedding.
<span class='lineno'> 131</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.seq_example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.seq_example', title='?'>seq_example</a> = tf.train.SequenceExample(
<span class='lineno'> 132</span>         feature_lists=tf.train.FeatureLists(
<span class='lineno'> 133</span>             feature_list={
<span class='lineno'> 134</span>                 <a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params', title='vggish_params'>vggish_params</a>.<a href='vggish_params.py.html#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.AUDIO_EMBEDDING_FEATURE_NAME', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_params.AUDIO_EMBEDDING_FEATURE_NAME', title='str'>AUDIO_EMBEDDING_FEATURE_NAME</a>:
<span class='lineno'> 135</span>                     tf.train.FeatureList(
<span class='lineno'> 136</span>                         feature=[
<span class='lineno'> 137</span>                             tf.train.Feature(
<span class='lineno'> 138</span>                                 bytes_list=tf.train.BytesList(
<span class='lineno'> 139</span>                                     value=[<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding', title='?'>embedding</a>.tobytes()]))
<span class='lineno'> 140</span>                             for <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.embedding', title='?'>embedding</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.postprocessed_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.postprocessed_batch', title='None'>postprocessed_batch</a>
<span class='lineno'> 141</span>                         ]
<span class='lineno'> 142</span>                     )
<span class='lineno'> 143</span>             }
<span class='lineno'> 144</span>         )
<span class='lineno'> 145</span>     )
<span class='lineno'> 146</span>     print(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.seq_example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.seq_example', title='?'>seq_example</a>)
<span class='lineno'> 147</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.writer', title='None'>writer</a>:
<span class='lineno'> 148</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.writer', title='None'>writer</a>.write(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.seq_example', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.seq_example', title='?'>seq_example</a>.SerializeToString())
<span class='lineno'> 149</span> 
<span class='lineno'> 150</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.writer', title='None'>writer</a>:
<span class='lineno'> 151</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.audioset.vggish.vggish_inference_demo.main.writer', title='None'>writer</a>.close()
<span class='lineno'> 152</span> 
<span class='lineno'> 153</span> if __name__ == &#39;__main__&#39;:
<span class='lineno'> 154</span>   tf.app.run()
</pre></td></tr></table></body></html>