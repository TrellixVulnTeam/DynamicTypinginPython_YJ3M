<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/object_detection/export_inference_graph.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', xid='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags'>flags</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', xid='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS'>FLAGS</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main', xid='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main'>main</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Lint as: python2, python3
<span class='lineno'>   2</span> # Copyright 2017 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   3</span> #
<span class='lineno'>   4</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   5</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   6</span> # You may obtain a copy of the License at
<span class='lineno'>   7</span> #
<span class='lineno'>   8</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   9</span> #
<span class='lineno'>  10</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  11</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  12</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  13</span> # See the License for the specific language governing permissions and
<span class='lineno'>  14</span> # limitations under the License.
<span class='lineno'>  15</span> # ==============================================================================
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span> r&quot;&quot;&quot;Tool to export an object detection model for inference.
<span class='lineno'>  18</span> 
<span class='lineno'>  19</span> Prepares an object detection tensorflow graph for inference using model
<span class='lineno'>  20</span> configuration and a trained checkpoint. Outputs inference
<span class='lineno'>  21</span> graph, associated checkpoint files, a frozen inference graph and a
<span class='lineno'>  22</span> SavedModel (https://tensorflow.github.io/serving/serving_basic.html).
<span class='lineno'>  23</span> 
<span class='lineno'>  24</span> The inference graph contains one of three input nodes depending on the user
<span class='lineno'>  25</span> specified option.
<span class='lineno'>  26</span>   * `image_tensor`: Accepts a uint8 4-D tensor of shape [None, None, None, 3]
<span class='lineno'>  27</span>   * `encoded_image_string_tensor`: Accepts a 1-D string tensor of shape [None]
<span class='lineno'>  28</span>     containing encoded PNG or JPEG images. Image resolutions are expected to be
<span class='lineno'>  29</span>     the same if more than 1 image is provided.
<span class='lineno'>  30</span>   * `tf_example`: Accepts a 1-D string tensor of shape [None] containing
<span class='lineno'>  31</span>     serialized TFExample protos. Image resolutions are expected to be the same
<span class='lineno'>  32</span>     if more than 1 image is provided.
<span class='lineno'>  33</span> 
<span class='lineno'>  34</span> and the following output nodes returned by the model.postprocess(..):
<span class='lineno'>  35</span>   * `num_detections`: Outputs float32 tensors of the form [batch]
<span class='lineno'>  36</span>       that specifies the number of valid boxes per image in the batch.
<span class='lineno'>  37</span>   * `detection_boxes`: Outputs float32 tensors of the form
<span class='lineno'>  38</span>       [batch, num_boxes, 4] containing detected boxes.
<span class='lineno'>  39</span>   * `detection_scores`: Outputs float32 tensors of the form
<span class='lineno'>  40</span>       [batch, num_boxes] containing class scores for the detections.
<span class='lineno'>  41</span>   * `detection_classes`: Outputs float32 tensors of the form
<span class='lineno'>  42</span>       [batch, num_boxes] containing classes for the detections.
<span class='lineno'>  43</span>   * `raw_detection_boxes`: Outputs float32 tensors of the form
<span class='lineno'>  44</span>       [batch, raw_num_boxes, 4] containing detection boxes without
<span class='lineno'>  45</span>       post-processing.
<span class='lineno'>  46</span>   * `raw_detection_scores`: Outputs float32 tensors of the form
<span class='lineno'>  47</span>       [batch, raw_num_boxes, num_classes_with_background] containing class score
<span class='lineno'>  48</span>       logits for raw detection boxes.
<span class='lineno'>  49</span>   * `detection_masks`: (Optional) Outputs float32 tensors of the form
<span class='lineno'>  50</span>       [batch, num_boxes, mask_height, mask_width] containing predicted instance
<span class='lineno'>  51</span>       masks for each box if its present in the dictionary of postprocessed
<span class='lineno'>  52</span>       tensors returned by the model.
<span class='lineno'>  53</span>   * detection_multiclass_scores: (Optional) Outputs float32 tensor of shape
<span class='lineno'>  54</span>       [batch, num_boxes, num_classes_with_background] for containing class
<span class='lineno'>  55</span>       score distribution for detected boxes including background if any.
<span class='lineno'>  56</span>   * detection_features: (Optional) float32 tensor of shape
<span class='lineno'>  57</span>       [batch, num_boxes, roi_height, roi_width, depth]
<span class='lineno'>  58</span>   containing classifier features
<span class='lineno'>  59</span> 
<span class='lineno'>  60</span> Notes:
<span class='lineno'>  61</span>  * This tool uses `use_moving_averages` from eval_config to decide which
<span class='lineno'>  62</span>    weights to freeze.
<span class='lineno'>  63</span> 
<span class='lineno'>  64</span> Example Usage:
<span class='lineno'>  65</span> --------------
<span class='lineno'>  66</span> python export_inference_graph.py \
<span class='lineno'>  67</span>     --input_type image_tensor \
<span class='lineno'>  68</span>     --pipeline_config_path path/to/ssd_inception_v2.config \
<span class='lineno'>  69</span>     --trained_checkpoint_prefix path/to/model.ckpt \
<span class='lineno'>  70</span>     --output_directory path/to/exported_model_directory
<span class='lineno'>  71</span> 
<span class='lineno'>  72</span> The expected output would be in the directory
<span class='lineno'>  73</span> path/to/exported_model_directory (which is created if it does not exist)
<span class='lineno'>  74</span> with contents:
<span class='lineno'>  75</span>  - inference_graph.pbtxt
<span class='lineno'>  76</span>  - model.ckpt.data-00000-of-00001
<span class='lineno'>  77</span>  - model.ckpt.info
<span class='lineno'>  78</span>  - model.ckpt.meta
<span class='lineno'>  79</span>  - frozen_inference_graph.pb
<span class='lineno'>  80</span>  + saved_model (a directory)
<span class='lineno'>  81</span> 
<span class='lineno'>  82</span> Config overrides (see the `config_override` flag) are text protobufs
<span class='lineno'>  83</span> (also of type pipeline_pb2.TrainEvalPipelineConfig) which are used to override
<span class='lineno'>  84</span> certain fields in the provided pipeline_config_path.  These are useful for
<span class='lineno'>  85</span> making small changes to the inference graph that differ from the training or
<span class='lineno'>  86</span> eval config.
<span class='lineno'>  87</span> 
<span class='lineno'>  88</span> Example Usage (in which we change the second stage post-processing score
<span class='lineno'>  89</span> threshold to be 0.5):
<span class='lineno'>  90</span> 
<span class='lineno'>  91</span> python export_inference_graph.py \
<span class='lineno'>  92</span>     --input_type image_tensor \
<span class='lineno'>  93</span>     --pipeline_config_path path/to/ssd_inception_v2.config \
<span class='lineno'>  94</span>     --trained_checkpoint_prefix path/to/model.ckpt \
<span class='lineno'>  95</span>     --output_directory path/to/exported_model_directory \
<span class='lineno'>  96</span>     --config_override &quot; \
<span class='lineno'>  97</span>             model{ \
<span class='lineno'>  98</span>               faster_rcnn { \
<span class='lineno'>  99</span>                 second_stage_post_processing { \
<span class='lineno'> 100</span>                   batch_non_max_suppression { \
<span class='lineno'> 101</span>                     score_threshold: 0.5 \
<span class='lineno'> 102</span>                   } \
<span class='lineno'> 103</span>                 } \
<span class='lineno'> 104</span>               } \
<span class='lineno'> 105</span>             }&quot;
<span class='lineno'> 106</span> &quot;&quot;&quot;
<span class='lineno'> 107</span> import tensorflow.compat.v1 as tf
<span class='lineno'> 108</span> from google.protobuf import text_format
<span class='lineno'> 109</span> from object_detection import exporter
<span class='lineno'> 110</span> from object_detection.protos import pipeline_pb2
<span class='lineno'> 111</span> 
<span class='lineno'> 112</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', title='?'>flags</a> = tf.app.flags
<span class='lineno'> 113</span> 
<span class='lineno'> 114</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', title='?'>flags</a>.DEFINE_string(&#39;input_type&#39;, &#39;image_tensor&#39;, &#39;Type of input node. Can be &#39;
<span class='lineno'> 115</span>                     &#39;one of [`image_tensor`, `encoded_image_string_tensor`, &#39;
<span class='lineno'> 116</span>                     &#39;`tf_example`]&#39;)
<span class='lineno'> 117</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', title='?'>flags</a>.DEFINE_string(&#39;input_shape&#39;, None,
<span class='lineno'> 118</span>                     &#39;If input_type is `image_tensor`, this can explicitly set &#39;
<span class='lineno'> 119</span>                     &#39;the shape of this input tensor to a fixed size. The &#39;
<span class='lineno'> 120</span>                     &#39;dimensions are to be provided as a comma-separated list &#39;
<span class='lineno'> 121</span>                     &#39;of integers. A value of -1 can be used for unknown &#39;
<span class='lineno'> 122</span>                     &#39;dimensions. If not specified, for an `image_tensor, the &#39;
<span class='lineno'> 123</span>                     &#39;default shape will be partially specified as &#39;
<span class='lineno'> 124</span>                     &#39;`[None, None, None, 3]`.&#39;)
<span class='lineno'> 125</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', title='?'>flags</a>.DEFINE_string(&#39;pipeline_config_path&#39;, None,
<span class='lineno'> 126</span>                     &#39;Path to a pipeline_pb2.TrainEvalPipelineConfig config &#39;
<span class='lineno'> 127</span>                     &#39;file.&#39;)
<span class='lineno'> 128</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', title='?'>flags</a>.DEFINE_string(&#39;trained_checkpoint_prefix&#39;, None,
<span class='lineno'> 129</span>                     &#39;Path to trained checkpoint, typically of the form &#39;
<span class='lineno'> 130</span>                     &#39;path/to/model.ckpt&#39;)
<span class='lineno'> 131</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', title='?'>flags</a>.DEFINE_string(&#39;output_directory&#39;, None, &#39;Path to write outputs.&#39;)
<span class='lineno'> 132</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', title='?'>flags</a>.DEFINE_string(&#39;config_override&#39;, &#39;&#39;,
<span class='lineno'> 133</span>                     &#39;pipeline_pb2.TrainEvalPipelineConfig &#39;
<span class='lineno'> 134</span>                     &#39;text proto to override pipeline_config_path.&#39;)
<span class='lineno'> 135</span> <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', title='?'>flags</a>.DEFINE_boolean(&#39;write_inference_graph&#39;, False,
<span class='lineno'> 136</span>                      &#39;If true, writes inference graph to disk.&#39;)
<span class='lineno'> 137</span> tf.app.flags.mark_flag_as_required(&#39;pipeline_config_path&#39;)
<span class='lineno'> 138</span> tf.app.flags.mark_flag_as_required(&#39;trained_checkpoint_prefix&#39;)
<span class='lineno'> 139</span> tf.app.flags.mark_flag_as_required(&#39;output_directory&#39;)
<span class='lineno'> 140</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', title='?'>FLAGS</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.flags', title='?'>flags</a>.FLAGS
<span class='lineno'> 141</span> 
<span class='lineno'> 142</span> 
<span class='lineno'> 143</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main', title='? -> None'>main</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main._', title='?'>_</a>):
<span class='lineno'> 144</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.pipeline_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.pipeline_config', title='?'>pipeline_config</a> = pipeline_pb2.TrainEvalPipelineConfig()
<span class='lineno'> 145</span>   with tf.gfile.GFile(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', title='?'>FLAGS</a>.pipeline_config_path, &#39;r&#39;) as <a name='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.f', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.f', title='?'>f</a>:
<span class='lineno'> 146</span>     text_format.Merge(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.f', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.f', title='?'>f</a>.read(), <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.pipeline_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.pipeline_config', title='?'>pipeline_config</a>)
<span class='lineno'> 147</span>   text_format.Merge(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', title='?'>FLAGS</a>.config_override, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.pipeline_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.pipeline_config', title='?'>pipeline_config</a>)
<span class='lineno'> 148</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', title='?'>FLAGS</a>.input_shape:
<span class='lineno'> 149</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.input_shape', title='[int]'>input_shape</a> = [
<span class='lineno'> 150</span>         int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.dim', title='?'>dim</a>) if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.dim', title='?'>dim</a> != &#39;-1&#39; else None
<span class='lineno'> 151</span>         for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.dim', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.dim', title='?'>dim</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', title='?'>FLAGS</a>.input_shape.split(&#39;,&#39;)
<span class='lineno'> 152</span>     ]
<span class='lineno'> 153</span>   else:
<span class='lineno'> 154</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.input_shape', title='None'>input_shape</a> = None
<span class='lineno'> 155</span>   exporter.export_inference_graph(
<span class='lineno'> 156</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', title='?'>FLAGS</a>.input_type, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.pipeline_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.pipeline_config', title='?'>pipeline_config</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', title='?'>FLAGS</a>.trained_checkpoint_prefix,
<span class='lineno'> 157</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', title='?'>FLAGS</a>.output_directory, input_shape=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.main.input_shape', title='[int]'>input_shape</a>,
<span class='lineno'> 158</span>       write_inference_graph=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.object_detection.export_inference_graph.FLAGS', title='?'>FLAGS</a>.write_inference_graph)
<span class='lineno'> 159</span> 
<span class='lineno'> 160</span> 
<span class='lineno'> 161</span> if __name__ == &#39;__main__&#39;:
<span class='lineno'> 162</span>   tf.app.run()
</pre></td></tr></table></body></html>