<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/research/street/python/vgsl_input.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageShape', xid='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageShape'>ImageShape</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput', xid='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput'>ImageInput</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples', xid='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples'>_ReadExamples</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing', xid='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing'>_ImageProcessing</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2016 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> 
<span class='lineno'>  16</span> &quot;&quot;&quot;String network description language to define network layouts.&quot;&quot;&quot;
<span class='lineno'>  17</span> import collections
<span class='lineno'>  18</span> import tensorflow as tf
<span class='lineno'>  19</span> from tensorflow.python.ops import parsing_ops
<span class='lineno'>  20</span> 
<span class='lineno'>  21</span> # Named tuple for the standard tf image tensor Shape.
<span class='lineno'>  22</span> # batch_size:     Number of images to batch-up for training.
<span class='lineno'>  23</span> # height:         Fixed height of image or None for variable.
<span class='lineno'>  24</span> # width:          Fixed width of image or None for variable.
<span class='lineno'>  25</span> # depth:          Desired depth in bytes per pixel of input images.
<span class='lineno'>  26</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageShape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageShape', title='<(namedtuple)>'>ImageShape</a> = collections.namedtuple(&#39;ImageTensorDims&#39;,
<span class='lineno'>  27</span>                                     [&#39;batch_size&#39;, &#39;height&#39;, &#39;width&#39;, &#39;depth&#39;])
<span class='lineno'>  28</span> 
<span class='lineno'>  29</span> 
<span class='lineno'>  30</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput', title='(?, ?, ?, ?, None) -> (?, ?, ?, ?, ?, ?) / (?, ?, (namedtuple), bool, None) -> (?, ?, ?, ?, ?, ?) / (?, ?, (namedtuple), bool, ?) -> (?, ?, ?, ?, ?, ?) / (str, int, (namedtuple), bool, None) -> (?, ?, ?, ?, ?, ?) / (?, int, (namedtuple), bool, None) -> (?, ?, ?, ?, ?, ?)'>ImageInput</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.input_pattern', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.input_pattern', title='str'>input_pattern</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.num_threads', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.num_threads', title='int'>num_threads</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', title='(namedtuple)'>shape</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.using_ctc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.using_ctc', title='bool'>using_ctc</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.reader', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.reader', title='None'>reader</a>=None):
<span class='lineno'>  31</span>   &quot;&quot;&quot;Creates an input image tensor from the input_pattern filenames.
<span class='lineno'>  32</span> 
<span class='lineno'>  33</span>   TODO(rays) Expand for 2-d labels, 0-d labels, and logistic targets.
<span class='lineno'>  34</span>   Args:
<span class='lineno'>  35</span>     input_pattern:  Filenames of the dataset(s) to read.
<span class='lineno'>  36</span>     num_threads:    Number of preprocessing threads.
<span class='lineno'>  37</span>     shape:          ImageShape with the desired shape of the input.
<span class='lineno'>  38</span>     using_ctc:      Take the unpadded_class labels instead of padded.
<span class='lineno'>  39</span>     reader:         Function that returns an actual reader to read Examples from
<span class='lineno'>  40</span>       input files. If None, uses tf.TFRecordReader().
<span class='lineno'>  41</span>   Returns:
<span class='lineno'>  42</span>     images:   Float Tensor containing the input image scaled to [-1.28, 1.27].
<span class='lineno'>  43</span>     heights:  Tensor int64 containing the heights of the images.
<span class='lineno'>  44</span>     widths:   Tensor int64 containing the widths of the images.
<span class='lineno'>  45</span>     labels:   Serialized SparseTensor containing the int64 labels.
<span class='lineno'>  46</span>     sparse_labels:   Serialized SparseTensor containing the int64 labels.
<span class='lineno'>  47</span>     truths:   Tensor string of the utf8 truth texts.
<span class='lineno'>  48</span>   Raises:
<span class='lineno'>  49</span>     ValueError: if the optimizer type is unrecognized.
<span class='lineno'>  50</span>   &quot;&quot;&quot;
<span class='lineno'>  51</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.data_files', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.data_files', title='?'>data_files</a> = tf.gfile.Glob(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.input_pattern', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.input_pattern', title='str'>input_pattern</a>)
<span class='lineno'>  52</span>   assert <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.data_files', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.data_files', title='?'>data_files</a>, &#39;no files found for dataset &#39; + <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.input_pattern', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.input_pattern', title='str'>input_pattern</a>
<span class='lineno'>  53</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.queue_capacity', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.queue_capacity', title='int'>queue_capacity</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', title='(namedtuple)'>shape</a>.batch_size * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.num_threads', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.num_threads', title='int'>num_threads</a> * 2
<span class='lineno'>  54</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.filename_queue', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.filename_queue', title='?'>filename_queue</a> = tf.train.string_input_producer(
<span class='lineno'>  55</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.data_files', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.data_files', title='?'>data_files</a>, capacity=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.queue_capacity', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.queue_capacity', title='int'>queue_capacity</a>)
<span class='lineno'>  56</span> 
<span class='lineno'>  57</span>   # Create a subgraph with its own reader (but sharing the
<span class='lineno'>  58</span>   # filename_queue) for each preprocessing thread.
<span class='lineno'>  59</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images_and_label_lists', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images_and_label_lists', title='[[None]]'>images_and_label_lists</a> = []
<span class='lineno'>  60</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput._', title='int'>_</a> in range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.num_threads', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.num_threads', title='int'>num_threads</a>):
<span class='lineno'>  61</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.image', title='None'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.height', title='?'>height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.width', title='?'>width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.text', title='?'>text</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples', title='(?, ?, ?, None) -> (None, ?, ?, ?, ?) / (?, (namedtuple), bool, None) -> (None, ?, ?, ?, ?) / (?, (namedtuple), bool, ?) -> (None, ?, ?, ?, ?)'>_ReadExamples</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.filename_queue', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.filename_queue', title='?'>filename_queue</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', title='(namedtuple)'>shape</a>,
<span class='lineno'>  62</span>                                                        <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.using_ctc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.using_ctc', title='bool'>using_ctc</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.reader', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.reader', title='None'>reader</a>)
<span class='lineno'>  63</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images_and_label_lists', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images_and_label_lists', title='[[None]]'>images_and_label_lists</a>.append([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.image', title='None'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.width', title='?'>width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.text', title='?'>text</a>])
<span class='lineno'>  64</span>   # Create a queue that produces the examples in batches.
<span class='lineno'>  65</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images', title='?'>images</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.heights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.heights', title='?'>heights</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.widths', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.widths', title='?'>widths</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.truths', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.truths', title='?'>truths</a> = tf.train.batch_join(
<span class='lineno'>  66</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images_and_label_lists', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images_and_label_lists', title='[[None]]'>images_and_label_lists</a>,
<span class='lineno'>  67</span>       batch_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', title='(namedtuple)'>shape</a>.batch_size,
<span class='lineno'>  68</span>       capacity=16 * <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', title='(namedtuple)'>shape</a>.batch_size,
<span class='lineno'>  69</span>       dynamic_pad=True)
<span class='lineno'>  70</span>   # Deserialize back to sparse, because the batcher doesn&#39;t do sparse.
<span class='lineno'>  71</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', title='?'>labels</a> = tf.deserialize_many_sparse(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', title='?'>labels</a>, tf.int64)
<span class='lineno'>  72</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.sparse_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.sparse_labels', title='?'>sparse_labels</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', title='?'>labels</a>, tf.int32)
<span class='lineno'>  73</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', title='?'>labels</a> = tf.sparse_tensor_to_dense(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', title='?'>labels</a>)
<span class='lineno'>  74</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', title='?'>labels</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', title='?'>labels</a>, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.shape', title='(namedtuple)'>shape</a>.batch_size, -1], name=&#39;Labels&#39;)
<span class='lineno'>  75</span>   # Crush the other shapes to just the batch dimension.
<span class='lineno'>  76</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.heights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.heights', title='?'>heights</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.heights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.heights', title='?'>heights</a>, [-1], name=&#39;Heights&#39;)
<span class='lineno'>  77</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.widths', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.widths', title='?'>widths</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.widths', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.widths', title='?'>widths</a>, [-1], name=&#39;Widths&#39;)
<span class='lineno'>  78</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.truths', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.truths', title='?'>truths</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.truths', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.truths', title='?'>truths</a>, [-1], name=&#39;Truths&#39;)
<span class='lineno'>  79</span>   # Give the images a nice name as well.
<span class='lineno'>  80</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images', title='?'>images</a> = tf.identity(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images', title='?'>images</a>, name=&#39;Images&#39;)
<span class='lineno'>  81</span> 
<span class='lineno'>  82</span>   tf.summary.image(&#39;Images&#39;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images', title='?'>images</a>)
<span class='lineno'>  83</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.images', title='?'>images</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.heights', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.heights', title='?'>heights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.widths', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.widths', title='?'>widths</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.sparse_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.sparse_labels', title='?'>sparse_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.truths', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input.ImageInput.truths', title='?'>truths</a>
<span class='lineno'>  84</span> 
<span class='lineno'>  85</span> 
<span class='lineno'>  86</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples', title='(?, ?, ?, None) -> (None, ?, ?, ?, ?) / (?, (namedtuple), bool, None) -> (None, ?, ?, ?, ?) / (?, (namedtuple), bool, ?) -> (None, ?, ?, ?, ?)'>_ReadExamples</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.filename_queue', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.filename_queue', title='?'>filename_queue</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.shape', title='(namedtuple)'>shape</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.using_ctc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.using_ctc', title='bool'>using_ctc</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', title='None'>reader</a>=None):
<span class='lineno'>  87</span>   &quot;&quot;&quot;Builds network input tensor ops for TF Example.
<span class='lineno'>  88</span> 
<span class='lineno'>  89</span>   Args:
<span class='lineno'>  90</span>     filename_queue: Queue of filenames, from tf.train.string_input_producer
<span class='lineno'>  91</span>     shape:          ImageShape with the desired shape of the input.
<span class='lineno'>  92</span>     using_ctc:      Take the unpadded_class labels instead of padded.
<span class='lineno'>  93</span>     reader:         Function that returns an actual reader to read Examples from
<span class='lineno'>  94</span>       input files. If None, uses tf.TFRecordReader().
<span class='lineno'>  95</span>   Returns:
<span class='lineno'>  96</span>     image:   Float Tensor containing the input image scaled to [-1.28, 1.27].
<span class='lineno'>  97</span>     height:  Tensor int64 containing the height of the image.
<span class='lineno'>  98</span>     width:   Tensor int64 containing the width of the image.
<span class='lineno'>  99</span>     labels:  Serialized SparseTensor containing the int64 labels.
<span class='lineno'> 100</span>     text:    Tensor string of the utf8 truth text.
<span class='lineno'> 101</span>   &quot;&quot;&quot;
<span class='lineno'> 102</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', title='None'>reader</a>:
<span class='lineno'> 103</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', title='?'>reader</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', title='None'>reader</a>()
<span class='lineno'> 104</span>   else:
<span class='lineno'> 105</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', title='?'>reader</a> = tf.TFRecordReader()
<span class='lineno'> 106</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples._', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples._', title='?'>_</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.example_serialized', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.example_serialized', title='?'>example_serialized</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.reader', title='?'>reader</a>.read(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.filename_queue', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.filename_queue', title='?'>filename_queue</a>)
<span class='lineno'> 107</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.example_serialized', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.example_serialized', title='?'>example_serialized</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.example_serialized', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.example_serialized', title='?'>example_serialized</a>, shape=[])
<span class='lineno'> 108</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', title='?'>features</a> = tf.parse_single_example(
<span class='lineno'> 109</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.example_serialized', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.example_serialized', title='?'>example_serialized</a>,
<span class='lineno'> 110</span>       {&#39;image/encoded&#39;: parsing_ops.FixedLenFeature(
<span class='lineno'> 111</span>           [1], dtype=tf.string, default_value=&#39;&#39;),
<span class='lineno'> 112</span>        &#39;image/text&#39;: parsing_ops.FixedLenFeature(
<span class='lineno'> 113</span>            [1], dtype=tf.string, default_value=&#39;&#39;),
<span class='lineno'> 114</span>        &#39;image/class&#39;: parsing_ops.VarLenFeature(dtype=tf.int64),
<span class='lineno'> 115</span>        &#39;image/unpadded_class&#39;: parsing_ops.VarLenFeature(dtype=tf.int64),
<span class='lineno'> 116</span>        &#39;image/height&#39;: parsing_ops.FixedLenFeature(
<span class='lineno'> 117</span>            [1], dtype=tf.int64, default_value=1),
<span class='lineno'> 118</span>        &#39;image/width&#39;: parsing_ops.FixedLenFeature(
<span class='lineno'> 119</span>            [1], dtype=tf.int64, default_value=1)})
<span class='lineno'> 120</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.using_ctc', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.using_ctc', title='bool'>using_ctc</a>:
<span class='lineno'> 121</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.labels', title='?'>labels</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', title='?'>features</a>[&#39;image/unpadded_class&#39;]
<span class='lineno'> 122</span>   else:
<span class='lineno'> 123</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.labels', title='?'>labels</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', title='?'>features</a>[&#39;image/class&#39;]
<span class='lineno'> 124</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.labels', title='?'>labels</a> = tf.serialize_sparse(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.labels', title='?'>labels</a>)
<span class='lineno'> 125</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.image', title='?'>image</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', title='?'>features</a>[&#39;image/encoded&#39;], shape=[], name=&#39;encoded&#39;)
<span class='lineno'> 126</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing', title='(?, (namedtuple)) -> None / (?, ?) -> None'>_ImageProcessing</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.shape', title='(namedtuple)'>shape</a>)
<span class='lineno'> 127</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.height', title='?'>height</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', title='?'>features</a>[&#39;image/height&#39;], [-1])
<span class='lineno'> 128</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.width', title='?'>width</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', title='?'>features</a>[&#39;image/width&#39;], [-1])
<span class='lineno'> 129</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.text', title='?'>text</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.features', title='?'>features</a>[&#39;image/text&#39;], shape=[])
<span class='lineno'> 130</span> 
<span class='lineno'> 131</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.image', title='None'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.height', title='?'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.width', title='?'>width</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ReadExamples.text', title='?'>text</a>
<span class='lineno'> 132</span> 
<span class='lineno'> 133</span> 
<span class='lineno'> 134</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing', title='(?, (namedtuple)) -> None / (?, ?) -> None'>_ImageProcessing</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image_buffer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image_buffer', title='?'>image_buffer</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.shape', title='(namedtuple)'>shape</a>):
<span class='lineno'> 135</span>   &quot;&quot;&quot;Convert a PNG string into an input tensor.
<span class='lineno'> 136</span> 
<span class='lineno'> 137</span>   We allow for fixed and variable sizes.
<span class='lineno'> 138</span>   Does fixed conversion to floats in the range [-1.28, 1.27].
<span class='lineno'> 139</span>   Args:
<span class='lineno'> 140</span>     image_buffer: Tensor containing a PNG encoded image.
<span class='lineno'> 141</span>     shape:          ImageShape with the desired shape of the input.
<span class='lineno'> 142</span>   Returns:
<span class='lineno'> 143</span>     image:        Decoded, normalized image in the range [-1.28, 1.27].
<span class='lineno'> 144</span>   &quot;&quot;&quot;
<span class='lineno'> 145</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', title='?'>image</a> = tf.image.decode_png(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image_buffer', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image_buffer', title='?'>image_buffer</a>, channels=<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.shape', title='(namedtuple)'>shape</a>.depth)
<span class='lineno'> 146</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', title='?'>image</a>.set_shape([<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.shape', title='(namedtuple)'>shape</a>.height, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.shape', title='(namedtuple)'>shape</a>.width, <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.shape', title='(namedtuple)'>shape</a>.depth])
<span class='lineno'> 147</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', title='?'>image</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', title='?'>image</a>, tf.float32)
<span class='lineno'> 148</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', title='?'>image</a> = tf.subtract(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', title='?'>image</a>, 128.0)
<span class='lineno'> 149</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', title='?'>image</a> = tf.multiply(<a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', title='?'>image</a>, 1 / 100.0)
<span class='lineno'> 150</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.research.street.python.vgsl_input._ImageProcessing.image', title='?'>image</a>
</pre></td></tr></table></body></html>