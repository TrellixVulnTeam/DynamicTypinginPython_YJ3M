<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/vision/image_classification/preprocessing.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.MEAN_RGB', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.MEAN_RGB'>MEAN_RGB</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.STDDEV_RGB', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.STDDEV_RGB'>STDDEV_RGB</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE'>IMAGE_SIZE</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.CROP_PADDING', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.CROP_PADDING'>CROP_PADDING</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction'>mean_image_subtraction</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image'>standardize_image</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images'>normalize_images</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop'>decode_and_center_crop</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip'>decode_crop_and_flip</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image'>resize_image</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval'>preprocess_for_eval</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image'>load_eval_image</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset'>build_eval_dataset</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train'>preprocess_for_train</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2019 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> &quot;&quot;&quot;Preprocessing functions for images.&quot;&quot;&quot;
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span> from __future__ import absolute_import
<span class='lineno'>  18</span> from __future__ import division
<span class='lineno'>  19</span> # from __future__ import google_type_annotations
<span class='lineno'>  20</span> from __future__ import print_function
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> import tensorflow as tf
<span class='lineno'>  23</span> from typing import List, Optional, Text, Tuple
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> from official.vision.image_classification import augment
<span class='lineno'>  26</span> 
<span class='lineno'>  27</span> 
<span class='lineno'>  28</span> # Calculated from the ImageNet training set
<span class='lineno'>  29</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.MEAN_RGB', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.MEAN_RGB', title='(float, float, float)'>MEAN_RGB</a> = (0.485 * 255, 0.456 * 255, 0.406 * 255)
<span class='lineno'>  30</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.STDDEV_RGB', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.STDDEV_RGB', title='(float, float, float)'>STDDEV_RGB</a> = (0.229 * 255, 0.224 * 255, 0.225 * 255)
<span class='lineno'>  31</span> 
<span class='lineno'>  32</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', title='int'>IMAGE_SIZE</a> = 224
<span class='lineno'>  33</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.CROP_PADDING', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.CROP_PADDING', title='int'>CROP_PADDING</a> = 32
<span class='lineno'>  34</span> 
<span class='lineno'>  35</span> 
<span class='lineno'>  36</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction', title='(None, (float, float, float), int, ?) -> None / (?, (float, float, float), int, ?) -> None / (?, ?, int, ?) -> None'>mean_image_subtraction</a>(
<span class='lineno'>  37</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.image_bytes', title='None'>ima</a>ge_bytes: tf.Tensor,
<span class='lineno'>  38</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', title='(float, float, float)'>mea</a>ns: Tuple[float, ...],
<span class='lineno'>  39</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.num_channels', title='int'>num</a>_channels: int = 3,
<span class='lineno'>  40</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.dtype', title='?'>dty</a>pe: tf.dtypes.DType = tf.float32,
<span class='lineno'>  41</span> ) -&gt;  tf.Tensor:
<span class='lineno'>  42</span>   &quot;&quot;&quot;Subtracts the given means from each image channel.
<span class='lineno'>  43</span> 
<span class='lineno'>  44</span>   For example:
<span class='lineno'>  45</span>     means = [123.68, 116.779, 103.939]
<span class='lineno'>  46</span>     image_bytes = mean_image_subtraction(image_bytes, means)
<span class='lineno'>  47</span> 
<span class='lineno'>  48</span>   Note that the rank of `image` must be known.
<span class='lineno'>  49</span> 
<span class='lineno'>  50</span>   Args:
<span class='lineno'>  51</span>     image_bytes: a tensor of size [height, width, C].
<span class='lineno'>  52</span>     means: a C-vector of values to subtract from each channel.
<span class='lineno'>  53</span>     num_channels: number of color channels in the image that will be distorted.
<span class='lineno'>  54</span>     dtype: the dtype to convert the images to. Set to `None` to skip conversion.
<span class='lineno'>  55</span> 
<span class='lineno'>  56</span>   Returns:
<span class='lineno'>  57</span>     the centered image.
<span class='lineno'>  58</span> 
<span class='lineno'>  59</span>   Raises:
<span class='lineno'>  60</span>     ValueError: If the rank of `image` is unknown, if `image` has a rank other
<span class='lineno'>  61</span>       than three or if the number of channels in `image` doesn&#39;t match the
<span class='lineno'>  62</span>       number of values in `means`.
<span class='lineno'>  63</span>   &quot;&quot;&quot;
<span class='lineno'>  64</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.image_bytes', title='None'>image_bytes</a>.get_shape().ndims != 3:
<span class='lineno'>  65</span>     raise ValueError(&#39;Input must be of size [height, width, C&gt;0]&#39;)
<span class='lineno'>  66</span> 
<span class='lineno'>  67</span>   if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', title='(float, float, float)'>means</a>) != <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.num_channels', title='int'>num_channels</a>:
<span class='lineno'>  68</span>     raise ValueError(&#39;len(means) must match the number of channels&#39;)
<span class='lineno'>  69</span> 
<span class='lineno'>  70</span>   # We have a 1-D tensor of means; convert to 3-D.
<span class='lineno'>  71</span>   # Note(b/130245863): we explicitly call `broadcast` instead of simply
<span class='lineno'>  72</span>   # expanding dimensions for better performance.
<span class='lineno'>  73</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', title='?'>means</a> = tf.broadcast_to(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', title='(float, float, float)'>means</a>, tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.image_bytes', title='None'>image_bytes</a>))
<span class='lineno'>  74</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.dtype', title='?'>dtype</a> is not None:
<span class='lineno'>  75</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', title='?'>means</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', title='?'>means</a>, dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.dtype', title='?'>dtype</a>)
<span class='lineno'>  76</span> 
<span class='lineno'>  77</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.image_bytes', title='None'>image_bytes</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction.means', title='?'>means</a>
<span class='lineno'>  78</span> 
<span class='lineno'>  79</span> 
<span class='lineno'>  80</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image', title='(?, ?, int, ?) -> None / (None, (float, float, float), int, ?) -> None'>standardize_image</a>(
<span class='lineno'>  81</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.image_bytes', title='None'>ima</a>ge_bytes: tf.Tensor,
<span class='lineno'>  82</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', title='(float, float, float)'>std</a>dev: Tuple[float, ...],
<span class='lineno'>  83</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.num_channels', title='int'>num</a>_channels: int = 3,
<span class='lineno'>  84</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.dtype', title='?'>dty</a>pe: tf.dtypes.DType = tf.float32,
<span class='lineno'>  85</span> ) -&gt;  tf.Tensor:
<span class='lineno'>  86</span>   &quot;&quot;&quot;Divides the given stddev from each image channel.
<span class='lineno'>  87</span> 
<span class='lineno'>  88</span>   For example:
<span class='lineno'>  89</span>     stddev = [123.68, 116.779, 103.939]
<span class='lineno'>  90</span>     image_bytes = standardize_image(image_bytes, stddev)
<span class='lineno'>  91</span> 
<span class='lineno'>  92</span>   Note that the rank of `image` must be known.
<span class='lineno'>  93</span> 
<span class='lineno'>  94</span>   Args:
<span class='lineno'>  95</span>     image_bytes: a tensor of size [height, width, C].
<span class='lineno'>  96</span>     stddev: a C-vector of values to divide from each channel.
<span class='lineno'>  97</span>     num_channels: number of color channels in the image that will be distorted.
<span class='lineno'>  98</span>     dtype: the dtype to convert the images to. Set to `None` to skip conversion.
<span class='lineno'>  99</span> 
<span class='lineno'> 100</span>   Returns:
<span class='lineno'> 101</span>     the centered image.
<span class='lineno'> 102</span> 
<span class='lineno'> 103</span>   Raises:
<span class='lineno'> 104</span>     ValueError: If the rank of `image` is unknown, if `image` has a rank other
<span class='lineno'> 105</span>       than three or if the number of channels in `image` doesn&#39;t match the
<span class='lineno'> 106</span>       number of values in `stddev`.
<span class='lineno'> 107</span>   &quot;&quot;&quot;
<span class='lineno'> 108</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.image_bytes', title='None'>image_bytes</a>.get_shape().ndims != 3:
<span class='lineno'> 109</span>     raise ValueError(&#39;Input must be of size [height, width, C&gt;0]&#39;)
<span class='lineno'> 110</span> 
<span class='lineno'> 111</span>   if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', title='(float, float, float)'>stddev</a>) != <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.num_channels', title='int'>num_channels</a>:
<span class='lineno'> 112</span>     raise ValueError(&#39;len(stddev) must match the number of channels&#39;)
<span class='lineno'> 113</span> 
<span class='lineno'> 114</span>   # We have a 1-D tensor of stddev; convert to 3-D.
<span class='lineno'> 115</span>   # Note(b/130245863): we explicitly call `broadcast` instead of simply
<span class='lineno'> 116</span>   # expanding dimensions for better performance.
<span class='lineno'> 117</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', title='?'>stddev</a> = tf.broadcast_to(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', title='(float, float, float)'>stddev</a>, tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.image_bytes', title='None'>image_bytes</a>))
<span class='lineno'> 118</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.dtype', title='?'>dtype</a> is not None:
<span class='lineno'> 119</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', title='?'>stddev</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', title='?'>stddev</a>, dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.dtype', title='?'>dtype</a>)
<span class='lineno'> 120</span> 
<span class='lineno'> 121</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.image_bytes', title='None'>image_bytes</a> / <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image.stddev', title='?'>stddev</a>
<span class='lineno'> 122</span> 
<span class='lineno'> 123</span> 
<span class='lineno'> 124</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images', title='(?, (float, float, float), (float, float, float), int, ?, str) -> None'>normalize_images</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>fea</a>tures: tf.Tensor,
<span class='lineno'> 125</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', title='(float, float, float)'>mea</a>n_rgb: Tuple[float, ...] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.MEAN_RGB', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.MEAN_RGB', title='(float, float, float)'>MEAN_RGB</a>,
<span class='lineno'> 126</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', title='(float, float, float)'>std</a>dev_rgb: Tuple[float, ...] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.STDDEV_RGB', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.STDDEV_RGB', title='(float, float, float)'>STDDEV_RGB</a>,
<span class='lineno'> 127</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.num_channels', title='int'>num</a>_channels: int = 3,
<span class='lineno'> 128</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.dtype', title='?'>dty</a>pe: tf.dtypes.DType = tf.float32,
<span class='lineno'> 129</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.data_format', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.data_format', title='str'>dat</a>a_format: Text = &#39;channels_last&#39;) -&gt; tf.Tensor:
<span class='lineno'> 130</span>   &quot;&quot;&quot;Normalizes the input image channels with the given mean and stddev.
<span class='lineno'> 131</span> 
<span class='lineno'> 132</span>   Args:
<span class='lineno'> 133</span>     features: `Tensor` representing decoded images in float format.
<span class='lineno'> 134</span>     mean_rgb: the mean of the channels to subtract.
<span class='lineno'> 135</span>     stddev_rgb: the stddev of the channels to divide.
<span class='lineno'> 136</span>     num_channels: the number of channels in the input image tensor.
<span class='lineno'> 137</span>     dtype: the dtype to convert the images to. Set to `None` to skip conversion.
<span class='lineno'> 138</span>     data_format: the format of the input image tensor
<span class='lineno'> 139</span>                  [&#39;channels_first&#39;, &#39;channels_last&#39;].
<span class='lineno'> 140</span> 
<span class='lineno'> 141</span>   Returns:
<span class='lineno'> 142</span>     A normalized image `Tensor`.
<span class='lineno'> 143</span>   &quot;&quot;&quot;
<span class='lineno'> 144</span>   # TODO(allencwang) - figure out how to use mean_image_subtraction and
<span class='lineno'> 145</span>   # standardize_image on batches of images and replace the following.
<span class='lineno'> 146</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.data_format', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.data_format', title='str'>data_format</a> == &#39;channels_first&#39;:
<span class='lineno'> 147</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stats_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stats_shape', title='[int]'>stats_shape</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.num_channels', title='int'>num_channels</a>, 1, 1]
<span class='lineno'> 148</span>   else:
<span class='lineno'> 149</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stats_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stats_shape', title='[int]'>stats_shape</a> = [1, 1, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.num_channels', title='int'>num_channels</a>]
<span class='lineno'> 150</span> 
<span class='lineno'> 151</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.dtype', title='?'>dtype</a> is not None:
<span class='lineno'> 152</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>features</a> = tf.image.convert_image_dtype(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>features</a>, dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.dtype', title='?'>dtype</a>)
<span class='lineno'> 153</span> 
<span class='lineno'> 154</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', title='(float, float, float)'>mean_rgb</a> is not None:
<span class='lineno'> 155</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', title='?'>mean_rgb</a> = tf.constant(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', title='(float, float, float)'>mean_rgb</a>,
<span class='lineno'> 156</span>                            shape=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stats_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stats_shape', title='[int]'>stats_shape</a>,
<span class='lineno'> 157</span>                            dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>features</a>.dtype)
<span class='lineno'> 158</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', title='?'>mean_rgb</a> = tf.broadcast_to(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', title='?'>mean_rgb</a>, tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>features</a>))
<span class='lineno'> 159</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>features</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>features</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.mean_rgb', title='?'>mean_rgb</a>
<span class='lineno'> 160</span> 
<span class='lineno'> 161</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', title='(float, float, float)'>stddev_rgb</a> is not None:
<span class='lineno'> 162</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', title='?'>stddev_rgb</a> = tf.constant(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', title='(float, float, float)'>stddev_rgb</a>,
<span class='lineno'> 163</span>                              shape=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stats_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stats_shape', title='[int]'>stats_shape</a>,
<span class='lineno'> 164</span>                              dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>features</a>.dtype)
<span class='lineno'> 165</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', title='?'>stddev_rgb</a> = tf.broadcast_to(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', title='?'>stddev_rgb</a>, tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>features</a>))
<span class='lineno'> 166</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>features</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>features</a> / <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.stddev_rgb', title='?'>stddev_rgb</a>
<span class='lineno'> 167</span> 
<span class='lineno'> 168</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.normalize_images.features', title='?'>features</a>
<span class='lineno'> 169</span> 
<span class='lineno'> 170</span> 
<span class='lineno'> 171</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop', title='(?, int, int) -> None'>decode_and_center_crop</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', title='?'>ima</a>ge_bytes: tf.Tensor,
<span class='lineno'> 172</span>                            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_size', title='int'>ima</a>ge_size: int = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', title='int'>IMAGE_SIZE</a>,
<span class='lineno'> 173</span>                            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.crop_padding', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.crop_padding', title='int'>cro</a>p_padding: int = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.CROP_PADDING', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.CROP_PADDING', title='int'>CROP_PADDING</a>) -&gt; tf.Tensor:
<span class='lineno'> 174</span>   &quot;&quot;&quot;Crops to center of image with padding then scales image_size.
<span class='lineno'> 175</span> 
<span class='lineno'> 176</span>   Args:
<span class='lineno'> 177</span>     image_bytes: `Tensor` representing an image binary of arbitrary size.
<span class='lineno'> 178</span>     image_size: image height/width dimension.
<span class='lineno'> 179</span>     crop_padding: the padding size to use when centering the crop.
<span class='lineno'> 180</span> 
<span class='lineno'> 181</span>   Returns:
<span class='lineno'> 182</span>     A decoded and cropped image `Tensor`.
<span class='lineno'> 183</span>   &quot;&quot;&quot;
<span class='lineno'> 184</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.decoded', title='bool'>decoded</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', title='?'>image_bytes</a>.dtype != tf.string
<span class='lineno'> 185</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.shape', title='?'>shape</a> = (tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', title='?'>image_bytes</a>) if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.decoded', title='bool'>decoded</a>
<span class='lineno'> 186</span>            else tf.image.extract_jpeg_shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', title='?'>image_bytes</a>))
<span class='lineno'> 187</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_height', title='?'>image_height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.shape', title='?'>shape</a>[0]
<span class='lineno'> 188</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_width', title='?'>image_width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.shape', title='?'>shape</a>[1]
<span class='lineno'> 189</span> 
<span class='lineno'> 190</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', title='?'>padded_center_crop_size</a> = tf.cast(
<span class='lineno'> 191</span>       ((<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_size', title='int'>image_size</a> / (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_size', title='int'>image_size</a> + <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.crop_padding', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.crop_padding', title='int'>crop_padding</a>)) *
<span class='lineno'> 192</span>        tf.cast(tf.minimum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_height', title='?'>image_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_width', title='?'>image_width</a>), tf.float32)),
<span class='lineno'> 193</span>       tf.int32)
<span class='lineno'> 194</span> 
<span class='lineno'> 195</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_height', title='int'>offset_height</a> = ((<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_height', title='?'>image_height</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', title='?'>padded_center_crop_size</a>) + 1) // 2
<span class='lineno'> 196</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_width', title='int'>offset_width</a> = ((<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_width', title='?'>image_width</a> - <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', title='?'>padded_center_crop_size</a>) + 1) // 2
<span class='lineno'> 197</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.crop_window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.crop_window', title='?'>crop_window</a> = tf.stack([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_height', title='int'>offset_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_width', title='int'>offset_width</a>,
<span class='lineno'> 198</span>                           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', title='?'>padded_center_crop_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', title='?'>padded_center_crop_size</a>])
<span class='lineno'> 199</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.decoded', title='bool'>decoded</a>:
<span class='lineno'> 200</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image', title='?'>image</a> = tf.image.crop_to_bounding_box(
<span class='lineno'> 201</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', title='?'>image_bytes</a>,
<span class='lineno'> 202</span>         offset_height=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_height', title='int'>offset_height</a>,
<span class='lineno'> 203</span>         offset_width=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.offset_width', title='int'>offset_width</a>,
<span class='lineno'> 204</span>         target_height=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', title='?'>padded_center_crop_size</a>,
<span class='lineno'> 205</span>         target_width=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.padded_center_crop_size', title='?'>padded_center_crop_size</a>)
<span class='lineno'> 206</span>   else:
<span class='lineno'> 207</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image', title='?'>image</a> = tf.image.decode_and_crop_jpeg(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_bytes', title='?'>image_bytes</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.crop_window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.crop_window', title='?'>crop_window</a>, channels=3)
<span class='lineno'> 208</span> 
<span class='lineno'> 209</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image', title='(None, int, int) -> None / (?, int, int) -> None'>resize_image</a>(image_bytes=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image', title='?'>image</a>,
<span class='lineno'> 210</span>                        height=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_size', title='int'>image_size</a>,
<span class='lineno'> 211</span>                        width=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image_size', title='int'>image_size</a>)
<span class='lineno'> 212</span> 
<span class='lineno'> 213</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop.image', title='None'>image</a>
<span class='lineno'> 214</span> 
<span class='lineno'> 215</span> 
<span class='lineno'> 216</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip', title='? -> None'>decode_crop_and_flip</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', title='?'>ima</a>ge_bytes: tf.Tensor) -&gt; tf.Tensor:
<span class='lineno'> 217</span>   &quot;&quot;&quot;Crops an image to a random part of the image, then randomly flips.
<span class='lineno'> 218</span> 
<span class='lineno'> 219</span>   Args:
<span class='lineno'> 220</span>     image_bytes: `Tensor` representing an image binary of arbitrary size.
<span class='lineno'> 221</span> 
<span class='lineno'> 222</span>   Returns:
<span class='lineno'> 223</span>     A decoded and cropped image `Tensor`.
<span class='lineno'> 224</span> 
<span class='lineno'> 225</span>   &quot;&quot;&quot;
<span class='lineno'> 226</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.decoded', title='bool'>decoded</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', title='?'>image_bytes</a>.dtype != tf.string
<span class='lineno'> 227</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox', title='?'>bbox</a> = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])
<span class='lineno'> 228</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.shape', title='?'>shape</a> = (tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', title='?'>image_bytes</a>) if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.decoded', title='bool'>decoded</a>
<span class='lineno'> 229</span>            else tf.image.extract_jpeg_shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', title='?'>image_bytes</a>))
<span class='lineno'> 230</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.sample_distorted_bounding_box', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.sample_distorted_bounding_box', title='?'>sample_distorted_bounding_box</a> = tf.image.sample_distorted_bounding_box(
<span class='lineno'> 231</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.shape', title='?'>shape</a>,
<span class='lineno'> 232</span>       bounding_boxes=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox', title='?'>bbox</a>,
<span class='lineno'> 233</span>       min_object_covered=0.1,
<span class='lineno'> 234</span>       aspect_ratio_range=[0.75, 1.33],
<span class='lineno'> 235</span>       area_range=[0.05, 1.0],
<span class='lineno'> 236</span>       max_attempts=100,
<span class='lineno'> 237</span>       use_image_if_no_bounding_boxes=True)
<span class='lineno'> 238</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox_begin', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox_begin', title='?'>bbox_begin</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox_size', title='?'>bbox_size</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip._', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip._', title='?'>_</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.sample_distorted_bounding_box', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.sample_distorted_bounding_box', title='?'>sample_distorted_bounding_box</a>
<span class='lineno'> 239</span> 
<span class='lineno'> 240</span>   # Reassemble the bounding box in the format the crop op requires.
<span class='lineno'> 241</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_height', title='?'>offset_height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_width', title='?'>offset_width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip._', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip._', title='?'>_</a> = tf.unstack(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox_begin', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox_begin', title='?'>bbox_begin</a>)
<span class='lineno'> 242</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_height', title='?'>target_height</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_width', title='?'>target_width</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip._', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip._', title='?'>_</a> = tf.unstack(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.bbox_size', title='?'>bbox_size</a>)
<span class='lineno'> 243</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.crop_window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.crop_window', title='?'>crop_window</a> = tf.stack([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_height', title='?'>offset_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_width', title='?'>offset_width</a>,
<span class='lineno'> 244</span>                           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_height', title='?'>target_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_width', title='?'>target_width</a>])
<span class='lineno'> 245</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.decoded', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.decoded', title='bool'>decoded</a>:
<span class='lineno'> 246</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.cropped', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.cropped', title='?'>cropped</a> = tf.image.crop_to_bounding_box(
<span class='lineno'> 247</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', title='?'>image_bytes</a>,
<span class='lineno'> 248</span>         offset_height=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_height', title='?'>offset_height</a>,
<span class='lineno'> 249</span>         offset_width=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.offset_width', title='?'>offset_width</a>,
<span class='lineno'> 250</span>         target_height=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_height', title='?'>target_height</a>,
<span class='lineno'> 251</span>         target_width=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.target_width', title='?'>target_width</a>)
<span class='lineno'> 252</span>   else:
<span class='lineno'> 253</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.cropped', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.cropped', title='?'>cropped</a> = tf.image.decode_and_crop_jpeg(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.image_bytes', title='?'>image_bytes</a>,
<span class='lineno'> 254</span>                                             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.crop_window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.crop_window', title='?'>crop_window</a>,
<span class='lineno'> 255</span>                                             channels=3)
<span class='lineno'> 256</span> 
<span class='lineno'> 257</span>   # Flip to add a little more random distortion in.
<span class='lineno'> 258</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.cropped', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.cropped', title='?'>cropped</a> = tf.image.random_flip_left_right(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.cropped', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.cropped', title='?'>cropped</a>)
<span class='lineno'> 259</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.cropped', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip.cropped', title='?'>cropped</a>
<span class='lineno'> 260</span> 
<span class='lineno'> 261</span> 
<span class='lineno'> 262</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image', title='(None, int, int) -> None / (?, int, int) -> None'>resize_image</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.image_bytes', title='None'>ima</a>ge_bytes: tf.Tensor,
<span class='lineno'> 263</span>                  <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.height', title='int'>hei</a>ght: int = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', title='int'>IMAGE_SIZE</a>,
<span class='lineno'> 264</span>                  <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.width', title='int'>wid</a>th: int = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', title='int'>IMAGE_SIZE</a>) -&gt; tf.Tensor:
<span class='lineno'> 265</span>   &quot;&quot;&quot;Resizes an image to a given height and width.
<span class='lineno'> 266</span> 
<span class='lineno'> 267</span>   Args:
<span class='lineno'> 268</span>     image_bytes: `Tensor` representing an image binary of arbitrary size.
<span class='lineno'> 269</span>     height: image height dimension.
<span class='lineno'> 270</span>     width: image width dimension.
<span class='lineno'> 271</span> 
<span class='lineno'> 272</span>   Returns:
<span class='lineno'> 273</span>     A tensor containing the resized image.
<span class='lineno'> 274</span> 
<span class='lineno'> 275</span>   &quot;&quot;&quot;
<span class='lineno'> 276</span>   return tf.compat.v1.image.resize(
<span class='lineno'> 277</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.image_bytes', title='None'>image_bytes</a>, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.height', title='int'>height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image.width', title='int'>width</a>], method=tf.image.ResizeMethod.BILINEAR,
<span class='lineno'> 278</span>       align_corners=False)
<span class='lineno'> 279</span> 
<span class='lineno'> 280</span> 
<span class='lineno'> 281</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval', title='(?, int, int, ?, ?, ?) -> None'>preprocess_for_eval</a>(
<span class='lineno'> 282</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_bytes', title='?'>ima</a>ge_bytes: tf.Tensor,
<span class='lineno'> 283</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_size', title='int'>ima</a>ge_size: int = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', title='int'>IMAGE_SIZE</a>,
<span class='lineno'> 284</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.num_channels', title='int'>num</a>_channels: int = 3,
<span class='lineno'> 285</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.mean_subtract', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.mean_subtract', title='?'>mea</a>n_subtract: bool = False,
<span class='lineno'> 286</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.standardize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.standardize', title='?'>sta</a>ndardize: bool = False,
<span class='lineno'> 287</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.dtype', title='?'>dty</a>pe: tf.dtypes.DType = tf.float32
<span class='lineno'> 288</span> ) -&gt; tf.Tensor:
<span class='lineno'> 289</span>   &quot;&quot;&quot;Preprocesses the given image for evaluation.
<span class='lineno'> 290</span> 
<span class='lineno'> 291</span>   Args:
<span class='lineno'> 292</span>     image_bytes: `Tensor` representing an image binary of arbitrary size.
<span class='lineno'> 293</span>     image_size: image height/width dimension.
<span class='lineno'> 294</span>     num_channels: number of image input channels.
<span class='lineno'> 295</span>     mean_subtract: whether or not to apply mean subtraction.
<span class='lineno'> 296</span>     standardize: whether or not to apply standardization.
<span class='lineno'> 297</span>     dtype: the dtype to convert the images to. Set to `None` to skip conversion.
<span class='lineno'> 298</span> 
<span class='lineno'> 299</span>   Returns:
<span class='lineno'> 300</span>     A preprocessed and normalized image `Tensor`.
<span class='lineno'> 301</span>   &quot;&quot;&quot;
<span class='lineno'> 302</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', title='None'>images</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_and_center_crop', title='(?, int, int) -> None'>decode_and_center_crop</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_bytes', title='?'>image_bytes</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_size', title='int'>image_size</a>)
<span class='lineno'> 303</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', title='?'>images</a> = tf.reshape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', title='None'>images</a>, [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_size', title='int'>image_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.image_size', title='int'>image_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.num_channels', title='int'>num_channels</a>])
<span class='lineno'> 304</span> 
<span class='lineno'> 305</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.mean_subtract', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.mean_subtract', title='?'>mean_subtract</a>:
<span class='lineno'> 306</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', title='None'>images</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction', title='(None, (float, float, float), int, ?) -> None / (?, (float, float, float), int, ?) -> None / (?, ?, int, ?) -> None'>mean_image_subtraction</a>(image_bytes=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', title='?'>images</a>, means=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.MEAN_RGB', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.MEAN_RGB', title='(float, float, float)'>MEAN_RGB</a>)
<span class='lineno'> 307</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.standardize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.standardize', title='?'>standardize</a>:
<span class='lineno'> 308</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', title='None'>images</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image', title='(?, ?, int, ?) -> None / (None, (float, float, float), int, ?) -> None'>standardize_image</a>(image_bytes=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', title='None'>images</a>, stddev=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.STDDEV_RGB', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.STDDEV_RGB', title='(float, float, float)'>STDDEV_RGB</a>)
<span class='lineno'> 309</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.dtype', title='?'>dtype</a> is not None:
<span class='lineno'> 310</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', title='?'>images</a> = tf.image.convert_image_dtype(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', title='None'>images</a>, dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.dtype', title='?'>dtype</a>)
<span class='lineno'> 311</span> 
<span class='lineno'> 312</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval.images', title='None'>images</a>
<span class='lineno'> 313</span> 
<span class='lineno'> 314</span> 
<span class='lineno'> 315</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image', title='(?, int) -> None'>load_eval_image</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.filename', title='?'>fil</a>ename: Text, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image_size', title='int'>ima</a>ge_size: int = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', title='int'>IMAGE_SIZE</a>) -&gt; tf.Tensor:
<span class='lineno'> 316</span>   &quot;&quot;&quot;Reads an image from the filesystem and applies image preprocessing.
<span class='lineno'> 317</span> 
<span class='lineno'> 318</span>   Args:
<span class='lineno'> 319</span>     filename: a filename path of an image.
<span class='lineno'> 320</span>     image_size: image height/width dimension.
<span class='lineno'> 321</span> 
<span class='lineno'> 322</span>   Returns:
<span class='lineno'> 323</span>     A preprocessed and normalized image `Tensor`.
<span class='lineno'> 324</span>   &quot;&quot;&quot;
<span class='lineno'> 325</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image_bytes', title='?'>image_bytes</a> = tf.io.read_file(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.filename', title='?'>filename</a>)
<span class='lineno'> 326</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image', title='None'>image</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_eval', title='(?, int, int, ?, ?, ?) -> None'>preprocess_for_eval</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image_bytes', title='?'>image_bytes</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image_size', title='int'>image_size</a>)
<span class='lineno'> 327</span> 
<span class='lineno'> 328</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image.image', title='None'>image</a>
<span class='lineno'> 329</span> 
<span class='lineno'> 330</span> 
<span class='lineno'> 331</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset', title='(?, None, int, int) -> None'>build_eval_dataset</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.filenames', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.filenames', title='?'>fil</a>enames: List[Text],
<span class='lineno'> 332</span>                        <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', title='None'>lab</a>els: List[int] = None,
<span class='lineno'> 333</span>                        <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.image_size', title='int'>ima</a>ge_size: int = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', title='int'>IMAGE_SIZE</a>,
<span class='lineno'> 334</span>                        <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.batch_size', title='int'>bat</a>ch_size: int = 1) -&gt; tf.Tensor:
<span class='lineno'> 335</span>   &quot;&quot;&quot;Builds a tf.data.Dataset from a list of filenames and labels.
<span class='lineno'> 336</span> 
<span class='lineno'> 337</span>   Args:
<span class='lineno'> 338</span>     filenames: a list of filename paths of images.
<span class='lineno'> 339</span>     labels: a list of labels corresponding to each image.
<span class='lineno'> 340</span>     image_size: image height/width dimension.
<span class='lineno'> 341</span>     batch_size: the batch size used by the dataset
<span class='lineno'> 342</span> 
<span class='lineno'> 343</span>   Returns:
<span class='lineno'> 344</span>     A preprocessed and normalized image `Tensor`.
<span class='lineno'> 345</span>   &quot;&quot;&quot;
<span class='lineno'> 346</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', title='None'>labels</a> is None:
<span class='lineno'> 347</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', title='?'>labels</a> = [0] * len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.filenames', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.filenames', title='?'>filenames</a>)
<span class='lineno'> 348</span> 
<span class='lineno'> 349</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.filenames', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.filenames', title='?'>filenames</a> = tf.constant(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.filenames', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.filenames', title='?'>filenames</a>)
<span class='lineno'> 350</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', title='?'>labels</a> = tf.constant(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', title='None'>labels</a>)
<span class='lineno'> 351</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', title='?'>dataset</a> = tf.data.Dataset.from_tensor_slices((<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.filenames', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.filenames', title='?'>filenames</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.labels', title='?'>labels</a>))
<span class='lineno'> 352</span> 
<span class='lineno'> 353</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', title='?'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', title='?'>dataset</a>.map(
<span class='lineno'> 354</span>       lambda <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.lambda%75.filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.lambda%75.filename', title='?'>fil</a>ename, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.lambda%75.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.lambda%75.label', title='?'>lab</a>el: (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.load_eval_image', title='(?, int) -> None'>load_eval_image</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.lambda%75.filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.lambda%75.filename', title='?'>filename</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.image_size', title='int'>image_size</a>), <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.lambda%75.label', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.lambda%75.label', title='?'>label</a>))
<span class='lineno'> 355</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', title='?'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', title='?'>dataset</a>.batch(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.batch_size', title='int'>batch_size</a>)
<span class='lineno'> 356</span> 
<span class='lineno'> 357</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.build_eval_dataset.dataset', title='?'>dataset</a>
<span class='lineno'> 358</span> 
<span class='lineno'> 359</span> 
<span class='lineno'> 360</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train', title='(?, int, None, ?, ?, ?) -> None'>preprocess_for_train</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.image_bytes', title='?'>ima</a>ge_bytes: tf.Tensor,
<span class='lineno'> 361</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.image_size', title='int'>ima</a>ge_size: int = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.IMAGE_SIZE', title='int'>IMAGE_SIZE</a>,
<span class='lineno'> 362</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.augmenter', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.augmenter', title='None'>aug</a>menter: Optional[augment.ImageAugment] = None,
<span class='lineno'> 363</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.mean_subtract', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.mean_subtract', title='?'>mea</a>n_subtract: bool = False,
<span class='lineno'> 364</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.standardize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.standardize', title='?'>sta</a>ndardize: bool = False,
<span class='lineno'> 365</span>                          <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.dtype', title='?'>dty</a>pe: tf.dtypes.DType = tf.float32) -&gt; tf.Tensor:
<span class='lineno'> 366</span>   &quot;&quot;&quot;Preprocesses the given image for training.
<span class='lineno'> 367</span> 
<span class='lineno'> 368</span>   Args:
<span class='lineno'> 369</span>     image_bytes: `Tensor` representing an image binary of
<span class='lineno'> 370</span>       arbitrary size of dtype tf.uint8.
<span class='lineno'> 371</span>     image_size: image height/width dimension.
<span class='lineno'> 372</span>     augmenter: the image augmenter to apply.
<span class='lineno'> 373</span>     mean_subtract: whether or not to apply mean subtraction.
<span class='lineno'> 374</span>     standardize: whether or not to apply standardization.
<span class='lineno'> 375</span>     dtype: the dtype to convert the images to. Set to `None` to skip conversion.
<span class='lineno'> 376</span> 
<span class='lineno'> 377</span>   Returns:
<span class='lineno'> 378</span>     A preprocessed and normalized image `Tensor`.
<span class='lineno'> 379</span>   &quot;&quot;&quot;
<span class='lineno'> 380</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='None'>images</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.decode_crop_and_flip', title='? -> None'>decode_crop_and_flip</a>(image_bytes=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.image_bytes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.image_bytes', title='?'>image_bytes</a>)
<span class='lineno'> 381</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='None'>images</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.resize_image', title='(None, int, int) -> None / (?, int, int) -> None'>resize_image</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='None'>images</a>, height=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.image_size', title='int'>image_size</a>, width=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.image_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.image_size', title='int'>image_size</a>)
<span class='lineno'> 382</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.mean_subtract', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.mean_subtract', title='?'>mean_subtract</a>:
<span class='lineno'> 383</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='None'>images</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.mean_image_subtraction', title='(None, (float, float, float), int, ?) -> None / (?, (float, float, float), int, ?) -> None / (?, ?, int, ?) -> None'>mean_image_subtraction</a>(image_bytes=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='None'>images</a>, means=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.MEAN_RGB', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.MEAN_RGB', title='(float, float, float)'>MEAN_RGB</a>)
<span class='lineno'> 384</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.standardize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.standardize', title='?'>standardize</a>:
<span class='lineno'> 385</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='None'>images</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.standardize_image', title='(?, ?, int, ?) -> None / (None, (float, float, float), int, ?) -> None'>standardize_image</a>(image_bytes=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='None'>images</a>, stddev=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.STDDEV_RGB', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.STDDEV_RGB', title='(float, float, float)'>STDDEV_RGB</a>)
<span class='lineno'> 386</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.augmenter', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.augmenter', title='None'>augmenter</a> is not None:
<span class='lineno'> 387</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='?'>images</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.augmenter', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.augmenter', title='None'>augmenter</a>.distort(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='None'>images</a>)
<span class='lineno'> 388</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.dtype', title='?'>dtype</a> is not None:
<span class='lineno'> 389</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='?'>images</a> = tf.image.convert_image_dtype(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='None'>images</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.dtype', title='?'>dtype</a>)
<span class='lineno'> 390</span> 
<span class='lineno'> 391</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.image_classification.preprocessing.preprocess_for_train.images', title='None'>images</a>
</pre></td></tr></table></body></html>