<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/vision/detection/utils/object_detection/preprocessor.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right'>_flip_boxes_left_right</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_masks_left_right', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_masks_left_right'>_flip_masks_left_right</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal'>keypoint_flip_horizontal</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame'>keypoint_change_coordinate_frame</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window'>keypoint_prune_outside_window</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip'>random_horizontal_flip</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size'>_compute_new_static_size</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size'>_compute_new_dynamic_size</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range'>resize_to_range</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields'>_copy_extra_fields</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale'>box_list_scale</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale'>keypoint_scale</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates', xid='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates'>scale_boxes_to_pixel_coordinates</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2017 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> &quot;&quot;&quot;Preprocess images and bounding boxes for detection.
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span> We perform two sets of operations in preprocessing stage:
<span class='lineno'>  18</span> (a) operations that are applied to both training and testing data,
<span class='lineno'>  19</span> (b) operations that are applied only to training data for the purpose of
<span class='lineno'>  20</span>     data augmentation.
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> A preprocessing function receives a set of inputs,
<span class='lineno'>  23</span> e.g. an image and bounding boxes,
<span class='lineno'>  24</span> performs an operation on them, and returns them.
<span class='lineno'>  25</span> Some examples are: randomly cropping the image, randomly mirroring the image,
<span class='lineno'>  26</span>                    randomly changing the brightness, contrast, hue and
<span class='lineno'>  27</span>                    randomly jittering the bounding boxes.
<span class='lineno'>  28</span> 
<span class='lineno'>  29</span> The image is a rank 4 tensor: [1, height, width, channels] with
<span class='lineno'>  30</span> dtype=tf.float32. The groundtruth_boxes is a rank 2 tensor: [N, 4] where
<span class='lineno'>  31</span> in each row there is a box with [ymin xmin ymax xmax].
<span class='lineno'>  32</span> Boxes are in normalized coordinates meaning
<span class='lineno'>  33</span> their coordinate values range in [0, 1]
<span class='lineno'>  34</span> 
<span class='lineno'>  35</span> Important Note: In tensor_dict, images is a rank 4 tensor, but preprocessing
<span class='lineno'>  36</span> functions receive a rank 3 tensor for processing the image. Thus, inside the
<span class='lineno'>  37</span> preprocess function we squeeze the image to become a rank 3 tensor and then
<span class='lineno'>  38</span> we pass it to the functions. At the end of the preprocess we expand the image
<span class='lineno'>  39</span> back to rank 4.
<span class='lineno'>  40</span> &quot;&quot;&quot;
<span class='lineno'>  41</span> 
<span class='lineno'>  42</span> import tensorflow as tf
<span class='lineno'>  43</span> 
<span class='lineno'>  44</span> import numpy as np
<span class='lineno'>  45</span> 
<span class='lineno'>  46</span> from official.vision.detection.utils.object_detection import box_list
<span class='lineno'>  47</span> 
<span class='lineno'>  48</span> 
<span class='lineno'>  49</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right', title='None -> None / ? -> None'>_flip_boxes_left_right</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.boxes', title='None'>boxes</a>):
<span class='lineno'>  50</span>   &quot;&quot;&quot;Left-right flip the boxes.
<span class='lineno'>  51</span> 
<span class='lineno'>  52</span>   Args:
<span class='lineno'>  53</span>     boxes: rank 2 float32 tensor containing the bounding boxes -&gt; [N, 4].
<span class='lineno'>  54</span>            Boxes are in normalized form meaning their coordinates vary
<span class='lineno'>  55</span>            between [0, 1].
<span class='lineno'>  56</span>            Each row is in the form of [ymin, xmin, ymax, xmax].
<span class='lineno'>  57</span> 
<span class='lineno'>  58</span>   Returns:
<span class='lineno'>  59</span>     Flipped boxes.
<span class='lineno'>  60</span>   &quot;&quot;&quot;
<span class='lineno'>  61</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.ymin', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.ymin', title='?'>ymin</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.xmin', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.xmin', title='?'>xmin</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.ymax', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.ymax', title='?'>ymax</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.xmax', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.xmax', title='?'>xmax</a> = tf.split(value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.boxes', title='None'>boxes</a>, num_or_size_splits=4, axis=1)
<span class='lineno'>  62</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_xmin', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_xmin', title='?'>flipped_xmin</a> = tf.subtract(1.0, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.xmax', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.xmax', title='?'>xmax</a>)
<span class='lineno'>  63</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_xmax', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_xmax', title='?'>flipped_xmax</a> = tf.subtract(1.0, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.xmin', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.xmin', title='?'>xmin</a>)
<span class='lineno'>  64</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_boxes', title='?'>flipped_boxes</a> = tf.concat([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.ymin', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.ymin', title='?'>ymin</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_xmin', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_xmin', title='?'>flipped_xmin</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.ymax', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.ymax', title='?'>ymax</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_xmax', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_xmax', title='?'>flipped_xmax</a>], 1)
<span class='lineno'>  65</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right.flipped_boxes', title='?'>flipped_boxes</a>
<span class='lineno'>  66</span> 
<span class='lineno'>  67</span> 
<span class='lineno'>  68</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_masks_left_right', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_masks_left_right', title='None -> None / ? -> None'>_flip_masks_left_right</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_masks_left_right.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_masks_left_right.masks', title='None'>masks</a>):
<span class='lineno'>  69</span>   &quot;&quot;&quot;Left-right flip masks.
<span class='lineno'>  70</span> 
<span class='lineno'>  71</span>   Args:
<span class='lineno'>  72</span>     masks: rank 3 float32 tensor with shape
<span class='lineno'>  73</span>       [num_instances, height, width] representing instance masks.
<span class='lineno'>  74</span> 
<span class='lineno'>  75</span>   Returns:
<span class='lineno'>  76</span>     flipped masks: rank 3 float32 tensor with shape
<span class='lineno'>  77</span>       [num_instances, height, width] representing instance masks.
<span class='lineno'>  78</span>   &quot;&quot;&quot;
<span class='lineno'>  79</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_masks_left_right.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_masks_left_right.masks', title='None'>masks</a>[:, :, ::-1]
<span class='lineno'>  80</span> 
<span class='lineno'>  81</span> 
<span class='lineno'>  82</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal', title='(None, float, None, None) -> None / (?, ?, ?, None) -> None'>keypoint_flip_horizontal</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', title='None'>keypoints</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.flip_point', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.flip_point', title='float'>flip_point</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.flip_permutation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.flip_permutation', title='None'>flip_permutation</a>,
<span class='lineno'>  83</span>                              <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.scope', title='None'>scope</a>=None):
<span class='lineno'>  84</span>   &quot;&quot;&quot;Flips the keypoints horizontally around the flip_point.
<span class='lineno'>  85</span> 
<span class='lineno'>  86</span>   This operation flips the x coordinate for each keypoint around the flip_point
<span class='lineno'>  87</span>   and also permutes the keypoints in a manner specified by flip_permutation.
<span class='lineno'>  88</span> 
<span class='lineno'>  89</span>   Args:
<span class='lineno'>  90</span>     keypoints: a tensor of shape [num_instances, num_keypoints, 2]
<span class='lineno'>  91</span>     flip_point:  (float) scalar tensor representing the x coordinate to flip the
<span class='lineno'>  92</span>       keypoints around.
<span class='lineno'>  93</span>     flip_permutation: rank 1 int32 tensor containing the keypoint flip
<span class='lineno'>  94</span>       permutation. This specifies the mapping from original keypoint indices
<span class='lineno'>  95</span>       to the flipped keypoint indices. This is used primarily for keypoints
<span class='lineno'>  96</span>       that are not reflection invariant. E.g. Suppose there are 3 keypoints
<span class='lineno'>  97</span>       representing [&#39;head&#39;, &#39;right_eye&#39;, &#39;left_eye&#39;], then a logical choice for
<span class='lineno'>  98</span>       flip_permutation might be [0, 2, 1] since we want to swap the &#39;left_eye&#39;
<span class='lineno'>  99</span>       and &#39;right_eye&#39; after a horizontal flip.
<span class='lineno'> 100</span>     scope: name scope.
<span class='lineno'> 101</span> 
<span class='lineno'> 102</span>   Returns:
<span class='lineno'> 103</span>     new_keypoints: a tensor of shape [num_instances, num_keypoints, 2]
<span class='lineno'> 104</span>   &quot;&quot;&quot;
<span class='lineno'> 105</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.scope', title='None'>scope</a>:
<span class='lineno'> 106</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.scope', title='str'>scope</a> = &#39;FlipHorizontal&#39;
<span class='lineno'> 107</span>   with tf.name_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.scope', title='str'>scope</a>):
<span class='lineno'> 108</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', title='?'>keypoints</a> = tf.transpose(a=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', title='None'>keypoints</a>, perm=[1, 0, 2])
<span class='lineno'> 109</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', title='?'>keypoints</a> = tf.gather(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', title='?'>keypoints</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.flip_permutation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.flip_permutation', title='None'>flip_permutation</a>)
<span class='lineno'> 110</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.v', title='?'>v</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.u', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.u', title='?'>u</a> = tf.split(value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.keypoints', title='?'>keypoints</a>, num_or_size_splits=2, axis=2)
<span class='lineno'> 111</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.u', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.u', title='float'>u</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.flip_point', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.flip_point', title='float'>flip_point</a> * 2.0 - <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.u', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.u', title='?'>u</a>
<span class='lineno'> 112</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.new_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.new_keypoints', title='?'>new_keypoints</a> = tf.concat([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.v', title='?'>v</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.u', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.u', title='float'>u</a>], 2)
<span class='lineno'> 113</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.new_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.new_keypoints', title='?'>new_keypoints</a> = tf.transpose(a=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.new_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.new_keypoints', title='?'>new_keypoints</a>, perm=[1, 0, 2])
<span class='lineno'> 114</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.new_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal.new_keypoints', title='?'>new_keypoints</a>
<span class='lineno'> 115</span> 
<span class='lineno'> 116</span> 
<span class='lineno'> 117</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame', title='(?, ?, None) -> None'>keypoint_change_coordinate_frame</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.keypoints', title='?'>keypoints</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', title='?'>window</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.scope', title='None'>scope</a>=None):
<span class='lineno'> 118</span>   &quot;&quot;&quot;Changes coordinate frame of the keypoints to be relative to window&#39;s frame.
<span class='lineno'> 119</span> 
<span class='lineno'> 120</span>   Given a window of the form [y_min, x_min, y_max, x_max], changes keypoint
<span class='lineno'> 121</span>   coordinates from keypoints of shape [num_instances, num_keypoints, 2]
<span class='lineno'> 122</span>   to be relative to this window.
<span class='lineno'> 123</span> 
<span class='lineno'> 124</span>   An example use case is data augmentation: where we are given groundtruth
<span class='lineno'> 125</span>   keypoints and would like to randomly crop the image to some window. In this
<span class='lineno'> 126</span>   case we need to change the coordinate frame of each groundtruth keypoint to be
<span class='lineno'> 127</span>   relative to this new window.
<span class='lineno'> 128</span> 
<span class='lineno'> 129</span>   Args:
<span class='lineno'> 130</span>     keypoints: a tensor of shape [num_instances, num_keypoints, 2]
<span class='lineno'> 131</span>     window: a tensor of shape [4] representing the [y_min, x_min, y_max, x_max]
<span class='lineno'> 132</span>       window we should change the coordinate frame to.
<span class='lineno'> 133</span>     scope: name scope.
<span class='lineno'> 134</span> 
<span class='lineno'> 135</span>   Returns:
<span class='lineno'> 136</span>     new_keypoints: a tensor of shape [num_instances, num_keypoints, 2]
<span class='lineno'> 137</span>   &quot;&quot;&quot;
<span class='lineno'> 138</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.scope', title='None'>scope</a>:
<span class='lineno'> 139</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.scope', title='str'>scope</a> = &#39;ChangeCoordinateFrame&#39;
<span class='lineno'> 140</span>   with tf.name_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.scope', title='str'>scope</a>):
<span class='lineno'> 141</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.win_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.win_height', title='?'>win_height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', title='?'>window</a>[2] - <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', title='?'>window</a>[0]
<span class='lineno'> 142</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.win_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.win_width', title='?'>win_width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', title='?'>window</a>[3] - <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', title='?'>window</a>[1]
<span class='lineno'> 143</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.new_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.new_keypoints', title='?'>new_keypoints</a> = box_list_ops.scale(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.keypoints', title='?'>keypoints</a> - [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', title='?'>window</a>[0], <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.window', title='?'>window</a>[1]],
<span class='lineno'> 144</span>                                        1.0 / <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.win_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.win_height', title='?'>win_height</a>, 1.0 / <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.win_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.win_width', title='?'>win_width</a>)
<span class='lineno'> 145</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.new_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_change_coordinate_frame.new_keypoints', title='?'>new_keypoints</a>
<span class='lineno'> 146</span> 
<span class='lineno'> 147</span> 
<span class='lineno'> 148</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window', title='(?, ?, None) -> None'>keypoint_prune_outside_window</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.keypoints', title='?'>keypoints</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.window', title='?'>window</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.scope', title='None'>scope</a>=None):
<span class='lineno'> 149</span>   &quot;&quot;&quot;Prunes keypoints that fall outside a given window.
<span class='lineno'> 150</span> 
<span class='lineno'> 151</span>   This function replaces keypoints that fall outside the given window with nan.
<span class='lineno'> 152</span>   See also clip_to_window which clips any keypoints that fall outside the given
<span class='lineno'> 153</span>   window.
<span class='lineno'> 154</span> 
<span class='lineno'> 155</span>   Args:
<span class='lineno'> 156</span>     keypoints: a tensor of shape [num_instances, num_keypoints, 2]
<span class='lineno'> 157</span>     window: a tensor of shape [4] representing the [y_min, x_min, y_max, x_max]
<span class='lineno'> 158</span>       window outside of which the op should prune the keypoints.
<span class='lineno'> 159</span>     scope: name scope.
<span class='lineno'> 160</span> 
<span class='lineno'> 161</span>   Returns:
<span class='lineno'> 162</span>     new_keypoints: a tensor of shape [num_instances, num_keypoints, 2]
<span class='lineno'> 163</span>   &quot;&quot;&quot;
<span class='lineno'> 164</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.scope', title='None'>scope</a>:
<span class='lineno'> 165</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.scope', title='str'>scope</a> = &#39;PruneOutsideWindow&#39;
<span class='lineno'> 166</span>   with tf.name_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.scope', title='str'>scope</a>):
<span class='lineno'> 167</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.y', title='?'>y</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.x', title='?'>x</a> = tf.split(value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.keypoints', title='?'>keypoints</a>, num_or_size_splits=2, axis=2)
<span class='lineno'> 168</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_y_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_y_min', title='?'>win_y_min</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_x_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_x_min', title='?'>win_x_min</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_y_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_y_max', title='?'>win_y_max</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_x_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_x_max', title='?'>win_x_max</a> = tf.unstack(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.window', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.window', title='?'>window</a>)
<span class='lineno'> 169</span> 
<span class='lineno'> 170</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.valid_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.valid_indices', title='?'>valid_indices</a> = tf.logical_and(
<span class='lineno'> 171</span>         tf.logical_and(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.y', title='?'>y</a> &gt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_y_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_y_min', title='?'>win_y_min</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.y', title='?'>y</a> &lt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_y_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_y_max', title='?'>win_y_max</a>),
<span class='lineno'> 172</span>         tf.logical_and(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.x', title='?'>x</a> &gt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_x_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_x_min', title='?'>win_x_min</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.x', title='?'>x</a> &lt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_x_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.win_x_max', title='?'>win_x_max</a>))
<span class='lineno'> 173</span> 
<span class='lineno'> 174</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_y', title='?'>new_y</a> = tf.where(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.valid_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.valid_indices', title='?'>valid_indices</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.y', title='?'>y</a>, np.nan * tf.ones_like(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.y', title='?'>y</a>))
<span class='lineno'> 175</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_x', title='?'>new_x</a> = tf.where(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.valid_indices', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.valid_indices', title='?'>valid_indices</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.x', title='?'>x</a>, np.nan * tf.ones_like(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.x', title='?'>x</a>))
<span class='lineno'> 176</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_keypoints', title='?'>new_keypoints</a> = tf.concat([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_y', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_y', title='?'>new_y</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_x', title='?'>new_x</a>], 2)
<span class='lineno'> 177</span> 
<span class='lineno'> 178</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_prune_outside_window.new_keypoints', title='?'>new_keypoints</a>
<span class='lineno'> 179</span> 
<span class='lineno'> 180</span> 
<span class='lineno'> 181</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip', title='(?, None, None, None, None, None) -> tuple'>random_horizontal_flip</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.image', title='?'>image</a>,
<span class='lineno'> 182</span>                            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', title='None'>boxes</a>=None,
<span class='lineno'> 183</span>                            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', title='None'>masks</a>=None,
<span class='lineno'> 184</span>                            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', title='None'>keypoints</a>=None,
<span class='lineno'> 185</span>                            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoint_flip_permutation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoint_flip_permutation', title='None'>keypoint_flip_permutation</a>=None,
<span class='lineno'> 186</span>                            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.seed', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.seed', title='None'>seed</a>=None):
<span class='lineno'> 187</span>   &quot;&quot;&quot;Randomly flips the image and detections horizontally.
<span class='lineno'> 188</span> 
<span class='lineno'> 189</span>   The probability of flipping the image is 50%.
<span class='lineno'> 190</span> 
<span class='lineno'> 191</span>   Args:
<span class='lineno'> 192</span>     image: rank 3 float32 tensor with shape [height, width, channels].
<span class='lineno'> 193</span>     boxes: (optional) rank 2 float32 tensor with shape [N, 4]
<span class='lineno'> 194</span>            containing the bounding boxes.
<span class='lineno'> 195</span>            Boxes are in normalized form meaning their coordinates vary
<span class='lineno'> 196</span>            between [0, 1].
<span class='lineno'> 197</span>            Each row is in the form of [ymin, xmin, ymax, xmax].
<span class='lineno'> 198</span>     masks: (optional) rank 3 float32 tensor with shape
<span class='lineno'> 199</span>            [num_instances, height, width] containing instance masks. The masks
<span class='lineno'> 200</span>            are of the same height, width as the input `image`.
<span class='lineno'> 201</span>     keypoints: (optional) rank 3 float32 tensor with shape
<span class='lineno'> 202</span>                [num_instances, num_keypoints, 2]. The keypoints are in y-x
<span class='lineno'> 203</span>                normalized coordinates.
<span class='lineno'> 204</span>     keypoint_flip_permutation: rank 1 int32 tensor containing the keypoint flip
<span class='lineno'> 205</span>                                permutation.
<span class='lineno'> 206</span>     seed: random seed
<span class='lineno'> 207</span> 
<span class='lineno'> 208</span>   Returns:
<span class='lineno'> 209</span>     image: image which is the same shape as input image.
<span class='lineno'> 210</span> 
<span class='lineno'> 211</span>     If boxes, masks, keypoints, and keypoint_flip_permutation are not None,
<span class='lineno'> 212</span>     the function also returns the following tensors.
<span class='lineno'> 213</span> 
<span class='lineno'> 214</span>     boxes: rank 2 float32 tensor containing the bounding boxes -&gt; [N, 4].
<span class='lineno'> 215</span>            Boxes are in normalized form meaning their coordinates vary
<span class='lineno'> 216</span>            between [0, 1].
<span class='lineno'> 217</span>     masks: rank 3 float32 tensor with shape [num_instances, height, width]
<span class='lineno'> 218</span>            containing instance masks.
<span class='lineno'> 219</span>     keypoints: rank 3 float32 tensor with shape
<span class='lineno'> 220</span>                [num_instances, num_keypoints, 2]
<span class='lineno'> 221</span> 
<span class='lineno'> 222</span>   Raises:
<span class='lineno'> 223</span>     ValueError: if keypoints are provided but keypoint_flip_permutation is not.
<span class='lineno'> 224</span>   &quot;&quot;&quot;
<span class='lineno'> 225</span> 
<span class='lineno'> 226</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image', title='? -> None'>_flip_image</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image.image', title='?'>image</a>):
<span class='lineno'> 227</span>     # flip image
<span class='lineno'> 228</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image.image_flipped', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image.image_flipped', title='?'>image_flipped</a> = tf.image.flip_left_right(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image.image', title='?'>image</a>)
<span class='lineno'> 229</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image.image_flipped', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image.image_flipped', title='?'>image_flipped</a>
<span class='lineno'> 230</span> 
<span class='lineno'> 231</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', title='None'>keypoints</a> is not None and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoint_flip_permutation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoint_flip_permutation', title='None'>keypoint_flip_permutation</a> is None:
<span class='lineno'> 232</span>     raise ValueError(
<span class='lineno'> 233</span>         &#39;keypoints are provided but keypoints_flip_permutation is not provided&#39;)
<span class='lineno'> 234</span> 
<span class='lineno'> 235</span>   with tf.name_scope(&#39;RandomHorizontalFlip&#39;):
<span class='lineno'> 236</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', title='[?]'>result</a> = []
<span class='lineno'> 237</span>     # random variable defining whether to do flip or not
<span class='lineno'> 238</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.do_a_flip_random', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.do_a_flip_random', title='?'>do_a_flip_random</a> = tf.greater(tf.random.uniform([], seed=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.seed', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.seed', title='None'>seed</a>), 0.5)
<span class='lineno'> 239</span> 
<span class='lineno'> 240</span>     # flip image
<span class='lineno'> 241</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.image', title='?'>image</a> = tf.cond(
<span class='lineno'> 242</span>         pred=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.do_a_flip_random', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.do_a_flip_random', title='?'>do_a_flip_random</a>,
<span class='lineno'> 243</span>         true_fn=lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip._flip_image', title='? -> None'>_flip_image</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.image', title='?'>image</a>),
<span class='lineno'> 244</span>         false_fn=lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.image', title='?'>image</a>)
<span class='lineno'> 245</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', title='[?]'>result</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.image', title='?'>image</a>)
<span class='lineno'> 246</span> 
<span class='lineno'> 247</span>     # flip boxes
<span class='lineno'> 248</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', title='None'>boxes</a> is not None:
<span class='lineno'> 249</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', title='?'>boxes</a> = tf.cond(
<span class='lineno'> 250</span>           pred=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.do_a_flip_random', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.do_a_flip_random', title='?'>do_a_flip_random</a>,
<span class='lineno'> 251</span>           true_fn=lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_boxes_left_right', title='None -> None / ? -> None'>_flip_boxes_left_right</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', title='None'>boxes</a>),
<span class='lineno'> 252</span>           false_fn=lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', title='None'>boxes</a>)
<span class='lineno'> 253</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', title='[?]'>result</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.boxes', title='?'>boxes</a>)
<span class='lineno'> 254</span> 
<span class='lineno'> 255</span>     # flip masks
<span class='lineno'> 256</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', title='None'>masks</a> is not None:
<span class='lineno'> 257</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', title='?'>masks</a> = tf.cond(
<span class='lineno'> 258</span>           pred=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.do_a_flip_random', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.do_a_flip_random', title='?'>do_a_flip_random</a>,
<span class='lineno'> 259</span>           true_fn=lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_masks_left_right', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._flip_masks_left_right', title='None -> None / ? -> None'>_flip_masks_left_right</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', title='None'>masks</a>),
<span class='lineno'> 260</span>           false_fn=lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', title='None'>masks</a>)
<span class='lineno'> 261</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', title='[?]'>result</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.masks', title='?'>masks</a>)
<span class='lineno'> 262</span> 
<span class='lineno'> 263</span>     # flip keypoints
<span class='lineno'> 264</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', title='None'>keypoints</a> is not None and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoint_flip_permutation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoint_flip_permutation', title='None'>keypoint_flip_permutation</a> is not None:
<span class='lineno'> 265</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.permutation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.permutation', title='None'>permutation</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoint_flip_permutation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoint_flip_permutation', title='None'>keypoint_flip_permutation</a>
<span class='lineno'> 266</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', title='?'>keypoints</a> = tf.cond(
<span class='lineno'> 267</span>           pred=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.do_a_flip_random', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.do_a_flip_random', title='?'>do_a_flip_random</a>,
<span class='lineno'> 268</span>           true_fn=lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_flip_horizontal', title='(None, float, None, None) -> None / (?, ?, ?, None) -> None'>keypoint_flip_horizontal</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', title='None'>keypoints</a>, 0.5, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.permutation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.permutation', title='None'>permutation</a>),
<span class='lineno'> 269</span>           false_fn=lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', title='None'>keypoints</a>)
<span class='lineno'> 270</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', title='[?]'>result</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.keypoints', title='?'>keypoints</a>)
<span class='lineno'> 271</span> 
<span class='lineno'> 272</span>     return tuple(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.random_horizontal_flip.result', title='[?]'>result</a>)
<span class='lineno'> 273</span> 
<span class='lineno'> 274</span> 
<span class='lineno'> 275</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size', title='(?, None, None) -> None / (?, ?, ?) -> None'>_compute_new_static_size</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.min_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.min_dimension', title='None'>min_dimension</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.max_dimension', title='None'>max_dimension</a>):
<span class='lineno'> 276</span>   &quot;&quot;&quot;Compute new static shape for resize_to_range method.&quot;&quot;&quot;
<span class='lineno'> 277</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image_shape', title='?'>image_shape</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image', title='?'>image</a>.get_shape().as_list()
<span class='lineno'> 278</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_height', title='?'>orig_height</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image_shape', title='?'>image_shape</a>[0]
<span class='lineno'> 279</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_width', title='?'>orig_width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image_shape', title='?'>image_shape</a>[1]
<span class='lineno'> 280</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.num_channels', title='?'>num_channels</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.image_shape', title='?'>image_shape</a>[2]
<span class='lineno'> 281</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_min_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_min_dim', title='int'>orig_min_dim</a> = min(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_height', title='?'>orig_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_width', title='?'>orig_width</a>)
<span class='lineno'> 282</span>   # Calculates the larger of the possible sizes
<span class='lineno'> 283</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_scale_factor', title='float'>large_scale_factor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.min_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.min_dimension', title='None'>min_dimension</a> / float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_min_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_min_dim', title='int'>orig_min_dim</a>)
<span class='lineno'> 284</span>   # Scaling orig_(height|width) by large_scale_factor will make the smaller
<span class='lineno'> 285</span>   # dimension equal to min_dimension, save for floating point rounding errors.
<span class='lineno'> 286</span>   # For reasonably-sized images, taking the nearest integer will reliably
<span class='lineno'> 287</span>   # eliminate this error.
<span class='lineno'> 288</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_height', title='int'>large_height</a> = int(round(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_height', title='?'>orig_height</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_scale_factor', title='float'>large_scale_factor</a>))
<span class='lineno'> 289</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_width', title='int'>large_width</a> = int(round(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_width', title='?'>orig_width</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_scale_factor', title='float'>large_scale_factor</a>))
<span class='lineno'> 290</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_size', title='[int]'>large_size</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_height', title='int'>large_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_width', title='int'>large_width</a>]
<span class='lineno'> 291</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.max_dimension', title='None'>max_dimension</a>:
<span class='lineno'> 292</span>     # Calculates the smaller of the possible sizes, use that if the larger
<span class='lineno'> 293</span>     # is too big.
<span class='lineno'> 294</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_max_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_max_dim', title='int'>orig_max_dim</a> = max(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_height', title='?'>orig_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_width', title='?'>orig_width</a>)
<span class='lineno'> 295</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_scale_factor', title='float'>small_scale_factor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.max_dimension', title='None'>max_dimension</a> / float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_max_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_max_dim', title='int'>orig_max_dim</a>)
<span class='lineno'> 296</span>     # Scaling orig_(height|width) by small_scale_factor will make the larger
<span class='lineno'> 297</span>     # dimension equal to max_dimension, save for floating point rounding
<span class='lineno'> 298</span>     # errors. For reasonably-sized images, taking the nearest integer will
<span class='lineno'> 299</span>     # reliably eliminate this error.
<span class='lineno'> 300</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_height', title='int'>small_height</a> = int(round(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_height', title='?'>orig_height</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_scale_factor', title='float'>small_scale_factor</a>))
<span class='lineno'> 301</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_width', title='int'>small_width</a> = int(round(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.orig_width', title='?'>orig_width</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_scale_factor', title='float'>small_scale_factor</a>))
<span class='lineno'> 302</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_size', title='[int]'>small_size</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_height', title='int'>small_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_width', title='int'>small_width</a>]
<span class='lineno'> 303</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.new_size', title='[int]'>new_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_size', title='[int]'>large_size</a>
<span class='lineno'> 304</span>     if max(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_size', title='[int]'>large_size</a>) &gt; <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.max_dimension', title='None'>max_dimension</a>:
<span class='lineno'> 305</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.new_size', title='[int]'>new_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.small_size', title='[int]'>small_size</a>
<span class='lineno'> 306</span>   else:
<span class='lineno'> 307</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.new_size', title='[int]'>new_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.large_size', title='[int]'>large_size</a>
<span class='lineno'> 308</span>   return tf.constant(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.new_size', title='[int]'>new_size</a> + [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size.num_channels', title='?'>num_channels</a>])
<span class='lineno'> 309</span> 
<span class='lineno'> 310</span> 
<span class='lineno'> 311</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size', title='(?, None, None) -> None / (?, ?, ?) -> None'>_compute_new_dynamic_size</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.min_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.min_dimension', title='None'>min_dimension</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', title='None'>max_dimension</a>):
<span class='lineno'> 312</span>   &quot;&quot;&quot;Compute new dynamic shape for resize_to_range method.&quot;&quot;&quot;
<span class='lineno'> 313</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image_shape', title='?'>image_shape</a> = tf.shape(input=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image', title='?'>image</a>)
<span class='lineno'> 314</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_height', title='?'>orig_height</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image_shape', title='?'>image_shape</a>[0], dtype=tf.float32)
<span class='lineno'> 315</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_width', title='?'>orig_width</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image_shape', title='?'>image_shape</a>[1], dtype=tf.float32)
<span class='lineno'> 316</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.num_channels', title='?'>num_channels</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.image_shape', title='?'>image_shape</a>[2]
<span class='lineno'> 317</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_min_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_min_dim', title='?'>orig_min_dim</a> = tf.minimum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_height', title='?'>orig_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_width', title='?'>orig_width</a>)
<span class='lineno'> 318</span>   # Calculates the larger of the possible sizes
<span class='lineno'> 319</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.min_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.min_dimension', title='?'>min_dimension</a> = tf.constant(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.min_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.min_dimension', title='None'>min_dimension</a>, dtype=tf.float32)
<span class='lineno'> 320</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_scale_factor', title='?'>large_scale_factor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.min_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.min_dimension', title='?'>min_dimension</a> / <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_min_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_min_dim', title='?'>orig_min_dim</a>
<span class='lineno'> 321</span>   # Scaling orig_(height|width) by large_scale_factor will make the smaller
<span class='lineno'> 322</span>   # dimension equal to min_dimension, save for floating point rounding errors.
<span class='lineno'> 323</span>   # For reasonably-sized images, taking the nearest integer will reliably
<span class='lineno'> 324</span>   # eliminate this error.
<span class='lineno'> 325</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_height', title='?'>large_height</a> = tf.cast(
<span class='lineno'> 326</span>       tf.round(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_height', title='?'>orig_height</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_scale_factor', title='?'>large_scale_factor</a>), dtype=tf.int32)
<span class='lineno'> 327</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_width', title='?'>large_width</a> = tf.cast(
<span class='lineno'> 328</span>       tf.round(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_width', title='?'>orig_width</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_scale_factor', title='?'>large_scale_factor</a>), dtype=tf.int32)
<span class='lineno'> 329</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_size', title='?'>large_size</a> = tf.stack([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_height', title='?'>large_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_width', title='?'>large_width</a>])
<span class='lineno'> 330</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', title='None'>max_dimension</a>:
<span class='lineno'> 331</span>     # Calculates the smaller of the possible sizes, use that if the larger
<span class='lineno'> 332</span>     # is too big.
<span class='lineno'> 333</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_max_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_max_dim', title='?'>orig_max_dim</a> = tf.maximum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_height', title='?'>orig_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_width', title='?'>orig_width</a>)
<span class='lineno'> 334</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', title='?'>max_dimension</a> = tf.constant(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', title='None'>max_dimension</a>, dtype=tf.float32)
<span class='lineno'> 335</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_scale_factor', title='?'>small_scale_factor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', title='?'>max_dimension</a> / <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_max_dim', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_max_dim', title='?'>orig_max_dim</a>
<span class='lineno'> 336</span>     # Scaling orig_(height|width) by small_scale_factor will make the larger
<span class='lineno'> 337</span>     # dimension equal to max_dimension, save for floating point rounding
<span class='lineno'> 338</span>     # errors. For reasonably-sized images, taking the nearest integer will
<span class='lineno'> 339</span>     # reliably eliminate this error.
<span class='lineno'> 340</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_height', title='?'>small_height</a> = tf.cast(
<span class='lineno'> 341</span>         tf.round(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_height', title='?'>orig_height</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_scale_factor', title='?'>small_scale_factor</a>), dtype=tf.int32)
<span class='lineno'> 342</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_width', title='?'>small_width</a> = tf.cast(
<span class='lineno'> 343</span>         tf.round(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.orig_width', title='?'>orig_width</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_scale_factor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_scale_factor', title='?'>small_scale_factor</a>), dtype=tf.int32)
<span class='lineno'> 344</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_size', title='?'>small_size</a> = tf.stack([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_height', title='?'>small_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_width', title='?'>small_width</a>])
<span class='lineno'> 345</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.new_size', title='?'>new_size</a> = tf.cond(
<span class='lineno'> 346</span>         pred=tf.cast(tf.reduce_max(input_tensor=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_size', title='?'>large_size</a>), dtype=tf.float32) &gt;
<span class='lineno'> 347</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.max_dimension', title='?'>max_dimension</a>,
<span class='lineno'> 348</span>         true_fn=lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.small_size', title='?'>small_size</a>,
<span class='lineno'> 349</span>         false_fn=lambda: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_size', title='?'>large_size</a>)
<span class='lineno'> 350</span>   else:
<span class='lineno'> 351</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.new_size', title='?'>new_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.large_size', title='?'>large_size</a>
<span class='lineno'> 352</span>   return tf.stack(tf.unstack(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.new_size', title='?'>new_size</a>) + [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.num_channels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size.num_channels', title='?'>num_channels</a>])
<span class='lineno'> 353</span> 
<span class='lineno'> 354</span> 
<span class='lineno'> 355</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range', title='(?, None, None, None, ?, bool, bool) -> [None]'>resize_to_range</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', title='?'>image</a>,
<span class='lineno'> 356</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.masks', title='None'>masks</a>=None,
<span class='lineno'> 357</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.min_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.min_dimension', title='None'>min_dimension</a>=None,
<span class='lineno'> 358</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', title='None'>max_dimension</a>=None,
<span class='lineno'> 359</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.method', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.method', title='?'>method</a>=tf.image.ResizeMethod.BILINEAR,
<span class='lineno'> 360</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.align_corners', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.align_corners', title='bool'>align_corners</a>=False,
<span class='lineno'> 361</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.pad_to_max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.pad_to_max_dimension', title='bool'>pad_to_max_dimension</a>=False):
<span class='lineno'> 362</span>   &quot;&quot;&quot;Resizes an image so its dimensions are within the provided value.
<span class='lineno'> 363</span> 
<span class='lineno'> 364</span>   The output size can be described by two cases:
<span class='lineno'> 365</span>   1. If the image can be rescaled so its minimum dimension is equal to the
<span class='lineno'> 366</span>      provided value without the other dimension exceeding max_dimension,
<span class='lineno'> 367</span>      then do so.
<span class='lineno'> 368</span>   2. Otherwise, resize so the largest dimension is equal to max_dimension.
<span class='lineno'> 369</span> 
<span class='lineno'> 370</span>   Args:
<span class='lineno'> 371</span>     image: A 3D tensor of shape [height, width, channels]
<span class='lineno'> 372</span>     masks: (optional) rank 3 float32 tensor with shape
<span class='lineno'> 373</span>            [num_instances, height, width] containing instance masks.
<span class='lineno'> 374</span>     min_dimension: (optional) (scalar) desired size of the smaller image
<span class='lineno'> 375</span>                    dimension.
<span class='lineno'> 376</span>     max_dimension: (optional) (scalar) maximum allowed size
<span class='lineno'> 377</span>                    of the larger image dimension.
<span class='lineno'> 378</span>     method: (optional) interpolation method used in resizing. Defaults to
<span class='lineno'> 379</span>             BILINEAR.
<span class='lineno'> 380</span>     align_corners: bool. If true, exactly align all 4 corners of the input
<span class='lineno'> 381</span>                    and output. Defaults to False.
<span class='lineno'> 382</span>     pad_to_max_dimension: Whether to resize the image and pad it with zeros
<span class='lineno'> 383</span>       so the resulting image is of the spatial size
<span class='lineno'> 384</span>       [max_dimension, max_dimension]. If masks are included they are padded
<span class='lineno'> 385</span>       similarly.
<span class='lineno'> 386</span> 
<span class='lineno'> 387</span>   Returns:
<span class='lineno'> 388</span>     Note that the position of the resized_image_shape changes based on whether
<span class='lineno'> 389</span>     masks are present.
<span class='lineno'> 390</span>     resized_image: A 3D tensor of shape [new_height, new_width, channels],
<span class='lineno'> 391</span>       where the image has been resized (with bilinear interpolation) so that
<span class='lineno'> 392</span>       min(new_height, new_width) == min_dimension or
<span class='lineno'> 393</span>       max(new_height, new_width) == max_dimension.
<span class='lineno'> 394</span>     resized_masks: If masks is not None, also outputs masks. A 3D tensor of
<span class='lineno'> 395</span>       shape [num_instances, new_height, new_width].
<span class='lineno'> 396</span>     resized_image_shape: A 1D tensor of shape [3] containing shape of the
<span class='lineno'> 397</span>       resized image.
<span class='lineno'> 398</span> 
<span class='lineno'> 399</span>   Raises:
<span class='lineno'> 400</span>     ValueError: if the image is not a 3D tensor.
<span class='lineno'> 401</span>   &quot;&quot;&quot;
<span class='lineno'> 402</span>   if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', title='?'>image</a>.get_shape()) != 3:
<span class='lineno'> 403</span>     raise ValueError(&#39;Image should be 3D tensor&#39;)
<span class='lineno'> 404</span> 
<span class='lineno'> 405</span>   with tf.name_scope(&#39;ResizeToRange&#39;):
<span class='lineno'> 406</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', title='?'>image</a>.get_shape().is_fully_defined():
<span class='lineno'> 407</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_size', title='None'>new_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_static_size', title='(?, None, None) -> None / (?, ?, ?) -> None'>_compute_new_static_size</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.min_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.min_dimension', title='None'>min_dimension</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', title='None'>max_dimension</a>)
<span class='lineno'> 408</span>     else:
<span class='lineno'> 409</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_size', title='None'>new_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._compute_new_dynamic_size', title='(?, None, None) -> None / (?, ?, ?) -> None'>_compute_new_dynamic_size</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.min_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.min_dimension', title='None'>min_dimension</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', title='None'>max_dimension</a>)
<span class='lineno'> 410</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_image', title='?'>new_image</a> = tf.image.resize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_size', title='None'>new_size</a>[:-1], method=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.method', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.method', title='?'>method</a>)
<span class='lineno'> 411</span> 
<span class='lineno'> 412</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.pad_to_max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.pad_to_max_dimension', title='bool'>pad_to_max_dimension</a>:
<span class='lineno'> 413</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_image', title='?'>new_image</a> = tf.image.pad_to_bounding_box(
<span class='lineno'> 414</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_image', title='?'>new_image</a>, 0, 0, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', title='None'>max_dimension</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', title='None'>max_dimension</a>)
<span class='lineno'> 415</span> 
<span class='lineno'> 416</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.result', title='[None]'>result</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_image', title='?'>new_image</a>]
<span class='lineno'> 417</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.masks', title='None'>masks</a> is not None:
<span class='lineno'> 418</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', title='?'>new_masks</a> = tf.expand_dims(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.masks', title='None'>masks</a>, 3)
<span class='lineno'> 419</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', title='?'>new_masks</a> = tf.image.resize(
<span class='lineno'> 420</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', title='?'>new_masks</a>,
<span class='lineno'> 421</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_size', title='None'>new_size</a>[:-1],
<span class='lineno'> 422</span>           method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
<span class='lineno'> 423</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', title='?'>new_masks</a> = tf.squeeze(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', title='?'>new_masks</a>, 3)
<span class='lineno'> 424</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.pad_to_max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.pad_to_max_dimension', title='bool'>pad_to_max_dimension</a>:
<span class='lineno'> 425</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', title='?'>new_masks</a> = tf.image.pad_to_bounding_box(
<span class='lineno'> 426</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', title='?'>new_masks</a>, 0, 0, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', title='None'>max_dimension</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.max_dimension', title='None'>max_dimension</a>)
<span class='lineno'> 427</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.result', title='[None]'>result</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_masks', title='?'>new_masks</a>)
<span class='lineno'> 428</span> 
<span class='lineno'> 429</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.result', title='[None]'>result</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.new_size', title='None'>new_size</a>)
<span class='lineno'> 430</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.resize_to_range.result', title='[None]'>result</a>
<span class='lineno'> 431</span> 
<span class='lineno'> 432</span> 
<span class='lineno'> 433</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields', title='(?, ?) -> None'>_copy_extra_fields</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_to', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_to', title='?'>boxlist_to_copy_to</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_from', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_from', title='?'>boxlist_to_copy_from</a>):
<span class='lineno'> 434</span>   &quot;&quot;&quot;Copies the extra fields of boxlist_to_copy_from to boxlist_to_copy_to.
<span class='lineno'> 435</span> 
<span class='lineno'> 436</span>   Args:
<span class='lineno'> 437</span>     boxlist_to_copy_to: BoxList to which extra fields are copied.
<span class='lineno'> 438</span>     boxlist_to_copy_from: BoxList from which fields are copied.
<span class='lineno'> 439</span> 
<span class='lineno'> 440</span>   Returns:
<span class='lineno'> 441</span>     boxlist_to_copy_to with extra fields.
<span class='lineno'> 442</span>   &quot;&quot;&quot;
<span class='lineno'> 443</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.field', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.field', title='?'>field</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_from', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_from', title='?'>boxlist_to_copy_from</a>.get_extra_fields():
<span class='lineno'> 444</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_to', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_to', title='?'>boxlist_to_copy_to</a>.add_field(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.field', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.field', title='?'>field</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_from', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_from', title='?'>boxlist_to_copy_from</a>.get_field(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.field', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.field', title='?'>field</a>))
<span class='lineno'> 445</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_to', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields.boxlist_to_copy_to', title='?'>boxlist_to_copy_to</a>
<span class='lineno'> 446</span> 
<span class='lineno'> 447</span> 
<span class='lineno'> 448</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale', title='(?, ?, ?, None) -> None'>box_list_scale</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.boxlist', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.boxlist', title='?'>boxlist</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_scale', title='?'>y_scale</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_scale', title='?'>x_scale</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scope', title='None'>scope</a>=None):
<span class='lineno'> 449</span>   &quot;&quot;&quot;scale box coordinates in x and y dimensions.
<span class='lineno'> 450</span> 
<span class='lineno'> 451</span>   Args:
<span class='lineno'> 452</span>     boxlist: BoxList holding N boxes
<span class='lineno'> 453</span>     y_scale: (float) scalar tensor
<span class='lineno'> 454</span>     x_scale: (float) scalar tensor
<span class='lineno'> 455</span>     scope: name scope.
<span class='lineno'> 456</span> 
<span class='lineno'> 457</span>   Returns:
<span class='lineno'> 458</span>     boxlist: BoxList holding N boxes
<span class='lineno'> 459</span>   &quot;&quot;&quot;
<span class='lineno'> 460</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scope', title='None'>scope</a>:
<span class='lineno'> 461</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scope', title='str'>scope</a> = &#39;Scale&#39;
<span class='lineno'> 462</span>   with tf.name_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scope', title='str'>scope</a>):
<span class='lineno'> 463</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_scale', title='?'>y_scale</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_scale', title='?'>y_scale</a>, tf.float32)
<span class='lineno'> 464</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_scale', title='?'>x_scale</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_scale', title='?'>x_scale</a>, tf.float32)
<span class='lineno'> 465</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_min', title='?'>y_min</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_min', title='?'>x_min</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_max', title='?'>y_max</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_max', title='?'>x_max</a> = tf.split(
<span class='lineno'> 466</span>         value=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.boxlist', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.boxlist', title='?'>boxlist</a>.get(), num_or_size_splits=4, axis=1)
<span class='lineno'> 467</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_min', title='?'>y_min</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_scale', title='?'>y_scale</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_min', title='?'>y_min</a>
<span class='lineno'> 468</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_max', title='?'>y_max</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_scale', title='?'>y_scale</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_max', title='?'>y_max</a>
<span class='lineno'> 469</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_min', title='?'>x_min</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_scale', title='?'>x_scale</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_min', title='?'>x_min</a>
<span class='lineno'> 470</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_max', title='?'>x_max</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_scale', title='?'>x_scale</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_max', title='?'>x_max</a>
<span class='lineno'> 471</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scaled_boxlist', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scaled_boxlist', title='?'>scaled_boxlist</a> = box_list.BoxList(
<span class='lineno'> 472</span>         tf.concat([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_min', title='?'>y_min</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_min', title='?'>x_min</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.y_max', title='?'>y_max</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.x_max', title='?'>x_max</a>], 1))
<span class='lineno'> 473</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor._copy_extra_fields', title='(?, ?) -> None'>_copy_extra_fields</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scaled_boxlist', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.scaled_boxlist', title='?'>scaled_boxlist</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.boxlist', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale.boxlist', title='?'>boxlist</a>)
<span class='lineno'> 474</span> 
<span class='lineno'> 475</span> 
<span class='lineno'> 476</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale', title='(?, ?, ?, None) -> [[[?]]] / (None, ?, ?, None) -> None'>keypoint_scale</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.keypoints', title='None'>keypoints</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.y_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.y_scale', title='?'>y_scale</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.x_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.x_scale', title='?'>x_scale</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.scope', title='None'>scope</a>=None):
<span class='lineno'> 477</span>   &quot;&quot;&quot;Scales keypoint coordinates in x and y dimensions.
<span class='lineno'> 478</span> 
<span class='lineno'> 479</span>   Args:
<span class='lineno'> 480</span>     keypoints: a tensor of shape [num_instances, num_keypoints, 2]
<span class='lineno'> 481</span>     y_scale: (float) scalar tensor
<span class='lineno'> 482</span>     x_scale: (float) scalar tensor
<span class='lineno'> 483</span>     scope: name scope.
<span class='lineno'> 484</span> 
<span class='lineno'> 485</span>   Returns:
<span class='lineno'> 486</span>     new_keypoints: a tensor of shape [num_instances, num_keypoints, 2]
<span class='lineno'> 487</span>   &quot;&quot;&quot;
<span class='lineno'> 488</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.scope', title='None'>scope</a>:
<span class='lineno'> 489</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.scope', title='str'>scope</a> = &#39;Scale&#39;
<span class='lineno'> 490</span>   with tf.name_scope(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.scope', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.scope', title='str'>scope</a>):
<span class='lineno'> 491</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.y_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.y_scale', title='?'>y_scale</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.y_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.y_scale', title='?'>y_scale</a>, tf.float32)
<span class='lineno'> 492</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.x_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.x_scale', title='?'>x_scale</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.x_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.x_scale', title='?'>x_scale</a>, tf.float32)
<span class='lineno'> 493</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.new_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.new_keypoints', title='[[[?]]]'>new_keypoints</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.keypoints', title='None'>keypoints</a> * [[[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.y_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.y_scale', title='?'>y_scale</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.x_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.x_scale', title='?'>x_scale</a>]]]
<span class='lineno'> 494</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.new_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale.new_keypoints', title='[[[?]]]'>new_keypoints</a>
<span class='lineno'> 495</span> 
<span class='lineno'> 496</span> 
<span class='lineno'> 497</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates', title='(?, ?, None) -> tuple'>scale_boxes_to_pixel_coordinates</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image', title='?'>image</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.boxes', title='?'>boxes</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.keypoints', title='None'>keypoints</a>=None):
<span class='lineno'> 498</span>   &quot;&quot;&quot;Scales boxes from normalized to pixel coordinates.
<span class='lineno'> 499</span> 
<span class='lineno'> 500</span>   Args:
<span class='lineno'> 501</span>     image: A 3D float32 tensor of shape [height, width, channels].
<span class='lineno'> 502</span>     boxes: A 2D float32 tensor of shape [num_boxes, 4] containing the bounding
<span class='lineno'> 503</span>       boxes in normalized coordinates. Each row is of the form
<span class='lineno'> 504</span>       [ymin, xmin, ymax, xmax].
<span class='lineno'> 505</span>     keypoints: (optional) rank 3 float32 tensor with shape
<span class='lineno'> 506</span>       [num_instances, num_keypoints, 2]. The keypoints are in y-x normalized
<span class='lineno'> 507</span>       coordinates.
<span class='lineno'> 508</span> 
<span class='lineno'> 509</span>   Returns:
<span class='lineno'> 510</span>     image: unchanged input image.
<span class='lineno'> 511</span>     scaled_boxes: a 2D float32 tensor of shape [num_boxes, 4] containing the
<span class='lineno'> 512</span>       bounding boxes in pixel coordinates.
<span class='lineno'> 513</span>     scaled_keypoints: a 3D float32 tensor with shape
<span class='lineno'> 514</span>       [num_instances, num_keypoints, 2] containing the keypoints in pixel
<span class='lineno'> 515</span>       coordinates.
<span class='lineno'> 516</span>   &quot;&quot;&quot;
<span class='lineno'> 517</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.boxlist', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.boxlist', title='?'>boxlist</a> = box_list.BoxList(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.boxes', title='?'>boxes</a>)
<span class='lineno'> 518</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_height', title='?'>image_height</a> = tf.shape(input=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image', title='?'>image</a>)[0]
<span class='lineno'> 519</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_width', title='?'>image_width</a> = tf.shape(input=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image', title='?'>image</a>)[1]
<span class='lineno'> 520</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.scaled_boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.scaled_boxes', title='?'>scaled_boxes</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.box_list_scale', title='(?, ?, ?, None) -> None'>box_list_scale</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.boxlist', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.boxlist', title='?'>boxlist</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_height', title='?'>image_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_width', title='?'>image_width</a>).get()
<span class='lineno'> 521</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.result', title='[None]'>result</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image', title='?'>image</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.scaled_boxes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.scaled_boxes', title='?'>scaled_boxes</a>]
<span class='lineno'> 522</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.keypoints', title='None'>keypoints</a> is not None:
<span class='lineno'> 523</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.scaled_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.scaled_keypoints', title='None'>scaled_keypoints</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.keypoint_scale', title='(?, ?, ?, None) -> [[[?]]] / (None, ?, ?, None) -> None'>keypoint_scale</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.keypoints', title='None'>keypoints</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_height', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_height', title='?'>image_height</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.image_width', title='?'>image_width</a>)
<span class='lineno'> 524</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.result', title='[None]'>result</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.scaled_keypoints', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.scaled_keypoints', title='None'>scaled_keypoints</a>)
<span class='lineno'> 525</span>   return tuple(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.result', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.vision.detection.utils.object_detection.preprocessor.scale_boxes_to_pixel_coordinates.result', title='[None]'>result</a>)
</pre></td></tr></table></body></html>