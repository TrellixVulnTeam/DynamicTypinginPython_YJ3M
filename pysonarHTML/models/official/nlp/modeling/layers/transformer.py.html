<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/nlp/modeling/layers/transformer.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer'>Transformer</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build'>build</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config'>get_config</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call'>call</a></li></ul>
</li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer'>CompiledTransformer</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call'>call</a></li></ul>
</li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2019 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> &quot;&quot;&quot;Keras-based transformer block layer.&quot;&quot;&quot;
<span class='lineno'>  16</span> # pylint: disable=g-classes-have-attributes
<span class='lineno'>  17</span> from __future__ import absolute_import
<span class='lineno'>  18</span> from __future__ import division
<span class='lineno'>  19</span> # from __future__ import google_type_annotations
<span class='lineno'>  20</span> from __future__ import print_function
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> import gin
<span class='lineno'>  23</span> import tensorflow as tf
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> from official.nlp.modeling.layers import attention
<span class='lineno'>  26</span> from official.nlp.modeling.layers import dense_einsum
<span class='lineno'>  27</span> from official.nlp.modeling.layers.util import tf_function_if_eager
<span class='lineno'>  28</span> 
<span class='lineno'>  29</span> 
<span class='lineno'>  30</span> @tf.keras.utils.register_keras_serializable(package=&quot;Text&quot;)
<span class='lineno'>  31</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer', title='<Transformer>'>Transformer</a>(tf.keras.layers.Layer):
<span class='lineno'>  32</span>   &quot;&quot;&quot;Transformer layer.
<span class='lineno'>  33</span> 
<span class='lineno'>  34</span>   This layer implements the Transformer from &quot;Attention Is All You Need&quot;.
<span class='lineno'>  35</span>   (https://arxiv.org/abs/1706.03762).
<span class='lineno'>  36</span> 
<span class='lineno'>  37</span>   Arguments:
<span class='lineno'>  38</span>     num_attention_heads: Number of attention heads.
<span class='lineno'>  39</span>     intermediate_size: Size of the intermediate layer.
<span class='lineno'>  40</span>     intermediate_activation: Activation for the intermediate layer.
<span class='lineno'>  41</span>     dropout_rate: Dropout probability for the post-attention and output dropout.
<span class='lineno'>  42</span>     attention_dropout_rate: Dropout probability for within the attention layer.
<span class='lineno'>  43</span>     output_range: the sequence output range, [0, output_range) by slicing the
<span class='lineno'>  44</span>       target sequence. `None` means the target sequence is not sliced.
<span class='lineno'>  45</span>     kernel_initializer: Initializer for dense layer kernels.
<span class='lineno'>  46</span>     bias_initializer: Initializer for dense layer biases.
<span class='lineno'>  47</span>     kernel_regularizer: Regularizer for dense layer kernels.
<span class='lineno'>  48</span>     bias_regularizer: Regularizer for dense layer biases.
<span class='lineno'>  49</span>     activity_regularizer: Regularizer for dense layer activity.
<span class='lineno'>  50</span>     kernel_constraint: Constraint for dense layer kernels.
<span class='lineno'>  51</span>     bias_constraint: Constraint for dense layer kernels.
<span class='lineno'>  52</span>   &quot;&quot;&quot;
<span class='lineno'>  53</span> 
<span class='lineno'>  54</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>,
<span class='lineno'>  55</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.num_attention_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.num_attention_heads', title='?'>num_attention_heads</a>,
<span class='lineno'>  56</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.intermediate_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.intermediate_size', title='?'>intermediate_size</a>,
<span class='lineno'>  57</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.intermediate_activation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.intermediate_activation', title='?'>intermediate_activation</a>,
<span class='lineno'>  58</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.dropout_rate', title='float'>dropout_rate</a>=0.0,
<span class='lineno'>  59</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.attention_dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.attention_dropout_rate', title='float'>attention_dropout_rate</a>=0.0,
<span class='lineno'>  60</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.output_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.output_range', title='None'>output_range</a>=None,
<span class='lineno'>  61</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_initializer', title='str'>kernel_initializer</a>=&quot;glorot_uniform&quot;,
<span class='lineno'>  62</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_initializer', title='str'>bias_initializer</a>=&quot;zeros&quot;,
<span class='lineno'>  63</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_regularizer', title='None'>kernel_regularizer</a>=None,
<span class='lineno'>  64</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_regularizer', title='None'>bias_regularizer</a>=None,
<span class='lineno'>  65</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.activity_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.activity_regularizer', title='None'>activity_regularizer</a>=None,
<span class='lineno'>  66</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_constraint', title='None'>kernel_constraint</a>=None,
<span class='lineno'>  67</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_constraint', title='None'>bias_constraint</a>=None,
<span class='lineno'>  68</span>                **kwargs):
<span class='lineno'>  69</span>     super(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer', title='<Transformer>'>Transformer</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>).__init__(**kwargs)
<span class='lineno'>  70</span> 
<span class='lineno'>  71</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', title='?'>_num_heads</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.num_attention_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.num_attention_heads', title='?'>num_attention_heads</a>
<span class='lineno'>  72</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_size', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_size', title='?'>_intermediate_size</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.intermediate_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.intermediate_size', title='?'>intermediate_size</a>
<span class='lineno'>  73</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_activation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_activation', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_activation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_activation', title='?'>_intermediate_activation</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.intermediate_activation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.intermediate_activation', title='?'>intermediate_activation</a>
<span class='lineno'>  74</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_dropout_rate', title='float'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_dropout_rate', title='float'>_attention_dropout_rate</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.attention_dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.attention_dropout_rate', title='float'>attention_dropout_rate</a>
<span class='lineno'>  75</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._dropout_rate', title='float'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._dropout_rate', title='float'>_dropout_rate</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.dropout_rate', title='float'>dropout_rate</a>
<span class='lineno'>  76</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', title='None'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', title='None'>_output_range</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.output_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.output_range', title='None'>output_range</a>
<span class='lineno'>  77</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', title='?'>_kernel_initializer</a></a> = tf.keras.initializers.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_initializer', title='str'>kernel_initializer</a>)
<span class='lineno'>  78</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', title='?'>_bias_initializer</a></a> = tf.keras.initializers.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_initializer', title='str'>bias_initializer</a>)
<span class='lineno'>  79</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', title='?'>_kernel_regularizer</a></a> = tf.keras.regularizers.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_regularizer', title='None'>kernel_regularizer</a>)
<span class='lineno'>  80</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', title='?'>_bias_regularizer</a></a> = tf.keras.regularizers.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_regularizer', title='None'>bias_regularizer</a>)
<span class='lineno'>  81</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', title='?'>_kernel_constraint</a></a> = tf.keras.constraints.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.kernel_constraint', title='None'>kernel_constraint</a>)
<span class='lineno'>  82</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.self', title='{CompiledTransformer | Transformer}'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', title='?'>_bias_constraint</a></a> = tf.keras.constraints.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.__init__.bias_constraint', title='None'>bias_constraint</a>)
<span class='lineno'>  83</span> 
<span class='lineno'>  84</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build', title='(Transformer, ?) -> None'>build</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', title='?'>input_shape</a>):
<span class='lineno'>  85</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor', title='?'>input_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', title='?'>input_shape</a>[0] if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', title='?'>input_shape</a>) == 2 else <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', title='?'>input_shape</a>
<span class='lineno'>  86</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor_shape', title='?'>input_tensor_shape</a> = tf.TensorShape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor', title='?'>input_tensor</a>)
<span class='lineno'>  87</span>     if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor_shape', title='?'>input_tensor_shape</a>) != 3:
<span class='lineno'>  88</span>       raise ValueError(&quot;TransformerLayer expects a three-dimensional input of &quot;
<span class='lineno'>  89</span>                        &quot;shape [batch, sequence, width].&quot;)
<span class='lineno'>  90</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.batch_size', title='?'>batch_size</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.sequence_length', title='?'>sequence_length</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.hidden_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.hidden_size', title='?'>hidden_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor_shape', title='?'>input_tensor_shape</a>
<span class='lineno'>  91</span> 
<span class='lineno'>  92</span>     if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', title='?'>input_shape</a>) == 2:
<span class='lineno'>  93</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.mask_tensor_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.mask_tensor_shape', title='?'>mask_tensor_shape</a> = tf.TensorShape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', title='?'>input_shape</a>[1])
<span class='lineno'>  94</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.expected_mask_tensor_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.expected_mask_tensor_shape', title='?'>expected_mask_tensor_shape</a> = tf.TensorShape(
<span class='lineno'>  95</span>           [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.batch_size', title='?'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.sequence_length', title='?'>sequence_length</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.sequence_length', title='?'>sequence_length</a>])
<span class='lineno'>  96</span>       if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.expected_mask_tensor_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.expected_mask_tensor_shape', title='?'>expected_mask_tensor_shape</a>.is_compatible_with(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.mask_tensor_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.mask_tensor_shape', title='?'>mask_tensor_shape</a>):
<span class='lineno'>  97</span>         raise ValueError(&quot;When passing a mask tensor to TransformerLayer, the &quot;
<span class='lineno'>  98</span>                          &quot;mask tensor must be of shape [batch, &quot;
<span class='lineno'>  99</span>                          &quot;sequence_length, sequence_length] (here %s). Got a &quot;
<span class='lineno'> 100</span>                          &quot;mask tensor of shape %s.&quot; %
<span class='lineno'> 101</span>                          (expected_mask_tensor_shape, mask_tensor_shape))
<span class='lineno'> 102</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.hidden_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.hidden_size', title='?'>hidden_size</a> % <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', title='?'>_num_heads</a> != 0:
<span class='lineno'> 103</span>       raise ValueError(
<span class='lineno'> 104</span>           &quot;The input size (%d) is not a multiple of the number of attention &quot;
<span class='lineno'> 105</span>           &quot;heads (%d)&quot; % (hidden_size, self._num_heads))
<span class='lineno'> 106</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_head_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_head_size', title='int'>_attention_head_size</a> = int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.hidden_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.hidden_size', title='?'>hidden_size</a> // <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', title='?'>_num_heads</a>)
<span class='lineno'> 107</span> 
<span class='lineno'> 108</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_layer', title='?'>_attention_layer</a> = attention.MultiHeadAttention(
<span class='lineno'> 109</span>         num_heads=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', title='?'>_num_heads</a>,
<span class='lineno'> 110</span>         key_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_head_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_head_size', title='int'>_attention_head_size</a>,
<span class='lineno'> 111</span>         dropout=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_dropout_rate', title='float'>_attention_dropout_rate</a>,
<span class='lineno'> 112</span>         kernel_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', title='?'>_kernel_initializer</a>,
<span class='lineno'> 113</span>         bias_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', title='?'>_bias_initializer</a>,
<span class='lineno'> 114</span>         kernel_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', title='?'>_kernel_regularizer</a>,
<span class='lineno'> 115</span>         bias_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', title='?'>_bias_regularizer</a>,
<span class='lineno'> 116</span>         activity_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>._activity_regularizer,
<span class='lineno'> 117</span>         kernel_constraint=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', title='?'>_kernel_constraint</a>,
<span class='lineno'> 118</span>         bias_constraint=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', title='?'>_bias_constraint</a>,
<span class='lineno'> 119</span>         name=&quot;self_attention&quot;)
<span class='lineno'> 120</span>     # pylint: disable=protected-access
<span class='lineno'> 121</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_layer', title='?'>_attention_layer</a>.build([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_tensor_shape', title='?'>input_tensor_shape</a>] * 3)
<span class='lineno'> 122</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_output_dense', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_output_dense', title='?'>_attention_output_dense</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_layer', title='?'>_attention_layer</a>._output_dense
<span class='lineno'> 123</span>     # pylint: enable=protected-access
<span class='lineno'> 124</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_dropout', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_dropout', title='?'>_attention_dropout</a> = tf.keras.layers.Dropout(rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._dropout_rate', title='float'>_dropout_rate</a>)
<span class='lineno'> 125</span>     # Use float32 in layernorm for numeric stability.
<span class='lineno'> 126</span>     # It is probably safe in mixed_float16, but we haven&#39;t validated this yet.
<span class='lineno'> 127</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_layer_norm', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_layer_norm', title='?'>_attention_layer_norm</a> = (
<span class='lineno'> 128</span>         tf.keras.layers.LayerNormalization(
<span class='lineno'> 129</span>             name=&quot;self_attention_layer_norm&quot;,
<span class='lineno'> 130</span>             axis=-1,
<span class='lineno'> 131</span>             epsilon=1e-12,
<span class='lineno'> 132</span>             dtype=tf.float32))
<span class='lineno'> 133</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_dense', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_dense', title='?'>_intermediate_dense</a> = dense_einsum.DenseEinsum(
<span class='lineno'> 134</span>         output_shape=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_size', title='?'>_intermediate_size</a>,
<span class='lineno'> 135</span>         activation=None,
<span class='lineno'> 136</span>         kernel_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', title='?'>_kernel_initializer</a>,
<span class='lineno'> 137</span>         bias_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', title='?'>_bias_initializer</a>,
<span class='lineno'> 138</span>         kernel_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', title='?'>_kernel_regularizer</a>,
<span class='lineno'> 139</span>         bias_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', title='?'>_bias_regularizer</a>,
<span class='lineno'> 140</span>         activity_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>._activity_regularizer,
<span class='lineno'> 141</span>         kernel_constraint=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', title='?'>_kernel_constraint</a>,
<span class='lineno'> 142</span>         bias_constraint=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', title='?'>_bias_constraint</a>,
<span class='lineno'> 143</span>         name=&quot;intermediate&quot;)
<span class='lineno'> 144</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.policy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.policy', title='?'>policy</a> = tf.keras.mixed_precision.experimental.global_policy()
<span class='lineno'> 145</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.policy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.policy', title='?'>policy</a>.name == &quot;mixed_bfloat16&quot;:
<span class='lineno'> 146</span>       # bfloat16 causes BERT with the LAMB optimizer to not converge
<span class='lineno'> 147</span>       # as well, so we use float32.
<span class='lineno'> 148</span>       # TODO(b/154538392): Investigate this.
<span class='lineno'> 149</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.policy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.policy', title='?'>policy</a> = tf.float32
<span class='lineno'> 150</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_activation_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_activation_layer', title='?'>_intermediate_activation_layer</a> = tf.keras.layers.Activation(
<span class='lineno'> 151</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_activation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_activation', title='?'>_intermediate_activation</a>, dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.policy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.policy', title='?'>policy</a>)
<span class='lineno'> 152</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_dense', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_dense', title='?'>_output_dense</a> = dense_einsum.DenseEinsum(
<span class='lineno'> 153</span>         output_shape=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.hidden_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.hidden_size', title='?'>hidden_size</a>,
<span class='lineno'> 154</span>         kernel_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', title='?'>_kernel_initializer</a>,
<span class='lineno'> 155</span>         bias_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', title='?'>_bias_initializer</a>,
<span class='lineno'> 156</span>         kernel_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', title='?'>_kernel_regularizer</a>,
<span class='lineno'> 157</span>         bias_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', title='?'>_bias_regularizer</a>,
<span class='lineno'> 158</span>         activity_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>._activity_regularizer,
<span class='lineno'> 159</span>         kernel_constraint=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', title='?'>_kernel_constraint</a>,
<span class='lineno'> 160</span>         bias_constraint=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', title='?'>_bias_constraint</a>,
<span class='lineno'> 161</span>         name=&quot;output&quot;)
<span class='lineno'> 162</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_dropout', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_dropout', title='?'>_output_dropout</a> = tf.keras.layers.Dropout(rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._dropout_rate', title='float'>_dropout_rate</a>)
<span class='lineno'> 163</span>     # Use float32 in layernorm for numeric stability.
<span class='lineno'> 164</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_layer_norm', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_layer_norm', title='?'>_output_layer_norm</a> = tf.keras.layers.LayerNormalization(
<span class='lineno'> 165</span>         name=&quot;output_layer_norm&quot;, axis=-1, epsilon=1e-12, dtype=tf.float32)
<span class='lineno'> 166</span> 
<span class='lineno'> 167</span>     super(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer', title='<Transformer>'>Transformer</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.self', title='Transformer'>self</a>).build(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.build.input_shape', title='?'>input_shape</a>)
<span class='lineno'> 168</span> 
<span class='lineno'> 169</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config', title='Transformer -> dict'>get_config</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>):
<span class='lineno'> 170</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.config', title='dict'>config</a> = {
<span class='lineno'> 171</span>         &quot;num_attention_heads&quot;:
<span class='lineno'> 172</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._num_heads', title='?'>_num_heads</a>,
<span class='lineno'> 173</span>         &quot;intermediate_size&quot;:
<span class='lineno'> 174</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_size', title='?'>_intermediate_size</a>,
<span class='lineno'> 175</span>         &quot;intermediate_activation&quot;:
<span class='lineno'> 176</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_activation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._intermediate_activation', title='?'>_intermediate_activation</a>,
<span class='lineno'> 177</span>         &quot;dropout_rate&quot;:
<span class='lineno'> 178</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._dropout_rate', title='float'>_dropout_rate</a>,
<span class='lineno'> 179</span>         &quot;attention_dropout_rate&quot;:
<span class='lineno'> 180</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._attention_dropout_rate', title='float'>_attention_dropout_rate</a>,
<span class='lineno'> 181</span>         &quot;output_range&quot;:
<span class='lineno'> 182</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', title='None'>_output_range</a>,
<span class='lineno'> 183</span>         &quot;kernel_initializer&quot;:
<span class='lineno'> 184</span>             tf.keras.initializers.serialize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_initializer', title='?'>_kernel_initializer</a>),
<span class='lineno'> 185</span>         &quot;bias_initializer&quot;:
<span class='lineno'> 186</span>             tf.keras.initializers.serialize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_initializer', title='?'>_bias_initializer</a>),
<span class='lineno'> 187</span>         &quot;kernel_regularizer&quot;:
<span class='lineno'> 188</span>             tf.keras.regularizers.serialize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_regularizer', title='?'>_kernel_regularizer</a>),
<span class='lineno'> 189</span>         &quot;bias_regularizer&quot;:
<span class='lineno'> 190</span>             tf.keras.regularizers.serialize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_regularizer', title='?'>_bias_regularizer</a>),
<span class='lineno'> 191</span>         &quot;activity_regularizer&quot;:
<span class='lineno'> 192</span>             tf.keras.regularizers.serialize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>._activity_regularizer),
<span class='lineno'> 193</span>         &quot;kernel_constraint&quot;:
<span class='lineno'> 194</span>             tf.keras.constraints.serialize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._kernel_constraint', title='?'>_kernel_constraint</a>),
<span class='lineno'> 195</span>         &quot;bias_constraint&quot;:
<span class='lineno'> 196</span>             tf.keras.constraints.serialize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._bias_constraint', title='?'>_bias_constraint</a>)
<span class='lineno'> 197</span>     }
<span class='lineno'> 198</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.base_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.base_config', title='?'>base_config</a> = super(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer', title='<Transformer>'>Transformer</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.self', title='Transformer'>self</a>).get_config()
<span class='lineno'> 199</span>     return dict(list(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.base_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.base_config', title='?'>base_config</a>.items()) + list(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.get_config.config', title='dict'>config</a>.items()))
<span class='lineno'> 200</span> 
<span class='lineno'> 201</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call', title='(Transformer, ?) -> None'>call</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.inputs', title='?'>inputs</a>):
<span class='lineno'> 202</span>     if isinstance(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.inputs', title='?'>inputs</a>, (list, tuple)) and len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.inputs', title='?'>inputs</a>) == 2:
<span class='lineno'> 203</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.input_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.input_tensor', title='?'>input_tensor</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_mask', title='?'>attention_mask</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.inputs', title='?'>inputs</a>
<span class='lineno'> 204</span>     else:
<span class='lineno'> 205</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.input_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.input_tensor', title='?'>input_tensor</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_mask', title='None'>attention_mask</a> = (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.inputs', title='?'>inputs</a>, None)
<span class='lineno'> 206</span> 
<span class='lineno'> 207</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', title='None'>_output_range</a>:
<span class='lineno'> 208</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.target_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.target_tensor', title='?'>target_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.input_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.input_tensor', title='?'>input_tensor</a>[:, 0:<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', title='None'>_output_range</a>, :]
<span class='lineno'> 209</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_mask', title='?'>attention_mask</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_mask', title='None'>attention_mask</a>[:, 0:<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer._output_range', title='None'>_output_range</a>, :]
<span class='lineno'> 210</span>     else:
<span class='lineno'> 211</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.target_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.target_tensor', title='?'>target_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.input_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.input_tensor', title='?'>input_tensor</a>
<span class='lineno'> 212</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_inputs', title='[?]'>attention_inputs</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.target_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.target_tensor', title='?'>target_tensor</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.input_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.input_tensor', title='?'>input_tensor</a>]
<span class='lineno'> 213</span> 
<span class='lineno'> 214</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', title='?'>attention_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>._attention_layer(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_inputs', title='[?]'>attention_inputs</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_mask', title='None'>attention_mask</a>)
<span class='lineno'> 215</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', title='?'>attention_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>._attention_dropout(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', title='?'>attention_output</a>)
<span class='lineno'> 216</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', title='?'>attention_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>._attention_layer_norm(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.target_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.target_tensor', title='?'>target_tensor</a> +
<span class='lineno'> 217</span>                                                   <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', title='?'>attention_output</a>)
<span class='lineno'> 218</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.intermediate_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.intermediate_output', title='?'>intermediate_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>._intermediate_dense(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', title='?'>attention_output</a>)
<span class='lineno'> 219</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.intermediate_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.intermediate_output', title='?'>intermediate_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>._intermediate_activation_layer(
<span class='lineno'> 220</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.intermediate_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.intermediate_output', title='?'>intermediate_output</a>)
<span class='lineno'> 221</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', title='?'>layer_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>._output_dense(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.intermediate_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.intermediate_output', title='?'>intermediate_output</a>)
<span class='lineno'> 222</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', title='?'>layer_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>._output_dropout(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', title='?'>layer_output</a>)
<span class='lineno'> 223</span>     # During mixed precision training, attention_output is from layer norm and
<span class='lineno'> 224</span>     # is always fp32 for now. Cast layer_output to fp32 for the subsequent
<span class='lineno'> 225</span>     # add.
<span class='lineno'> 226</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', title='?'>layer_output</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', title='?'>layer_output</a>, tf.float32)
<span class='lineno'> 227</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', title='?'>layer_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.self', title='Transformer'>self</a>._output_layer_norm(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', title='?'>layer_output</a> + <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.attention_output', title='?'>attention_output</a>)
<span class='lineno'> 228</span> 
<span class='lineno'> 229</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer.call.layer_output', title='?'>layer_output</a>
<span class='lineno'> 230</span> 
<span class='lineno'> 231</span> 
<span class='lineno'> 232</span> @tf.keras.utils.register_keras_serializable(package=&quot;Text&quot;)
<span class='lineno'> 233</span> @gin.configurable
<span class='lineno'> 234</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer', title='<CompiledTransformer>'>CompiledTransformer</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.Transformer', title='<Transformer>'>Transformer</a>):
<span class='lineno'> 235</span> 
<span class='lineno'> 236</span>   @tf_function_if_eager(experimental_compile=True)
<span class='lineno'> 237</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call', title='(CompiledTransformer, ?) -> ?'>call</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call.self', title='CompiledTransformer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call.inputs', title='?'>inputs</a>):
<span class='lineno'> 238</span>     return super(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer', title='<CompiledTransformer>'>CompiledTransformer</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call.self', title='CompiledTransformer'>self</a>).call(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.layers.transformer.CompiledTransformer.call.inputs', title='?'>inputs</a>)
</pre></td></tr></table></body></html>