<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels'>_adjust_labels</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank'>_validate_rank</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss'>per_example_loss</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss'>loss</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2019 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> &quot;&quot;&quot;Sparse categorical cross-entropy losses.&quot;&quot;&quot;
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span> from __future__ import absolute_import
<span class='lineno'>  18</span> from __future__ import division
<span class='lineno'>  19</span> # from __future__ import google_type_annotations
<span class='lineno'>  20</span> from __future__ import print_function
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> import tensorflow as tf
<span class='lineno'>  23</span> 
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels', title='(?, ?) -> (?, ?)'>_adjust_labels</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.predictions', title='?'>predictions</a>):
<span class='lineno'>  26</span>   &quot;&quot;&quot;Adjust the &#39;labels&#39; tensor by squeezing it if needed.&quot;&quot;&quot;
<span class='lineno'>  27</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', title='?'>labels</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', title='?'>labels</a>, tf.int32)
<span class='lineno'>  28</span>   if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.predictions', title='?'>predictions</a>.shape) == len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', title='?'>labels</a>.shape):
<span class='lineno'>  29</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', title='?'>labels</a> = tf.squeeze(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', title='?'>labels</a>, [-1])
<span class='lineno'>  30</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels.predictions', title='?'>predictions</a>
<span class='lineno'>  31</span> 
<span class='lineno'>  32</span> 
<span class='lineno'>  33</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank', title='(?, ?, ?) -> None / (?, ?, None) -> None'>_validate_rank</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.predictions', title='?'>predictions</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.weights', title='None'>weights</a>):
<span class='lineno'>  34</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.weights', title='None'>weights</a> is not None and len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.weights', title='None'>weights</a>.shape) != len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.labels', title='?'>labels</a>.shape):
<span class='lineno'>  35</span>     raise RuntimeError(
<span class='lineno'>  36</span>         (&quot;Weight and label tensors were not of the same rank. weights.shape &quot;
<span class='lineno'>  37</span>          &quot;was %s, and labels.shape was %s.&quot;) %
<span class='lineno'>  38</span>         (predictions.shape, labels.shape))
<span class='lineno'>  39</span>   if (len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.predictions', title='?'>predictions</a>.shape) - 1) != len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank.labels', title='?'>labels</a>.shape):
<span class='lineno'>  40</span>     raise RuntimeError(
<span class='lineno'>  41</span>         (&quot;Weighted sparse categorical crossentropy expects `labels` to have a &quot;
<span class='lineno'>  42</span>          &quot;rank of one less than `predictions`. labels.shape was %s, and &quot;
<span class='lineno'>  43</span>          &quot;predictions.shape was %s.&quot;) % (labels.shape, predictions.shape))
<span class='lineno'>  44</span> 
<span class='lineno'>  45</span> 
<span class='lineno'>  46</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss', title='(?, ?, None) -> None'>per_example_loss</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', title='?'>predictions</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', title='None'>weights</a>=None):
<span class='lineno'>  47</span>   &quot;&quot;&quot;Calculate a per-example sparse categorical crossentropy loss.
<span class='lineno'>  48</span> 
<span class='lineno'>  49</span>   This loss function assumes that the predictions are post-softmax.
<span class='lineno'>  50</span>   Args:
<span class='lineno'>  51</span>     labels: The labels to evaluate against. Should be a set of integer indices
<span class='lineno'>  52</span>       ranging from 0 to (vocab_size-1).
<span class='lineno'>  53</span>     predictions: The network predictions. Should have softmax already applied.
<span class='lineno'>  54</span>     weights: An optional weight array of the same shape as the &#39;labels&#39; array.
<span class='lineno'>  55</span>       If None, all examples will be used.
<span class='lineno'>  56</span> 
<span class='lineno'>  57</span>   Returns:
<span class='lineno'>  58</span>     A tensor of shape predictions.shape[:-1] containing the per-example
<span class='lineno'>  59</span>       loss.
<span class='lineno'>  60</span>   &quot;&quot;&quot;
<span class='lineno'>  61</span>   # When using these functions with the Keras core API, we will need to squeeze
<span class='lineno'>  62</span>   # the labels tensor - Keras adds a spurious inner dimension.
<span class='lineno'>  63</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', title='?'>predictions</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels', title='(?, ?) -> (?, ?)'>_adjust_labels</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', title='?'>predictions</a>)
<span class='lineno'>  64</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank', title='(?, ?, ?) -> None / (?, ?, None) -> None'>_validate_rank</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', title='?'>predictions</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', title='None'>weights</a>)
<span class='lineno'>  65</span> 
<span class='lineno'>  66</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels_one_hot', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels_one_hot', title='?'>labels_one_hot</a> = tf.one_hot(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', title='?'>predictions</a>.shape[-1])
<span class='lineno'>  67</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels_one_hot', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels_one_hot', title='?'>labels_one_hot</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels_one_hot', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels_one_hot', title='?'>labels_one_hot</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', title='?'>predictions</a>.dtype)
<span class='lineno'>  68</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.per_example_loss_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.per_example_loss_data', title='?'>per_example_loss_data</a> = -tf.reduce_sum(
<span class='lineno'>  69</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.predictions', title='?'>predictions</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels_one_hot', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.labels_one_hot', title='?'>labels_one_hot</a>, axis=[-1])
<span class='lineno'>  70</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', title='None'>weights</a> is not None:
<span class='lineno'>  71</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', title='?'>weights</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', title='None'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.per_example_loss_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.per_example_loss_data', title='?'>per_example_loss_data</a>.dtype)
<span class='lineno'>  72</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.per_example_loss_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.per_example_loss_data', title='?'>per_example_loss_data</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.weights', title='?'>weights</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.per_example_loss_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.per_example_loss_data', title='?'>per_example_loss_data</a>
<span class='lineno'>  73</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.per_example_loss_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss.per_example_loss_data', title='?'>per_example_loss_data</a>
<span class='lineno'>  74</span> 
<span class='lineno'>  75</span> 
<span class='lineno'>  76</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss', title='(?, ?, None) -> float'>loss</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', title='?'>predictions</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', title='None'>weights</a>=None):
<span class='lineno'>  77</span>   &quot;&quot;&quot;Calculate a per-batch sparse categorical crossentropy loss.
<span class='lineno'>  78</span> 
<span class='lineno'>  79</span>   This loss function assumes that the predictions are post-softmax.
<span class='lineno'>  80</span>   Args:
<span class='lineno'>  81</span>     labels: The labels to evaluate against. Should be a set of integer indices
<span class='lineno'>  82</span>       ranging from 0 to (vocab_size-1).
<span class='lineno'>  83</span>     predictions: The network predictions. Should have softmax already applied.
<span class='lineno'>  84</span>     weights: An optional weight array of the same shape as the &#39;labels&#39; array.
<span class='lineno'>  85</span>       If None, all examples will be used.
<span class='lineno'>  86</span> 
<span class='lineno'>  87</span>   Returns:
<span class='lineno'>  88</span>     A loss scalar.
<span class='lineno'>  89</span> 
<span class='lineno'>  90</span>   Raises:
<span class='lineno'>  91</span>     RuntimeError if the passed tensors do not have the same rank.
<span class='lineno'>  92</span>   &quot;&quot;&quot;
<span class='lineno'>  93</span>   # When using these functions with the Keras core API, we will need to squeeze
<span class='lineno'>  94</span>   # the labels tensor - Keras adds a spurious inner dimension.
<span class='lineno'>  95</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.labels', title='?'>labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', title='?'>predictions</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._adjust_labels', title='(?, ?) -> (?, ?)'>_adjust_labels</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', title='?'>predictions</a>)
<span class='lineno'>  96</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy._validate_rank', title='(?, ?, ?) -> None / (?, ?, None) -> None'>_validate_rank</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', title='?'>predictions</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', title='None'>weights</a>)
<span class='lineno'>  97</span> 
<span class='lineno'>  98</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.per_example_loss_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.per_example_loss_data', title='None'>per_example_loss_data</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.per_example_loss', title='(?, ?, None) -> None'>per_example_loss</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', title='?'>predictions</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', title='None'>weights</a>)
<span class='lineno'>  99</span> 
<span class='lineno'> 100</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', title='None'>weights</a> is None:
<span class='lineno'> 101</span>     return tf.reduce_mean(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.per_example_loss_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.per_example_loss_data', title='None'>per_example_loss_data</a>)
<span class='lineno'> 102</span>   else:
<span class='lineno'> 103</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.numerator', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.numerator', title='?'>numerator</a> = tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.per_example_loss_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.per_example_loss_data', title='None'>per_example_loss_data</a>)
<span class='lineno'> 104</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', title='?'>weights</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', title='None'>weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.predictions', title='?'>predictions</a>.dtype)
<span class='lineno'> 105</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.denominator', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.denominator', title='float'>denominator</a> = tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.weights', title='?'>weights</a>) + 1e-5
<span class='lineno'> 106</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.numerator', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.numerator', title='?'>numerator</a> / <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.denominator', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.losses.weighted_sparse_categorical_crossentropy.loss.denominator', title='float'>denominator</a>
</pre></td></tr></table></body></html>