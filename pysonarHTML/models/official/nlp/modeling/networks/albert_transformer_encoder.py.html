<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/nlp/modeling/networks/albert_transformer_encoder.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder'>AlbertTransformerEncoder</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_embedding_table', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_embedding_table'>get_embedding_table</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_config', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_config'>get_config</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.from_config', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.from_config'>from_config</a></li></ul>
</li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2019 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> &quot;&quot;&quot;ALBERT (https://arxiv.org/abs/1810.04805) text encoder network.&quot;&quot;&quot;
<span class='lineno'>  16</span> # pylint: disable=g-classes-have-attributes
<span class='lineno'>  17</span> from __future__ import absolute_import
<span class='lineno'>  18</span> from __future__ import division
<span class='lineno'>  19</span> # from __future__ import google_type_annotations
<span class='lineno'>  20</span> from __future__ import print_function
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> import tensorflow as tf
<span class='lineno'>  23</span> 
<span class='lineno'>  24</span> from official.modeling import activations
<span class='lineno'>  25</span> from official.nlp.modeling import layers
<span class='lineno'>  26</span> 
<span class='lineno'>  27</span> 
<span class='lineno'>  28</span> @tf.keras.utils.register_keras_serializable(package=&#39;Text&#39;)
<span class='lineno'>  29</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder', title='<AlbertTransformerEncoder>'>AlbertTransformerEncoder</a>(tf.keras.Model):
<span class='lineno'>  30</span>   &quot;&quot;&quot;ALBERT (https://arxiv.org/abs/1810.04805) text encoder network.
<span class='lineno'>  31</span> 
<span class='lineno'>  32</span>   This network implements the encoder described in the paper &quot;ALBERT: A Lite
<span class='lineno'>  33</span>   BERT for Self-supervised Learning of Language Representations&quot;
<span class='lineno'>  34</span>   (https://arxiv.org/abs/1909.11942).
<span class='lineno'>  35</span> 
<span class='lineno'>  36</span>   Compared with BERT (https://arxiv.org/abs/1810.04805), ALBERT refactorizes
<span class='lineno'>  37</span>   embedding parameters into two smaller matrices and shares parameters
<span class='lineno'>  38</span>   across layers.
<span class='lineno'>  39</span> 
<span class='lineno'>  40</span>   The default values for this object are taken from the ALBERT-Base
<span class='lineno'>  41</span>   implementation described in the paper.
<span class='lineno'>  42</span> 
<span class='lineno'>  43</span>   Arguments:
<span class='lineno'>  44</span>     vocab_size: The size of the token vocabulary.
<span class='lineno'>  45</span>     embedding_width: The width of the word embeddings. If the embedding width is
<span class='lineno'>  46</span>       not equal to hidden size, embedding parameters will be factorized into two
<span class='lineno'>  47</span>       matrices in the shape of [&#39;vocab_size&#39;, &#39;embedding_width&#39;] and
<span class='lineno'>  48</span>       [&#39;embedding_width&#39;, &#39;hidden_size&#39;] (&#39;embedding_width&#39; is usually much
<span class='lineno'>  49</span>       smaller than &#39;hidden_size&#39;).
<span class='lineno'>  50</span>     hidden_size: The size of the transformer hidden layers.
<span class='lineno'>  51</span>     num_layers: The number of transformer layers.
<span class='lineno'>  52</span>     num_attention_heads: The number of attention heads for each transformer. The
<span class='lineno'>  53</span>       hidden size must be divisible by the number of attention heads.
<span class='lineno'>  54</span>     sequence_length: The sequence length that this encoder expects. If None, the
<span class='lineno'>  55</span>       sequence length is dynamic; if an integer, the encoder will require
<span class='lineno'>  56</span>       sequences padded to this length.
<span class='lineno'>  57</span>     max_sequence_length: The maximum sequence length that this encoder can
<span class='lineno'>  58</span>       consume. If None, max_sequence_length uses the value from sequence length.
<span class='lineno'>  59</span>       This determines the variable shape for positional embeddings.
<span class='lineno'>  60</span>     type_vocab_size: The number of types that the &#39;type_ids&#39; input can take.
<span class='lineno'>  61</span>     intermediate_size: The intermediate size for the transformer layers.
<span class='lineno'>  62</span>     activation: The activation to use for the transformer layers.
<span class='lineno'>  63</span>     dropout_rate: The dropout rate to use for the transformer layers.
<span class='lineno'>  64</span>     attention_dropout_rate: The dropout rate to use for the attention layers
<span class='lineno'>  65</span>       within the transformer layers.
<span class='lineno'>  66</span>     initializer: The initialzer to use for all weights in this encoder.
<span class='lineno'>  67</span>   &quot;&quot;&quot;
<span class='lineno'>  68</span> 
<span class='lineno'>  69</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', title='AlbertTransformerEncoder'>self</a>,
<span class='lineno'>  70</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.vocab_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.vocab_size', title='?'>vocab_size</a>,
<span class='lineno'>  71</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', title='int'>embedding_width</a>=128,
<span class='lineno'>  72</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', title='int'>hidden_size</a>=768,
<span class='lineno'>  73</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_layers', title='int'>num_layers</a>=12,
<span class='lineno'>  74</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_attention_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_attention_heads', title='int'>num_attention_heads</a>=12,
<span class='lineno'>  75</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', title='int'>sequence_length</a>=512,
<span class='lineno'>  76</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.max_sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.max_sequence_length', title='None'>max_sequence_length</a>=None,
<span class='lineno'>  77</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_vocab_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_vocab_size', title='int'>type_vocab_size</a>=16,
<span class='lineno'>  78</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.intermediate_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.intermediate_size', title='int'>intermediate_size</a>=3072,
<span class='lineno'>  79</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.activation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.activation', title='?'>activation</a>=activations.gelu,
<span class='lineno'>  80</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.dropout_rate', title='float'>dropout_rate</a>=0.1,
<span class='lineno'>  81</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.attention_dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.attention_dropout_rate', title='float'>attention_dropout_rate</a>=0.1,
<span class='lineno'>  82</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', title='?'>initializer</a>=tf.keras.initializers.TruncatedNormal(stddev=0.02),
<span class='lineno'>  83</span>                **kwargs):
<span class='lineno'>  84</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.activation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.activation', title='?'>activation</a> = tf.keras.activations.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.activation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.activation', title='?'>activation</a>)
<span class='lineno'>  85</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', title='?'>initializer</a> = tf.keras.initializers.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', title='?'>initializer</a>)
<span class='lineno'>  86</span> 
<span class='lineno'>  87</span>     if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.max_sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.max_sequence_length', title='None'>max_sequence_length</a>:
<span class='lineno'>  88</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.max_sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.max_sequence_length', title='int'>max_sequence_length</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', title='int'>sequence_length</a>
<span class='lineno'>  89</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', title='AlbertTransformerEncoder'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._self_setattr_tracking', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._self_setattr_tracking', title='bool'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._self_setattr_tracking', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._self_setattr_tracking', title='bool'>_self_setattr_tracking</a></a> = False
<span class='lineno'>  90</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', title='AlbertTransformerEncoder'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._config_dict', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._config_dict', title='dict'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._config_dict', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._config_dict', title='dict'>_config_dict</a></a> = {
<span class='lineno'>  91</span>         &#39;vocab_size&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.vocab_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.vocab_size', title='?'>vocab_size</a>,
<span class='lineno'>  92</span>         &#39;embedding_width&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', title='int'>embedding_width</a>,
<span class='lineno'>  93</span>         &#39;hidden_size&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', title='int'>hidden_size</a>,
<span class='lineno'>  94</span>         &#39;num_layers&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_layers', title='int'>num_layers</a>,
<span class='lineno'>  95</span>         &#39;num_attention_heads&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_attention_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_attention_heads', title='int'>num_attention_heads</a>,
<span class='lineno'>  96</span>         &#39;sequence_length&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', title='int'>sequence_length</a>,
<span class='lineno'>  97</span>         &#39;max_sequence_length&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.max_sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.max_sequence_length', title='int'>max_sequence_length</a>,
<span class='lineno'>  98</span>         &#39;type_vocab_size&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_vocab_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_vocab_size', title='int'>type_vocab_size</a>,
<span class='lineno'>  99</span>         &#39;intermediate_size&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.intermediate_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.intermediate_size', title='int'>intermediate_size</a>,
<span class='lineno'> 100</span>         &#39;activation&#39;: tf.keras.activations.serialize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.activation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.activation', title='?'>activation</a>),
<span class='lineno'> 101</span>         &#39;dropout_rate&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.dropout_rate', title='float'>dropout_rate</a>,
<span class='lineno'> 102</span>         &#39;attention_dropout_rate&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.attention_dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.attention_dropout_rate', title='float'>attention_dropout_rate</a>,
<span class='lineno'> 103</span>         &#39;initializer&#39;: tf.keras.initializers.serialize(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', title='?'>initializer</a>),
<span class='lineno'> 104</span>     }
<span class='lineno'> 105</span> 
<span class='lineno'> 106</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_ids', title='?'>word_ids</a> = tf.keras.layers.Input(
<span class='lineno'> 107</span>         shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', title='int'>sequence_length</a>,), dtype=tf.int32, name=&#39;input_word_ids&#39;)
<span class='lineno'> 108</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.mask', title='?'>mask</a> = tf.keras.layers.Input(
<span class='lineno'> 109</span>         shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', title='int'>sequence_length</a>,), dtype=tf.int32, name=&#39;input_mask&#39;)
<span class='lineno'> 110</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_ids', title='?'>type_ids</a> = tf.keras.layers.Input(
<span class='lineno'> 111</span>         shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.sequence_length', title='int'>sequence_length</a>,), dtype=tf.int32, name=&#39;input_type_ids&#39;)
<span class='lineno'> 112</span> 
<span class='lineno'> 113</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', title='int'>embedding_width</a> is None:
<span class='lineno'> 114</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', title='int'>embedding_width</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', title='int'>hidden_size</a>
<span class='lineno'> 115</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', title='AlbertTransformerEncoder'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._embedding_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._embedding_layer', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._embedding_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._embedding_layer', title='?'>_embedding_layer</a></a> = layers.OnDeviceEmbedding(
<span class='lineno'> 116</span>         vocab_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.vocab_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.vocab_size', title='?'>vocab_size</a>,
<span class='lineno'> 117</span>         embedding_width=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', title='int'>embedding_width</a>,
<span class='lineno'> 118</span>         initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', title='?'>initializer</a>,
<span class='lineno'> 119</span>         name=&#39;word_embeddings&#39;)
<span class='lineno'> 120</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_embeddings', title='?'>word_embeddings</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', title='AlbertTransformerEncoder'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._embedding_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._embedding_layer', title='?'>_embedding_layer</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_ids', title='?'>word_ids</a>)
<span class='lineno'> 121</span> 
<span class='lineno'> 122</span>     # Always uses dynamic slicing for simplicity.
<span class='lineno'> 123</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', title='AlbertTransformerEncoder'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._position_embedding_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._position_embedding_layer', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._position_embedding_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._position_embedding_layer', title='?'>_position_embedding_layer</a></a> = layers.PositionEmbedding(
<span class='lineno'> 124</span>         initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', title='?'>initializer</a>,
<span class='lineno'> 125</span>         use_dynamic_slicing=True,
<span class='lineno'> 126</span>         max_sequence_length=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.max_sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.max_sequence_length', title='int'>max_sequence_length</a>,
<span class='lineno'> 127</span>         name=&#39;position_embedding&#39;)
<span class='lineno'> 128</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.position_embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.position_embeddings', title='?'>position_embeddings</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', title='AlbertTransformerEncoder'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._position_embedding_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._position_embedding_layer', title='?'>_position_embedding_layer</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_embeddings', title='?'>word_embeddings</a>)
<span class='lineno'> 129</span> 
<span class='lineno'> 130</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_embeddings', title='?'>type_embeddings</a> = (
<span class='lineno'> 131</span>         layers.OnDeviceEmbedding(
<span class='lineno'> 132</span>             vocab_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_vocab_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_vocab_size', title='int'>type_vocab_size</a>,
<span class='lineno'> 133</span>             embedding_width=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', title='int'>embedding_width</a>,
<span class='lineno'> 134</span>             initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', title='?'>initializer</a>,
<span class='lineno'> 135</span>             use_one_hot=True,
<span class='lineno'> 136</span>             name=&#39;type_embeddings&#39;)(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_ids', title='?'>type_ids</a>))
<span class='lineno'> 137</span> 
<span class='lineno'> 138</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', title='?'>embeddings</a> = tf.keras.layers.Add()(
<span class='lineno'> 139</span>         [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_embeddings', title='?'>word_embeddings</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.position_embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.position_embeddings', title='?'>position_embeddings</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_embeddings', title='?'>type_embeddings</a>])
<span class='lineno'> 140</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', title='?'>embeddings</a> = (
<span class='lineno'> 141</span>         tf.keras.layers.LayerNormalization(
<span class='lineno'> 142</span>             name=&#39;embeddings/layer_norm&#39;,
<span class='lineno'> 143</span>             axis=-1,
<span class='lineno'> 144</span>             epsilon=1e-12,
<span class='lineno'> 145</span>             dtype=tf.float32)(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', title='?'>embeddings</a>))
<span class='lineno'> 146</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', title='?'>embeddings</a> = (tf.keras.layers.Dropout(rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.dropout_rate', title='float'>dropout_rate</a>)(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', title='?'>embeddings</a>))
<span class='lineno'> 147</span>     # We project the &#39;embedding&#39; output to &#39;hidden_size&#39; if it is not already
<span class='lineno'> 148</span>     # &#39;hidden_size&#39;.
<span class='lineno'> 149</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embedding_width', title='int'>embedding_width</a> != <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', title='int'>hidden_size</a>:
<span class='lineno'> 150</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', title='?'>embeddings</a> = tf.keras.layers.experimental.EinsumDense(
<span class='lineno'> 151</span>           &#39;...x,xy-&gt;...y&#39;,
<span class='lineno'> 152</span>           output_shape=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', title='int'>hidden_size</a>,
<span class='lineno'> 153</span>           bias_axes=&#39;y&#39;,
<span class='lineno'> 154</span>           kernel_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', title='?'>initializer</a>,
<span class='lineno'> 155</span>           name=&#39;embedding_projection&#39;)(
<span class='lineno'> 156</span>               <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', title='?'>embeddings</a>)
<span class='lineno'> 157</span> 
<span class='lineno'> 158</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', title='?'>data</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.embeddings', title='?'>embeddings</a>
<span class='lineno'> 159</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.attention_mask', title='?'>attention_mask</a> = layers.SelfAttentionMask()([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', title='?'>data</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.mask', title='?'>mask</a>])
<span class='lineno'> 160</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.shared_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.shared_layer', title='?'>shared_layer</a> = layers.Transformer(
<span class='lineno'> 161</span>         num_attention_heads=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_attention_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_attention_heads', title='int'>num_attention_heads</a>,
<span class='lineno'> 162</span>         intermediate_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.intermediate_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.intermediate_size', title='int'>intermediate_size</a>,
<span class='lineno'> 163</span>         intermediate_activation=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.activation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.activation', title='?'>activation</a>,
<span class='lineno'> 164</span>         dropout_rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.dropout_rate', title='float'>dropout_rate</a>,
<span class='lineno'> 165</span>         attention_dropout_rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.attention_dropout_rate', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.attention_dropout_rate', title='float'>attention_dropout_rate</a>,
<span class='lineno'> 166</span>         kernel_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', title='?'>initializer</a>,
<span class='lineno'> 167</span>         name=&#39;transformer&#39;)
<span class='lineno'> 168</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__._', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__._', title='int'>_</a> in range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_layers', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.num_layers', title='int'>num_layers</a>):
<span class='lineno'> 169</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', title='?'>data</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.shared_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.shared_layer', title='?'>shared_layer</a>([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', title='?'>data</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.attention_mask', title='?'>attention_mask</a>])
<span class='lineno'> 170</span> 
<span class='lineno'> 171</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.first_token_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.first_token_tensor', title='?'>first_token_tensor</a> = (
<span class='lineno'> 172</span>         tf.keras.layers.Lambda(lambda <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.lambda%92.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.lambda%92.x', title='?'>x</a>: tf.squeeze(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.lambda%92.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.lambda%92.x', title='?'>x</a>[:, 0:1, :], axis=1))(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', title='?'>data</a>)
<span class='lineno'> 173</span>     )
<span class='lineno'> 174</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.cls_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.cls_output', title='?'>cls_output</a> = tf.keras.layers.Dense(
<span class='lineno'> 175</span>         units=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.hidden_size', title='int'>hidden_size</a>,
<span class='lineno'> 176</span>         activation=&#39;tanh&#39;,
<span class='lineno'> 177</span>         kernel_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.initializer', title='?'>initializer</a>,
<span class='lineno'> 178</span>         name=&#39;pooler_transform&#39;)(
<span class='lineno'> 179</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.first_token_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.first_token_tensor', title='?'>first_token_tensor</a>)
<span class='lineno'> 180</span> 
<span class='lineno'> 181</span>     super(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder', title='<AlbertTransformerEncoder>'>AlbertTransformerEncoder</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.self', title='AlbertTransformerEncoder'>self</a>).__init__(
<span class='lineno'> 182</span>         inputs=[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.word_ids', title='?'>word_ids</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.mask', title='?'>mask</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.type_ids', title='?'>type_ids</a>], outputs=[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.data', title='?'>data</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.cls_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.__init__.cls_output', title='?'>cls_output</a>], **kwargs)
<span class='lineno'> 183</span> 
<span class='lineno'> 184</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_embedding_table', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_embedding_table', title='AlbertTransformerEncoder -> ?'>get_embedding_table</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_embedding_table.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_embedding_table.self', title='AlbertTransformerEncoder'>self</a>):
<span class='lineno'> 185</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_embedding_table.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_embedding_table.self', title='AlbertTransformerEncoder'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._embedding_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._embedding_layer', title='?'>_embedding_layer</a>.embeddings
<span class='lineno'> 186</span> 
<span class='lineno'> 187</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_config', title='AlbertTransformerEncoder -> dict'>get_config</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_config.self', title='AlbertTransformerEncoder'>self</a>):
<span class='lineno'> 188</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_config.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.get_config.self', title='AlbertTransformerEncoder'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._config_dict', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder._config_dict', title='dict'>_config_dict</a>
<span class='lineno'> 189</span> 
<span class='lineno'> 190</span>   @classmethod
<span class='lineno'> 191</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.from_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.from_config', title='(<AlbertTransformerEncoder>, ?) -> AlbertTransformerEncoder'>from_config</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.from_config.cls', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.from_config.cls', title='<AlbertTransformerEncoder>'>cls</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.from_config.config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.from_config.config', title='?'>config</a>):
<span class='lineno'> 192</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.from_config.cls', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.modeling.networks.albert_transformer_encoder.AlbertTransformerEncoder.from_config.cls', title='<AlbertTransformerEncoder>'>cls</a>(**config)
</pre></td></tr></table></body></html>