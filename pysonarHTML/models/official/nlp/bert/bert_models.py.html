<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/nlp/bert/bert_models.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer'>BertPretrainLossAndMetricLayer</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics'>_add_metrics</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call'>call</a></li></ul>
</li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder'>get_transformer_encoder</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model'>pretrain_model</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model'>squad_model</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model'>classifier_model</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2019 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> &quot;&quot;&quot;BERT models that are compatible with TF 2.0.&quot;&quot;&quot;
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span> from __future__ import absolute_import
<span class='lineno'>  18</span> from __future__ import division
<span class='lineno'>  19</span> from __future__ import print_function
<span class='lineno'>  20</span> 
<span class='lineno'>  21</span> import gin
<span class='lineno'>  22</span> import tensorflow as tf
<span class='lineno'>  23</span> import tensorflow_hub as hub
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> from official.modeling import tf_utils
<span class='lineno'>  26</span> from official.nlp.albert import configs as albert_configs
<span class='lineno'>  27</span> from official.nlp.bert import configs
<span class='lineno'>  28</span> from official.nlp.modeling import losses
<span class='lineno'>  29</span> from official.nlp.modeling import models
<span class='lineno'>  30</span> from official.nlp.modeling import networks
<span class='lineno'>  31</span> 
<span class='lineno'>  32</span> 
<span class='lineno'>  33</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer', title='<BertPretrainLossAndMetricLayer>'>BertPretrainLossAndMetricLayer</a>(tf.keras.layers.Layer):
<span class='lineno'>  34</span>   &quot;&quot;&quot;Returns layer that computes custom loss and metrics for pretraining.&quot;&quot;&quot;
<span class='lineno'>  35</span> 
<span class='lineno'>  36</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.self', title='BertPretrainLossAndMetricLayer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.vocab_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.vocab_size', title='?'>vocab_size</a>, **kwargs):
<span class='lineno'>  37</span>     super(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer', title='<BertPretrainLossAndMetricLayer>'>BertPretrainLossAndMetricLayer</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.self', title='BertPretrainLossAndMetricLayer'>self</a>).__init__(**kwargs)
<span class='lineno'>  38</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.self', title='BertPretrainLossAndMetricLayer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._vocab_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._vocab_size', title='?'>_vocab_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.vocab_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.vocab_size', title='?'>vocab_size</a>
<span class='lineno'>  39</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.self', title='BertPretrainLossAndMetricLayer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.config', title='dict'>config</a> = {
<span class='lineno'>  40</span>         &#39;vocab_size&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.vocab_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.__init__.vocab_size', title='?'>vocab_size</a>,
<span class='lineno'>  41</span>     }
<span class='lineno'>  42</span> 
<span class='lineno'>  43</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics', title='(BertPretrainLossAndMetricLayer, ?, ?, ?, ?, ?, ?, ?) -> None / (BertPretrainLossAndMetricLayer, ?, ?, ?, ?, ?, None, None) -> None'>_add_metrics</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.self', title='BertPretrainLossAndMetricLayer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_output', title='?'>lm_output</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_labels', title='?'>lm_labels</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_label_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_label_weights', title='?'>lm_label_weights</a>,
<span class='lineno'>  44</span>                    <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_example_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_example_loss', title='?'>lm_example_loss</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.sentence_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.sentence_output', title='?'>sentence_output</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.sentence_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.sentence_labels', title='None'>sentence_labels</a>,
<span class='lineno'>  45</span>                    <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.next_sentence_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.next_sentence_loss', title='None'>next_sentence_loss</a>):
<span class='lineno'>  46</span>     &quot;&quot;&quot;Adds metrics.&quot;&quot;&quot;
<span class='lineno'>  47</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.masked_lm_accuracy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.masked_lm_accuracy', title='?'>masked_lm_accuracy</a> = tf.keras.metrics.sparse_categorical_accuracy(
<span class='lineno'>  48</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_labels', title='?'>lm_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_output', title='?'>lm_output</a>)
<span class='lineno'>  49</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.numerator', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.numerator', title='?'>numerator</a> = tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.masked_lm_accuracy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.masked_lm_accuracy', title='?'>masked_lm_accuracy</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_label_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_label_weights', title='?'>lm_label_weights</a>)
<span class='lineno'>  50</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.denominator', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.denominator', title='float'>denominator</a> = tf.reduce_sum(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_label_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_label_weights', title='?'>lm_label_weights</a>) + 1e-5
<span class='lineno'>  51</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.masked_lm_accuracy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.masked_lm_accuracy', title='float'>masked_lm_accuracy</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.numerator', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.numerator', title='?'>numerator</a> / <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.denominator', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.denominator', title='float'>denominator</a>
<span class='lineno'>  52</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.self', title='BertPretrainLossAndMetricLayer'>self</a>.add_metric(
<span class='lineno'>  53</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.masked_lm_accuracy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.masked_lm_accuracy', title='float'>masked_lm_accuracy</a>, name=&#39;masked_lm_accuracy&#39;, aggregation=&#39;mean&#39;)
<span class='lineno'>  54</span> 
<span class='lineno'>  55</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.self', title='BertPretrainLossAndMetricLayer'>self</a>.add_metric(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_example_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.lm_example_loss', title='?'>lm_example_loss</a>, name=&#39;lm_example_loss&#39;, aggregation=&#39;mean&#39;)
<span class='lineno'>  56</span> 
<span class='lineno'>  57</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.sentence_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.sentence_labels', title='None'>sentence_labels</a> is not None:
<span class='lineno'>  58</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.next_sentence_accuracy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.next_sentence_accuracy', title='?'>next_sentence_accuracy</a> = tf.keras.metrics.sparse_categorical_accuracy(
<span class='lineno'>  59</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.sentence_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.sentence_labels', title='None'>sentence_labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.sentence_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.sentence_output', title='?'>sentence_output</a>)
<span class='lineno'>  60</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.self', title='BertPretrainLossAndMetricLayer'>self</a>.add_metric(
<span class='lineno'>  61</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.next_sentence_accuracy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.next_sentence_accuracy', title='?'>next_sentence_accuracy</a>,
<span class='lineno'>  62</span>           name=&#39;next_sentence_accuracy&#39;,
<span class='lineno'>  63</span>           aggregation=&#39;mean&#39;)
<span class='lineno'>  64</span> 
<span class='lineno'>  65</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.next_sentence_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.next_sentence_loss', title='None'>next_sentence_loss</a> is not None:
<span class='lineno'>  66</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.self', title='BertPretrainLossAndMetricLayer'>self</a>.add_metric(
<span class='lineno'>  67</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.next_sentence_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics.next_sentence_loss', title='None'>next_sentence_loss</a>, name=&#39;next_sentence_loss&#39;, aggregation=&#39;mean&#39;)
<span class='lineno'>  68</span> 
<span class='lineno'>  69</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call', title='(BertPretrainLossAndMetricLayer, ?, ?, ?, ?, None) -> None'>call</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.self', title='BertPretrainLossAndMetricLayer'>self</a>,
<span class='lineno'>  70</span>            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_output', title='?'>lm_output</a>,
<span class='lineno'>  71</span>            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_output', title='?'>sentence_output</a>,
<span class='lineno'>  72</span>            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_ids', title='?'>lm_label_ids</a>,
<span class='lineno'>  73</span>            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_weights', title='?'>lm_label_weights</a>,
<span class='lineno'>  74</span>            <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_labels', title='None'>sentence_labels</a>=None):
<span class='lineno'>  75</span>     &quot;&quot;&quot;Implements call() for the layer.&quot;&quot;&quot;
<span class='lineno'>  76</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_weights', title='?'>lm_label_weights</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_weights', title='?'>lm_label_weights</a>, tf.float32)
<span class='lineno'>  77</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_output', title='?'>lm_output</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_output', title='?'>lm_output</a>, tf.float32)
<span class='lineno'>  78</span> 
<span class='lineno'>  79</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.mask_label_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.mask_label_loss', title='?'>mask_label_loss</a> = losses.weighted_sparse_categorical_crossentropy_loss(
<span class='lineno'>  80</span>         labels=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_ids', title='?'>lm_label_ids</a>, predictions=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_output', title='?'>lm_output</a>, weights=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_weights', title='?'>lm_label_weights</a>)
<span class='lineno'>  81</span> 
<span class='lineno'>  82</span>     if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_labels', title='None'>sentence_labels</a> is not None:
<span class='lineno'>  83</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_output', title='?'>sentence_output</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_output', title='?'>sentence_output</a>, tf.float32)
<span class='lineno'>  84</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_loss', title='?'>sentence_loss</a> = losses.weighted_sparse_categorical_crossentropy_loss(
<span class='lineno'>  85</span>           labels=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_labels', title='None'>sentence_labels</a>, predictions=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_output', title='?'>sentence_output</a>)
<span class='lineno'>  86</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.loss', title='?'>loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.mask_label_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.mask_label_loss', title='?'>mask_label_loss</a> + <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_loss', title='?'>sentence_loss</a>
<span class='lineno'>  87</span>     else:
<span class='lineno'>  88</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_loss', title='None'>sentence_loss</a> = None
<span class='lineno'>  89</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.loss', title='?'>loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.mask_label_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.mask_label_loss', title='?'>mask_label_loss</a>
<span class='lineno'>  90</span> 
<span class='lineno'>  91</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.batch_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.batch_shape', title='?'>batch_shape</a> = tf.slice(tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_ids', title='?'>lm_label_ids</a>), [0], [1])
<span class='lineno'>  92</span>     # TODO(hongkuny): Avoids the hack and switches add_loss.
<span class='lineno'>  93</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.final_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.final_loss', title='?'>final_loss</a> = tf.fill(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.batch_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.batch_shape', title='?'>batch_shape</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.loss', title='?'>loss</a>)
<span class='lineno'>  94</span> 
<span class='lineno'>  95</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.self', title='BertPretrainLossAndMetricLayer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer._add_metrics', title='(BertPretrainLossAndMetricLayer, ?, ?, ?, ?, ?, ?, ?) -> None / (BertPretrainLossAndMetricLayer, ?, ?, ?, ?, ?, None, None) -> None'>_add_metrics</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_output', title='?'>lm_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_ids', title='?'>lm_label_ids</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.lm_label_weights', title='?'>lm_label_weights</a>,
<span class='lineno'>  96</span>                       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.mask_label_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.mask_label_loss', title='?'>mask_label_loss</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_output', title='?'>sentence_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_labels', title='None'>sentence_labels</a>,
<span class='lineno'>  97</span>                       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.sentence_loss', title='None'>sentence_loss</a>)
<span class='lineno'>  98</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.final_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer.call.final_loss', title='?'>final_loss</a>
<span class='lineno'>  99</span> 
<span class='lineno'> 100</span> 
<span class='lineno'> 101</span> @gin.configurable
<span class='lineno'> 102</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder', title='(?, None, None, None) -> None / (?, ?, None, None) -> None'>get_transformer_encoder</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>,
<span class='lineno'> 103</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.sequence_length', title='None'>sequence_length</a>,
<span class='lineno'> 104</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.transformer_encoder_cls', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.transformer_encoder_cls', title='None'>transformer_encoder_cls</a>=None,
<span class='lineno'> 105</span>                             <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.output_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.output_range', title='None'>output_range</a>=None):
<span class='lineno'> 106</span>   &quot;&quot;&quot;Gets a &#39;TransformerEncoder&#39; object.
<span class='lineno'> 107</span> 
<span class='lineno'> 108</span>   Args:
<span class='lineno'> 109</span>     bert_config: A &#39;modeling.BertConfig&#39; or &#39;modeling.AlbertConfig&#39; object.
<span class='lineno'> 110</span>     sequence_length: Maximum sequence length of the training data.
<span class='lineno'> 111</span>     transformer_encoder_cls: A EncoderScaffold class. If it is None, uses the
<span class='lineno'> 112</span>       default BERT encoder implementation.
<span class='lineno'> 113</span>     output_range: the sequence output range, [0, output_range). Default setting
<span class='lineno'> 114</span>       is to return the entire sequence output.
<span class='lineno'> 115</span> 
<span class='lineno'> 116</span>   Returns:
<span class='lineno'> 117</span>     A networks.TransformerEncoder object.
<span class='lineno'> 118</span>   &quot;&quot;&quot;
<span class='lineno'> 119</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.transformer_encoder_cls', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.transformer_encoder_cls', title='None'>transformer_encoder_cls</a> is not None:
<span class='lineno'> 120</span>     # TODO(hongkuny): evaluate if it is better to put cfg definition in gin.
<span class='lineno'> 121</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.embedding_cfg', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.embedding_cfg', title='dict'>embedding_cfg</a> = dict(
<span class='lineno'> 122</span>         vocab_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.vocab_size,
<span class='lineno'> 123</span>         type_vocab_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.type_vocab_size,
<span class='lineno'> 124</span>         hidden_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.hidden_size,
<span class='lineno'> 125</span>         seq_length=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.sequence_length', title='None'>sequence_length</a>,
<span class='lineno'> 126</span>         max_seq_length=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.max_position_embeddings,
<span class='lineno'> 127</span>         initializer=tf.keras.initializers.TruncatedNormal(
<span class='lineno'> 128</span>             stddev=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.initializer_range),
<span class='lineno'> 129</span>         dropout_rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.hidden_dropout_prob,
<span class='lineno'> 130</span>     )
<span class='lineno'> 131</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.hidden_cfg', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.hidden_cfg', title='dict'>hidden_cfg</a> = dict(
<span class='lineno'> 132</span>         num_attention_heads=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.num_attention_heads,
<span class='lineno'> 133</span>         intermediate_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.intermediate_size,
<span class='lineno'> 134</span>         intermediate_activation=tf_utils.get_activation(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.hidden_act),
<span class='lineno'> 135</span>         dropout_rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.hidden_dropout_prob,
<span class='lineno'> 136</span>         attention_dropout_rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.attention_probs_dropout_prob,
<span class='lineno'> 137</span>         kernel_initializer=tf.keras.initializers.TruncatedNormal(
<span class='lineno'> 138</span>             stddev=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.initializer_range),
<span class='lineno'> 139</span>     )
<span class='lineno'> 140</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.kwargs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.kwargs', title='dict'>kwargs</a> = dict(
<span class='lineno'> 141</span>         embedding_cfg=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.embedding_cfg', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.embedding_cfg', title='dict'>embedding_cfg</a>,
<span class='lineno'> 142</span>         hidden_cfg=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.hidden_cfg', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.hidden_cfg', title='dict'>hidden_cfg</a>,
<span class='lineno'> 143</span>         num_hidden_instances=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.num_hidden_layers,
<span class='lineno'> 144</span>         pooled_output_dim=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.hidden_size,
<span class='lineno'> 145</span>         pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
<span class='lineno'> 146</span>             stddev=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.initializer_range))
<span class='lineno'> 147</span> 
<span class='lineno'> 148</span>     # Relies on gin configuration to define the Transformer encoder arguments.
<span class='lineno'> 149</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.transformer_encoder_cls', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.transformer_encoder_cls', title='None'>transformer_encoder_cls</a>(**kwargs)
<span class='lineno'> 150</span> 
<span class='lineno'> 151</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.kwargs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.kwargs', title='dict'>kwargs</a> = dict(
<span class='lineno'> 152</span>       vocab_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.vocab_size,
<span class='lineno'> 153</span>       hidden_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.hidden_size,
<span class='lineno'> 154</span>       num_layers=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.num_hidden_layers,
<span class='lineno'> 155</span>       num_attention_heads=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.num_attention_heads,
<span class='lineno'> 156</span>       intermediate_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.intermediate_size,
<span class='lineno'> 157</span>       activation=tf_utils.get_activation(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.hidden_act),
<span class='lineno'> 158</span>       dropout_rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.hidden_dropout_prob,
<span class='lineno'> 159</span>       attention_dropout_rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.attention_probs_dropout_prob,
<span class='lineno'> 160</span>       sequence_length=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.sequence_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.sequence_length', title='None'>sequence_length</a>,
<span class='lineno'> 161</span>       max_sequence_length=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.max_position_embeddings,
<span class='lineno'> 162</span>       type_vocab_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.type_vocab_size,
<span class='lineno'> 163</span>       embedding_width=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.embedding_size,
<span class='lineno'> 164</span>       initializer=tf.keras.initializers.TruncatedNormal(
<span class='lineno'> 165</span>           stddev=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>.initializer_range))
<span class='lineno'> 166</span>   if isinstance(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a></a>, albert_configs.AlbertConfig):
<span class='lineno'> 167</span>     return networks.AlbertTransformerEncoder(**kwargs)
<span class='lineno'> 168</span>   else:
<span class='lineno'> 169</span>     assert isinstance(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.bert_config', title='?'>bert_config</a>, configs.BertConfig)
<span class='lineno'> 170</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.kwargs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.kwargs', title='dict'>kwargs</a>[&#39;output_range&#39;] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.output_range', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder.output_range', title='None'>output_range</a>
<span class='lineno'> 171</span>     return networks.TransformerEncoder(**kwargs)
<span class='lineno'> 172</span> 
<span class='lineno'> 173</span> 
<span class='lineno'> 174</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model', title='(?, ?, ?, None, bool, bool) -> {(?, None) | (?, None, ?)}'>pretrain_model</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.bert_config', title='?'>bert_config</a>,
<span class='lineno'> 175</span>                    <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.seq_length', title='?'>seq_length</a>,
<span class='lineno'> 176</span>                    <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.max_predictions_per_seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.max_predictions_per_seq', title='?'>max_predictions_per_seq</a>,
<span class='lineno'> 177</span>                    <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.initializer', title='None'>initializer</a>=None,
<span class='lineno'> 178</span>                    <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.use_next_sentence_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.use_next_sentence_label', title='bool'>use_next_sentence_label</a>=True,
<span class='lineno'> 179</span>                    <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.return_core_pretrainer_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.return_core_pretrainer_model', title='bool'>return_core_pretrainer_model</a>=False):
<span class='lineno'> 180</span>   &quot;&quot;&quot;Returns model to be used for pre-training.
<span class='lineno'> 181</span> 
<span class='lineno'> 182</span>   Args:
<span class='lineno'> 183</span>       bert_config: Configuration that defines the core BERT model.
<span class='lineno'> 184</span>       seq_length: Maximum sequence length of the training data.
<span class='lineno'> 185</span>       max_predictions_per_seq: Maximum number of tokens in sequence to mask out
<span class='lineno'> 186</span>         and use for pretraining.
<span class='lineno'> 187</span>       initializer: Initializer for weights in BertPretrainer.
<span class='lineno'> 188</span>       use_next_sentence_label: Whether to use the next sentence label.
<span class='lineno'> 189</span>       return_core_pretrainer_model: Whether to also return the `BertPretrainer`
<span class='lineno'> 190</span>         object.
<span class='lineno'> 191</span> 
<span class='lineno'> 192</span>   Returns:
<span class='lineno'> 193</span>       A Tuple of (1) Pretraining model, (2) core BERT submodel from which to
<span class='lineno'> 194</span>       save weights after pretraining, and (3) optional core `BertPretrainer`
<span class='lineno'> 195</span>       object if argument `return_core_pretrainer_model` is True.
<span class='lineno'> 196</span>   &quot;&quot;&quot;
<span class='lineno'> 197</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_word_ids', title='?'>input_word_ids</a> = tf.keras.layers.Input(
<span class='lineno'> 198</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.seq_length', title='?'>seq_length</a>,), name=&#39;input_word_ids&#39;, dtype=tf.int32)
<span class='lineno'> 199</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_mask', title='?'>input_mask</a> = tf.keras.layers.Input(
<span class='lineno'> 200</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.seq_length', title='?'>seq_length</a>,), name=&#39;input_mask&#39;, dtype=tf.int32)
<span class='lineno'> 201</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_type_ids', title='?'>input_type_ids</a> = tf.keras.layers.Input(
<span class='lineno'> 202</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.seq_length', title='?'>seq_length</a>,), name=&#39;input_type_ids&#39;, dtype=tf.int32)
<span class='lineno'> 203</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_positions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_positions', title='?'>masked_lm_positions</a> = tf.keras.layers.Input(
<span class='lineno'> 204</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.max_predictions_per_seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.max_predictions_per_seq', title='?'>max_predictions_per_seq</a>,),
<span class='lineno'> 205</span>       name=&#39;masked_lm_positions&#39;,
<span class='lineno'> 206</span>       dtype=tf.int32)
<span class='lineno'> 207</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_ids', title='?'>masked_lm_ids</a> = tf.keras.layers.Input(
<span class='lineno'> 208</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.max_predictions_per_seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.max_predictions_per_seq', title='?'>max_predictions_per_seq</a>,), name=&#39;masked_lm_ids&#39;, dtype=tf.int32)
<span class='lineno'> 209</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_weights', title='?'>masked_lm_weights</a> = tf.keras.layers.Input(
<span class='lineno'> 210</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.max_predictions_per_seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.max_predictions_per_seq', title='?'>max_predictions_per_seq</a>,),
<span class='lineno'> 211</span>       name=&#39;masked_lm_weights&#39;,
<span class='lineno'> 212</span>       dtype=tf.int32)
<span class='lineno'> 213</span> 
<span class='lineno'> 214</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.use_next_sentence_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.use_next_sentence_label', title='bool'>use_next_sentence_label</a>:
<span class='lineno'> 215</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.next_sentence_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.next_sentence_labels', title='?'>next_sentence_labels</a> = tf.keras.layers.Input(
<span class='lineno'> 216</span>         shape=(1,), name=&#39;next_sentence_labels&#39;, dtype=tf.int32)
<span class='lineno'> 217</span>   else:
<span class='lineno'> 218</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.next_sentence_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.next_sentence_labels', title='None'>next_sentence_labels</a> = None
<span class='lineno'> 219</span> 
<span class='lineno'> 220</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.transformer_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.transformer_encoder', title='None'>transformer_encoder</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder', title='(?, None, None, None) -> None / (?, ?, None, None) -> None'>get_transformer_encoder</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.bert_config', title='?'>bert_config</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.seq_length', title='?'>seq_length</a>)
<span class='lineno'> 221</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.initializer', title='None'>initializer</a> is None:
<span class='lineno'> 222</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.initializer', title='?'>initializer</a> = tf.keras.initializers.TruncatedNormal(
<span class='lineno'> 223</span>         stddev=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.bert_config', title='?'>bert_config</a>.initializer_range)
<span class='lineno'> 224</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.pretrainer_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.pretrainer_model', title='?'>pretrainer_model</a> = models.BertPretrainer(
<span class='lineno'> 225</span>       network=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.transformer_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.transformer_encoder', title='None'>transformer_encoder</a>,
<span class='lineno'> 226</span>       embedding_table=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.transformer_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.transformer_encoder', title='None'>transformer_encoder</a>.get_embedding_table(),
<span class='lineno'> 227</span>       num_classes=2,  # The next sentence prediction label has two classes.
<span class='lineno'> 228</span>       activation=tf_utils.get_activation(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.bert_config', title='?'>bert_config</a>.hidden_act),
<span class='lineno'> 229</span>       num_token_predictions=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.max_predictions_per_seq', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.max_predictions_per_seq', title='?'>max_predictions_per_seq</a>,
<span class='lineno'> 230</span>       initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.initializer', title='None'>initializer</a>,
<span class='lineno'> 231</span>       output=&#39;predictions&#39;)
<span class='lineno'> 232</span> 
<span class='lineno'> 233</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.outputs', title='?'>outputs</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.pretrainer_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.pretrainer_model', title='?'>pretrainer_model</a>(
<span class='lineno'> 234</span>       [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_word_ids', title='?'>input_word_ids</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_mask', title='?'>input_mask</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_type_ids', title='?'>input_type_ids</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_positions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_positions', title='?'>masked_lm_positions</a>])
<span class='lineno'> 235</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.lm_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.lm_output', title='?'>lm_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.outputs', title='?'>outputs</a>[&#39;masked_lm&#39;]
<span class='lineno'> 236</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.sentence_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.sentence_output', title='?'>sentence_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.outputs', title='?'>outputs</a>[&#39;classification&#39;]
<span class='lineno'> 237</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.pretrain_loss_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.pretrain_loss_layer', title='BertPretrainLossAndMetricLayer'>pretrain_loss_layer</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.BertPretrainLossAndMetricLayer', title='<BertPretrainLossAndMetricLayer>'>BertPretrainLossAndMetricLayer</a>(
<span class='lineno'> 238</span>       vocab_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.bert_config', title='?'>bert_config</a>.vocab_size)
<span class='lineno'> 239</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.output_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.output_loss', title='?'>output_loss</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.pretrain_loss_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.pretrain_loss_layer', title='BertPretrainLossAndMetricLayer'>pretrain_loss_layer</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.lm_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.lm_output', title='?'>lm_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.sentence_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.sentence_output', title='?'>sentence_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_ids', title='?'>masked_lm_ids</a>,
<span class='lineno'> 240</span>                                     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_weights', title='?'>masked_lm_weights</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.next_sentence_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.next_sentence_labels', title='None'>next_sentence_labels</a>)
<span class='lineno'> 241</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.inputs', title='dict'>inputs</a> = {
<span class='lineno'> 242</span>       &#39;input_word_ids&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_word_ids', title='?'>input_word_ids</a>,
<span class='lineno'> 243</span>       &#39;input_mask&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_mask', title='?'>input_mask</a>,
<span class='lineno'> 244</span>       &#39;input_type_ids&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.input_type_ids', title='?'>input_type_ids</a>,
<span class='lineno'> 245</span>       &#39;masked_lm_positions&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_positions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_positions', title='?'>masked_lm_positions</a>,
<span class='lineno'> 246</span>       &#39;masked_lm_ids&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_ids', title='?'>masked_lm_ids</a>,
<span class='lineno'> 247</span>       &#39;masked_lm_weights&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_weights', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.masked_lm_weights', title='?'>masked_lm_weights</a>,
<span class='lineno'> 248</span>   }
<span class='lineno'> 249</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.use_next_sentence_label', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.use_next_sentence_label', title='bool'>use_next_sentence_label</a>:
<span class='lineno'> 250</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.inputs', title='dict'>inputs</a>[&#39;next_sentence_labels&#39;] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.next_sentence_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.next_sentence_labels', title='None'>next_sentence_labels</a>
<span class='lineno'> 251</span> 
<span class='lineno'> 252</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.keras_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.keras_model', title='?'>keras_model</a> = tf.keras.Model(inputs=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.inputs', title='dict'>inputs</a>, outputs=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.output_loss', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.output_loss', title='?'>output_loss</a>)
<span class='lineno'> 253</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.return_core_pretrainer_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.return_core_pretrainer_model', title='bool'>return_core_pretrainer_model</a>:
<span class='lineno'> 254</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.keras_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.keras_model', title='?'>keras_model</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.transformer_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.transformer_encoder', title='None'>transformer_encoder</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.pretrainer_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.pretrainer_model', title='?'>pretrainer_model</a>
<span class='lineno'> 255</span>   else:
<span class='lineno'> 256</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.keras_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.keras_model', title='?'>keras_model</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.transformer_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.pretrain_model.transformer_encoder', title='None'>transformer_encoder</a>
<span class='lineno'> 257</span> 
<span class='lineno'> 258</span> 
<span class='lineno'> 259</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model', title='(?, ?, None, None, bool) -> (?, None)'>squad_model</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_config', title='?'>bert_config</a>,
<span class='lineno'> 260</span>                 <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.max_seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.max_seq_length', title='?'>max_seq_length</a>,
<span class='lineno'> 261</span>                 <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.initializer', title='None'>initializer</a>=None,
<span class='lineno'> 262</span>                 <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.hub_module_url', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.hub_module_url', title='None'>hub_module_url</a>=None,
<span class='lineno'> 263</span>                 <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.hub_module_trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.hub_module_trainable', title='bool'>hub_module_trainable</a>=True):
<span class='lineno'> 264</span>   &quot;&quot;&quot;Returns BERT Squad model along with core BERT model to import weights.
<span class='lineno'> 265</span> 
<span class='lineno'> 266</span>   Args:
<span class='lineno'> 267</span>     bert_config: BertConfig, the config defines the core Bert model.
<span class='lineno'> 268</span>     max_seq_length: integer, the maximum input sequence length.
<span class='lineno'> 269</span>     initializer: Initializer for the final dense layer in the span labeler.
<span class='lineno'> 270</span>       Defaulted to TruncatedNormal initializer.
<span class='lineno'> 271</span>     hub_module_url: TF-Hub path/url to Bert module.
<span class='lineno'> 272</span>     hub_module_trainable: True to finetune layers in the hub module.
<span class='lineno'> 273</span> 
<span class='lineno'> 274</span>   Returns:
<span class='lineno'> 275</span>     A tuple of (1) keras model that outputs start logits and end logits and
<span class='lineno'> 276</span>     (2) the core BERT transformer encoder.
<span class='lineno'> 277</span>   &quot;&quot;&quot;
<span class='lineno'> 278</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.initializer', title='None'>initializer</a> is None:
<span class='lineno'> 279</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.initializer', title='?'>initializer</a> = tf.keras.initializers.TruncatedNormal(
<span class='lineno'> 280</span>         stddev=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_config', title='?'>bert_config</a>.initializer_range)
<span class='lineno'> 281</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.hub_module_url', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.hub_module_url', title='None'>hub_module_url</a>:
<span class='lineno'> 282</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', title='None'>bert_encoder</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder', title='(?, None, None, None) -> None / (?, ?, None, None) -> None'>get_transformer_encoder</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_config', title='?'>bert_config</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.max_seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.max_seq_length', title='?'>max_seq_length</a>)
<span class='lineno'> 283</span>     return models.BertSpanLabeler(
<span class='lineno'> 284</span>         network=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', title='None'>bert_encoder</a>, initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.initializer', title='None'>initializer</a>), <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', title='None'>bert_encoder</a>
<span class='lineno'> 285</span> 
<span class='lineno'> 286</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_word_ids', title='?'>input_word_ids</a> = tf.keras.layers.Input(
<span class='lineno'> 287</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.max_seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.max_seq_length', title='?'>max_seq_length</a>,), dtype=tf.int32, name=&#39;input_word_ids&#39;)
<span class='lineno'> 288</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_mask', title='?'>input_mask</a> = tf.keras.layers.Input(
<span class='lineno'> 289</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.max_seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.max_seq_length', title='?'>max_seq_length</a>,), dtype=tf.int32, name=&#39;input_mask&#39;)
<span class='lineno'> 290</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_type_ids', title='?'>input_type_ids</a> = tf.keras.layers.Input(
<span class='lineno'> 291</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.max_seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.max_seq_length', title='?'>max_seq_length</a>,), dtype=tf.int32, name=&#39;input_type_ids&#39;)
<span class='lineno'> 292</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.core_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.core_model', title='?'>core_model</a> = hub.KerasLayer(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.hub_module_url', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.hub_module_url', title='None'>hub_module_url</a>, trainable=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.hub_module_trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.hub_module_trainable', title='bool'>hub_module_trainable</a>)
<span class='lineno'> 293</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.pooled_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.pooled_output', title='?'>pooled_output</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.sequence_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.sequence_output', title='?'>sequence_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.core_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.core_model', title='?'>core_model</a>(
<span class='lineno'> 294</span>       [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_word_ids', title='?'>input_word_ids</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_mask', title='?'>input_mask</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_type_ids', title='?'>input_type_ids</a>])
<span class='lineno'> 295</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', title='?'>bert_encoder</a> = tf.keras.Model(
<span class='lineno'> 296</span>       inputs={
<span class='lineno'> 297</span>           &#39;input_word_ids&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_word_ids', title='?'>input_word_ids</a>,
<span class='lineno'> 298</span>           &#39;input_mask&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_mask', title='?'>input_mask</a>,
<span class='lineno'> 299</span>           &#39;input_type_ids&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.input_type_ids', title='?'>input_type_ids</a>,
<span class='lineno'> 300</span>       },
<span class='lineno'> 301</span>       outputs=[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.sequence_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.sequence_output', title='?'>sequence_output</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.pooled_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.pooled_output', title='?'>pooled_output</a>],
<span class='lineno'> 302</span>       name=&#39;core_model&#39;)
<span class='lineno'> 303</span>   return models.BertSpanLabeler(
<span class='lineno'> 304</span>       network=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', title='?'>bert_encoder</a>, initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.initializer', title='None'>initializer</a>), <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.squad_model.bert_encoder', title='?'>bert_encoder</a>
<span class='lineno'> 305</span> 
<span class='lineno'> 306</span> 
<span class='lineno'> 307</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model', title='(?, ?, None, None, None, bool) -> (?, None)'>classifier_model</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_config', title='?'>bert_config</a>,
<span class='lineno'> 308</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.num_labels', title='?'>num_labels</a>,
<span class='lineno'> 309</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.max_seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.max_seq_length', title='None'>max_seq_length</a>=None,
<span class='lineno'> 310</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.final_layer_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.final_layer_initializer', title='None'>final_layer_initializer</a>=None,
<span class='lineno'> 311</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.hub_module_url', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.hub_module_url', title='None'>hub_module_url</a>=None,
<span class='lineno'> 312</span>                      <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.hub_module_trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.hub_module_trainable', title='bool'>hub_module_trainable</a>=True):
<span class='lineno'> 313</span>   &quot;&quot;&quot;BERT classifier model in functional API style.
<span class='lineno'> 314</span> 
<span class='lineno'> 315</span>   Construct a Keras model for predicting `num_labels` outputs from an input with
<span class='lineno'> 316</span>   maximum sequence length `max_seq_length`.
<span class='lineno'> 317</span> 
<span class='lineno'> 318</span>   Args:
<span class='lineno'> 319</span>     bert_config: BertConfig or AlbertConfig, the config defines the core BERT or
<span class='lineno'> 320</span>       ALBERT model.
<span class='lineno'> 321</span>     num_labels: integer, the number of classes.
<span class='lineno'> 322</span>     max_seq_length: integer, the maximum input sequence length.
<span class='lineno'> 323</span>     final_layer_initializer: Initializer for final dense layer. Defaulted
<span class='lineno'> 324</span>       TruncatedNormal initializer.
<span class='lineno'> 325</span>     hub_module_url: TF-Hub path/url to Bert module.
<span class='lineno'> 326</span>     hub_module_trainable: True to finetune layers in the hub module.
<span class='lineno'> 327</span> 
<span class='lineno'> 328</span>   Returns:
<span class='lineno'> 329</span>     Combined prediction model (words, mask, type) -&gt; (one-hot labels)
<span class='lineno'> 330</span>     BERT sub-model (words, mask, type) -&gt; (bert_outputs)
<span class='lineno'> 331</span>   &quot;&quot;&quot;
<span class='lineno'> 332</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.final_layer_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.final_layer_initializer', title='None'>final_layer_initializer</a> is not None:
<span class='lineno'> 333</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.initializer', title='None'>initializer</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.final_layer_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.final_layer_initializer', title='None'>final_layer_initializer</a>
<span class='lineno'> 334</span>   else:
<span class='lineno'> 335</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.initializer', title='?'>initializer</a> = tf.keras.initializers.TruncatedNormal(
<span class='lineno'> 336</span>         stddev=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_config', title='?'>bert_config</a>.initializer_range)
<span class='lineno'> 337</span> 
<span class='lineno'> 338</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.hub_module_url', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.hub_module_url', title='None'>hub_module_url</a>:
<span class='lineno'> 339</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_encoder', title='None'>bert_encoder</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.get_transformer_encoder', title='(?, None, None, None) -> None / (?, ?, None, None) -> None'>get_transformer_encoder</a>(
<span class='lineno'> 340</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_config', title='?'>bert_config</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.max_seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.max_seq_length', title='None'>max_seq_length</a>, output_range=1)
<span class='lineno'> 341</span>     return models.BertClassifier(
<span class='lineno'> 342</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_encoder', title='None'>bert_encoder</a>,
<span class='lineno'> 343</span>         num_classes=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.num_labels', title='?'>num_labels</a>,
<span class='lineno'> 344</span>         dropout_rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_config', title='?'>bert_config</a>.hidden_dropout_prob,
<span class='lineno'> 345</span>         initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.initializer', title='None'>initializer</a>), <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_encoder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_encoder', title='None'>bert_encoder</a>
<span class='lineno'> 346</span> 
<span class='lineno'> 347</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_word_ids', title='?'>input_word_ids</a> = tf.keras.layers.Input(
<span class='lineno'> 348</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.max_seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.max_seq_length', title='None'>max_seq_length</a>,), dtype=tf.int32, name=&#39;input_word_ids&#39;)
<span class='lineno'> 349</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_mask', title='?'>input_mask</a> = tf.keras.layers.Input(
<span class='lineno'> 350</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.max_seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.max_seq_length', title='None'>max_seq_length</a>,), dtype=tf.int32, name=&#39;input_mask&#39;)
<span class='lineno'> 351</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_type_ids', title='?'>input_type_ids</a> = tf.keras.layers.Input(
<span class='lineno'> 352</span>       shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.max_seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.max_seq_length', title='None'>max_seq_length</a>,), dtype=tf.int32, name=&#39;input_type_ids&#39;)
<span class='lineno'> 353</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_model', title='?'>bert_model</a> = hub.KerasLayer(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.hub_module_url', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.hub_module_url', title='None'>hub_module_url</a>, trainable=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.hub_module_trainable', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.hub_module_trainable', title='bool'>hub_module_trainable</a>)
<span class='lineno'> 354</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.pooled_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.pooled_output', title='?'>pooled_output</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model._', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model._', title='?'>_</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_model', title='?'>bert_model</a>([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_word_ids', title='?'>input_word_ids</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_mask', title='?'>input_mask</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_type_ids', title='?'>input_type_ids</a>])
<span class='lineno'> 355</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.output', title='?'>output</a> = tf.keras.layers.Dropout(rate=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_config', title='?'>bert_config</a>.hidden_dropout_prob)(
<span class='lineno'> 356</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.pooled_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.pooled_output', title='?'>pooled_output</a>)
<span class='lineno'> 357</span> 
<span class='lineno'> 358</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.output', title='?'>output</a> = tf.keras.layers.Dense(
<span class='lineno'> 359</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.num_labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.num_labels', title='?'>num_labels</a>, kernel_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.initializer', title='None'>initializer</a>, name=&#39;output&#39;)(
<span class='lineno'> 360</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.output', title='?'>output</a>)
<span class='lineno'> 361</span>   return tf.keras.Model(
<span class='lineno'> 362</span>       inputs={
<span class='lineno'> 363</span>           &#39;input_word_ids&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_word_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_word_ids', title='?'>input_word_ids</a>,
<span class='lineno'> 364</span>           &#39;input_mask&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_mask', title='?'>input_mask</a>,
<span class='lineno'> 365</span>           &#39;input_type_ids&#39;: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_type_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.input_type_ids', title='?'>input_type_ids</a>
<span class='lineno'> 366</span>       },
<span class='lineno'> 367</span>       outputs=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.output', title='?'>output</a>), <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.bert_models.classifier_model.bert_model', title='?'>bert_model</a>
</pre></td></tr></table></body></html>