<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/nlp/bert/tokenization_test.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest'>TokenizationTest</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer'>test_full_tokenizer</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese'>test_chinese</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower'>test_basic_tokenizer_lower</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower'>test_basic_tokenizer_no_lower</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc'>test_basic_tokenizer_no_split_on_punc</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer'>test_wordpiece_tokenizer</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids'>test_convert_tokens_to_ids</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace'>test_is_whitespace</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control'>test_is_control</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation'>test_is_punctuation</a></li></ul>
</li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2019 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> from __future__ import absolute_import
<span class='lineno'>  16</span> from __future__ import division
<span class='lineno'>  17</span> from __future__ import print_function
<span class='lineno'>  18</span> 
<span class='lineno'>  19</span> import os
<span class='lineno'>  20</span> import tempfile
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> import six
<span class='lineno'>  23</span> import tensorflow as tf
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> from official.nlp.bert import tokenization
<span class='lineno'>  26</span> 
<span class='lineno'>  27</span> 
<span class='lineno'>  28</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest', title='<TokenizationTest>'>TokenizationTest</a>(tf.test.TestCase):
<span class='lineno'>  29</span>   &quot;&quot;&quot;Tokenization test.
<span class='lineno'>  30</span> 
<span class='lineno'>  31</span>     The implementation is forked from
<span class='lineno'>  32</span>     https://github.com/google-research/bert/blob/master/tokenization_test.py.&quot;
<span class='lineno'>  33</span>   &quot;&quot;&quot;
<span class='lineno'>  34</span> 
<span class='lineno'>  35</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer', title='TokenizationTest -> None'>test_full_tokenizer</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.self', title='TokenizationTest'>self</a>):
<span class='lineno'>  36</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_tokens', title='[str]'>vocab_tokens</a> = [
<span class='lineno'>  37</span>         &quot;[UNK]&quot;, &quot;[CLS]&quot;, &quot;[SEP]&quot;, &quot;want&quot;, &quot;##want&quot;, &quot;##ed&quot;, &quot;wa&quot;, &quot;un&quot;, &quot;runn&quot;,
<span class='lineno'>  38</span>         &quot;##ing&quot;, &quot;,&quot;
<span class='lineno'>  39</span>     ]
<span class='lineno'>  40</span>     with tempfile.NamedTemporaryFile(delete=False) as <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_writer', title='?'>vocab_writer</a>:
<span class='lineno'>  41</span>       if six.PY2:
<span class='lineno'>  42</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_writer', title='?'>vocab_writer</a>.write(&quot;&quot;.join([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', title='str'>x</a> + &quot;\n&quot; for <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', title='str'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', title='str'>x</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_tokens', title='[str]'>vocab_tokens</a>]))
<span class='lineno'>  43</span>       else:
<span class='lineno'>  44</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_writer', title='?'>vocab_writer</a>.write(&quot;&quot;.join([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', title='str'>x</a> + &quot;\n&quot; for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', title='str'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.x', title='str'>x</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_tokens', title='[str]'>vocab_tokens</a>
<span class='lineno'>  45</span>                                    ]).encode(&quot;utf-8&quot;))
<span class='lineno'>  46</span> 
<span class='lineno'>  47</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_file', title='?'>vocab_file</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_writer', title='?'>vocab_writer</a>.name
<span class='lineno'>  48</span> 
<span class='lineno'>  49</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokenizer', title='?'>tokenizer</a> = tokenization.FullTokenizer(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_file', title='?'>vocab_file</a>)
<span class='lineno'>  50</span>     os.unlink(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.vocab_file', title='?'>vocab_file</a>)
<span class='lineno'>  51</span> 
<span class='lineno'>  52</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokens', title='?'>tokens</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokenizer', title='?'>tokenizer</a>.tokenize(u&quot;UNwant\u00E9d,running&quot;)
<span class='lineno'>  53</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.self', title='TokenizationTest'>self</a>.assertAllEqual(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokens', title='?'>tokens</a>, [&quot;un&quot;, &quot;##want&quot;, &quot;##ed&quot;, &quot;,&quot;, &quot;runn&quot;, &quot;##ing&quot;])
<span class='lineno'>  54</span> 
<span class='lineno'>  55</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.self', title='TokenizationTest'>self</a>.assertAllEqual(
<span class='lineno'>  56</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokenizer', title='?'>tokenizer</a>.convert_tokens_to_ids(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_full_tokenizer.tokens', title='?'>tokens</a>), [7, 4, 5, 10, 8, 9])
<span class='lineno'>  57</span> 
<span class='lineno'>  58</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese', title='TokenizationTest -> None'>test_chinese</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese.self', title='TokenizationTest'>self</a>):
<span class='lineno'>  59</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese.tokenizer', title='?'>tokenizer</a> = tokenization.BasicTokenizer()
<span class='lineno'>  60</span> 
<span class='lineno'>  61</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese.self', title='TokenizationTest'>self</a>.assertAllEqual(
<span class='lineno'>  62</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_chinese.tokenizer', title='?'>tokenizer</a>.tokenize(u&quot;ah\u535A\u63A8zz&quot;),
<span class='lineno'>  63</span>         [u&quot;ah&quot;, u&quot;\u535A&quot;, u&quot;\u63A8&quot;, u&quot;zz&quot;])
<span class='lineno'>  64</span> 
<span class='lineno'>  65</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower', title='TokenizationTest -> None'>test_basic_tokenizer_lower</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.self', title='TokenizationTest'>self</a>):
<span class='lineno'>  66</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.tokenizer', title='?'>tokenizer</a> = tokenization.BasicTokenizer(do_lower_case=True)
<span class='lineno'>  67</span> 
<span class='lineno'>  68</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.self', title='TokenizationTest'>self</a>.assertAllEqual(
<span class='lineno'>  69</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.tokenizer', title='?'>tokenizer</a>.tokenize(u&quot; \tHeLLo!how  \n Are yoU?  &quot;),
<span class='lineno'>  70</span>         [&quot;hello&quot;, &quot;!&quot;, &quot;how&quot;, &quot;are&quot;, &quot;you&quot;, &quot;?&quot;])
<span class='lineno'>  71</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.self', title='TokenizationTest'>self</a>.assertAllEqual(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_lower.tokenizer', title='?'>tokenizer</a>.tokenize(u&quot;H\u00E9llo&quot;), [&quot;hello&quot;])
<span class='lineno'>  72</span> 
<span class='lineno'>  73</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower', title='TokenizationTest -> None'>test_basic_tokenizer_no_lower</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower.self', title='TokenizationTest'>self</a>):
<span class='lineno'>  74</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower.tokenizer', title='?'>tokenizer</a> = tokenization.BasicTokenizer(do_lower_case=False)
<span class='lineno'>  75</span> 
<span class='lineno'>  76</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower.self', title='TokenizationTest'>self</a>.assertAllEqual(
<span class='lineno'>  77</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_lower.tokenizer', title='?'>tokenizer</a>.tokenize(u&quot; \tHeLLo!how  \n Are yoU?  &quot;),
<span class='lineno'>  78</span>         [&quot;HeLLo&quot;, &quot;!&quot;, &quot;how&quot;, &quot;Are&quot;, &quot;yoU&quot;, &quot;?&quot;])
<span class='lineno'>  79</span> 
<span class='lineno'>  80</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc', title='TokenizationTest -> None'>test_basic_tokenizer_no_split_on_punc</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc.self', title='TokenizationTest'>self</a>):
<span class='lineno'>  81</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc.tokenizer', title='?'>tokenizer</a> = tokenization.BasicTokenizer(
<span class='lineno'>  82</span>         do_lower_case=True, split_on_punc=False)
<span class='lineno'>  83</span> 
<span class='lineno'>  84</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc.self', title='TokenizationTest'>self</a>.assertAllEqual(
<span class='lineno'>  85</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_basic_tokenizer_no_split_on_punc.tokenizer', title='?'>tokenizer</a>.tokenize(u&quot; \tHeLLo!how  \n Are yoU?  &quot;),
<span class='lineno'>  86</span>         [&quot;hello!how&quot;, &quot;are&quot;, &quot;you?&quot;])
<span class='lineno'>  87</span> 
<span class='lineno'>  88</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer', title='TokenizationTest -> None'>test_wordpiece_tokenizer</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', title='TokenizationTest'>self</a>):
<span class='lineno'>  89</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.vocab_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.vocab_tokens', title='[str]'>vocab_tokens</a> = [
<span class='lineno'>  90</span>         &quot;[UNK]&quot;, &quot;[CLS]&quot;, &quot;[SEP]&quot;, &quot;want&quot;, &quot;##want&quot;, &quot;##ed&quot;, &quot;wa&quot;, &quot;un&quot;, &quot;runn&quot;,
<span class='lineno'>  91</span>         &quot;##ing&quot;, &quot;##!&quot;, &quot;!&quot;
<span class='lineno'>  92</span>     ]
<span class='lineno'>  93</span> 
<span class='lineno'>  94</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.vocab', title='dict'>vocab</a> = {}
<span class='lineno'>  95</span>     for (<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.i', title='?'>i</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.token', title='?'>token</a>) in enumerate(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.vocab_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.vocab_tokens', title='[str]'>vocab_tokens</a>):
<span class='lineno'>  96</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.vocab', title='dict'>vocab</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.token', title='?'>token</a>] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.i', title='?'>i</a>
<span class='lineno'>  97</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', title='?'>tokenizer</a> = tokenization.WordpieceTokenizer(vocab=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.vocab', title='dict'>vocab</a>)
<span class='lineno'>  98</span> 
<span class='lineno'>  99</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', title='TokenizationTest'>self</a>.assertAllEqual(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', title='?'>tokenizer</a>.tokenize(&quot;&quot;), [])
<span class='lineno'> 100</span> 
<span class='lineno'> 101</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', title='TokenizationTest'>self</a>.assertAllEqual(
<span class='lineno'> 102</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', title='?'>tokenizer</a>.tokenize(&quot;unwanted running&quot;),
<span class='lineno'> 103</span>         [&quot;un&quot;, &quot;##want&quot;, &quot;##ed&quot;, &quot;runn&quot;, &quot;##ing&quot;])
<span class='lineno'> 104</span> 
<span class='lineno'> 105</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', title='TokenizationTest'>self</a>.assertAllEqual(
<span class='lineno'> 106</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', title='?'>tokenizer</a>.tokenize(&quot;unwanted running !&quot;),
<span class='lineno'> 107</span>         [&quot;un&quot;, &quot;##want&quot;, &quot;##ed&quot;, &quot;runn&quot;, &quot;##ing&quot;, &quot;!&quot;])
<span class='lineno'> 108</span> 
<span class='lineno'> 109</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', title='TokenizationTest'>self</a>.assertAllEqual(
<span class='lineno'> 110</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', title='?'>tokenizer</a>.tokenize(&quot;unwanted running!&quot;),
<span class='lineno'> 111</span>         [&quot;un&quot;, &quot;##want&quot;, &quot;##ed&quot;, &quot;runn&quot;, &quot;##ing&quot;, &quot;##!&quot;])
<span class='lineno'> 112</span> 
<span class='lineno'> 113</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.self', title='TokenizationTest'>self</a>.assertAllEqual(
<span class='lineno'> 114</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_wordpiece_tokenizer.tokenizer', title='?'>tokenizer</a>.tokenize(&quot;unwantedX running&quot;), [&quot;[UNK]&quot;, &quot;runn&quot;, &quot;##ing&quot;])
<span class='lineno'> 115</span> 
<span class='lineno'> 116</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids', title='TokenizationTest -> None'>test_convert_tokens_to_ids</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.self', title='TokenizationTest'>self</a>):
<span class='lineno'> 117</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.vocab_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.vocab_tokens', title='[str]'>vocab_tokens</a> = [
<span class='lineno'> 118</span>         &quot;[UNK]&quot;, &quot;[CLS]&quot;, &quot;[SEP]&quot;, &quot;want&quot;, &quot;##want&quot;, &quot;##ed&quot;, &quot;wa&quot;, &quot;un&quot;, &quot;runn&quot;,
<span class='lineno'> 119</span>         &quot;##ing&quot;
<span class='lineno'> 120</span>     ]
<span class='lineno'> 121</span> 
<span class='lineno'> 122</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.vocab', title='dict'>vocab</a> = {}
<span class='lineno'> 123</span>     for (<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.i', title='?'>i</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.token', title='?'>token</a>) in enumerate(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.vocab_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.vocab_tokens', title='[str]'>vocab_tokens</a>):
<span class='lineno'> 124</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.vocab', title='dict'>vocab</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.token', title='?'>token</a>] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.i', title='?'>i</a>
<span class='lineno'> 125</span> 
<span class='lineno'> 126</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.self', title='TokenizationTest'>self</a>.assertAllEqual(
<span class='lineno'> 127</span>         tokenization.convert_tokens_to_ids(
<span class='lineno'> 128</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_convert_tokens_to_ids.vocab', title='dict'>vocab</a>, [&quot;un&quot;, &quot;##want&quot;, &quot;##ed&quot;, &quot;runn&quot;, &quot;##ing&quot;]), [7, 4, 5, 8, 9])
<span class='lineno'> 129</span> 
<span class='lineno'> 130</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace', title='TokenizationTest -> None'>test_is_whitespace</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', title='TokenizationTest'>self</a>):
<span class='lineno'> 131</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', title='TokenizationTest'>self</a>.assertTrue(tokenization._is_whitespace(u&quot; &quot;))
<span class='lineno'> 132</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', title='TokenizationTest'>self</a>.assertTrue(tokenization._is_whitespace(u&quot;\t&quot;))
<span class='lineno'> 133</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', title='TokenizationTest'>self</a>.assertTrue(tokenization._is_whitespace(u&quot;\r&quot;))
<span class='lineno'> 134</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', title='TokenizationTest'>self</a>.assertTrue(tokenization._is_whitespace(u&quot;\n&quot;))
<span class='lineno'> 135</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', title='TokenizationTest'>self</a>.assertTrue(tokenization._is_whitespace(u&quot;\u00A0&quot;))
<span class='lineno'> 136</span> 
<span class='lineno'> 137</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', title='TokenizationTest'>self</a>.assertFalse(tokenization._is_whitespace(u&quot;A&quot;))
<span class='lineno'> 138</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_whitespace.self', title='TokenizationTest'>self</a>.assertFalse(tokenization._is_whitespace(u&quot;-&quot;))
<span class='lineno'> 139</span> 
<span class='lineno'> 140</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control', title='TokenizationTest -> None'>test_is_control</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', title='TokenizationTest'>self</a>):
<span class='lineno'> 141</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', title='TokenizationTest'>self</a>.assertTrue(tokenization._is_control(u&quot;\u0005&quot;))
<span class='lineno'> 142</span> 
<span class='lineno'> 143</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', title='TokenizationTest'>self</a>.assertFalse(tokenization._is_control(u&quot;A&quot;))
<span class='lineno'> 144</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', title='TokenizationTest'>self</a>.assertFalse(tokenization._is_control(u&quot; &quot;))
<span class='lineno'> 145</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', title='TokenizationTest'>self</a>.assertFalse(tokenization._is_control(u&quot;\t&quot;))
<span class='lineno'> 146</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', title='TokenizationTest'>self</a>.assertFalse(tokenization._is_control(u&quot;\r&quot;))
<span class='lineno'> 147</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_control.self', title='TokenizationTest'>self</a>.assertFalse(tokenization._is_control(u&quot;\U0001F4A9&quot;))
<span class='lineno'> 148</span> 
<span class='lineno'> 149</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation', title='TokenizationTest -> None'>test_is_punctuation</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', title='TokenizationTest'>self</a>):
<span class='lineno'> 150</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', title='TokenizationTest'>self</a>.assertTrue(tokenization._is_punctuation(u&quot;-&quot;))
<span class='lineno'> 151</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', title='TokenizationTest'>self</a>.assertTrue(tokenization._is_punctuation(u&quot;$&quot;))
<span class='lineno'> 152</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', title='TokenizationTest'>self</a>.assertTrue(tokenization._is_punctuation(u&quot;`&quot;))
<span class='lineno'> 153</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', title='TokenizationTest'>self</a>.assertTrue(tokenization._is_punctuation(u&quot;.&quot;))
<span class='lineno'> 154</span> 
<span class='lineno'> 155</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', title='TokenizationTest'>self</a>.assertFalse(tokenization._is_punctuation(u&quot;A&quot;))
<span class='lineno'> 156</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization_test.TokenizationTest.test_is_punctuation.self', title='TokenizationTest'>self</a>.assertFalse(tokenization._is_punctuation(u&quot; &quot;))
<span class='lineno'> 157</span> 
<span class='lineno'> 158</span> 
<span class='lineno'> 159</span> if __name__ == &quot;__main__&quot;:
<span class='lineno'> 160</span>   tf.test.main()
</pre></td></tr></table></body></html>