<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/nlp/bert/common_flags.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.define_common_bert_flags', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.define_common_bert_flags'>define_common_bert_flags</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.dtype', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.dtype'>dtype</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.use_float16', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.use_float16'>use_float16</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.use_graph_rewrite', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.use_graph_rewrite'>use_graph_rewrite</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.get_loss_scale', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.get_loss_scale'>get_loss_scale</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2019 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> &quot;&quot;&quot;Defining common flags used across all BERT models/applications.&quot;&quot;&quot;
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span> from absl import flags
<span class='lineno'>  18</span> import tensorflow as tf
<span class='lineno'>  19</span> 
<span class='lineno'>  20</span> from official.utils import hyperparams_flags
<span class='lineno'>  21</span> from official.utils.flags import core as flags_core
<span class='lineno'>  22</span> 
<span class='lineno'>  23</span> 
<span class='lineno'>  24</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.define_common_bert_flags', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.define_common_bert_flags', title='() -> None'>define_common_bert_flags</a>():
<span class='lineno'>  25</span>   &quot;&quot;&quot;Define common flags for BERT tasks.&quot;&quot;&quot;
<span class='lineno'>  26</span>   flags_core.define_base(
<span class='lineno'>  27</span>       data_dir=False,
<span class='lineno'>  28</span>       model_dir=True,
<span class='lineno'>  29</span>       clean=False,
<span class='lineno'>  30</span>       train_epochs=False,
<span class='lineno'>  31</span>       epochs_between_evals=False,
<span class='lineno'>  32</span>       stop_threshold=False,
<span class='lineno'>  33</span>       batch_size=False,
<span class='lineno'>  34</span>       num_gpu=True,
<span class='lineno'>  35</span>       export_dir=False,
<span class='lineno'>  36</span>       distribution_strategy=True,
<span class='lineno'>  37</span>       run_eagerly=True)
<span class='lineno'>  38</span>   flags_core.define_distribution()
<span class='lineno'>  39</span>   flags.DEFINE_string(&#39;bert_config_file&#39;, None,
<span class='lineno'>  40</span>                       &#39;Bert configuration file to define core bert layers.&#39;)
<span class='lineno'>  41</span>   flags.DEFINE_string(
<span class='lineno'>  42</span>       &#39;model_export_path&#39;, None,
<span class='lineno'>  43</span>       &#39;Path to the directory, where trainined model will be &#39;
<span class='lineno'>  44</span>       &#39;exported.&#39;)
<span class='lineno'>  45</span>   flags.DEFINE_string(&#39;tpu&#39;, &#39;&#39;, &#39;TPU address to connect to.&#39;)
<span class='lineno'>  46</span>   flags.DEFINE_string(
<span class='lineno'>  47</span>       &#39;init_checkpoint&#39;, None,
<span class='lineno'>  48</span>       &#39;Initial checkpoint (usually from a pre-trained BERT model).&#39;)
<span class='lineno'>  49</span>   flags.DEFINE_integer(&#39;num_train_epochs&#39;, 3,
<span class='lineno'>  50</span>                        &#39;Total number of training epochs to perform.&#39;)
<span class='lineno'>  51</span>   flags.DEFINE_integer(
<span class='lineno'>  52</span>       &#39;steps_per_loop&#39;, None,
<span class='lineno'>  53</span>       &#39;Number of steps per graph-mode loop. Only training step &#39;
<span class='lineno'>  54</span>       &#39;happens inside the loop. Callbacks will not be called &#39;
<span class='lineno'>  55</span>       &#39;inside. If not set the value will be configured depending on the &#39;
<span class='lineno'>  56</span>       &#39;devices available.&#39;)
<span class='lineno'>  57</span>   flags.DEFINE_float(&#39;learning_rate&#39;, 5e-5,
<span class='lineno'>  58</span>                      &#39;The initial learning rate for Adam.&#39;)
<span class='lineno'>  59</span>   flags.DEFINE_float(&#39;end_lr&#39;, 0.0,
<span class='lineno'>  60</span>                      &#39;The end learning rate for learning rate decay.&#39;)
<span class='lineno'>  61</span>   flags.DEFINE_string(&#39;optimizer_type&#39;, &#39;adamw&#39;,
<span class='lineno'>  62</span>                       &#39;The type of optimizer to use for training (adamw|lamb)&#39;)
<span class='lineno'>  63</span>   flags.DEFINE_boolean(
<span class='lineno'>  64</span>       &#39;scale_loss&#39;, False,
<span class='lineno'>  65</span>       &#39;Whether to divide the loss by number of replica inside the per-replica &#39;
<span class='lineno'>  66</span>       &#39;loss function.&#39;)
<span class='lineno'>  67</span>   flags.DEFINE_boolean(
<span class='lineno'>  68</span>       &#39;use_keras_compile_fit&#39;, False,
<span class='lineno'>  69</span>       &#39;If True, uses Keras compile/fit() API for training logic. Otherwise &#39;
<span class='lineno'>  70</span>       &#39;use custom training loop.&#39;)
<span class='lineno'>  71</span>   flags.DEFINE_string(
<span class='lineno'>  72</span>       &#39;hub_module_url&#39;, None, &#39;TF-Hub path/url to Bert module. &#39;
<span class='lineno'>  73</span>       &#39;If specified, init_checkpoint flag should not be used.&#39;)
<span class='lineno'>  74</span>   flags.DEFINE_bool(&#39;hub_module_trainable&#39;, True,
<span class='lineno'>  75</span>                     &#39;True to make keras layers in the hub module trainable.&#39;)
<span class='lineno'>  76</span>   flags.DEFINE_string(&#39;sub_model_export_name&#39;, None,
<span class='lineno'>  77</span>                       &#39;If set, `sub_model` checkpoints are exported into &#39;
<span class='lineno'>  78</span>                       &#39;FLAGS.model_dir/FLAGS.sub_model_export_name.&#39;)
<span class='lineno'>  79</span> 
<span class='lineno'>  80</span>   flags_core.define_log_steps()
<span class='lineno'>  81</span> 
<span class='lineno'>  82</span>   # Adds flags for mixed precision and multi-worker training.
<span class='lineno'>  83</span>   flags_core.define_performance(
<span class='lineno'>  84</span>       num_parallel_calls=False,
<span class='lineno'>  85</span>       inter_op=False,
<span class='lineno'>  86</span>       intra_op=False,
<span class='lineno'>  87</span>       synthetic_data=False,
<span class='lineno'>  88</span>       max_train_steps=False,
<span class='lineno'>  89</span>       dtype=True,
<span class='lineno'>  90</span>       dynamic_loss_scale=True,
<span class='lineno'>  91</span>       loss_scale=True,
<span class='lineno'>  92</span>       all_reduce_alg=True,
<span class='lineno'>  93</span>       num_packs=False,
<span class='lineno'>  94</span>       tf_gpu_thread_mode=True,
<span class='lineno'>  95</span>       datasets_num_private_threads=True,
<span class='lineno'>  96</span>       enable_xla=True,
<span class='lineno'>  97</span>       fp16_implementation=True,
<span class='lineno'>  98</span>   )
<span class='lineno'>  99</span> 
<span class='lineno'> 100</span>   # Adds gin configuration flags.
<span class='lineno'> 101</span>   hyperparams_flags.define_gin_flags()
<span class='lineno'> 102</span> 
<span class='lineno'> 103</span> 
<span class='lineno'> 104</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.dtype', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.dtype', title='() -> ?'>dtype</a>():
<span class='lineno'> 105</span>   return flags_core.get_tf_dtype(flags.FLAGS)
<span class='lineno'> 106</span> 
<span class='lineno'> 107</span> 
<span class='lineno'> 108</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.use_float16', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.use_float16', title='() -> bool'>use_float16</a>():
<span class='lineno'> 109</span>   return flags_core.get_tf_dtype(flags.FLAGS) == tf.float16
<span class='lineno'> 110</span> 
<span class='lineno'> 111</span> 
<span class='lineno'> 112</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.use_graph_rewrite', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.use_graph_rewrite', title='() -> bool'>use_graph_rewrite</a>():
<span class='lineno'> 113</span>   return flags.FLAGS.fp16_implementation == &#39;graph_rewrite&#39;
<span class='lineno'> 114</span> 
<span class='lineno'> 115</span> 
<span class='lineno'> 116</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.get_loss_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.common_flags.get_loss_scale', title='() -> ?'>get_loss_scale</a>():
<span class='lineno'> 117</span>   return flags_core.get_loss_scale(flags.FLAGS, default_for_fp16=&#39;dynamic&#39;)
</pre></td></tr></table></body></html>