<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/nlp/nhnet/evaluation.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore'>rouge_l_fscore</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore'>rouge_2_fscore</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score'>bleu_score</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval'>continuous_eval</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Lint as: python3
<span class='lineno'>   2</span> # Copyright 2020 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   3</span> #
<span class='lineno'>   4</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   5</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   6</span> # You may obtain a copy of the License at
<span class='lineno'>   7</span> #
<span class='lineno'>   8</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   9</span> #
<span class='lineno'>  10</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  11</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  12</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  13</span> # See the License for the specific language governing permissions and
<span class='lineno'>  14</span> # limitations under the License.
<span class='lineno'>  15</span> # ==============================================================================
<span class='lineno'>  16</span> &quot;&quot;&quot;Evaluation for Bert2Bert.&quot;&quot;&quot;
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> from __future__ import absolute_import
<span class='lineno'>  19</span> from __future__ import division
<span class='lineno'>  20</span> # from __future__ import google_type_annotations
<span class='lineno'>  21</span> from __future__ import print_function
<span class='lineno'>  22</span> 
<span class='lineno'>  23</span> import os
<span class='lineno'>  24</span> from absl import logging
<span class='lineno'>  25</span> import numpy as np
<span class='lineno'>  26</span> import tensorflow as tf
<span class='lineno'>  27</span> 
<span class='lineno'>  28</span> from official.nlp.nhnet import input_pipeline
<span class='lineno'>  29</span> from official.nlp.nhnet import models
<span class='lineno'>  30</span> from official.nlp.transformer import metrics as metrics_v2
<span class='lineno'>  31</span> from official.nlp.transformer.utils import metrics
<span class='lineno'>  32</span> 
<span class='lineno'>  33</span> 
<span class='lineno'>  34</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore', title='(?, ?) -> None'>rouge_l_fscore</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.labels', title='?'>labels</a>):
<span class='lineno'>  35</span>   &quot;&quot;&quot;ROUGE scores computation between labels and predictions.
<span class='lineno'>  36</span> 
<span class='lineno'>  37</span>   This is an approximate ROUGE scoring method since we do not glue word pieces
<span class='lineno'>  38</span>   or decode the ids and tokenize the output.
<span class='lineno'>  39</span> 
<span class='lineno'>  40</span>   Args:
<span class='lineno'>  41</span>     logits: tensor, model predictions
<span class='lineno'>  42</span>     labels: tensor, gold output.
<span class='lineno'>  43</span> 
<span class='lineno'>  44</span>   Returns:
<span class='lineno'>  45</span>     rouge_l_fscore: approx rouge-l f1 score.
<span class='lineno'>  46</span>   &quot;&quot;&quot;
<span class='lineno'>  47</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.predictions', title='?'>predictions</a> = np.argmax(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.logits', title='?'>logits</a>, axis=-1)
<span class='lineno'>  48</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.rouge_l_f_score', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.rouge_l_f_score', title='?'>rouge_l_f_score</a> = metrics.rouge_l_sentence_level(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.predictions', title='?'>predictions</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.labels', title='?'>labels</a>)
<span class='lineno'>  49</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.rouge_l_f_score', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore.rouge_l_f_score', title='?'>rouge_l_f_score</a>
<span class='lineno'>  50</span> 
<span class='lineno'>  51</span> 
<span class='lineno'>  52</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore', title='(?, ?) -> None'>rouge_2_fscore</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.labels', title='?'>labels</a>):
<span class='lineno'>  53</span>   &quot;&quot;&quot;ROUGE-2 F1 score computation between labels and predictions.
<span class='lineno'>  54</span> 
<span class='lineno'>  55</span>   This is an approximate ROUGE scoring method since we do not glue word pieces
<span class='lineno'>  56</span>   or decode the ids and tokenize the output.
<span class='lineno'>  57</span> 
<span class='lineno'>  58</span>   Args:
<span class='lineno'>  59</span>     logits: tensor, model predictions
<span class='lineno'>  60</span>     labels: tensor, gold output.
<span class='lineno'>  61</span> 
<span class='lineno'>  62</span>   Returns:
<span class='lineno'>  63</span>     rouge2_fscore: approx rouge-2 f1 score.
<span class='lineno'>  64</span>   &quot;&quot;&quot;
<span class='lineno'>  65</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.predictions', title='?'>predictions</a> = np.argmax(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.logits', title='?'>logits</a>, axis=-1)
<span class='lineno'>  66</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.rouge_2_f_score', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.rouge_2_f_score', title='?'>rouge_2_f_score</a> = metrics.rouge_n(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.predictions', title='?'>predictions</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.labels', title='?'>labels</a>)
<span class='lineno'>  67</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.rouge_2_f_score', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore.rouge_2_f_score', title='?'>rouge_2_f_score</a>
<span class='lineno'>  68</span> 
<span class='lineno'>  69</span> 
<span class='lineno'>  70</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score', title='(?, ?) -> None'>bleu_score</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.labels', title='?'>labels</a>):
<span class='lineno'>  71</span>   &quot;&quot;&quot;Approximate BLEU score computation between labels and predictions.
<span class='lineno'>  72</span> 
<span class='lineno'>  73</span>   An approximate BLEU scoring method since we do not glue word pieces or
<span class='lineno'>  74</span>   decode the ids and tokenize the output. By default, we use ngram order of 4
<span class='lineno'>  75</span>   and use brevity penalty. Also, this does not have beam search.
<span class='lineno'>  76</span> 
<span class='lineno'>  77</span>   Args:
<span class='lineno'>  78</span>     logits: Tensor of size [batch_size, length_logits, vocab_size]
<span class='lineno'>  79</span>     labels: Tensor of size [batch-size, length_labels]
<span class='lineno'>  80</span> 
<span class='lineno'>  81</span>   Returns:
<span class='lineno'>  82</span>     bleu: int, approx bleu score
<span class='lineno'>  83</span>   &quot;&quot;&quot;
<span class='lineno'>  84</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.predictions', title='?'>predictions</a> = np.argmax(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.logits', title='?'>logits</a>, axis=-1)
<span class='lineno'>  85</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.bleu', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.bleu', title='?'>bleu</a> = metrics.compute_bleu(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.labels', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.labels', title='?'>labels</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.predictions', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.predictions', title='?'>predictions</a>)
<span class='lineno'>  86</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.bleu', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score.bleu', title='?'>bleu</a>
<span class='lineno'>  87</span> 
<span class='lineno'>  88</span> 
<span class='lineno'>  89</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval', title='(?, ?, ?, None, int, None, None, int) -> dict'>continuous_eval</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.strategy', title='?'>strategy</a>,
<span class='lineno'>  90</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.params', title='?'>params</a>,
<span class='lineno'>  91</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model_type', title='?'>model_type</a>,
<span class='lineno'>  92</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_file_pattern', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_file_pattern', title='None'>eval_file_pattern</a>=None,
<span class='lineno'>  93</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.batch_size', title='int'>batch_size</a>=4,
<span class='lineno'>  94</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_steps', title='None'>eval_steps</a>=None,
<span class='lineno'>  95</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model_dir', title='None'>model_dir</a>=None,
<span class='lineno'>  96</span>                     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.timeout', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.timeout', title='int'>timeout</a>=3000):
<span class='lineno'>  97</span>   &quot;&quot;&quot;Continuously evaluate checkpoints on testing data.&quot;&quot;&quot;
<span class='lineno'>  98</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_dataset', title='?'>test_dataset</a> = input_pipeline.get_input_dataset(
<span class='lineno'>  99</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_file_pattern', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_file_pattern', title='None'>eval_file_pattern</a>,
<span class='lineno'> 100</span>       batch_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.batch_size', title='int'>batch_size</a>,
<span class='lineno'> 101</span>       params=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.params', title='?'>params</a>,
<span class='lineno'> 102</span>       is_training=False,
<span class='lineno'> 103</span>       strategy=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.strategy', title='?'>strategy</a>)
<span class='lineno'> 104</span> 
<span class='lineno'> 105</span>   with <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.strategy', title='?'>strategy</a>.scope():
<span class='lineno'> 106</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', title='?'>model</a> = models.create_model(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model_type', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model_type', title='?'>model_type</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.params', title='?'>params</a>)
<span class='lineno'> 107</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric_layer', title='?'>metric_layer</a> = metrics_v2.MetricLayer(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.params', title='?'>params</a>.vocab_size)
<span class='lineno'> 108</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_summary_writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_summary_writer', title='?'>eval_summary_writer</a> = tf.summary.create_file_writer(
<span class='lineno'> 109</span>         os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model_dir', title='None'>model_dir</a>, &quot;summaries/eval&quot;))
<span class='lineno'> 110</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.global_step', title='?'>global_step</a> = tf.Variable(
<span class='lineno'> 111</span>         0,
<span class='lineno'> 112</span>         trainable=False,
<span class='lineno'> 113</span>         dtype=tf.int64,
<span class='lineno'> 114</span>         aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA,
<span class='lineno'> 115</span>         shape=[])
<span class='lineno'> 116</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', title='?'>model</a>.global_step = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.global_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.global_step', title='?'>global_step</a>
<span class='lineno'> 117</span> 
<span class='lineno'> 118</span>   @tf.function
<span class='lineno'> 119</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step', title='? -> None'>test_step</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step.inputs', title='?'>inputs</a>):
<span class='lineno'> 120</span>     &quot;&quot;&quot;Calculates evaluation metrics on distributed devices.&quot;&quot;&quot;
<span class='lineno'> 121</span> 
<span class='lineno'> 122</span>     def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn', title='? -> (?, ?)'>_test_step_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.inputs', title='?'>inputs</a>):
<span class='lineno'> 123</span>       &quot;&quot;&quot;Replicated accuracy calculation.&quot;&quot;&quot;
<span class='lineno'> 124</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.targets', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.targets', title='?'>targets</a> = models.remove_sos_from_seq(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.inputs', title='?'>inputs</a>[&quot;target_ids&quot;],
<span class='lineno'> 125</span>                                            <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.params', title='?'>params</a>.pad_token_id)
<span class='lineno'> 126</span> 
<span class='lineno'> 127</span>       # Using ground truth sequences as targets to calculate logits for accuracy
<span class='lineno'> 128</span>       # and perplexity metrics.
<span class='lineno'> 129</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.logits', title='?'>logits</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn._', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn._', title='?'>_</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn._', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn._', title='?'>_</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', title='?'>model</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.inputs', title='?'>inputs</a>, training=False, mode=&quot;train&quot;)
<span class='lineno'> 130</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric_layer', title='?'>metric_layer</a>([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.logits', title='?'>logits</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.targets', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.targets', title='?'>targets</a>])
<span class='lineno'> 131</span> 
<span class='lineno'> 132</span>       # Get logits from top beam search results for bleu and rouge metrics.
<span class='lineno'> 133</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.logits', title='?'>logits</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', title='?'>model</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.inputs', title='?'>inputs</a>, training=False, mode=&quot;eval&quot;)
<span class='lineno'> 134</span> 
<span class='lineno'> 135</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.targets', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.targets', title='?'>targets</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.logits', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn.logits', title='?'>logits</a>
<span class='lineno'> 136</span> 
<span class='lineno'> 137</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step.outputs', title='?'>outputs</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.strategy', title='?'>strategy</a>.run(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step._test_step_fn', title='? -> (?, ?)'>_test_step_fn</a>, args=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step.inputs', title='?'>inputs</a>,))
<span class='lineno'> 138</span> 
<span class='lineno'> 139</span>     return tf.nest.map_structure(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.strategy', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.strategy', title='?'>strategy</a>.experimental_local_results, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step.outputs', title='?'>outputs</a>)
<span class='lineno'> 140</span> 
<span class='lineno'> 141</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metrics_and_funcs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metrics_and_funcs', title='[(?, {(?, ?) -> None | (?, ?) -> None | (?, ?) -> None})]'>metrics_and_funcs</a> = [
<span class='lineno'> 142</span>       (tf.keras.metrics.Mean(&quot;bleu&quot;, dtype=tf.float32), <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.bleu_score', title='(?, ?) -> None'>bleu_score</a>),
<span class='lineno'> 143</span>       (tf.keras.metrics.Mean(&quot;rouge_2_fscore&quot;,
<span class='lineno'> 144</span>                              dtype=tf.float32), <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_2_fscore', title='(?, ?) -> None'>rouge_2_fscore</a>),
<span class='lineno'> 145</span>       (tf.keras.metrics.Mean(&quot;rouge_l_fscore&quot;,
<span class='lineno'> 146</span>                              dtype=tf.float32), <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.rouge_l_fscore', title='(?, ?) -> None'>rouge_l_fscore</a>),
<span class='lineno'> 147</span>   ]
<span class='lineno'> 148</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', title='dict'>eval_results</a> = {}
<span class='lineno'> 149</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.latest_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.latest_checkpoint', title='?'>latest_checkpoint</a> in tf.train.checkpoints_iterator(
<span class='lineno'> 150</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model_dir', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model_dir', title='None'>model_dir</a>, timeout=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.timeout', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.timeout', title='int'>timeout</a>):
<span class='lineno'> 151</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.checkpoint', title='?'>checkpoint</a> = tf.train.Checkpoint(model=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', title='?'>model</a>)
<span class='lineno'> 152</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.checkpoint', title='?'>checkpoint</a>.restore(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.latest_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.latest_checkpoint', title='?'>latest_checkpoint</a>).expect_partial()
<span class='lineno'> 153</span>     logging.info(&quot;Loaded checkpoint %s&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.latest_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.latest_checkpoint', title='?'>latest_checkpoint</a>)
<span class='lineno'> 154</span> 
<span class='lineno'> 155</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.i', title='?'>i</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.inputs', title='?'>inputs</a> in enumerate(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_dataset', title='?'>test_dataset</a>):
<span class='lineno'> 156</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_steps', title='None'>eval_steps</a> and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.i', title='?'>i</a> &gt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_steps', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_steps', title='None'>eval_steps</a>:
<span class='lineno'> 157</span>         break
<span class='lineno'> 158</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.outputs', title='None'>outputs</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.test_step', title='? -> None'>test_step</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.inputs', title='?'>inputs</a>)
<span class='lineno'> 159</span>       for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.func', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.func', title='{(?, ?) -> None | (?, ?) -> None | (?, ?) -> None}'>func</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metrics_and_funcs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metrics_and_funcs', title='[(?, {(?, ?) -> None | (?, ?) -> None | (?, ?) -> None})]'>metrics_and_funcs</a>:
<span class='lineno'> 160</span>         for targets, logits in zip(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.outputs', title='None'>outputs</a>[0], <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.outputs', title='None'>outputs</a>[1]):
<span class='lineno'> 161</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>.update_state(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.func', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.func', title='{(?, ?) -> None | (?, ?) -> None | (?, ?) -> None}'>func</a>(logits.numpy(), targets.numpy()))
<span class='lineno'> 162</span> 
<span class='lineno'> 163</span>     with <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_summary_writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_summary_writer', title='?'>eval_summary_writer</a>.as_default():
<span class='lineno'> 164</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.step', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.step', title='?'>step</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.model', title='?'>model</a>.global_step.numpy()
<span class='lineno'> 165</span>       for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval._', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval._', title='{(?, ?) -> None | (?, ?) -> None | (?, ?) -> None}'>_</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metrics_and_funcs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metrics_and_funcs', title='[(?, {(?, ?) -> None | (?, ?) -> None | (?, ?) -> None})]'>metrics_and_funcs</a>:
<span class='lineno'> 166</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', title='dict'>eval_results</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>.name] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>.result().numpy().astype(float)
<span class='lineno'> 167</span>         tf.summary.scalar(
<span class='lineno'> 168</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>.name,
<span class='lineno'> 169</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', title='dict'>eval_results</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>.name],
<span class='lineno'> 170</span>             step=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.step', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.step', title='?'>step</a>)
<span class='lineno'> 171</span>       for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric_layer', title='?'>metric_layer</a>.metrics:
<span class='lineno'> 172</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', title='dict'>eval_results</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>.name] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>.result().numpy().astype(float)
<span class='lineno'> 173</span>         tf.summary.scalar(
<span class='lineno'> 174</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>.name,
<span class='lineno'> 175</span>             <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', title='dict'>eval_results</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>.name],
<span class='lineno'> 176</span>             step=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.step', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.step', title='?'>step</a>)
<span class='lineno'> 177</span>       logging.info(&quot;Step %d Metrics= %s&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.step', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.step', title='?'>step</a>, str(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', title='dict'>eval_results</a>))
<span class='lineno'> 178</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_summary_writer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_summary_writer', title='?'>eval_summary_writer</a>.flush()
<span class='lineno'> 179</span> 
<span class='lineno'> 180</span>     # Resets metrics.
<span class='lineno'> 181</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval._', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval._', title='{(?, ?) -> None | (?, ?) -> None | (?, ?) -> None}'>_</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metrics_and_funcs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metrics_and_funcs', title='[(?, {(?, ?) -> None | (?, ?) -> None | (?, ?) -> None})]'>metrics_and_funcs</a>:
<span class='lineno'> 182</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>.reset_states()
<span class='lineno'> 183</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric_layer', title='?'>metric_layer</a>.metrics:
<span class='lineno'> 184</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.metric', title='?'>metric</a>.reset_states()
<span class='lineno'> 185</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.evaluation.continuous_eval.eval_results', title='dict'>eval_results</a>
</pre></td></tr></table></body></html>