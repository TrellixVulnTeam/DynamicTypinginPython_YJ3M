<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/nlp/nhnet/multi_channel_attention.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention'>DocAttention</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build'>build</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call'>call</a></li></ul>
</li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention'>MultiChannelAttention</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build'>build</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call'>call</a></li></ul>
</li></ul>
</td><td><pre><span class='lineno'>   1</span> # Lint as: python3
<span class='lineno'>   2</span> # Copyright 2020 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   3</span> #
<span class='lineno'>   4</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   5</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   6</span> # You may obtain a copy of the License at
<span class='lineno'>   7</span> #
<span class='lineno'>   8</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   9</span> #
<span class='lineno'>  10</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  11</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  12</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  13</span> # See the License for the specific language governing permissions and
<span class='lineno'>  14</span> # limitations under the License.
<span class='lineno'>  15</span> # ==============================================================================
<span class='lineno'>  16</span> &quot;&quot;&quot;Multi-channel decoder.&quot;&quot;&quot;
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> from __future__ import absolute_import
<span class='lineno'>  19</span> from __future__ import division
<span class='lineno'>  20</span> # from __future__ import google_type_annotations
<span class='lineno'>  21</span> from __future__ import print_function
<span class='lineno'>  22</span> 
<span class='lineno'>  23</span> import math
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> import tensorflow as tf
<span class='lineno'>  26</span> from official.modeling import tf_utils
<span class='lineno'>  27</span> from official.nlp.modeling import layers
<span class='lineno'>  28</span> 
<span class='lineno'>  29</span> 
<span class='lineno'>  30</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention', title='<DocAttention>'>DocAttention</a>(tf.keras.layers.Layer):
<span class='lineno'>  31</span>   &quot;&quot;&quot;Documents Attention layer.&quot;&quot;&quot;
<span class='lineno'>  32</span> 
<span class='lineno'>  33</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', title='DocAttention'>self</a>,
<span class='lineno'>  34</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.num_heads', title='?'>num_heads</a>,
<span class='lineno'>  35</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.head_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.head_size', title='?'>head_size</a>,
<span class='lineno'>  36</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_initializer', title='str'>kernel_initializer</a>=&quot;glorot_uniform&quot;,
<span class='lineno'>  37</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_initializer', title='str'>bias_initializer</a>=&quot;zeros&quot;,
<span class='lineno'>  38</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_regularizer', title='None'>kernel_regularizer</a>=None,
<span class='lineno'>  39</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_regularizer', title='None'>bias_regularizer</a>=None,
<span class='lineno'>  40</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.activity_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.activity_regularizer', title='None'>activity_regularizer</a>=None,
<span class='lineno'>  41</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_constraint', title='None'>kernel_constraint</a>=None,
<span class='lineno'>  42</span>                <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_constraint', title='None'>bias_constraint</a>=None,
<span class='lineno'>  43</span>                **kwargs):
<span class='lineno'>  44</span>     super(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention', title='<DocAttention>'>DocAttention</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', title='DocAttention'>self</a>).__init__(**kwargs)
<span class='lineno'>  45</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._num_heads', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._num_heads', title='?'>_num_heads</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.num_heads', title='?'>num_heads</a>
<span class='lineno'>  46</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._head_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._head_size', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._head_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._head_size', title='?'>_head_size</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.head_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.head_size', title='?'>head_size</a>
<span class='lineno'>  47</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', title='DocAttention'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_initializer', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_initializer', title='?'>_kernel_initializer</a></a> = tf.keras.initializers.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_initializer', title='str'>kernel_initializer</a>)
<span class='lineno'>  48</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_initializer', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_initializer', title='?'>_bias_initializer</a></a> = tf.keras.initializers.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_initializer', title='str'>bias_initializer</a>)
<span class='lineno'>  49</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', title='DocAttention'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_regularizer', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_regularizer', title='?'>_kernel_regularizer</a></a> = tf.keras.regularizers.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_regularizer', title='None'>kernel_regularizer</a>)
<span class='lineno'>  50</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_regularizer', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_regularizer', title='?'>_bias_regularizer</a></a> = tf.keras.regularizers.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_regularizer', title='None'>bias_regularizer</a>)
<span class='lineno'>  51</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', title='DocAttention'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_constraint', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_constraint', title='?'>_kernel_constraint</a></a> = tf.keras.constraints.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.kernel_constraint', title='None'>kernel_constraint</a>)
<span class='lineno'>  52</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_constraint', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_constraint', title='?'>_bias_constraint</a></a> = tf.keras.constraints.get(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.__init__.bias_constraint', title='None'>bias_constraint</a>)
<span class='lineno'>  53</span> 
<span class='lineno'>  54</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build', title='(DocAttention, ?) -> None'>build</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.unused_input_shapes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.unused_input_shapes', title='?'>unused_input_shapes</a>):
<span class='lineno'>  55</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._query_dense', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._query_dense', title='?'>_query_dense</a> = layers.DenseEinsum(
<span class='lineno'>  56</span>         output_shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._num_heads', title='?'>_num_heads</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._head_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._head_size', title='?'>_head_size</a>),
<span class='lineno'>  57</span>         kernel_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_initializer', title='?'>_kernel_initializer</a>,
<span class='lineno'>  58</span>         bias_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_initializer', title='?'>_bias_initializer</a>,
<span class='lineno'>  59</span>         kernel_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_regularizer', title='?'>_kernel_regularizer</a>,
<span class='lineno'>  60</span>         bias_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_regularizer', title='?'>_bias_regularizer</a>,
<span class='lineno'>  61</span>         activity_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>._activity_regularizer,
<span class='lineno'>  62</span>         kernel_constraint=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_constraint', title='?'>_kernel_constraint</a>,
<span class='lineno'>  63</span>         bias_constraint=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_constraint', title='?'>_bias_constraint</a>,
<span class='lineno'>  64</span>         dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.dtype,
<span class='lineno'>  65</span>         name=&quot;encdocatt_query&quot;)
<span class='lineno'>  66</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._key_dense', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._key_dense', title='?'>_key_dense</a> = layers.DenseEinsum(
<span class='lineno'>  67</span>         output_shape=(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._num_heads', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._num_heads', title='?'>_num_heads</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._head_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._head_size', title='?'>_head_size</a>),
<span class='lineno'>  68</span>         kernel_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_initializer', title='?'>_kernel_initializer</a>,
<span class='lineno'>  69</span>         bias_initializer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_initializer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_initializer', title='?'>_bias_initializer</a>,
<span class='lineno'>  70</span>         kernel_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_regularizer', title='?'>_kernel_regularizer</a>,
<span class='lineno'>  71</span>         bias_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_regularizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_regularizer', title='?'>_bias_regularizer</a>,
<span class='lineno'>  72</span>         activity_regularizer=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>._activity_regularizer,
<span class='lineno'>  73</span>         kernel_constraint=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._kernel_constraint', title='?'>_kernel_constraint</a>,
<span class='lineno'>  74</span>         bias_constraint=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_constraint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._bias_constraint', title='?'>_bias_constraint</a>,
<span class='lineno'>  75</span>         dtype=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>.dtype,
<span class='lineno'>  76</span>         name=&quot;encdocatt_key&quot;)
<span class='lineno'>  77</span>     super(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention', title='<DocAttention>'>DocAttention</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.self', title='DocAttention'>self</a>).build(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.unused_input_shapes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.build.unused_input_shapes', title='?'>unused_input_shapes</a>)
<span class='lineno'>  78</span> 
<span class='lineno'>  79</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call', title='(DocAttention, ?, ?) -> None'>call</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.self', title='DocAttention'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.encoder_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.encoder_outputs', title='?'>encoder_outputs</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', title='?'>doc_attention_mask</a>):
<span class='lineno'>  80</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.num_docs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.num_docs', title='?'>num_docs</a> = tf_utils.get_shape_list(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.encoder_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.encoder_outputs', title='?'>encoder_outputs</a>, expected_rank=[4])[1]
<span class='lineno'>  81</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.cls_embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.cls_embeddings', title='?'>cls_embeddings</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.encoder_outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.encoder_outputs', title='?'>encoder_outputs</a>[:, :, 0, :]
<span class='lineno'>  82</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.key', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.key', title='?'>key</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._key_dense', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._key_dense', title='?'>_key_dense</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.cls_embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.cls_embeddings', title='?'>cls_embeddings</a>)
<span class='lineno'>  83</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.query', title='?'>query</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.self', title='DocAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._query_dense', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention._query_dense', title='?'>_query_dense</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.cls_embeddings', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.cls_embeddings', title='?'>cls_embeddings</a>)
<span class='lineno'>  84</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', title='?'>doc_attention_mask</a> = tf.cast(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', title='?'>doc_attention_mask</a>, tf.float32)
<span class='lineno'>  85</span> 
<span class='lineno'>  86</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.key', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.key', title='?'>key</a> = tf.einsum(&quot;BANH,BA-&gt;BANH&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.key', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.key', title='?'>key</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', title='?'>doc_attention_mask</a>)
<span class='lineno'>  87</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.query', title='?'>query</a> = tf.einsum(&quot;BANH,BA-&gt;BANH&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.query', title='?'>query</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', title='?'>doc_attention_mask</a>)
<span class='lineno'>  88</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.attention_matrix', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.attention_matrix', title='?'>attention_matrix</a> = tf.einsum(&quot;BXNH,BYNH-&gt;BNXY&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.query', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.query', title='?'>query</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.key', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.key', title='?'>key</a>)
<span class='lineno'>  89</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.mask', title='?'>mask</a> = tf.ones([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.num_docs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.num_docs', title='?'>num_docs</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.num_docs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.num_docs', title='?'>num_docs</a>])
<span class='lineno'>  90</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.mask', title='?'>mask</a> = tf.linalg.set_diag(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.mask', title='?'>mask</a>, tf.zeros(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.num_docs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.num_docs', title='?'>num_docs</a>))
<span class='lineno'>  91</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.attention_matrix', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.attention_matrix', title='?'>attention_matrix</a> = tf.einsum(&quot;BNXY,XY-&gt;BNXY&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.attention_matrix', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.attention_matrix', title='?'>attention_matrix</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.mask', title='?'>mask</a>)
<span class='lineno'>  92</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_probs', title='?'>doc_attention_probs</a> = tf.einsum(&quot;BNAY-&gt;BNA&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.attention_matrix', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.attention_matrix', title='?'>attention_matrix</a>)
<span class='lineno'>  93</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_probs', title='?'>doc_attention_probs</a> = tf.einsum(&quot;BNA-&gt;BA&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_probs', title='?'>doc_attention_probs</a>)
<span class='lineno'>  94</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.infadder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.infadder', title='float'>infadder</a> = (1.0 - <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_mask', title='?'>doc_attention_mask</a>) * -100000.0
<span class='lineno'>  95</span>     return tf.nn.softmax(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.doc_attention_probs', title='?'>doc_attention_probs</a> + <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.infadder', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.DocAttention.call.infadder', title='float'>infadder</a>)
<span class='lineno'>  96</span> 
<span class='lineno'>  97</span> 
<span class='lineno'>  98</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention', title='<MultiChannelAttention>'>MultiChannelAttention</a>(layers.MultiHeadAttention):
<span class='lineno'>  99</span>   &quot;&quot;&quot;Multi-channel Attention layer.&quot;&quot;&quot;
<span class='lineno'> 100</span> 
<span class='lineno'> 101</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build', title='(MultiChannelAttention, ?) -> None'>build</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build.self', title='MultiChannelAttention'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build.input_shape', title='?'>input_shape</a>):
<span class='lineno'> 102</span>     super(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention', title='<MultiChannelAttention>'>MultiChannelAttention</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build.self', title='MultiChannelAttention'>self</a>).build(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build.input_shape', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build.input_shape', title='?'>input_shape</a>)
<span class='lineno'> 103</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.build.self', title='MultiChannelAttention'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention._masked_softmax', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention._masked_softmax', title='?'>_masked_softmax</a> = layers.MaskedSoftmax(mask_expansion_axes=[2])
<span class='lineno'> 104</span> 
<span class='lineno'> 105</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call', title='(MultiChannelAttention, ?, None) -> None'>call</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', title='MultiChannelAttention'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.inputs', title='?'>inputs</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_mask', title='None'>attention_mask</a>=None):
<span class='lineno'> 106</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.from_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.from_tensor', title='?'>from_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.inputs', title='?'>inputs</a>[0]
<span class='lineno'> 107</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.to_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.to_tensor', title='?'>to_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.inputs', title='?'>inputs</a>[1]
<span class='lineno'> 108</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.doc_attention_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.doc_attention_probs', title='?'>doc_attention_probs</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.inputs', title='?'>inputs</a>[2]
<span class='lineno'> 109</span> 
<span class='lineno'> 110</span>     # Scalar dimensions referenced here:
<span class='lineno'> 111</span>     #   B = batch size (number of stories)
<span class='lineno'> 112</span>     #   A = num_docs (number of docs)
<span class='lineno'> 113</span>     #   F = `from_tensor` sequence length
<span class='lineno'> 114</span>     #   T = `to_tensor` sequence length
<span class='lineno'> 115</span>     #   N = `num_attention_heads`
<span class='lineno'> 116</span>     #   H = `size_per_head`
<span class='lineno'> 117</span>     # `query_tensor` = [B, F, N ,H]
<span class='lineno'> 118</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.query_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.query_tensor', title='?'>query_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', title='MultiChannelAttention'>self</a>._query_dense(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.from_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.from_tensor', title='?'>from_tensor</a>)
<span class='lineno'> 119</span> 
<span class='lineno'> 120</span>     # `key_tensor` = [B, A, T, N, H]
<span class='lineno'> 121</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.key_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.key_tensor', title='?'>key_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', title='MultiChannelAttention'>self</a>._key_dense(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.to_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.to_tensor', title='?'>to_tensor</a>)
<span class='lineno'> 122</span> 
<span class='lineno'> 123</span>     # `value_tensor` = [B, A, T, N, H]
<span class='lineno'> 124</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.value_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.value_tensor', title='?'>value_tensor</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', title='MultiChannelAttention'>self</a>._value_dense(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.to_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.to_tensor', title='?'>to_tensor</a>)
<span class='lineno'> 125</span> 
<span class='lineno'> 126</span>     # Take the dot product between &quot;query&quot; and &quot;key&quot; to get the raw
<span class='lineno'> 127</span>     # attention scores.
<span class='lineno'> 128</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_scores', title='?'>attention_scores</a> = tf.einsum(&quot;BATNH,BFNH-&gt;BANFT&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.key_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.key_tensor', title='?'>key_tensor</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.query_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.query_tensor', title='?'>query_tensor</a>)
<span class='lineno'> 129</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_scores', title='?'>attention_scores</a> = tf.multiply(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_scores', title='?'>attention_scores</a>,
<span class='lineno'> 130</span>                                    1.0 / math.sqrt(float(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', title='MultiChannelAttention'>self</a>._key_size)))
<span class='lineno'> 131</span> 
<span class='lineno'> 132</span>     # Normalize the attention scores to probabilities.
<span class='lineno'> 133</span>     # `attention_probs` = [B, A, N, F, T]
<span class='lineno'> 134</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_probs', title='?'>attention_probs</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', title='MultiChannelAttention'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention._masked_softmax', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention._masked_softmax', title='?'>_masked_softmax</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_scores', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_scores', title='?'>attention_scores</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_mask', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_mask', title='None'>attention_mask</a>)
<span class='lineno'> 135</span> 
<span class='lineno'> 136</span>     # This is actually dropping out entire tokens to attend to, which might
<span class='lineno'> 137</span>     # seem a bit unusual, but is taken from the original Transformer paper.
<span class='lineno'> 138</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_probs', title='?'>attention_probs</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', title='MultiChannelAttention'>self</a>._dropout_layer(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_probs', title='?'>attention_probs</a>)
<span class='lineno'> 139</span> 
<span class='lineno'> 140</span>     # `context_layer` = [B, F, N, H]
<span class='lineno'> 141</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.context_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.context_layer', title='?'>context_layer</a> = tf.einsum(&quot;BANFT,BATNH-&gt;BAFNH&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_probs', title='?'>attention_probs</a>,
<span class='lineno'> 142</span>                               <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.value_tensor', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.value_tensor', title='?'>value_tensor</a>)
<span class='lineno'> 143</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_output', title='?'>attention_output</a> = tf.einsum(&quot;BNFA,BAFNH-&gt;BFNH&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.doc_attention_probs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.doc_attention_probs', title='?'>doc_attention_probs</a>,
<span class='lineno'> 144</span>                                  <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.context_layer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.context_layer', title='?'>context_layer</a>)
<span class='lineno'> 145</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_output', title='?'>attention_output</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.self', title='MultiChannelAttention'>self</a>._output_dense(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_output', title='?'>attention_output</a>)
<span class='lineno'> 146</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.nhnet.multi_channel_attention.MultiChannelAttention.call.attention_output', title='?'>attention_output</a>
</pre></td></tr></table></body></html>