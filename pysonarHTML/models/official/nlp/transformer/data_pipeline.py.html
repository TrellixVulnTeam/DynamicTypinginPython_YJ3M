<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/nlp/transformer/data_pipeline.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._READ_RECORD_BUFFER', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._READ_RECORD_BUFFER'>_READ_RECORD_BUFFER</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._MIN_BOUNDARY', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._MIN_BOUNDARY'>_MIN_BOUNDARY</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._BOUNDARY_SCALE', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._BOUNDARY_SCALE'>_BOUNDARY_SCALE</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._load_records', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._load_records'>_load_records</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example'>_parse_example</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length'>_filter_max_length</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length'>_get_example_length</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries'>_create_min_max_boundaries</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples'>_batch_examples</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files'>_read_and_batch_from_files</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data'>_generate_synthetic_data</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn'>train_input_fn</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn'>eval_input_fn</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn'>map_data_for_transformer_fn</a></li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2018 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> &quot;&quot;&quot;Input pipeline for the transformer model to read, filter, and batch examples.
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span> Two things to note in the pipeline:
<span class='lineno'>  18</span> 
<span class='lineno'>  19</span> 1. Batching scheme
<span class='lineno'>  20</span> 
<span class='lineno'>  21</span>    The examples encoded in the TFRecord files contain data in the format:
<span class='lineno'>  22</span>      {&quot;inputs&quot;: [variable length array of integers],
<span class='lineno'>  23</span>       &quot;targets&quot;: [variable length array of integers]}
<span class='lineno'>  24</span>    Where integers in the arrays refer to tokens in the English and German vocab
<span class='lineno'>  25</span>    file (named `vocab.ende.32768`).
<span class='lineno'>  26</span> 
<span class='lineno'>  27</span>    Prior to batching, elements in the dataset are grouped by length (max between
<span class='lineno'>  28</span>    &quot;inputs&quot; and &quot;targets&quot; length). Each group is then batched such that:
<span class='lineno'>  29</span>      group_batch_size * length &lt;= batch_size.
<span class='lineno'>  30</span> 
<span class='lineno'>  31</span>    Another way to view batch_size is the maximum number of tokens in each batch.
<span class='lineno'>  32</span> 
<span class='lineno'>  33</span>    Once batched, each element in the dataset will have the shape:
<span class='lineno'>  34</span>      {&quot;inputs&quot;: [group_batch_size, padded_input_length],
<span class='lineno'>  35</span>       &quot;targets&quot;: [group_batch_size, padded_target_length]}
<span class='lineno'>  36</span>    Lengths are padded to the longest &quot;inputs&quot; or &quot;targets&quot; sequence in the batch
<span class='lineno'>  37</span>    (padded_input_length and padded_target_length can be different).
<span class='lineno'>  38</span> 
<span class='lineno'>  39</span>    This batching scheme decreases the fraction of padding tokens per training
<span class='lineno'>  40</span>    batch, thus improving the training speed significantly.
<span class='lineno'>  41</span> 
<span class='lineno'>  42</span> 2. Shuffling
<span class='lineno'>  43</span> 
<span class='lineno'>  44</span>    While training, the dataset is shuffled in two places in the code. The first
<span class='lineno'>  45</span>    is the list of training files. Second, while reading records using
<span class='lineno'>  46</span>    `parallel_interleave`, the `sloppy` argument is used to generate randomness
<span class='lineno'>  47</span>    in the order of the examples.
<span class='lineno'>  48</span> &quot;&quot;&quot;
<span class='lineno'>  49</span> 
<span class='lineno'>  50</span> from __future__ import absolute_import
<span class='lineno'>  51</span> from __future__ import division
<span class='lineno'>  52</span> from __future__ import print_function
<span class='lineno'>  53</span> 
<span class='lineno'>  54</span> import os
<span class='lineno'>  55</span> 
<span class='lineno'>  56</span> from absl import logging
<span class='lineno'>  57</span> import tensorflow as tf
<span class='lineno'>  58</span> 
<span class='lineno'>  59</span> from official.utils.misc import model_helpers
<span class='lineno'>  60</span> 
<span class='lineno'>  61</span> # Buffer size for reading records from a TFRecord file. Each training file is
<span class='lineno'>  62</span> # 7.2 MB, so 8 MB allows an entire file to be kept in memory.
<span class='lineno'>  63</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._READ_RECORD_BUFFER', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._READ_RECORD_BUFFER', title='int'>_READ_RECORD_BUFFER</a> = 8 * 1000 * 1000
<span class='lineno'>  64</span> 
<span class='lineno'>  65</span> # Example grouping constants. Defines length boundaries for each group.
<span class='lineno'>  66</span> # These values are the defaults used in Tensor2Tensor.
<span class='lineno'>  67</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._MIN_BOUNDARY', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._MIN_BOUNDARY', title='int'>_MIN_BOUNDARY</a> = 8
<span class='lineno'>  68</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._BOUNDARY_SCALE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._BOUNDARY_SCALE', title='float'>_BOUNDARY_SCALE</a> = 1.1
<span class='lineno'>  69</span> 
<span class='lineno'>  70</span> 
<span class='lineno'>  71</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._load_records', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._load_records', title='? -> None'>_load_records</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._load_records.filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._load_records.filename', title='?'>filename</a>):
<span class='lineno'>  72</span>   &quot;&quot;&quot;Read file and return a dataset of tf.Examples.&quot;&quot;&quot;
<span class='lineno'>  73</span>   return tf.data.TFRecordDataset(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._load_records.filename', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._load_records.filename', title='?'>filename</a>, buffer_size=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._READ_RECORD_BUFFER', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._READ_RECORD_BUFFER', title='int'>_READ_RECORD_BUFFER</a>)
<span class='lineno'>  74</span> 
<span class='lineno'>  75</span> 
<span class='lineno'>  76</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example', title='? -> (?, ?)'>_parse_example</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.serialized_example', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.serialized_example', title='?'>serialized_example</a>):
<span class='lineno'>  77</span>   &quot;&quot;&quot;Return inputs and targets Tensors from a serialized tf.Example.&quot;&quot;&quot;
<span class='lineno'>  78</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.data_fields', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.data_fields', title='dict'>data_fields</a> = {
<span class='lineno'>  79</span>       &quot;inputs&quot;: tf.io.VarLenFeature(tf.int64),
<span class='lineno'>  80</span>       &quot;targets&quot;: tf.io.VarLenFeature(tf.int64)
<span class='lineno'>  81</span>   }
<span class='lineno'>  82</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.parsed', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.parsed', title='?'>parsed</a> = tf.io.parse_single_example(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.serialized_example', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.serialized_example', title='?'>serialized_example</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.data_fields', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.data_fields', title='dict'>data_fields</a>)
<span class='lineno'>  83</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.inputs', title='?'>inputs</a> = tf.sparse.to_dense(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.parsed', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.parsed', title='?'>parsed</a>[&quot;inputs&quot;])
<span class='lineno'>  84</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.targets', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.targets', title='?'>targets</a> = tf.sparse.to_dense(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.parsed', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.parsed', title='?'>parsed</a>[&quot;targets&quot;])
<span class='lineno'>  85</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.inputs', title='?'>inputs</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.targets', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example.targets', title='?'>targets</a>
<span class='lineno'>  86</span> 
<span class='lineno'>  87</span> 
<span class='lineno'>  88</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length', title='((?, ?), ?) -> None / (?, int) -> None'>_filter_max_length</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.example', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.example', title='(?, ?)'>example</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.max_length', title='int'>max_length</a>=256):
<span class='lineno'>  89</span>   &quot;&quot;&quot;Indicates whether the example&#39;s length is lower than the maximum length.&quot;&quot;&quot;
<span class='lineno'>  90</span>   return tf.logical_and(tf.size(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.example', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.example', title='(?, ?)'>example</a>[0]) &lt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.max_length', title='int'>max_length</a>,
<span class='lineno'>  91</span>                         tf.size(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.example', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.example', title='(?, ?)'>example</a>[1]) &lt;= <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length.max_length', title='int'>max_length</a>)
<span class='lineno'>  92</span> 
<span class='lineno'>  93</span> 
<span class='lineno'>  94</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length', title='(?, ?) -> None / ? -> None'>_get_example_length</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length.example', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length.example', title='(?, ?)'>example</a>):
<span class='lineno'>  95</span>   &quot;&quot;&quot;Returns the maximum length between the example inputs and targets.&quot;&quot;&quot;
<span class='lineno'>  96</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length.length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length.length', title='?'>length</a> = tf.maximum(tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length.example', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length.example', title='(?, ?)'>example</a>[0])[0], tf.shape(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length.example', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length.example', title='(?, ?)'>example</a>[1])[0])
<span class='lineno'>  97</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length.length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length.length', title='?'>length</a>
<span class='lineno'>  98</span> 
<span class='lineno'>  99</span> 
<span class='lineno'> 100</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries', title='(?, int, float) -> ([int], [int])'>_create_min_max_boundaries</a>(
<span class='lineno'> 101</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.max_length', title='?'>max_length</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.min_boundary', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.min_boundary', title='int'>min_boundary</a>=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._MIN_BOUNDARY', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._MIN_BOUNDARY', title='int'>_MIN_BOUNDARY</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.boundary_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.boundary_scale', title='float'>boundary_scale</a>=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._BOUNDARY_SCALE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._BOUNDARY_SCALE', title='float'>_BOUNDARY_SCALE</a>):
<span class='lineno'> 102</span>   &quot;&quot;&quot;Create min and max boundary lists up to max_length.
<span class='lineno'> 103</span> 
<span class='lineno'> 104</span>   For example, when max_length=24, min_boundary=4 and boundary_scale=2, the
<span class='lineno'> 105</span>   returned values will be:
<span class='lineno'> 106</span>     buckets_min = [0, 4, 8, 16, 24]
<span class='lineno'> 107</span>     buckets_max = [4, 8, 16, 24, 25]
<span class='lineno'> 108</span> 
<span class='lineno'> 109</span>   Args:
<span class='lineno'> 110</span>     max_length: The maximum length of example in dataset.
<span class='lineno'> 111</span>     min_boundary: Minimum length in boundary.
<span class='lineno'> 112</span>     boundary_scale: Amount to scale consecutive boundaries in the list.
<span class='lineno'> 113</span> 
<span class='lineno'> 114</span>   Returns:
<span class='lineno'> 115</span>     min and max boundary lists
<span class='lineno'> 116</span> 
<span class='lineno'> 117</span>   &quot;&quot;&quot;
<span class='lineno'> 118</span>   # Create bucket boundaries list by scaling the previous boundary or adding 1
<span class='lineno'> 119</span>   # (to ensure increasing boundary sizes).
<span class='lineno'> 120</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.bucket_boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.bucket_boundaries', title='[int]'>bucket_boundaries</a> = []
<span class='lineno'> 121</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', title='int'>x</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.min_boundary', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.min_boundary', title='int'>min_boundary</a>
<span class='lineno'> 122</span>   while <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', title='int'>x</a> &lt; <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.max_length', title='?'>max_length</a>:
<span class='lineno'> 123</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.bucket_boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.bucket_boundaries', title='[int]'>bucket_boundaries</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', title='int'>x</a>)
<span class='lineno'> 124</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', title='int'>x</a> = max(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', title='int'>x</a> + 1, int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.x', title='int'>x</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.boundary_scale', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.boundary_scale', title='float'>boundary_scale</a>))
<span class='lineno'> 125</span> 
<span class='lineno'> 126</span>   # Create min and max boundary lists from the initial list.
<span class='lineno'> 127</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.buckets_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.buckets_min', title='[int]'>buckets_min</a> = [0] + <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.bucket_boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.bucket_boundaries', title='[int]'>bucket_boundaries</a>
<span class='lineno'> 128</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.buckets_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.buckets_max', title='[int]'>buckets_max</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.bucket_boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.bucket_boundaries', title='[int]'>bucket_boundaries</a> + [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.max_length', title='?'>max_length</a> + 1]
<span class='lineno'> 129</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.buckets_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.buckets_min', title='[int]'>buckets_min</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.buckets_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries.buckets_max', title='[int]'>buckets_max</a>
<span class='lineno'> 130</span> 
<span class='lineno'> 131</span> 
<span class='lineno'> 132</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples', title='(?, ?, ?) -> None'>_batch_examples</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.dataset', title='?'>dataset</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batch_size', title='?'>batch_size</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.max_length', title='?'>max_length</a>):
<span class='lineno'> 133</span>   &quot;&quot;&quot;Group examples by similar lengths, and return batched dataset.
<span class='lineno'> 134</span> 
<span class='lineno'> 135</span>   Each batch of similar-length examples are padded to the same length, and may
<span class='lineno'> 136</span>   have different number of elements in each batch, such that:
<span class='lineno'> 137</span>     group_batch_size * padded_length &lt;= batch_size.
<span class='lineno'> 138</span> 
<span class='lineno'> 139</span>   This decreases the number of padding tokens per batch, which improves the
<span class='lineno'> 140</span>   training speed.
<span class='lineno'> 141</span> 
<span class='lineno'> 142</span>   Args:
<span class='lineno'> 143</span>     dataset: Dataset of unbatched examples.
<span class='lineno'> 144</span>     batch_size: Max number of tokens per batch of examples.
<span class='lineno'> 145</span>     max_length: Max number of tokens in an example input or target sequence.
<span class='lineno'> 146</span> 
<span class='lineno'> 147</span>   Returns:
<span class='lineno'> 148</span>     Dataset of batched examples with similar lengths.
<span class='lineno'> 149</span>   &quot;&quot;&quot;
<span class='lineno'> 150</span>   # Get min and max boundary lists for each example. These are used to calculate
<span class='lineno'> 151</span>   # the `bucket_id`, which is the index at which:
<span class='lineno'> 152</span>   # buckets_min[bucket_id] &lt;= len(example) &lt; buckets_max[bucket_id]
<span class='lineno'> 153</span>   # Note that using both min and max lists improves the performance.
<span class='lineno'> 154</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.buckets_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.buckets_min', title='[int]'>buckets_min</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.buckets_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.buckets_max', title='[int]'>buckets_max</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._create_min_max_boundaries', title='(?, int, float) -> ([int], [int])'>_create_min_max_boundaries</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.max_length', title='?'>max_length</a>)
<span class='lineno'> 155</span> 
<span class='lineno'> 156</span>   # Create list of batch sizes for each bucket_id, so that
<span class='lineno'> 157</span>   # bucket_batch_size[bucket_id] * buckets_max[bucket_id] &lt;= batch_size
<span class='lineno'> 158</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.bucket_batch_sizes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.bucket_batch_sizes', title='[int]'>bucket_batch_sizes</a> = [int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batch_size', title='?'>batch_size</a>) // <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.x', title='int'>x</a> for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.x', title='int'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.x', title='int'>x</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.buckets_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.buckets_max', title='[int]'>buckets_max</a>]
<span class='lineno'> 159</span>   # bucket_id will be a tensor, so convert this list to a tensor as well.
<span class='lineno'> 160</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.bucket_batch_sizes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.bucket_batch_sizes', title='?'>bucket_batch_sizes</a> = tf.constant(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.bucket_batch_sizes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.bucket_batch_sizes', title='[int]'>bucket_batch_sizes</a>, dtype=tf.int64)
<span class='lineno'> 161</span> 
<span class='lineno'> 162</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id', title='(?, ?) -> None'>example_to_bucket_id</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.example_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.example_input', title='?'>example_input</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.example_target', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.example_target', title='?'>example_target</a>):
<span class='lineno'> 163</span>     &quot;&quot;&quot;Return int64 bucket id for this example, calculated based on length.&quot;&quot;&quot;
<span class='lineno'> 164</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.seq_length', title='None'>seq_length</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._get_example_length', title='(?, ?) -> None / ? -> None'>_get_example_length</a>((<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.example_input', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.example_input', title='?'>example_input</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.example_target', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.example_target', title='?'>example_target</a>))
<span class='lineno'> 165</span> 
<span class='lineno'> 166</span>     # TODO(xunkai): investigate if removing code branching improves performance.
<span class='lineno'> 167</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.conditions_c', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.conditions_c', title='?'>conditions_c</a> = tf.logical_and(
<span class='lineno'> 168</span>         tf.less_equal(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.buckets_min', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.buckets_min', title='[int]'>buckets_min</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.seq_length', title='None'>seq_length</a>),
<span class='lineno'> 169</span>         tf.less(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.seq_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.seq_length', title='None'>seq_length</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.buckets_max', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.buckets_max', title='[int]'>buckets_max</a>))
<span class='lineno'> 170</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.bucket_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.bucket_id', title='?'>bucket_id</a> = tf.reduce_min(tf.where(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.conditions_c', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.conditions_c', title='?'>conditions_c</a>))
<span class='lineno'> 171</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.bucket_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id.bucket_id', title='?'>bucket_id</a>
<span class='lineno'> 172</span> 
<span class='lineno'> 173</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.window_size_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.window_size_fn', title='? -> None'>window_size_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.window_size_fn.bucket_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.window_size_fn.bucket_id', title='?'>bucket_id</a>):
<span class='lineno'> 174</span>     &quot;&quot;&quot;Return number of examples to be grouped when given a bucket id.&quot;&quot;&quot;
<span class='lineno'> 175</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.bucket_batch_sizes', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.bucket_batch_sizes', title='?'>bucket_batch_sizes</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.window_size_fn.bucket_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.window_size_fn.bucket_id', title='?'>bucket_id</a>]
<span class='lineno'> 176</span> 
<span class='lineno'> 177</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn', title='(?, ?) -> None'>batching_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.bucket_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.bucket_id', title='?'>bucket_id</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.grouped_dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.grouped_dataset', title='?'>grouped_dataset</a>):
<span class='lineno'> 178</span>     &quot;&quot;&quot;Batch and add padding to a dataset of elements with similar lengths.&quot;&quot;&quot;
<span class='lineno'> 179</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.bucket_batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.bucket_batch_size', title='None'>bucket_batch_size</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.window_size_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.window_size_fn', title='? -> None'>window_size_fn</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.bucket_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.bucket_id', title='?'>bucket_id</a>)
<span class='lineno'> 180</span> 
<span class='lineno'> 181</span>     # Batch the dataset and add padding so that all input sequences in the
<span class='lineno'> 182</span>     # examples have the same length, and all target sequences have the same
<span class='lineno'> 183</span>     # lengths as well. Resulting lengths of inputs and targets can differ.
<span class='lineno'> 184</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.grouped_dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.grouped_dataset', title='?'>grouped_dataset</a>.padded_batch(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.bucket_batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn.bucket_batch_size', title='None'>bucket_batch_size</a>, ([None], [None]))
<span class='lineno'> 185</span> 
<span class='lineno'> 186</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.dataset', title='?'>dataset</a>.apply(tf.data.experimental.group_by_window(
<span class='lineno'> 187</span>       key_func=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.example_to_bucket_id', title='(?, ?) -> None'>example_to_bucket_id</a>,
<span class='lineno'> 188</span>       reduce_func=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.batching_fn', title='(?, ?) -> None'>batching_fn</a>,
<span class='lineno'> 189</span>       window_size=None,
<span class='lineno'> 190</span>       window_size_func=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.window_size_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples.window_size_fn', title='? -> None'>window_size_fn</a>))
<span class='lineno'> 191</span> 
<span class='lineno'> 192</span> 
<span class='lineno'> 193</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files', title='(?, ?, ?, ?, ?, ?, bool, int, None) -> None / (str, ?, ?, ?, bool, int, bool, int, None) -> None / (str, ?, ?, ?, bool, ?, bool, int, None) -> None'>_read_and_batch_from_files</a>(
<span class='lineno'> 194</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.file_pattern', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.file_pattern', title='str'>file_pattern</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.batch_size', title='?'>batch_size</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', title='?'>max_length</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_io_parallelism', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_io_parallelism', title='?'>max_io_parallelism</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.shuffle', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.shuffle', title='bool'>shuffle</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.repeat', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.repeat', title='int'>repeat</a>,
<span class='lineno'> 195</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.static_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.static_batch', title='bool'>static_batch</a>=False, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.num_replicas', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.num_replicas', title='int'>num_replicas</a>=1, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', title='None'>ctx</a>=None):
<span class='lineno'> 196</span>   &quot;&quot;&quot;Create dataset where each item is a dict of &quot;inputs&quot; and &quot;targets&quot;.
<span class='lineno'> 197</span> 
<span class='lineno'> 198</span>   Args:
<span class='lineno'> 199</span>     file_pattern: String used to match the input TFRecord files.
<span class='lineno'> 200</span>     batch_size: Maximum number of tokens per global batch of examples.
<span class='lineno'> 201</span>     max_length: Maximum number of tokens per example
<span class='lineno'> 202</span>     max_io_parallelism: Max number of cpu cores for parallel input processing.
<span class='lineno'> 203</span>     shuffle: If true, randomizes order of elements.
<span class='lineno'> 204</span>     repeat: Number of times to repeat the dataset. If None, the dataset is
<span class='lineno'> 205</span>       repeated forever.
<span class='lineno'> 206</span>     static_batch: Whether the batches in the dataset should have static shapes.
<span class='lineno'> 207</span>       If True, the input is batched so that every batch has the
<span class='lineno'> 208</span>       shape [batch_size // max_length, max_length]. If False, the input is
<span class='lineno'> 209</span>       grouped by length, and batched so that batches may have different
<span class='lineno'> 210</span>       shapes [N, M], where:
<span class='lineno'> 211</span>         N * M &lt;= batch_size
<span class='lineno'> 212</span>         M &lt;= max_length
<span class='lineno'> 213</span>       In general, this setting should be False. Dynamic shapes allow the inputs
<span class='lineno'> 214</span>       to be grouped so that the number of padding tokens is minimized, and helps
<span class='lineno'> 215</span>       model training. In cases where the input shape must be static
<span class='lineno'> 216</span>       (e.g. running on TPU), this setting should be set to True.
<span class='lineno'> 217</span>     num_replicas: Number of GPUs or other workers. We will generate global
<span class='lineno'> 218</span>       batches, and each global batch is equally divisible by number of replicas.
<span class='lineno'> 219</span>       Currently it is only effective when static_batch==True. TODO: make it
<span class='lineno'> 220</span>       effective when static_batch=False.
<span class='lineno'> 221</span>     ctx: Input context.
<span class='lineno'> 222</span> 
<span class='lineno'> 223</span>   Returns:
<span class='lineno'> 224</span>     tf.data.Dataset object containing examples loaded from the files.
<span class='lineno'> 225</span>   &quot;&quot;&quot;
<span class='lineno'> 226</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a> = tf.data.Dataset.list_files(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.file_pattern', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.file_pattern', title='str'>file_pattern</a>, shuffle=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.shuffle', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.shuffle', title='bool'>shuffle</a>)
<span class='lineno'> 227</span> 
<span class='lineno'> 228</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', title='None'>ctx</a> and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', title='None'>ctx</a>.num_input_pipelines &gt; 1:
<span class='lineno'> 229</span>     logging.info(&quot;Shard %d of the dataset.&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', title='None'>ctx</a>.input_pipeline_id)
<span class='lineno'> 230</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a>.shard(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', title='None'>ctx</a>.num_input_pipelines, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.ctx', title='None'>ctx</a>.input_pipeline_id)
<span class='lineno'> 231</span> 
<span class='lineno'> 232</span>   # Read files and interleave results. When training, the order of the examples
<span class='lineno'> 233</span>   # will be non-deterministic.
<span class='lineno'> 234</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.options', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.options', title='?'>options</a> = tf.data.Options()
<span class='lineno'> 235</span>   <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.options', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.options', title='?'>options</a>.experimental_deterministic = False
<span class='lineno'> 236</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a>.interleave(
<span class='lineno'> 237</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._load_records', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._load_records', title='? -> None'>_load_records</a>,
<span class='lineno'> 238</span>       cycle_length=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_io_parallelism', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_io_parallelism', title='?'>max_io_parallelism</a>,
<span class='lineno'> 239</span>       num_parallel_calls=tf.data.experimental.AUTOTUNE).with_options(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.options', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.options', title='?'>options</a>)
<span class='lineno'> 240</span> 
<span class='lineno'> 241</span>   # Parse each tf.Example into a dictionary
<span class='lineno'> 242</span>   # TODO: Look into prefetch_input_elements for performance optimization.
<span class='lineno'> 243</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a>.map(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._parse_example', title='? -> (?, ?)'>_parse_example</a>,
<span class='lineno'> 244</span>                         num_parallel_calls=tf.data.experimental.AUTOTUNE)
<span class='lineno'> 245</span> 
<span class='lineno'> 246</span>   # Remove examples where the input or target length exceeds the maximum length,
<span class='lineno'> 247</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a>.filter(lambda <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.lambda%116.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.lambda%116.x', title='?'>x</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.lambda%116.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.lambda%116.y', title='?'>y</a>: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._filter_max_length', title='((?, ?), ?) -> None / (?, int) -> None'>_filter_max_length</a>((<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.lambda%116.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.lambda%116.x', title='?'>x</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.lambda%116.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.lambda%116.y', title='?'>y</a>), <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', title='?'>max_length</a>))
<span class='lineno'> 248</span> 
<span class='lineno'> 249</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.static_batch', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.static_batch', title='bool'>static_batch</a>:
<span class='lineno'> 250</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a>.padded_batch(
<span class='lineno'> 251</span>         # First calculate batch size (token number) per worker, then divide it
<span class='lineno'> 252</span>         # into sentences, and finally expand to a global batch. It could prove
<span class='lineno'> 253</span>         # the global batch divisble for distribution strategy.
<span class='lineno'> 254</span>         int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.batch_size', title='?'>batch_size</a> // <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.num_replicas', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.num_replicas', title='int'>num_replicas</a> // <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', title='?'>max_length</a> * <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.num_replicas', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.num_replicas', title='int'>num_replicas</a>),
<span class='lineno'> 255</span>         ([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', title='?'>max_length</a>], [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', title='?'>max_length</a>]), drop_remainder=True)
<span class='lineno'> 256</span>   else:
<span class='lineno'> 257</span>     # Group and batch such that each batch has examples of similar length.
<span class='lineno'> 258</span>     # TODO(xunkai): _batch_examples might need to do something special for
<span class='lineno'> 259</span>     # num_replicas.
<span class='lineno'> 260</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='None'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._batch_examples', title='(?, ?, ?) -> None'>_batch_examples</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.batch_size', title='?'>batch_size</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.max_length', title='?'>max_length</a>)
<span class='lineno'> 261</span> 
<span class='lineno'> 262</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='None'>dataset</a>.repeat(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.repeat', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.repeat', title='int'>repeat</a>)
<span class='lineno'> 263</span> 
<span class='lineno'> 264</span>   # Prefetch the next element to improve speed of input pipeline.
<span class='lineno'> 265</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a>.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
<span class='lineno'> 266</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files.dataset', title='?'>dataset</a>
<span class='lineno'> 267</span> 
<span class='lineno'> 268</span> 
<span class='lineno'> 269</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data', title='? -> None'>_generate_synthetic_data</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.params', title='?'>params</a>):
<span class='lineno'> 270</span>   &quot;&quot;&quot;Create synthetic data based on the parameter batch size.&quot;&quot;&quot;
<span class='lineno'> 271</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.batch_size', title='int'>batch_size</a> = int(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.params', title='?'>params</a>[&quot;batch_size&quot;] // <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.params', title='?'>params</a>[&quot;max_length&quot;])
<span class='lineno'> 272</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.length', title='?'>length</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.params', title='?'>params</a>[&quot;max_length&quot;]
<span class='lineno'> 273</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', title='?'>dataset</a> = model_helpers.generate_synthetic_data(
<span class='lineno'> 274</span>       input_shape=tf.TensorShape([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.length', title='?'>length</a>]),
<span class='lineno'> 275</span>       input_value=1,
<span class='lineno'> 276</span>       input_dtype=tf.int64,
<span class='lineno'> 277</span>       label_shape=tf.TensorShape([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.length', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.length', title='?'>length</a>]),
<span class='lineno'> 278</span>       label_value=1,
<span class='lineno'> 279</span>       label_dtype=tf.int64,
<span class='lineno'> 280</span>   )
<span class='lineno'> 281</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.params', title='?'>params</a>[&quot;static_batch&quot;]:
<span class='lineno'> 282</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', title='?'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', title='?'>dataset</a>.batch(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.batch_size', title='int'>batch_size</a>, drop_remainder=True)
<span class='lineno'> 283</span>   else:
<span class='lineno'> 284</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', title='?'>dataset</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', title='?'>dataset</a>.padded_batch(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.batch_size', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.batch_size', title='int'>batch_size</a>, ([None], [None]))
<span class='lineno'> 285</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data.dataset', title='?'>dataset</a>
<span class='lineno'> 286</span> 
<span class='lineno'> 287</span> 
<span class='lineno'> 288</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn', title='(?, None) -> None'>train_input_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', title='?'>params</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.ctx', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.ctx', title='None'>ctx</a>=None):
<span class='lineno'> 289</span>   &quot;&quot;&quot;Load and return dataset of batched examples for use during training.&quot;&quot;&quot;
<span class='lineno'> 290</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.file_pattern', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.file_pattern', title='str'>file_pattern</a> = os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', title='?'>params</a>[&quot;data_dir&quot;] or &quot;&quot;, &quot;*train*&quot;)
<span class='lineno'> 291</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', title='?'>params</a>[&quot;use_synthetic_data&quot;]:
<span class='lineno'> 292</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data', title='? -> None'>_generate_synthetic_data</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', title='?'>params</a>)
<span class='lineno'> 293</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files', title='(?, ?, ?, ?, ?, ?, bool, int, None) -> None / (str, ?, ?, ?, bool, int, bool, int, None) -> None / (str, ?, ?, ?, bool, ?, bool, int, None) -> None'>_read_and_batch_from_files</a>(
<span class='lineno'> 294</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.file_pattern', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.file_pattern', title='str'>file_pattern</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', title='?'>params</a>[&quot;batch_size&quot;], <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', title='?'>params</a>[&quot;max_length&quot;],
<span class='lineno'> 295</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', title='?'>params</a>[&quot;max_io_parallelism&quot;], shuffle=True,
<span class='lineno'> 296</span>       repeat=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', title='?'>params</a>[&quot;repeat_dataset&quot;], static_batch=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', title='?'>params</a>[&quot;static_batch&quot;],
<span class='lineno'> 297</span>       num_replicas=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.params', title='?'>params</a>[&quot;num_gpus&quot;], ctx=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.ctx', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.train_input_fn.ctx', title='None'>ctx</a>)
<span class='lineno'> 298</span> 
<span class='lineno'> 299</span> 
<span class='lineno'> 300</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn', title='(?, None) -> None'>eval_input_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', title='?'>params</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.ctx', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.ctx', title='None'>ctx</a>=None):
<span class='lineno'> 301</span>   &quot;&quot;&quot;Load and return dataset of batched examples for use during evaluation.&quot;&quot;&quot;
<span class='lineno'> 302</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.file_pattern', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.file_pattern', title='str'>file_pattern</a> = os.path.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', title='?'>params</a>[&quot;data_dir&quot;] or &quot;&quot;, &quot;*dev*&quot;)
<span class='lineno'> 303</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', title='?'>params</a>[&quot;use_synthetic_data&quot;]:
<span class='lineno'> 304</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._generate_synthetic_data', title='? -> None'>_generate_synthetic_data</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', title='?'>params</a>)
<span class='lineno'> 305</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline._read_and_batch_from_files', title='(?, ?, ?, ?, ?, ?, bool, int, None) -> None / (str, ?, ?, ?, bool, int, bool, int, None) -> None / (str, ?, ?, ?, bool, ?, bool, int, None) -> None'>_read_and_batch_from_files</a>(
<span class='lineno'> 306</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.file_pattern', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.file_pattern', title='str'>file_pattern</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', title='?'>params</a>[&quot;batch_size&quot;], <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', title='?'>params</a>[&quot;max_length&quot;],
<span class='lineno'> 307</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', title='?'>params</a>[&quot;max_io_parallelism&quot;], shuffle=False, repeat=1,
<span class='lineno'> 308</span>       static_batch=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', title='?'>params</a>[&quot;static_batch&quot;], num_replicas=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.params', title='?'>params</a>[&quot;num_gpus&quot;],
<span class='lineno'> 309</span>       ctx=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.ctx', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.eval_input_fn.ctx', title='None'>ctx</a>)
<span class='lineno'> 310</span> 
<span class='lineno'> 311</span> 
<span class='lineno'> 312</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn', title='(?, ?) -> (?, ?)'>map_data_for_transformer_fn</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn.x', title='?'>x</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn.y', title='?'>y</a>):
<span class='lineno'> 313</span>   &quot;&quot;&quot;Maps data for training, and handles weried behaviors for different vers.&quot;&quot;&quot;
<span class='lineno'> 314</span>   # Will transform input x and targets y into tuple(x, y) as new model inputs.
<span class='lineno'> 315</span>   # For TF v2, the 2nd parameter is omitted to make Keras training work.
<span class='lineno'> 316</span>   return ((<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn.x', title='?'>x</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn.y', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.transformer.data_pipeline.map_data_for_transformer_fn.y', title='?'>y</a>),)
</pre></td></tr></table></body></html>